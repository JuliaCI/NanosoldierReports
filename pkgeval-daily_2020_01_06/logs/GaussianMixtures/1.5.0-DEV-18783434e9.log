Julia Version 1.5.0-DEV.11
Commit 18783434e9 (2020-01-04 00:48 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed CMake ────────────── v1.1.2
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Blosc ────────────── v0.5.1
 Installed JLD ──────────────── v0.9.1
 Installed BinDeps ──────────── v1.0.0
 Installed QuadGK ───────────── v2.3.1
 Installed StatsFuns ────────── v0.9.3
 Installed Parameters ───────── v0.12.0
 Installed OrderedCollections ─ v1.1.0
 Installed Missings ─────────── v0.4.3
 Installed DataAPI ──────────── v1.1.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed SpecialFunctions ─── v0.9.0
 Installed Rmath ────────────── v0.6.0
 Installed HDF5 ─────────────── v0.12.5
 Installed URIParser ────────── v0.4.0
 Installed NearestNeighbors ─── v0.4.4
 Installed Compat ───────────── v2.2.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed SortingAlgorithms ── v0.3.1
 Installed LegacyStrings ────── v0.4.1
 Installed StatsBase ────────── v0.32.0
 Installed Arpack ───────────── v0.4.0
 Installed FillArrays ───────── v0.8.2
 Installed BinaryProvider ───── v0.5.8
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed DataStructures ───── v0.17.7
 Installed OpenBLAS_jll ─────── v0.3.7+3
 Installed FileIO ───────────── v1.2.1
 Installed Clustering ───────── v0.13.3
 Installed Distributions ────── v0.21.12
 Installed StaticArrays ─────── v0.12.1
 Installed PDMats ───────────── v0.9.10
 Installed Distances ────────── v0.8.2
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.12
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+3
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_GXkAya/Project.toml`
 [no changes]
  Updating `/tmp/jl_GXkAya/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_ZVyZmn/Project.toml`
 [no changes]
  Updating `/tmp/jl_ZVyZmn/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_0QV02D/Project.toml`
 [no changes]
  Updating `/tmp/jl_0QV02D/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_3vA4lb/Project.toml`
 [no changes]
  Updating `/tmp/jl_3vA4lb/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_ip0Wxd/Project.toml`
 [no changes]
  Updating `/tmp/jl_ip0Wxd/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_ip0Wxd/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.12
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -7.9720419298595525e6, [94590.74594827378, 5409.254051726228], [4609.177091667915 -69.26821533497423 3476.222725996929; -5116.951709304222 -175.84461098110464 -3947.62962357132], [[90987.68475105031 1019.2073951364133 -3331.5431781402167; 1019.2073951364133 99713.95246827856 818.3959150805308; -3331.5431781402167 818.3959150805308 90236.06453431131], [8543.346779915577 -779.5680017979023 3193.6080713337637; -779.5680017979023 556.1380372403825 -808.64502788582; 3193.6080713337637 -808.6450278858199 9531.389192086504]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.069621e+03
      1       1.147917e+03      -9.217038e+02 |        6
      2       9.514972e+02      -1.964200e+02 |        5
      3       8.782043e+02      -7.329291e+01 |        2
      4       8.527768e+02      -2.542751e+01 |        2
      5       8.228799e+02      -2.989688e+01 |        2
      6       8.165522e+02      -6.327700e+00 |        0
      7       8.165522e+02       0.000000e+00 |        0
K-means converged with 7 iterations (objv = 816.5521842446792)
┌ Info: K-means with 272 data points using 7 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.059902
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.847351
[ Info: iteration 2, lowerbound -3.736683
[ Info: iteration 3, lowerbound -3.613335
[ Info: iteration 4, lowerbound -3.467066
[ Info: iteration 5, lowerbound -3.323700
[ Info: iteration 6, lowerbound -3.212361
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.141959
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -3.093492
[ Info: iteration 9, lowerbound -3.075989
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -3.062895
[ Info: iteration 11, lowerbound -3.045124
[ Info: iteration 12, lowerbound -3.029421
[ Info: iteration 13, lowerbound -3.006237
[ Info: iteration 14, lowerbound -2.972604
[ Info: iteration 15, lowerbound -2.925027
[ Info: iteration 16, lowerbound -2.860217
[ Info: iteration 17, lowerbound -2.777158
[ Info: iteration 18, lowerbound -2.680872
[ Info: iteration 19, lowerbound -2.584723
[ Info: iteration 20, lowerbound -2.503756
[ Info: iteration 21, lowerbound -2.444437
[ Info: iteration 22, lowerbound -2.405947
[ Info: dropping number of Gaussions to 3
[ Info: iteration 23, lowerbound -2.369455
[ Info: iteration 24, lowerbound -2.337331
[ Info: iteration 25, lowerbound -2.316183
[ Info: iteration 26, lowerbound -2.307497
[ Info: dropping number of Gaussions to 2
[ Info: iteration 27, lowerbound -2.302969
[ Info: iteration 28, lowerbound -2.299261
[ Info: iteration 29, lowerbound -2.299257
[ Info: iteration 30, lowerbound -2.299255
[ Info: iteration 31, lowerbound -2.299254
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Jan  6 13:47:56 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Jan  6 13:48:05 2020: K-means with 272 data points using 7 iterations
11.3 data points per parameter
, Mon Jan  6 13:48:07 2020: EM with 272 data points 0 iterations avll -2.059902
5.8 data points per parameter
, Mon Jan  6 13:48:09 2020: GMM converted to Variational GMM
, Mon Jan  6 13:48:18 2020: iteration 1, lowerbound -3.847351
, Mon Jan  6 13:48:18 2020: iteration 2, lowerbound -3.736683
, Mon Jan  6 13:48:18 2020: iteration 3, lowerbound -3.613335
, Mon Jan  6 13:48:18 2020: iteration 4, lowerbound -3.467066
, Mon Jan  6 13:48:18 2020: iteration 5, lowerbound -3.323700
, Mon Jan  6 13:48:18 2020: iteration 6, lowerbound -3.212361
, Mon Jan  6 13:48:18 2020: dropping number of Gaussions to 7
, Mon Jan  6 13:48:18 2020: iteration 7, lowerbound -3.141959
, Mon Jan  6 13:48:18 2020: dropping number of Gaussions to 6
, Mon Jan  6 13:48:18 2020: iteration 8, lowerbound -3.093492
, Mon Jan  6 13:48:18 2020: iteration 9, lowerbound -3.075989
, Mon Jan  6 13:48:18 2020: dropping number of Gaussions to 4
, Mon Jan  6 13:48:18 2020: iteration 10, lowerbound -3.062895
, Mon Jan  6 13:48:18 2020: iteration 11, lowerbound -3.045124
, Mon Jan  6 13:48:18 2020: iteration 12, lowerbound -3.029421
, Mon Jan  6 13:48:18 2020: iteration 13, lowerbound -3.006237
, Mon Jan  6 13:48:18 2020: iteration 14, lowerbound -2.972604
, Mon Jan  6 13:48:18 2020: iteration 15, lowerbound -2.925027
, Mon Jan  6 13:48:18 2020: iteration 16, lowerbound -2.860217
, Mon Jan  6 13:48:18 2020: iteration 17, lowerbound -2.777158
, Mon Jan  6 13:48:18 2020: iteration 18, lowerbound -2.680872
, Mon Jan  6 13:48:18 2020: iteration 19, lowerbound -2.584723
, Mon Jan  6 13:48:18 2020: iteration 20, lowerbound -2.503756
, Mon Jan  6 13:48:18 2020: iteration 21, lowerbound -2.444437
, Mon Jan  6 13:48:18 2020: iteration 22, lowerbound -2.405947
, Mon Jan  6 13:48:18 2020: dropping number of Gaussions to 3
, Mon Jan  6 13:48:18 2020: iteration 23, lowerbound -2.369455
, Mon Jan  6 13:48:18 2020: iteration 24, lowerbound -2.337331
, Mon Jan  6 13:48:18 2020: iteration 25, lowerbound -2.316183
, Mon Jan  6 13:48:18 2020: iteration 26, lowerbound -2.307497
, Mon Jan  6 13:48:18 2020: dropping number of Gaussions to 2
, Mon Jan  6 13:48:18 2020: iteration 27, lowerbound -2.302969
, Mon Jan  6 13:48:18 2020: iteration 28, lowerbound -2.299261
, Mon Jan  6 13:48:18 2020: iteration 29, lowerbound -2.299257
, Mon Jan  6 13:48:18 2020: iteration 30, lowerbound -2.299255
, Mon Jan  6 13:48:18 2020: iteration 31, lowerbound -2.299254
, Mon Jan  6 13:48:18 2020: iteration 32, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 33, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 34, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 35, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 36, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 37, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 38, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 39, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 40, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 41, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 42, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 43, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 44, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 45, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 46, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 47, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 48, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 49, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: iteration 50, lowerbound -2.299253
, Mon Jan  6 13:48:18 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777379669, 178.04509222620342]
β = [95.95490777379669, 178.04509222620342]
m = [2.000229257773778 53.85198717245298; 4.250300733268371 79.2868669443392]
ν = [97.95490777379669, 180.04509222620342]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119748596 -0.00895312382737764; 0.0 0.01274866477741723], [0.18404155547463416 -0.007644049042347513; 0.0 0.008581705166304682]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0050568027230584
avll from llpg:  -1.0050568027230584
avll direct:     -1.0050568027230584
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0029478348322116
avll from llpg:  -1.0029478348322116
avll direct:     -1.0029478348322116
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0354588    0.0524062   -0.0800875    0.118686      0.0677672    0.0337035   -0.0846249    0.0876664     0.0950655   -0.0207026    0.131665      0.0694783     0.063349    -0.00092953  -0.111126    -0.0163236    0.0364201    0.0553977    0.0695209   -0.0628972    -0.136328     0.054549    -0.0333745   -0.0567062    0.0169999   -0.00817417
 -0.0341124    0.10618     -0.0175875   -0.0954725    -0.0917565   -0.0666995    0.0690313    0.0859425     0.139734    -0.106368    -0.069007      0.149086      0.00738447   0.109534     0.0726967   -0.0574966   -0.100424     0.0724251    0.147475    -0.0585835    -0.132999    -0.0657028   -0.108726    -0.0625211    0.054456     0.00344589
  0.167407    -0.103875     0.0467324   -0.0267926     0.019472     0.00499245  -0.105637    -0.14122       0.101512    -0.0914281    0.000224901   0.0802493    -0.0485357   -0.0704436    0.0184657    0.174484     0.0445823    0.0196922   -0.0530649   -0.181385     -0.0614709    0.132012    -0.126561     0.0438575   -0.0727102    0.0829014
  0.180735     0.00395982   0.193197     0.253982      0.0594824    0.00048006  -0.13258      0.0240371     0.0760296   -0.118494    -0.136733     -0.0552679    -0.0172673   -0.113238     0.0433957   -0.017468     0.234133     0.0120264   -0.160131     0.030699     -0.0661584    0.136002    -0.0404381    0.0704082    0.0925167    0.139556
 -0.0162625    0.0331542   -0.0460091   -0.0995421    -0.234315    -0.0125041    0.0843162   -0.0652581     0.110819     0.105864    -0.0194629     0.0399643     0.0281237    0.0190254    0.0129945    0.109178     0.0277039    0.228626    -0.0712005    0.151103     -0.0207583   -0.135231    -0.00473661   0.167471     0.0988552   -0.202987
 -0.0226289    0.126916     0.250794     0.0157672     0.0405202   -0.0305706   -0.0584583   -0.0950198    -0.0528122   -0.00148064  -0.0637653    -0.122951     -0.0894533    0.0636611   -0.0539374    0.0259328    0.0488628   -0.128409    -0.130242     0.00792167    0.0410489   -0.0509561    0.0488588    0.00960586   0.277263    -0.137146
  0.200805    -0.119191     0.160983    -0.00589518   -0.117784     0.0370629   -0.0520622   -0.0220135     0.227293     0.116535     0.0967095    -0.208759      0.0267071    0.208       -0.206085    -0.121778     0.00869927  -0.0136106   -0.121158    -0.0288271     0.0968422   -0.0910297    0.165919    -0.0993266   -0.124549     0.0466827
  0.0393304    0.0114524    0.00610003   0.0320762     0.03741     -0.129681    -0.0259259   -0.0284934    -0.0820792    0.0388987    0.106123      0.0344178     0.134258    -0.188404     0.151629     0.00739393  -0.0143568   -0.0157292    0.0760648   -0.0285013    -0.159639     0.0963566    0.189752    -0.00602687   0.0409813    0.159067
 -0.202296     0.0211417   -0.00622614  -0.0125543     0.0720246   -0.0101668   -0.181843     0.060038     -0.0390981   -0.0241968   -0.00923209   -0.000316276  -0.20177     -0.0273076   -0.00269763   0.170466    -0.101252     0.0764745   -0.0563058    0.0354654    -0.0864049   -0.00443483   0.296479    -0.0825102    0.100333    -0.0470816
  0.0707041    0.00408449   0.0153419   -0.0449925     0.046901     0.126199    -0.280375     0.0813677    -0.0463816   -0.0577842    0.0841985     0.0681904    -0.0506919    0.0460215    0.0914826   -0.0331017   -0.0334356    0.183541    -0.0875126    0.256891     -0.107225     0.115709    -0.0385195   -0.0358826    0.0657598    0.162162
 -0.127508    -0.0362126   -0.12842      0.0563781    -0.0449657   -0.036722     0.160635    -0.0207917    -0.0482364    0.113802     0.148331      0.0653272    -0.107707    -0.0470107   -0.0642112    0.163105    -0.0924551    0.146223    -0.163384     0.238428     -0.0997375   -8.45719e-5   0.0856991    0.0032465    0.123432    -0.0449117
  0.0487371   -0.0661243    0.172509    -0.0388725    -0.00824008   0.0324085   -0.0546358    0.152169      0.0455388   -0.0149283   -0.136683      0.13755      -0.0544954    0.0877224   -0.0529636   -0.151316    -0.0596047   -0.121476     0.06271     -0.13165      -0.0540138    0.188604    -0.0743665    0.0207204   -0.152612    -0.0623541
 -0.00233984  -0.0669579   -0.126565     0.00980118    0.0582178    0.0492628    0.0998301   -0.129067     -0.0196584    0.0630536   -0.148429      0.039152     -0.0793827    0.048368    -0.273419     0.0500195    0.150786    -0.116739    -0.00162042   0.0616473    -0.16574     -0.065793    -0.0293177   -0.133761     0.00371478   0.0182559
  0.0344554   -0.123232     0.0645471    0.119482     -0.133278    -0.010508     0.0646346    0.0502317    -0.0115975   -0.0289231   -0.0480401     0.12463      -0.0233742    0.0741006   -0.0648672    0.0741592   -0.121193     0.00366561  -0.0144452    0.00988594   -0.0122033   -0.0585442    0.0648098   -0.113701    -0.045696     0.0352127
  0.0801555    0.105462    -0.0339416   -0.0471945     0.0335498   -0.137698     0.0447016    0.0545876     0.105652    -0.0176632    0.0727344     0.0122601    -0.114117     0.17007      0.0287566    0.00122942  -0.150554    -0.0597297    0.0755796   -0.0472477     0.224507     0.0974286    0.030919    -0.00600034  -0.0239913    0.0419786
  0.0207033   -0.185718    -0.0392817   -0.282811     -0.0908745    0.10868      0.24883      0.168519     -0.0118242   -0.0315206    0.0283394     0.195974      0.223195    -0.0891288    0.144403    -0.0646572   -0.0316952    0.053799    -0.0259512   -0.113622      0.125358     0.135377     0.0309568    0.089611     0.0702293    0.241654
  0.134497     0.0178599   -0.00516467   0.0225761     0.0366395   -0.104244     0.00539515  -0.0691864     0.0831971   -0.0583217   -0.216141      0.132284      0.097767     0.0306804    0.0812043   -0.0508469   -0.0284169   -0.0681195   -0.0263888   -0.108019      0.0313999    0.0223096   -0.0422323   -0.0835819    0.0246012   -0.307368
 -0.109413     0.131337    -0.0695479    0.217161     -0.0188643   -0.0464481   -0.0577456    0.0149463     0.0882818    0.0177565   -0.00565751    0.00986936   -0.00852022   0.037923     0.12956     -0.00708562   0.070285    -0.0361974    0.0857017    0.000439854   0.110664    -0.0203932   -0.109271     0.124815    -0.0547345   -0.0806549
  0.0209502    0.0515204    0.0883723   -0.181381      0.02856      0.119778    -0.0478784    0.000725404  -0.109686     0.0250894   -0.0795242    -0.0504302    -0.084471    -0.191728     0.0235641    0.0737849   -0.0124302    0.0986596   -0.0310469    0.0650652     0.0783794   -0.0795273   -0.0245227    0.153884     0.00517183  -0.0572782
  0.0102825    0.00711702  -0.0627822    0.00764814    0.0158925   -0.103044    -0.189962     0.153515      0.0129911    0.126643     0.104121      0.0897328    -0.0684355    0.0696305   -0.0481052   -0.0271638   -0.0898059   -0.0166622    0.0970994   -0.0476076    -0.105909     0.287857    -0.0357813   -0.0253984    0.0611832   -0.0608016
 -0.105225     0.0485794   -0.116512     0.0804069     0.121147     0.020279    -0.0854646   -0.0369597    -0.0270616    0.212126    -0.134372      0.0492162    -0.126294    -0.00836956   0.0635053    0.137613    -0.0141932   -0.0574642   -0.00939497   0.0965962     0.042985     0.0586148    0.0361022    0.00725938   0.101184     0.0240425
  0.132454    -0.0623686    0.035107     0.091591     -0.0538766   -0.141316     0.0767597   -0.0815642    -0.113355     0.138252     0.0479976    -0.00951036    0.0547078    0.0347102    0.0297878    0.0402748    0.202147    -0.00970999  -0.0697267   -0.0360092     0.221103     0.221783     0.131069     0.0906503    0.0210426   -0.115837
  0.00416203  -0.199014    -0.0524137    0.157036     -0.034792     0.00359209   0.103776     0.0760316     0.137515    -0.098946     0.0182335    -0.0598026    -0.120912     0.271595    -0.163408    -0.0192238    0.114758    -0.206506     0.128885    -0.0755259    -0.0436921   -0.0777473   -0.117651    -0.122106    -0.104576    -0.0204553
 -0.0429027   -0.127409    -0.00760942   0.0212462    -0.0831913   -0.0584575   -0.00212292  -0.059124     -0.0026458   -0.0241696   -0.0928939    -0.0709967     0.107254     0.00810144  -0.0878883   -0.238919    -0.0783824   -0.0931172   -0.0962217    0.0187669     0.0756999    0.0473238   -0.20135     -0.0954984   -0.0393371    0.0488768
 -0.0526054    0.0205399   -0.0695869    0.0912187    -0.0228219    0.141125     0.0604621    0.0278623     0.119371    -0.00865934   0.0773633     0.218575      0.144572    -0.00523281  -0.126973     0.172338    -0.0861222    0.184004    -0.173038    -0.0632787    -0.00561652   0.077039     0.0315911    0.18864      0.0765774    0.00714487
  0.0244353   -0.00734216   0.131458     0.000442214  -0.161851     0.050663     0.0644638    0.0421045    -0.00297803  -0.142276    -0.0447962     0.0707285     0.027355    -0.0519141    0.147128    -0.0157962   -0.0174567   -0.0833784   -0.146845    -0.0143661     0.0419588    0.0295868    0.0491121   -0.00325854   0.0126594   -0.11608
 -0.073686    -0.0919791   -0.0375048   -0.0550676    -0.243381     0.0796216    0.150385     0.0723348    -0.067441    -0.0629012   -0.0654821    -0.0456033    -0.0345153    0.142555    -0.0750956    0.0746554    0.0204545    0.17844      0.204617    -0.169424     -0.0196077   -0.0226513   -0.0292016    0.0307979   -0.179565    -0.219026
  0.0540236   -0.0396067   -0.00189214  -0.0935941    -0.162266    -0.138369     0.0915669    0.0611709     0.0694255   -0.0384328   -0.132123      0.0129317    -0.035332     0.00418782   0.0806344   -0.0188493    0.0984972    0.181934    -0.0280655    0.137579      0.0597645    0.0627055    0.206597    -0.149421     0.0979221   -0.0577911
 -0.165211    -0.128452     0.168234    -0.0352183    -0.0334135    0.192117    -0.044322     0.00616947   -0.172883     0.00234977   0.0391644    -0.0325448     0.0180097   -0.200505     0.00956732   0.114593    -0.0592112    0.0620222    0.0484225    0.0756679     0.148468     0.0647169   -0.0690047   -0.0905845    0.0378954   -0.00855797
 -0.0728877   -0.024327     0.0071576    0.0641827    -0.0370536   -0.0997759    0.0264381   -0.058485     -0.0115701    0.187769     0.0914406     0.0667825     0.165812    -0.0984753    0.0150285    0.098255     0.0912838   -0.134847    -0.0140627   -0.00249199    0.0658371   -0.0120709    0.0427553   -0.0965361   -0.1414      -0.0867963
  0.0835823    0.0420615   -0.103772    -0.0973382    -0.0796292    0.0883554    0.0373576    0.0956795    -0.159258     0.157645    -0.0267803    -0.115691      0.0138077    0.0507424    0.0136081   -0.151234     0.0421067    0.0731792   -0.06689     -0.0257668     0.0410868   -0.150968     0.182644    -0.0940584    0.146919     0.129919
 -0.185825    -0.0543327   -0.00930975   0.0324008     0.0714627   -0.0787357   -0.0587092    0.11369      -0.0203837    0.0787262   -0.0388312     0.0693543     0.00404848   0.0427141   -0.0261403   -0.0777632    0.0472011   -0.342601     0.0686378    0.0641036    -0.0732491   -0.00213029   0.0268883   -0.0878548    0.238484    -0.128991kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4277888390001392
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427902
[ Info: iteration 2, average log likelihood -1.427805
[ Info: iteration 3, average log likelihood -1.427278
[ Info: iteration 4, average log likelihood -1.422239
[ Info: iteration 5, average log likelihood -1.408349
[ Info: iteration 6, average log likelihood -1.400672
[ Info: iteration 7, average log likelihood -1.398993
[ Info: iteration 8, average log likelihood -1.398278
[ Info: iteration 9, average log likelihood -1.397829
[ Info: iteration 10, average log likelihood -1.397509
[ Info: iteration 11, average log likelihood -1.397254
[ Info: iteration 12, average log likelihood -1.397019
[ Info: iteration 13, average log likelihood -1.396736
[ Info: iteration 14, average log likelihood -1.396241
[ Info: iteration 15, average log likelihood -1.395622
[ Info: iteration 16, average log likelihood -1.395317
[ Info: iteration 17, average log likelihood -1.395160
[ Info: iteration 18, average log likelihood -1.395057
[ Info: iteration 19, average log likelihood -1.394979
[ Info: iteration 20, average log likelihood -1.394915
[ Info: iteration 21, average log likelihood -1.394858
[ Info: iteration 22, average log likelihood -1.394802
[ Info: iteration 23, average log likelihood -1.394745
[ Info: iteration 24, average log likelihood -1.394680
[ Info: iteration 25, average log likelihood -1.394606
[ Info: iteration 26, average log likelihood -1.394517
[ Info: iteration 27, average log likelihood -1.394412
[ Info: iteration 28, average log likelihood -1.394292
[ Info: iteration 29, average log likelihood -1.394165
[ Info: iteration 30, average log likelihood -1.394041
[ Info: iteration 31, average log likelihood -1.393929
[ Info: iteration 32, average log likelihood -1.393833
[ Info: iteration 33, average log likelihood -1.393757
[ Info: iteration 34, average log likelihood -1.393698
[ Info: iteration 35, average log likelihood -1.393654
[ Info: iteration 36, average log likelihood -1.393620
[ Info: iteration 37, average log likelihood -1.393594
[ Info: iteration 38, average log likelihood -1.393574
[ Info: iteration 39, average log likelihood -1.393558
[ Info: iteration 40, average log likelihood -1.393546
[ Info: iteration 41, average log likelihood -1.393536
[ Info: iteration 42, average log likelihood -1.393528
[ Info: iteration 43, average log likelihood -1.393522
[ Info: iteration 44, average log likelihood -1.393517
[ Info: iteration 45, average log likelihood -1.393513
[ Info: iteration 46, average log likelihood -1.393510
[ Info: iteration 47, average log likelihood -1.393508
[ Info: iteration 48, average log likelihood -1.393506
[ Info: iteration 49, average log likelihood -1.393505
[ Info: iteration 50, average log likelihood -1.393504
┌ Info: EM with 100000 data points 50 iterations avll -1.393504
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.427902252900333
│     -1.4278046949751884
│      ⋮
└     -1.3935035448494344
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.393696
[ Info: iteration 2, average log likelihood -1.393544
[ Info: iteration 3, average log likelihood -1.393198
[ Info: iteration 4, average log likelihood -1.389891
[ Info: iteration 5, average log likelihood -1.376382
[ Info: iteration 6, average log likelihood -1.364329
[ Info: iteration 7, average log likelihood -1.358504
[ Info: iteration 8, average log likelihood -1.355150
[ Info: iteration 9, average log likelihood -1.353089
[ Info: iteration 10, average log likelihood -1.351635
[ Info: iteration 11, average log likelihood -1.350549
[ Info: iteration 12, average log likelihood -1.349764
[ Info: iteration 13, average log likelihood -1.349244
[ Info: iteration 14, average log likelihood -1.348902
[ Info: iteration 15, average log likelihood -1.348659
[ Info: iteration 16, average log likelihood -1.348462
[ Info: iteration 17, average log likelihood -1.348276
[ Info: iteration 18, average log likelihood -1.348084
[ Info: iteration 19, average log likelihood -1.347897
[ Info: iteration 20, average log likelihood -1.347725
[ Info: iteration 21, average log likelihood -1.347577
[ Info: iteration 22, average log likelihood -1.347455
[ Info: iteration 23, average log likelihood -1.347359
[ Info: iteration 24, average log likelihood -1.347287
[ Info: iteration 25, average log likelihood -1.347230
[ Info: iteration 26, average log likelihood -1.347182
[ Info: iteration 27, average log likelihood -1.347139
[ Info: iteration 28, average log likelihood -1.347099
[ Info: iteration 29, average log likelihood -1.347064
[ Info: iteration 30, average log likelihood -1.347032
[ Info: iteration 31, average log likelihood -1.347003
[ Info: iteration 32, average log likelihood -1.346979
[ Info: iteration 33, average log likelihood -1.346957
[ Info: iteration 34, average log likelihood -1.346938
[ Info: iteration 35, average log likelihood -1.346922
[ Info: iteration 36, average log likelihood -1.346907
[ Info: iteration 37, average log likelihood -1.346893
[ Info: iteration 38, average log likelihood -1.346881
[ Info: iteration 39, average log likelihood -1.346869
[ Info: iteration 40, average log likelihood -1.346858
[ Info: iteration 41, average log likelihood -1.346847
[ Info: iteration 42, average log likelihood -1.346837
[ Info: iteration 43, average log likelihood -1.346826
[ Info: iteration 44, average log likelihood -1.346816
[ Info: iteration 45, average log likelihood -1.346805
[ Info: iteration 46, average log likelihood -1.346794
[ Info: iteration 47, average log likelihood -1.346784
[ Info: iteration 48, average log likelihood -1.346773
[ Info: iteration 49, average log likelihood -1.346762
[ Info: iteration 50, average log likelihood -1.346751
┌ Info: EM with 100000 data points 50 iterations avll -1.346751
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3936959642713187
│     -1.3935437777805584
│      ⋮
└     -1.3467511557940555
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.346980
[ Info: iteration 2, average log likelihood -1.346754
[ Info: iteration 3, average log likelihood -1.346319
[ Info: iteration 4, average log likelihood -1.342268
[ Info: iteration 5, average log likelihood -1.325017
[ Info: iteration 6, average log likelihood -1.304193
[ Info: iteration 7, average log likelihood -1.294225
[ Info: iteration 8, average log likelihood -1.289662
[ Info: iteration 9, average log likelihood -1.287782
[ Info: iteration 10, average log likelihood -1.286368
[ Info: iteration 11, average log likelihood -1.285025
[ Info: iteration 12, average log likelihood -1.284121
[ Info: iteration 13, average log likelihood -1.283684
[ Info: iteration 14, average log likelihood -1.283434
[ Info: iteration 15, average log likelihood -1.283199
[ Info: iteration 16, average log likelihood -1.282930
[ Info: iteration 17, average log likelihood -1.282624
[ Info: iteration 18, average log likelihood -1.282331
[ Info: iteration 19, average log likelihood -1.282118
[ Info: iteration 20, average log likelihood -1.281991
[ Info: iteration 21, average log likelihood -1.281923
[ Info: iteration 22, average log likelihood -1.281884
[ Info: iteration 23, average log likelihood -1.281857
[ Info: iteration 24, average log likelihood -1.281838
[ Info: iteration 25, average log likelihood -1.281823
[ Info: iteration 26, average log likelihood -1.281810
[ Info: iteration 27, average log likelihood -1.281799
[ Info: iteration 28, average log likelihood -1.281788
[ Info: iteration 29, average log likelihood -1.281777
[ Info: iteration 30, average log likelihood -1.281765
[ Info: iteration 31, average log likelihood -1.281751
[ Info: iteration 32, average log likelihood -1.281733
[ Info: iteration 33, average log likelihood -1.281711
[ Info: iteration 34, average log likelihood -1.281680
[ Info: iteration 35, average log likelihood -1.281637
[ Info: iteration 36, average log likelihood -1.281568
[ Info: iteration 37, average log likelihood -1.281447
[ Info: iteration 38, average log likelihood -1.281219
[ Info: iteration 39, average log likelihood -1.280747
[ Info: iteration 40, average log likelihood -1.279757
[ Info: iteration 41, average log likelihood -1.278172
[ Info: iteration 42, average log likelihood -1.277361
[ Info: iteration 43, average log likelihood -1.277209
[ Info: iteration 44, average log likelihood -1.277141
[ Info: iteration 45, average log likelihood -1.277087
[ Info: iteration 46, average log likelihood -1.277041
[ Info: iteration 47, average log likelihood -1.277003
[ Info: iteration 48, average log likelihood -1.276971
[ Info: iteration 49, average log likelihood -1.276944
[ Info: iteration 50, average log likelihood -1.276920
┌ Info: EM with 100000 data points 50 iterations avll -1.276920
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.346980173918156
│     -1.3467544837232053
│      ⋮
└     -1.276920243147617
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.277172
[ Info: iteration 2, average log likelihood -1.276859
[ Info: iteration 3, average log likelihood -1.276044
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.263181
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.223468
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.205339
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.207228
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.209669
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.196644
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.199823
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.201046
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.191263
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.202916
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.204075
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.192590
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.197055
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.199351
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.190215
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.202353
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.203533
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.192133
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.196716
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.199005
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.189763
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.201954
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.203125
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.191664
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.196479
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.198763
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.189475
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.201725
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.202925
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.191451
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.196366
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.198637
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.189372
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.201568
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.202815
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.191348
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.196309
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.198576
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.189344
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.201495
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.202771
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.191318
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.196303
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.198567
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.189349
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.201473
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.202758
┌ Info: EM with 100000 data points 50 iterations avll -1.202758
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2771723638039996
│     -1.2768588504015455
│      ⋮
└     -1.2027578892933362
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.191749
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.181132
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.188959
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.173937
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.165485
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.153200
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.142844
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│     17
│     18
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.140984
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.145290
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.138947
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│     17
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.137481
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.138175
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.125232
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│     17
│     18
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.124043
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.129805
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.122975
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│     17
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.122608
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.128708
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.121082
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│     17
│     18
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.121230
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.126970
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.120410
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│     17
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.120074
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.126996
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.119670
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│     17
│     18
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.120385
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.126379
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.120072
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│     17
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.119852
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.126755
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.119500
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│     17
│     18
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.120129
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.126064
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.119572
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│     17
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.119301
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.126070
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.118889
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│     17
│     18
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.119479
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.125602
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.119111
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│     17
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.118982
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.125305
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.115400
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│     17
│     18
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.108364
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.110447
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.120209
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│     17
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.119184
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.125983
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.118884
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│     17
│     18
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.119442
┌ Info: EM with 100000 data points 50 iterations avll -1.119442
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1917487987178177
│     -1.1811315197033228
│      ⋮
└     -1.1194417142219137
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4277888390001392
│     -1.427902252900333
│     -1.4278046949751884
│     -1.427278425842081
│      ⋮
│     -1.1259833016983445
│     -1.1188838316653607
└     -1.1194417142219137
32×26 Array{Float64,2}:
 -0.0382968    -0.0282939    0.0254693   -0.0036276     0.00631186   0.0152862    -0.0542979   -0.00230777   0.0122095    0.0809477    -0.0144777   -0.0541107   -0.0261836   -0.0301223   -0.0323416     0.0350374   -0.0171119   -0.010511    -0.0566077    0.0370681    0.0317748   -0.000503115   0.0537363  -0.0369659    -0.0370283   -0.00115023
  0.0188407     0.00358694   0.00432635  -0.000983929  -0.0550214    0.0208341    -0.0192206    0.0469328    0.0915538    0.0276461    -0.0120304    0.0742675    0.0176422    0.0363045   -0.0579593    -0.0211324   -0.00101507   0.0395189    0.0260863    0.0149679   -0.0647532    0.0327846    -0.0394375   0.0265579    -0.0188403   -0.0888221
  0.0713809    -0.0405914    0.116927     0.0328378    -0.108139    -0.0147146     0.0659285   -0.00833984  -0.0534086    0.00499307    0.0196399    0.0184824    0.0334495   -0.00632537   0.0695972     0.013418     0.0368491   -0.033366    -0.0920932   -0.00926897   0.143011     0.122546      0.0826481   0.0510691     0.0134508   -0.1135
 -0.0932959    -0.056333    -0.0682833    0.0106107     0.0741364   -0.0131609     0.016401    -0.0153246   -0.0341474    0.084968     -0.0931499    0.0641929   -0.029721     0.0454992   -0.147413     -0.0270679    0.0944094   -0.227647    -0.00162702   0.0149038   -0.115454    -0.0299571    -0.0141378  -0.106035      0.117981    -0.0605583
  0.167945     -0.115104     0.0445515   -0.0402785     0.0348892   -0.000305565  -0.14669     -0.139914     0.114437    -0.0747964    -0.0126041    0.081167    -0.0413858   -0.0960672    0.0116105     0.181554     0.045387     0.00273193  -0.0552805   -0.161253    -0.0558832    0.131811     -0.224189    0.0748447    -0.101356     0.0782022
  0.0428449     0.0176565    0.00428926   0.038397      0.0539309   -0.121106      0.00289904  -0.0347594   -0.0921342   -0.00663935    0.172931     0.0415099    0.184085    -0.220723     0.149385     -0.0151702   -0.0032607   -0.0254524    0.0719893   -0.0370789   -0.175362     0.0946537     0.207157   -0.000263147   0.00743915   0.123842
  0.0396735    -0.202167    -0.051638     0.156988     -0.0343602    0.0263112     0.0947449    0.0786472    0.119281    -0.100884      0.0155856   -0.0659304   -0.121547     0.26899     -0.199668     -0.0214501    0.0793149   -0.179647     0.121531    -0.0363641   -0.0439665   -0.049989     -0.0604158  -0.128212     -0.101422    -0.0111424
  0.0592738     0.0737532   -0.0670848   -0.065805     -0.0277755   -0.0574579     0.0251679    0.0572884   -0.0251457    0.0389615     0.028102    -0.0556671   -0.0573619    0.101787     0.0442349    -0.0628301   -0.0448447    0.0462858   -0.0023613   -0.037401     0.13709     -0.0253168     0.098227   -0.0546005     0.0754178    0.0553243
  0.0280572    -0.119045     0.0822223    0.127994     -0.131242    -0.00574819    0.0583168    0.0558316   -0.00692609  -0.0257228    -0.0354839    0.0965027   -0.0224687    0.0793266   -0.0578492     0.0748421   -0.120717     0.00506381  -0.00774735  -0.00586656  -0.00983554  -0.0602646     0.0645243  -0.111597     -0.0562735    0.0251213
 -0.0759505     0.10112     -0.0699444    0.205511     -0.0109088   -0.0192255    -0.0623413    0.00853365   0.0905694    0.0470707    -0.00935634  -0.00416677  -0.00576419   0.0615016    0.123682      0.0114656    0.0827108   -0.0742631    0.0783697    0.00456091   0.10382     -0.00743405   -0.168424    0.125069     -0.0513046   -0.081388
 -0.157235     -0.107071    -0.0286717   -0.0283946    -0.058786    -0.0766507    -0.0104006    0.166274    -0.195959     0.0246257     0.0891705   -0.0437565    0.0359112   -0.171004    -0.0226044     0.0284863    0.0171442   -0.299982     0.041462     0.0739171    0.024649     0.0820989    -0.0155773   0.116935      0.0125199   -0.0522235
 -0.140305     -0.17771      0.245145    -0.0654791    -0.0207137    0.294918     -0.0306185   -0.133236    -0.100549    -2.4509e-5     0.0477035   -0.0248289    0.00939299  -0.256625     0.0413406     0.150567    -0.0686342    0.353997     0.0616399    0.0757474    0.301513     0.0526934    -0.102361   -0.14002       0.0252842    0.00982771
  0.173142      0.00421169   0.188393     0.248343      0.0598257   -0.00836908   -0.13781      0.025293     0.0915809   -0.109035     -0.158814    -0.0602113   -0.00575955  -0.121694     0.0430887    -0.0216692    0.233861     0.0153836   -0.158752     0.0280936   -0.0523337    0.13749      -0.0393482   0.079713      0.0921686    0.134975
  0.0601094     0.00688425   0.0230339   -0.0381894     0.0472545    0.124014     -0.273646     0.07339     -0.0457836   -0.0419047     0.0857579    0.108356    -0.0539225    0.0541175    0.0926498    -0.0371198   -0.0528918    0.171939    -0.0883508    0.254952    -0.0965973    0.124338     -0.0479169  -0.0411401     0.0711835    0.173044
 -0.594659      0.0943711   -0.0541161   -0.0872845    -0.005677    -0.513396      0.0782731    0.0799416    0.0937397   -0.0858278    -0.0441112    0.12798     -0.0107514    0.364282     0.0628966    -0.0708123   -0.130747    -0.062867     0.129865     0.0547733   -0.0955851   -0.0599396    -0.0831205  -0.0397196     0.034449    -0.0310504
  0.370884      0.0785249    0.00317089  -0.0950716    -0.137564     0.360881      0.0238089    0.0770247    0.17049     -0.0905501    -0.102605     0.134041     0.0121378   -0.115996     0.0758449    -0.034713    -0.0287625    0.104644     0.129673    -0.104987    -0.150241    -0.0620748    -0.128334   -0.0859682     0.0700655    0.0161866
  0.0263323     0.183135     0.2404       0.0143506     0.0664333   -0.00921826   -0.0129598   -0.0846511   -0.0574626   -0.0547372     0.0452758   -0.0933184   -0.0116013    0.0652373   -0.213834      0.0274722    0.0722808   -0.00331998   0.120592     0.0481951   -0.009793    -0.0701116     0.0485554  -0.194722      0.29702     -0.142383
 -0.0399616     0.0666404    0.268525    -0.0119226     0.00784787  -0.0370771    -0.0732227   -0.108208    -0.062935     0.0539537    -0.148246    -0.146971    -0.191155     0.0636175    0.248367      0.0193121    0.0237603   -0.28621     -0.363201    -0.0525051    0.126773    -0.033681      0.0487115   0.177381      0.25745     -0.137163
 -0.0844691    -0.118982    -0.0313266   -0.927227     -0.502072     0.0998317     0.151292     0.0795511    0.0754341   -0.183124     -0.145779    -0.0430971   -0.396153     0.145421    -0.0843291     0.151025     0.0209129    0.0844884    0.212194    -0.201072    -0.0110125    0.0188488    -0.0530926  -0.0225606    -0.0832605   -0.242638
 -0.0162309    -0.0887871   -0.0357749    0.484088     -0.110932     0.0421138     0.151244     0.0705153   -0.137502    -0.00979737   -0.0610134   -0.0437005    0.125658     0.141616    -0.0791529     0.0456958    0.020718     0.281866     0.208375    -0.133925    -0.0189708   -0.0430245    -0.0289562   0.0626545    -0.243858    -0.185517
  0.0708457    -0.00892771   0.0305119   -0.136356     -0.203713    -0.134801      0.0914829    0.0289794    0.0749611   -0.100553     -0.13858      0.0150213   -0.668619     0.0664882   -0.0389827    -0.0190167    0.0936368    0.140419     0.0108609    0.235642    -0.0246621   -0.0913969     0.196501   -0.171495      0.113044    -0.0574432
  0.000215277  -0.0476512   -0.0172913   -0.0801703    -0.0960877   -0.132864      0.0915415    0.0630077    0.0748282    0.0506042    -0.129119     0.0129533    0.680152    -0.051178     0.169869     -0.0195444    0.0950503    0.248452    -0.0432412    0.0399231    0.141041     0.166948      0.217445   -0.163224      0.0923992   -0.0553413
  0.126175      0.0146743   -0.106067     0.12446       0.0214957   -0.116538     -0.00236328  -0.137819     0.0951504   -0.0745016    -0.229651     0.113662     0.112813    -0.0131427    0.0831552    -0.0261999   -0.0151052   -0.199858    -0.18237     -0.0958835    0.0484771    0.0123797    -0.0489146  -0.958904     -0.00233896  -0.309743
  0.142022      0.0195154    0.0908711    0.0046357     0.0548734   -0.0918651     0.0077435   -0.0507999    0.0612786   -0.047194     -0.201653     0.156748     0.0694114    0.0901605    0.0801908    -0.054243    -0.0485963   -0.134105     0.164738    -0.11113      0.0410079    0.015438     -0.0689154   0.9981        0.0893285   -0.303551
 -0.134524     -0.0463141   -0.309884     0.046228     -0.0348302   -0.0446918     0.202242    -0.0299253   -0.0629778    0.0997174     0.159513     0.032182    -0.15477     -0.0225966   -0.0797148     0.172945    -0.10952      0.151012    -0.316519     0.258804    -0.121164     0.00244016    0.115161   -0.0384989     0.176681    -0.0412074
 -0.106294     -0.0177504    0.0477723    0.0536237    -0.0465009   -0.063719      0.0569735   -0.0239401   -0.0149419    0.177708      0.148202     0.0693117   -0.0117666   -0.0842       0.000102283   0.1521      -0.0732622    0.0604941   -0.0938298    0.0795912    0.0157451   -0.00825847    0.0781961  -0.0589505    -0.0356007   -0.0650984
 -0.0525414     0.0222452   -0.0593536    0.59333      -0.0162868   -0.00190962    0.0939959    0.0260709   -0.281265    -0.00231813    0.0789747    0.218832     0.128029    -0.00651905  -0.190218      0.153674    -0.0758902    0.183474    -0.186166    -0.0248649    0.00134425   0.0866423     0.0255168   0.184068      0.0784924    0.00515226
 -0.0554698     0.0162197   -0.0499691   -0.538694     -0.00558104   0.232259      0.0652544    0.0264649    0.499224     0.000953179   0.0773348    0.214943     0.143776    -0.00871284  -0.0681666     0.189749    -0.0754712    0.171171    -0.161057    -0.0797097   -0.0105806    0.0861187     0.023673    0.169279      0.0555305    0.00490086
  0.0283969    -0.228545    -0.117515    -0.308328     -0.0647091   -1.13431       0.236505     0.167187    -0.0199653   -0.0823223     0.0842957    0.188156     0.222705    -0.0884682    0.122044     -0.0685381   -0.0323569    0.0531844   -0.0341633   -0.111732     0.12043      0.13132       0.022412    0.116554      0.0709231    0.25821
  0.0105291    -0.174112    -0.0854525   -0.243365     -0.0764248    1.4032        0.253281     0.167294    -0.00439662  -0.000774387   0.0186398    0.219447     0.222942    -0.0907921    0.155096     -0.0664333   -0.0330157    0.0505358   -0.0516497   -0.114856     0.133697     0.115848      0.0106642   0.109667      0.0917169    0.241095
  0.0141474     0.0383399   -0.31918      4.18258e-5   -0.00198812  -0.132789     -0.159924     0.222794     0.0323871    0.0555544     0.100968     0.086254    -0.142182     0.112662    -0.0986905    -0.00969142  -0.112987    -0.0154758    0.0560482   -0.0417614   -0.0874632    0.300515     -0.0582924  -0.0703801     0.0983192   -0.05883
  0.00443492   -0.0264511    0.258339     0.0125991    -0.0125827   -0.0840298    -0.220682     0.0823908   -0.0136517    0.159721      0.115128     0.101369     0.0137371    0.0201297   -0.00753978    0.00563152  -0.073767    -0.0180172    0.129301    -0.0432827   -0.106005     0.29553      -0.0226904  -0.016539      0.074532    -0.0625093[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.125616
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.109203
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│     17
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.116861
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.113724
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.113726
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      7
│     15
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.093000
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.109527
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.110171
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│     17
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.116900
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.114102
┌ Info: EM with 100000 data points 10 iterations avll -1.114102
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.939823e+05
      1       6.998091e+05      -1.941732e+05 |       32
      2       6.695110e+05      -3.029805e+04 |       32
      3       6.533370e+05      -1.617399e+04 |       32
      4       6.429873e+05      -1.034972e+04 |       32
      5       6.360922e+05      -6.895077e+03 |       32
      6       6.323840e+05      -3.708262e+03 |       32
      7       6.301862e+05      -2.197784e+03 |       32
      8       6.282982e+05      -1.887945e+03 |       32
      9       6.265955e+05      -1.702760e+03 |       32
     10       6.254107e+05      -1.184800e+03 |       32
     11       6.245761e+05      -8.345541e+02 |       32
     12       6.238268e+05      -7.492762e+02 |       32
     13       6.232619e+05      -5.649568e+02 |       32
     14       6.228603e+05      -4.015402e+02 |       32
     15       6.225768e+05      -2.835800e+02 |       32
     16       6.223972e+05      -1.795241e+02 |       32
     17       6.222863e+05      -1.109350e+02 |       32
     18       6.222229e+05      -6.342482e+01 |       32
     19       6.221790e+05      -4.392312e+01 |       32
     20       6.221536e+05      -2.537751e+01 |       31
     21       6.221332e+05      -2.036101e+01 |       32
     22       6.221169e+05      -1.630842e+01 |       32
     23       6.221065e+05      -1.044773e+01 |       30
     24       6.220977e+05      -8.721161e+00 |       27
     25       6.220923e+05      -5.449429e+00 |       31
     26       6.220848e+05      -7.468937e+00 |       27
     27       6.220786e+05      -6.203908e+00 |       25
     28       6.220710e+05      -7.623965e+00 |       28
     29       6.220637e+05      -7.297369e+00 |       26
     30       6.220577e+05      -5.998817e+00 |       26
     31       6.220538e+05      -3.946641e+00 |       24
     32       6.220504e+05      -3.323644e+00 |       22
     33       6.220465e+05      -3.883512e+00 |       25
     34       6.220412e+05      -5.301513e+00 |       28
     35       6.220366e+05      -4.670024e+00 |       23
     36       6.220343e+05      -2.232242e+00 |       23
     37       6.220327e+05      -1.658188e+00 |       18
     38       6.220315e+05      -1.178712e+00 |       15
     39       6.220307e+05      -8.097822e-01 |       11
     40       6.220301e+05      -5.608205e-01 |       10
     41       6.220297e+05      -4.448404e-01 |       13
     42       6.220292e+05      -5.242962e-01 |       12
     43       6.220287e+05      -4.336457e-01 |        8
     44       6.220284e+05      -2.968285e-01 |        6
     45       6.220282e+05      -1.994911e-01 |        6
     46       6.220281e+05      -1.539224e-01 |        9
     47       6.220278e+05      -3.134439e-01 |        8
     48       6.220276e+05      -1.677126e-01 |        6
     49       6.220273e+05      -2.900377e-01 |       12
     50       6.220267e+05      -5.793586e-01 |       14
K-means terminated without convergence after 50 iterations (objv = 622026.7333670827)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.335860
[ Info: iteration 2, average log likelihood -1.301000
[ Info: iteration 3, average log likelihood -1.265776
[ Info: iteration 4, average log likelihood -1.226165
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.170139
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.122326
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     18
│     23
│     24
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.101412
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.127619
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.120406
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      9
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.111936
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.107007
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     18
│     20
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.085433
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.098766
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      9
│     14
│     24
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.067350
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.125374
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.091178
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     21
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.071479
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      9
│     14
│     15
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.088109
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.122108
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     20
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.069322
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.090329
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      9
│     14
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.088630
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.120382
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     18
│     20
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.079534
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.095564
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.088675
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.112625
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     20
│     21
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.085541
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.096721
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     15
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.092807
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.113226
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     20
│     21
│     23
│     24
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.050551
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.120263
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      9
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.096858
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.084258
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     15
│     18
│     20
│     21
│     23
│     24
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.040975
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.136218
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      9
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.094750
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.077006
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     20
│     21
│     23
│     24
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.056602
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.128652
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     15
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.082140
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.093669
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     14
│     18
│     20
│     21
│     23
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.050269
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.124112
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      9
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.094430
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.100500
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     15
│     18
│     20
│     21
│     23
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.060893
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.113633
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     14
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.087468
┌ Info: EM with 100000 data points 50 iterations avll -1.087468
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0725624    0.00235695   0.0184078    0.0574925   -0.0543855   -0.110615     0.021749    -0.0799715    0.00422144   0.159806     0.166988     0.064746      0.198226     -0.0874894    0.0150724    0.156908     0.126335    -0.116022    -0.0149305    -0.0105635     0.0301605   -0.00244912   0.0196283  -0.0790617   -0.153077    -0.0895311
  0.105537     0.0162337   -0.0889052    0.0378261    0.00399214  -0.0870605    0.0033819   -0.0514129    0.096702    -0.0856142   -0.225483     0.179824      0.124096     -0.096829     0.0836      -0.0757473    0.0172505   -0.361899    -0.0439458    -0.10019       0.0402968   -0.00385395  -0.0100744  -0.216528     0.0251571   -0.311272
  0.035372    -0.0288539    0.00623164  -0.108313    -0.149003    -0.134874     0.091608     0.0482102    0.0748095   -0.0211197   -0.134071     0.0133001     0.018152      0.00735069   0.0661056   -0.0191577    0.093956     0.195983    -0.0160939     0.134754      0.0595715    0.039249     0.20669    -0.166658     0.102351    -0.0558666
  0.100398    -0.0707478    0.0746836    0.0753895   -0.0480328   -0.10343      0.0765794   -0.0687971   -0.121398     0.134678     0.0936802   -0.0199494     0.0411952     0.0293335    0.0285801    0.0596077    0.129238    -0.011498    -0.0859338    -0.0146848     0.228093     0.224854     0.127962    0.110099     0.0206725   -0.135657
 -0.0392095   -0.135319    -0.00879194   0.057658    -0.0996631   -0.0417459    0.00673277  -0.0302144    0.00406206  -0.00293148  -0.103393    -0.0915276     0.0985579    -0.00582907  -0.11395     -0.220483    -0.0796544   -0.0896307   -0.0980588     0.020538      0.0908963    0.0224825   -0.210689   -0.0958051   -0.080449     0.0367566
 -0.150992    -0.147255     0.132518    -0.0496693   -0.0387274    0.134748    -0.0178315   -0.0044646   -0.144552     0.0136606    0.0669186   -0.0329888     0.0192048    -0.221586     0.011585     0.0994812   -0.0336747    0.0649374    0.0559559     0.0747437     0.188929     0.0663348   -0.0668233  -0.0291043    0.016932    -0.0164879
 -0.194673    -0.0549287   -0.0128568    0.00933434   0.0707594   -0.0567703   -0.0458341    0.106213    -0.0198019    0.0883437   -0.0471248    0.0924281     0.000437793   0.0469736   -0.0334181   -0.0822522    0.0831017   -0.337949    -0.000490755   0.00121369   -0.0787316   -0.0060904    0.0223083  -0.105496     0.214823    -0.124243
  0.0323655    0.0386065   -0.0804264   -0.102328    -0.155432     0.0422151    0.0425447   -0.00870774  -0.0168215    0.106512    -0.0168896   -0.0324313     0.0174101     0.00568257   0.00231577  -0.0291373    0.0408651    0.161419    -0.0669034     0.064213      0.0157769   -0.14005      0.0933083   0.0217126    0.128778    -0.0473342
 -0.00772101   0.12568      0.253493     0.0014983    0.0382181   -0.0205468   -0.0412022   -0.0934226   -0.0604415   -0.00130242  -0.0487028   -0.116808     -0.0972743     0.0641515    0.0168179    0.0236077    0.0475924   -0.140131    -0.117777     -0.00405482    0.0571328   -0.0509863    0.0484688  -0.00700947   0.277593    -0.137513
 -0.114982    -0.0348577   -0.164484     0.0528422   -0.0310756   -0.0440728    0.149376    -0.0173811   -0.0421309    0.102204     0.144961     0.0774914    -0.0600884    -0.0401393   -0.0706987    0.171118    -0.0970044    0.133776    -0.231712      0.171441     -0.0670125    0.0135295    0.0858573  -0.00383749   0.107731    -0.0393672
  0.0091466    0.00492074  -0.0237195    0.00606827  -0.00578052  -0.108839    -0.190137     0.149828     0.00889471   0.108175     0.108108     0.0937585    -0.0616716     0.06534     -0.0519803   -0.00103644  -0.0930934   -0.0160883    0.0909802    -0.0430362    -0.096773     0.298772    -0.0399328  -0.0410385    0.0883564   -0.0600824
  0.188917    -0.14265      0.122586    -0.00172628  -0.115811     0.0263467   -0.0510345   -0.00217029   0.231386     0.0956129    0.132664    -0.221651      0.0286107     0.21939     -0.205991    -0.0973317    0.0240752   -0.00620154  -0.123432     -0.0268086     0.0431012   -0.0802214    0.165367   -0.107669    -0.127399     0.0508938
 -0.20043      0.0417518    0.0224452   -0.0297877    0.114713     0.0157455   -0.207566     0.0933316   -0.0265686   -0.015427     0.00699726  -0.030119     -0.167327     -0.0360043    0.00438573   0.165025    -0.113586     0.0531963   -0.0715632     0.0395209    -0.0867937    0.00391005   0.287159   -0.0609914    0.0556681   -0.0352921
 -0.116269     0.035851    -0.114017     0.0815872    0.120901     0.0248781   -0.0735073   -0.0388121   -0.0190031    0.205941    -0.0987457    0.0456139    -0.128079     -0.00995058   0.0701439    0.177832    -0.00660065  -0.0577581   -0.00922521    0.10364       0.0321168    0.0946854    0.0366208  -0.0352662    0.0830672    0.0310519
  0.0374761    0.0319463   -0.103833     0.119741     0.0764697    0.0331945   -0.0763343    0.093254     0.105713    -0.0145212    0.157818     0.0592593     0.053797     -0.00810137  -0.121988    -0.00965012   0.0330097    0.0812962    0.0676688     0.0613785    -0.124463     0.0313526   -0.0571877  -0.0709543    0.0131971   -0.00904292
 -0.0729928    0.109033    -0.0661764    0.205484    -0.0186775   -0.012088    -0.0587694    0.0110726    0.101783     0.0359809   -0.00706013  -0.00204751   -0.00549549    0.0552848    0.128761     0.00839015   0.0806045   -0.0728765    0.0791575     0.00155013    0.0923382   -0.0111141   -0.159398    0.126259    -0.0542436   -0.0806257
  0.0488888   -0.0284868    0.16907     -0.043051    -0.0150255    0.0378052   -0.0495876    0.144539     0.0459782   -0.00049536  -0.160955     0.163072     -0.0450455     0.103558     0.00595133  -0.166422    -0.0561596   -0.134454     0.0656597    -0.129943     -0.0303807    0.189899    -0.0649319   0.0249603   -0.163682    -0.0864064
  0.0259152   -0.00600423   0.126432    -0.0420121   -0.138116     0.0871729    0.0366013    0.0569914   -0.030696    -0.0848467   -0.0494261    0.0241188     0.0192524    -0.0592271    0.138592    -0.0132364   -0.0657911   -0.0230684   -0.0623413     0.000464981   0.0510057    0.00303929   0.028378    0.0343782   -0.00671924  -0.160217
  0.0283749   -0.118925     0.0813099    0.129467    -0.131251    -0.00507058   0.0595475    0.0563615   -0.00620985  -0.025774    -0.0349518    0.0981539    -0.0222349     0.078478    -0.0577367    0.0752094   -0.120725     0.00796288  -0.00741987   -0.00405942   -0.010032    -0.0607435    0.065993   -0.111456    -0.0567324    0.0250291
 -0.0424052   -0.0936314   -0.0324909   -0.0554822   -0.253685     0.0657394    0.148266     0.0724861   -0.0458898   -0.0734106   -0.0901597   -0.0394947    -0.0578295     0.131982    -0.0772074    0.0870494    0.0172845    0.197568     0.200548     -0.157152     -0.013557    -0.0118533   -0.0348673   0.0378308   -0.173184    -0.198868
 -0.0146117    0.0386025    0.10035     -0.160416     0.05973      0.120875    -0.0289403   -0.0205901   -0.108432     0.0474129   -0.330643    -0.0726055    -0.246318     -0.380513     0.0260426    0.0803239   -0.00836999   0.113067    -0.0185776     0.0656423     0.0655636   -0.147707    -0.0146368   0.115815     0.0192055   -0.0105984
  0.176839     0.0182905    0.109643     0.108055     0.0890738   -0.131429     0.00170812  -0.164145     0.0513924   -0.0239524   -0.201453     0.0660459     0.0425804     0.241556     0.078859     0.0151209   -0.105538     0.126407     0.0354799    -0.107974      0.0517368    0.04122     -0.132552    0.331462     0.068986    -0.299842
  0.0440056   -0.20887     -0.0561442    0.15495     -0.0347119    0.018821     0.120248     0.0819304    0.134391    -0.103557     0.016163    -0.0771421    -0.147854      0.377556    -0.307639    -0.0186227    0.10449     -0.222929     0.129118     -0.0476008    -0.0479639   -0.058958    -0.0956406  -0.161955    -0.0996235    0.0821641
 -0.0491432    0.0364685   -0.0531988    0.0482488   -0.0456008    0.171311     0.0770758    0.0315138    0.143068    -0.0133562    0.0674498    0.215602      0.130495     -0.0106402   -0.145633     0.165038    -0.0751177    0.168379    -0.210088     -0.0565739     0.00865748   0.0759851    0.0272508   0.163593     0.0767953    0.0154227
  0.0602464    0.00647703   0.0247499   -0.0390181    0.0478184    0.124195    -0.275106     0.0697796   -0.0466713   -0.0407381    0.0862286    0.105662     -0.055103      0.0517502    0.0928049   -0.0350487   -0.0502167    0.178082    -0.0902991     0.257049     -0.0973148    0.125043    -0.0479734  -0.0414623    0.0716424    0.173365
  0.0451119    0.106629    -0.037814    -0.0266451    0.0289606   -0.220442     0.0482938    0.0576464    0.0971362   -0.0310459    0.0844321    0.000389915  -0.113761      0.184226     0.045814     0.0142782   -0.148745    -0.0209023    0.0757942    -0.0663473     0.222933     0.0961139    0.0222972  -0.00304747  -0.00523685   0.012434
  0.160432    -0.104278     0.0375678   -0.0154472    0.0362502    0.00286413  -0.129477    -0.13032      0.109115    -0.0742945   -9.12794e-5   0.0826692    -0.0246871    -0.102883     0.0148046    0.170445     0.0354814    0.00737457  -0.0467959    -0.174572     -0.0643122    0.132106    -0.174425    0.071333    -0.0989842    0.0750396
  0.00343791  -0.0669529   -0.124917     0.00970696   0.0941225    0.0383556    0.103457    -0.127715    -0.0511984    0.0713662   -0.143968     0.0378855    -0.0327578     0.0431511   -0.262062     0.0381994    0.135458    -0.112754     0.0178441     0.0609582    -0.143521    -0.0595719   -0.0643563  -0.121308     0.0148201    0.0185038
  0.0606412    0.0427194    0.0808072    0.0834817   -0.010429    -0.00818632  -0.0437395    0.0514673    0.11581     -0.0996627   -0.109828     0.0450555     0.00581722   -0.0226874    0.0561504   -0.0324908    0.0767503    0.0387335   -0.0124765    -0.00776424   -0.0971054    0.0395201   -0.070394    0.0173402    0.0737471    0.0666673
  0.0360108    0.0187142    0.0135945    0.0197598    0.071977    -0.119406     0.0124432   -0.038908    -0.0931579    0.0102035    0.206548     0.0397755     0.209116     -0.210061     0.13126     -0.0153803   -0.00228686  -0.0228289    0.0766685    -0.0377449    -0.158736     0.0920102    0.16728     0.0122743   -0.00156346   0.131344
 -0.0804376    0.0105477   -0.0525608   -0.00167745   0.0465388    0.0375606   -0.0549741    0.0372499    0.00278294   0.0395481   -0.115181     0.00510033   -0.278965     -0.0277583    0.054544     0.126487     0.0379875   -0.0393362    0.020472      0.0797755    -0.00340182   0.0563169    0.0493492   0.00563934   0.0415153    0.0316394
  0.0198174   -0.199795    -0.101504    -0.27529     -0.0704996    0.091333     0.242726     0.166349    -0.0125905   -0.0440251    0.0521037    0.203878      0.222398     -0.0894566    0.139164    -0.0668871   -0.0324885    0.0528666   -0.0423624    -0.113448      0.125875     0.123057     0.016766    0.112456     0.0785207    0.247919[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.110199
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     15
│     18
│     20
│     21
│     23
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.038125
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│     14
│     15
│     20
│      ⋮
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.032164
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      9
│     15
│     18
│      ⋮
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.058917
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     23
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.071728
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│     14
│     15
│     18
│      ⋮
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.012258
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      9
│     15
│     20
│     27
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.069044
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     21
│     23
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.055209
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│     14
│     15
│     18
│      ⋮
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.023105
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      9
│     15
│     20
│      ⋮
│     27
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.040656
┌ Info: EM with 100000 data points 10 iterations avll -1.040656
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0471022    0.165835    -0.0300607   -0.0955987    0.113229    -0.108439     0.0986569   -0.0714637    0.0768     -0.00727882  -0.0201254    0.0458898    0.0999412    0.00278262   0.215272    -0.00796145  -0.0129535    0.0796189   -0.0507326   -0.0978539    0.14004     -0.00365693   0.0857884   0.162197      0.08469      0.0922072
  0.0149811    0.0205393   -0.06569     -0.0740234   -0.0295305    0.0283697   -0.0955857    0.224891    -0.052043    0.0835603    0.0355132    0.164119     0.187838     0.141841     0.144786    -8.93861e-5   0.0635723    0.00535035  -0.138685     0.149371     0.135749    -0.021241     0.0895359  -0.0913683     0.145985     0.0388235
 -0.0533966    0.060281     0.00976849   0.0331909   -0.0426369   -0.0510463    0.015884     0.0712159    0.0731251  -0.0155038    0.0178265   -0.108134     0.099696     0.0655149   -0.0370875   -0.0972447   -0.125786    -0.144261    -0.081516     0.0263986    0.0754328    0.00967354  -0.195511    0.12798       0.0389571   -0.0190517
 -0.0404044   -0.0619909   -0.0603187    0.0807242   -0.0954764    0.0961826    0.0285844   -0.0315301   -0.0177691   0.113652     0.0297741   -0.0251755   -0.030316    -0.0633215    0.0364132    0.0591883   -0.122483     0.0563236   -0.0279251    0.0985544    0.0591036    0.0668718    0.243145   -0.0567136    -0.0226118    0.0836977
 -0.0684025   -0.0826284    0.1581      -0.12502      0.135717    -0.193691    -0.162795     0.127432    -0.0593285   0.051014     0.0766483    0.0610698    0.109249     0.0981947   -0.0237277   -0.0692104    0.214855    -0.186184     0.0439225   -0.277383     0.0604889   -0.145062    -0.0113469   0.0866813     0.0797156   -0.137492
 -0.0609896    0.20107      0.0229904   -0.15703     -0.0956822   -0.0102791   -0.0199505    0.0355472    0.022493   -0.00635673   0.0179899    0.156795     0.106769    -0.169575     0.0681322   -0.0119102   -0.0739135    0.0338907    0.204364     0.0223922   -0.0679231    0.144107     0.0252158  -0.18907      -0.16871     -0.0376184
 -0.130969    -0.169212     0.123596     0.00163102  -0.0496946    0.0519736    0.0528246    0.0508338   -0.163265   -0.160889     0.042164     0.133446     0.119474    -0.0927236    0.0307891   -0.155079    -0.0777784   -0.014938    -0.190899     0.0155799    0.0136803   -0.0518189   -0.0486339   0.0882115    -0.216862     0.00246977
 -0.136104    -0.0828546   -0.110273     0.180869    -0.0113973    0.164592    -0.0823169   -0.0482894    0.0663559   0.0887765    0.034162     0.120572    -0.111054     0.071269    -0.0541126    0.0600276   -0.118206    -0.0889531    0.00407117   0.106344     0.0599445   -0.119253    -0.0185416  -0.152422      0.00498961  -0.130152
 -0.0687205   -0.100487    -0.193725     0.0479646   -0.132761     0.236067     0.0227741   -0.205483     0.0356962   0.0248191    0.0973728   -0.0457035    0.100519     0.0981499    0.0232014    0.240917     0.104825     0.0411264    0.0440981   -0.0565509   -0.0544944   -0.00299863   0.0334443  -0.0451257     0.097938     0.0273705
  0.12717     -0.0990619    0.0752959    0.160927     0.128205    -0.046675    -0.146148    -0.0144364    0.0406933   0.00430054   0.026542    -0.0337541   -0.143271     0.117639    -0.0814312   -0.0764933    0.133873    -0.0561625    0.0297828    0.119541    -0.0864222   -0.0543953   -0.127002    0.0472966     0.19364      0.0256276
  0.0598629   -0.0141774   -0.127465     0.104894     0.1598       0.00762722   0.0446356    0.0944621    0.0546633   0.0540785   -0.155649    -0.145015     0.0747196    0.209728     0.158455     0.0530087    0.0713553   -0.0108194   -0.163382    -0.0122087   -0.0284862   -0.122007     0.0722439   0.0201853    -0.204988    -0.105282
 -0.228785     0.143731     0.0442316   -0.0375155   -0.0703       0.124042     0.136776     0.139476    -0.0216442  -0.00776355   0.0429615    0.0593104   -0.0526423    0.00442889  -0.0418703   -0.0930221    0.146153     0.0645214    0.105375     0.13282     -0.160764     0.00258118   0.0818211  -0.10881      -0.0705483    0.0898293
 -0.0308476    3.85051e-5   0.0155123    0.00462251  -0.0541254   -0.0205656    0.0255657   -0.0110771   -0.178655    0.157599     0.0695393   -0.192612    -0.00598627  -0.0482873   -0.00448752   0.0654603   -0.164224    -0.0859589    0.1697       0.0705096    0.0227764    0.135958    -0.0655503  -0.0012077     0.142242     0.151275
  0.0600064   -0.109585    -0.00337568  -0.0604711    0.174826     0.189527     0.116835    -0.0871412    0.0238573  -0.0267797    0.149704     0.0657702    0.0791501    0.0465997    0.0949105    0.0490391   -0.0417206    0.170918     0.101089    -0.018515     0.158007    -0.0267684    0.0358344   0.130985      0.00068868   0.102124
 -0.0701804    0.144604    -0.0953661    0.0172405    0.0490885    0.0492049    0.0748221    0.0628636    0.139203    0.0142992   -0.0332038    0.0637511   -0.0264868   -0.0263577    0.00574605  -0.116685     0.15173     -0.0684398    0.0386294    0.0171676   -0.0689962   -0.0220142    0.0704531   0.106743     -0.0197521    0.16666
 -0.187598    -0.0424779   -0.0640246    0.00917797   0.00257046   0.0921373   -0.0306695    0.141884    -0.0113939   0.121898     0.0163211   -0.185478    -0.0512111    0.0647139    0.0670558   -0.0587857   -0.0505523    0.0904329   -0.135047    -0.155269     0.0296004   -0.0645082   -0.105266    0.0435789    -0.112012     0.158827
  0.126235    -0.0171681    0.187341     0.0282358   -0.0442847   -0.0918653   -0.170187     0.0515317   -0.0577998   0.00617331   0.105923     0.0125773    0.114765     0.158969     0.042719    -0.0716385   -0.117809     0.00657279   0.0974998   -0.00800638   0.083452    -0.125222    -0.0247336  -0.107501      0.0406992    0.156063
 -0.182083    -0.053319     0.0999924   -0.0674151    0.0628182    0.131057    -0.0440703   -0.0801815   -0.034017   -0.0927077   -0.0478753   -0.209131     0.0474095    0.0611192    0.0621999    0.0144194    0.00809585   0.049086    -0.0478739    0.199806     0.141587    -0.107168    -0.0791799   0.000453927  -0.0229107   -0.122804
  0.0172305   -0.0312479   -0.199601     0.0722451    0.106514     0.00936103   0.114752     0.0280245   -0.0833867   0.103688     0.00415397   0.108756    -0.0584492   -0.00725449  -0.0385593   -0.00963725   0.008094     0.0915365    0.028611     0.0014601    0.122474     0.0174546   -0.0832571   0.0638182     0.00492008  -0.0708397
 -0.0381948    0.125129     0.136241     0.133498    -0.079182    -0.107557     0.10099     -0.0710167    0.112934    0.0168014   -0.0341364    0.0531573    0.0202913   -0.0112129   -0.0225183    0.0367664    0.0560081    0.049011     0.016064     0.133693    -0.0472641    0.178867     0.0274408   0.130688     -0.0694973   -0.0558602
  0.00787581   0.065521    -0.150139    -0.0775003   -0.0487723    0.0484365    0.00787966   0.0133469   -0.0679351   0.185742     0.0343559   -0.0445988    0.0037453    0.109454    -0.0582831   -0.124968    -0.0250464   -0.0785498   -0.00959792   0.144057    -0.00314142   0.0780067   -0.163382    0.092392     -0.0528804   -0.0516336
 -0.0026474    0.0530512    0.0887518   -0.107967    -0.0140888   -0.122949    -0.25166     -0.0586167   -0.0752633   0.0563714   -0.0363416    0.0342226    0.0261798    0.0162255   -0.0705527   -0.0536624    0.036627    -0.0316006    0.118949     0.0516861   -0.0160442    0.0697835    0.0187219   0.0599797     0.0203894    0.111285
  0.233974    -0.133572     0.0677531    0.0616792   -0.093892    -0.12957     -0.0525935    0.0965492   -0.0278448  -0.0605801    0.20867     -0.016204    -0.0636795   -0.115974     0.0832073    0.0270045   -0.0375811   -0.20389      0.0924418    0.0480711    0.108619     0.170002    -0.116386   -0.0678824     0.107647     0.030007
 -0.0158224   -0.0229117   -0.289217     0.0777579    0.0265255   -0.00365006  -0.0449243    0.068773    -0.0127958  -0.0079679   -0.0594257    0.0186007   -0.104943     0.0863056   -0.0825577    0.0627159    0.0330978   -0.041799    -0.0947415   -0.140934     0.189798    -0.0840232    0.14016    -0.0264979     0.100046    -0.0713114
  0.0526513   -0.0374039   -0.123643    -0.0378795    0.0632107   -0.0701105   -0.0340972    0.00313675  -0.014198   -0.101137     0.165552    -0.242435     0.316688     0.143143     0.00955957  -0.0654704   -0.122478     0.167988    -0.281014    -0.030156     0.0346287    0.0317787    0.134231   -0.0629422     0.0473819    0.0189074
 -0.0853047   -0.00999141   0.229936    -0.0869507    0.0411511   -0.0880374    0.167328    -0.036256    -0.0135854   0.0361067   -0.126907    -0.0400266    0.0037671    0.0556328   -0.0477564    0.0891854   -0.0522767   -0.100974     0.14876     -0.066876     0.164505    -0.0195072   -0.0540286  -0.192103      0.030591    -0.144822
 -0.0443372    0.078023    -0.0864655    0.106801     0.0602335    0.0513503    0.101635    -0.0416959   -0.0526242  -0.101218    -0.0174773   -0.171469    -0.0387166   -0.0869286    0.0140315   -0.017146     0.050892     0.059647     0.256435     0.108736    -0.283677     0.0423797   -0.340307   -0.0146383    -0.164514     0.176384
 -0.0765589    0.108322    -0.0246444    0.151459     0.244861    -0.0816208   -0.116337     0.00247838  -0.0376275   0.0422533    0.220609    -0.021939     0.0456148    0.013959     0.0578229   -0.063996     0.04738     -0.0808429    0.139126    -0.00883382   0.0997983   -0.0686254    0.159195    0.0739188     0.0400865    0.0626329
 -0.190067     0.0848612   -0.00959536   0.122236    -0.0865834   -0.119519     0.0135808   -0.0154874   -0.0372633   0.100746    -0.00706778   0.00934616  -0.0271685    0.0639727   -0.147547    -0.072031    -0.0929743    0.00493605   0.156439    -0.111737     0.141786     0.109104     0.149815   -0.005083      0.00331647   0.00152253
 -0.0844099   -0.0797417    0.211241    -0.0653533    0.109456     0.077364    -0.0509575    0.0834258    0.122768   -0.0529224   -0.0709414    0.14626     -0.0598687   -0.234952    -0.238698    -0.00934206  -0.0108367   -0.0489071    0.0666814   -0.17647      0.0608154   -0.107088     0.133097    0.0679687     0.149585    -0.127391
  0.0209626   -0.165459    -0.0532736    0.105389     0.201023    -0.0759265    0.124643     0.0112613    0.037424    0.0583103   -0.124938    -0.128576     0.126388    -0.0460265    0.0673974   -0.134268    -0.0648005   -0.0346492   -0.0836064    0.159606     0.0453692   -0.161755    -0.0825106   0.0380208     0.0448779    0.134739
 -0.0270112   -0.11668     -0.14681      0.070426     0.00283564  -0.103033     0.127448    -0.066808    -0.125066   -0.084381     0.0505483   -0.0624202   -0.0126289   -0.0167045   -0.116704    -0.0800455    0.148219    -0.0545203   -0.0276611   -0.0693497   -0.0564761    0.133847    -0.205947   -0.00158409    0.122136    -0.0467222kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4219399065822103
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421960
[ Info: iteration 2, average log likelihood -1.421861
[ Info: iteration 3, average log likelihood -1.421765
[ Info: iteration 4, average log likelihood -1.421639
[ Info: iteration 5, average log likelihood -1.421481
[ Info: iteration 6, average log likelihood -1.421302
[ Info: iteration 7, average log likelihood -1.421122
[ Info: iteration 8, average log likelihood -1.420952
[ Info: iteration 9, average log likelihood -1.420778
[ Info: iteration 10, average log likelihood -1.420558
[ Info: iteration 11, average log likelihood -1.420233
[ Info: iteration 12, average log likelihood -1.419745
[ Info: iteration 13, average log likelihood -1.419081
[ Info: iteration 14, average log likelihood -1.418324
[ Info: iteration 15, average log likelihood -1.417637
[ Info: iteration 16, average log likelihood -1.417152
[ Info: iteration 17, average log likelihood -1.416871
[ Info: iteration 18, average log likelihood -1.416728
[ Info: iteration 19, average log likelihood -1.416659
[ Info: iteration 20, average log likelihood -1.416626
[ Info: iteration 21, average log likelihood -1.416611
[ Info: iteration 22, average log likelihood -1.416603
[ Info: iteration 23, average log likelihood -1.416599
[ Info: iteration 24, average log likelihood -1.416597
[ Info: iteration 25, average log likelihood -1.416596
[ Info: iteration 26, average log likelihood -1.416595
[ Info: iteration 27, average log likelihood -1.416595
[ Info: iteration 28, average log likelihood -1.416594
[ Info: iteration 29, average log likelihood -1.416594
[ Info: iteration 30, average log likelihood -1.416594
[ Info: iteration 31, average log likelihood -1.416594
[ Info: iteration 32, average log likelihood -1.416593
[ Info: iteration 33, average log likelihood -1.416593
[ Info: iteration 34, average log likelihood -1.416593
[ Info: iteration 35, average log likelihood -1.416593
[ Info: iteration 36, average log likelihood -1.416593
[ Info: iteration 37, average log likelihood -1.416593
[ Info: iteration 38, average log likelihood -1.416592
[ Info: iteration 39, average log likelihood -1.416592
[ Info: iteration 40, average log likelihood -1.416592
[ Info: iteration 41, average log likelihood -1.416592
[ Info: iteration 42, average log likelihood -1.416592
[ Info: iteration 43, average log likelihood -1.416592
[ Info: iteration 44, average log likelihood -1.416592
[ Info: iteration 45, average log likelihood -1.416592
[ Info: iteration 46, average log likelihood -1.416592
[ Info: iteration 47, average log likelihood -1.416592
[ Info: iteration 48, average log likelihood -1.416592
[ Info: iteration 49, average log likelihood -1.416592
[ Info: iteration 50, average log likelihood -1.416592
┌ Info: EM with 100000 data points 50 iterations avll -1.416592
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4219597505023485
│     -1.421861484172404
│      ⋮
└     -1.4165916949280375
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416611
[ Info: iteration 2, average log likelihood -1.416510
[ Info: iteration 3, average log likelihood -1.416408
[ Info: iteration 4, average log likelihood -1.416276
[ Info: iteration 5, average log likelihood -1.416115
[ Info: iteration 6, average log likelihood -1.415945
[ Info: iteration 7, average log likelihood -1.415795
[ Info: iteration 8, average log likelihood -1.415685
[ Info: iteration 9, average log likelihood -1.415611
[ Info: iteration 10, average log likelihood -1.415562
[ Info: iteration 11, average log likelihood -1.415528
[ Info: iteration 12, average log likelihood -1.415501
[ Info: iteration 13, average log likelihood -1.415479
[ Info: iteration 14, average log likelihood -1.415460
[ Info: iteration 15, average log likelihood -1.415441
[ Info: iteration 16, average log likelihood -1.415423
[ Info: iteration 17, average log likelihood -1.415405
[ Info: iteration 18, average log likelihood -1.415386
[ Info: iteration 19, average log likelihood -1.415366
[ Info: iteration 20, average log likelihood -1.415344
[ Info: iteration 21, average log likelihood -1.415322
[ Info: iteration 22, average log likelihood -1.415298
[ Info: iteration 23, average log likelihood -1.415274
[ Info: iteration 24, average log likelihood -1.415250
[ Info: iteration 25, average log likelihood -1.415226
[ Info: iteration 26, average log likelihood -1.415204
[ Info: iteration 27, average log likelihood -1.415183
[ Info: iteration 28, average log likelihood -1.415164
[ Info: iteration 29, average log likelihood -1.415148
[ Info: iteration 30, average log likelihood -1.415133
[ Info: iteration 31, average log likelihood -1.415122
[ Info: iteration 32, average log likelihood -1.415112
[ Info: iteration 33, average log likelihood -1.415104
[ Info: iteration 34, average log likelihood -1.415098
[ Info: iteration 35, average log likelihood -1.415093
[ Info: iteration 36, average log likelihood -1.415088
[ Info: iteration 37, average log likelihood -1.415085
[ Info: iteration 38, average log likelihood -1.415082
[ Info: iteration 39, average log likelihood -1.415080
[ Info: iteration 40, average log likelihood -1.415078
[ Info: iteration 41, average log likelihood -1.415076
[ Info: iteration 42, average log likelihood -1.415075
[ Info: iteration 43, average log likelihood -1.415074
[ Info: iteration 44, average log likelihood -1.415073
[ Info: iteration 45, average log likelihood -1.415072
[ Info: iteration 46, average log likelihood -1.415071
[ Info: iteration 47, average log likelihood -1.415070
[ Info: iteration 48, average log likelihood -1.415069
[ Info: iteration 49, average log likelihood -1.415069
[ Info: iteration 50, average log likelihood -1.415068
┌ Info: EM with 100000 data points 50 iterations avll -1.415068
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4166112945310418
│     -1.4165095146447324
│      ⋮
└     -1.415068174776243
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415081
[ Info: iteration 2, average log likelihood -1.415011
[ Info: iteration 3, average log likelihood -1.414947
[ Info: iteration 4, average log likelihood -1.414866
[ Info: iteration 5, average log likelihood -1.414764
[ Info: iteration 6, average log likelihood -1.414644
[ Info: iteration 7, average log likelihood -1.414513
[ Info: iteration 8, average log likelihood -1.414386
[ Info: iteration 9, average log likelihood -1.414270
[ Info: iteration 10, average log likelihood -1.414167
[ Info: iteration 11, average log likelihood -1.414077
[ Info: iteration 12, average log likelihood -1.413997
[ Info: iteration 13, average log likelihood -1.413926
[ Info: iteration 14, average log likelihood -1.413863
[ Info: iteration 15, average log likelihood -1.413808
[ Info: iteration 16, average log likelihood -1.413760
[ Info: iteration 17, average log likelihood -1.413717
[ Info: iteration 18, average log likelihood -1.413680
[ Info: iteration 19, average log likelihood -1.413648
[ Info: iteration 20, average log likelihood -1.413619
[ Info: iteration 21, average log likelihood -1.413593
[ Info: iteration 22, average log likelihood -1.413570
[ Info: iteration 23, average log likelihood -1.413550
[ Info: iteration 24, average log likelihood -1.413532
[ Info: iteration 25, average log likelihood -1.413516
[ Info: iteration 26, average log likelihood -1.413501
[ Info: iteration 27, average log likelihood -1.413488
[ Info: iteration 28, average log likelihood -1.413476
[ Info: iteration 29, average log likelihood -1.413466
[ Info: iteration 30, average log likelihood -1.413456
[ Info: iteration 31, average log likelihood -1.413448
[ Info: iteration 32, average log likelihood -1.413440
[ Info: iteration 33, average log likelihood -1.413433
[ Info: iteration 34, average log likelihood -1.413426
[ Info: iteration 35, average log likelihood -1.413420
[ Info: iteration 36, average log likelihood -1.413415
[ Info: iteration 37, average log likelihood -1.413409
[ Info: iteration 38, average log likelihood -1.413405
[ Info: iteration 39, average log likelihood -1.413400
[ Info: iteration 40, average log likelihood -1.413396
[ Info: iteration 41, average log likelihood -1.413392
[ Info: iteration 42, average log likelihood -1.413388
[ Info: iteration 43, average log likelihood -1.413385
[ Info: iteration 44, average log likelihood -1.413381
[ Info: iteration 45, average log likelihood -1.413378
[ Info: iteration 46, average log likelihood -1.413375
[ Info: iteration 47, average log likelihood -1.413372
[ Info: iteration 48, average log likelihood -1.413369
[ Info: iteration 49, average log likelihood -1.413367
[ Info: iteration 50, average log likelihood -1.413364
┌ Info: EM with 100000 data points 50 iterations avll -1.413364
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4150811811739774
│     -1.4150114949099648
│      ⋮
└     -1.413364279735522
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413372
[ Info: iteration 2, average log likelihood -1.413307
[ Info: iteration 3, average log likelihood -1.413248
[ Info: iteration 4, average log likelihood -1.413181
[ Info: iteration 5, average log likelihood -1.413101
[ Info: iteration 6, average log likelihood -1.413004
[ Info: iteration 7, average log likelihood -1.412893
[ Info: iteration 8, average log likelihood -1.412774
[ Info: iteration 9, average log likelihood -1.412654
[ Info: iteration 10, average log likelihood -1.412536
[ Info: iteration 11, average log likelihood -1.412425
[ Info: iteration 12, average log likelihood -1.412322
[ Info: iteration 13, average log likelihood -1.412227
[ Info: iteration 14, average log likelihood -1.412141
[ Info: iteration 15, average log likelihood -1.412063
[ Info: iteration 16, average log likelihood -1.411994
[ Info: iteration 17, average log likelihood -1.411933
[ Info: iteration 18, average log likelihood -1.411881
[ Info: iteration 19, average log likelihood -1.411835
[ Info: iteration 20, average log likelihood -1.411795
[ Info: iteration 21, average log likelihood -1.411761
[ Info: iteration 22, average log likelihood -1.411730
[ Info: iteration 23, average log likelihood -1.411703
[ Info: iteration 24, average log likelihood -1.411679
[ Info: iteration 25, average log likelihood -1.411656
[ Info: iteration 26, average log likelihood -1.411636
[ Info: iteration 27, average log likelihood -1.411617
[ Info: iteration 28, average log likelihood -1.411599
[ Info: iteration 29, average log likelihood -1.411582
[ Info: iteration 30, average log likelihood -1.411566
[ Info: iteration 31, average log likelihood -1.411551
[ Info: iteration 32, average log likelihood -1.411536
[ Info: iteration 33, average log likelihood -1.411522
[ Info: iteration 34, average log likelihood -1.411509
[ Info: iteration 35, average log likelihood -1.411495
[ Info: iteration 36, average log likelihood -1.411482
[ Info: iteration 37, average log likelihood -1.411470
[ Info: iteration 38, average log likelihood -1.411458
[ Info: iteration 39, average log likelihood -1.411446
[ Info: iteration 40, average log likelihood -1.411435
[ Info: iteration 41, average log likelihood -1.411424
[ Info: iteration 42, average log likelihood -1.411413
[ Info: iteration 43, average log likelihood -1.411403
[ Info: iteration 44, average log likelihood -1.411393
[ Info: iteration 45, average log likelihood -1.411384
[ Info: iteration 46, average log likelihood -1.411375
[ Info: iteration 47, average log likelihood -1.411366
[ Info: iteration 48, average log likelihood -1.411357
[ Info: iteration 49, average log likelihood -1.411349
[ Info: iteration 50, average log likelihood -1.411341
┌ Info: EM with 100000 data points 50 iterations avll -1.411341
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.413371569954193
│     -1.413306745009131
│      ⋮
└     -1.411340878506521
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411341
[ Info: iteration 2, average log likelihood -1.411274
[ Info: iteration 3, average log likelihood -1.411209
[ Info: iteration 4, average log likelihood -1.411133
[ Info: iteration 5, average log likelihood -1.411037
[ Info: iteration 6, average log likelihood -1.410916
[ Info: iteration 7, average log likelihood -1.410770
[ Info: iteration 8, average log likelihood -1.410605
[ Info: iteration 9, average log likelihood -1.410431
[ Info: iteration 10, average log likelihood -1.410259
[ Info: iteration 11, average log likelihood -1.410097
[ Info: iteration 12, average log likelihood -1.409951
[ Info: iteration 13, average log likelihood -1.409822
[ Info: iteration 14, average log likelihood -1.409711
[ Info: iteration 15, average log likelihood -1.409615
[ Info: iteration 16, average log likelihood -1.409532
[ Info: iteration 17, average log likelihood -1.409459
[ Info: iteration 18, average log likelihood -1.409396
[ Info: iteration 19, average log likelihood -1.409340
[ Info: iteration 20, average log likelihood -1.409289
[ Info: iteration 21, average log likelihood -1.409243
[ Info: iteration 22, average log likelihood -1.409201
[ Info: iteration 23, average log likelihood -1.409161
[ Info: iteration 24, average log likelihood -1.409123
[ Info: iteration 25, average log likelihood -1.409088
[ Info: iteration 26, average log likelihood -1.409054
[ Info: iteration 27, average log likelihood -1.409021
[ Info: iteration 28, average log likelihood -1.408990
[ Info: iteration 29, average log likelihood -1.408960
[ Info: iteration 30, average log likelihood -1.408931
[ Info: iteration 31, average log likelihood -1.408903
[ Info: iteration 32, average log likelihood -1.408876
[ Info: iteration 33, average log likelihood -1.408850
[ Info: iteration 34, average log likelihood -1.408825
[ Info: iteration 35, average log likelihood -1.408801
[ Info: iteration 36, average log likelihood -1.408778
[ Info: iteration 37, average log likelihood -1.408756
[ Info: iteration 38, average log likelihood -1.408735
[ Info: iteration 39, average log likelihood -1.408715
[ Info: iteration 40, average log likelihood -1.408695
[ Info: iteration 41, average log likelihood -1.408677
[ Info: iteration 42, average log likelihood -1.408659
[ Info: iteration 43, average log likelihood -1.408642
[ Info: iteration 44, average log likelihood -1.408626
[ Info: iteration 45, average log likelihood -1.408611
[ Info: iteration 46, average log likelihood -1.408596
[ Info: iteration 47, average log likelihood -1.408582
[ Info: iteration 48, average log likelihood -1.408569
[ Info: iteration 49, average log likelihood -1.408556
[ Info: iteration 50, average log likelihood -1.408544
┌ Info: EM with 100000 data points 50 iterations avll -1.408544
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.411341150844485
│     -1.4112739589113261
│      ⋮
└     -1.4085435269342037
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4219399065822103
│     -1.4219597505023485
│     -1.421861484172404
│     -1.4217650668406887
│      ⋮
│     -1.408568774692382
│     -1.4085558927377564
└     -1.4085435269342037
32×26 Array{Float64,2}:
 -0.0469581   -0.0218014   -0.00387479  -0.0895122    0.125491    0.0068071    0.0269302   -0.0191953  -0.0241608   -0.0637792    0.187063    0.0131666  -0.00113278  -0.0334757   0.169982   -0.000268555  -0.104938    0.0862237    0.113283   -0.0659057   -0.0924756  -0.0812953   0.0106198  -0.0531873   -0.02983     0.110559
  0.189999    -0.0569045   -0.0684656   -0.00305175  -0.244552    0.095155    -0.29219     -0.0699806   0.00797063   0.134688     0.042006    0.0434676   0.137551     0.275632   -0.234072   -0.0830046     0.065693   -0.00948782  -0.0525297   0.211411     0.363563    0.250279   -0.168314    0.131784     0.0724666  -0.220066
 -0.0573831    0.303061     0.169745     0.418429    -0.0712344  -0.223254     0.0413662    0.0688779   0.151892     0.00473585  -0.136656   -0.274523   -0.364226    -0.0501558   0.0638409  -0.364845      0.131081   -0.357956     0.137423   -0.0194187    0.0152812  -0.323677    0.210585    0.0925558    0.179234   -0.0158919
  0.00342972   0.121464    -0.142294     0.271304    -0.186717    0.166022     0.255059     0.0202464  -0.0263394    0.468072    -0.0902558   0.441512   -0.340378    -0.803133   -0.395546   -0.110065      0.126378   -0.0028009    0.119555   -0.117667     0.474599   -0.403953   -0.0721232   0.251215     0.14362    -0.357726
 -0.0769753   -0.338531     0.230761     0.281188    -0.0412111  -0.24218      0.20144      0.718334    0.0579655    0.155792     0.546222    0.54165    -0.00194557   0.0750719  -0.173864    0.278977     -0.199739    0.414846    -0.11628     0.0456813    0.0367084   0.227753    0.161088   -0.646702    -0.0286684  -0.201268
 -0.653079    -0.0530673    0.0426913    0.563774     0.105715    0.261166     0.2333       0.463328   -0.149039    -0.290954     0.0782265   0.396       0.560753    -0.117259   -0.70785    -0.0337564    -0.558823    0.365262     0.419759   -0.0457767    0.154432   -0.160361   -0.251722   -0.249817     0.0969225   0.615923
  0.158129     0.454566     0.149978     0.0820321    0.188767   -0.11206     -0.0390721    0.239707    0.122907     0.021814     0.580679    0.0821076   0.0168831    0.412122    1.0626      0.0741528     0.0309768   0.381098     0.148231   -0.242851    -0.244377    0.116528    0.455865   -0.361645    -0.0701714   0.637341
  0.645612     0.288488    -0.317558     0.265357     0.0843807   0.429892     0.0325857    0.296411    0.00346587  -0.0827708    0.651954    0.141078   -0.279743     0.306842    0.175535   -0.112835     -0.198798    0.403665     0.371168    0.37904      0.472945   -0.269798   -0.0974107   0.195859    -0.265753    0.791936
 -0.241697    -0.163878    -0.0649197   -0.413788     0.30148     0.282498     0.164138    -0.383771   -0.351425    -0.120625    -0.246862   -0.427056    0.743498     0.119397    0.0713867   0.148682      0.0837157   0.104285    -0.249892   -0.0382213   -0.334104   -0.218627   -0.329185    0.255722    -0.382826    0.204692
 -0.235241    -0.375302    -0.153434    -0.208794    -0.157199    0.535718     0.303761     0.0318581   0.0329049    0.670941    -0.0997562  -0.341889    0.565372    -0.258902    0.102862   -0.115396     -0.774554    0.100554    -0.818905   -0.236462     0.0497079  -0.385563    0.434684   -0.235057     0.328372    0.282914
 -0.446068     0.0735482    0.259399     0.382568     0.623047   -0.160346     0.468143    -0.0459392  -0.182278    -0.142397    -0.523826    0.139842    0.0967996   -0.37089    -0.132829    0.0917212     0.215625   -0.292362     0.0413052   0.251932    -0.202391   -0.036248   -0.430442    0.0131079   -0.0629351   0.191289
 -0.339518     0.00141901   0.00491126   0.031579     1.04066    -0.506392     0.317991    -0.161287    1.07364     -0.589526     0.0867275  -0.387232   -0.331336    -0.301776   -0.408867   -0.156908     -0.25465     0.223145     0.0396077  -0.059891    -0.116192   -0.114205   -0.558766    0.180584     0.0229578   0.434546
  0.275691     0.256254    -0.665158    -0.458533    -0.233674    0.180021    -0.13329     -0.598122   -0.865691    -0.0208507   -0.510567   -0.0226077  -0.494018     0.0117797   0.540557    0.396785      0.560612   -0.630174     0.109736   -0.029008     0.240054    0.309526   -0.0329941   0.0304179    0.066399    0.120497
  0.195841    -0.198743     0.0200898   -0.403843    -0.362677   -0.344735     0.328061     0.527699   -0.933214    -0.0707543   -0.120694    0.270648   -0.0266448    0.238781    0.196624    0.112073      0.636926    0.190631     0.0263327   0.0361666   -0.113111   -0.363879    0.0820514  -0.00761417  -0.068736    0.13585
 -0.404409    -0.0284609   -0.287897    -0.167521    -0.41941    -0.455623     0.309061    -0.324693    0.291939    -0.228422    -0.470731   -0.12042     0.214552    -0.0336837   0.105046    0.0132369     0.408555   -0.197588    -0.164623   -0.379077     0.287103    0.957275    0.166789   -0.162472     0.46398    -0.203625
  0.0878268   -0.279061    -0.346062    -0.115035     0.232102   -0.332366     0.00715867  -0.0136707   0.0501841   -0.453676    -0.0572189  -0.597937    0.200657     0.700894    0.251268    0.210728     -0.288609   -0.427309     0.0774594   0.156792     0.113008    0.567595    0.393994    0.0182762   -0.0220958   0.542979
 -0.0679868    0.886322    -0.43832     -0.0691563   -0.559858    0.299975    -0.623267    -0.232106    0.839867     0.256277    -0.0752253   0.210773   -0.369629    -0.189653    0.0762774  -0.784466     -0.0365854  -0.367987    -0.0880875   0.516841     0.027835   -0.0170164   0.101388    0.0867004    0.0639126  -0.400692
  0.0601214   -0.0594132   -0.00778011   0.389924     0.142703    0.302793    -0.427417    -0.543155    0.304618     0.395655    -0.16624    -0.446438   -0.0554687    0.261461   -0.717338   -0.124125     -0.430341   -0.688179    -0.260179    0.449316     0.316264    0.0633609  -0.101927    0.156853    -0.0926161  -0.698014
 -0.827945     0.615679     0.366257    -0.111695    -0.292711    0.137266    -0.685725    -0.660827    0.218805     0.2398       0.442444    0.19165    -0.450935     0.282287   -0.0648155  -0.289629      0.551965   -0.216739     0.0965598  -0.328358     0.35602    -0.441923   -0.245591    0.0449005    0.348234   -0.139427
  0.405625    -0.0914037    0.318637     0.00732065  -0.413037   -0.119746    -0.58363      0.230466   -0.231029     0.0274734    0.29732     0.308298   -0.187236     0.335854   -0.257524   -0.122986      0.35247     0.151452     0.426174    0.147298     0.532117    0.0022003  -0.0963373   0.250648     0.481654   -0.753806
 -0.0933645    0.0889741   -0.850666    -0.180674     0.351335    0.536102     0.544859    -0.756541   -0.00568175   0.178644    -0.0474777  -0.215426   -0.158458    -0.825514    0.463656   -0.278933     -0.0338777  -0.0395905   -0.129246   -0.194732    -0.513523   -0.136964   -0.176888    0.0893005   -0.30241     0.203734
 -0.614233    -0.037649     0.465853     0.128001    -0.0490569  -0.236784     0.613089     0.0669403  -0.372349     0.278753    -0.304311   -0.211056   -0.197635    -0.583914    0.220417    0.108968      0.224562   -0.371393    -0.142302   -0.523883    -0.345946   -0.588687    0.269994   -0.271869     0.422558    0.220895
 -0.0894112    0.346467    -0.0874685    0.186972     0.224685   -0.143864     0.434587    -0.341209   -0.236142    -0.0772978   -0.758189   -0.554928    0.0345702    0.0140658  -0.384726   -0.13077       0.596696   -0.183761    -0.03269     0.671784     0.245363   -0.498842   -0.311935    0.433421     0.0637153   0.329286
 -0.00889196  -0.100432    -0.226756    -0.0435643   -0.150183    0.00484988   0.0187391    0.0207731  -0.151104     0.00702336   0.130503    0.0605707   0.044572     0.242871    0.192985    0.0548596    -0.116613   -0.203946    -0.0371183  -0.15514      0.296096    0.385543    0.335465   -0.161002     0.033072   -0.0209236
  0.222573    -0.282451     0.578161    -0.34584     -0.125101   -0.795671    -0.148641    -0.042913    0.154627     0.344527     0.378234   -0.954049    0.345224     0.705619    0.148623   -0.0805464     0.106456    0.464596    -0.35616     0.00327921  -0.514418    0.114359    0.0154111  -0.0624477   -0.0474492  -0.149828
  0.4147      -0.270595    -0.173341    -0.550249     0.107559    0.726885    -0.607587    -0.16925     0.149302    -0.159217     0.341889   -0.101137    0.816675     0.514139   -0.0900723   0.131939     -0.216692    0.778192     0.0518881   0.299225    -0.516141    0.214933   -0.448736    0.371745    -0.445684   -0.193262
  0.161098    -0.807627    -0.0989787   -0.620319    -0.750003    0.10252     -0.43568     -0.112491   -0.164661     0.216692     0.537345    0.172838    0.362984     0.111012    0.227148   -0.38844      -0.312666    0.117104    -0.125855   -0.952586    -0.0693591  -0.066484    0.228267    0.0231754   -0.450781   -0.466762
 -0.0130488   -0.326262    -0.430119    -0.158578     0.245311    0.467328    -0.30165      0.27304    -0.0457123   -0.169753     0.296867    0.624356    0.288324     0.241874    0.140379    0.185457     -0.65574    -0.129777    -0.08587    -0.203047     0.033205    0.653667    0.374284   -0.299141    -0.367595   -0.355501
 -0.164986     0.0823963    0.449849     0.206973     0.601897   -0.163184     0.0778565    0.520647   -0.293876    -0.743843     0.394678    0.925312   -0.07436     -0.237764    0.289394    0.305307      0.488439    0.577583     0.478805   -0.208934    -0.169353    0.082756   -0.275133    0.0528146    0.0813908   0.246878
  0.323161    -0.971524    -0.0488581   -0.0524344    0.588941   -0.207257     1.04232      0.523927   -0.59714     -0.0778113   -0.378939   -0.119757    0.590119    -0.144884   -0.0202257   0.584432     -0.529886    0.511499     0.213877    0.13037     -0.401462    0.536721   -0.131225   -0.191557    -0.557669    0.204491
 -0.139964     0.335082     0.495203     0.358654     0.222425   -0.227877    -0.878709     0.596399    0.982072     0.137775     0.0312658   0.216304   -0.0602812   -0.22378    -0.512171    0.0150395    -0.251725   -0.126977    -0.032929    0.378787    -0.234009   -0.132049   -0.413545    0.302681     0.0158353  -0.0989982
  0.608929     0.0693075    0.447928     0.68112      0.31628    -0.159766     0.110761     0.917692    0.682445     0.599934     0.0685277   0.0208255  -0.265739    -0.800033    0.0281895  -0.058819     -0.228337    0.411997    -0.0181758   0.363803    -0.473716   -0.617685    0.378488    0.01273     -0.0917457  -0.26868[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408532
[ Info: iteration 2, average log likelihood -1.408520
[ Info: iteration 3, average log likelihood -1.408509
[ Info: iteration 4, average log likelihood -1.408499
[ Info: iteration 5, average log likelihood -1.408488
[ Info: iteration 6, average log likelihood -1.408478
[ Info: iteration 7, average log likelihood -1.408469
[ Info: iteration 8, average log likelihood -1.408459
[ Info: iteration 9, average log likelihood -1.408450
[ Info: iteration 10, average log likelihood -1.408442
┌ Info: EM with 100000 data points 10 iterations avll -1.408442
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.341943e+05
      1       7.016412e+05      -2.325531e+05 |       32
      2       6.884121e+05      -1.322911e+04 |       32
      3       6.834635e+05      -4.948621e+03 |       32
      4       6.809629e+05      -2.500640e+03 |       32
      5       6.794074e+05      -1.555476e+03 |       32
      6       6.782736e+05      -1.133791e+03 |       32
      7       6.773887e+05      -8.848838e+02 |       32
      8       6.767010e+05      -6.877088e+02 |       32
      9       6.761247e+05      -5.763465e+02 |       32
     10       6.756144e+05      -5.102367e+02 |       32
     11       6.751892e+05      -4.252017e+02 |       32
     12       6.748311e+05      -3.581639e+02 |       32
     13       6.744986e+05      -3.324500e+02 |       32
     14       6.742182e+05      -2.804040e+02 |       32
     15       6.739612e+05      -2.569645e+02 |       32
     16       6.737195e+05      -2.417568e+02 |       32
     17       6.734875e+05      -2.320248e+02 |       32
     18       6.732647e+05      -2.227580e+02 |       32
     19       6.730616e+05      -2.030571e+02 |       32
     20       6.728935e+05      -1.681725e+02 |       32
     21       6.727279e+05      -1.655194e+02 |       32
     22       6.725491e+05      -1.788258e+02 |       32
     23       6.723850e+05      -1.641669e+02 |       32
     24       6.722159e+05      -1.690576e+02 |       32
     25       6.720350e+05      -1.809023e+02 |       32
     26       6.718626e+05      -1.723507e+02 |       32
     27       6.717041e+05      -1.585594e+02 |       32
     28       6.715589e+05      -1.451939e+02 |       32
     29       6.714392e+05      -1.197116e+02 |       32
     30       6.713226e+05      -1.165367e+02 |       32
     31       6.712220e+05      -1.006064e+02 |       32
     32       6.711309e+05      -9.118066e+01 |       32
     33       6.710472e+05      -8.363964e+01 |       32
     34       6.709751e+05      -7.215074e+01 |       32
     35       6.709071e+05      -6.792223e+01 |       32
     36       6.708449e+05      -6.220823e+01 |       32
     37       6.707840e+05      -6.097459e+01 |       32
     38       6.707241e+05      -5.986247e+01 |       32
     39       6.706609e+05      -6.320059e+01 |       32
     40       6.706009e+05      -5.997800e+01 |       32
     41       6.705450e+05      -5.590702e+01 |       32
     42       6.705000e+05      -4.499005e+01 |       32
     43       6.704505e+05      -4.948025e+01 |       32
     44       6.704101e+05      -4.046517e+01 |       32
     45       6.703743e+05      -3.575805e+01 |       32
     46       6.703379e+05      -3.639137e+01 |       32
     47       6.703059e+05      -3.204531e+01 |       32
     48       6.702796e+05      -2.623816e+01 |       32
     49       6.702585e+05      -2.115527e+01 |       32
     50       6.702363e+05      -2.216491e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 670236.3246013245)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420280
[ Info: iteration 2, average log likelihood -1.415327
[ Info: iteration 3, average log likelihood -1.414041
[ Info: iteration 4, average log likelihood -1.413148
[ Info: iteration 5, average log likelihood -1.412230
[ Info: iteration 6, average log likelihood -1.411327
[ Info: iteration 7, average log likelihood -1.410621
[ Info: iteration 8, average log likelihood -1.410176
[ Info: iteration 9, average log likelihood -1.409912
[ Info: iteration 10, average log likelihood -1.409743
[ Info: iteration 11, average log likelihood -1.409622
[ Info: iteration 12, average log likelihood -1.409525
[ Info: iteration 13, average log likelihood -1.409444
[ Info: iteration 14, average log likelihood -1.409375
[ Info: iteration 15, average log likelihood -1.409314
[ Info: iteration 16, average log likelihood -1.409260
[ Info: iteration 17, average log likelihood -1.409211
[ Info: iteration 18, average log likelihood -1.409166
[ Info: iteration 19, average log likelihood -1.409125
[ Info: iteration 20, average log likelihood -1.409087
[ Info: iteration 21, average log likelihood -1.409052
[ Info: iteration 22, average log likelihood -1.409018
[ Info: iteration 23, average log likelihood -1.408986
[ Info: iteration 24, average log likelihood -1.408956
[ Info: iteration 25, average log likelihood -1.408927
[ Info: iteration 26, average log likelihood -1.408900
[ Info: iteration 27, average log likelihood -1.408873
[ Info: iteration 28, average log likelihood -1.408847
[ Info: iteration 29, average log likelihood -1.408823
[ Info: iteration 30, average log likelihood -1.408799
[ Info: iteration 31, average log likelihood -1.408776
[ Info: iteration 32, average log likelihood -1.408753
[ Info: iteration 33, average log likelihood -1.408732
[ Info: iteration 34, average log likelihood -1.408711
[ Info: iteration 35, average log likelihood -1.408691
[ Info: iteration 36, average log likelihood -1.408672
[ Info: iteration 37, average log likelihood -1.408653
[ Info: iteration 38, average log likelihood -1.408635
[ Info: iteration 39, average log likelihood -1.408618
[ Info: iteration 40, average log likelihood -1.408602
[ Info: iteration 41, average log likelihood -1.408587
[ Info: iteration 42, average log likelihood -1.408572
[ Info: iteration 43, average log likelihood -1.408558
[ Info: iteration 44, average log likelihood -1.408545
[ Info: iteration 45, average log likelihood -1.408532
[ Info: iteration 46, average log likelihood -1.408520
[ Info: iteration 47, average log likelihood -1.408509
[ Info: iteration 48, average log likelihood -1.408498
[ Info: iteration 49, average log likelihood -1.408487
[ Info: iteration 50, average log likelihood -1.408478
┌ Info: EM with 100000 data points 50 iterations avll -1.408478
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.632332     0.0399032   -0.167347     0.567149    0.200823    0.305978    0.387048    0.288128    0.0347632   -0.312035    0.0254263     0.297534    0.673386    -0.378914   -0.80747    -0.170802    -0.509807      0.47974     0.530328    -0.0438399    0.148987    -0.0638431  -0.442672    -0.198317    0.0763998   0.66679
  0.0271719   -0.585789     0.0256575   -0.787455    0.10773     1.19793    -0.194633   -0.177153   -0.196346    -0.0612104   0.000180999   0.0533893   0.548217     0.32817     0.27448    -0.0786325    0.867361      0.883862   -0.00802519   0.285002    -0.113588    -0.832539   -0.511705     0.773072    0.41344    -0.15174
  0.226274    -0.16076      0.16154     -0.0618589  -0.215321   -0.0379116  -0.530339    0.129044   -0.101757     0.0787187   0.19219       0.160998    0.228059     0.651789   -0.286693    0.0708588    0.0962517     0.11647    -0.0246948    0.335527     0.305666     0.380061   -0.295155    -0.072544    0.117668   -0.241299
 -0.227609     0.520341     0.253888     0.109619   -0.296535    0.073221    0.0476821  -0.589921   -0.403448     0.352643   -0.348301     -0.276956   -0.173039     0.240777   -0.22757    -0.303396     0.592203     -0.180942    0.0840596    0.207989     0.217015    -0.77201    -0.18833      0.111704    0.0382201  -0.0516276
  0.366516     0.02732     -0.710713    -0.290188   -0.737784   -0.227422   -0.278007    0.0520868   0.460423    -0.0156221   0.229622     -0.533917   -0.0697994    0.470866   -0.173023   -0.00354705   0.26059       0.0974701   0.211622    -0.0713209    0.654393     0.390862    0.204329     0.714397    0.153397   -0.190063
 -0.128296    -0.180301    -0.172264    -0.282747    0.210546    0.284621    0.0812216  -0.323712   -0.155201    -0.0467283  -0.235821     -0.369607    0.527171    -0.0132838   0.065175   -0.00690361  -0.119736     -0.0311323  -0.251201    -0.019956    -0.138324    -0.0213957  -0.165664     0.258677   -0.235681    0.121472
 -0.048101     0.186223     0.432979     0.154264   -0.223199    0.255893   -0.584214    0.392336   -0.15722     -0.132514    0.725793      1.07922    -0.425642     0.180076   -0.179146    0.0639248    0.0240984     0.326311    0.108541    -0.292207     0.543528    -0.287283    0.105893    -0.234212    0.147965   -0.158097
 -0.0837429   -0.444881    -0.33551     -0.4638     -0.26123     0.298461    0.338518    0.171179   -0.273605     0.420305    0.0138224    -0.186647    0.308058    -0.294101    0.393446   -0.41194     -0.469961      0.0993011  -0.533669    -0.548314    -0.0192217   -0.724045    0.690719    -0.310755    0.257406    0.357023
 -0.457076    -0.130507    -0.652918    -0.629236   -0.534366    0.269901   -0.101222   -1.04134    -0.493338    -0.28206    -0.140144      0.0947234   0.285221     0.374404    0.22326     0.00508607   0.169115     -0.198144   -0.22484     -0.682634     0.421909     0.817211   -0.0689809   -0.0948752   0.0637758  -0.183863
  0.677776    -0.233137    -0.0203573   -0.552236   -0.125485   -0.327744   -0.123591    0.107533   -0.602483     0.234428   -0.00262126   -0.183785   -0.767334     0.392488    1.00906     0.29562      0.713284     -0.581591   -0.0267425    0.146595    -0.216005     0.105512   -0.236891     0.285276   -0.0879307  -0.384388
 -0.58626      0.20621      0.709404     0.526669    0.440704   -0.026959    0.0502341   0.233236    0.122471    -0.027254   -0.174796      0.227466   -0.00363167  -0.352438   -0.0782561   0.00272784  -0.0781232    -0.364282   -0.0519007    0.132712    -0.479861    -0.325628   -0.289933     0.116944   -0.0720588   0.0745148
 -0.0736275    0.375239     0.450655     0.0925055   0.198139   -0.253426    0.37418     0.302867   -0.125082    -0.281297    0.137345      0.257433   -0.266518    -0.284826    1.04017    -0.130555     0.712943      0.547974    0.467451    -0.333732    -0.0751728    0.011642   -0.148604    -0.43899     0.427288    0.708082
 -0.138022     0.0696232    0.0156408    0.109354    0.10834    -0.114368    0.283958    0.02465    -0.178602     0.0333936  -0.168141     -0.0722513   0.0333422   -0.0905865   0.0879871   0.0256284    0.124472     -0.108635    0.0372512    0.0775508   -0.0797314   -0.117978    0.0340928    0.0431091   0.0730458   0.220349
 -0.36396     -0.226979     0.13603     -0.284569    0.111164   -0.740681    0.366908   -0.288862   -0.0834779   -0.242176   -0.77728      -0.504682    0.330563     0.143988    0.155604    0.0338347    0.341484     -0.501953    0.151372     0.276524    -0.00382427   0.499228    0.0318902    0.0153382   0.342988    0.244954
 -0.160181    -0.225843     0.177597     0.05479    -0.112924    0.107261    0.148629    0.332943   -0.00687682   0.311031    0.51212       0.381351    0.0986692   -0.0791765  -0.0832692   0.0972906   -0.255463      0.452418   -0.3518      -0.126907    -0.126199    -0.108579    0.0407913   -0.449178   -0.0616751  -0.0765751
  0.0505863   -0.264935     0.306882    -0.0858096   0.326069   -0.464555    0.378342    0.318161   -0.981301    -0.603909   -0.0782645     0.121929    0.359643     0.287822   -0.347584    0.372841     0.463281      0.357266    0.0603155   -0.0316553   -0.0924444   -0.232084    0.0788912    0.181156   -0.3096      0.167069
  0.296573    -0.63285     -0.334681    -0.238764    0.654751    0.279545    0.386581    0.150895   -0.197064    -0.105337   -0.11395      -0.279418    0.764175     0.0801151  -0.0755008   0.404037    -0.608068      0.541777    0.00991282   0.0579337   -0.79395      0.371675   -0.426474    -0.0525288  -0.860056    0.195676
  0.0501966    0.203643    -0.940485     0.0636104   0.325987    0.523751    0.301452   -0.472909   -0.348985    -0.129421   -0.254151      0.0261641  -0.464618    -0.400234    0.426844   -0.0108468   -0.00685313   -0.528506    0.187623     0.016799     0.0558647   -0.161437   -0.120429     0.244897   -0.282598    0.576279
  0.123772    -0.450238    -0.188705     0.0500867   0.0901905  -0.182844    0.274093    0.690591   -0.136587    -0.267911    0.14221       0.463539    0.221325     0.215824    0.236524    0.391946    -0.266375      0.0965325   0.224444     0.125336     0.30917      0.965156    0.335881    -0.436499   -0.0296415   0.0623341
 -0.0572635   -0.0032075   -0.31842     -0.0135748   0.152074   -0.243677    0.0142589  -0.0127834   0.104895    -0.186862    0.217055     -0.294754    0.210625     0.597317    0.435831    0.170838    -0.351388     -0.244419   -0.170406    -0.281129    -0.145677     0.477091    0.611757    -0.432832   -0.0659764   0.31571
  0.13778      0.00960391  -0.0260735    0.345956    0.0518051   0.353551   -0.527539   -0.344801    0.385006     0.28582    -0.154219     -0.355454    0.0694804    0.262517   -0.623581   -0.179821    -0.482825     -0.577543   -0.25729      0.465641     0.287375     0.09875    -0.0410222    0.133979   -0.0978466  -0.493959
  0.124173    -0.478568     0.431527    -0.447392   -0.385797   -0.258165   -0.363949   -0.0066615   0.439048     0.632382    0.724483     -0.476139    0.601854     0.366834    0.293339   -0.208797    -0.279086      0.564203   -0.320965    -0.2463      -0.606708     0.184366   -0.00159197  -0.136928   -0.319712   -0.448571
  0.524632     0.48638     -0.0347325   -0.145439    0.169277    0.197862   -0.286132    0.154064    0.154351    -0.155546    0.840997     -0.116139    0.00691775   0.502715    0.549849   -0.026534    -0.241665      0.44902     0.389158     0.196581    -0.105055    -0.156037    0.0268206    0.125174   -0.412929    0.534499
 -0.316506    -0.0222708    0.161946    -0.0059496   1.04947    -0.577174    0.0864424  -0.139696    1.08662     -0.581483    0.151631     -0.597517   -0.466347     0.038886   -0.356108   -0.108778    -0.246441      0.144139   -0.125682     0.0333807   -0.0822579   -0.243464   -0.466426     0.124643    0.258283    0.585236
  0.599471     0.243508     0.386797     0.834142    0.321548   -0.205086    0.145976    0.838499    0.563686     0.366086   -0.0187628    -0.0407405  -0.349893    -0.569328   -0.0488035   0.0200946   -0.163888      0.283532    0.0453527    0.443312    -0.148293    -0.491935    0.492902     0.0785675  -0.0584115   0.0690108
  0.135781    -0.409136     0.547893     0.2339     -0.0467669  -0.472357   -0.0381682   0.243789   -0.155679     0.212081    0.412383      0.175744   -0.382439    -0.106057   -0.627274   -0.176438     0.143932      0.177741    0.809056     0.110529     0.321337    -0.344672   -0.412667     0.510988    0.523413   -0.680388
  0.0146908    0.237115     0.00228927   0.298803   -0.150944    0.0220965  -0.214576   -0.0184281   0.39384      0.103363   -0.0496875    -0.0148887  -0.254244    -0.0607725  -0.127517   -0.329278     0.000298993  -0.294092   -0.014746     0.0660888    0.222992     0.0228837   0.105382     0.082276    0.2386     -0.245161
  0.00387159  -0.0417916   -0.0590003    0.0121325   0.0789594  -0.173167    0.244051    0.0491205  -0.215263    -0.0616403   0.0257827     0.0814302  -0.126184    -0.0743162   0.11608     0.0547941    0.103328      0.0515675   0.288399    -0.00318553   0.12145     -0.0776622  -0.0559559   -0.070038   -0.0140549   0.22587
  0.123071     0.0568357   -0.494018    -0.172126   -0.34045     0.523563   -0.458515    0.210592   -0.0748726    0.215889    0.0264474     0.77849     0.0166704   -0.51239     0.0833808  -0.0913478   -0.286003     -0.0451098   0.249267    -0.0447805    0.0779597    0.0993111   0.491127     0.355451   -0.175678   -0.946238
 -0.537644     1.00112     -0.0668236   -0.0278634  -0.573412   -0.0198639  -0.682284   -0.353222    0.736077     0.209538    0.214894      0.224626   -0.607672    -0.0107141   0.0641108  -0.767128     0.410493     -0.559999    0.0421588    0.135207     0.296015    -0.111637   -0.0117505   -0.0267269   0.349525   -0.260638
 -0.0811723    0.212667    -0.538701     0.198548    0.199211   -0.0181317   0.423527   -0.260382    0.401508     0.297442   -0.569833      0.0301992  -0.0858826   -0.969647   -0.353049   -0.159567     0.337983      0.142306   -0.229468     0.189017     0.0348297   -0.11231    -0.451591     0.214792    0.151236   -0.229737
 -0.425862    -0.0836824    0.218087     0.114858   -0.336404   -0.206803    0.37132    -0.300174   -0.150406     0.381562   -0.273531     -0.504573   -0.146846    -0.670035    0.0188342   0.395974     0.299398     -0.408133   -0.579383    -1.13043     -0.274957    -0.0916668   0.322936    -0.23143     0.499998   -0.272733[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408468
[ Info: iteration 2, average log likelihood -1.408460
[ Info: iteration 3, average log likelihood -1.408451
[ Info: iteration 4, average log likelihood -1.408444
[ Info: iteration 5, average log likelihood -1.408436
[ Info: iteration 6, average log likelihood -1.408429
[ Info: iteration 7, average log likelihood -1.408422
[ Info: iteration 8, average log likelihood -1.408416
[ Info: iteration 9, average log likelihood -1.408409
[ Info: iteration 10, average log likelihood -1.408403
┌ Info: EM with 100000 data points 10 iterations avll -1.408403
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
