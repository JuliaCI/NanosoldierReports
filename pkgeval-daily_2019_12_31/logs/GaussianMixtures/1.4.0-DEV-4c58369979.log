Julia Version 1.4.0-DEV.672
Commit 4c58369979 (2019-12-30 22:17 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed CMakeWrapper ─────── v0.2.3
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed CMake ────────────── v1.1.2
 Installed Arpack ───────────── v0.4.0
 Installed SpecialFunctions ─── v0.9.0
 Installed StatsFuns ────────── v0.9.3
 Installed Clustering ───────── v0.13.3
 Installed URIParser ────────── v0.4.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed LegacyStrings ────── v0.4.1
 Installed SortingAlgorithms ── v0.3.1
 Installed Rmath ────────────── v0.6.0
 Installed StaticArrays ─────── v0.12.1
 Installed NearestNeighbors ─── v0.4.4
 Installed BinDeps ──────────── v1.0.0
 Installed Distributions ────── v0.21.11
 Installed FillArrays ───────── v0.8.2
 Installed Blosc ────────────── v0.5.1
 Installed Parameters ───────── v0.12.0
 Installed BinaryProvider ───── v0.5.8
 Installed Missings ─────────── v0.4.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed OrderedCollections ─ v1.1.0
 Installed FileIO ───────────── v1.2.1
 Installed HDF5 ─────────────── v0.12.5
 Installed ScikitLearnBase ──── v0.5.0
 Installed Compat ───────────── v2.2.0
 Installed DataAPI ──────────── v1.1.0
 Installed JLD ──────────────── v0.9.1
 Installed Distances ────────── v0.8.2
 Installed QuadGK ───────────── v2.3.1
 Installed StatsBase ────────── v0.32.0
 Installed DataStructures ───── v0.17.6
 Installed PDMats ───────────── v0.9.10
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_zgmo07/Project.toml`
 [no changes]
  Updating `/tmp/jl_zgmo07/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_Ulcy0D/Project.toml`
 [no changes]
  Updating `/tmp/jl_Ulcy0D/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_PEAwOG/Project.toml`
 [no changes]
  Updating `/tmp/jl_PEAwOG/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_wF9Oip/Project.toml`
 [no changes]
  Updating `/tmp/jl_wF9Oip/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_dOtQNy/Project.toml`
 [no changes]
  Updating `/tmp/jl_dOtQNy/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_dOtQNy/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.1014695359929027e7, [54766.01362908348, 45233.98637091653], [-29219.262198959877 12778.48820774297 -16936.281270747957; 29544.70555056028 -12811.076845712392 16999.60461749134], [[46558.37786061057 3310.6907737258202 -5627.601097080496; 3310.6907737258207 53300.928455603265 2737.7067058549546; -5627.601097080496 2737.7067058549546 51657.51008764684], [54156.897466610404 -3490.0025379884237 5625.2097458501075; -3490.0025379884237 47242.016916076995 -2108.7616522506587; 5625.2097458501075 -2108.7616522506587 48424.84780478617]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.278302e+03
      1       1.090160e+03      -1.881424e+02 |        4
      2       1.036995e+03      -5.316445e+01 |        4
      3       1.016436e+03      -2.055916e+01 |        3
      4       9.763913e+02      -4.004485e+01 |        2
      5       9.709603e+02      -5.431050e+00 |        0
      6       9.709603e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 970.9602907578537)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.059338
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.707061
[ Info: iteration 2, lowerbound -3.598220
[ Info: iteration 3, lowerbound -3.503704
[ Info: iteration 4, lowerbound -3.412821
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.320660
[ Info: iteration 6, lowerbound -3.225098
[ Info: iteration 7, lowerbound -3.132234
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -3.030449
[ Info: iteration 9, lowerbound -2.920140
[ Info: dropping number of Gaussions to 5
[ Info: iteration 10, lowerbound -2.804543
[ Info: iteration 11, lowerbound -2.692240
[ Info: dropping number of Gaussions to 4
[ Info: iteration 12, lowerbound -2.588433
[ Info: iteration 13, lowerbound -2.490033
[ Info: iteration 14, lowerbound -2.409787
[ Info: iteration 15, lowerbound -2.352329
[ Info: iteration 16, lowerbound -2.322173
[ Info: dropping number of Gaussions to 3
[ Info: iteration 17, lowerbound -2.311183
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302940
[ Info: iteration 19, lowerbound -2.299263
[ Info: iteration 20, lowerbound -2.299258
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Dec 31 09:14:52 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Dec 31 09:15:02 2019: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Tue Dec 31 09:15:04 2019: EM with 272 data points 0 iterations avll -2.059338
5.8 data points per parameter
, Tue Dec 31 09:15:07 2019: GMM converted to Variational GMM
, Tue Dec 31 09:15:17 2019: iteration 1, lowerbound -3.707061
, Tue Dec 31 09:15:17 2019: iteration 2, lowerbound -3.598220
, Tue Dec 31 09:15:17 2019: iteration 3, lowerbound -3.503704
, Tue Dec 31 09:15:17 2019: iteration 4, lowerbound -3.412821
, Tue Dec 31 09:15:18 2019: dropping number of Gaussions to 7
, Tue Dec 31 09:15:18 2019: iteration 5, lowerbound -3.320660
, Tue Dec 31 09:15:18 2019: iteration 6, lowerbound -3.225098
, Tue Dec 31 09:15:18 2019: iteration 7, lowerbound -3.132234
, Tue Dec 31 09:15:18 2019: dropping number of Gaussions to 6
, Tue Dec 31 09:15:18 2019: iteration 8, lowerbound -3.030449
, Tue Dec 31 09:15:18 2019: iteration 9, lowerbound -2.920140
, Tue Dec 31 09:15:18 2019: dropping number of Gaussions to 5
, Tue Dec 31 09:15:18 2019: iteration 10, lowerbound -2.804543
, Tue Dec 31 09:15:18 2019: iteration 11, lowerbound -2.692240
, Tue Dec 31 09:15:18 2019: dropping number of Gaussions to 4
, Tue Dec 31 09:15:18 2019: iteration 12, lowerbound -2.588433
, Tue Dec 31 09:15:18 2019: iteration 13, lowerbound -2.490033
, Tue Dec 31 09:15:18 2019: iteration 14, lowerbound -2.409787
, Tue Dec 31 09:15:18 2019: iteration 15, lowerbound -2.352329
, Tue Dec 31 09:15:18 2019: iteration 16, lowerbound -2.322173
, Tue Dec 31 09:15:18 2019: dropping number of Gaussions to 3
, Tue Dec 31 09:15:18 2019: iteration 17, lowerbound -2.311183
, Tue Dec 31 09:15:18 2019: dropping number of Gaussions to 2
, Tue Dec 31 09:15:18 2019: iteration 18, lowerbound -2.302940
, Tue Dec 31 09:15:18 2019: iteration 19, lowerbound -2.299263
, Tue Dec 31 09:15:18 2019: iteration 20, lowerbound -2.299258
, Tue Dec 31 09:15:18 2019: iteration 21, lowerbound -2.299255
, Tue Dec 31 09:15:18 2019: iteration 22, lowerbound -2.299254
, Tue Dec 31 09:15:18 2019: iteration 23, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 24, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 25, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 26, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 27, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 28, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 29, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 30, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 31, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 32, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 33, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 34, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 35, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 36, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 37, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 38, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 39, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 40, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 41, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 42, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 43, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 44, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 45, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 46, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 47, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 48, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 49, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: iteration 50, lowerbound -2.299253
, Tue Dec 31 09:15:18 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398595, 178.04509222601402]
β = [95.95490777398595, 178.04509222601402]
m = [2.000229257775369 53.85198717246128; 4.250300733269909 79.28686694436182]
ν = [97.95490777398595, 180.04509222601402]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948455 -0.008953123827346036; 0.0 0.012748664777409303], [0.184041555474851 -0.007644049042327771; 0.0 0.008581705166333558]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.9954048154312727
avll from llpg:  -0.9954048154312709
avll direct:     -0.9954048154312709
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9717879692581781
avll from llpg:  -0.9717879692581781
avll direct:     -0.9717879692581781
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.045051    -0.0495547   0.114436     0.0581889    0.23804      0.0247363   -0.0323764   -0.0410644    0.123055     0.0849334   -0.17471     -0.125006     0.00614308  -0.0389512  -0.0322434    -0.171474    -0.0653445    0.0778659     0.0828716   -0.0287939    0.0684383   -0.0392138   -0.011039     -0.109908     0.0343694    0.0615648
 -0.139263     0.0365638   0.00920361  -0.093524     0.0982065    0.0239715    0.0300192    0.066165    -0.0570194   -0.028365     0.0848418    0.051552     0.0489166    0.115755   -0.0506415    -0.101977     0.057961    -0.113038     -0.10582     -0.125565     0.0975148   -0.0346002    0.0135582    -0.172675     0.0944988    0.0225675
  0.194691    -0.0394146  -0.0653488    0.0676589    0.210457    -0.133775     0.00501381  -0.0522247   -0.0776701    0.236709    -0.0817782    0.0809795    0.16749      0.0669623  -0.0685316    -0.0723176   -0.036962     0.158772      0.136324    -0.0316292    0.0932762   -0.0135954   -0.00797651    0.0328472    0.0626817   -0.0994861
 -0.0180962    0.046036    0.03945     -0.194883     0.0250679   -0.00806654   0.1158       0.0216628    0.0687893    0.0788795   -0.118386    -0.0751335    0.0580129    0.0689382  -0.199034      0.0176337    0.00735824   0.00901492   -0.0304114   -0.047537     0.193126    -0.107296    -0.00491958   -0.0466761    0.0415969    0.0746225
  0.134575    -0.0123916   0.0561275    0.136243     0.0301197    0.169683    -0.138758    -0.184584     0.127846     0.193612     0.152625    -0.0470894   -0.110439     0.0660077  -0.0306719     0.208365     0.0981081   -0.14206       0.12637     -0.150144    -0.196744    -0.0966872    0.161694     -0.164277     0.276457    -0.0964746
 -0.0767435    0.163751    0.0853458    0.078363    -0.118828     0.100501    -0.0577105    0.0287483    0.0627828   -0.0247834    0.148079    -0.0746331   -0.276416    -0.187781    0.0219402     0.0490375   -0.00618972  -0.0423103    -0.125332     0.0681355    0.00660171   0.137477     0.0518167    -0.0858842    0.0166282   -0.0436773
  0.0345944    0.0331123  -0.00279516  -0.230815    -0.103932     0.11518     -0.0376653    0.0191949    0.00757265   0.169745    -0.00802807   0.119413    -0.0595988   -0.0613314   0.0350913    -0.0749533   -0.039502    -0.0651085     0.0122703    0.209631     0.0313059    0.00356583  -0.0219703    -0.0118928    0.0835017    0.00684944
  0.128731     0.0202525   0.0209378   -0.00501104   0.102232     0.121066     0.0320139    0.0818918   -0.00607551   0.0991663    0.00386891   0.0514622   -0.199252     0.115768    0.0372219    -0.0111744    0.0210064    0.0918508    -0.0639514   -0.0160151    0.11106      0.0403469    0.0254144    -0.132414    -0.089342     0.0574655
 -0.129121    -0.0733221  -0.062925    -0.0352346   -0.257658     0.246441    -0.010943    -0.0446084   -0.136265    -0.0844167   -0.0173657    0.00419433   0.0240489    0.0472228  -0.054377     -0.130812     0.138797     0.291528      0.0932531   -0.0573038   -0.102752    -0.105783    -0.173168      0.00682246  -0.0903553   -0.12384
  0.0591881    0.119384    0.0662638   -0.0545368   -0.0910559    0.0528331   -0.020296     0.00119874   0.015899     0.0987173    0.0939115   -0.0796899    0.0759692    0.0211005   0.0724287    -0.17302      0.197072    -0.216372     -0.0712355    0.028144     0.114287     0.0457966    0.0670464    -0.0236676   -0.0159089    0.0301948
 -0.0564705    0.188673    0.00873019   0.0886303    0.0443379    0.0272539   -0.0540862    0.0460352    0.00466228  -0.0235098   -0.0229232    0.0484348    0.0780836   -0.0190694   0.0973717    -0.0716331   -0.0544655   -0.0504395     0.108533    -0.073004     0.0362312    0.0544448    0.00448636    0.123099     0.087338    -0.0235512
 -0.0715141    0.0542509   0.0462573   -0.127203     0.0879676    0.0346915   -0.0723467    0.274945     0.0625006    0.03931     -0.16814      0.0175974   -0.0326782   -0.100469    0.0101691     0.0520672   -0.0500198   -0.197415      0.0246358   -0.0365186    0.203494    -0.154478     0.0848083    -0.0720126   -0.0732693   -0.110974
 -0.0267212    0.0556933  -0.0970203    0.0940962    0.0226024    0.0242022    0.193313     0.027913     0.084875     0.00853564   0.0225138    0.182518     0.0160075    0.210381   -0.0574742    -0.00811563  -0.104619    -0.0242898     0.0293109    0.0918678    0.107352    -0.00989912  -0.143093      0.0800324   -0.0902179   -0.00498553
 -0.014519    -0.0180028   0.0673672   -0.109213    -0.160324     0.0195749    0.0369674    0.00876421   0.0131602   -0.105246     0.152923     0.0379841   -0.0552387   -0.116713   -0.0653568    -0.0444079    0.0430964    0.057151     -0.0621389   -0.146974     0.0831518   -0.117682     0.163724      0.0944219   -0.173358    -0.184967
 -0.0522472   -0.0822632  -0.13085      0.0384539   -0.0164878    0.158524     0.107604     0.130867     0.013037     0.0572269    0.108468     0.0568727   -0.00225342  -0.0971708  -0.0401894     0.0255278    0.203836     0.0290758    -0.138914     0.108802    -0.139795     0.185341    -0.0602135     0.0435573    0.0304584   -0.0190797
  0.0555722    0.0919268   0.0243007    0.0188359   -0.00152363  -0.0915133    0.212308     0.0780105   -0.0185908    0.0165519   -0.0523989   -0.170738    -0.0434902   -0.0494054   0.204198      0.061659    -0.173286     0.130071      0.198687     0.0369239   -0.0713159   -0.0160175    0.174554     -0.0622694   -0.102068     0.0916768
  0.00495045  -0.128535   -0.137481     0.0740241    0.161994     0.0575996   -0.0823315    0.146719    -0.0929241    0.0372885    0.0754501    0.0113798   -0.0731611    0.246081   -0.068996     -0.0174884   -0.00872243  -0.0751236    -0.135926    -0.100847     0.0810859    0.0302002    0.130783      0.199854     0.0728245    0.010686
  0.0883781    0.0560156  -0.110621    -0.229096     0.016552     0.024064     0.0129728   -0.0741746    0.0450742    0.0364612   -0.096407    -0.0783285    0.0889006   -0.199597    0.18897      -0.0563615   -0.00069695  -0.0253587     0.128676     0.00673103  -0.0613675   -0.0452043   -0.0132293     0.0630842   -0.167022     0.06779
 -0.216741     0.146787   -0.021469     0.0800215   -0.241521    -0.0769535    0.00311316  -0.126698     0.175337     0.0974272    0.20134     -0.141124    -0.0606817    0.15186     0.184829     -0.0261774   -0.00286797  -0.0452587    -0.0405819   -0.0935544   -0.105665    -0.0611435    0.108921      0.158207    -0.077674    -0.0979828
 -0.124482     0.0511165  -0.190752     0.197181     0.0550136    0.108889    -0.104797    -0.0892731    0.0862789    0.0380638    0.074066     0.147976    -0.0185654    0.073335    0.0271488     0.187914     0.036446     0.0528144    -0.128893     0.0816749   -0.146854    -0.034155    -0.0337563     0.200506    -0.00735554  -0.074857
 -0.0237597    0.0134165   0.0572189    0.108132    -0.155966    -0.0143004   -0.0920764   -0.0673132   -0.124981    -0.12592      0.0349665    0.12419      0.0348917   -0.276609    0.0677064     0.108857     0.00619632  -0.178924     -0.00971556  -0.0629562   -0.212727    -0.0513224   -0.109153     -0.129094     0.00842166  -0.158986
  0.172897    -0.0667105   0.0262055   -0.091525    -0.27611     -0.107644    -0.0101115   -0.115095     0.026258     0.0705113   -0.146781     0.0836622    0.0362883    0.175483    0.0513775     0.119354     0.0148633    0.0147418     0.105623     0.129554     0.0149762   -0.0978388   -0.000336583   0.141285     0.100935    -0.0179554
 -0.0586114   -0.0378408   0.0708791   -0.00267517   0.0572219   -0.0611035   -0.14624     -0.0723482   -0.147193    -0.0257788    0.072328     0.123909    -0.12479     -0.104858    0.0241872     0.0238897   -0.0806424   -0.0141459    -0.172426     0.0517411    0.0689221    0.0435093    0.122068     -0.117991     0.0807757    0.0283248
 -0.0514957   -0.0296748  -0.0627112    0.0087804    0.162438    -0.0790648   -0.08612      0.112562     0.0847518   -0.0278893    0.192309     0.0170667   -0.05287     -0.243983    0.0428366     0.183035     0.00439335   0.000912806  -0.0937052    0.0895267    0.0335397    0.036606     0.0924106    -0.0577122   -0.0367803    0.00135105
  0.0115759    0.166185    0.0528343   -0.077798    -0.0669989   -0.0464804    0.0498664    0.0927985    0.0311273    0.158682    -0.0119631    0.134035    -0.0439797    0.0888925   0.172332     -0.134004     0.0620589    0.0898607    -0.071423    -0.0198477   -0.122637     0.0402837    0.123007     -0.0941638    0.175637     0.0493469
  0.125576     0.0297694   0.129101     0.153156    -0.126565    -0.0567922   -0.0206066   -0.0322693   -0.0542586   -0.00281179   0.0648768    0.0832661   -0.0850684   -0.0430804  -0.0581357     0.05923      0.0164075    0.063646      0.0659841   -0.101163     0.219033    -0.068242    -0.0187671    -0.0658338   -0.0296324   -0.0198473
  0.0250297   -0.062219    0.0811283   -0.18231      0.0600276   -0.036215     0.0357419    0.0483651   -0.02594     -0.0228693   -0.081216     0.130937    -0.0214808   -0.150586   -0.0321565     0.0437121    0.0342459    0.126848     -0.169781     0.0430477   -0.0647264   -0.145282     0.0510559    -0.0653729   -0.20115      0.0183907
 -0.156911     0.0515391  -0.116843    -0.069828    -0.194113     0.0579148   -0.0962649   -0.108512     0.100516    -0.0108895   -0.0753143    0.111659     0.109998    -0.0334792   0.000198276  -0.0790015   -0.0151603    0.150586      0.107509    -0.0556634   -0.00406114   0.0796079   -0.0329081    -0.00519878   0.100176     0.0694829
  0.265408    -0.0316156   0.133099     0.0926222    0.0881376   -0.142079    -0.0591617    0.0554067   -0.0801374    0.0433716   -0.100719    -0.0867497    0.0989436    0.0247724   0.0879875     0.0113459    0.0272905   -0.106753     -0.0854067    0.10514     -0.0234702    0.0675413    0.0492856    -0.179444     0.117531     0.0384701
 -0.0260681    0.0635979  -0.0442004    0.207879     0.161879     0.00297003  -0.054969     0.0392782    0.098062    -0.0346469   -0.0362349    0.126005    -0.0317834   -0.122722   -0.0683178     0.0870465    0.0338761   -0.114024     -0.0133038   -0.0989909    0.0596751    0.0486502    0.0984508    -0.0320475    0.1992      -0.0773222
 -0.0539859    0.183964    0.108797    -0.115004     0.135519     0.0247745   -0.0983937   -0.245508     0.0624412    0.102931     0.0469751   -0.027458    -0.0296236   -0.0365748  -0.180039      0.08017      0.126701    -0.108734     -0.101158    -0.148073    -0.0316857   -0.0260992    0.0759275     0.12836     -0.00158439  -0.0616598
 -0.0182906    0.101918    0.0126117   -0.0664547    0.00997271   0.186442    -0.0159585   -0.0694035   -0.00387583   0.0258038   -0.0112443   -0.0134365   -0.0295609   -0.239436   -0.159013     -0.0140423   -0.0397229   -0.15119      -0.0510386    0.236676     0.017037     0.181373    -0.0917096    -0.0836726    0.123829    -0.126546kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4544221742625207
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.454545
[ Info: iteration 2, average log likelihood -1.454452
[ Info: iteration 3, average log likelihood -1.453995
[ Info: iteration 4, average log likelihood -1.448676
[ Info: iteration 5, average log likelihood -1.433366
[ Info: iteration 6, average log likelihood -1.425729
[ Info: iteration 7, average log likelihood -1.424446
[ Info: iteration 8, average log likelihood -1.423997
[ Info: iteration 9, average log likelihood -1.423734
[ Info: iteration 10, average log likelihood -1.423490
[ Info: iteration 11, average log likelihood -1.423182
[ Info: iteration 12, average log likelihood -1.422845
[ Info: iteration 13, average log likelihood -1.422562
[ Info: iteration 14, average log likelihood -1.422354
[ Info: iteration 15, average log likelihood -1.422214
[ Info: iteration 16, average log likelihood -1.422117
[ Info: iteration 17, average log likelihood -1.422043
[ Info: iteration 18, average log likelihood -1.421982
[ Info: iteration 19, average log likelihood -1.421927
[ Info: iteration 20, average log likelihood -1.421876
[ Info: iteration 21, average log likelihood -1.421827
[ Info: iteration 22, average log likelihood -1.421778
[ Info: iteration 23, average log likelihood -1.421733
[ Info: iteration 24, average log likelihood -1.421692
[ Info: iteration 25, average log likelihood -1.421657
[ Info: iteration 26, average log likelihood -1.421629
[ Info: iteration 27, average log likelihood -1.421607
[ Info: iteration 28, average log likelihood -1.421589
[ Info: iteration 29, average log likelihood -1.421575
[ Info: iteration 30, average log likelihood -1.421562
[ Info: iteration 31, average log likelihood -1.421552
[ Info: iteration 32, average log likelihood -1.421542
[ Info: iteration 33, average log likelihood -1.421533
[ Info: iteration 34, average log likelihood -1.421523
[ Info: iteration 35, average log likelihood -1.421512
[ Info: iteration 36, average log likelihood -1.421499
[ Info: iteration 37, average log likelihood -1.421481
[ Info: iteration 38, average log likelihood -1.421450
[ Info: iteration 39, average log likelihood -1.421385
[ Info: iteration 40, average log likelihood -1.421243
[ Info: iteration 41, average log likelihood -1.420978
[ Info: iteration 42, average log likelihood -1.420643
[ Info: iteration 43, average log likelihood -1.420358
[ Info: iteration 44, average log likelihood -1.420159
[ Info: iteration 45, average log likelihood -1.420024
[ Info: iteration 46, average log likelihood -1.419930
[ Info: iteration 47, average log likelihood -1.419861
[ Info: iteration 48, average log likelihood -1.419809
[ Info: iteration 49, average log likelihood -1.419769
[ Info: iteration 50, average log likelihood -1.419738
┌ Info: EM with 100000 data points 50 iterations avll -1.419738
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4545445799147696
│     -1.4544518642513633
│      ⋮
└     -1.4197380387471568
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419839
[ Info: iteration 2, average log likelihood -1.419694
[ Info: iteration 3, average log likelihood -1.419191
[ Info: iteration 4, average log likelihood -1.415084
[ Info: iteration 5, average log likelihood -1.403359
[ Info: iteration 6, average log likelihood -1.394615
[ Info: iteration 7, average log likelihood -1.391346
[ Info: iteration 8, average log likelihood -1.389365
[ Info: iteration 9, average log likelihood -1.387670
[ Info: iteration 10, average log likelihood -1.386174
[ Info: iteration 11, average log likelihood -1.384845
[ Info: iteration 12, average log likelihood -1.383637
[ Info: iteration 13, average log likelihood -1.382547
[ Info: iteration 14, average log likelihood -1.381570
[ Info: iteration 15, average log likelihood -1.380742
[ Info: iteration 16, average log likelihood -1.380085
[ Info: iteration 17, average log likelihood -1.379598
[ Info: iteration 18, average log likelihood -1.379252
[ Info: iteration 19, average log likelihood -1.379016
[ Info: iteration 20, average log likelihood -1.378857
[ Info: iteration 21, average log likelihood -1.378749
[ Info: iteration 22, average log likelihood -1.378671
[ Info: iteration 23, average log likelihood -1.378614
[ Info: iteration 24, average log likelihood -1.378569
[ Info: iteration 25, average log likelihood -1.378532
[ Info: iteration 26, average log likelihood -1.378503
[ Info: iteration 27, average log likelihood -1.378478
[ Info: iteration 28, average log likelihood -1.378458
[ Info: iteration 29, average log likelihood -1.378441
[ Info: iteration 30, average log likelihood -1.378426
[ Info: iteration 31, average log likelihood -1.378414
[ Info: iteration 32, average log likelihood -1.378404
[ Info: iteration 33, average log likelihood -1.378395
[ Info: iteration 34, average log likelihood -1.378387
[ Info: iteration 35, average log likelihood -1.378381
[ Info: iteration 36, average log likelihood -1.378375
[ Info: iteration 37, average log likelihood -1.378371
[ Info: iteration 38, average log likelihood -1.378367
[ Info: iteration 39, average log likelihood -1.378363
[ Info: iteration 40, average log likelihood -1.378361
[ Info: iteration 41, average log likelihood -1.378359
[ Info: iteration 42, average log likelihood -1.378357
[ Info: iteration 43, average log likelihood -1.378355
[ Info: iteration 44, average log likelihood -1.378354
[ Info: iteration 45, average log likelihood -1.378353
[ Info: iteration 46, average log likelihood -1.378352
[ Info: iteration 47, average log likelihood -1.378351
[ Info: iteration 48, average log likelihood -1.378351
[ Info: iteration 49, average log likelihood -1.378350
[ Info: iteration 50, average log likelihood -1.378350
┌ Info: EM with 100000 data points 50 iterations avll -1.378350
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4198388983803738
│     -1.4196940905213233
│      ⋮
└     -1.3783497127733595
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.378518
[ Info: iteration 2, average log likelihood -1.378363
[ Info: iteration 3, average log likelihood -1.377825
[ Info: iteration 4, average log likelihood -1.373296
[ Info: iteration 5, average log likelihood -1.357662
[ Info: iteration 6, average log likelihood -1.341270
[ Info: iteration 7, average log likelihood -1.335121
[ Info: iteration 8, average log likelihood -1.332387
[ Info: iteration 9, average log likelihood -1.330317
[ Info: iteration 10, average log likelihood -1.328548
[ Info: iteration 11, average log likelihood -1.327202
[ Info: iteration 12, average log likelihood -1.326409
[ Info: iteration 13, average log likelihood -1.325975
[ Info: iteration 14, average log likelihood -1.325708
[ Info: iteration 15, average log likelihood -1.325520
[ Info: iteration 16, average log likelihood -1.325370
[ Info: iteration 17, average log likelihood -1.325236
[ Info: iteration 18, average log likelihood -1.325100
[ Info: iteration 19, average log likelihood -1.324942
[ Info: iteration 20, average log likelihood -1.324746
[ Info: iteration 21, average log likelihood -1.324482
[ Info: iteration 22, average log likelihood -1.324112
[ Info: iteration 23, average log likelihood -1.323572
[ Info: iteration 24, average log likelihood -1.322779
[ Info: iteration 25, average log likelihood -1.321895
[ Info: iteration 26, average log likelihood -1.321217
[ Info: iteration 27, average log likelihood -1.320772
[ Info: iteration 28, average log likelihood -1.320452
[ Info: iteration 29, average log likelihood -1.320195
[ Info: iteration 30, average log likelihood -1.319969
[ Info: iteration 31, average log likelihood -1.319762
[ Info: iteration 32, average log likelihood -1.319572
[ Info: iteration 33, average log likelihood -1.319394
[ Info: iteration 34, average log likelihood -1.319212
[ Info: iteration 35, average log likelihood -1.318990
[ Info: iteration 36, average log likelihood -1.318682
[ Info: iteration 37, average log likelihood -1.318254
[ Info: iteration 38, average log likelihood -1.317825
[ Info: iteration 39, average log likelihood -1.317562
[ Info: iteration 40, average log likelihood -1.317432
[ Info: iteration 41, average log likelihood -1.317359
[ Info: iteration 42, average log likelihood -1.317312
[ Info: iteration 43, average log likelihood -1.317278
[ Info: iteration 44, average log likelihood -1.317251
[ Info: iteration 45, average log likelihood -1.317230
[ Info: iteration 46, average log likelihood -1.317212
[ Info: iteration 47, average log likelihood -1.317198
[ Info: iteration 48, average log likelihood -1.317187
[ Info: iteration 49, average log likelihood -1.317178
[ Info: iteration 50, average log likelihood -1.317171
┌ Info: EM with 100000 data points 50 iterations avll -1.317171
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3785175202789537
│     -1.3783630898359536
│      ⋮
└     -1.3171710108546888
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.317444
[ Info: iteration 2, average log likelihood -1.317145
[ Info: iteration 3, average log likelihood -1.315893
[ Info: iteration 4, average log likelihood -1.303168
[ Info: iteration 5, average log likelihood -1.271603
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.249127
[ Info: iteration 7, average log likelihood -1.252403
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.239381
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.239747
[ Info: iteration 10, average log likelihood -1.255533
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.241690
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.240281
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.243940
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.240389
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.239954
[ Info: iteration 16, average log likelihood -1.254871
[ Info: iteration 17, average log likelihood -1.240871
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.232242
[ Info: iteration 19, average log likelihood -1.256475
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.238223
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.239853
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.243507
[ Info: iteration 23, average log likelihood -1.242660
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.231884
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.249693
[ Info: iteration 26, average log likelihood -1.243170
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.232231
[ Info: iteration 28, average log likelihood -1.252250
[ Info: iteration 29, average log likelihood -1.238270
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.230412
[ Info: iteration 31, average log likelihood -1.249323
[ Info: iteration 32, average log likelihood -1.236189
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.228249
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.243571
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.239192
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.237018
[ Info: iteration 37, average log likelihood -1.252530
[ Info: iteration 38, average log likelihood -1.239085
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.231666
[ Info: iteration 40, average log likelihood -1.247840
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.233975
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.234388
[ Info: iteration 43, average log likelihood -1.252711
[ Info: iteration 44, average log likelihood -1.239102
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.231378
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.240271
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.239103
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.237614
[ Info: iteration 49, average log likelihood -1.253232
[ Info: iteration 50, average log likelihood -1.239581
┌ Info: EM with 100000 data points 50 iterations avll -1.239581
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3174444420453064
│     -1.3171451482142928
│      ⋮
└     -1.239580509178427
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.232157
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.228924
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.224535
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.203973
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│      9
│     17
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.165354
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.158125
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     15
│     17
│     19
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.120310
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.118765
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     17
│     19
│     20
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.142679
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     7
│     8
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.136369
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.122004
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.136957
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.148519
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     17
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.118876
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     18
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.130517
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│     17
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.123836
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.145342
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.122146
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.141387
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.126390
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     17
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.135194
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│      9
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.120599
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     17
│     19
│     21
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.129203
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.136062
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.129908
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│      9
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.132713
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.140327
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│     17
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.116927
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     18
│     21
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.130028
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     17
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.138438
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.136144
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.111251
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.149915
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│      9
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.129609
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      7
│      8
│     17
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.122764
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│     18
│     19
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.118607
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.148325
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.126997
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      7
│      8
│     17
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.127103
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.129356
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.141061
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     17
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.122082
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      7
│      8
│     18
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.123073
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│     17
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.129351
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.146097
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│      9
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.115635
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      7
│      8
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.134946
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.131340
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     17
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.129917
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      7
│      8
│      9
│     18
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.116158
┌ Info: EM with 100000 data points 50 iterations avll -1.116158
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2321567357959116
│     -1.2289242178659399
│      ⋮
└     -1.1161578126123228
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4544221742625207
│     -1.4545445799147696
│     -1.4544518642513633
│     -1.4539951743186463
│      ⋮
│     -1.131339841209811
│     -1.1299173607294466
└     -1.1161578126123228
32×26 Array{Float64,2}:
 -0.044462    0.031283     0.0577107    0.100061    -0.0643812  -0.0212795    -0.24399      -0.0305445   -0.182376     -0.15301      0.0439452    0.0962693   -0.0373369   -0.266176    0.0728518    0.0898882    0.0134813   -0.211768    -0.00153188  -0.0636341   -0.235938    -0.0391817    -0.154577    -0.128908     0.0423291   -1.63464
 -0.0170247  -0.00641456   0.0545366    0.107497    -0.146565    0.0370852     0.110898     -0.0782783   -0.047308     -0.11512      0.0350336    0.170261    -0.033896    -0.276846    0.0595123    0.133446     0.00729285  -0.182325    -0.0127112   -0.0758483   -0.195155    -0.155485     -0.0207824   -0.129504    -0.0260653    1.29329
 -0.147217    0.0694741    0.00244908  -0.107065     0.116378    0.0389907    -0.000285094   0.0650648   -0.0452653    -0.0196927    0.0805887    0.0758842    0.0494586    0.120685   -0.0535073   -0.086244     0.0508008   -0.102379    -0.104725    -0.132026     0.0919134    0.0105072     0.00714979  -0.178293     0.0897682   -0.00753218
 -0.0114324   0.0335664    0.0185952   -0.187886     0.0249325   0.000868869   0.105636      0.0194628    0.0684748     0.079097    -0.11662     -0.0547161    0.0446598    0.0743911  -0.198626     0.0783536    0.053454     0.0014666   -0.0347727   -0.0584565    0.198088    -0.107835     -0.0314762   -0.0429045    0.0492413    0.0200287
 -0.0299022  -0.0508315    0.0834166   -5.425e-5    -0.0493874  -0.145274     -0.153249     -0.0901165   -0.157223     -0.0246403    0.0810569    0.124304    -0.114859    -0.124928    0.0190977    0.0339879   -0.0850349   -0.0156276   -0.174189     0.0577341    0.0698352    0.0607431     0.124527    -0.134272     0.0537642    0.00644537
 -0.0197543  -0.080732    -0.111261     0.0370495    0.0376942   0.220637      0.114096      0.210506     0.0103497     0.0490337    0.113114     0.0664847   -0.0347511   -0.0978577  -0.0614815    0.0495906    0.171629     0.0240896   -0.141501     0.0990322   -0.0726153    0.192723     -0.00332832   0.0335404    0.0716985   -0.0219256
 -0.106318   -0.127275    -0.138548     0.122134    -0.223849   -0.083333     -0.274654      0.138721    -0.0124061     0.0374767    0.12671      0.0113005   -0.0729377    0.504837   -0.00198548  -0.0294562   -0.0271979   -0.120067    -0.135994    -0.100946     0.0793583   -0.000219733   0.142455     0.368584     0.231545     0.0750114
  0.0922332  -0.118142    -0.137736     0.00870212   0.506702    0.201672      0.0847273     0.166149    -0.181676      0.0375627    0.0601849    0.0129426   -0.0785979    0.0539967  -0.102993    -0.00552521   0.00295361   0.0289593   -0.136551    -0.0501284    0.079615     0.0552615     0.124675     0.0581181   -0.0736335   -0.0684428
 -0.0637936  -0.0306276   -0.0514028    0.0324163    0.0958901  -0.070006     -0.0910267     0.117227     0.0529313    -0.0299651    0.187058     0.0175893   -0.0483707   -0.227752    0.0471779    0.181674     0.0170099   -0.0242796   -0.0944262    0.0722442    0.0343799    0.0333716     0.126413    -0.0350524   -0.0357813   -0.00450482
  0.128215   -0.0299117    0.063583     0.161445     0.0145103   0.156859     -0.137674     -0.183897     0.134589      0.197438     0.150295    -0.0591193   -0.0887545    0.0862626  -0.0255382    0.208892     0.0983914   -0.142431     0.127038    -0.152643    -0.193733    -0.0853069     0.158769    -0.162856     0.270624    -0.0986448
 -0.220025    0.137032    -0.0313843    0.0861659   -0.237586   -0.101462      0.00258129   -0.120075     0.170534      0.0643013    0.201464    -0.131527    -0.0582307    0.147027    0.162408    -0.0192138   -0.0430131   -0.0262805   -0.0420119   -0.0906508   -0.0891324   -0.0503881     0.136296     0.153674    -0.0758488   -0.0998235
 -0.0135366   0.0437681    0.0231284    0.0622965    0.140357    0.0529692    -0.0398626    -0.0145706    0.0577776     0.0281523   -0.0785818   -0.0170603    0.0211353   -0.036521    0.0388505   -0.0982557   -0.0312704    0.0430716    0.0670617   -0.0402402    0.0184723    0.00841569   -0.0247418    0.00950228   0.0592649    0.0134726
  0.0552655   0.128342     0.0557421   -0.0414387   -0.0881533   0.059892     -0.0247931    -0.0090373    0.0349876     0.110029     0.105159    -0.0578888    0.0778941    0.0215986   0.105259    -0.180533     0.190606    -0.207153    -0.0990618    0.0374696    0.104382     0.0441361     0.0410481   -0.0044539   -0.0121807    0.0200513
 -0.161588    0.0118437   -0.196948     0.192734     0.0440787   0.150043     -0.100998     -0.109919     0.0619904     0.0256662    0.0974278    0.177091     0.00773381   0.0610116   0.0269359    0.175266     0.0431568    0.07083     -0.113547     0.0737097   -0.137826    -0.0421361    -0.0809667    0.183525    -0.00220908  -0.090173
 -0.0806665   0.0837733   -0.00918685  -0.0828233   -0.0810275   0.126019     -0.0458056    -0.104425     0.0313488     0.0235875   -0.0544284    0.0451258    0.0380438   -0.181538   -0.0925329   -0.0456289   -0.0256939   -0.0308634    0.0112041    0.116545     0.00985232   0.14299      -0.0714166   -0.0466371    0.127048    -0.051546
  0.129055    0.0207905   -0.0182213   -0.00366647   0.116334    0.122018      0.0184966     0.117784    -0.00525538    0.116102     0.00628356   0.0389134   -0.161695     0.13119     0.0197879   -0.0136639    0.00127625   0.0680725   -0.0766185   -0.0161175    0.065988     0.0219249     0.00499296  -0.129507    -0.0723836    0.095293
 -0.0419762   0.179536     0.047484     0.0736975   -0.115658    0.101166     -0.0804114    -0.00253493   0.0647687    -0.0239937    0.144475    -0.0727814   -0.262819    -0.200874    0.0360478    0.0484793   -0.00290222   0.0283732   -0.122618     0.0771858    0.0039671    0.133704      0.0516799   -0.0789605    0.00627406   0.0035524
  0.126753    0.0190644    0.122279     0.106195    -0.12501    -0.0399764    -0.0207294    -0.0431397   -0.0436943    -0.00681302   0.0698326    0.0769008   -0.0917851   -0.0410806  -0.0563436    0.0652534   -0.00115223   0.0785704    0.0736536   -0.155947     0.253754    -0.0645649    -0.00635561  -0.0679921   -0.0400315   -0.041585
 -0.177587    0.0918179    0.0235868    0.0321196   -0.110166   -0.0809154     0.213618      0.100685    -0.000655787   0.0151281   -0.115548    -0.190317    -0.0440433   -0.0447098   0.210971     0.0574982   -0.226966     0.132719     0.191842     0.0212412   -0.0902663    0.00310001    0.173857    -0.0636307   -0.0893031    0.0962649
  1.32046     0.0967741   -0.00851047  -0.131774     0.534087   -0.108904      0.17564       0.0718878   -0.0969824     0.0176852    0.304292    -0.189642    -0.0441499   -0.0545183   0.368944    -0.0137573    0.092861     0.127386     0.179409     0.0434218   -0.12541     -0.0961673     0.171733    -0.0662755   -0.0419496   -0.187835
  0.0110285  -0.0690051    0.06706     -0.181642     0.0563524  -0.0289726     0.00320208    0.0410568   -0.0540186    -0.0188934   -0.0759263    0.144338    -0.0150868   -0.150299   -0.0309595    0.0444445    0.00914763   0.120601    -0.240772     0.0367718   -0.0360269   -0.104136      0.0434622   -0.0769353   -0.197498     0.0249637
  0.123594   -0.00760811  -0.107191    -0.0792945    0.119721   -0.0576265     0.00923302   -0.0818349   -0.0163284     0.134539    -0.0784566    0.00567656   0.127927    -0.0493154   0.0490924   -0.0656727    0.0133052    0.0577733    0.108388     0.00380146   0.036875    -0.0318784    -0.0230726    0.0473653   -0.0481023   -0.0316437
  0.163439   -0.0742495    0.066127    -0.0971808   -0.283025   -0.0954204    -0.0401471    -0.125099     0.0401895     0.0702928   -0.148427     0.0862955    0.040187     0.201697    0.0661767    0.0947409    0.0196181    0.0120812    0.0549826    0.133251     0.044569    -0.107642     -0.00815412   0.158472     0.0982274   -0.0161334
  0.275049   -0.0329744    0.108052     0.0944159    0.0902194  -0.142623     -0.0601532     0.0475101   -0.101721      0.0446869   -0.132642    -0.110569     0.103175     0.0259226   0.104275     0.0212212    0.0417967   -0.120843    -0.068201     0.110942    -0.0170184    0.0673474     0.0470927   -0.181386     0.11549      0.029566
  0.0446077   0.165046     0.058933    -0.073307    -0.304007   -0.107719      0.0407716     0.181363    -0.0644305     0.380435     0.106278     0.0347312   -0.0459695    0.075498    0.163801    -0.0886079   -0.0658418    0.0414109   -0.0619191    0.0626262   -0.112712     0.0557207     0.122355    -0.429547     0.102467    -0.0122953
 -0.0544865   0.167121     0.0429918   -0.0796643    0.212956   -0.0171219     0.0628231     0.0777972    0.0539121    -0.0717009   -0.0773653    0.22808     -0.0434187    0.0342334   0.207191    -0.153804     0.138396     0.0787012   -0.0474812   -0.0892938   -0.120599     0.00900887    0.121761     0.23325      0.223779     0.0266095
  0.0262541  -0.0285114   -0.0150626   -0.242617    -0.105785    0.089013     -0.0269434     0.0108112    0.00928313    0.203802    -0.00951538   0.120303    -0.0492411   -0.0686179   0.0280093   -0.0657783   -0.0596705   -0.0788791   -0.0165787    0.20242      0.026329    -0.01166      -0.0189301   -0.0400387    0.0688525    0.0108345
 -0.0510602   0.135733     0.0201602    0.0400686    0.160505    0.0132019    -0.0744362    -0.109779     0.0876875     0.02307      0.00823307   0.0512579   -0.0154972   -0.0851518  -0.100255     0.073812     0.0844643   -0.142344    -0.0593076   -0.110065     0.0126841    0.000631139   0.0826643    0.0717471    0.0982211   -0.0772102
 -0.0331228   0.0500962   -0.0251677    0.0858645    0.0243922   0.0419591     0.213835      0.0376641    0.0826718     0.0214646    0.023969     0.165877     0.0166715    0.211468   -0.0642776    0.00537435  -0.0968479    0.00235944   0.00600233   0.114792     0.160248     0.00166185   -0.143533     0.0822942   -0.0866271   -0.0118464
 -0.0183231   0.00235565   0.0765854   -0.100871    -0.159886    0.0370477     0.0188835     0.00790624   0.00535583   -0.100853     0.140871     0.049761    -0.0487409   -0.123729   -0.0584806   -0.0528756    0.0559824    0.0347274   -0.0619643   -0.139685     0.0861883   -0.10254       0.154141     0.0930703   -0.16067     -0.185069
 -0.123493   -0.0765428   -0.0530019   -0.0256104   -0.257697    0.240057     -0.00689735   -0.0348405   -0.136235     -0.0880994   -0.0223863    0.00596001   0.0420515    0.0294405  -0.0511418   -0.0924665    0.137374     0.297958     0.0865331   -0.0503022   -0.0935833   -0.103575     -0.174483     0.0184118   -0.0737291   -0.114235
 -0.101417    0.0533721    0.0379489   -0.126524     0.0766925   0.0384134    -0.0670429     0.301913     0.0623368     0.0475178   -0.177577     0.0223646   -0.0347285   -0.0845105   0.0104061    0.0437634   -0.0513482   -0.197302     0.0213157   -0.046218     0.204547    -0.158709      0.0682512   -0.0744683   -0.060216    -0.107227[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     17
│     19
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.144023
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.119739
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      7
│      8
│     17
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.119225
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.127997
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     17
│     19
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.125558
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      7
│      8
│      9
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.107288
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     17
│     19
│     20
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.135274
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.123492
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.120340
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      7
│      8
│      9
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.125624
┌ Info: EM with 100000 data points 10 iterations avll -1.125624
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.833808e+05
      1       7.486389e+05      -2.347419e+05 |       32
      2       7.182479e+05      -3.039093e+04 |       32
      3       6.997723e+05      -1.847568e+04 |       32
      4       6.880358e+05      -1.173645e+04 |       32
      5       6.812877e+05      -6.748081e+03 |       32
      6       6.773760e+05      -3.911691e+03 |       32
      7       6.744225e+05      -2.953564e+03 |       32
      8       6.719536e+05      -2.468895e+03 |       32
      9       6.700985e+05      -1.855112e+03 |       32
     10       6.687886e+05      -1.309821e+03 |       32
     11       6.680738e+05      -7.148280e+02 |       32
     12       6.675980e+05      -4.757715e+02 |       32
     13       6.672260e+05      -3.720771e+02 |       32
     14       6.669466e+05      -2.793610e+02 |       32
     15       6.667208e+05      -2.257747e+02 |       32
     16       6.665642e+05      -1.565978e+02 |       32
     17       6.664373e+05      -1.269092e+02 |       32
     18       6.663240e+05      -1.133020e+02 |       32
     19       6.662213e+05      -1.026815e+02 |       32
     20       6.661242e+05      -9.712140e+01 |       32
     21       6.660105e+05      -1.137054e+02 |       32
     22       6.658802e+05      -1.303677e+02 |       32
     23       6.657439e+05      -1.362640e+02 |       32
     24       6.656422e+05      -1.016704e+02 |       32
     25       6.655559e+05      -8.634484e+01 |       32
     26       6.654743e+05      -8.159297e+01 |       32
     27       6.654116e+05      -6.272353e+01 |       32
     28       6.653628e+05      -4.874802e+01 |       32
     29       6.653350e+05      -2.779051e+01 |       31
     30       6.653105e+05      -2.452512e+01 |       31
     31       6.652926e+05      -1.786905e+01 |       26
     32       6.652843e+05      -8.354094e+00 |       27
     33       6.652760e+05      -8.288536e+00 |       28
     34       6.652693e+05      -6.676032e+00 |       28
     35       6.652607e+05      -8.585405e+00 |       29
     36       6.652533e+05      -7.435393e+00 |       28
     37       6.652453e+05      -8.001023e+00 |       29
     38       6.652368e+05      -8.467435e+00 |       27
     39       6.652247e+05      -1.210470e+01 |       25
     40       6.652093e+05      -1.539526e+01 |       26
     41       6.651934e+05      -1.594384e+01 |       26
     42       6.651777e+05      -1.571075e+01 |       27
     43       6.651659e+05      -1.176218e+01 |       27
     44       6.651575e+05      -8.357497e+00 |       23
     45       6.651520e+05      -5.572827e+00 |       23
     46       6.651458e+05      -6.134707e+00 |       27
     47       6.651420e+05      -3.789804e+00 |       21
     48       6.651400e+05      -2.006990e+00 |       18
     49       6.651382e+05      -1.789264e+00 |       12
     50       6.651374e+05      -8.746910e-01 |       14
K-means terminated without convergence after 50 iterations (objv = 665137.372096263)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.372236
[ Info: iteration 2, average log likelihood -1.341937
[ Info: iteration 3, average log likelihood -1.309264
[ Info: iteration 4, average log likelihood -1.276625
[ Info: iteration 5, average log likelihood -1.244040
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.197921
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     18
│     19
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.154081
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.185410
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.161485
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.160488
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     19
│     23
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.136641
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.184010
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.157980
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.130465
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     19
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.117741
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.173898
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.163655
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.153830
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     18
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.124614
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.157775
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.156337
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.152578
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.132895
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.152089
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.138910
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.130100
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     18
│     19
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.140222
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.172042
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.140554
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     24
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.125539
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     18
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.136167
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.172829
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.155596
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.127220
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     19
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.123581
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.174483
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.159910
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.143861
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     18
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.124966
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     24
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.158096
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.141721
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.143855
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.131511
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.152321
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     24
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.128313
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.152308
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.168790
[ Info: iteration 48, average log likelihood -1.157573
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     14
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.114636
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.146136
┌ Info: EM with 100000 data points 50 iterations avll -1.146136
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0308076     0.0517111   -0.0221759    0.0854892     0.0230178    0.0385067     0.209149      0.0423092     0.0837651     0.0211298    0.0232066    0.168552     0.0123013     0.209816     -0.063588     0.00170306  -0.110656     0.0128771    0.0094843    0.113346    0.159352     -0.00389201  -0.142918     0.0808178   -0.0873344   -0.0132168
  0.0328148    -0.0527805    0.102298     0.058881      0.241204     0.0343731    -0.0364685    -0.0543434     0.114887      0.0648044   -0.144791    -0.122939    -0.013435     -0.0230939     0.01438     -0.145165    -0.0539007    0.100429     0.0822905   -0.0121686   0.0664774    -0.0696123   -0.0454772   -0.104012     0.0346285    0.0502702
 -0.0197171    -0.0506342    0.0745254    0.000334917  -0.0409664   -0.12958      -0.141673     -0.0785562    -0.148296     -0.022887     0.0820783    0.123217    -0.117222     -0.125491      0.0159291    0.0357129   -0.0795785   -0.0180032   -0.173189     0.0651638   0.0727178     0.0692341    0.122073    -0.130814     0.0602033    0.00552844
 -0.156783      0.0146477   -0.203365     0.193763      0.0349706    0.150214     -0.10158      -0.106127      0.0715518     0.0301705    0.0915677    0.179005     0.00485221    0.0557622     0.0223326    0.172819     0.0410072    0.0696344   -0.116596     0.076958   -0.133083     -0.0440105   -0.0878246    0.179296    -0.00577352  -0.0969494
 -0.0313578     0.0116526    0.056329     0.10573      -0.107694     0.00819412   -0.0612131    -0.0524618    -0.112065     -0.133469     0.0389851    0.136762    -0.037072     -0.27232       0.0659818    0.112837     0.0111514   -0.197347    -0.00676225  -0.0704863  -0.215886     -0.100572    -0.0863445   -0.129309     0.00647285  -0.111529
 -0.0621978    -0.0579467   -0.0446773   -0.0233896    -0.144657     0.143761      0.0415436     0.0278602    -0.0376261    -0.0434146    0.0749398    0.0318535    0.000208252  -0.0601256    -0.0559668   -0.0271281    0.140946     0.130187    -0.0351013   -0.0499442  -0.0381484    -0.00615938  -0.0294955    0.0567143   -0.0646828   -0.099498
 -0.0521702     0.153429     0.0638841   -0.0397463     0.151962     0.0206192    -0.0843827    -0.181587      0.0757287     0.0471848    0.0269756    0.00841744  -0.027493     -0.0628996    -0.131061     0.0596043    0.100752    -0.142791    -0.0776252   -0.122708   -0.00791526   -0.0198408    0.0763476    0.106614     0.0315445   -0.0621276
  0.155658     -0.0275038   -0.0671208    0.0546758     0.198507    -0.133581     -0.0121805    -0.0849333    -0.0755026     0.22901     -0.0749209    0.0864088    0.155312      0.0816438    -0.0635633   -0.0773405   -0.00786668   0.137967     0.123767    -0.0497065   0.137378     -0.0243118   -0.0203427    0.0279525    0.0590818   -0.111007
 -0.0174227     0.128823     0.0726526   -0.106931      0.00237584   0.172079     -0.0201003    -0.0870548    -0.00862492    0.0536189   -0.020328    -0.0214635   -0.0224927    -0.328987     -0.133549    -0.0334064   -0.0448318   -0.165391    -0.00973408   0.208379    0.027439      0.165951    -0.148784    -0.0522076    0.256066    -0.163993
 -0.206718      0.0353515    0.00834126  -0.599573      0.108439     0.115013     -0.479812      0.0159487    -0.128337     -0.0183934    0.0779894    0.0379158    0.0443537     0.114594     -0.0493541   -0.012371     0.0499888   -0.058956    -0.0263565   -0.0314381   0.00920101    0.185849     0.0295035   -0.164362     0.204214    -0.0350696
  0.140729     -0.00911715   0.0559858    0.158002     -0.0312746    0.158799     -0.135706     -0.171002      0.123218      0.134915     0.142492    -0.0681299   -0.0319389     0.0736411    -0.0756727    0.207724     0.0990977   -0.135671     0.136052    -0.158764   -0.186743      0.0273983    0.157955    -0.177498     0.257835    -0.128745
 -0.0121026     0.0346068    0.018811    -0.191597      0.0238512   -0.00181593    0.10423       0.0119745     0.0684306     0.0793541   -0.116665    -0.057155     0.0452116     0.0748596    -0.198979     0.0762763    0.0491975    0.00110251  -0.0326069   -0.0626101   0.203003     -0.110307    -0.0310077   -0.0441103    0.0469213    0.0240906
  0.270622     -0.0329442    0.106795     0.0929956     0.0845951   -0.140967     -0.0565026     0.0426931    -0.0995668     0.0455562   -0.122559    -0.103498     0.0962614     0.021652      0.0964579    0.0188848    0.0509176   -0.120439    -0.0613966    0.107231   -0.0132237     0.0625746    0.0443927   -0.179961     0.116477     0.0269045
 -0.0449632     0.214545    -0.0198322    0.0865475     0.162549     0.037073     -0.0505768     0.0393022     0.000664267  -0.0343218   -0.0188341    0.0914736    0.0749524     0.000277378   0.127576    -0.061768    -0.084556    -0.0471887    0.122879    -0.0658768   0.0125022     0.0286836    0.0210748    0.152474     0.0773401   -0.0391955
 -0.189541      0.131195    -0.0139452    0.10703      -0.230759    -0.0951426    -0.000251683  -0.12327       0.150926      0.0666656    0.194253    -0.129957    -0.0653929     0.142794      0.137779    -0.0132415   -0.0433008   -0.0324044   -0.0429472   -0.09987    -0.0518522    -0.0532499    0.132242     0.138459    -0.0825933   -0.100117
  0.106325      0.0326302   -0.141517    -0.245188      0.0296963    0.0235112    -0.00195644   -0.0726186     0.0390678     0.0299748   -0.0874032   -0.0676944    0.0897692    -0.180983      0.177988    -0.0610612    0.0151331   -0.0257668    0.13907      0.0468161  -0.0604384    -0.056477    -0.00770956   0.0563488   -0.180931     0.0422757
  0.125788      0.0254425   -0.00178334  -0.00444365    0.111119     0.121034      0.0138587     0.115976     -0.00649312    0.115381     0.0101862    0.0337408   -0.164175      0.121632      0.0195634   -0.012469    -0.00755945   0.0635461   -0.0710618   -0.0172037   0.0640313     0.0150796    0.00841432  -0.131355    -0.0811832    0.0847429
 -0.0640103    -0.0308798   -0.0521245    0.0370423     0.0896227   -0.0665273    -0.0894571     0.117293      0.0533495    -0.0291295    0.187438     0.0173075   -0.0493569    -0.2266        0.0498447    0.179897     0.0188489   -0.023987    -0.0935497    0.0708526   0.033661      0.034686     0.127526    -0.0384621   -0.0356611   -0.00328423
 -0.00445915   -0.122561    -0.138234     0.064283      0.149394     0.0614023    -0.0910823     0.152709     -0.0994504     0.0375249    0.0922552    0.0122197   -0.0755869     0.273713     -0.054896    -0.0171534   -0.0116018   -0.0444321   -0.136353    -0.0734003   0.0799424     0.0266509    0.133531     0.210975     0.0756989    0.0023618
 -0.112891      0.0893662    0.00178917   0.109384      0.120453    -0.000380564   0.218666      0.0868436    -0.00224664   -0.0195825    0.083823     0.0881514    0.0513595     0.122597     -0.0622944   -0.113433     0.0528303   -0.124896    -0.136935    -0.171196    0.135029     -0.0743417   -4.87165e-5  -0.191055     0.0501534    0.00112676
  0.0837241    -0.121945     0.0931787    0.196484      0.252062     0.149082     -0.150848     -0.251025      0.183158      0.503846     0.180837    -0.0123464   -0.363766      0.135718      0.205203     0.213708     0.0958046   -0.1759       0.0855717   -0.121809   -0.230509     -0.618833     0.162722    -0.0922441    0.328033     0.0514553
 -0.153963      0.0595442   -0.0943562   -0.0703175    -0.187933     0.0389312    -0.0923951    -0.109194      0.0695413     0.00225336  -0.0856551    0.118046     0.0964999    -0.030326      0.00906956  -0.0735986   -0.00936817   0.142979     0.104657    -0.0548197  -0.0114446     0.072183    -0.00882992  -0.00656957   0.0971155    0.0658862
  0.0421581     0.117577     0.0555672   -0.0480253    -0.0945272    0.068778     -0.0258554    -0.0224708     0.0182486     0.096466     0.0948524   -0.046128     0.0793129     0.0242906     0.097226    -0.177005     0.188777    -0.193559    -0.0879159    0.0325808   0.101311      0.0324387    0.037104    -0.00778648  -0.0128419    0.00896502
  0.000534998   0.167155     0.056721    -0.0765939    -0.0546739   -0.0627627     0.0557748     0.136738     -0.0131404     0.158458     0.020585     0.133359    -0.0431498     0.0590727     0.189991    -0.131483     0.0279262    0.0571872   -0.0573417   -0.0105581  -0.118377      0.0359334    0.121632    -0.109971     0.167931     0.00474333
 -0.068609      0.0871608   -0.0438439    0.266642      0.117032     0.0258825    -0.0513915     0.0901307     0.101075     -0.046357    -0.0124719    0.14537     -0.0440793    -0.133233     -0.0165741    0.103665     0.0158519   -0.0857402   -0.00709176  -0.0672324   0.0666491     0.0594845    0.0940063   -0.0455091    0.283892    -0.125472
 -0.0142976     0.15003      0.0363315    0.0710452    -0.107622     0.0789093    -0.0678629     0.000179024   0.0422238    -0.0267247    0.115398    -0.0589789   -0.223451     -0.199904      0.0141553    0.0457486   -0.026106     0.0369584   -0.134246     0.103835    0.000938597   0.0907284    0.0543524   -0.0741569    0.0111171    0.0126123
  0.153362     -0.0772941    0.0735061   -0.103655     -0.269074    -0.0875569    -0.0379911    -0.116951      0.0387606     0.0699058   -0.144867     0.0891037    0.0372695     0.182621      0.0627675    0.0929507    0.0259027    0.0184842    0.0111435    0.127978    0.0426534    -0.115339    -0.00331113   0.151447     0.0942861   -0.0160279
  0.0471204     0.0944574    0.0219332    0.00767885   -0.0161546   -0.0911863     0.210347      0.098388     -0.0169279     0.0153284   -0.0552942   -0.191443    -0.0438328    -0.046067      0.235792     0.0447984   -0.192632     0.131851     0.196305     0.022452   -0.0933602    -0.0118374    0.173989    -0.0643255   -0.0861083    0.0582096
  0.0269556    -0.0271955   -0.0164744   -0.243259     -0.105813     0.089432     -0.0272254     0.0104607     0.00829577    0.195834    -0.00988228   0.118972    -0.0497215    -0.0691575     0.0273808   -0.0651853   -0.0680844   -0.0738705   -0.00763059   0.202288    0.0265517    -0.0173386   -0.0196301   -0.0413628    0.0666381    0.0108155
  0.00466888   -0.0654382    0.102189    -0.202205      0.0399285   -0.0159142     0.017962      0.016809     -0.0637176    -0.0635927   -0.0577691    0.127105    -0.0313731    -0.147764     -0.0564484    0.0450173    0.005807     0.0884462   -0.444436     0.0721973  -0.0590932    -0.0701798    0.0696171   -0.0768081   -0.325206     0.0212763
 -0.10417       0.0526917    0.039945    -0.125513      0.075854     0.0394128    -0.066685      0.30127       0.0623763     0.0462031   -0.176337     0.0207654   -0.035362     -0.0817231     0.00978261   0.0446053   -0.0496047   -0.197312     0.0212699   -0.0445095   0.203181     -0.158078     0.0659032   -0.0758872   -0.0604024   -0.107804
  0.111652      0.0185563    0.144563     0.133641     -0.11842     -0.0407468    -0.0248545    -0.0306865    -0.037684     -0.0102636    0.0416537    0.11008     -0.0932912    -0.0503229    -0.0521722    0.0589983    0.0310595    0.121457     0.224608    -0.253068    0.320789     -0.0555357    0.0126898   -0.0610175   -0.0918568   -0.0473632[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.157712
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.117510
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     18
│     24
│     26
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.080409
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     14
│     18
│     19
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.109148
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.126546
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     18
│     23
│     24
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.102415
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     19
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.094661
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.118946
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     18
│     24
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.113010
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     18
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.112102
┌ Info: EM with 100000 data points 10 iterations avll -1.112102
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.119285     -0.110975    -0.236129    -0.0568462    -0.0371599   -0.113387   -0.0676024   -0.0378231    0.0604335   -0.0241468   -0.0766216   0.0833464    0.0619127    0.0182148     0.150372   -0.0170989   -0.109586     0.0226104    0.00572209  -0.0497579   -0.154261    -0.00435116  -0.0117406   -0.130614     0.134462     0.0167059
  0.0355571    -0.0116651    0.00215858  -0.111424      0.0233266   -0.135912   -0.00857271  -0.0204531    0.065074    -0.0712134    0.078666   -0.116415     0.193349    -0.0204109     0.107445   -0.144953     0.0269194   -0.0454762   -0.0827899    0.0437868    0.0471278   -0.0310108    0.0520092    0.22547     -0.030513     0.0445329
 -0.161629     -0.12111     -0.0258702    0.172184     -0.0451354   -0.0292271  -0.186957     0.052043    -0.0466368   -0.00197418  -0.0640929   0.0120638   -0.149929     0.266857     -0.0457215  -0.0545798    0.0215645    0.0313673    0.00453731  -0.150286    -0.0134802   -0.0206295   -0.0445949    0.110345    -0.100439     0.0893763
  0.0818117     0.00992146  -0.0762354   -0.0472493     0.147474    -0.0547653   0.169163    -0.100762    -0.022653     0.0703325    0.0668754   0.122644     0.284557     0.0961922    -0.0599481   0.0121123   -0.0360981    0.0813398   -0.101915     0.146612    -0.0735372    0.0551535   -0.105655     0.184374     0.175949    -0.0605469
  0.0528382     0.0385157    0.10727      0.000756782  -0.00723989   0.0668678   0.19049     -0.0344659    0.0472337   -0.0208422    0.0669098   0.0848759   -0.0682566   -0.0814301     0.230046    0.0247912    0.0732939    0.143785     0.082001     0.11741     -0.0120914    0.0183827    0.180001     0.0606358   -0.112475    -0.0408294
 -0.0386278    -0.0416538    0.145009     0.0610146    -0.0108301    0.0859954  -0.163369    -0.0183831    0.170752    -0.0114932   -0.03482     0.103271    -0.0720425   -0.0439991    -0.104639    0.183991    -0.109489    -0.048054     0.0898043    0.113195    -0.0603268    0.0442637    0.0708931    0.0274271   -0.00419441   0.0630251
  0.0827977    -0.0929587    0.127857    -0.0220525    -0.00745209   0.143431    0.187258     0.00779206  -0.152707     0.0238037    0.0550522  -0.00291456  -0.0418086   -0.0899542     0.0761669   0.0992846   -0.0299112   -0.0468208    0.0914289    0.0433804    0.0253038    0.0427109   -0.00899732   0.104568    -0.0383801    0.0224709
 -0.000315988   0.115796    -0.0428357    0.03353       0.0452387    0.0457789  -0.0667402   -0.0916222   -0.0706065    0.162539    -0.0524584   0.0052391    0.0728848   -0.0734418    -0.0325005  -0.0645346    0.0221568    0.181389    -0.0523609   -0.0388711   -0.00336069   0.15224     -0.089528    -0.0670771   -0.090803    -0.00542692
  0.0748426     0.0540016   -0.207168     0.0318722     0.0723125    0.0651322  -0.206571     0.193833    -0.137461     0.0879827    0.0688843  -0.0114869    0.116779     0.0114421    -0.0850888   0.0746326    0.023654     0.150217    -0.0136001    0.147275    -0.00602939   0.20591     -0.00643432  -0.119683     0.0325514   -0.139871
 -0.195608     -0.188348    -0.105471     0.0604666    -0.13334      0.0748091   0.0549463   -0.00124518   0.00344937   0.0445264   -0.157261    0.0356802    0.0406592    0.0261543    -0.017128    0.159125    -0.21355      0.0218057    0.035738    -0.0949183   -0.0831475   -0.0680947    0.0551366    0.00636307   0.0608143   -0.0405499
  0.087022      0.0549381    0.0329652    0.0531357     0.0084255   -0.0783798   0.101343     0.0084603    0.0911779    0.0129658    0.0150941   0.041003    -0.135406    -0.0558176    -0.0502452   0.0617566    0.0372361   -0.0814707   -0.211707    -0.113576    -0.146427     0.121923     0.0306851    0.00642823   0.132342     0.103207
  0.140469      0.0309315    0.124507     0.0201897     0.00350055  -0.193797    0.0618778   -0.0205221    0.0370564    0.169123     0.148976    0.0934763    0.0327066    0.0510548    -0.104492   -0.0887187   -0.134678     0.131189     0.0560053    0.148712    -0.137822    -0.303333    -0.00817171  -0.124438     0.0343211    0.050568
  0.0283926    -0.116852     0.111233     0.117349      0.0522271   -0.0354918   0.201797    -0.0607142    0.0259835   -0.0283035    0.0764951  -0.0367352   -0.0968046    0.00170281    0.104879    0.181297    -0.0219964    0.132504    -0.0165425    0.161758    -0.192798     0.0931723   -0.103144    -0.112054     0.00107116  -0.0825107
  0.00860878   -0.129032     0.0381367    0.0329701    -0.112451     0.11816     0.050844     0.0709769   -0.0439627    0.0518168   -0.0288169   0.064657     0.0691441    0.113937      0.013157   -0.017306     0.00895     -0.0938944   -0.0513288   -0.0655521   -0.04129     -0.0644394    0.0548813    0.0706268   -0.0457113   -0.0589407
  0.0160687     0.0304637    0.0223587    0.0705564    -0.0811885   -0.10001    -0.0590374    0.139234     0.0247278   -0.0794919    0.0301813  -0.150791     0.132184     0.0594492     0.0392115   0.0374085   -0.0952182   -0.137143     0.0278867    0.0498735   -0.0315848   -0.16068      0.0560343    0.0821586    0.180181     0.0968427
  0.0251029     0.0145585   -0.00738059   0.0125478    -0.0758476    0.106349    0.0993812    0.122289    -0.0347122   -0.0935513    0.0635979   0.0927161   -0.012859    -0.0251822    -0.0469651  -0.152217     0.14651      0.00229958   0.00186926  -0.130406     0.0111814   -0.221052     0.0212507    0.094244     0.0856757    0.0991631
  0.0696514    -0.0782774   -0.126645    -0.200784      0.0490861    0.0520655   0.181742     0.0402489   -0.016016    -0.0201008   -0.118441   -0.120153    -0.00261398   0.0933825     0.0261402   0.0448668   -0.0741409   -0.0249373    0.0504253    0.025586    -0.0181128   -0.110384     0.0101946    0.0419762   -0.131248    -0.0626859
  0.0296564    -0.0127621    0.0411377    0.020263     -0.145025    -0.1246      0.211911     0.127153    -0.0979986    0.112647    -0.14248    -0.204632    -0.0644616   -0.0244       -0.0551446   0.0130959    0.152879     0.118832    -0.0499177    0.0376022   -0.00262824  -0.036782     0.120096    -0.196729    -0.0531114    0.0704568
  0.120847     -0.0119657    0.0132054    0.144305     -0.125377     0.15947    -0.0575598    0.0348639    0.0703324   -0.188272    -0.0730374  -0.0260326    0.032183     0.138291      0.0894544  -0.00415718   0.0884908   -0.113234    -0.073017    -0.033709    -0.0307135   -0.158725     0.0546705   -0.0135947    0.130602     0.189998
 -0.122304      0.0518559   -0.123632     0.0555082    -0.073293    -0.179667   -0.141454    -0.0737943    0.170141     0.133858     0.0850721  -0.0197859   -0.0568016    0.0356292     0.0662237   0.133243    -0.0336373   -0.0679507    0.0752805    0.17524      0.0309681    0.0762174    0.018191     0.00595057   0.158168    -0.147564
  0.00326235   -0.247967    -0.0561044    0.124311      0.245233     0.0631381  -0.037014     0.0326372    0.0612971    0.147211    -0.0824037   0.106719    -0.162459    -0.142671     -0.0788584   0.146391     0.147003     0.0384452   -0.122824    -0.109317    -0.0424076   -0.083241     0.17131     -0.0482379   -0.0916877   -0.0812781
  0.112085     -0.0282274   -0.268336    -0.0128306     0.0734044   -0.0752299   0.00470866   0.110809    -0.0421801    0.0838646   -0.195676   -0.027737     0.00306795   0.0107935    -0.0980269  -0.0893588   -0.0286249   -0.0710433    0.139804     0.00199385   0.0907758    0.0296021    0.0665169    0.00191142   0.103255    -0.00884274
  0.124262      0.277112    -0.0198947    0.0788441     0.0945154   -0.126007    0.179781    -0.0910034   -0.0734612    0.0728874    0.0796699  -0.0564004   -0.0683841    0.0500857     0.194692    0.128043     0.0778566    0.0896079    0.0427144    0.0930394   -0.055521    -0.104798    -0.0491597    0.0238087   -0.0163625    0.0197898
 -0.12075      -0.00750357  -0.0449236   -0.105334     -0.0737086   -0.0641116  -0.0240849    0.0573397   -0.0886197   -0.0382105   -0.0267252  -0.076666     0.0915716   -0.0904076     0.0870037  -0.119371    -0.065458    -0.0980432   -0.0382797    0.109159    -0.130247     0.121368    -0.183822     0.00807502  -0.00252446  -0.00381215
 -0.174232      0.0161024    0.01308     -0.0105746     0.0352953    0.0635409   0.0952885   -0.115348     0.011696    -0.0570248   -0.093873   -0.0621624   -0.156177     0.0418649     0.121679    0.00279296   0.0490524    0.149851    -0.181464    -0.0550451   -0.0768862   -0.0888512   -0.150251     0.0130459    0.039321     0.264003
 -0.163315      0.104833    -0.0249948   -0.0749433     0.00515015   0.0340374  -0.077891    -0.216043    -0.145512    -0.163614     0.0429547  -0.00167956  -0.0904748   -0.22394       0.0514777   0.130003     0.0694978   -0.116952     0.0188982    0.131124     0.0381086   -0.0468597   -0.0117031   -0.098609    -0.112278     0.0333859
  0.132367     -0.136751    -0.0221661   -0.240307     -0.0682726    0.0262158  -0.00367227  -0.114137    -0.0427086    0.0910693    0.0253901  -0.144005    -0.0253582   -0.0400785    -0.0447352   0.0461891    0.0233978   -0.197932    -0.0142882    0.021227     0.115887     0.0220944    0.189401     0.0401868    0.0951867    0.205635
  0.0899817     0.0612587    0.0529274    0.123321     -0.0413064    0.167355    0.0697861   -0.152622    -0.169291    -0.00275953   0.0508116   0.114674     0.14434      0.0376463     0.0893915  -0.0481218    0.0627714    0.0428001    0.15062     -0.167758    -0.023411    -0.0242877   -0.0902557    0.0935945   -0.0218258   -0.0353095
 -0.100103     -0.0562786    0.139527     0.0990393    -0.137901     0.0304716  -0.202443    -0.0161434   -0.0510095   -0.120719     0.134088   -0.10671     -0.156813     0.0936099     0.0581474  -0.149448    -0.0236608   -0.0392967   -0.0018571    0.0740828    0.122544    -0.0777301   -0.0397769    0.202442    -0.0463963    0.117477
  0.0480441    -0.0614701    0.0466908   -0.0144831    -0.0409647   -0.133794   -0.115076    -0.0616282    0.153305    -0.101165     0.259337    0.117955    -0.0629354    0.0999836    -0.0158808   0.00330486  -0.032896     0.0365438   -0.164527    -0.099654     0.0563086   -0.0809392    0.00613563  -0.114639    -0.0229977    0.0973126
 -0.108814      0.0147468   -0.0266302    0.114372     -0.0273636    0.029295   -0.176229     0.029062    -0.0536676   -0.00210968  -0.141554   -0.0772762    0.0691645    0.000677665  -0.311818   -0.0682934    0.00264903  -0.0485978   -0.27567      0.0321586    0.0524218    0.027115    -0.0586618    0.0805726   -0.0177655   -0.113682
  0.000897114  -0.00592887   0.0722762    0.0753455    -0.0447645    0.0521111   0.0026898   -0.0648884    0.0110467    0.0626807    0.0613      0.0494571    0.0301995    0.176784     -0.0368054  -0.0485924    0.0538031    0.183308    -0.0321002    0.035078    -0.131633    -0.101299     0.00338974  -0.055622    -0.0896612    0.0996798kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4173887965830474
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417407
[ Info: iteration 2, average log likelihood -1.417335
[ Info: iteration 3, average log likelihood -1.417283
[ Info: iteration 4, average log likelihood -1.417224
[ Info: iteration 5, average log likelihood -1.417153
[ Info: iteration 6, average log likelihood -1.417068
[ Info: iteration 7, average log likelihood -1.416969
[ Info: iteration 8, average log likelihood -1.416858
[ Info: iteration 9, average log likelihood -1.416724
[ Info: iteration 10, average log likelihood -1.416535
[ Info: iteration 11, average log likelihood -1.416222
[ Info: iteration 12, average log likelihood -1.415686
[ Info: iteration 13, average log likelihood -1.414865
[ Info: iteration 14, average log likelihood -1.413883
[ Info: iteration 15, average log likelihood -1.413036
[ Info: iteration 16, average log likelihood -1.412510
[ Info: iteration 17, average log likelihood -1.412252
[ Info: iteration 18, average log likelihood -1.412138
[ Info: iteration 19, average log likelihood -1.412089
[ Info: iteration 20, average log likelihood -1.412068
[ Info: iteration 21, average log likelihood -1.412059
[ Info: iteration 22, average log likelihood -1.412055
[ Info: iteration 23, average log likelihood -1.412053
[ Info: iteration 24, average log likelihood -1.412052
[ Info: iteration 25, average log likelihood -1.412051
[ Info: iteration 26, average log likelihood -1.412050
[ Info: iteration 27, average log likelihood -1.412050
[ Info: iteration 28, average log likelihood -1.412050
[ Info: iteration 29, average log likelihood -1.412049
[ Info: iteration 30, average log likelihood -1.412049
[ Info: iteration 31, average log likelihood -1.412049
[ Info: iteration 32, average log likelihood -1.412049
[ Info: iteration 33, average log likelihood -1.412049
[ Info: iteration 34, average log likelihood -1.412048
[ Info: iteration 35, average log likelihood -1.412048
[ Info: iteration 36, average log likelihood -1.412048
[ Info: iteration 37, average log likelihood -1.412048
[ Info: iteration 38, average log likelihood -1.412048
[ Info: iteration 39, average log likelihood -1.412048
[ Info: iteration 40, average log likelihood -1.412048
[ Info: iteration 41, average log likelihood -1.412048
[ Info: iteration 42, average log likelihood -1.412048
[ Info: iteration 43, average log likelihood -1.412048
[ Info: iteration 44, average log likelihood -1.412047
[ Info: iteration 45, average log likelihood -1.412047
[ Info: iteration 46, average log likelihood -1.412047
[ Info: iteration 47, average log likelihood -1.412047
[ Info: iteration 48, average log likelihood -1.412047
[ Info: iteration 49, average log likelihood -1.412047
[ Info: iteration 50, average log likelihood -1.412047
┌ Info: EM with 100000 data points 50 iterations avll -1.412047
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4174071519212916
│     -1.417334724690213
│      ⋮
└     -1.4120472542506617
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412065
[ Info: iteration 2, average log likelihood -1.411991
[ Info: iteration 3, average log likelihood -1.411937
[ Info: iteration 4, average log likelihood -1.411876
[ Info: iteration 5, average log likelihood -1.411802
[ Info: iteration 6, average log likelihood -1.411716
[ Info: iteration 7, average log likelihood -1.411623
[ Info: iteration 8, average log likelihood -1.411533
[ Info: iteration 9, average log likelihood -1.411454
[ Info: iteration 10, average log likelihood -1.411391
[ Info: iteration 11, average log likelihood -1.411343
[ Info: iteration 12, average log likelihood -1.411307
[ Info: iteration 13, average log likelihood -1.411278
[ Info: iteration 14, average log likelihood -1.411254
[ Info: iteration 15, average log likelihood -1.411233
[ Info: iteration 16, average log likelihood -1.411213
[ Info: iteration 17, average log likelihood -1.411194
[ Info: iteration 18, average log likelihood -1.411174
[ Info: iteration 19, average log likelihood -1.411154
[ Info: iteration 20, average log likelihood -1.411134
[ Info: iteration 21, average log likelihood -1.411112
[ Info: iteration 22, average log likelihood -1.411091
[ Info: iteration 23, average log likelihood -1.411068
[ Info: iteration 24, average log likelihood -1.411046
[ Info: iteration 25, average log likelihood -1.411024
[ Info: iteration 26, average log likelihood -1.411003
[ Info: iteration 27, average log likelihood -1.410983
[ Info: iteration 28, average log likelihood -1.410964
[ Info: iteration 29, average log likelihood -1.410946
[ Info: iteration 30, average log likelihood -1.410930
[ Info: iteration 31, average log likelihood -1.410915
[ Info: iteration 32, average log likelihood -1.410902
[ Info: iteration 33, average log likelihood -1.410890
[ Info: iteration 34, average log likelihood -1.410879
[ Info: iteration 35, average log likelihood -1.410869
[ Info: iteration 36, average log likelihood -1.410860
[ Info: iteration 37, average log likelihood -1.410852
[ Info: iteration 38, average log likelihood -1.410845
[ Info: iteration 39, average log likelihood -1.410839
[ Info: iteration 40, average log likelihood -1.410833
[ Info: iteration 41, average log likelihood -1.410828
[ Info: iteration 42, average log likelihood -1.410823
[ Info: iteration 43, average log likelihood -1.410818
[ Info: iteration 44, average log likelihood -1.410815
[ Info: iteration 45, average log likelihood -1.410811
[ Info: iteration 46, average log likelihood -1.410808
[ Info: iteration 47, average log likelihood -1.410805
[ Info: iteration 48, average log likelihood -1.410802
[ Info: iteration 49, average log likelihood -1.410800
[ Info: iteration 50, average log likelihood -1.410798
┌ Info: EM with 100000 data points 50 iterations avll -1.410798
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.41206539134636
│     -1.4119908918699131
│      ⋮
└     -1.410797787720238
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410808
[ Info: iteration 2, average log likelihood -1.410743
[ Info: iteration 3, average log likelihood -1.410687
[ Info: iteration 4, average log likelihood -1.410622
[ Info: iteration 5, average log likelihood -1.410540
[ Info: iteration 6, average log likelihood -1.410441
[ Info: iteration 7, average log likelihood -1.410328
[ Info: iteration 8, average log likelihood -1.410211
[ Info: iteration 9, average log likelihood -1.410103
[ Info: iteration 10, average log likelihood -1.410011
[ Info: iteration 11, average log likelihood -1.409936
[ Info: iteration 12, average log likelihood -1.409876
[ Info: iteration 13, average log likelihood -1.409828
[ Info: iteration 14, average log likelihood -1.409789
[ Info: iteration 15, average log likelihood -1.409755
[ Info: iteration 16, average log likelihood -1.409725
[ Info: iteration 17, average log likelihood -1.409698
[ Info: iteration 18, average log likelihood -1.409672
[ Info: iteration 19, average log likelihood -1.409648
[ Info: iteration 20, average log likelihood -1.409624
[ Info: iteration 21, average log likelihood -1.409601
[ Info: iteration 22, average log likelihood -1.409580
[ Info: iteration 23, average log likelihood -1.409558
[ Info: iteration 24, average log likelihood -1.409538
[ Info: iteration 25, average log likelihood -1.409519
[ Info: iteration 26, average log likelihood -1.409500
[ Info: iteration 27, average log likelihood -1.409483
[ Info: iteration 28, average log likelihood -1.409466
[ Info: iteration 29, average log likelihood -1.409449
[ Info: iteration 30, average log likelihood -1.409434
[ Info: iteration 31, average log likelihood -1.409419
[ Info: iteration 32, average log likelihood -1.409404
[ Info: iteration 33, average log likelihood -1.409391
[ Info: iteration 34, average log likelihood -1.409377
[ Info: iteration 35, average log likelihood -1.409365
[ Info: iteration 36, average log likelihood -1.409353
[ Info: iteration 37, average log likelihood -1.409341
[ Info: iteration 38, average log likelihood -1.409330
[ Info: iteration 39, average log likelihood -1.409320
[ Info: iteration 40, average log likelihood -1.409310
[ Info: iteration 41, average log likelihood -1.409300
[ Info: iteration 42, average log likelihood -1.409291
[ Info: iteration 43, average log likelihood -1.409283
[ Info: iteration 44, average log likelihood -1.409275
[ Info: iteration 45, average log likelihood -1.409267
[ Info: iteration 46, average log likelihood -1.409259
[ Info: iteration 47, average log likelihood -1.409252
[ Info: iteration 48, average log likelihood -1.409245
[ Info: iteration 49, average log likelihood -1.409238
[ Info: iteration 50, average log likelihood -1.409231
┌ Info: EM with 100000 data points 50 iterations avll -1.409231
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.410808397711895
│     -1.4107427353118882
│      ⋮
└     -1.4092309771078846
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409235
[ Info: iteration 2, average log likelihood -1.409164
[ Info: iteration 3, average log likelihood -1.409103
[ Info: iteration 4, average log likelihood -1.409038
[ Info: iteration 5, average log likelihood -1.408961
[ Info: iteration 6, average log likelihood -1.408872
[ Info: iteration 7, average log likelihood -1.408772
[ Info: iteration 8, average log likelihood -1.408664
[ Info: iteration 9, average log likelihood -1.408551
[ Info: iteration 10, average log likelihood -1.408439
[ Info: iteration 11, average log likelihood -1.408330
[ Info: iteration 12, average log likelihood -1.408229
[ Info: iteration 13, average log likelihood -1.408136
[ Info: iteration 14, average log likelihood -1.408053
[ Info: iteration 15, average log likelihood -1.407981
[ Info: iteration 16, average log likelihood -1.407920
[ Info: iteration 17, average log likelihood -1.407868
[ Info: iteration 18, average log likelihood -1.407824
[ Info: iteration 19, average log likelihood -1.407787
[ Info: iteration 20, average log likelihood -1.407754
[ Info: iteration 21, average log likelihood -1.407726
[ Info: iteration 22, average log likelihood -1.407700
[ Info: iteration 23, average log likelihood -1.407677
[ Info: iteration 24, average log likelihood -1.407656
[ Info: iteration 25, average log likelihood -1.407636
[ Info: iteration 26, average log likelihood -1.407617
[ Info: iteration 27, average log likelihood -1.407599
[ Info: iteration 28, average log likelihood -1.407582
[ Info: iteration 29, average log likelihood -1.407566
[ Info: iteration 30, average log likelihood -1.407550
[ Info: iteration 31, average log likelihood -1.407535
[ Info: iteration 32, average log likelihood -1.407520
[ Info: iteration 33, average log likelihood -1.407506
[ Info: iteration 34, average log likelihood -1.407492
[ Info: iteration 35, average log likelihood -1.407478
[ Info: iteration 36, average log likelihood -1.407465
[ Info: iteration 37, average log likelihood -1.407453
[ Info: iteration 38, average log likelihood -1.407440
[ Info: iteration 39, average log likelihood -1.407428
[ Info: iteration 40, average log likelihood -1.407417
[ Info: iteration 41, average log likelihood -1.407405
[ Info: iteration 42, average log likelihood -1.407394
[ Info: iteration 43, average log likelihood -1.407383
[ Info: iteration 44, average log likelihood -1.407373
[ Info: iteration 45, average log likelihood -1.407363
[ Info: iteration 46, average log likelihood -1.407352
[ Info: iteration 47, average log likelihood -1.407342
[ Info: iteration 48, average log likelihood -1.407333
[ Info: iteration 49, average log likelihood -1.407323
[ Info: iteration 50, average log likelihood -1.407314
┌ Info: EM with 100000 data points 50 iterations avll -1.407314
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4092345211174089
│     -1.409164013198744
│      ⋮
└     -1.4073136132225388
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407311
[ Info: iteration 2, average log likelihood -1.407239
[ Info: iteration 3, average log likelihood -1.407171
[ Info: iteration 4, average log likelihood -1.407092
[ Info: iteration 5, average log likelihood -1.406992
[ Info: iteration 6, average log likelihood -1.406868
[ Info: iteration 7, average log likelihood -1.406717
[ Info: iteration 8, average log likelihood -1.406542
[ Info: iteration 9, average log likelihood -1.406352
[ Info: iteration 10, average log likelihood -1.406156
[ Info: iteration 11, average log likelihood -1.405966
[ Info: iteration 12, average log likelihood -1.405788
[ Info: iteration 13, average log likelihood -1.405629
[ Info: iteration 14, average log likelihood -1.405488
[ Info: iteration 15, average log likelihood -1.405366
[ Info: iteration 16, average log likelihood -1.405261
[ Info: iteration 17, average log likelihood -1.405171
[ Info: iteration 18, average log likelihood -1.405093
[ Info: iteration 19, average log likelihood -1.405025
[ Info: iteration 20, average log likelihood -1.404964
[ Info: iteration 21, average log likelihood -1.404910
[ Info: iteration 22, average log likelihood -1.404861
[ Info: iteration 23, average log likelihood -1.404816
[ Info: iteration 24, average log likelihood -1.404774
[ Info: iteration 25, average log likelihood -1.404735
[ Info: iteration 26, average log likelihood -1.404699
[ Info: iteration 27, average log likelihood -1.404664
[ Info: iteration 28, average log likelihood -1.404632
[ Info: iteration 29, average log likelihood -1.404601
[ Info: iteration 30, average log likelihood -1.404572
[ Info: iteration 31, average log likelihood -1.404545
[ Info: iteration 32, average log likelihood -1.404519
[ Info: iteration 33, average log likelihood -1.404494
[ Info: iteration 34, average log likelihood -1.404470
[ Info: iteration 35, average log likelihood -1.404448
[ Info: iteration 36, average log likelihood -1.404427
[ Info: iteration 37, average log likelihood -1.404407
[ Info: iteration 38, average log likelihood -1.404389
[ Info: iteration 39, average log likelihood -1.404371
[ Info: iteration 40, average log likelihood -1.404354
[ Info: iteration 41, average log likelihood -1.404338
[ Info: iteration 42, average log likelihood -1.404323
[ Info: iteration 43, average log likelihood -1.404308
[ Info: iteration 44, average log likelihood -1.404294
[ Info: iteration 45, average log likelihood -1.404281
[ Info: iteration 46, average log likelihood -1.404268
[ Info: iteration 47, average log likelihood -1.404256
[ Info: iteration 48, average log likelihood -1.404244
[ Info: iteration 49, average log likelihood -1.404233
[ Info: iteration 50, average log likelihood -1.404222
┌ Info: EM with 100000 data points 50 iterations avll -1.404222
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.407311400812102
│     -1.407239414576421
│      ⋮
└     -1.4042222626601368
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4173887965830474
│     -1.4174071519212916
│     -1.417334724690213
│     -1.417282648263749
│      ⋮
│     -1.4042443177820205
│     -1.4042330809364196
└     -1.4042222626601368
32×26 Array{Float64,2}:
  0.246858    0.0922212   0.198777   -0.859832     0.887864   -0.331048    0.254689   -0.641701   -0.320968   -0.216803    -0.0314349   0.113026   -0.329466     0.0916222    0.675177   -0.357407   -0.240915    0.353202   -0.195766     0.420332    -0.195393    0.171175   -0.163906     0.0948337   0.526616    -0.0448626
  0.223175   -0.0895553   0.897263   -0.084946     0.207622   -0.629859    0.366195   -0.349084   -0.499943   -0.124558     0.304902   -0.450027   -0.46435     -0.31713     -0.259742   -0.378225    0.358218    0.0430835  -0.556295     0.580493     0.870999    0.634901    0.181327     0.397913    0.349915     0.255868
 -0.246129   -0.573322   -0.483001   -0.397614     0.171576    0.428631    0.451297    0.460881   -0.561577    0.761966     0.504322   -0.569746   -0.836115     0.464164     0.177907   -0.0787342   0.157502    0.23217     0.238609    -0.0212656    0.135815    0.0521567   0.389462     0.152011    0.5921       0.382428
 -0.0174954   0.146601    0.47895    -0.0106474    0.525604    0.30606     0.0760903   0.358891   -0.269386    0.388319     0.166563    0.415351   -0.10853      0.717203     0.345599   -0.546168    0.639552    0.131193   -0.13222      0.347998     0.185111   -0.276922    0.111639     0.165806    0.135479    -0.536924
 -0.0717508   0.32523    -0.324866    0.534885    -0.0836066  -0.0762848   0.577486   -0.351491   -0.14743     0.00352753  -0.363954   -0.147377    0.286522     0.218835    -0.016175   -0.400481    0.0576833   0.0974027   0.395961     0.72152     -0.0252587   0.203423   -0.187507    -0.322438   -0.774912     0.0391278
 -0.160777   -0.408325    0.334072    0.417492    -0.866768    0.1892      0.504194   -0.370527   -0.456556    0.328755    -0.064813   -0.21879    -0.303004    -0.0543175    0.188182   -0.752112   -0.430333    0.121083    0.482708     0.477739     0.0695621   0.0135162   0.509606    -0.0710215   0.117342    -0.352821
  0.375394   -0.469569   -0.0723308  -0.0867628   -0.814859   -0.395591    0.0570558  -0.223378   -0.138917    0.0788793    0.209543    0.122319    0.0148107   -0.0980962   -0.242822    0.632969    0.161415    0.183017    0.585202    -0.00623007  -0.541159    0.673988    0.115896    -0.0184926   0.334616    -0.0273365
  0.376101    0.279068   -0.195896   -0.1704      -0.192439   -0.0443086   0.654115    0.0304942  -0.20029    -0.00113997  -0.0624046  -0.279062    0.152267    -0.227273    -0.139321    0.224172    0.172014   -0.288766    0.28338      0.130012     0.176623    0.20051     0.0476829   -0.255565    0.4614      -0.0902476
  0.174487   -0.157193   -0.134858   -0.918375    -0.203037    0.353143    0.456297   -0.110522    0.404682   -0.441799    -0.329889   -0.201777   -0.259198    -0.896454    -0.738581   -0.0102579  -0.461468   -0.145331    0.0923871   -0.334727     0.37274     0.109419    0.0306116    0.488271   -0.192683     0.489333
 -0.290867   -0.595562    0.107157    0.485542    -0.245874    0.072386   -0.137318    0.526103    0.34031     0.13412     -0.322151   -0.741047    0.0980612   -0.00455773  -0.808123   -0.0598584  -0.062914    0.0268237  -0.328928     0.0600978    0.173772    0.398248   -0.0698167    0.519954   -0.436312     0.140226
  0.307058   -0.330698    0.820937    0.181169    -0.469281   -0.0667324  -0.664378   -0.247514    0.135284   -0.225369    -0.287551   -0.183997    0.00451744   0.207408    -0.207463   -0.0421274   0.252327   -0.604155   -0.786226     0.172602     0.516722    0.146474   -0.720744    -0.443601    0.18307     -0.0770656
  0.0216954  -0.697983    0.189513    0.31841     -0.354505    0.199399   -0.460907    0.127353    0.49518    -0.408209     0.666614    0.0228764  -0.0265616    0.174067     0.607936   -0.307755    0.0133182   0.164182   -0.0343874    0.0688828    0.433359    0.0178004  -0.818115     0.374396   -0.00203281   0.377521
  0.195083    0.420026   -0.488345    0.418531    -0.301554    0.31171    -0.57892    -0.568108    0.410254    0.0914378   -0.349391   -1.00898    -0.129386    -0.242849     0.05747     0.344781   -0.238984   -0.208099   -0.364317    -0.330865    -0.32812    -0.297208   -0.0936678   -0.233702   -0.0726719    0.674451
 -0.227069    0.113555   -0.0904745   0.212644    -0.455472   -0.0255367  -0.431448   -0.733306    0.278123    0.00573265  -0.228927    0.712701    0.251739     0.0475082    0.229933    0.302928   -0.16856     0.442615    0.324924    -0.140424    -0.572475   -0.49496     0.125871    -0.041638   -0.254944     0.0608008
 -0.0170557   0.102233   -0.446015    0.0939248    0.825124   -0.25211    -0.374392    0.330734   -0.0827693  -0.279123    -0.245166    0.0258233   0.145487     0.224937     0.0356833   0.14208    -0.203902    0.0736982  -0.676726     0.0152687    0.0414631  -0.227475   -0.177354     0.22136    -0.34429      0.246347
 -0.213833   -0.414201   -0.447337    0.0726685   -0.532241    0.698068    0.180653    1.00409     0.589476   -0.0471395    0.0293708   0.284832    0.468501    -0.10267     -0.336172    0.307081   -0.304794   -0.365979    0.854428    -0.763597    -0.856629   -0.406368    0.320354    -0.346092   -0.582578    -0.0305527
  0.477072   -0.145433   -0.0969929  -0.119207     0.115992    0.116207   -0.349639    0.101161   -0.14682    -0.240146     0.0862619   0.466478   -0.300564    -0.0846212   -0.0550255   0.824695    0.383537    0.163716    0.0595496   -0.429066    -0.0316115  -0.520541   -0.208172     0.35863     0.771636    -0.360935
  0.090836   -0.548868   -0.422116   -0.0272647    0.306568    0.265716   -0.13536     0.261033    0.0225924  -0.163476    -0.132417    0.339808   -0.171099     0.35719     -0.0766884   0.0554972   0.0643897   0.0904826   0.156708    -0.262869    -0.115012   -0.642874   -0.490606     0.383717   -0.107559     0.541805
 -0.0965287   0.0693941  -0.293066    0.00966063  -0.105729    0.1528     -0.167523   -0.634276   -0.0154584  -0.257555     0.196729    0.455544   -0.122358    -0.0377532    0.46412     0.0233312  -0.310822    0.485631    0.342057    -0.175916    -0.128403   -0.44738     0.0328457   -0.251227   -0.175534     0.175882
  0.0126629   0.329291   -0.122725    0.761357    -0.16065     0.191028    0.494611    0.464503   -0.308141   -0.212518     0.178064   -0.136158    0.066773    -0.185524     0.496739    0.295352    0.350876    0.336458    0.431256     0.0558263   -0.0920438  -0.493251    0.00412612  -0.222793    0.0689678   -0.140834
 -0.227746   -0.164247   -0.241699   -0.878235     0.551774    0.244377    0.113614    0.149555   -0.185134    0.0753179   -0.0699382   0.0422787   0.417462    -0.569851    -0.0329722   0.503783    0.0774146   0.535117    0.291767     0.160496    -0.439018    0.227054    0.239634     0.281577   -0.137003    -0.240122
  0.281195    0.421973   -0.372236   -0.548922     0.168472   -0.169866    0.202412    0.141486   -0.219381    0.294284     0.136738    0.497616    0.285289     0.256184     0.233627    0.408978    0.175162   -0.470174    0.687458     0.301841    -0.399412   -0.0584149   0.2334      -0.369915    0.145266    -0.441557
  0.15642     0.0793657  -0.492078    0.0638951    0.0311512  -0.27299     0.209323    0.023024   -0.354012    0.157398    -0.563164    0.0251626   0.254036     0.149012    -0.669797   -0.117373   -0.448649   -0.699785    0.0999116   -0.175588     0.205828    0.233209    0.712115    -0.161919    0.192163    -0.190167
 -0.394765    0.87371    -0.458129   -0.0172964    0.42076     0.0691221   0.875904    0.241887   -0.256837    0.622949    -0.644325   -0.0436674  -0.038394    -0.121828    -0.781456    0.106997    0.107322    0.604818   -0.335448    -0.350805    -0.657349   -0.0957437   0.707249     0.309738    0.0357995   -0.240491
  0.245933   -0.18349     0.0514048  -0.319088    -0.0229159   0.0373011   0.211177   -0.0661092  -0.146748   -0.207826     0.149244   -0.0566885  -0.020704    -0.0555923    0.209402   -0.136796   -0.449933   -0.138292   -0.134886    -0.0512535    0.0490463   0.228954   -0.0365223    0.0919985   0.29689      0.130851
 -0.0558818  -0.0923429  -0.0182631   0.261701    -0.262995   -0.0628406  -0.052281    0.0657245   0.0849556   0.109629     0.0492174  -0.03829     0.0253568    0.0480101   -0.12751     0.06761     0.151383   -0.0802175   0.023265    -0.0342215   -0.0413151  -0.018821    0.10541     -0.0459862  -0.0283605    0.105686
 -0.103282   -0.137332    0.520653   -0.0613805   -0.493817    0.02033    -0.209952   -0.741772    0.359948    0.229928     0.024894    0.064545   -0.169772     0.192107    -0.165353   -0.239499    0.4934      0.552115    0.0579732    0.246232     0.118984    0.273064   -0.126709     0.319325    0.156902    -0.183398
 -0.0710953   0.108698    0.0752113  -0.0325394    0.533314    0.10189    -0.110753    0.0984838  -0.0111579  -0.118202    -0.205998   -0.0826583  -0.031844     0.088068    -0.0402155  -0.0489274   0.197438    0.23356    -0.339297     0.240229     0.129243   -0.0582511  -0.323483     0.276484   -0.0419124   -0.210648
 -0.883883    0.0503391   0.653298   -0.131664     0.0662101   0.157838   -0.736204   -0.166471    0.440839    0.228348     0.32851    -0.242215   -1.03641     -0.251918     0.0155738  -0.418139    0.0518828  -0.47889     0.00177282  -0.284871     0.27494     0.149981    0.0707176   -0.302456   -0.707509     0.557281
 -0.552886    0.430913    0.102559    0.256838     0.0777062  -0.477603   -0.587431   -0.198779    0.495562    0.00122912  -0.265351    0.0039504   0.4023      -0.217725     0.186821   -0.0880222  -0.376486   -0.182327   -0.387437     0.361059    -0.0989971  -0.148778    0.147945    -0.365329   -0.824107    -0.305634
 -0.0455655   0.0683177   0.0341793   0.199336     0.389735   -0.206299   -0.265489    0.624859    0.111238    0.133249     0.35665     0.06114     0.480167    -0.146119     0.252032    0.313102   -0.19768    -0.431925   -0.672512    -0.486783    -0.246447   -0.306834    0.0237671   -0.226002    0.0130952    0.119649
 -0.193495    0.473       0.444557    0.238594    -0.530828   -0.464074    0.183568   -0.104259    0.181236    0.168409     0.618517    0.122013    0.310524     0.14506      0.338212   -0.395511    0.0112204  -0.231566   -0.517614    -0.0457198   -0.155396    0.0978882   0.238785    -0.669171    0.0730426    0.290139[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404212
[ Info: iteration 2, average log likelihood -1.404202
[ Info: iteration 3, average log likelihood -1.404192
[ Info: iteration 4, average log likelihood -1.404183
[ Info: iteration 5, average log likelihood -1.404174
[ Info: iteration 6, average log likelihood -1.404165
[ Info: iteration 7, average log likelihood -1.404156
[ Info: iteration 8, average log likelihood -1.404148
[ Info: iteration 9, average log likelihood -1.404140
[ Info: iteration 10, average log likelihood -1.404132
┌ Info: EM with 100000 data points 10 iterations avll -1.404132
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.220554e+05
      1       7.008663e+05      -2.211891e+05 |       32
      2       6.840653e+05      -1.680100e+04 |       32
      3       6.777673e+05      -6.298012e+03 |       32
      4       6.747216e+05      -3.045706e+03 |       32
      5       6.729034e+05      -1.818199e+03 |       32
      6       6.716558e+05      -1.247545e+03 |       32
      7       6.707894e+05      -8.664022e+02 |       32
      8       6.701646e+05      -6.248195e+02 |       32
      9       6.696497e+05      -5.149063e+02 |       32
     10       6.692148e+05      -4.348678e+02 |       32
     11       6.688360e+05      -3.788569e+02 |       32
     12       6.685263e+05      -3.097086e+02 |       32
     13       6.682758e+05      -2.504963e+02 |       32
     14       6.680440e+05      -2.317316e+02 |       32
     15       6.678311e+05      -2.129100e+02 |       32
     16       6.676251e+05      -2.060522e+02 |       32
     17       6.674290e+05      -1.961052e+02 |       32
     18       6.672293e+05      -1.996692e+02 |       32
     19       6.670389e+05      -1.903942e+02 |       32
     20       6.668605e+05      -1.784119e+02 |       32
     21       6.666835e+05      -1.770322e+02 |       32
     22       6.665268e+05      -1.566958e+02 |       32
     23       6.663789e+05      -1.478731e+02 |       32
     24       6.662252e+05      -1.536946e+02 |       32
     25       6.660902e+05      -1.349985e+02 |       32
     26       6.659713e+05      -1.189522e+02 |       32
     27       6.658528e+05      -1.184708e+02 |       32
     28       6.657341e+05      -1.187116e+02 |       32
     29       6.656228e+05      -1.112735e+02 |       32
     30       6.655165e+05      -1.063128e+02 |       32
     31       6.654162e+05      -1.002799e+02 |       32
     32       6.653170e+05      -9.922226e+01 |       32
     33       6.652258e+05      -9.113626e+01 |       32
     34       6.651407e+05      -8.517759e+01 |       32
     35       6.650568e+05      -8.384120e+01 |       32
     36       6.649739e+05      -8.291406e+01 |       32
     37       6.648983e+05      -7.558933e+01 |       32
     38       6.648323e+05      -6.606701e+01 |       32
     39       6.647595e+05      -7.273519e+01 |       32
     40       6.646873e+05      -7.218345e+01 |       32
     41       6.646155e+05      -7.178931e+01 |       32
     42       6.645448e+05      -7.072251e+01 |       32
     43       6.644733e+05      -7.156430e+01 |       32
     44       6.644073e+05      -6.595037e+01 |       32
     45       6.643471e+05      -6.021609e+01 |       32
     46       6.642873e+05      -5.976832e+01 |       32
     47       6.642263e+05      -6.105395e+01 |       32
     48       6.641712e+05      -5.507243e+01 |       32
     49       6.641148e+05      -5.637505e+01 |       32
     50       6.640545e+05      -6.032141e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 664054.5036633261)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415665
[ Info: iteration 2, average log likelihood -1.410743
[ Info: iteration 3, average log likelihood -1.409437
[ Info: iteration 4, average log likelihood -1.408472
[ Info: iteration 5, average log likelihood -1.407466
[ Info: iteration 6, average log likelihood -1.406545
[ Info: iteration 7, average log likelihood -1.405901
[ Info: iteration 8, average log likelihood -1.405526
[ Info: iteration 9, average log likelihood -1.405305
[ Info: iteration 10, average log likelihood -1.405156
[ Info: iteration 11, average log likelihood -1.405041
[ Info: iteration 12, average log likelihood -1.404947
[ Info: iteration 13, average log likelihood -1.404865
[ Info: iteration 14, average log likelihood -1.404794
[ Info: iteration 15, average log likelihood -1.404732
[ Info: iteration 16, average log likelihood -1.404677
[ Info: iteration 17, average log likelihood -1.404628
[ Info: iteration 18, average log likelihood -1.404585
[ Info: iteration 19, average log likelihood -1.404547
[ Info: iteration 20, average log likelihood -1.404512
[ Info: iteration 21, average log likelihood -1.404481
[ Info: iteration 22, average log likelihood -1.404453
[ Info: iteration 23, average log likelihood -1.404428
[ Info: iteration 24, average log likelihood -1.404404
[ Info: iteration 25, average log likelihood -1.404382
[ Info: iteration 26, average log likelihood -1.404362
[ Info: iteration 27, average log likelihood -1.404343
[ Info: iteration 28, average log likelihood -1.404326
[ Info: iteration 29, average log likelihood -1.404309
[ Info: iteration 30, average log likelihood -1.404293
[ Info: iteration 31, average log likelihood -1.404278
[ Info: iteration 32, average log likelihood -1.404264
[ Info: iteration 33, average log likelihood -1.404250
[ Info: iteration 34, average log likelihood -1.404237
[ Info: iteration 35, average log likelihood -1.404224
[ Info: iteration 36, average log likelihood -1.404211
[ Info: iteration 37, average log likelihood -1.404199
[ Info: iteration 38, average log likelihood -1.404188
[ Info: iteration 39, average log likelihood -1.404176
[ Info: iteration 40, average log likelihood -1.404165
[ Info: iteration 41, average log likelihood -1.404154
[ Info: iteration 42, average log likelihood -1.404144
[ Info: iteration 43, average log likelihood -1.404134
[ Info: iteration 44, average log likelihood -1.404124
[ Info: iteration 45, average log likelihood -1.404114
[ Info: iteration 46, average log likelihood -1.404105
[ Info: iteration 47, average log likelihood -1.404095
[ Info: iteration 48, average log likelihood -1.404087
[ Info: iteration 49, average log likelihood -1.404078
[ Info: iteration 50, average log likelihood -1.404070
┌ Info: EM with 100000 data points 50 iterations avll -1.404070
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.219625     0.296933     0.0239765    0.170049     0.0772921   0.206945     0.327788   -0.0188968   -0.229245    -0.227169     0.531404      0.158411     0.042981   -0.371839     0.617684     0.214727    0.0715835    1.02918      0.429983     0.0388962   -0.374999   -0.439333    0.271425    -0.0312876   -0.0997597   -0.0253034
 -0.287386    -0.428225    -0.327472     0.846306    -0.874674    0.435112     0.143406    0.708965     0.380373     0.0252558    0.382083     -0.176817     0.411405   -0.0606391   -0.24822      0.449092   -0.113952    -0.062222     0.443079    -0.536645    -0.489916   -0.155471    0.158812    -0.149484    -0.371557     0.187363
  0.813678    -0.234291    -0.387906    -0.0788276    0.0519249  -0.281949    -0.0606035   0.0197503   -0.473412    -0.456788     0.198472      0.473788     0.162311    0.187323     0.00369029   0.876777    0.0627438    0.236291     0.169777    -0.106952    -0.232381   -0.263118   -0.149187     0.210537     0.835046    -0.300662
  0.162069     0.157302    -0.582154    -0.0772982    0.551823    0.0219131   -0.214307    0.146781     0.59502     -0.660716     0.0738622     0.0691924    0.0325352   0.0622435    0.381602     0.29594     0.0921487    0.21428     -0.511825    -0.315799     0.317703   -0.0628411  -0.985015     0.261338     0.0104815    0.678615
 -0.0818931    0.0329497    0.0567865   -0.439815     0.0655097  -0.671461    -0.308043   -0.0727995    0.24412      0.397814    -0.111604      0.573491     0.526029   -0.268919    -0.094375     0.666204    0.345331    -0.276203     0.689139     0.579447    -0.66898     0.35358     0.148145    -0.179014    -0.489347    -0.654378
  0.130027     0.036802     0.226873    -0.0582423   -0.196855   -0.19741      0.040542   -0.0410522    0.118621     0.115992     0.191214     -0.206078     0.253509   -0.137345     0.046971     0.0311109  -0.174906    -0.277774    -0.521957    -0.141552    -0.252458    0.230063   -0.012153    -0.223046     0.231331     0.180445
 -0.786454     0.109806     0.541634    -0.00978399  -0.0783001   0.312727    -0.290674    0.00554192   0.736893     0.388504     0.000801125  -0.728168    -0.174859   -0.301281    -0.205001    -0.602356   -0.361957    -0.305741    -0.0947867    0.00171131   0.125974    0.344008    0.351042    -0.0335125   -0.84416      0.553415
  0.0224953   -0.318746     0.0132893    0.171797    -0.677292    0.100003     0.346395   -0.64149     -0.209886     0.20277     -0.28981      -0.0960881   -0.361056    0.142572    -0.030881    -0.380704   -0.0552429    0.521355     0.680176     0.597203    -0.0405074   0.360509    0.0764975    0.173077    -0.00766315  -0.218959
  0.46425     -0.325167    -0.295574     0.110315     0.0447451  -0.118137     0.23889     0.320223     0.00951322   0.274781    -0.529283      0.299983     0.229253    0.639085    -0.392362    -0.610159   -0.521773    -1.01872     -0.131203    -0.0789271    0.0437361  -0.0290528  -0.00477598   0.0912564    0.0384887    0.333006
  0.186557    -0.601062     0.00685888  -1.18872     -0.40885     0.453052     0.173144    0.225717     0.604269    -0.342078    -0.273042     -0.0391153   -0.212875   -0.842137    -0.880172     0.424791   -0.240464    -0.456529     0.26154     -0.733127    -0.032113   -0.0362351  -0.0497265    0.141377     0.0467773    0.379257
 -0.115261     0.254394     0.105946     0.0444357    0.233701   -0.00554995  -0.0261495  -0.154511     0.0331615   -0.0758649   -0.219757      0.0559539    0.121818    0.14673      0.0699564   -0.249367    0.0914372    0.199502    -0.162123     0.349007     0.050757   -0.103225   -0.14649      0.0274317   -0.204297    -0.219562
 -0.276743     0.468716    -0.489216    -0.227686     0.62822     0.280773     0.541452    0.471945    -0.232441     0.35464     -0.735546     -0.135016     0.0377823  -0.00323306  -0.687747     0.252564    0.280933     0.508765    -0.279535    -0.246563    -0.511783   -0.141646    0.273113     0.484287    -0.00558545  -0.0709734
  0.508142     0.600349    -0.334449    -0.540284     0.220511    0.501747     0.467584    0.0952056   -0.407183     0.455093    -0.0816417     0.0984139   -0.0913251   0.0619256    0.356397     0.218102   -0.0740022   -0.410498     0.548327    -0.302324    -0.267787   -0.299924    0.529902    -0.265297     0.501597    -0.525484
 -0.239017    -0.0520459    0.276151     0.735137    -0.0682374  -0.0310733   -0.577395   -0.0345722    0.207538    -0.0205567   -0.26072      -0.297865    -0.545951   -0.188979    -0.313218     0.133385    0.43131     -0.00410307  -0.567868    -0.0935096    0.207198   -0.275052   -0.211617    -0.121808    -0.461206     0.0022927
 -0.0208166    0.471543    -0.702111     0.245708     0.0529551  -0.22836      0.464777   -0.124631    -0.460971     0.0190956   -0.0298762    -0.219765     0.184899    0.137613     0.0851236   -0.0511837  -0.317379    -0.276521     0.423653     0.424878     0.0861326   0.0661199   0.20965     -0.872039    -0.365733    -0.086286
 -0.0362628   -0.385202     0.0547343    0.00844833   0.16645    -0.348628    -0.0901551   0.349306    -0.17411     -0.262652    -0.136816     -0.472258     0.136246    0.0862366   -0.845332    -0.206839    0.141974    -0.175884    -0.277724     0.477087     0.741617    0.571559   -0.323328     0.552273     0.0263419   -0.110149
  0.113341    -0.189491     0.00250515   0.0209253   -0.140109    0.236377     0.11438    -0.0434519   -0.251149    -0.220649     0.0730454    -0.0884775   -0.402225   -0.0403597    0.013053    -0.0676947  -0.109147    -0.123757     0.100661    -0.136264     0.402696    0.0121879   0.035571     0.238987     0.204377     0.213552
 -0.387106     0.202542     0.345631    -0.234673    -0.524323   -0.540375    -0.0359132  -0.605092     0.311692     0.0159724    0.795264      0.547519    -0.0585481   0.211413     0.00805552  -0.0922437   0.308148     0.068162     0.312949    -0.152417    -0.0198393   0.125637    0.163233    -0.451971     0.0121534    0.290822
 -0.0115486   -0.438937     0.444303     0.143406    -0.21648     0.0907102   -0.371401   -0.0277151    0.377783     0.136002     0.100651     -0.104148    -0.0239588   0.107563    -0.144891     0.108347    0.354187     0.284099    -0.189053    -0.0459541   -0.0677941   0.108124   -0.365101     0.417232     0.135585     0.0709597
  0.00322178   0.100397    -0.0740756   -0.0314253    0.0335718  -0.0810932    0.0987423  -0.20301     -0.134102     0.0579535   -0.12785      -0.00965713   0.0414226   0.0954274    0.025703    -0.0235589  -0.120709     0.122812    -0.0908142    0.0567612   -0.0772121  -0.044326    0.210964    -0.00782462   0.0525528    0.0621191
  0.394072     0.19443      0.259804     0.108872    -0.277705    0.137923     0.579069    0.556756     0.0138839    0.0609111    0.663689     -0.278624     0.196511   -0.340306     0.314601     0.342447    1.06268     -0.314534     0.515071     0.583909     0.437787    0.229866   -0.719938    -0.339793     0.358322    -0.39748
 -0.0788314    0.413566     0.50866      0.835773    -0.099412    0.0857065   -0.0440294   0.0416895   -0.270426     0.613429     0.155931      0.0820143    0.117792    0.758811     0.553575    -0.49127     0.638139     0.103053    -0.500697     0.12055     -0.0565846  -0.114954    0.19691     -0.331412     0.30543     -0.091976
 -0.130911     0.292198    -0.160595     0.11549     -0.217243   -0.437157     0.316643   -0.168625    -0.224168     0.234389    -0.490338     -0.174238     0.216625   -0.228052    -0.701869     0.11872    -0.165782    -0.192875    -0.027914    -0.252454     0.0118091   0.31708     1.13746     -0.0145359    0.177359    -0.328923
 -0.0240974   -0.544193     0.0834207   -0.149147     0.373886    0.513098    -0.436301    0.268512     0.0931324    0.0924638    0.25408       0.539731    -0.343612    0.315082     0.38332     -0.131106    0.217701     0.299647     0.15858     -0.0672963   -0.0213479  -0.684883   -0.537019     0.472964    -0.0501145    0.0051428
 -0.319571    -0.702366    -0.362137    -0.328944     0.0662974   0.193565     0.432263    0.506908    -0.574954     0.929685     0.661334     -0.598839    -0.937732    0.416034     0.185878    -0.132888    0.0354248    0.239565     0.172737    -0.0211568    0.172191    0.110712    0.613053     0.113141     0.55243      0.389638
 -0.0469601    0.555224    -0.155172     0.793077    -0.833796   -0.0765079    0.0163933  -0.353717     0.139418    -0.580351    -0.91337       0.501475     0.983587   -0.293817     0.0264124    0.0435499  -0.116551    -0.175374     0.174071    -0.0411103   -0.279577   -0.637087   -0.350342    -0.302151    -0.226811    -0.0116076
 -0.260079     0.00969081  -0.651803    -0.23139      0.0473632   0.274492    -0.58729    -0.789337     0.108143    -0.407497    -0.454863     -0.00236864   0.0329536  -0.296092     0.114375     0.246435   -0.784889     0.477012    -0.00977392  -0.126259    -0.267673   -0.207698    0.0905536    0.201005    -0.311633     0.237796
 -0.26195      0.39821     -0.0738363    0.346849     0.544096   -0.346881    -0.319579    0.553654     0.0241488    0.00660422   0.262109      0.123819     0.567195   -0.15447      0.463699     0.144683   -0.459684    -0.46785     -0.651283    -0.210186    -0.194593   -0.440125    0.325124    -0.378599    -0.384145    -0.100567
  0.242605    -0.00854594   0.653293    -0.728914     0.633211   -0.325831     0.347704   -0.459452    -0.420413    -0.156241     0.104327     -0.0907863   -0.410383   -0.130633     0.228762    -0.449297    0.0892863    0.22235     -0.455071     0.49451      0.267124    0.385857    0.0490584    0.288503     0.453479     0.0370284
  0.0357094   -0.53951      0.565476     0.25104     -0.538092   -0.259561    -0.607092   -0.396712     0.279857    -0.322733     0.44452      -0.0213812   -0.0409606   0.135583     0.567906    -0.443491   -0.390895    -0.375622    -0.461257     0.209827     0.554288    0.165491   -0.508582    -0.400696    -0.120259     0.123166
  0.00559545  -0.213443    -0.3843      -0.150077     0.111423    0.0509193    0.0877125   0.335357    -0.0337143    0.0170112    0.116702      0.21538      0.173322   -0.0277249    0.0558705    0.307599    0.00827453   0.012871     0.327272    -0.0801453   -0.312191   -0.141642    0.110875    -0.0836075   -0.0423739    0.00326969
  0.5872       0.474577    -0.80339      0.439572    -0.279901   -0.133438    -0.551427   -0.146414     0.937569     0.0515646   -0.886078     -0.592689    -0.312998   -0.138688     0.226245     0.345912    0.356609    -0.569488    -0.0978967    0.147476    -0.874492   -0.650878   -0.307596    -0.523479    -0.0528545    1.18382[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404061
[ Info: iteration 2, average log likelihood -1.404053
[ Info: iteration 3, average log likelihood -1.404046
[ Info: iteration 4, average log likelihood -1.404038
[ Info: iteration 5, average log likelihood -1.404031
[ Info: iteration 6, average log likelihood -1.404024
[ Info: iteration 7, average log likelihood -1.404017
[ Info: iteration 8, average log likelihood -1.404011
[ Info: iteration 9, average log likelihood -1.404004
[ Info: iteration 10, average log likelihood -1.403998
┌ Info: EM with 100000 data points 10 iterations avll -1.403998
└ 59.0 data points per parameter
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
