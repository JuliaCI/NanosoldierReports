Julia Version 1.4.0-DEV.662
Commit ce498d65f8 (2019-12-25 11:44 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed SortingAlgorithms ── v0.3.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed Compat ───────────── v2.2.0
 Installed CMake ────────────── v1.1.2
 Installed Arpack ───────────── v0.4.0
 Installed OrderedCollections ─ v1.1.0
 Installed BinaryProvider ───── v0.5.8
 Installed URIParser ────────── v0.4.0
 Installed PDMats ───────────── v0.9.10
 Installed ScikitLearnBase ──── v0.5.0
 Installed BinDeps ──────────── v1.0.0
 Installed FileIO ───────────── v1.2.0
 Installed Rmath ────────────── v0.6.0
 Installed FillArrays ───────── v0.8.2
 Installed Missings ─────────── v0.4.3
 Installed NearestNeighbors ─── v0.4.4
 Installed StatsFuns ────────── v0.9.3
 Installed LegacyStrings ────── v0.4.1
 Installed JLD ──────────────── v0.9.1
 Installed Distances ────────── v0.8.2
 Installed StatsBase ────────── v0.32.0
 Installed Parameters ───────── v0.12.0
 Installed QuadGK ───────────── v2.3.1
 Installed Clustering ───────── v0.13.3
 Installed Distributions ────── v0.21.11
 Installed Blosc ────────────── v0.5.1
 Installed DataAPI ──────────── v1.1.0
 Installed DataStructures ───── v0.17.6
 Installed SpecialFunctions ─── v0.9.0
 Installed StaticArrays ─────── v0.12.1
 Installed HDF5 ─────────────── v0.12.5
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed OpenBLAS_jll ─────── v0.3.7+1
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_MlN9Xv/Project.toml`
 [no changes]
  Updating `/tmp/jl_MlN9Xv/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_TYaQoe/Project.toml`
 [no changes]
  Updating `/tmp/jl_TYaQoe/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_Msacsu/Project.toml`
 [no changes]
  Updating `/tmp/jl_Msacsu/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_7Wmq0w/Project.toml`
 [no changes]
  Updating `/tmp/jl_7Wmq0w/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_w3S8h3/Project.toml`
 [no changes]
  Updating `/tmp/jl_w3S8h3/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_w3S8h3/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.3931631416444858e6, [8796.412927448891, 91203.5870725511], [9911.690822010562 3517.0233055537246 4586.756264505129; -10093.75710898587 -3661.8537467699725 -4653.44196576388], [[12567.969883344467 5117.457849700806 2503.3984103127423; 5117.457849700807 7851.754753388617 1280.9547616652576; 2503.3984103127423 1280.9547616652576 10444.697614782299], [87274.00306929747 -5055.101446466623 -2669.8794161791498; -5055.101446466623 91857.40155575976 -880.4829366513021; -2669.8794161791493 -880.4829366513021 89979.78014654029]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.769235e+03
      1       9.762140e+02      -7.930213e+02 |        6
      2       9.357252e+02      -4.048879e+01 |        2
      3       9.293972e+02      -6.328017e+00 |        2
      4       9.074076e+02      -2.198954e+01 |        2
      5       9.056635e+02      -1.744147e+00 |        0
      6       9.056635e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 905.6634886135116)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.076638
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.865431
[ Info: iteration 2, lowerbound -3.755945
[ Info: iteration 3, lowerbound -3.641256
[ Info: iteration 4, lowerbound -3.510605
[ Info: iteration 5, lowerbound -3.373166
[ Info: iteration 6, lowerbound -3.240042
[ Info: iteration 7, lowerbound -3.123938
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -3.009915
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.895416
[ Info: iteration 10, lowerbound -2.795246
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.704003
[ Info: iteration 12, lowerbound -2.612844
[ Info: iteration 13, lowerbound -2.532676
[ Info: iteration 14, lowerbound -2.467912
[ Info: iteration 15, lowerbound -2.423183
[ Info: dropping number of Gaussions to 3
[ Info: iteration 16, lowerbound -2.383474
[ Info: iteration 17, lowerbound -2.348839
[ Info: iteration 18, lowerbound -2.323868
[ Info: iteration 19, lowerbound -2.309438
[ Info: iteration 20, lowerbound -2.308670
[ Info: dropping number of Gaussions to 2
[ Info: iteration 21, lowerbound -2.302914
[ Info: iteration 22, lowerbound -2.299258
[ Info: iteration 23, lowerbound -2.299255
[ Info: iteration 24, lowerbound -2.299254
[ Info: iteration 25, lowerbound -2.299254
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Dec 27 11:39:54 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Dec 27 11:40:02 2019: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Fri Dec 27 11:40:04 2019: EM with 272 data points 0 iterations avll -2.076638
5.8 data points per parameter
, Fri Dec 27 11:40:06 2019: GMM converted to Variational GMM
, Fri Dec 27 11:40:14 2019: iteration 1, lowerbound -3.865431
, Fri Dec 27 11:40:14 2019: iteration 2, lowerbound -3.755945
, Fri Dec 27 11:40:14 2019: iteration 3, lowerbound -3.641256
, Fri Dec 27 11:40:14 2019: iteration 4, lowerbound -3.510605
, Fri Dec 27 11:40:14 2019: iteration 5, lowerbound -3.373166
, Fri Dec 27 11:40:14 2019: iteration 6, lowerbound -3.240042
, Fri Dec 27 11:40:14 2019: iteration 7, lowerbound -3.123938
, Fri Dec 27 11:40:15 2019: dropping number of Gaussions to 6
, Fri Dec 27 11:40:15 2019: iteration 8, lowerbound -3.009915
, Fri Dec 27 11:40:15 2019: dropping number of Gaussions to 5
, Fri Dec 27 11:40:15 2019: iteration 9, lowerbound -2.895416
, Fri Dec 27 11:40:15 2019: iteration 10, lowerbound -2.795246
, Fri Dec 27 11:40:15 2019: dropping number of Gaussions to 4
, Fri Dec 27 11:40:15 2019: iteration 11, lowerbound -2.704003
, Fri Dec 27 11:40:15 2019: iteration 12, lowerbound -2.612844
, Fri Dec 27 11:40:15 2019: iteration 13, lowerbound -2.532676
, Fri Dec 27 11:40:15 2019: iteration 14, lowerbound -2.467912
, Fri Dec 27 11:40:15 2019: iteration 15, lowerbound -2.423183
, Fri Dec 27 11:40:15 2019: dropping number of Gaussions to 3
, Fri Dec 27 11:40:15 2019: iteration 16, lowerbound -2.383474
, Fri Dec 27 11:40:15 2019: iteration 17, lowerbound -2.348839
, Fri Dec 27 11:40:15 2019: iteration 18, lowerbound -2.323868
, Fri Dec 27 11:40:15 2019: iteration 19, lowerbound -2.309438
, Fri Dec 27 11:40:15 2019: iteration 20, lowerbound -2.308670
, Fri Dec 27 11:40:15 2019: dropping number of Gaussions to 2
, Fri Dec 27 11:40:15 2019: iteration 21, lowerbound -2.302914
, Fri Dec 27 11:40:15 2019: iteration 22, lowerbound -2.299258
, Fri Dec 27 11:40:15 2019: iteration 23, lowerbound -2.299255
, Fri Dec 27 11:40:15 2019: iteration 24, lowerbound -2.299254
, Fri Dec 27 11:40:15 2019: iteration 25, lowerbound -2.299254
, Fri Dec 27 11:40:15 2019: iteration 26, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 27, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 28, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 29, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 30, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 31, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 32, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 33, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 34, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 35, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 36, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 37, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 38, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 39, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 40, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 41, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 42, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 43, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 44, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 45, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 46, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 47, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 48, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 49, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: iteration 50, lowerbound -2.299253
, Fri Dec 27 11:40:15 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601456, 95.95490777398543]
β = [178.04509222601456, 95.95490777398543]
m = [4.250300733269904 79.28686694436176; 2.000229257775364 53.85198717246126]
ν = [180.04509222601456, 97.95490777398543]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484463 -0.007644049042327406; 0.0 0.008581705166333354], [0.37587636119485224 -0.008953123827346173; 0.0 0.012748664777409368]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -1.0071471708351538
avll from llpg:  -1.0071471708351813
avll direct:     -1.0071471708351813
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9609213755119712
avll from llpg:  -0.9609213755119713
avll direct:     -0.9609213755119713
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0518563    0.0156446    0.135033    -0.0237899    0.182417    -0.144684     0.0158267   0.140761     -0.240385     -0.133016     -0.0930343    0.202162     0.0559231     0.0404423   -0.069287    -0.126362     0.0759376     0.0954338    0.118738    -0.0202837    0.0645734   -0.038291      0.416163    -0.0299852     0.220005     0.0788848
  0.136746     0.0799298    0.107763    -0.028132     0.100182    -0.0212063    0.0849771   0.0135711     0.227427      0.0631754    -0.0755066    0.132884     0.00513892    0.118464    -0.108871    -0.0720065   -0.0581098    -0.0238556    0.0288866    0.00365919  -0.037397     0.013005      0.0547217   -0.0230755    -1.26068e-5  -0.174494
 -0.155759    -0.0799709    0.141884    -0.036119     0.246153     0.0704199   -0.102324    0.0253611    -0.0310412    -0.0140707     0.160776    -0.0228672    0.0542802     0.13369      0.171244     0.0314415   -0.0666802     0.0676016    0.0235594    0.166035     0.0293916    0.0170803     0.0716706   -0.0714059    -0.0427209    0.136647
 -0.0506046   -0.00184658   0.0854524    0.116099     0.0270069   -0.104744    -0.0122039   0.189975      0.0534232     0.00616216   -0.0155092   -0.0473774   -0.0623963     0.0973322    0.0425776    0.101993    -0.0355439    -0.0188129   -0.0633438    0.0248028    0.18176     -0.0165833     0.0408644   -0.039713     -0.00774791  -0.0883016
 -0.0384019    0.0469864   -0.0586341    0.122102     0.0425235    0.0416494    0.0137109  -0.07043       0.093399     -0.178241      0.105417    -0.066119     0.187168     -0.00922901   0.0626956    0.00680751  -0.0880141    -0.0624958    0.0245242   -0.266902     0.00174151   0.0309714    -0.0506697   -0.190064      0.0568667    0.147625
 -0.140964    -0.0157515   -0.0494352    0.155991    -0.00901409   0.025031     0.0777487   0.0870014    -0.0365984     0.190184      0.181501     0.0709118    0.0303478    -0.0367435   -0.141206    -0.0367864   -0.193383      0.0279271   -0.113703    -0.0296745   -0.0256168   -0.088065     -0.00860396  -0.0803204    -0.0526658    0.0341431
 -0.259823    -0.0241848   -0.0575367    0.142903    -0.032606    -0.00522526   0.110745   -0.0964611    -0.0991458    -0.000185336  -0.0570212    0.0394925   -0.00823194   -0.149246     0.0250623   -0.00931098  -0.013442      0.088861     0.0211338    0.0552899    0.146733     0.212558     -0.140246    -0.115342     -0.00843976   0.0455447
  0.0617428    0.0275961    0.133321     0.230603    -0.13556     -0.0577497    0.12011     0.122356      0.0208293     0.0317565    -0.0477375   -0.0880351    0.207908      0.163256     0.0763383    0.057476     0.0144976    -0.155809     0.0822218   -0.0603581    0.0818712    0.14123       0.182448    -0.0420836     0.148167    -0.105702
 -0.0522426    0.0185887    0.0416293   -0.0114846   -0.152544    -0.139402     0.0157108  -0.00124786   -0.0607268     0.0291915    -0.117741    -0.0215801   -0.0523499     0.076067     0.0417034    0.122667    -0.0101464    -0.180287    -0.117232     0.237864    -0.0581147   -0.148183      0.0390467   -0.0603678     0.132261     0.151101
  0.0398738   -0.139805    -0.106383     0.13279      0.00149856   0.0513408    0.0797832   0.0887404     0.0733514    -0.0395883    -0.00533229   0.0674595    0.16603       0.0591376    0.0348677   -0.0280611   -0.0996642     0.148655     0.0934193   -0.209146     0.0285814   -0.038868     -0.0228747    0.126662      0.0809857    0.145686
 -0.0773617    0.0933458    0.103373     0.183285     0.0487611    0.0724679   -0.0132277   0.0569716    -0.0672911     0.110875     -0.232704     0.190297    -0.00323173    0.0190434    0.0169359   -0.0195407    0.0267703     0.152573    -0.0409561    0.101838    -0.0727766   -0.0988042     0.0656669   -0.0268317    -0.061289     0.0786181
 -0.0491854    0.0117953    0.00727793   0.0551085   -0.0735613    0.175767     0.0189397   0.0426619     0.0602894     0.0392538    -0.0517356    0.112994    -0.0310991    -0.0562159   -0.0120927    0.115209    -0.0902829     0.0542825    0.135305    -0.0321874   -0.0580775   -0.225681      0.151175     0.15166      -0.154935     0.213627
  0.0175107    0.0527099   -0.192713     0.242144    -0.213621    -0.0835849   -0.0256068  -0.0730375    -0.112435      0.138833     -0.163592    -0.00267967  -0.238845     -0.126586     0.0166988    0.0168792    0.0555985     0.0219347    0.0266511    0.0353441    0.0073835    0.0699543    -0.00696572   0.0765328     0.0342026    0.0513503
 -0.141506    -0.00755431  -0.106771     0.161373    -0.0278732   -0.0490928    0.0200938   0.00386861    0.0740005     0.0561976    -0.196527     0.0571325    0.0316331     0.0533028   -0.0443713   -0.0146963   -0.0954958    -0.0752551   -0.0741426    0.00965202   0.0420881    0.0235068    -0.211371    -0.00431321   -0.0967072   -0.0133216
  0.0188996    0.0544725    0.0394974   -0.174134     0.0151456   -0.0469792   -0.119488    0.153993     -0.000816382   0.000109859  -0.274094    -0.0112438    0.0107838     0.0245522   -0.0704684   -0.054671     0.143492      0.0509568    0.0717755    0.0632913    0.0100783    0.0104654     0.0524743    0.0180537    -0.0133776   -0.11332
  0.126956     0.0464908   -0.060622    -0.0623146    0.153652    -0.131034    -0.0345761  -0.00349088    0.175229     -0.0793249    -0.187413     0.0609051   -0.0347623    -0.0616235   -0.255343     0.260194    -0.000858985  -0.105191     0.0358547    0.0140437    0.0303805   -0.000859646  -0.16527      0.0213179     0.0724172   -0.00724174
 -0.00988264   0.0130313   -0.0793709    0.0668483    0.0574972   -0.175691    -0.128631   -0.142366      0.0560577     0.0778969     0.147392    -0.207315    -0.235557     -0.0491733   -0.0444832    0.0899492   -0.184803     -0.117056     0.0167202   -0.0754563   -0.00771312   0.14547      -0.0587842    0.0941254    -0.0884143   -0.0901184
  0.0431927   -0.0462141   -0.150614     0.274011     0.0561034   -0.0503263   -0.0438307   0.182629     -0.0514141     0.0358529    -0.108329     0.0592195    0.0112135     0.0304829   -0.0826652    0.0485657    0.0898221    -0.0486744    0.0293477    0.0599559    0.0308076    0.0285545     0.196876     0.0662871     0.150934    -0.046296
 -0.0841727   -0.142363     0.0777986    0.0690775   -0.0606548    0.0252805   -0.014379    0.0294961     0.0570952    -0.047495      0.0110121    0.168714    -0.122139     -0.0920672    0.0451437    0.104562    -0.0559182    -0.0820709    0.175665    -0.107109    -0.0368252    0.135454     -0.0948232    0.178181      0.132939    -0.0492038
 -0.0696139   -0.00147621   0.139322    -0.0756155    0.0585766   -0.158707    -0.0334376   0.000881189   0.119098     -0.0257875     0.0698715    0.116367     0.0696189     0.100186     0.0686       0.0305014    0.0620937     0.00339881   0.0369261    0.0946987   -0.214028    -0.0132045    -0.0844176    0.0674433    -0.111236     0.0263889
 -0.151132     0.0885842   -0.146829     0.0778021   -0.00523216   0.104958     0.083687   -0.0214694     0.118782     -0.00197594    0.0748647    0.0598307   -0.121055     -0.0020409   -0.0476257   -0.021217     0.106931      0.0907985    0.0150415   -0.0381028   -0.0230122    0.0697538     0.100841    -0.00566659    0.0171421    0.082649
  0.0488845    0.0662597    0.056905     0.0620247   -0.0225302    0.232418    -0.0775602   0.0522958    -0.0573397    -0.0597179     0.0846286   -0.0456574   -0.1584        0.136405     0.190565     0.0874949    0.015221      0.0451609    0.0311827   -0.0429689   -0.0142196    0.0932082    -0.00963427   0.00582046   -0.00328797  -0.154101
  0.0452947   -0.0506665   -0.094065     0.0221294   -0.156499     0.183408    -0.0265482  -0.120159      0.108662     -0.0401852    -0.10201      0.0949587   -0.000525133  -0.109226    -0.0673663   -0.130097    -0.194276      0.11512      0.0642437    0.194961     0.114855     0.148989     -0.0297253    0.0603787    -0.153296     0.0514804
 -0.0971154   -0.138622    -0.134788    -0.0867682    0.00799505  -0.160169    -0.0149824  -0.0501904    -0.197415      0.0489197     0.0111317   -0.0342058   -0.17918       0.065927    -0.20339      0.0221853    0.109244     -0.116012     0.00356499  -0.196282    -0.0398951   -0.0175183     0.1719      -0.123539      0.0541393   -0.0129457
 -0.0255309   -0.109484    -0.0126048   -0.131324     0.0272105   -0.00266964   0.0828171  -0.03973      -0.0742686     0.0895159    -0.0881864    0.0931575   -0.00298008    0.14366     -0.00813365   0.162938    -0.0291698    -0.229303     0.127673     0.180243     0.03632     -0.19062      -0.120156    -0.0372007    -0.136298     0.173307
 -0.147918     0.0624598   -0.0523137    0.00268888  -0.0494034   -0.0522027   -0.0311964  -0.00322812   -0.281181     -0.0367779    -0.0268908   -0.160838    -0.0282758     0.0374536   -0.11125      0.124065     0.0483913     0.0803964   -0.02254      0.0481839   -0.0800474   -0.0807447    -0.0934564    0.0841207    -0.001596    -0.0342259
 -0.1666      -0.0580317    0.0662135    0.0325798    0.148283    -0.0417329    0.0153539   0.0603905     0.185772     -0.147768      0.0117814    0.0699832   -0.0181849    -0.0864441    0.0425325    0.0287253    0.14629      -0.0243577   -0.0635359    0.272546    -0.0181536    0.152646      0.00492931   0.0553534     0.132454     0.0278337
  0.0729936    0.0096928    0.127312    -0.040717    -0.0248193    0.0777879    0.0970383  -0.00487723    0.0543765    -0.0453423    -0.0453684    0.315757    -0.0590462    -0.0957906   -0.139189     0.153689    -0.0115758     0.138961     0.100446     0.0743083    0.0913108   -0.131587     -0.102633     0.0333583    -0.192499    -0.145461
  0.118386     0.0712652   -0.252146     0.262137    -0.0341113    0.142023     0.112009   -0.00913478    0.00339258    0.0356478    -0.0890219   -0.0199898   -0.130756     -0.0333159   -0.0333871   -0.0791735   -0.0182562     0.0264689   -0.163814     0.144812     0.0314152    0.0534183    -0.0725388   -0.134604      0.0744818   -0.0878614
  0.0974375    0.073196    -0.0422928   -0.0623569    0.12144     -0.0691042    0.0998115   0.0479972    -0.194806      0.0322018    -0.0258257   -0.0069111    0.0520483    -0.121578    -0.221778     0.0722284   -0.14006      -0.0761998   -0.108333    -0.0415395    0.192502    -0.0357903    -0.0600744   -0.183836      0.120815     0.0368082
 -0.00884049   0.0173831   -0.0431791   -0.00797488  -0.0828527   -0.085038     0.091044   -0.0723643     0.0380441    -0.00715921   -0.00107901   0.0568711    0.218688     -0.0376019   -0.0590765    0.171108     0.00298192   -0.0696371   -0.0169779   -0.104567     0.0556092   -0.206268     -0.0224002    0.000172045  -0.0794811    0.0206317
 -0.114353    -0.180514     0.0951947    0.217447    -0.00171796   0.196673     0.0417918  -0.0242315    -0.0712195     0.226712     -0.120302    -0.112712    -0.157976      0.0429097   -0.105018     0.098118    -0.103022      0.0577195    0.0448253    0.0894709    0.128636    -0.0125177     0.067373    -0.0300076     0.0356431    0.111219kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4172031812092027
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417301
[ Info: iteration 2, average log likelihood -1.417235
[ Info: iteration 3, average log likelihood -1.417038
[ Info: iteration 4, average log likelihood -1.414663
[ Info: iteration 5, average log likelihood -1.402366
[ Info: iteration 6, average log likelihood -1.386088
[ Info: iteration 7, average log likelihood -1.381099
[ Info: iteration 8, average log likelihood -1.379476
[ Info: iteration 9, average log likelihood -1.378634
[ Info: iteration 10, average log likelihood -1.377984
[ Info: iteration 11, average log likelihood -1.377377
[ Info: iteration 12, average log likelihood -1.376879
[ Info: iteration 13, average log likelihood -1.376491
[ Info: iteration 14, average log likelihood -1.376155
[ Info: iteration 15, average log likelihood -1.375873
[ Info: iteration 16, average log likelihood -1.375680
[ Info: iteration 17, average log likelihood -1.375571
[ Info: iteration 18, average log likelihood -1.375511
[ Info: iteration 19, average log likelihood -1.375478
[ Info: iteration 20, average log likelihood -1.375460
[ Info: iteration 21, average log likelihood -1.375449
[ Info: iteration 22, average log likelihood -1.375443
[ Info: iteration 23, average log likelihood -1.375439
[ Info: iteration 24, average log likelihood -1.375437
[ Info: iteration 25, average log likelihood -1.375436
[ Info: iteration 26, average log likelihood -1.375435
[ Info: iteration 27, average log likelihood -1.375435
[ Info: iteration 28, average log likelihood -1.375434
[ Info: iteration 29, average log likelihood -1.375434
[ Info: iteration 30, average log likelihood -1.375434
[ Info: iteration 31, average log likelihood -1.375434
[ Info: iteration 32, average log likelihood -1.375434
[ Info: iteration 33, average log likelihood -1.375434
[ Info: iteration 34, average log likelihood -1.375434
[ Info: iteration 35, average log likelihood -1.375434
[ Info: iteration 36, average log likelihood -1.375434
[ Info: iteration 37, average log likelihood -1.375434
[ Info: iteration 38, average log likelihood -1.375434
[ Info: iteration 39, average log likelihood -1.375434
[ Info: iteration 40, average log likelihood -1.375434
[ Info: iteration 41, average log likelihood -1.375434
[ Info: iteration 42, average log likelihood -1.375434
[ Info: iteration 43, average log likelihood -1.375434
[ Info: iteration 44, average log likelihood -1.375434
[ Info: iteration 45, average log likelihood -1.375434
[ Info: iteration 46, average log likelihood -1.375434
[ Info: iteration 47, average log likelihood -1.375434
[ Info: iteration 48, average log likelihood -1.375434
[ Info: iteration 49, average log likelihood -1.375434
[ Info: iteration 50, average log likelihood -1.375434
┌ Info: EM with 100000 data points 50 iterations avll -1.375434
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4173013750007573
│     -1.4172346685747519
│      ⋮
└     -1.3754338174246334
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.375554
[ Info: iteration 2, average log likelihood -1.375438
[ Info: iteration 3, average log likelihood -1.375014
[ Info: iteration 4, average log likelihood -1.371243
[ Info: iteration 5, average log likelihood -1.358620
[ Info: iteration 6, average log likelihood -1.349006
[ Info: iteration 7, average log likelihood -1.346023
[ Info: iteration 8, average log likelihood -1.344296
[ Info: iteration 9, average log likelihood -1.342779
[ Info: iteration 10, average log likelihood -1.341511
[ Info: iteration 11, average log likelihood -1.340432
[ Info: iteration 12, average log likelihood -1.339420
[ Info: iteration 13, average log likelihood -1.338577
[ Info: iteration 14, average log likelihood -1.338015
[ Info: iteration 15, average log likelihood -1.337671
[ Info: iteration 16, average log likelihood -1.337448
[ Info: iteration 17, average log likelihood -1.337290
[ Info: iteration 18, average log likelihood -1.337172
[ Info: iteration 19, average log likelihood -1.337080
[ Info: iteration 20, average log likelihood -1.337004
[ Info: iteration 21, average log likelihood -1.336940
[ Info: iteration 22, average log likelihood -1.336885
[ Info: iteration 23, average log likelihood -1.336838
[ Info: iteration 24, average log likelihood -1.336799
[ Info: iteration 25, average log likelihood -1.336767
[ Info: iteration 26, average log likelihood -1.336742
[ Info: iteration 27, average log likelihood -1.336722
[ Info: iteration 28, average log likelihood -1.336706
[ Info: iteration 29, average log likelihood -1.336694
[ Info: iteration 30, average log likelihood -1.336684
[ Info: iteration 31, average log likelihood -1.336676
[ Info: iteration 32, average log likelihood -1.336670
[ Info: iteration 33, average log likelihood -1.336665
[ Info: iteration 34, average log likelihood -1.336660
[ Info: iteration 35, average log likelihood -1.336656
[ Info: iteration 36, average log likelihood -1.336653
[ Info: iteration 37, average log likelihood -1.336650
[ Info: iteration 38, average log likelihood -1.336647
[ Info: iteration 39, average log likelihood -1.336644
[ Info: iteration 40, average log likelihood -1.336642
[ Info: iteration 41, average log likelihood -1.336639
[ Info: iteration 42, average log likelihood -1.336637
[ Info: iteration 43, average log likelihood -1.336635
[ Info: iteration 44, average log likelihood -1.336633
[ Info: iteration 45, average log likelihood -1.336631
[ Info: iteration 46, average log likelihood -1.336629
[ Info: iteration 47, average log likelihood -1.336628
[ Info: iteration 48, average log likelihood -1.336626
[ Info: iteration 49, average log likelihood -1.336624
[ Info: iteration 50, average log likelihood -1.336623
┌ Info: EM with 100000 data points 50 iterations avll -1.336623
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3755539084478994
│     -1.3754378860154508
│      ⋮
└     -1.336622955865747
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.336800
[ Info: iteration 2, average log likelihood -1.336630
[ Info: iteration 3, average log likelihood -1.336016
[ Info: iteration 4, average log likelihood -1.329738
[ Info: iteration 5, average log likelihood -1.310660
[ Info: iteration 6, average log likelihood -1.296929
[ Info: iteration 7, average log likelihood -1.291568
[ Info: iteration 8, average log likelihood -1.288543
[ Info: iteration 9, average log likelihood -1.286590
[ Info: iteration 10, average log likelihood -1.285528
[ Info: iteration 11, average log likelihood -1.284942
[ Info: iteration 12, average log likelihood -1.284578
[ Info: iteration 13, average log likelihood -1.284318
[ Info: iteration 14, average log likelihood -1.284112
[ Info: iteration 15, average log likelihood -1.283941
[ Info: iteration 16, average log likelihood -1.283795
[ Info: iteration 17, average log likelihood -1.283664
[ Info: iteration 18, average log likelihood -1.283538
[ Info: iteration 19, average log likelihood -1.283393
[ Info: iteration 20, average log likelihood -1.283166
[ Info: iteration 21, average log likelihood -1.282666
[ Info: iteration 22, average log likelihood -1.281905
[ Info: iteration 23, average log likelihood -1.281424
[ Info: iteration 24, average log likelihood -1.281209
[ Info: iteration 25, average log likelihood -1.281094
[ Info: iteration 26, average log likelihood -1.281025
[ Info: iteration 27, average log likelihood -1.280978
[ Info: iteration 28, average log likelihood -1.280942
[ Info: iteration 29, average log likelihood -1.280912
[ Info: iteration 30, average log likelihood -1.280884
[ Info: iteration 31, average log likelihood -1.280856
[ Info: iteration 32, average log likelihood -1.280827
[ Info: iteration 33, average log likelihood -1.280793
[ Info: iteration 34, average log likelihood -1.280755
[ Info: iteration 35, average log likelihood -1.280712
[ Info: iteration 36, average log likelihood -1.280664
[ Info: iteration 37, average log likelihood -1.280615
[ Info: iteration 38, average log likelihood -1.280567
[ Info: iteration 39, average log likelihood -1.280528
[ Info: iteration 40, average log likelihood -1.280501
[ Info: iteration 41, average log likelihood -1.280484
[ Info: iteration 42, average log likelihood -1.280473
[ Info: iteration 43, average log likelihood -1.280465
[ Info: iteration 44, average log likelihood -1.280459
[ Info: iteration 45, average log likelihood -1.280455
[ Info: iteration 46, average log likelihood -1.280451
[ Info: iteration 47, average log likelihood -1.280448
[ Info: iteration 48, average log likelihood -1.280446
[ Info: iteration 49, average log likelihood -1.280443
[ Info: iteration 50, average log likelihood -1.280442
┌ Info: EM with 100000 data points 50 iterations avll -1.280442
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3368004874672907
│     -1.3366303948368226
│      ⋮
└     -1.280441534381113
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.280654
[ Info: iteration 2, average log likelihood -1.280362
[ Info: iteration 3, average log likelihood -1.278754
[ Info: iteration 4, average log likelihood -1.264945
[ Info: iteration 5, average log likelihood -1.230413
[ Info: iteration 6, average log likelihood -1.204734
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.188130
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.184827
[ Info: iteration 9, average log likelihood -1.206579
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.186302
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.185005
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.182365
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.204102
[ Info: iteration 14, average log likelihood -1.196930
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.179816
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.176643
[ Info: iteration 17, average log likelihood -1.212350
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.190880
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.187527
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.181030
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.189900
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.202160
[ Info: iteration 23, average log likelihood -1.194622
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.174032
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.196780
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.192409
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.190971
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.183535
[ Info: iteration 29, average log likelihood -1.202824
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.184447
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.183646
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.192857
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.197334
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.192646
[ Info: iteration 35, average log likelihood -1.188403
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.170567
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.208801
[ Info: iteration 38, average log likelihood -1.199990
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.181552
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.177237
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.199072
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.196361
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.191088
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.183208
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.191113
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.188991
[ Info: iteration 47, average log likelihood -1.200217
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.177772
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.199319
[ Info: iteration 50, average log likelihood -1.193642
┌ Info: EM with 100000 data points 50 iterations avll -1.193642
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.280653718705667
│     -1.2803618293939263
│      ⋮
└     -1.1936416159973646
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.178123
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     17
│     18
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.166743
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.175233
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     18
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.136267
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.106101
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.073401
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      3
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.119994
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     22
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.083897
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     11
│     17
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.080361
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.095822
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.108644
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.052543
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      3
│     17
│     18
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.117187
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     21
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.076739
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     11
│     17
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.090725
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.080320
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.111769
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.064173
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      3
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.108159
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     22
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.079909
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     11
│     17
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.084958
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.091302
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.096612
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.070542
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      3
│     17
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.116550
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.074996
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     11
│     17
│      ⋮
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.089742
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     18
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.087938
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.096631
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.074601
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│     17
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.098552
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.088396
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     11
│     17
│      ⋮
│     22
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.082328
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     18
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.089652
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.106689
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.056044
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      3
│     17
│     18
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.111805
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     18
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.087938
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     11
│     17
│      ⋮
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.076671
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     19
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.085723
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     20
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.101869
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.066584
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│     17
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.096592
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     18
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.090854
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     11
│     17
│      ⋮
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.088179
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.076205
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.105618
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.060768
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      3
│     17
│     18
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.106644
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.075071
┌ Info: EM with 100000 data points 50 iterations avll -1.075071
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1781229335308678
│     -1.1667429020430493
│      ⋮
└     -1.075071276382396
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4172031812092027
│     -1.4173013750007573
│     -1.4172346685747519
│     -1.4170377358419712
│      ⋮
│     -1.0607679331394608
│     -1.1066439787299573
└     -1.075071276382396
32×26 Array{Float64,2}:
 -0.1035       0.0967964    0.105377     0.187743      0.261384     0.101025    -0.0130571   0.0607344   -0.0915207     0.213833    -0.489155    -0.208669      0.0862764    0.0321277    0.154032     -0.0419803    0.0259476    0.148807     0.159809     0.0737698   -0.0700609   -0.727854     0.115766     0.107651    -0.0432829    0.0509915
 -0.034921     0.103925     0.0984593    0.173622     -0.135066     0.0486665   -0.0129119   0.047093    -0.070464      0.0168225   -0.0971226    0.468164     -0.0794833    0.00663887  -0.150574     -0.00444643   0.0369423    0.156983    -0.372666     0.127193    -0.0696781    0.429616    -0.0165022   -0.122326    -0.0692586    0.124269
  0.139964     0.0632086    0.0970404   -0.000221054   0.0933134   -0.0216153    0.0745641   0.0178935    0.215269      0.0613183   -0.0660317    0.135407     -0.00202678   0.153397    -0.115644     -0.0687646   -0.0337006   -0.0345695    0.0276466   -0.033251    -0.0432165    0.0206251    0.053747    -0.0727516    0.0149749   -0.169165
 -0.134327     0.0222162   -0.0581477    0.160157     -0.011585     0.0211788    0.0402279   0.0962353   -0.0659386     0.184603     0.159028     0.0826064     0.0304491   -0.0627229   -0.161624     -0.0298896   -0.188011     0.0275832   -0.115243    -0.0191567   -0.0130723   -0.0672684   -0.00620752  -0.0858606   -0.107221     0.0424768
  0.00993314   0.0505963   -0.071557    -0.0221447     0.0791567   -0.0669574   -0.0444193  -0.00664525  -0.00651745   -0.0509803   -0.115565    -0.0645131    -0.0315164   -0.0161239   -0.186492      0.207429     0.0295745   -0.03683      0.00563732   0.0147705   -0.0171409   -0.0339327   -0.1022       0.0454875    0.050545    -0.0161024
 -0.0410284    0.0494714   -0.0340336    0.105207      0.0446206    0.0169318    0.0419962  -0.0820533    0.0850811    -0.192486     0.0356744   -0.0640169     0.125049    -0.00360891   0.0578517     0.0193476   -0.0925631   -0.0677582    0.0379182   -0.255536    -0.00219901   0.0217046   -0.0529116   -0.143536     0.0458524    0.13772
 -0.148372    -0.00473663  -0.118758     0.189266     -0.0240844   -0.0676994    0.0218612   0.00796529   0.0430366     0.0603091   -0.156373     0.0649481     0.0445739    0.0336715   -0.0422117    -0.00743485  -0.0908351   -0.0936521   -0.094918     0.0120693    0.0466739    0.0221119   -0.195668     0.0141008   -0.0658165   -0.0145304
 -0.010248    -0.063929    -0.127338     0.00637976   -0.155919     0.180887    -0.025805   -0.120588     0.116707     -0.0435408   -0.104316     0.12934      -0.00362372  -0.103959    -0.0683293    -0.139971    -0.193539     0.145244     0.119709     0.139819     0.106105     0.179296     0.00423159   0.0618792   -0.162631     0.0513075
  0.0400561   -0.0986551   -0.130418     0.190597      0.0125761   -0.00786548   0.0112075   0.126822     0.0336613     0.0160137   -0.0839782    0.0659382     0.0950161    0.0453472   -0.0155605     0.0165547   -0.00612832   0.0716571    0.060156    -0.0536495    0.0317682   -0.0174296    0.0797904    0.0991928    0.12354      0.0634274
  0.121657     0.0527651   -0.0410268   -0.0388726     0.112469    -0.0145661    0.102698    0.0329933   -0.212399      0.0367371   -0.0101678   -0.000610874   0.0523762   -0.155484    -0.202887      0.0567513   -0.184642    -0.0745638   -0.10844     -0.0477273    0.190319    -0.0358177   -0.0633057   -0.164296     0.112993     0.0242123
  0.0726168    0.0240058    0.109958    -0.0659341    -0.0439073    0.0603217    0.10269    -0.00162824   0.0844863    -0.0408759   -0.0339664    0.306433     -0.0573663   -0.103865    -0.132578      0.157091    -0.0257431    0.155965     0.109672     0.0774848    0.0766669   -0.114578    -0.0878915    0.0340592   -0.186904    -0.142146
  0.0225129    0.0563001   -0.192453     0.220851     -0.211443    -0.0982522   -0.0177021  -0.0684883   -0.121662      0.17604     -0.146824    -0.0149132    -0.240296    -0.119272     0.0144073     0.0179076    0.0261455   -0.00142583   0.0234776    0.0381341    0.016118     0.0803374    0.010188     0.0296367    0.0232087    0.0625444
  0.0219065    0.0745827    0.0359872   -0.968445      0.0199223   -0.0460657   -0.119939    0.155459    -0.00107074    0.0300737   -0.270434    -0.0121803    -0.00164934   0.0672924   -0.071844     -0.0514248    0.13763     -0.132958     0.00110364   0.0825222    0.0129285    0.0164905    0.123117     0.01662     -0.0131921   -0.228439
  0.0199951    0.0640395    0.0522072    0.92741       0.00164244  -0.0481874   -0.119266    0.154562    -0.000873377  -0.0145021   -0.272562    -0.00326097    0.0470887   -0.00921098  -0.0711728    -0.0529312    0.141669     0.206801     0.170331    -0.0965414    0.0118977    0.017162    -0.0323644    0.0164069   -0.0129792    0.0610419
 -0.122906    -0.191479     0.0916024    0.211686     -0.00459031   0.119639     0.0391924  -0.0208585   -0.107419      0.224436    -0.112883    -0.133839     -0.138379     0.0418564   -0.106226      0.103724    -0.103534     0.0492565    0.0441933    0.119367     0.127527    -0.0229745    0.0643363   -0.0389988    0.0265493    0.0950917
 -0.00765658   0.00952909  -0.0848109    0.100846     -0.0198366    0.00934591   0.0758773   0.00589215   0.0754242    -0.0288641   -0.0279543    0.0388158     0.0287112   -0.0565291   -0.0131609     0.0522465    0.03377      0.00167306  -0.102826     0.117953     0.028255     0.0109178   -0.0138146   -0.0100604    0.0481883   -0.0160671
 -0.0137721    0.0337717   -0.0533258    0.0827716     0.0921448   -0.147956    -0.138393   -0.671088    -0.042868      0.077616     0.144492    -0.207262     -0.06399     -0.216985    -0.000386768   0.30552     -0.179881    -0.0927544    0.0165123   -0.0746081    0.0635411    0.260029    -0.086223     0.129598    -0.434307    -0.0379942
 -0.0215548   -0.0111225   -0.0563867    0.025327      0.0514533   -0.205833    -0.110758    0.41912      0.137559      0.0799225    0.0936935   -0.206968     -0.368372     0.0565071   -0.0833516    -0.138575    -0.159389    -0.117093     0.0175322   -0.0753871   -0.0322524    0.0180993   -0.0450869    0.0778718    0.17692     -0.11679
 -0.150823     0.0741526   -0.153831     0.0783837    -0.0521863    0.106733     0.0833789   0.00743972   0.106382     -0.00237441   0.0741733    0.0603942    -0.105382     0.0315993   -0.0461798    -0.0160333    0.132244     0.0987557    0.020242    -0.0301422   -0.0493768    0.0609413    0.102615    -0.0431107    0.0335921    0.0218384
 -0.0551383   -0.00108062   0.0979633    0.109316      0.034873    -0.104616    -0.0343173   0.158867     0.0535215     0.0187526   -0.0108916   -0.0503505    -0.0623173    0.102051     0.0469415     0.0843944   -0.0542345   -0.0142445   -0.0623585    0.0177156    0.12223     -0.00934674   0.0409754   -0.0449578   -0.0169653   -0.0805874
 -0.0953068   -0.117423    -0.140182    -0.0817074     0.00693084  -0.150606    -0.014405   -0.0302541   -0.17517       0.0290439    0.0170902   -0.035944     -0.178147     0.0645309   -0.226059      0.0214592    0.108906    -0.100633     0.00614517  -0.19619     -0.0171171   -0.0129372    0.162124    -0.115334     0.0467922   -0.0135716
  0.0050115    0.0552652   -0.272864    -0.0798714    -0.00337759  -0.130924     0.0819149  -1.5969       0.196369     -0.0341501    0.0332711   -0.192603     -0.178246    -0.382849    -0.221112      0.163697    -0.198758    -0.616513     0.109036    -0.199503     0.0897366   -0.136048    -0.137812    -0.114365     0.0692949   -0.0768557
 -0.0845307   -0.140032     0.100344     0.076192     -0.0704806    0.0303485   -0.0494373   0.0166304    0.0622463    -0.0676174   -0.00749005   0.169164     -0.115962    -0.0897208    0.036317      0.0862003   -0.0374827   -0.0821213    0.220662    -0.085227    -0.0385524    0.189852    -0.0945629    0.181019     0.115676    -0.0465208
 -0.159584    -0.0517605    0.142834    -0.0352145     0.204466     0.0593197   -0.0831141   0.00885393  -0.0269576    -0.0110691    0.157403    -0.0195281     0.0516355    0.145984     0.169085      0.0710665   -0.0737953    0.067065     0.0488989    0.160934     0.0237854    0.0198719    0.0716674   -0.0589629   -0.0444597    0.133234
 -0.121216     0.00924937   0.0219077    0.0568106    -0.100024     0.146423     0.0194321   0.0349026    0.0602332     0.0393754   -0.0598898    0.108876     -0.0320853   -0.0522298   -0.00949129    0.110501    -0.079973     0.0505502    0.1298      -0.0311362   -0.075091    -0.219792     0.150569     0.144419    -0.15268      0.182727
 -0.0297958   -0.109609     0.00244714  -0.137601      0.0344684   -0.00982521   0.0826295  -0.0319298   -0.05209       0.0870663   -0.0708292    0.0937042    -0.0139304    0.13768     -0.00596311    0.161097    -0.0328558   -0.227343     0.173333     0.200672     0.0164085   -0.162457    -0.115631    -0.0440753   -0.134663     0.171114
 -0.0513669    0.0198171    0.209677     0.178956      0.269272    -0.143842    -0.0112041   0.147699    -0.240945     -0.139216    -0.272085     0.19531       0.056242    -0.260712    -0.0616135    -0.11621      0.0676498    0.105707     0.106936    -0.0326292    0.0548709   -0.0444628    0.415566    -0.0627729    0.220438     0.123086
  0.114434     0.00582997   0.147615    -0.134024      0.0824495   -0.14304      0.0455553   0.148014    -0.236809     -0.126357     0.147221     0.227281      0.0391149    0.369454    -0.0673567    -0.143869     0.0809826    0.0910838    0.108431    -0.00561261   0.0587824   -0.0330179    0.416586     0.00901494   0.219728     0.152555
 -0.0511114    0.0234291    0.0238361   -0.014266     -0.163424    -0.144192     0.021048   -0.00271715  -0.117624      0.0231831   -0.129999    -0.0400204    -0.040301     0.0835137    0.00759085    0.104637    -0.0115888   -0.115784    -0.103296     0.235637    -0.0584584   -0.126212     0.0326394   -0.0565655    0.130132     0.136921
  0.052377     0.0644996    0.0496251    0.0638822    -0.0264428    0.238289    -0.0765408   0.0881243   -0.0750708    -0.0635231    0.0924959   -0.0372612    -0.131886     0.162769     0.209228      0.069645     0.0106134    0.0258795    0.0273292   -0.0493049   -0.010436     0.101261    -0.0114591    0.00567566   0.00380038  -0.0963119
 -0.255222    -0.0238134   -0.0836444    0.114477     -0.0317926   -0.00459578   0.116248   -0.112134    -0.106629      0.0141227   -0.032539     0.0844768    -0.062714    -0.13437      0.0238193    -0.0116468   -0.0680899    0.0683374   -0.0362523    0.0695061    0.140055     0.212408    -0.155608    -0.0974304    0.0191395    0.0286698
 -0.0162015    0.0162036    0.134043     0.107194     -0.0394014   -0.123798     0.0486201   0.0590775    0.0749072     0.0128813    0.0270705    0.0301718     0.142705     0.139049     0.0715174     0.0481153    0.0498785   -0.0609678    0.0635265    0.017543    -0.0452153    0.0717237    0.0482712   -0.00696668   0.0226604   -0.0616339[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     11
│     17
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.089772
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.061549
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     11
│     17
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.075173
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.059512
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     11
│     17
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.080361
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.060687
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│     11
│     17
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.074595
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.064730
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     11
│     17
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.086383
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.050236
┌ Info: EM with 100000 data points 10 iterations avll -1.050236
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind diag, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.304400e+05
      1       6.894359e+05      -2.410041e+05 |       32
      2       6.580459e+05      -3.138997e+04 |       32
      3       6.418913e+05      -1.615461e+04 |       32
      4       6.336296e+05      -8.261729e+03 |       32
      5       6.282374e+05      -5.392153e+03 |       32
      6       6.237629e+05      -4.474565e+03 |       32
      7       6.204058e+05      -3.357027e+03 |       32
      8       6.180660e+05      -2.339846e+03 |       32
      9       6.166955e+05      -1.370477e+03 |       32
     10       6.159953e+05      -7.002184e+02 |       32
     11       6.157155e+05      -2.797756e+02 |       32
     12       6.155780e+05      -1.375616e+02 |       32
     13       6.154679e+05      -1.100970e+02 |       32
     14       6.153461e+05      -1.218082e+02 |       32
     15       6.151889e+05      -1.571374e+02 |       32
     16       6.150263e+05      -1.626524e+02 |       32
     17       6.148013e+05      -2.250095e+02 |       32
     18       6.145002e+05      -3.011077e+02 |       32
     19       6.141395e+05      -3.606290e+02 |       32
     20       6.137832e+05      -3.563116e+02 |       32
     21       6.136087e+05      -1.745348e+02 |       32
     22       6.135241e+05      -8.460960e+01 |       31
     23       6.134887e+05      -3.533008e+01 |       31
     24       6.134719e+05      -1.684578e+01 |       32
     25       6.134628e+05      -9.116076e+00 |       30
     26       6.134569e+05      -5.853011e+00 |       26
     27       6.134523e+05      -4.596780e+00 |       24
     28       6.134486e+05      -3.689310e+00 |       23
     29       6.134461e+05      -2.496762e+00 |       23
     30       6.134441e+05      -1.992585e+00 |       20
     31       6.134424e+05      -1.731454e+00 |       19
     32       6.134414e+05      -9.976899e-01 |       14
     33       6.134405e+05      -9.018353e-01 |       14
     34       6.134401e+05      -4.664197e-01 |       10
     35       6.134397e+05      -3.299782e-01 |        8
     36       6.134394e+05      -3.059553e-01 |        9
     37       6.134391e+05      -3.259928e-01 |       14
     38       6.134385e+05      -5.712362e-01 |       10
     39       6.134381e+05      -4.066756e-01 |       10
     40       6.134378e+05      -2.927237e-01 |        9
     41       6.134373e+05      -4.758351e-01 |        6
     42       6.134371e+05      -2.534444e-01 |        8
     43       6.134367e+05      -3.685702e-01 |       10
     44       6.134363e+05      -4.599905e-01 |        8
     45       6.134359e+05      -3.105005e-01 |        7
     46       6.134355e+05      -4.531298e-01 |       11
     47       6.134350e+05      -5.007167e-01 |        7
     48       6.134347e+05      -2.986675e-01 |        8
     49       6.134344e+05      -3.137991e-01 |        7
     50       6.134342e+05      -1.918676e-01 |        9
K-means terminated without convergence after 50 iterations (objv = 613434.1912964995)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.330854
[ Info: iteration 2, average log likelihood -1.302977
[ Info: iteration 3, average log likelihood -1.274052
[ Info: iteration 4, average log likelihood -1.235436
[ Info: iteration 5, average log likelihood -1.186759
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.133455
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     11
│     12
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.123419
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      8
│     10
│     17
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.116222
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.144316
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.126619
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│     11
│     12
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.075911
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│     19
│     25
│     26
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.116717
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.168864
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     15
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.108287
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│     11
│     12
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.070304
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      8
│     19
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.127056
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.138434
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.101169
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     11
│     12
│     22
│     23
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.073865
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      8
│     15
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.126934
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.145928
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.091991
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     11
│     12
│     19
│     21
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.064220
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      8
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.144780
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.137967
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.105895
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│     11
│     12
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.061406
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      8
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.157651
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.128832
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     15
│     27
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.078089
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     11
│     12
│     17
│     19
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.089036
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      8
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.156692
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.122129
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.106073
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│     10
│     11
│     12
│      ⋮
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.050234
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.144679
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      8
│     22
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.120195
[ Info: iteration 38, average log likelihood -1.145267
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     11
│     12
│     19
│     21
│     23
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.066935
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.149172
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     22
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.107377
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.102692
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     11
│     12
│     19
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.092775
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      3
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.142288
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.115818
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.092535
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      8
│     11
│     12
│     19
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.068118
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.141537
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.134673
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     15
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
32×26 Array{Float64,2}:
 -0.248793 [ Info: iteration 50, average log likelihood -1.086017
┌ Info: EM with 100000 data points 50 iterations avll -1.086017
└ 59.0 data points per parameter
  -0.0234067   -0.0936748     0.115922    -0.0274699   -0.00196369   0.112655    -0.117799    -0.0978865    0.00998065   -0.0383829     0.0882892   -0.0640679   -0.137292    0.0172909   -0.00545417  -0.0743646     0.078701    -0.0311351     0.0723027    0.135154     0.210643    -0.169708    -0.0967545    0.012056     0.0313948
  0.101358   -0.0744602   -0.110982      0.106773     0.0187841    0.07774      0.0964244    0.0378162    0.179915    -0.0319415     0.0194903     0.0665876    0.129914    -0.0328029  -0.00641567  -0.006509    -0.0772088     0.161145     0.0423906    -0.283185     0.0310824   -0.018045    -0.0694879    0.0225378    0.115628     0.0661783
 -0.160945   -0.0102012   -0.130041      0.195679    -0.0200289   -0.0829208    0.0297452    0.00235554   0.0699416    0.0507734    -0.209751      0.0752855    0.0827465    0.0300158  -0.0388863   -0.00492384  -0.0884274    -0.135614    -0.0936008     0.00686317   0.0524286    0.0273416   -0.209965     0.00182846  -0.0861814   -0.0156217
 -0.150671    0.0702445   -0.147048      0.0799147   -0.0497085    0.106319     0.0811805    0.00131037   0.1047      -0.00187889    0.0719961     0.0595764   -0.105944     0.0270698  -0.0431388   -0.0144272    0.120173      0.0961776    0.021222     -0.0302411   -0.0473853    0.051387     0.100176    -0.034641     0.0274591    0.0256233
  0.0296506   0.013011     0.179685      0.0278946    0.178794    -0.143428     0.0161775    0.148377    -0.238931    -0.132868     -0.0697876     0.21098      0.0472095    0.0431039  -0.064361    -0.129303     0.0744815     0.0988504    0.107639     -0.0192442    0.0564951   -0.0385989    0.416119    -0.0287204    0.220079     0.138429
  0.0272377   0.0290389    0.125074      0.208561    -0.130202    -0.0460426    0.106231     0.102213     0.0357631    0.030802     -0.0538818    -0.0424752    0.191732     0.141707    0.0625366    0.0668453    0.00719805   -0.125544     0.0860846    -0.0644603    0.0721749    0.0872463    0.180893    -0.054606     0.0936564   -0.106187
 -0.0208861   0.0175301   -0.0902237     0.144863     0.00833743   0.0408602    0.0711152    0.0287032    0.0921859   -0.0380983    -0.0360709     0.0295511   -0.0523648   -0.0610526   0.00396375  -0.00137868   0.0569364     0.00611384  -0.14279       0.218414     0.00952901   0.0907656   -0.0152187   -0.024015     0.100756    -0.0352261
 -0.0526314   0.0219402    0.0229095    -0.0118484   -0.158418    -0.14465      0.021552    -0.00365385  -0.101704     0.0209157    -0.129327     -0.035872    -0.0343963    0.0830903   0.0020892    0.106429    -0.0128048    -0.123703    -0.105703      0.231726    -0.0553574   -0.127283     0.0269732   -0.0562689    0.129974     0.133911
  0.120451    0.0487687   -0.0394044    -0.0411081    0.112418    -0.00247825   0.101194     0.0312401   -0.205113     0.036193     -0.00624487    0.00244064   0.0560282   -0.153153   -0.200692     0.0545243   -0.184745     -0.0742893   -0.108603     -0.0487741    0.187665    -0.0406918   -0.0661472   -0.159947     0.108526     0.0254554
  0.033993   -0.13582     -0.107502      0.132806     0.00069319   0.0304828    0.0734005    0.0787133    0.0941009   -0.000279364  -0.0356884     0.0611942    0.159397     0.0592445   0.055909     0.00431697  -0.0937588     0.169253     0.0851463    -0.172507     0.0241268   -0.0564158   -0.0217703    0.11029      0.104958     0.145758
  0.0208332   0.0714317    0.0418693    -0.136199     0.0103605   -0.0486366   -0.115439     0.151259     0.00158525   0.0150894    -0.263542     -0.00369295   0.0190839    0.033903   -0.0709525   -0.0504548    0.132846      0.0101816    0.0766615     0.0100493    0.0147698    0.0137471    0.0481172    0.0176471   -0.0159151   -0.0961591
 -0.139943    0.0619922   -0.0520499     0.0427242   -0.00577574  -0.02249     -0.0352494   -0.00341286  -0.248241    -0.0539827    -0.0161144    -0.158971    -0.0331953    0.0267553  -0.115447     0.130601     0.037576      0.0507687   -0.0354817     0.0412304   -0.0842754   -0.0723718   -0.0863444    0.0757605    0.0259009   -0.0354209
  0.0457719  -0.038564    -0.149626      0.272247     0.0393288   -0.0615304   -0.0482104    0.183028    -0.0405678    0.0322416    -0.127443      0.0651361    0.00816609   0.0246442  -0.103063     0.0450178    0.0930048    -0.0552538    0.0269859     0.0978396    0.0374637    0.045998     0.203053     0.0763671    0.132048    -0.0402033
 -0.0638095   0.0234961    0.0526765     0.0395573    0.0495844   -0.070164     0.00926804  -0.0337967    0.10314     -0.102262      0.0836817     0.0253978    0.102482     0.0482056   0.0703089    0.0163556   -0.0142892    -0.0416561    0.0430118    -0.104341    -0.10772      0.0204759   -0.0721107   -0.0457503   -0.0248281    0.0871357
 -0.0344017  -0.111316    -0.00265162   -0.136119     0.0312886   -0.00562393   0.0825723   -0.0300664   -0.051941     0.0846657    -0.0731019     0.0961874   -0.0158258    0.135105   -0.0071771    0.163142    -0.0332644    -0.225425     0.177602      0.201064     0.0169518   -0.167718    -0.118398    -0.0418997   -0.135237     0.175199
 -0.125571    0.0180078   -0.051206      0.152508    -0.00993064   0.0199719    0.0412267    0.0939037   -0.0537111    0.182858      0.148567      0.0883447    0.0302018   -0.050797   -0.161863    -0.0324949   -0.192235      0.0271768   -0.115925     -0.0252953   -0.0141034   -0.0669256   -0.00500121  -0.0887527   -0.104002     0.0364778
 -0.146579    0.0181904   -0.0178618     0.140904     0.0446385   -0.107894    -0.0440321    0.404996     0.114936     0.0794534    -0.121358     -0.0895213   -0.0667564    0.0778441  -0.0682484   -0.0134705    0.00558604    0.0174134   -0.0328713    -0.0110064    0.125486    -0.0335132   -0.0135784   -0.0265904   -0.0164033   -0.0594797
  0.022227    0.00284827  -0.0489529    -0.0131253   -0.0881547   -0.067598     0.089109    -0.0596999    0.0448676   -0.0230015    -0.000372922   0.0506617    0.208892    -0.0375358  -0.0612932    0.176271     0.00492949   -0.0330272   -0.033256     -0.100534     0.0689011   -0.17662     -0.003197     0.00836193  -0.0802519    0.0116061
 -0.0630314   0.0963538    0.0940005     0.169193     0.0565299    0.0703137   -0.0103634    0.0496782   -0.0618984    0.105499     -0.276069      0.140509     0.00763303   0.0122392  -0.0104567   -0.0202981    0.0256717     0.146219    -0.103376      0.0974348   -0.0634789   -0.117465     0.0527493   -0.00716143  -0.0585012    0.0839469
  0.0517119   0.0385974   -0.0516329     0.0758506   -0.136365    -0.0218636    0.0383474   -0.0384323   -0.0206943    0.0755423    -0.103697      0.139815    -0.162911    -0.118509   -0.0545661    0.0779667    0.000312188   0.07586      0.0664662     0.0578324    0.0454757   -0.0128812   -0.0454987    0.0338978   -0.0773035   -0.0371869
 -0.0164573  -0.067502    -0.134727      0.0183505   -0.147422     0.168354    -0.025168    -0.112772     0.122223    -0.037404     -0.108806      0.128118    -0.00500215  -0.100968   -0.066164    -0.128263    -0.185828      0.148941     0.0913485     0.134594     0.101489     0.162391    -0.01464      0.0630484   -0.157835     0.0460148
 -0.054871   -0.00878445   0.102398      0.119785     0.0321933   -0.0936024   -0.0275277    0.147855     0.0583201    0.00403037   -0.0152244    -0.0333967   -0.0630113    0.0883956   0.0816185    0.107466    -0.0570321    -0.0184146   -0.0528801     0.0201118    0.120353    -0.0218201    0.0276575   -0.0251103   -0.0179648   -0.0909334
 -0.0824758  -0.102935    -0.13966      -0.0794258    0.0103122   -0.150631    -0.0268716   -0.0461764   -0.154614     0.034514      0.0169627    -0.0466961   -0.17417      0.0659039  -0.220426     0.0210663    0.0947321    -0.101619     0.000496798  -0.177286    -0.013317    -0.00705495   0.154448    -0.115684     0.0471266   -0.0155821
  0.0511686   0.0647719    0.0450879     0.0587037   -0.025163     0.237186    -0.0748836    0.0832873   -0.0749871   -0.0597102     0.0918276    -0.034141    -0.129552     0.159274    0.200259     0.0712866    0.0102747     0.0251568    0.0286575    -0.0461999   -0.00786573   0.102437    -0.0120866    0.00594867   0.00116087  -0.092449
  0.142469    0.0610956    0.100255     -0.00806142   0.09789     -0.0242912    0.0791503    0.0126515    0.22624      0.0596768    -0.0668919     0.135628     0.00461214   0.143246   -0.111288    -0.0691287   -0.0415331    -0.0355009    0.029922     -0.0316402   -0.0374521    0.0217582    0.0493067   -0.0690836    0.00658778  -0.169493
 -0.110673    0.0216432   -0.000822938   0.0502984   -0.0759053    0.149257     0.0158182    0.0232475    0.0713258    0.026232     -0.0601575     0.124822    -0.051494    -0.0523831  -0.0256526    0.12        -0.0624533     0.0520699    0.125776     -0.0258411   -0.0708451   -0.200649     0.175736     0.135523    -0.120673     0.241536
 -0.0258436   0.0346178    0.0429382    -0.0268049    0.135028    -0.0876895   -0.0560415   -0.0406752    0.0866254    0.0214624     0.0344359     0.0338394    0.0571352   -0.0272727  -0.0714495    0.148427    -0.0265272     0.00771529   0.0738207     0.106575     0.0280095    0.0344747    0.109928    -0.0288122    0.0338672    0.0573602
 -0.016386    0.0126641   -0.0519262     0.0520591    0.0718178   -0.176135    -0.126767    -0.143225     0.0488284    0.0783527     0.1251       -0.206794    -0.215495    -0.0836927  -0.039134     0.0873601   -0.174434     -0.102157     0.0176307    -0.0746817    0.0154064    0.139558    -0.0677214    0.105245    -0.132659    -0.0757272
  0.135229    0.0553547   -0.101527     -0.0421173    0.140227    -0.127629    -0.030928    -0.0279653    0.178112    -0.0777347    -0.213687      0.052114    -0.110797    -0.0524189  -0.236938     0.295997    -0.00052149   -0.0897716    0.0477065    -0.0106899    0.0340051   -3.17595e-5  -0.252237     0.00588091   0.078713    -0.0045476
 -0.160562   -0.050807     0.144898     -0.036322     0.20521      0.0596234   -0.0812269    0.00808646  -0.0264725   -0.0105137     0.155753     -0.0194062    0.0517762    0.144869    0.169659     0.0724689   -0.0746634     0.0666904    0.0501555     0.161096     0.0236942    0.0197105    0.0715641   -0.0597465   -0.0445423    0.133173
 -0.0894316  -0.140297     0.116309      0.0659622   -0.0602551    0.0360314   -0.0474023    0.0202424    0.0639069   -0.0559906     0.0020233     0.162499    -0.121569    -0.0871962   0.0204759    0.0786461   -0.0361286    -0.0758772    0.227074     -0.0879757   -0.0292214    0.183167    -0.0895814    0.169379     0.105547    -0.0456309
 -0.122952   -0.182388     0.092346      0.206512    -0.00929649   0.118432     0.0377066   -0.0225607   -0.101612     0.216975     -0.109741     -0.131297    -0.13787      0.0412154  -0.104556     0.105127    -0.103908      0.0506307    0.0444275     0.113803     0.127193    -0.0236735    0.0578176   -0.0375549    0.0207381    0.100685[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     11
│     12
│     19
│     21
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.074374
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      8
│     11
│      ⋮
│     23
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.028420
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      4
│      8
│     11
│      ⋮
│     26
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.020249
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      4
│      8
│     11
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.025297
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│     11
│     12
│     19
│      ⋮
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.052271
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.019792
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      8
│     11
│     12
│      ⋮
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.029366
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      4
│      8
│     11
│      ⋮
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.002428
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      8
│     11
│     12
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.038531
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      8
│     11
│      ⋮
│     23
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.032846
┌ Info: EM with 100000 data points 10 iterations avll -1.032846
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.159484    -0.0165828   0.0997964    0.0712724  -0.0828075   -0.196871     0.0836955    0.035302    -0.0170116     0.0256285   0.0557326     0.131761    -0.00745642  -0.00361641  -0.0765441    0.0365088   -0.0433966   -0.0802252    0.0201026   -0.155216     0.00173816  -0.0898778    -0.00671845  -0.14681     -0.103555    -0.155116
  0.0418246   -0.0948541   0.0406594    0.0750946  -0.0482906    0.105015     0.0645628   -0.122739     0.0484042    -0.0465093   0.0460014    -0.10988     -0.0434248    0.0998302   -0.0809436   -0.0984469   -0.0909436    0.133006     0.0892257    0.0745587   -0.0757592    0.0437522    -0.118       -0.0726376   -0.137038    -0.116656
  0.0876125    0.155584    0.0164295    0.183228   -0.0987913   -0.045202     0.0122956   -0.0148295   -0.059236      0.114491   -0.0330639    -0.100164     0.129718     0.0649498   -0.161687     0.0786775   -0.0518172    0.0441652    0.15818      0.0630323   -0.139866     0.0874579     0.0271084    0.0241888   -0.071189     0.0491929
 -0.0394348   -0.112871    0.00573456  -0.0759205   0.0476774   -0.00252201   0.110771     0.00939947  -0.000195305   0.0332737  -0.105601      0.0596861    0.0267671   -0.055054     0.0141885    0.0759341    0.134384    -0.0231965    0.117394     0.146327     0.0307797   -0.0993079     0.0552323   -0.0107595    0.052335     0.290733
  0.0889309    0.0147376  -0.048826     0.0938455   0.0764819   -0.0311958    0.100368    -0.0349991   -0.0293869     0.0974707  -0.300057      0.0531535    0.156732     0.0601447   -0.00142369   0.0269879    0.0853732    0.0254277    0.0244674    0.0418871    0.0211073   -0.0621687     0.0458963    0.089975    -0.100147     0.0630314
 -0.0203108   -0.0193192   0.0889934    0.106934    0.00646996  -0.0468319   -0.127436    -0.137267     0.00797456    0.281244    0.0948762     0.0829509   -0.0294844   -0.239025    -0.00517965  -0.0709158   -0.0483741    0.0516791    0.188978     0.0186866    0.137695     0.130854      0.101628    -0.160247    -0.172598     0.0892257
 -0.00619454  -0.0306276   0.0383529   -0.0126677  -0.045449     0.0661095    0.0536754    0.0446959   -0.111649     -0.0820378   0.127385     -0.0495718   -0.166124    -0.127401    -0.074796     0.00538679  -0.152249     0.0708632   -0.0264366    0.0764909    0.103803    -0.0123664     0.0428956   -0.166272     0.0366373   -0.0614716
 -0.256571     0.121102    0.0593838    0.0172464  -0.10684      0.106157     0.0610571    0.234883    -0.0375057     0.0735791   0.0228529    -0.100774    -0.20169      0.109544    -0.0473477   -0.161205     0.0854536    0.0462221    0.00378257  -0.0799402    0.0102805    0.0283521    -0.0609271   -0.0697478   -0.184752     0.00255949
  0.0386846    0.0180337   0.0664346    0.0393391  -0.12131     -0.00158708  -0.00352619  -0.0208615    0.0141888    -0.125206   -0.140845      0.114433     0.0394132    0.0552893    0.00229231   0.0865469   -0.208404    -0.0693932    0.0078939   -0.00299857   0.240218     0.0799687     0.0454414    0.202851    -0.0207325    0.0928145
  0.0279695   -0.0606464  -0.170035    -0.0731488   0.0652423    0.0461133   -0.0998912    0.0189272   -0.0335744    -0.109456    0.0218067     0.157327     0.132261     0.0912375   -0.106967     0.00885045   0.0186444   -0.0716298    0.00825841   0.0960703    0.0222652    0.028694      0.070908     0.202863    -0.025823    -0.00875379
  0.0317263   -0.0115641  -0.0611027   -0.0199199   0.0426651    0.0230662   -0.168752    -0.0341021    0.0446073     0.131989    0.0470383     0.121397     2.92233e-5  -0.0316494    0.0289108    0.0638276   -0.125742    -0.0690722   -0.14305      0.125409     0.097191    -0.112302      0.00627445   0.00886358   0.0361669    0.0944926
 -0.091869     0.0487943   0.044995    -0.0127006   0.198248     0.0196588   -0.0412365   -0.0338157   -0.0702294     0.231763   -0.119633     -0.0894291    0.00236059   0.143505     0.104598    -0.010453     0.0546837    0.00184665   0.232886    -0.0659612   -0.0127325    0.00554951    0.0470482   -0.0995567    0.0455272    0.0845155
  0.0610037    0.0413145   0.100159    -0.0471875  -0.152655    -0.107935     0.0384778    0.216889     0.0119464    -0.0135196  -0.0622076     0.0153993    0.0215058    0.00645367  -0.259167     0.00418343  -0.147284    -0.0627888    0.0527941   -0.0760563    0.0884998   -0.161989      0.0529016    0.17602      0.0363195    0.0650216
 -0.0195602   -0.141394    0.142269    -0.0968436   0.15505     -0.0238628    0.27207      0.0758937    0.0308004     0.119541   -0.217906     -0.0179042   -0.150128     0.0474459   -0.0857389   -0.109385     0.0977362    0.0173233   -0.0440566   -0.00703737  -0.0199136    0.129509      0.122044    -0.0967317    0.21633     -0.0434652
 -0.040892    -0.178712    0.276572     0.0026612   0.076584    -0.0647671   -0.057919     0.227953     0.00961983   -0.0389131   0.131772     -0.129793     0.26718      0.00502788   0.0378764   -0.0345769    0.163444    -0.218099    -0.046462     0.111791    -0.0846466    0.0303676    -0.114476    -0.0365963   -0.00794478  -0.114468
 -0.174855    -0.148197    0.137672     0.0873676   0.0450725   -0.17302     -0.0973837    0.00426258  -0.0445859     0.0173154  -0.000476073   0.230991    -0.0713159    0.090153    -0.0680113   -0.0658185   -0.0204133    0.00972123   0.087357    -0.00334805  -0.0234591   -0.0352841     0.01127     -0.169504     0.109164     0.0105118
  0.0489647    0.175163    0.112335    -0.107519    0.064671    -0.083607    -0.0485839   -0.0240118    0.0201971     0.0826078  -0.0718285    -0.139356    -0.00837051   0.0455491    0.130836     0.0457209    0.0667924   -0.134284    -0.205841    -0.0525458    0.127419     0.0120626     0.0822188    0.007218    -0.0742694   -0.0926732
 -0.032114     0.093882    0.215955    -0.025783    0.037835     0.16368      0.0695442   -0.224359     0.0136909     0.0295132   0.0961059    -0.119376    -0.0758746    0.0587713   -0.136703     0.0514521    0.0224206    0.0415409   -0.189308    -0.0481368   -0.0165654   -0.134715     -0.0655133    0.24058     -0.218081    -0.0500867
  0.0611502    0.0201743  -0.0920251   -0.0685147   0.0928265   -0.081009     0.106627    -0.101979    -0.0355266    -0.0266379  -0.0247817     0.0495685   -0.0353804   -0.0668298   -0.0177267    0.0591338   -0.0124737   -0.1131      -0.0307549    0.0332922    0.122106     0.154697     -0.117515    -0.0297027    0.112177     0.0151607
 -0.141428    -0.0528756   0.00461106   0.156339   -0.0718326    0.139012     0.0210213   -0.0598669   -0.0662724    -0.0487194  -0.0611268     0.0339242    0.0438659    0.164937    -0.150356     0.147668    -0.04837      0.0487258   -0.0379029    0.0443689   -0.00330097   0.0531495     0.136962    -0.23087      0.034932     0.0141775
 -0.030602    -0.0236265  -0.0143328    0.150001    0.00293313  -0.0151856   -0.012137    -0.182652    -0.162098      0.0420586  -0.0148931    -0.110661    -0.0208186    0.0449175   -0.00967974  -0.0958061    0.160382     0.138819    -0.15585     -0.0501516   -0.00261563  -0.198995     -0.00878024  -0.0918479   -0.0723945    0.0609028
  0.0117417    0.104715    0.0322821   -0.185953    0.0211713    0.0783384   -0.198989    -0.0244551    0.0555252    -0.0415165   0.0200761     0.0561345   -0.0234155    0.033317    -0.08962      0.0498688    0.028807     0.0175092    0.0449059    0.0226206   -0.017336     0.160217     -0.113416     0.0145613    0.209415     0.0336251
  0.0358902    0.250805    0.0595465    0.0161975   0.138003     0.0421678    0.00527131  -0.0626696   -0.0437452     0.170318    0.0367072     0.212044    -0.0777577    0.0992342    0.04517     -0.0669447    0.00738221   0.158454     0.01964      0.0137508    0.060548    -0.0450994    -0.0293969   -0.0563946   -0.0552167    0.0741179
 -0.0779099   -0.0479839   0.123645     0.209737    0.113022    -0.239592     0.00535207  -0.0317188    0.0244157     0.0730415   0.079028      0.0482724    0.0328453   -0.293868    -0.166421    -0.148327     0.10378      0.0320192    0.0409178    0.0803335    0.0082531    0.000726249   0.0156652    0.0576248    0.0257026   -0.0326986
  0.0482149    0.075309    0.0100877   -0.0551607  -0.0767284    0.0527079    0.0961963    0.0366249    0.221356     -0.0477429   0.089675     -0.0957076    0.0973149   -0.0444827    0.0362823   -0.104631    -0.00338974   0.0644832   -0.0688007   -0.138711     0.0150362    0.0989136    -0.0854087    0.0253407    0.0738623    0.0823711
  0.0764635    0.0954245  -0.0927244   -0.0507842   0.0643377   -0.10884     -0.0556384   -0.183859    -0.0477523     0.0281421  -0.247084     -0.0922447   -0.0611859   -0.0312312    0.0143965   -0.155064    -0.0612317    0.0292092    0.0788286   -0.0592494   -0.0112191   -0.114639      0.0484076   -0.0221962   -0.148355     0.0208579
 -0.0778135    0.107197   -0.0872751   -0.0574222  -0.019574     0.145474     0.0120736    0.086795     0.0804117    -0.184507    0.146821      0.338708     0.155479    -0.144343     0.0849693    0.184339    -0.0198369   -0.00752241  -0.0393456   -0.217978     0.0328706   -0.147839     -0.117308    -0.0241157   -0.0274323    0.0353335
  0.0206352   -0.0584487  -0.172778    -0.0209343  -0.111433     0.0144805   -0.0247397    0.013647     0.0851666     0.204239   -0.00802395    0.0525389    0.0735405   -0.0626043    0.0659758   -0.136255    -0.0180543   -0.15315     -0.0514928    0.0332918    0.0303191    0.166704      0.00781533   0.011397    -0.144745    -0.0412154
  0.260788    -0.256924    0.0989297   -0.0774338  -0.0104129   -0.0327005    0.048724     0.0599723   -0.01259       0.129616    0.064372     -0.105844    -0.0356191   -0.126211     0.0625731   -0.00324852  -0.0531981    0.159468     0.115733    -0.140206     0.00589411   0.0737369    -0.0823746    0.191198     0.121087     0.150538
 -0.23022      0.0950128  -0.00448154  -0.0666865   0.0403829    0.0259403   -0.0280839   -0.0610052    0.0777422    -0.051381   -0.0756541    -0.0575211    0.0261432    0.00186919   0.0517117   -0.0591398    0.0079134   -0.0686044   -0.0889584    0.0594393    0.00651108  -0.116144     -0.0189896    0.0852383   -0.0175174    0.00318563
 -0.020353     0.204349   -0.00885609  -0.0747667   0.116094     0.104218     0.0968242   -0.0108454    0.027126      0.125314    0.143495      0.00563715   0.0144701    0.101483    -0.0342803    0.00663365  -0.160503     0.113978    -0.0227979    0.0633       0.00578076  -0.00378747   -0.0286715   -0.0765864   -0.113802     0.0411385
 -0.0575827    0.048266    0.0198912   -0.0398647  -0.0208417    0.177672    -0.0649305    0.118195     0.0182479     0.0584093   0.0734132    -0.119865    -0.152442    -0.0938901    0.0237842   -0.0577061    0.0698503   -0.0158023   -0.0286284    0.12746      0.0766079   -0.135981     -0.137092     0.086474    -0.113448    -0.0822918kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4179980318748227
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418018
[ Info: iteration 2, average log likelihood -1.417948
[ Info: iteration 3, average log likelihood -1.417891
[ Info: iteration 4, average log likelihood -1.417812
[ Info: iteration 5, average log likelihood -1.417685
[ Info: iteration 6, average log likelihood -1.417455
[ Info: iteration 7, average log likelihood -1.417003
[ Info: iteration 8, average log likelihood -1.416178
[ Info: iteration 9, average log likelihood -1.415002
[ Info: iteration 10, average log likelihood -1.413865
[ Info: iteration 11, average log likelihood -1.413141
[ Info: iteration 12, average log likelihood -1.412800
[ Info: iteration 13, average log likelihood -1.412660
[ Info: iteration 14, average log likelihood -1.412603
[ Info: iteration 15, average log likelihood -1.412579
[ Info: iteration 16, average log likelihood -1.412569
[ Info: iteration 17, average log likelihood -1.412564
[ Info: iteration 18, average log likelihood -1.412562
[ Info: iteration 19, average log likelihood -1.412561
[ Info: iteration 20, average log likelihood -1.412560
[ Info: iteration 21, average log likelihood -1.412560
[ Info: iteration 22, average log likelihood -1.412560
[ Info: iteration 23, average log likelihood -1.412559
[ Info: iteration 24, average log likelihood -1.412559
[ Info: iteration 25, average log likelihood -1.412559
[ Info: iteration 26, average log likelihood -1.412559
[ Info: iteration 27, average log likelihood -1.412559
[ Info: iteration 28, average log likelihood -1.412559
[ Info: iteration 29, average log likelihood -1.412558
[ Info: iteration 30, average log likelihood -1.412558
[ Info: iteration 31, average log likelihood -1.412558
[ Info: iteration 32, average log likelihood -1.412558
[ Info: iteration 33, average log likelihood -1.412558
[ Info: iteration 34, average log likelihood -1.412558
[ Info: iteration 35, average log likelihood -1.412558
[ Info: iteration 36, average log likelihood -1.412558
[ Info: iteration 37, average log likelihood -1.412558
[ Info: iteration 38, average log likelihood -1.412558
[ Info: iteration 39, average log likelihood -1.412558
[ Info: iteration 40, average log likelihood -1.412558
[ Info: iteration 41, average log likelihood -1.412558
[ Info: iteration 42, average log likelihood -1.412558
[ Info: iteration 43, average log likelihood -1.412558
[ Info: iteration 44, average log likelihood -1.412557
[ Info: iteration 45, average log likelihood -1.412557
[ Info: iteration 46, average log likelihood -1.412557
[ Info: iteration 47, average log likelihood -1.412557
[ Info: iteration 48, average log likelihood -1.412557
[ Info: iteration 49, average log likelihood -1.412557
[ Info: iteration 50, average log likelihood -1.412557
┌ Info: EM with 100000 data points 50 iterations avll -1.412557
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4180175569555364
│     -1.4179482397522947
│      ⋮
└     -1.4125573778838916
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412573
[ Info: iteration 2, average log likelihood -1.412507
[ Info: iteration 3, average log likelihood -1.412450
[ Info: iteration 4, average log likelihood -1.412377
[ Info: iteration 5, average log likelihood -1.412284
[ Info: iteration 6, average log likelihood -1.412171
[ Info: iteration 7, average log likelihood -1.412045
[ Info: iteration 8, average log likelihood -1.411919
[ Info: iteration 9, average log likelihood -1.411806
[ Info: iteration 10, average log likelihood -1.411711
[ Info: iteration 11, average log likelihood -1.411636
[ Info: iteration 12, average log likelihood -1.411579
[ Info: iteration 13, average log likelihood -1.411536
[ Info: iteration 14, average log likelihood -1.411505
[ Info: iteration 15, average log likelihood -1.411481
[ Info: iteration 16, average log likelihood -1.411463
[ Info: iteration 17, average log likelihood -1.411448
[ Info: iteration 18, average log likelihood -1.411435
[ Info: iteration 19, average log likelihood -1.411423
[ Info: iteration 20, average log likelihood -1.411413
[ Info: iteration 21, average log likelihood -1.411403
[ Info: iteration 22, average log likelihood -1.411395
[ Info: iteration 23, average log likelihood -1.411386
[ Info: iteration 24, average log likelihood -1.411378
[ Info: iteration 25, average log likelihood -1.411371
[ Info: iteration 26, average log likelihood -1.411364
[ Info: iteration 27, average log likelihood -1.411357
[ Info: iteration 28, average log likelihood -1.411351
[ Info: iteration 29, average log likelihood -1.411345
[ Info: iteration 30, average log likelihood -1.411340
[ Info: iteration 31, average log likelihood -1.411334
[ Info: iteration 32, average log likelihood -1.411329
[ Info: iteration 33, average log likelihood -1.411324
[ Info: iteration 34, average log likelihood -1.411319
[ Info: iteration 35, average log likelihood -1.411314
[ Info: iteration 36, average log likelihood -1.411309
[ Info: iteration 37, average log likelihood -1.411304
[ Info: iteration 38, average log likelihood -1.411300
[ Info: iteration 39, average log likelihood -1.411295
[ Info: iteration 40, average log likelihood -1.411290
[ Info: iteration 41, average log likelihood -1.411286
[ Info: iteration 42, average log likelihood -1.411282
[ Info: iteration 43, average log likelihood -1.411277
[ Info: iteration 44, average log likelihood -1.411273
[ Info: iteration 45, average log likelihood -1.411269
[ Info: iteration 46, average log likelihood -1.411265
[ Info: iteration 47, average log likelihood -1.411261
[ Info: iteration 48, average log likelihood -1.411258
[ Info: iteration 49, average log likelihood -1.411254
[ Info: iteration 50, average log likelihood -1.411251
┌ Info: EM with 100000 data points 50 iterations avll -1.411251
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.41257310419569
│     -1.4125073689063066
│      ⋮
└     -1.4112510018653412
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411263
[ Info: iteration 2, average log likelihood -1.411200
[ Info: iteration 3, average log likelihood -1.411149
[ Info: iteration 4, average log likelihood -1.411091
[ Info: iteration 5, average log likelihood -1.411022
[ Info: iteration 6, average log likelihood -1.410942
[ Info: iteration 7, average log likelihood -1.410851
[ Info: iteration 8, average log likelihood -1.410756
[ Info: iteration 9, average log likelihood -1.410663
[ Info: iteration 10, average log likelihood -1.410575
[ Info: iteration 11, average log likelihood -1.410496
[ Info: iteration 12, average log likelihood -1.410425
[ Info: iteration 13, average log likelihood -1.410364
[ Info: iteration 14, average log likelihood -1.410309
[ Info: iteration 15, average log likelihood -1.410261
[ Info: iteration 16, average log likelihood -1.410219
[ Info: iteration 17, average log likelihood -1.410181
[ Info: iteration 18, average log likelihood -1.410148
[ Info: iteration 19, average log likelihood -1.410119
[ Info: iteration 20, average log likelihood -1.410094
[ Info: iteration 21, average log likelihood -1.410071
[ Info: iteration 22, average log likelihood -1.410052
[ Info: iteration 23, average log likelihood -1.410035
[ Info: iteration 24, average log likelihood -1.410020
[ Info: iteration 25, average log likelihood -1.410007
[ Info: iteration 26, average log likelihood -1.409996
[ Info: iteration 27, average log likelihood -1.409985
[ Info: iteration 28, average log likelihood -1.409976
[ Info: iteration 29, average log likelihood -1.409968
[ Info: iteration 30, average log likelihood -1.409960
[ Info: iteration 31, average log likelihood -1.409952
[ Info: iteration 32, average log likelihood -1.409945
[ Info: iteration 33, average log likelihood -1.409938
[ Info: iteration 34, average log likelihood -1.409932
[ Info: iteration 35, average log likelihood -1.409925
[ Info: iteration 36, average log likelihood -1.409919
[ Info: iteration 37, average log likelihood -1.409913
[ Info: iteration 38, average log likelihood -1.409906
[ Info: iteration 39, average log likelihood -1.409900
[ Info: iteration 40, average log likelihood -1.409894
[ Info: iteration 41, average log likelihood -1.409887
[ Info: iteration 42, average log likelihood -1.409881
[ Info: iteration 43, average log likelihood -1.409875
[ Info: iteration 44, average log likelihood -1.409868
[ Info: iteration 45, average log likelihood -1.409861
[ Info: iteration 46, average log likelihood -1.409855
[ Info: iteration 47, average log likelihood -1.409848
[ Info: iteration 48, average log likelihood -1.409841
[ Info: iteration 49, average log likelihood -1.409834
[ Info: iteration 50, average log likelihood -1.409827
┌ Info: EM with 100000 data points 50 iterations avll -1.409827
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4112626044020582
│     -1.411200149164838
│      ⋮
└     -1.4098271505152646
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409829
[ Info: iteration 2, average log likelihood -1.409770
[ Info: iteration 3, average log likelihood -1.409716
[ Info: iteration 4, average log likelihood -1.409655
[ Info: iteration 5, average log likelihood -1.409580
[ Info: iteration 6, average log likelihood -1.409489
[ Info: iteration 7, average log likelihood -1.409381
[ Info: iteration 8, average log likelihood -1.409258
[ Info: iteration 9, average log likelihood -1.409126
[ Info: iteration 10, average log likelihood -1.408992
[ Info: iteration 11, average log likelihood -1.408865
[ Info: iteration 12, average log likelihood -1.408749
[ Info: iteration 13, average log likelihood -1.408649
[ Info: iteration 14, average log likelihood -1.408563
[ Info: iteration 15, average log likelihood -1.408491
[ Info: iteration 16, average log likelihood -1.408430
[ Info: iteration 17, average log likelihood -1.408377
[ Info: iteration 18, average log likelihood -1.408332
[ Info: iteration 19, average log likelihood -1.408292
[ Info: iteration 20, average log likelihood -1.408256
[ Info: iteration 21, average log likelihood -1.408224
[ Info: iteration 22, average log likelihood -1.408195
[ Info: iteration 23, average log likelihood -1.408168
[ Info: iteration 24, average log likelihood -1.408143
[ Info: iteration 25, average log likelihood -1.408120
[ Info: iteration 26, average log likelihood -1.408099
[ Info: iteration 27, average log likelihood -1.408079
[ Info: iteration 28, average log likelihood -1.408060
[ Info: iteration 29, average log likelihood -1.408042
[ Info: iteration 30, average log likelihood -1.408025
[ Info: iteration 31, average log likelihood -1.408009
[ Info: iteration 32, average log likelihood -1.407994
[ Info: iteration 33, average log likelihood -1.407980
[ Info: iteration 34, average log likelihood -1.407966
[ Info: iteration 35, average log likelihood -1.407953
[ Info: iteration 36, average log likelihood -1.407940
[ Info: iteration 37, average log likelihood -1.407928
[ Info: iteration 38, average log likelihood -1.407916
[ Info: iteration 39, average log likelihood -1.407904
[ Info: iteration 40, average log likelihood -1.407893
[ Info: iteration 41, average log likelihood -1.407882
[ Info: iteration 42, average log likelihood -1.407871
[ Info: iteration 43, average log likelihood -1.407861
[ Info: iteration 44, average log likelihood -1.407851
[ Info: iteration 45, average log likelihood -1.407841
[ Info: iteration 46, average log likelihood -1.407831
[ Info: iteration 47, average log likelihood -1.407822
[ Info: iteration 48, average log likelihood -1.407812
[ Info: iteration 49, average log likelihood -1.407803
[ Info: iteration 50, average log likelihood -1.407794
┌ Info: EM with 100000 data points 50 iterations avll -1.407794
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4098291159164555
│     -1.4097700568565743
│      ⋮
└     -1.4077943918823344
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407794
[ Info: iteration 2, average log likelihood -1.407728
[ Info: iteration 3, average log likelihood -1.407666
[ Info: iteration 4, average log likelihood -1.407593
[ Info: iteration 5, average log likelihood -1.407502
[ Info: iteration 6, average log likelihood -1.407390
[ Info: iteration 7, average log likelihood -1.407257
[ Info: iteration 8, average log likelihood -1.407108
[ Info: iteration 9, average log likelihood -1.406949
[ Info: iteration 10, average log likelihood -1.406789
[ Info: iteration 11, average log likelihood -1.406636
[ Info: iteration 12, average log likelihood -1.406492
[ Info: iteration 13, average log likelihood -1.406360
[ Info: iteration 14, average log likelihood -1.406240
[ Info: iteration 15, average log likelihood -1.406134
[ Info: iteration 16, average log likelihood -1.406039
[ Info: iteration 17, average log likelihood -1.405954
[ Info: iteration 18, average log likelihood -1.405878
[ Info: iteration 19, average log likelihood -1.405811
[ Info: iteration 20, average log likelihood -1.405750
[ Info: iteration 21, average log likelihood -1.405695
[ Info: iteration 22, average log likelihood -1.405645
[ Info: iteration 23, average log likelihood -1.405599
[ Info: iteration 24, average log likelihood -1.405556
[ Info: iteration 25, average log likelihood -1.405517
[ Info: iteration 26, average log likelihood -1.405480
[ Info: iteration 27, average log likelihood -1.405446
[ Info: iteration 28, average log likelihood -1.405413
[ Info: iteration 29, average log likelihood -1.405383
[ Info: iteration 30, average log likelihood -1.405354
[ Info: iteration 31, average log likelihood -1.405327
[ Info: iteration 32, average log likelihood -1.405301
[ Info: iteration 33, average log likelihood -1.405276
[ Info: iteration 34, average log likelihood -1.405252
[ Info: iteration 35, average log likelihood -1.405229
[ Info: iteration 36, average log likelihood -1.405207
[ Info: iteration 37, average log likelihood -1.405186
[ Info: iteration 38, average log likelihood -1.405165
[ Info: iteration 39, average log likelihood -1.405145
[ Info: iteration 40, average log likelihood -1.405126
[ Info: iteration 41, average log likelihood -1.405107
[ Info: iteration 42, average log likelihood -1.405089
[ Info: iteration 43, average log likelihood -1.405071
[ Info: iteration 44, average log likelihood -1.405054
[ Info: iteration 45, average log likelihood -1.405038
[ Info: iteration 46, average log likelihood -1.405022
[ Info: iteration 47, average log likelihood -1.405006
[ Info: iteration 48, average log likelihood -1.404991
[ Info: iteration 49, average log likelihood -1.404977
[ Info: iteration 50, average log likelihood -1.404964
┌ Info: EM with 100000 data points 50 iterations avll -1.404964
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4077943350812507
│     -1.407728210286306
│      ⋮
└     -1.4049635466290797
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4179980318748227
│     -1.4180175569555364
│     -1.4179482397522947
│     -1.4178906941131986
│      ⋮
│     -1.4049914854789465
│     -1.4049772452738278
└     -1.4049635466290797
32×26 Array{Float64,2}:
 -0.0905076   -0.253438   -0.497324   -0.38502      0.0303791    -0.356271   -0.209985   -0.28474    -0.0462393   0.827698   -0.411656    0.0845673   -0.0944651   -0.114262   -0.277855     -0.0634417   -0.117836     0.0966426    -0.0887565    0.333381    -0.299986     0.0482478   0.0707691   -0.264065   -0.164768    -0.486272
 -0.0448631   -0.396375    0.237894   -0.296416    -0.0372211    -0.178316   -0.356402   -0.46714     0.195069    0.813088    0.06641    -0.116833    -0.219792    -0.198857   -0.438439      0.237942    -0.127846     0.402001      0.0627365   -0.294876    -0.344656     0.146343   -0.0824802   -0.0596125  -0.256038     0.523534
 -0.20186     -0.577852   -0.4444     -0.329804    -0.0870964     0.373963   -0.0266522   0.475981   -0.0264034   0.0432416  -0.777113    0.130202     0.110251     0.031616   -0.558556     -0.333212    -0.0743381   -0.129523      0.0336149    0.29386      0.180625    -0.0587952  -0.258332     0.376436   -0.201137    -0.0449424
 -0.442931    -0.494981    0.255267    0.374142     0.000636998   0.270817   -0.0803564   0.135132   -0.0169228   0.137268   -0.599369   -0.378936     0.00718752   0.32613    -0.0517499    -1.12611      0.24403     -0.15828      -0.167902     0.00998781   0.0844681   -0.307625    0.0163856   -0.549296   -0.269573     0.491663
  0.10302     -0.189827   -0.0461264  -0.0232715   -0.189605     -0.0402158   0.0152708  -0.201124   -0.115268    0.0148188  -0.0163671   0.134993     0.0635184    0.0334901  -0.156287     -0.288838     0.185237     0.141996     -0.003462    -0.0961701   -0.0285216   -0.134521   -0.157257    -0.0630195  -0.00251524   0.104542
 -0.0725143    0.221496    0.111937    0.0927955    0.171044     -0.0507914   0.014816    0.0104259   0.0592469   0.135866   -0.0194865  -0.0445296   -0.0593195   -0.0840941  -0.0011326     0.207017    -0.18663     -0.000896275  -0.019952     0.0289683    0.0869319    0.0476603   0.207002     0.0465951  -0.127532    -0.0181432
  0.181158    -0.0501939  -0.211321   -0.11578     -0.199626     -0.0805017  -0.257377    0.656856    0.0999869  -0.148863    0.137751   -0.0146916   -0.410425    -0.0348071   0.487975      0.117953     0.121587    -0.457056     -0.150109    -0.314933     0.0258798    0.0293394  -0.339173     0.396447    0.0753757   -0.29137
  0.0633497   -0.058204    0.119601   -0.174526     0.246968      0.473213   -0.0627618   0.138403    0.346628   -0.117749    0.221516    0.100206     0.488942    -0.0107756   0.0577688    -0.00539672   0.224357    -0.508836     -0.0997995    0.260582    -0.248469     0.254903   -0.365887    -0.363804    0.209309    -0.043856
 -1.03466      0.0784747  -0.047981   -0.381486     0.34025      -0.112812    0.0479898   0.145103    0.272482   -0.130452    0.241263    0.172641    -0.321554     0.308144    0.0214882     0.272971     0.541653     0.226975     -0.0118802    0.133383     0.0749294    0.205279    0.0793178    0.23857    -0.16642      0.114372
 -0.583647     0.624529   -0.210525    0.80871     -0.280684      0.332816   -0.114867    0.0793535   0.26598     0.149885   -0.177172    0.376033    -0.770668    -0.460874   -0.321564     -0.0340265    0.400177     0.0327423     0.860464     0.0631899    0.145909    -0.0610609   0.618509     0.421456   -0.162619     0.188441
 -0.0874152    0.114805   -0.975634   -0.27203      0.0531753    -0.0178794   0.279239   -0.502132    0.0833183  -0.0388256   0.578823    0.130243     0.141724     0.0344373  -0.34846       0.769669     0.0961122    0.0317389     1.03496     -0.184167     0.194098     0.132203    0.00812822   0.318586    0.00897193   0.0610637
 -0.0817416    0.13005     0.378605    0.51407      0.0212744     0.106057    0.563223    0.149774    0.371489   -0.295034    0.374756   -0.853358    -0.346303     0.170705   -0.0269908     0.159921     0.126912    -0.0580968     0.768713    -0.153587     0.409373    -0.0924412  -0.0840724   -0.18773    -0.254789    -0.0655837
 -0.451345     0.356241    0.216116   -0.00791318   0.0368481     0.027338    0.270712    0.158851   -0.252557   -0.0220252  -0.0332113   0.109522    -0.151881    -0.0452299  -0.433628      0.41204     -0.709634     0.0874861    -0.231887     0.127926     0.36636     -0.420596    0.297575     0.197366   -0.333843     0.0497561
 -0.223216     0.524826   -0.0191752   0.127748     0.381009      0.0738333  -0.0320326  -0.211376   -0.397474   -0.260637    0.242133   -0.186582     0.355289    -0.332722    0.0743349     0.151239    -0.714708     0.0385925    -0.186077     0.224401     0.513845     0.499082    0.18944      0.0698358  -0.0539373    0.198459
  0.222917    -0.462372    0.128533    0.132084    -0.357587      0.306661    0.211548   -0.0398195  -0.25081    -0.542385    0.146627    0.48809      0.0935249    0.155683   -0.445332      0.0019864    0.21625      0.426475      0.207453    -0.573467     0.623044    -0.447543    0.534239     0.718057   -0.0207696    0.779069
  0.682672     0.770049    0.578274    0.192243     0.34337       1.03187    -0.203896    0.156674   -0.065156   -0.487009    0.394433    0.41008     -0.275464     0.133413   -0.297265     -0.0404858   -0.0632518   -0.0385174    -0.0218904   -0.776499    -0.727479    -0.0916824   0.0439731    0.445037    0.287735     0.204911
 -0.33814      0.161236    0.303061    0.173089     0.477665      0.147395    0.255496   -0.118493    0.577621    0.408142   -0.395049    0.165161     0.448917    -0.554906   -0.32515       0.0320587    0.00164778  -0.214913     -0.247959    -0.0881472    0.26397      0.501723   -0.126802     0.188735   -1.04291     -0.122261
 -0.0113593   -0.17096     1.05526     0.209017     0.601181      0.0190864  -0.152025   -0.0221918   0.291564    0.443799    0.540183   -0.0388192    0.212381    -0.4499     -0.355094      0.447753     0.0626957   -0.563569     -0.703647    -0.46417      0.158637    -0.110593   -0.0249293   -0.138484   -0.185159     0.0590688
 -0.133344     0.192452    0.0818791   0.104752     0.599909     -0.287782   -0.554918    0.460968    0.0840814   0.817058    0.0938103  -0.347737    -0.35722     -0.803248    0.0834451     0.914609    -0.249497    -0.550501      0.627607    -0.393449     0.210927     0.647563    0.0638129    0.368591    0.00361533  -0.013986
  0.726132    -0.127577    0.424532   -0.24466      0.339991     -0.18895     0.0839234   0.0897062  -0.263722    0.587915   -0.0679081  -0.82418     -0.162137     0.29634     0.682106      0.274482    -0.0927547   -0.534008     -0.095023    -0.264808    -0.837505     0.565789   -0.280631    -0.253856    0.455369     0.0256046
 -0.119356    -0.0090476   0.526872    0.205654     0.116368      0.0373786  -0.246388    0.359229    0.390939    0.0763778   0.0693749   0.00816655  -0.190781    -0.0996633  -0.0605543    -0.043657     0.221537    -0.186669     -0.150248    -0.161866    -0.132274     0.149992   -0.0724846   -0.121233   -0.097913     0.0502671
 -0.422719    -0.087263   -0.53333    -0.34944      0.0540989    -0.0424228   0.327504   -0.0862238  -0.638789   -0.17002     0.0656811  -0.223785    -0.23941      0.249388    0.0222374     0.0342841   -0.190773     0.118401      0.120481     0.0887051    0.151532    -0.11155     0.0610021    0.223719   -0.202334     0.0828714
 -0.0279641    0.28013     0.0511012   0.183333     0.0317843     0.352185    0.404549   -0.724776   -0.142075   -0.102594   -0.0222393   0.534332     0.718833    -0.0100154  -0.691704     -0.399787    -0.407997     0.249044      0.00562286   0.378054    -0.0768336   -0.132239    0.0849989   -0.602798   -0.243142     0.214995
  0.491411    -0.193455    0.164712   -0.438894    -0.215438      0.0163475   0.568604   -0.298591    0.258096    0.282022   -0.0287024  -0.0543203    0.870352    -0.371932    0.424879      0.157716    -0.346195     0.378269     -0.278552     0.309179     0.342987    -0.153228    0.0503791   -0.240907    0.17802     -0.746833
  0.157301    -0.0095367  -0.824427    0.0378584   -0.458972      0.0470215  -0.349947   -0.139121   -0.213595   -0.504715   -0.0218351   0.276305    -0.0552811    0.490217    0.31721      -0.774676     0.40986      0.435389      0.500956     0.181711    -0.305606    -0.0119619  -0.253782    -0.359711    0.25439      0.176768
  0.00263311   0.362444    0.134455   -0.124632     0.00201871   -0.271427   -0.354703   -0.188045   -0.208086   -0.0472713   0.280619   -0.0682961   -0.275057     0.232242    0.483        -0.142533    -0.00578039   0.344449     -0.0209988    0.160507    -0.0541764   -0.341913    0.285367    -0.613101    0.707042     0.366568
  0.337757    -0.405769   -0.422055   -0.958614     0.0901017     0.244183   -0.437983    0.199492   -0.107854    0.39308    -0.201421    0.608505     0.131369    -0.208854    0.387649     -0.575554     0.535368    -0.108658     -0.126932     0.103859    -0.330059     0.155558   -0.0455365    0.243224    0.581853    -0.0322659
  0.594008     0.225906    0.448215    0.461736    -0.602847     -0.0207236  -0.448983    0.638042   -0.0555539   0.0784377  -0.826395    0.548021    -0.0462364   -0.153381    0.128283     -0.430922    -0.234618    -0.286714     -0.496438     0.534171    -0.611052     0.381393    0.543009     0.126747    0.327034     0.0127642
 -0.272793    -0.379373   -0.131908    0.178168    -0.423143     -1.2066      0.236816   -0.19774     0.507203    0.43224    -0.197905   -0.723283     0.0737887    0.0702181   0.330422      0.312502     0.0256621    0.350704      0.270804     0.285798     0.269692    -0.245553   -0.545155    -0.31164    -0.204579    -0.292885
  1.01444     -0.610252    0.713012    0.256484    -0.440143     -0.284877    0.215433    0.157552    0.1033     -0.0851202  -0.324911   -0.140781     0.131933     0.480423   -0.0874506    -0.408584     0.136455     0.00626965   -0.398012    -0.0361052    0.00969957  -0.347297   -0.435995    -0.043012    0.32569     -0.28109
  0.339163     0.548316    0.344268    0.890633    -0.596318     -0.700241    0.154587   -0.167978   -0.858159   -0.352248   -0.0172927  -0.37211      0.110421     0.154888   -0.000940585  -0.0846442   -0.561648    -0.0686232    -0.350845    -0.427542     0.394121    -0.41845     0.193033    -0.0423878   0.0131445   -0.186819
  0.455703     0.325016   -0.609583   -0.0967194    0.0267166     0.16807     0.503417   -0.148289   -0.671308   -0.444279   -0.409003    0.218855     0.0696723    0.0663904   0.203414      0.162193    -0.196391     0.203022      0.0808651    0.173124     0.157767    -0.224703    0.092214     0.774581    0.104707    -0.780131[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404950
[ Info: iteration 2, average log likelihood -1.404938
[ Info: iteration 3, average log likelihood -1.404926
[ Info: iteration 4, average log likelihood -1.404914
[ Info: iteration 5, average log likelihood -1.404903
[ Info: iteration 6, average log likelihood -1.404892
[ Info: iteration 7, average log likelihood -1.404882
[ Info: iteration 8, average log likelihood -1.404872
[ Info: iteration 9, average log likelihood -1.404862
[ Info: iteration 10, average log likelihood -1.404853
┌ Info: EM with 100000 data points 10 iterations avll -1.404853
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.002912e+05
      1       7.057099e+05      -1.945813e+05 |       32
      2       6.866706e+05      -1.903929e+04 |       32
      3       6.802046e+05      -6.465977e+03 |       32
      4       6.772329e+05      -2.971737e+03 |       32
      5       6.755204e+05      -1.712460e+03 |       32
      6       6.743464e+05      -1.174006e+03 |       32
      7       6.734188e+05      -9.276442e+02 |       32
      8       6.726563e+05      -7.625360e+02 |       32
      9       6.720641e+05      -5.921925e+02 |       32
     10       6.715349e+05      -5.291283e+02 |       32
     11       6.710775e+05      -4.574558e+02 |       32
     12       6.707210e+05      -3.565251e+02 |       32
     13       6.704104e+05      -3.105165e+02 |       32
     14       6.701660e+05      -2.443953e+02 |       32
     15       6.699413e+05      -2.247817e+02 |       32
     16       6.697595e+05      -1.818002e+02 |       32
     17       6.695822e+05      -1.772842e+02 |       32
     18       6.694109e+05      -1.712394e+02 |       32
     19       6.692421e+05      -1.688149e+02 |       32
     20       6.690762e+05      -1.659110e+02 |       32
     21       6.689067e+05      -1.695506e+02 |       32
     22       6.687533e+05      -1.533247e+02 |       32
     23       6.686092e+05      -1.440946e+02 |       32
     24       6.684836e+05      -1.256476e+02 |       32
     25       6.683688e+05      -1.148176e+02 |       32
     26       6.682592e+05      -1.095642e+02 |       32
     27       6.681620e+05      -9.719822e+01 |       32
     28       6.680844e+05      -7.766124e+01 |       32
     29       6.680165e+05      -6.782014e+01 |       32
     30       6.679347e+05      -8.181942e+01 |       32
     31       6.678550e+05      -7.975234e+01 |       32
     32       6.677747e+05      -8.022140e+01 |       32
     33       6.676983e+05      -7.647847e+01 |       32
     34       6.676295e+05      -6.873112e+01 |       32
     35       6.675585e+05      -7.099393e+01 |       32
     36       6.674756e+05      -8.288521e+01 |       32
     37       6.673912e+05      -8.449488e+01 |       32
     38       6.673189e+05      -7.225022e+01 |       32
     39       6.672430e+05      -7.587625e+01 |       32
     40       6.671708e+05      -7.218372e+01 |       32
     41       6.671046e+05      -6.622115e+01 |       32
     42       6.670488e+05      -5.581229e+01 |       32
     43       6.669969e+05      -5.194027e+01 |       32
     44       6.669506e+05      -4.621996e+01 |       32
     45       6.669064e+05      -4.426138e+01 |       32
     46       6.668592e+05      -4.723297e+01 |       32
     47       6.668115e+05      -4.768216e+01 |       32
     48       6.667726e+05      -3.887433e+01 |       32
     49       6.667357e+05      -3.688005e+01 |       32
     50       6.667008e+05      -3.488590e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 666700.8328613923)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416901
[ Info: iteration 2, average log likelihood -1.411811
[ Info: iteration 3, average log likelihood -1.410353
[ Info: iteration 4, average log likelihood -1.409236
[ Info: iteration 5, average log likelihood -1.408143
[ Info: iteration 6, average log likelihood -1.407239
[ Info: iteration 7, average log likelihood -1.406654
[ Info: iteration 8, average log likelihood -1.406318
[ Info: iteration 9, average log likelihood -1.406115
[ Info: iteration 10, average log likelihood -1.405977
[ Info: iteration 11, average log likelihood -1.405871
[ Info: iteration 12, average log likelihood -1.405785
[ Info: iteration 13, average log likelihood -1.405711
[ Info: iteration 14, average log likelihood -1.405646
[ Info: iteration 15, average log likelihood -1.405588
[ Info: iteration 16, average log likelihood -1.405536
[ Info: iteration 17, average log likelihood -1.405489
[ Info: iteration 18, average log likelihood -1.405446
[ Info: iteration 19, average log likelihood -1.405406
[ Info: iteration 20, average log likelihood -1.405369
[ Info: iteration 21, average log likelihood -1.405334
[ Info: iteration 22, average log likelihood -1.405302
[ Info: iteration 23, average log likelihood -1.405272
[ Info: iteration 24, average log likelihood -1.405243
[ Info: iteration 25, average log likelihood -1.405216
[ Info: iteration 26, average log likelihood -1.405191
[ Info: iteration 27, average log likelihood -1.405167
[ Info: iteration 28, average log likelihood -1.405143
[ Info: iteration 29, average log likelihood -1.405121
[ Info: iteration 30, average log likelihood -1.405100
[ Info: iteration 31, average log likelihood -1.405080
[ Info: iteration 32, average log likelihood -1.405060
[ Info: iteration 33, average log likelihood -1.405042
[ Info: iteration 34, average log likelihood -1.405023
[ Info: iteration 35, average log likelihood -1.405006
[ Info: iteration 36, average log likelihood -1.404989
[ Info: iteration 37, average log likelihood -1.404973
[ Info: iteration 38, average log likelihood -1.404957
[ Info: iteration 39, average log likelihood -1.404942
[ Info: iteration 40, average log likelihood -1.404927
[ Info: iteration 41, average log likelihood -1.404913
[ Info: iteration 42, average log likelihood -1.404899
[ Info: iteration 43, average log likelihood -1.404885
[ Info: iteration 44, average log likelihood -1.404872
[ Info: iteration 45, average log likelihood -1.404859
[ Info: iteration 46, average log likelihood -1.404846
[ Info: iteration 47, average log likelihood -1.404834
[ Info: iteration 48, average log likelihood -1.404822
[ Info: iteration 49, average log likelihood -1.404810
32×26 Array{Float64,[ Info: iteration 50, average log likelihood -1.404799
┌ Info: EM with 100000 data points 50 iterations avll -1.404799
└ 59.0 data points per parameter
2}:
 -0.36012     0.303588   -0.167577     0.646204    -0.471193    0.298821     0.291308    0.145378     0.321916   -0.00749867  -0.0822868    0.0910743  -0.515037     -0.298346   -0.232947    -0.000298996  -0.0902537     0.267523     0.799711     0.0424467    0.650985   -0.216704     0.362106     0.441589    -0.482066    -0.124789
 -0.601315   -0.0444845  -0.527661    -0.455724     0.0559817   0.0887235    0.168552   -0.450783     0.121771    0.0998626    0.585745    -0.190997   -0.343322      0.206442   -0.228438     0.583622      0.450477      0.213234     0.841754    -0.103987    -0.185486    0.301781    -0.0499625    0.410044    -0.172457     0.463531
 -0.159794    0.0605484   0.73954      0.0576782    0.544456   -0.243152    -0.137981    0.280335     0.179231    0.47343      0.449796    -0.442234   -0.274139     -0.532596   -0.0156749    0.942502     -0.171146     -0.458839    -0.105459    -0.670549     0.335679    0.079972     0.197997     0.160824    -0.220064    -0.10168
 -0.0935748  -0.0619187   0.0536872   -0.28389     -0.237316   -0.328625    -0.531796   -0.255294     0.0332022   0.128176     0.225731    -0.019661   -0.386015      0.300587    0.387859    -0.292216      0.306193      0.386879     0.0129035    0.14538     -0.254142   -0.441962    -0.0313387   -0.797165     0.527818     0.302327
 -0.0164372  -0.361144    0.301831    -0.416793     0.273028    0.718884     0.021167    0.106592     0.729579    0.134536     0.265919     0.0727514   0.555441     -0.0667653  -0.326963     0.245625      0.144292     -0.613942    -0.117186     0.237234    -0.265925    0.145326    -0.766856    -0.393266    -0.0358499   -0.226384
 -0.0191906   0.0474028   0.0033615   -0.0580346    0.0443179  -0.0353714   -0.0523749   0.00399146  -0.0445729   0.110746    -0.0400844   -0.0113468  -0.00105598   -0.0569944   0.0262918    0.0680159    -0.117019      0.00941921  -0.0348451    0.0627649    0.0256228  -0.00246871   0.0533376   -0.00841826   0.00861798  -0.0441218
 -0.815622   -0.0158831   0.311991     0.341226     0.560453   -0.1985      -0.417064    0.192677     0.124178    0.051628    -0.241844    -0.417859   -0.777392      0.0166505  -0.0746954   -0.156073     -0.0290041     0.0201845    0.182793    -0.0695959   -0.301172   -0.277355     0.404365    -0.405528    -0.521666     0.591485
 -0.122094   -0.322232   -0.539564    -0.228197    -0.0282701   0.486711    -0.0642157   0.309756    -0.567693   -0.938192     0.0183175   -0.290227    0.0546579     0.140336   -0.00960104   0.11876      -0.212373      0.0126734    0.214631     0.0427937    0.535593   -0.524346    -0.222488     0.280756     0.308251    -0.0485161
 -0.365377    1.15032    -0.0789899    0.00722662   0.628233    0.256745    -0.0194871  -0.43233     -0.362618    0.0285263    0.31266     -0.206698    0.158389     -0.355567    0.232557     0.114126     -0.791235      0.123628     0.157277     0.306908     0.35887     0.0897       0.55851     -0.294621     0.258908     0.307176
  0.302981   -0.205754   -0.56145     -0.135855    -0.119093    0.23107     -0.226466    0.469658     0.48463     0.466217    -0.0960977    0.351839   -0.210269     -0.149087    0.389983    -0.341409      0.659476     -0.713198     0.196448    -0.156061    -0.376499   -0.00829535   0.0359583   -0.0271629    0.0702921   -0.426186
 -0.403344    0.0089316   0.582658     0.0893114    0.677303    0.00887141  -0.270777   -0.105501     0.477925    0.708375    -0.209297     0.411359    0.705667     -0.730556   -0.271206     0.0404359     0.183868     -0.0309348   -0.500186     0.188819     0.0221104   0.599516     0.21871     -0.138339    -0.509225     0.119831
 -0.472375    0.217263    0.0932229   -0.171543     0.18141     0.019976    -0.0318207   0.771104     0.384973   -0.263934     0.353387    -0.0871422  -0.423995      0.204065    0.48741      0.237596      0.253647     -0.161317    -0.0905385   -0.00623612   0.288686    0.350075    -0.109948     0.339448     0.078932    -0.082567
  0.654966   -0.0808604   0.31721     -0.140442     0.377247   -0.179592    -0.243599   -0.0226882   -0.239742    0.518193    -0.0661574   -0.88173    -0.0741051     0.125943    0.601082     0.188505     -0.0486806    -0.589241    -0.0208279   -0.154745    -0.705706    0.510373    -0.321191    -0.367254     0.483072     0.164625
 -0.0643779   0.139355    0.453128     0.505689     0.177196   -0.182782    -0.0380306  -0.41378      0.0870421   0.167099     0.393773    -0.333814    0.358671     -0.343216   -0.525102     0.214134     -0.569088      0.0816352   -0.194399    -0.0810367    0.474242    0.346084    -0.357527    -0.0463146   -0.503094     0.283958
 -0.0234224   0.189524   -0.212436    -0.115776     0.467008    0.467832     0.565906   -0.0251204   -0.152443   -0.0214761   -0.440952     0.235223    0.247669     -0.245123   -0.14381      0.0879901    -0.213778     -0.414388    -0.179052    -0.139227     0.383306    0.452825     0.0288519    0.835318    -0.601827    -0.434026
  0.302359   -0.404784    0.5427       0.906112    -0.397149   -0.424098     0.495936    0.071768     0.399874   -0.0309211   -0.310015    -0.785813    0.00376074    0.453934   -0.0531375   -0.243949      0.208237      0.0472143    0.46352     -0.0905982    0.370019   -0.428891    -0.559991    -0.280994    -0.0704065   -0.219335
  0.0498718   0.0860744  -0.810201    -0.217566    -0.213677    0.148997    -0.400963    0.123631    -0.58598    -0.455368    -0.263555     0.471704   -0.129504      0.394197    0.240739    -1.02157       0.290642      0.222552     0.242124     0.328659    -0.269711    0.27696     -0.0120953    0.0328505    0.189815     0.211958
 -0.219359    0.301698    0.354005     0.149648     0.0223738   0.196092     0.751863   -0.411875     0.0225088  -0.289157    -0.140259     0.257847    0.412388      0.0445703  -0.151367    -0.634886     -0.200787      0.282367    -0.333106     0.0692456    0.153775   -0.345343     0.227433    -0.606784    -0.963969    -0.0171024
 -0.152369   -0.415875   -0.421086    -0.49144      0.0103899  -0.312074    -0.258528   -0.0117655   -0.133339    0.745587    -0.561117     0.0672206  -0.241986     -0.166331   -0.508861    -0.0294007    -0.258823      0.124451    -0.108676     0.2782      -0.176719    0.046464    -0.0860739    0.0592641   -0.300218    -0.202301
  0.536553   -0.16702     0.765988     0.445939    -0.404538   -0.0458088   -0.302214    0.706138    -0.0246093  -0.0227275   -0.693382     0.133647    0.000368444   0.140595    0.114045    -0.586269     -0.0195753    -0.336426    -0.914447     0.279061    -0.260524    0.108192     0.104537     0.107991     0.335154    -0.0580869
  0.523738   -0.360382   -0.0845712   -0.15041     -0.496289    0.0637375   -0.126047   -0.787929    -0.194621    0.130323    -0.0412438    0.0365785   0.7754        0.134143   -0.363057    -0.503155     -0.492285      0.49202      0.0278259    0.355745    -0.0794665   0.0605686   -0.0866187   -0.652277     0.130075     0.010114
 -0.443458    0.0492525   0.00725359   0.00394378   0.158119    0.19727      0.442522   -0.161774    -0.27754    -0.0587024    0.0509337    0.709426    0.254464      0.410871   -0.916508     0.448986     -0.0329403     0.399083     0.0645162   -0.0148988    0.252469   -0.365228     0.680644     0.437559     0.0575856    0.525901
 -0.169891    0.0759504   0.15667      0.0883437    0.130802    0.060507    -0.122239    0.143223     0.0779319   0.0964869    0.0342338   -0.0010113  -0.147431     -0.150947   -0.105958     0.060364      0.0658856    -0.140201    -0.00318392  -0.0853352   -0.0582286   0.147684    -0.0316057    0.0313256   -0.131574     0.0860854
 -0.301748    0.23567    -0.934278     0.264294     0.0478337  -0.821125     0.0548181  -0.198319     0.228374    0.161476     0.0173205   -0.0373705   0.254653     -0.0654076   0.176088     0.482534      0.229739      0.121452     0.499426    -0.0394111    0.0566758   0.28485     -0.531745    -0.282825     0.00927427  -0.317452
  0.365319    0.50243     0.189716     0.691601    -0.626222   -0.611024     0.0421128  -0.0390491   -0.856947   -0.300114     0.0513375   -0.317359   -0.0821238     0.0837347   0.0614522    0.00832186   -0.503123     -0.0640232   -0.265701    -0.434043     0.430641   -0.452233     0.231662     0.158096     0.138602    -0.0787906
  0.558179   -1.12428     0.082599    -0.514554    -0.440417   -0.180998    -0.0948607  -0.0966879    0.0699649   0.0561702   -0.0742713    0.522906    0.000492205  -0.117828    0.179748    -0.0186427     0.283852      0.51387     -0.067824    -0.657547     0.3988     -0.259199     0.070623     0.997182     0.440574     0.575418
  0.791854    0.674776    0.403968     0.182889     0.134224    0.942358    -0.20579     0.182117    -0.113081   -0.536944     0.42844      0.351859   -0.250908      0.133165   -0.184023    -0.0625796    -0.000950207  -0.0422776    0.0753262   -0.816042    -0.607036   -0.155188    -0.00555569   0.429302     0.353939     0.199093
  0.417937    0.629536   -0.00156597  -0.252852    -0.169743   -0.500766    -0.0724557  -0.246602     0.0417416  -0.00189263   0.287401     0.515875   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.322891     -0.0185858  -0.136561     0.927036     -0.469504      0.108753     0.0172087    0.262294    -0.514129    0.252863     0.355607     0.288691    -0.0620341   -0.473538
  0.629799   -0.222208   -0.0845925   -0.579465    -0.150922   -0.193173     0.676012    0.126597    -0.103381    0.208481    -0.0848127   -0.0851746   0.159698      0.0858052   0.842817     0.091908     -0.0804406     0.436414    -0.0724923    0.0176185   -0.141174   -0.278237    -0.0241301    0.0764724    0.558959    -0.814048
  0.179498    0.598534    0.0426341    0.298374     0.117197    0.160038     0.199045   -0.178737    -0.215094   -0.594468     0.0892522    0.443746    0.57124       0.0639934   0.18876     -0.191556      0.137014     -0.109179    -0.0484462    0.503493     0.133384   -0.0443458    0.159506    -0.345298     0.717377    -0.00348632
 -0.628175   -0.608799   -0.36755     -0.52981     -0.51635    -0.716914     0.642464   -0.448667    -0.0112577   0.235236     0.00444052  -0.642023    0.273196     -0.123541    0.171751     0.161408     -0.0662077     0.172231    -0.134106     0.628756     0.819559   -0.163714    -0.252397    -0.0435444   -0.500524    -0.079361
  0.0806714  -0.253555    0.116092     0.0972284   -0.128167    0.164913     0.119135   -0.115067     0.0763436  -0.0305379   -0.0492038    0.110677    0.0589688     0.130744   -0.294349    -0.431738      0.35394       0.00497989  -0.02624     -0.233478    -0.0744574  -0.156304    -0.182061    -0.0494528   -0.174026     0.292709[ Info: iteration 1, average log likelihood -1.404787
[ Info: iteration 2, average log likelihood -1.404776
[ Info: iteration 3, average log likelihood -1.404766
[ Info: iteration 4, average log likelihood -1.404755
[ Info: iteration 5, average log likelihood -1.404745
[ Info: iteration 6, average log likelihood -1.404735
[ Info: iteration 7, average log likelihood -1.404725
[ Info: iteration 8, average log likelihood -1.404716
[ Info: iteration 9, average log likelihood -1.404706
[ Info: iteration 10, average log likelihood -1.404697
┌ Info: EM with 100000 data points 10 iterations avll -1.404697
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
