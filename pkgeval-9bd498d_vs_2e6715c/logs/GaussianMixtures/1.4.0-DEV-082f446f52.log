Julia Version 1.4.0-DEV.674
Commit 082f446f52 (2020-01-02 16:59 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed DataAPI ──────────── v1.1.0
 Installed OpenBLAS_jll ─────── v0.3.7+2
 Installed GaussianMixtures ─── v0.3.0
 Installed Rmath ────────────── v0.6.0
 Installed JLD ──────────────── v0.9.1
 Installed Distances ────────── v0.8.2
 Installed SpecialFunctions ─── v0.9.0
 Installed Clustering ───────── v0.13.3
 Installed CMake ────────────── v1.1.2
 Installed LegacyStrings ────── v0.4.1
 Installed StatsFuns ────────── v0.9.3
 Installed Compat ───────────── v2.2.0
 Installed FillArrays ───────── v0.8.2
 Installed BinaryProvider ───── v0.5.8
 Installed ScikitLearnBase ──── v0.5.0
 Installed SortingAlgorithms ── v0.3.1
 Installed QuadGK ───────────── v2.3.1
 Installed URIParser ────────── v0.4.0
 Installed Arpack ───────────── v0.4.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed BinDeps ──────────── v1.0.0
 Installed Parameters ───────── v0.12.0
 Installed OrderedCollections ─ v1.1.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Blosc ────────────── v0.5.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed Missings ─────────── v0.4.3
 Installed Distributions ────── v0.21.11
 Installed HDF5 ─────────────── v0.12.5
 Installed PDMats ───────────── v0.9.10
 Installed NearestNeighbors ─── v0.4.4
 Installed StatsBase ────────── v0.32.0
 Installed DataStructures ───── v0.17.6
 Installed StaticArrays ─────── v0.12.1
 Installed FileIO ───────────── v1.2.1
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+2
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_LfYl0P/Project.toml`
 [no changes]
  Updating `/tmp/jl_LfYl0P/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_QnITgD/Project.toml`
 [no changes]
  Updating `/tmp/jl_QnITgD/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_1fJ3lT/Project.toml`
 [no changes]
  Updating `/tmp/jl_1fJ3lT/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_eV01zO/Project.toml`
 [no changes]
  Updating `/tmp/jl_eV01zO/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_Pq3uja/Project.toml`
 [no changes]
  Updating `/tmp/jl_Pq3uja/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_Pq3uja/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.0807833362558149e7, [90858.5134256829, 9141.486574317096], [1141.1406838496785 -15639.921262057695 -1447.0559384016065; -1168.8138552043015 15766.36969481096 1466.364721177063], [[90309.50057611876 1725.7421230271689 -7.36933610917491; 1725.7421230271693 71681.90424985289 -1430.500269623158; -7.369336109174938 -1430.5002696231581 90217.07229958462], [8991.02896146978 -1913.30477744566 112.34690780678393; -1913.30477744566 28254.641359025718 2294.879965422571; 112.34690780678395 2294.879965422571 8617.883776996288]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.757659e+03
      1       1.209828e+03      -5.478310e+02 |        6
      2       1.072453e+03      -1.373748e+02 |        4
      3       9.715765e+02      -1.008764e+02 |        5
      4       9.199725e+02      -5.160392e+01 |        2
      5       9.081456e+02      -1.182694e+01 |        2
      6       8.867687e+02      -2.137694e+01 |        0
      7       8.867687e+02       0.000000e+00 |        0
K-means converged with 7 iterations (objv = 886.7686562743065)
┌ Info: K-means with 272 data points using 7 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.070206
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.844189
[ Info: iteration 2, lowerbound -3.717135
[ Info: iteration 3, lowerbound -3.565978
[ Info: iteration 4, lowerbound -3.380848
[ Info: iteration 5, lowerbound -3.183070
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.987939
[ Info: iteration 7, lowerbound -2.802659
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.643953
[ Info: iteration 9, lowerbound -2.525569
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.436897
[ Info: iteration 11, lowerbound -2.378645
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.342216
[ Info: iteration 13, lowerbound -2.316501
[ Info: iteration 14, lowerbound -2.307526
[ Info: dropping number of Gaussions to 2
[ Info: iteration 15, lowerbound -2.302980
[ Info: iteration 16, lowerbound -2.299263
[ Info: iteration 17, lowerbound -2.299257
[ Info: iteration 18, lowerbound -2.299255
[ Info: iteration 19, lowerbound -2.299254
[ Info: iteration 20, lowerbound -2.299253
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan  2 20:08:29 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan  2 20:08:37 2020: K-means with 272 data points using 7 iterations
11.3 data points per parameter
, Thu Jan  2 20:08:40 2020: EM with 272 data points 0 iterations avll -2.070206
5.8 data points per parameter
, Thu Jan  2 20:08:42 2020: GMM converted to Variational GMM
, Thu Jan  2 20:08:51 2020: iteration 1, lowerbound -3.844189
, Thu Jan  2 20:08:51 2020: iteration 2, lowerbound -3.717135
, Thu Jan  2 20:08:51 2020: iteration 3, lowerbound -3.565978
, Thu Jan  2 20:08:51 2020: iteration 4, lowerbound -3.380848
, Thu Jan  2 20:08:51 2020: iteration 5, lowerbound -3.183070
, Thu Jan  2 20:08:51 2020: dropping number of Gaussions to 7
, Thu Jan  2 20:08:51 2020: iteration 6, lowerbound -2.987939
, Thu Jan  2 20:08:51 2020: iteration 7, lowerbound -2.802659
, Thu Jan  2 20:08:51 2020: dropping number of Gaussions to 6
, Thu Jan  2 20:08:51 2020: iteration 8, lowerbound -2.643953
, Thu Jan  2 20:08:51 2020: iteration 9, lowerbound -2.525569
, Thu Jan  2 20:08:51 2020: dropping number of Gaussions to 4
, Thu Jan  2 20:08:51 2020: iteration 10, lowerbound -2.436897
, Thu Jan  2 20:08:51 2020: iteration 11, lowerbound -2.378645
, Thu Jan  2 20:08:51 2020: dropping number of Gaussions to 3
, Thu Jan  2 20:08:51 2020: iteration 12, lowerbound -2.342216
, Thu Jan  2 20:08:51 2020: iteration 13, lowerbound -2.316501
, Thu Jan  2 20:08:51 2020: iteration 14, lowerbound -2.307526
, Thu Jan  2 20:08:51 2020: dropping number of Gaussions to 2
, Thu Jan  2 20:08:51 2020: iteration 15, lowerbound -2.302980
, Thu Jan  2 20:08:51 2020: iteration 16, lowerbound -2.299263
, Thu Jan  2 20:08:51 2020: iteration 17, lowerbound -2.299257
, Thu Jan  2 20:08:51 2020: iteration 18, lowerbound -2.299255
, Thu Jan  2 20:08:51 2020: iteration 19, lowerbound -2.299254
, Thu Jan  2 20:08:51 2020: iteration 20, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 21, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 22, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 23, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 24, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 25, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 26, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 27, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 28, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 29, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 30, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 31, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 32, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 33, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 34, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 35, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 36, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 37, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 38, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 39, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 40, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 41, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 42, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 43, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 44, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 45, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 46, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 47, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 48, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 49, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: iteration 50, lowerbound -2.299253
, Thu Jan  2 20:08:51 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398618, 178.04509222601385]
β = [95.95490777398618, 178.04509222601385]
m = [2.000229257775371 53.8519871724613; 4.250300733269909 79.28686694436183]
ν = [97.95490777398618, 180.04509222601385]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119484036 -0.008953123827345958; 0.0 0.01274866477740938], [0.184041555474848 -0.0076440490423277385; 0.0 0.00858170516633361]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.9814210161343478
avll from llpg:  -0.9814210161343564
avll direct:     -0.9814210161343564
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9873254811734253
avll from llpg:  -0.9873254811734253
avll direct:     -0.9873254811734254
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0855559    0.254226    -0.119933     0.027824    0.0976425     0.0300306   -0.0779075   -0.153486    -0.12718      0.0699947    0.124096     0.0130248    0.014843    -0.00515333    0.00317472   0.095842    -0.181729      0.168327   -0.0455592    0.0889711    0.0214553    0.154967    -0.156914     0.110157    -0.123052    0.123107
  0.0454945   -0.122772    -0.0203567    0.118114    0.0996725    -0.030194    -0.147444    -0.0468829   -0.0166099   -0.0143128   -0.00306338  -0.135986    -0.0302109    0.0329819     0.11596     -0.0154857    0.15514      -0.0623628   0.0107802   -0.0431742    0.0481358    0.00525886  -0.102778     0.0136803    0.0155197   0.0227872
  0.0254977    0.0498659   -0.0101421    0.121378   -0.0970242     0.0742922    0.083457    -0.153464    -0.157013     0.0594172   -0.00583157   0.0584651   -0.0482096   -0.000200953   0.065132    -0.231612    -0.218683     -0.194799    0.200874    -0.170506     0.0980926    0.0637063   -0.0370435    0.0787111   -0.0441623  -0.0252583
 -0.147061     0.0646907    0.0135312   -0.146426   -0.0801585     0.0551033   -0.155649     0.0631696    0.011992     0.0257005   -0.170136    -0.0090471   -0.095065    -0.0892962     0.161508    -0.109834    -0.00467513   -0.0339052  -0.0404657    0.076093    -0.031711     0.224291     0.0172361   -0.0564861   -0.0962089   0.026065
 -0.114399     0.0587678   -0.144674     0.0708042   0.158719     -0.197248     0.0334773    0.100264    -0.0556278   -0.0238967    0.0124862   -0.0106935   -0.112091    -0.0706565     0.0728811    0.029722     0.000485935  -0.0095635  -0.0658319    0.248037     0.0815168    0.0933867   -0.135025    -0.0131459    0.0772668  -0.0598183
  0.00500197   0.0497761    0.0310255    0.0263503  -0.0825931    -0.0287308   -0.143396    -0.0404509   -0.0118506   -0.00231082   0.250516    -0.105957    -0.103597    -0.061353      0.0413104   -0.0054686   -0.0450918    -0.100965    0.0826219   -0.113688     0.0115825   -0.0227892    0.185689     0.0380497   -0.138056    0.0167414
  0.0903915   -0.0110844    0.112049    -0.0939025  -0.0160909     0.0932347    0.078985    -0.0170779    0.0954743   -0.0983147    0.00991449  -0.0577247   -0.0777569   -0.0520063    -0.0137854    0.0568806   -0.0756479     0.0924486   0.0950765    0.081656    -0.0100865   -0.00454353   0.0144774   -0.118452    -0.0410109   0.0146193
  0.077114     0.0352041   -0.00218091  -0.0265255   0.0571243     0.0392827   -0.138551    -0.104214     0.180188     0.0909788   -0.0914982   -0.0451349   -0.148167    -0.0763648    -0.17446      0.0319089   -0.106908      0.0479705   0.231762    -0.0297159    0.113404    -0.114918     0.134895    -0.159178     0.0396382   0.0409318
  0.0484336    0.114938     0.051385     0.0314271   0.154471      0.127764     0.0901074    0.0639629   -0.0884811   -0.0558317    0.0335803   -0.13578      0.0506989   -0.078238     -0.132664     0.0183821   -0.121854      0.0386406   0.127317     0.185183    -0.0966692    0.0886749    0.0756766   -0.0226018    0.0488382  -0.119509
 -0.0737306    0.00506926   0.0447887   -0.0443125   0.0600103    -0.139842    -0.0564962    0.01009     -0.0652781   -0.131004    -0.149318    -0.0856191    0.118184     0.0816358     0.172897    -0.0481874   -0.0886076     0.0859435  -0.0141221    0.182333     0.0339155   -0.0457097    0.0779492   -0.221        0.106327    0.0532549
 -0.0144552   -0.113853    -0.208137    -0.130945   -0.0276411     0.18464      0.0960294    0.0561784   -0.0674427   -0.0727386   -0.0827722    0.0727477    0.0776083    0.0483676    -0.0158826   -0.0635231    0.116906     -0.0961177   0.14047      0.0277826   -0.00991436   0.171555     0.00362393   0.0994666   -0.0257526   0.0996598
 -0.0513776    0.0208562    0.0793239    0.046807   -0.035057     -0.00559227  -0.203449    -0.104944    -0.0232755   -0.110421    -0.115682    -0.00632605   0.0549453    0.0723982     0.0652963   -0.117222     0.0652596     0.0580774   0.0242919   -0.128325     0.0219705   -0.0954113    0.0537974    0.00388639   0.0318516   0.0699701
 -0.0582588   -0.043878    -0.0497287   -0.0933119  -0.154062      0.0158811   -0.079615     0.165468    -0.111827    -0.167902     0.227719     0.00875691   0.0958547    0.0161921    -0.0268917    0.145257    -0.14376       0.0359921   0.134273    -0.0340895   -0.0816325    0.0502564    0.140887    -0.0177462    0.13283    -0.0176115
  0.0366085   -0.165542    -0.235454     0.142426   -0.146208     -0.119181    -0.00260331   0.0666784   -0.0331813   -0.152109    -0.0691161   -0.0947       0.138474     0.0488775    -0.124909     0.188727    -0.120496      0.122402   -0.0747655   -0.157504     0.0618542    0.0183148    0.173664     0.230415    -0.149802   -0.156164
  0.0202429   -0.0999295    0.0870963   -0.084969   -0.142277      0.104959     0.190252     0.0342864   -0.0493941   -0.0732324   -0.0824589    0.180494     0.0746144   -0.0988141     0.0905411    0.126831     0.0331732     0.123317   -0.156369     0.0884295   -0.0372548   -0.0184002   -0.286306     0.0401436    0.0027213  -0.0563366
 -0.00969211   0.123218    -0.0751573   -0.0349712   0.11661       0.0841067    0.0304292   -0.0259719    0.131261    -0.0390128   -0.084413     0.177531     0.1226       0.147198     -0.00801942  -0.178595     0.19028      -0.0182992   0.0141278    0.0913653    0.126624     0.220658     0.0590757    0.0144442   -0.116368   -0.0773669
  0.0274103    0.124842     0.0633915   -0.108685   -0.0978556    -0.0420912   -0.0838624   -0.0360717   -0.1892      -0.0132841   -0.19845     -0.00680112  -0.0107216    0.070834     -0.0288919   -0.144636     0.221046      0.0187599  -0.0283979   -0.039424     0.00303923   0.0386244   -0.0275823    0.0565609    0.020919   -0.0783089
  0.118596    -0.0721266   -0.129879     0.288312   -0.102671      0.0446212   -0.0101986    0.107764     0.121223    -0.152587     0.0221305   -0.207786    -0.0507085   -0.19176       0.0160189   -0.0340823    0.0431166    -0.16631    -0.00223573   0.0901123   -0.00891673  -0.154835     0.0582042   -0.0024214   -0.0884364   0.127722
  0.0220492    0.17077     -0.250377     0.0805769   0.0809073     0.0343904   -0.0124164    0.0312922   -0.0686162    0.0125032   -0.108655     0.0410698    0.0105845   -0.0149638    -0.0631101    0.0647755   -0.15298      -0.106825    0.135404    -0.0955411    0.0921173    0.0432839    0.0523921   -0.117872    -0.0188262  -0.13896
 -0.0897797   -0.125117    -0.0286049    0.122852   -0.159125      0.0703825    0.0394492   -0.068116    -0.095295     0.00105192  -0.0882942    0.190057    -0.0600365   -0.118727     -0.0746442    0.115513     0.106547     -0.0330852  -0.0482734    0.0596894   -0.0125304   -0.171382     0.104704    -0.158904     0.234971    0.112841
  0.0264995   -0.154164     0.129899     0.0917248  -0.157994     -0.0547694    0.0300696    0.152913     0.151771     0.130263    -0.0126362    0.160436     0.0587083   -0.104106     -0.0752068   -0.00904875  -0.149885     -0.0884468   0.0727124    0.00444996  -0.0983303    0.0160342    0.0536341   -0.0874065    0.116353   -0.00679569
 -0.0870268    0.0438732   -0.0281995    0.158965   -0.0483362     0.0201006   -0.0749691   -0.039364    -0.0760471   -0.0551708    0.0755806   -0.0533521   -0.00156952  -0.116058     -0.055223     0.0504588   -0.180264     -0.013865   -0.038032    -0.140892     0.0659711   -0.178846    -0.00533722  -0.0925767    0.0229334  -0.181936
  0.111539     0.0515593    0.0105175   -0.134432   -0.147366      0.0596605   -0.0429717    0.185183     0.0883533   -0.0820518   -0.184118    -0.00105583   0.136036    -0.0759818    -0.00351874  -0.108513     0.00516142   -0.0950141  -0.103713     0.00635998  -0.0899581    0.0210548    0.00896374  -0.0241687   -0.0419159   0.123356
 -0.0450203    0.0393904    0.00379522   0.165296    0.0605976    -0.0496801    0.07789     -0.0571866    0.108507     0.194199     0.015561     0.190458    -0.0279058    0.101923      0.0148513    0.0980173   -0.0876047     0.0911754   0.0552032    0.0700854    0.0825896   -0.1547      -0.282187     0.0873774   -0.0400989  -0.144754
 -0.0722058   -0.00863128   0.061604     0.187157    0.0660341     0.0871655    0.140832    -0.0292384    0.0444468   -0.235162     0.0445281   -0.0964051   -0.162807    -0.0698885    -0.0260115   -0.0564081    0.0703418    -0.162581    0.0606506   -0.0562306   -0.116964     0.0672094    0.196342    -0.042304     0.160773   -0.0621928
  0.198483    -0.140372    -0.213988     0.076281    0.148404      0.0242567   -0.0827499   -0.00431153   0.0778378   -0.0192355    0.10572     -0.0834955   -0.0834457   -0.0106009     0.0374223    0.0376184   -0.0112058    -0.121593   -0.00299081   0.130916     0.0287024   -0.114097     0.0486365   -0.0332721   -0.183774    0.216693
  0.00309864  -0.11836     -0.130699    -0.0765629  -0.000952574   0.0440779    0.0180037   -0.0609777    0.173158    -0.0888657   -0.0305051    0.175397     0.142835    -0.0372521     0.0850013    0.00399515  -0.0275266     0.0204052   0.00129009   0.134319    -0.139489     0.130491    -0.112442    -0.10081      0.0628394   0.205374
 -0.0841352    0.148604     0.0658414   -0.104653    0.0337915    -0.147263    -0.00617011  -0.0858456   -0.0742645    0.282086    -0.0759277    0.0220731    0.0782632   -0.189228      0.070103     0.0565945    0.0429072     0.0328114   0.00119412   0.016345     0.0349357    0.0732625   -0.130105     0.0455751   -0.0810634   0.0172783
 -0.0959955    0.0680758   -0.141818    -0.0329975   0.180963     -0.0277622   -0.114309     0.119191    -0.0689634    0.185338     0.0593244   -0.144272     0.0703044    0.109379      0.0244627   -0.0725451    0.107432      0.153709    0.0799259   -0.115126     0.0437499    0.088632    -0.136832     0.0528813    0.17205     0.0951212
  0.0352505    0.177841    -0.11168      0.0444798  -0.0143604    -0.109296     0.0275871    0.10684     -0.0138172    0.0815988    0.0205717   -0.0228499    0.0316113    0.083983      0.0189468    0.0270273    0.0440967     0.0710985   0.00848261   0.215056    -0.00843975   0.038617     0.0353218    0.0133753    0.0231568   0.00292799
  0.0172339   -0.0157978   -0.13071      0.0903549  -0.0610077    -0.097315    -0.0584816    0.0115701    0.0954414   -0.132389    -0.0965856    0.00338628   0.105949    -0.0477148     0.0325748   -0.0431332    0.0948546    -0.0579422   0.05935     -0.0859056   -0.0282642   -0.0540324    0.0389791   -0.223721    -0.0138079  -0.175228
  0.0987018   -0.0268122   -0.125929     0.0184658   0.159136      0.068335    -0.00280801  -0.24384      0.00621807   0.0526235    0.0320515    0.1129      -0.143292    -0.095691      0.0906055   -0.0231917    0.0284987     0.0669081  -0.0358633   -0.109964    -0.00931924  -0.0698265    0.237979    -0.00199413   0.0283756  -0.152047kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4210977932764632
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421142
[ Info: iteration 2, average log likelihood -1.421077
[ Info: iteration 3, average log likelihood -1.420412
[ Info: iteration 4, average log likelihood -1.412958
[ Info: iteration 5, average log likelihood -1.392400
[ Info: iteration 6, average log likelihood -1.385107
[ Info: iteration 7, average log likelihood -1.383811
[ Info: iteration 8, average log likelihood -1.383268
[ Info: iteration 9, average log likelihood -1.382982
[ Info: iteration 10, average log likelihood -1.382811
[ Info: iteration 11, average log likelihood -1.382700
[ Info: iteration 12, average log likelihood -1.382622
[ Info: iteration 13, average log likelihood -1.382567
[ Info: iteration 14, average log likelihood -1.382526
[ Info: iteration 15, average log likelihood -1.382495
[ Info: iteration 16, average log likelihood -1.382470
[ Info: iteration 17, average log likelihood -1.382451
[ Info: iteration 18, average log likelihood -1.382434
[ Info: iteration 19, average log likelihood -1.382420
[ Info: iteration 20, average log likelihood -1.382408
[ Info: iteration 21, average log likelihood -1.382396
[ Info: iteration 22, average log likelihood -1.382386
[ Info: iteration 23, average log likelihood -1.382376
[ Info: iteration 24, average log likelihood -1.382366
[ Info: iteration 25, average log likelihood -1.382357
[ Info: iteration 26, average log likelihood -1.382349
[ Info: iteration 27, average log likelihood -1.382341
[ Info: iteration 28, average log likelihood -1.382334
[ Info: iteration 29, average log likelihood -1.382328
[ Info: iteration 30, average log likelihood -1.382322
[ Info: iteration 31, average log likelihood -1.382317
[ Info: iteration 32, average log likelihood -1.382312
[ Info: iteration 33, average log likelihood -1.382309
[ Info: iteration 34, average log likelihood -1.382305
[ Info: iteration 35, average log likelihood -1.382303
[ Info: iteration 36, average log likelihood -1.382300
[ Info: iteration 37, average log likelihood -1.382298
[ Info: iteration 38, average log likelihood -1.382297
[ Info: iteration 39, average log likelihood -1.382296
[ Info: iteration 40, average log likelihood -1.382294
[ Info: iteration 41, average log likelihood -1.382294
[ Info: iteration 42, average log likelihood -1.382293
[ Info: iteration 43, average log likelihood -1.382292
[ Info: iteration 44, average log likelihood -1.382292
[ Info: iteration 45, average log likelihood -1.382291
[ Info: iteration 46, average log likelihood -1.382291
[ Info: iteration 47, average log likelihood -1.382291
[ Info: iteration 48, average log likelihood -1.382290
[ Info: iteration 49, average log likelihood -1.382290
[ Info: iteration 50, average log likelihood -1.382290
┌ Info: EM with 100000 data points 50 iterations avll -1.382290
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4211424997870374
│     -1.421077362053037
│      ⋮
└     -1.3822899446364507
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.382382
[ Info: iteration 2, average log likelihood -1.382281
[ Info: iteration 3, average log likelihood -1.381651
[ Info: iteration 4, average log likelihood -1.376020
[ Info: iteration 5, average log likelihood -1.362067
[ Info: iteration 6, average log likelihood -1.353109
[ Info: iteration 7, average log likelihood -1.349777
[ Info: iteration 8, average log likelihood -1.348169
[ Info: iteration 9, average log likelihood -1.347219
[ Info: iteration 10, average log likelihood -1.346620
[ Info: iteration 11, average log likelihood -1.346219
[ Info: iteration 12, average log likelihood -1.345935
[ Info: iteration 13, average log likelihood -1.345726
[ Info: iteration 14, average log likelihood -1.345562
[ Info: iteration 15, average log likelihood -1.345421
[ Info: iteration 16, average log likelihood -1.345295
[ Info: iteration 17, average log likelihood -1.345173
[ Info: iteration 18, average log likelihood -1.345049
[ Info: iteration 19, average log likelihood -1.344913
[ Info: iteration 20, average log likelihood -1.344748
[ Info: iteration 21, average log likelihood -1.344542
[ Info: iteration 22, average log likelihood -1.344287
[ Info: iteration 23, average log likelihood -1.343971
[ Info: iteration 24, average log likelihood -1.343583
[ Info: iteration 25, average log likelihood -1.343118
[ Info: iteration 26, average log likelihood -1.342554
[ Info: iteration 27, average log likelihood -1.341883
[ Info: iteration 28, average log likelihood -1.341127
[ Info: iteration 29, average log likelihood -1.340400
[ Info: iteration 30, average log likelihood -1.339902
[ Info: iteration 31, average log likelihood -1.339508
[ Info: iteration 32, average log likelihood -1.339153
[ Info: iteration 33, average log likelihood -1.338833
[ Info: iteration 34, average log likelihood -1.338545
[ Info: iteration 35, average log likelihood -1.338288
[ Info: iteration 36, average log likelihood -1.338062
[ Info: iteration 37, average log likelihood -1.337860
[ Info: iteration 38, average log likelihood -1.337671
[ Info: iteration 39, average log likelihood -1.337487
[ Info: iteration 40, average log likelihood -1.337307
[ Info: iteration 41, average log likelihood -1.337138
[ Info: iteration 42, average log likelihood -1.336986
[ Info: iteration 43, average log likelihood -1.336854
[ Info: iteration 44, average log likelihood -1.336741
[ Info: iteration 45, average log likelihood -1.336646
[ Info: iteration 46, average log likelihood -1.336566
[ Info: iteration 47, average log likelihood -1.336498
[ Info: iteration 48, average log likelihood -1.336439
[ Info: iteration 49, average log likelihood -1.336388
[ Info: iteration 50, average log likelihood -1.336343
┌ Info: EM with 100000 data points 50 iterations avll -1.336343
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3823823355727993
│     -1.382281330143187
│      ⋮
└     -1.336342956853895
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.336424
[ Info: iteration 2, average log likelihood -1.336244
[ Info: iteration 3, average log likelihood -1.335347
[ Info: iteration 4, average log likelihood -1.328280
[ Info: iteration 5, average log likelihood -1.310684
[ Info: iteration 6, average log likelihood -1.296214
[ Info: iteration 7, average log likelihood -1.289290
[ Info: iteration 8, average log likelihood -1.285593
[ Info: iteration 9, average log likelihood -1.282729
[ Info: iteration 10, average log likelihood -1.279923
[ Info: iteration 11, average log likelihood -1.277929
[ Info: iteration 12, average log likelihood -1.276687
[ Info: iteration 13, average log likelihood -1.275849
[ Info: iteration 14, average log likelihood -1.275278
[ Info: iteration 15, average log likelihood -1.274885
[ Info: iteration 16, average log likelihood -1.274609
[ Info: iteration 17, average log likelihood -1.274401
[ Info: iteration 18, average log likelihood -1.274219
[ Info: iteration 19, average log likelihood -1.274040
[ Info: iteration 20, average log likelihood -1.273853
[ Info: iteration 21, average log likelihood -1.273655
[ Info: iteration 22, average log likelihood -1.273446
[ Info: iteration 23, average log likelihood -1.273233
[ Info: iteration 24, average log likelihood -1.273024
[ Info: iteration 25, average log likelihood -1.272823
[ Info: iteration 26, average log likelihood -1.272634
[ Info: iteration 27, average log likelihood -1.272459
[ Info: iteration 28, average log likelihood -1.272299
[ Info: iteration 29, average log likelihood -1.272152
[ Info: iteration 30, average log likelihood -1.272015
[ Info: iteration 31, average log likelihood -1.271883
[ Info: iteration 32, average log likelihood -1.271756
[ Info: iteration 33, average log likelihood -1.271631
[ Info: iteration 34, average log likelihood -1.271513
[ Info: iteration 35, average log likelihood -1.271408
[ Info: iteration 36, average log likelihood -1.271316
[ Info: iteration 37, average log likelihood -1.271238
[ Info: iteration 38, average log likelihood -1.271174
[ Info: iteration 39, average log likelihood -1.271124
[ Info: iteration 40, average log likelihood -1.271084
[ Info: iteration 41, average log likelihood -1.271051
[ Info: iteration 42, average log likelihood -1.271023
[ Info: iteration 43, average log likelihood -1.271000
[ Info: iteration 44, average log likelihood -1.270980
[ Info: iteration 45, average log likelihood -1.270964
[ Info: iteration 46, average log likelihood -1.270950
[ Info: iteration 47, average log likelihood -1.270939
[ Info: iteration 48, average log likelihood -1.270929
[ Info: iteration 49, average log likelihood -1.270921
[ Info: iteration 50, average log likelihood -1.270914
┌ Info: EM with 100000 data points 50 iterations avll -1.270914
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3364242656499425
│     -1.3362435814507099
│      ⋮
└     -1.2709140750604324
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.271059
[ Info: iteration 2, average log likelihood -1.270815
[ Info: iteration 3, average log likelihood -1.268690
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.248940
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.224489
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.211875
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.204878
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.194778
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.199735
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.206430
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.189605
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.201862
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.194420
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.182891
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.196181
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.184733
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.191368
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.193202
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.192186
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.187868
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.191139
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.182724
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.185964
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.179647
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.185570
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.179587
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.185551
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.179574
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.185545
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.179567
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.185536
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.179555
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.185512
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.179519
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.185430
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.179369
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.185055
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.180440
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.185556
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.179520
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.185542
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.179526
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.185542
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.179529
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.185542
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.179531
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.185541
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.179532
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.185541
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.179533
┌ Info: EM with 100000 data points 50 iterations avll -1.179533
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2710590749056883
│     -1.2708149598560308
│      ⋮
└     -1.1795326829733883
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.185812
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.179425
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.182121
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     15
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.153860
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.114545
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     15
│     20
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.088535
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     15
│     17
│     23
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.089353
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│     11
│     12
│     15
│     23
│     24
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.099372
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     17
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.102094
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     11
│     12
│     15
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.088859
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.105244
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│     11
│     12
│     15
│     20
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.086217
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     15
│     17
│     23
│     24
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.095772
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     15
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.104864
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     20
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.086875
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     24
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.087922
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     23
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.106898
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     15
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.097887
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     15
│     17
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.089607
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│     11
│     12
│     15
│     23
│     24
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.092463
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     20
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.098460
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     11
│     12
│     15
│     23
│     24
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.094237
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.101435
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     11
│     12
│     15
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.079177
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     15
│     17
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.106234
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     15
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.106693
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     20
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.081444
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     25
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.085784
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     17
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.112909
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     15
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.094216
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     15
│     17
│     23
│     24
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.082762
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     12
│     15
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.102828
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     17
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.100457
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     11
│     12
│     15
│     23
│     24
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.088735
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     17
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.099144
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     12
│     15
│      ⋮
│     24
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.084921
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     15
│     17
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.102291
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     15
│     23
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.099548
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     20
│     21
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.091697
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     24
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.087631
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     17
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.107336
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     15
│     20
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.091730
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     15
│     17
│     23
│     24
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.088296
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     12
│     15
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.099052
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     15
│     17
│     20
│     23
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.093587
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     11
│     12
│     15
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.099240
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     17
│     21
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.101157
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     12
│     15
│      ⋮
│     24
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.079511
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     15
│     17
│     23
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.100347
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     15
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.105593
┌ Info: EM with 100000 data points 50 iterations avll -1.105593
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1858121327819506
│     -1.1794253842824394
│      ⋮
└     -1.1055927816810087
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4210977932764632
│     -1.4211424997870374
│     -1.421077362053037
│     -1.420411702555832
│      ⋮
│     -1.0795114692436016
│     -1.1003471489265375
└     -1.1055927816810087
32×26 Array{Float64,2}:
 -0.0749131    0.0503483    -0.0823815    0.106207     0.0461605   -0.0713388   -0.0218918    0.0370254    -0.0501611   -0.0287676    0.0478912   -0.00444569  -0.0527168   -0.088604     0.00182711   0.0412903   -0.0980489   0.00479316  -0.0573433    0.0488884    0.0982519   -0.0616379   -0.0663717    -0.0708811    0.0369129    -0.130668
  0.12674     -0.139892     -0.24079      0.132647    -0.12945     -0.116185     0.00350411   0.0666026    -0.0306719   -0.155955    -0.024524    -0.11876      0.154202     0.0430189   -0.120352     0.168048    -0.111061    0.125707    -0.0696077   -0.108291     0.0535249    0.00818007   0.172095      0.221771    -0.121941     -0.0954757
 -0.0191517    0.0505767     0.0383942    0.00682374   0.105184     0.00126547   0.0103244    0.0377635    -0.0698127   -0.14117     -0.054208    -0.12079      0.0727471   -0.00482176   0.024693     0.0074405   -0.106014    0.0605789    0.0612524    0.174731    -0.047743     0.00720886   0.0853418    -0.122838     0.057875     -0.0507593
  0.088304     0.250886     -0.120622     0.0170562    0.113859     0.0229103   -0.0961881   -0.141138     -0.128645     0.0613115    0.123211    -0.00913635   0.0182414   -0.00508958  -0.00240191   0.144571    -0.168563    0.16936     -0.0447521    0.0949075    0.00716334   0.158782    -0.146263      0.0766146   -0.123499      0.167452
 -0.0527236   -0.0436381    -0.0778941   -0.157796    -0.120319     0.0140223   -0.00270082   0.177428     -0.120356    -0.188913     0.196304     0.0140085    0.105331     0.0204624   -0.0204382    0.134721    -0.133558    0.0305365    0.123731    -0.00277436  -0.100894     0.0855088    0.147595     -0.0196828    0.116876     -0.0120714
 -0.00652908  -0.122858     -0.20144     -0.127496    -0.118589     0.177521     0.0786895    0.042318     -0.0678702   -0.119095    -0.0762521    0.0768822    0.0616231    0.0317662    0.00735937  -0.0704129    0.120346   -0.102781     0.143893     0.0255453   -0.0177066    0.23338      0.000602174   0.0862048   -0.0136675     0.0936655
  0.1222      -0.038415     -0.0657223    0.00390033   0.104268     0.0320004   -0.138138    -0.0762493     0.162803     0.0875489   -0.0140838   -0.0583211   -0.119293    -0.0665275   -0.0906327    0.0332005   -0.0681234  -0.00498061   0.104898     0.0280221    0.0799578   -0.106804     0.106298     -0.133894    -0.052786      0.108678
  0.00665236  -0.0636815     0.0366939    0.130449    -0.0557997   -0.049955     0.0572918    0.0422727     0.130564     0.169313    -0.0205688    0.156541     0.0212082   -0.0144713   -0.032385     0.0469099   -0.122435   -0.0150058    0.0710516    0.035724    -0.0251012   -0.0640826   -0.130795      0.00384871   0.0507126    -0.0496813
  0.0360349   -0.65161      -0.0429832    0.131995     0.00656826  -0.10131     -0.152467    -0.0678087    -0.0611561   -0.0811858   -4.15147e-6  -0.215508    -0.0570825    0.0341828    0.0815707    0.142362     0.141695   -0.0727904   -0.0216282   -0.069197     0.0538452    0.0316815   -0.0943674     0.0188474    0.0272148     0.0212078
  0.0476783    0.306722      0.0145901    0.111343     0.220826     0.0307319   -0.142856    -0.0384215     0.0319947    0.0386392   -0.0143487   -0.0758505    0.00814108   0.00598004   0.15711     -0.217892     0.16006    -0.0543944    0.0153909   -0.0245694    0.0413483   -0.0184828   -0.108127      0.00272022   0.00667602    0.0240107
  0.0115284    0.103977      0.11526     -0.108793    -0.0583493   -0.0529967   -0.102199    -0.0847239    -0.188466    -0.0367033   -0.197132    -0.00665841  -0.0327277    0.0766757   -0.0242824   -0.151674     0.224138    0.0264619   -0.12329     -0.0526617    0.00192799   0.03435     -0.0280987     0.0524114   -0.481908     -0.0790982
  0.0181297    0.145243      0.0141274   -0.108763    -0.0848402   -0.0483402   -0.0771379   -0.0255101    -0.18864     -0.00201937  -0.194972    -0.00670503   0.0112784    0.0849427   -0.0427448   -0.144717     0.220004    0.0161307    0.0424194   -0.0597457    0.00171832   0.0354111   -0.0282297     0.0633197    0.546306     -0.0867227
  0.109033    -0.090184     -0.127704     0.342845    -0.0843702    0.0791301   -0.00994059  -0.0786135     0.124401    -0.137319     0.0210889   -0.209959    -0.0512524   -0.182538    -0.0458886   -0.0296124   -0.0462615  -0.10226     -0.00247522   0.119984    -0.033313    -0.127576     0.246255      0.00808028  -0.335532      0.135713
  0.122671    -0.0399556    -0.132572     0.223217    -0.0912264    0.0127217   -0.0157928    0.218957      0.121509    -0.161421    -0.00168259  -0.205931    -0.0513962   -0.184483     0.0657301   -0.0792361    0.129074   -0.252699    -0.00118118   0.0651621    0.0152539   -0.176919    -0.0381365    -0.00910896   0.215333      0.118539
 -0.0423218    0.0700297    -0.165623    -0.0311938    0.201294    -0.0249819   -0.116887     0.114938     -0.0691319    0.186962     0.0621562   -0.124529     0.089086     0.109355     0.0468013   -0.0721449    0.0969113   0.149669     0.0820629   -0.110744     0.0435419    0.10122     -0.136997      0.0525679    0.167892      0.0962706
  0.11871     -0.00343937    0.113809    -0.0723328    0.0344484    0.093432     0.0796324   -0.00636178    0.0918435   -0.0987621   -0.00137162  -0.0579344   -0.0748664   -0.0505072    0.00545333   0.0693431   -0.0782991   0.0744749    0.0824799    0.095115    -0.00916008   0.00766273   0.0144709    -0.12149     -0.041324      0.0151688
  0.0201423    0.188527     -0.247139     0.0810169    0.0791581    0.0324777   -0.0299556    0.0376296    -0.110751     0.0112369   -0.10662      0.0394802    0.00757286  -0.00888138  -0.0623344    0.0613204   -0.156936   -0.108526     0.145979    -0.0986104    0.0842998    0.0474808    0.0391794    -0.10315     -0.0229222    -0.135145
  0.0421639    0.166845     -0.100738     0.0417861   -0.0130497   -0.114524     0.0320949    0.0985058    -0.00644655   0.080842    -0.0447789   -0.0129043    0.0371716    0.0829295    0.0197704    0.0392448    0.0790787   0.0438419    0.0172001    0.236694    -0.048195     0.0384196    0.0655977     0.0570407    0.0265252     0.0363946
  0.0560099    0.000334843   0.0491797   -0.107241    -0.149099     0.0892817    0.070979     0.126606      0.023088    -0.0838384   -0.124839     0.0848744    0.128533    -0.0968813    0.0533773    0.00697232   0.0214376   0.0206947   -0.138244     0.0406659   -0.0561386   -0.00222766  -0.144039      0.00106134  -0.000796004   0.015806
  0.00685321   0.0534017     0.0311629    0.0245487   -0.0639205   -0.0371606   -0.142237    -0.027659     -0.0174112    0.0203076    0.244347    -0.0583305   -0.112855    -0.0903402    0.0437048    0.0165288   -0.0492726  -0.119591     0.106335    -0.0822577    0.0219159   -0.023275     0.170638      0.036303    -0.131979      0.0107631
  0.123495     0.102663     -0.00340316  -0.0800671    0.00170624   0.0876577    0.0214949   -0.000623242   0.182118    -0.0387932   -0.0950383    0.174982     0.299549     0.152674     0.0092851   -0.185434     0.190476   -0.0256534   -0.00438227   0.117512     0.194621     0.267105    -0.451868     -0.21778     -0.0839895    -0.0933696
 -0.0961242    0.141518     -0.134934     0.0200537    0.26748      0.0822775    0.0457657   -0.0679385     0.0768453   -0.0621923   -0.0851443    0.178861    -0.0922898    0.158461     0.0550263   -0.179977     0.179225   -0.0382064    0.0494333    0.0811157    0.0448673    0.184794     0.608191      0.3196      -0.0915108    -0.0637087
 -0.0605052   -0.15173       0.00957793  -0.189409    -0.0809707    0.0555732   -0.159192     0.133282      0.0122734    0.0395236   -0.187052     0.0661395   -0.120394    -0.103697     0.174409    -0.110264     0.0212058  -0.0388355   -0.555148     0.106984    -1.37737      0.215811     0.00895807   -0.0419553   -0.0955756     0.0306036
 -0.239542     0.253053      0.0153983   -0.151149    -0.0788133    0.0555124   -0.15515      0.107257      0.0176117    0.0292898   -0.138742    -0.0567408   -0.0853045   -0.0943001    0.143063    -0.109118    -0.0593652  -0.0523607    0.345936     0.0492935    1.29255      0.221564     0.0161264    -0.0425914   -0.0964692     0.0344068
 -0.06419      0.0181864     0.0674635    0.0504829   -0.0317381    0.0115822   -0.18736     -0.0866886    -0.0741075   -0.0927573   -0.10698      0.00422944   0.0313085    0.0603597    0.0593502   -0.086469     0.0383768   0.0487654    0.00626575  -0.113319     0.0327361   -0.0714605    0.0671037     0.019863    -0.02902       0.069995
  0.00263553  -0.0397668    -0.0691397    0.0166878   -0.0494145    0.0716878    0.0497079   -0.100356      0.018891     0.00558483  -0.0280148    0.113844     0.0664701   -0.021433     0.0763501   -0.110514    -0.123183   -0.0970732    0.110689     0.0344992   -0.0261111    0.0962791   -0.0566859    -0.00545459   0.0176565     0.118423
 -0.0651264   -0.0195558     0.0477106    0.188214     0.0680239    0.0665489    0.139386    -0.0232976     0.0620178   -0.223463     0.027623    -0.0958652   -0.171941    -0.0684282    0.0164002   -0.0537639    0.0958266  -0.162368     0.0752429   -0.0600169   -0.11113      0.104354     0.202152     -0.0413771    0.158568     -0.0786891
 -0.10406     -0.117002     -0.0310721    0.136011    -0.162386     0.0767606    0.0407301   -0.0532936    -0.0914317   -0.0305916   -0.0800121    0.221959    -0.0556775   -0.120117    -0.096087     0.135466     0.130112   -0.0305349   -0.0658901    0.053941     0.0168838   -0.171551     0.077941     -0.158188     0.22887       0.116937
 -0.0732026    0.151154      0.0610535   -0.0986364    0.0496317   -0.157282    -0.00365853  -0.0875377    -0.057551     0.271011    -0.0816658    0.0262324    0.0843726   -0.184572     0.082877     0.0755466    0.0576193  -0.00192196  -0.00397624   0.0189147    0.0575054    0.0760779   -0.130016      0.0199112   -0.0867507     0.0101035
  0.0206626   -0.0498073    -0.132327     0.0644328    0.0539755   -0.0852182   -0.0627961    0.011323      0.102822    -0.146486    -0.092747    -0.0108065    0.0869187   -0.0269957    0.00558569  -0.0403885    0.0779083  -0.0146717    0.0900519   -0.141491    -0.0313586   -0.0259124    0.0460309    -0.256219    -0.0548846    -0.177433
  0.0677088   -0.0687731    -0.115343    -0.112107     0.204608     0.0349322    0.012013    -0.174348      0.0264645    0.0186208    0.0418027    0.017505    -0.151318    -0.0781875    0.0632611   -0.00581102  -0.0397063  -0.155011    -0.030387    -0.122515     0.0480234   -0.536916     0.206785     -0.137011     0.0607861    -0.147267
  0.142533     0.0798948    -0.100862     0.263588     0.0602939    0.127895    -0.0225136   -0.345612     -0.0344244    0.0656903    0.0280214    0.209971    -0.135257    -0.113105     0.288245    -0.0572251    0.118095    0.351989    -0.0454909   -0.105602    -0.0296404    0.679418     0.20338       0.221026    -0.0109973    -0.156924[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     17
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.088156
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.066776
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     20
│     21
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.088034
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.066546
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     20
│     21
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.088033
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.066535
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     20
│     21
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.088031
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.066531
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     17
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.088029
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.066528
┌ Info: EM with 100000 data points 10 iterations avll -1.066528
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.385420e+05
      1       6.928205e+05      -2.457215e+05 |       32
      2       6.686367e+05      -2.418378e+04 |       32
      3       6.548311e+05      -1.380564e+04 |       32
      4       6.469142e+05      -7.916885e+03 |       32
      5       6.411202e+05      -5.793946e+03 |       32
      6       6.353701e+05      -5.750141e+03 |       32
      7       6.309281e+05      -4.441950e+03 |       32
      8       6.280417e+05      -2.886410e+03 |       32
      9       6.259530e+05      -2.088754e+03 |       32
     10       6.240907e+05      -1.862229e+03 |       32
     11       6.229899e+05      -1.100827e+03 |       32
     12       6.224484e+05      -5.415151e+02 |       32
     13       6.221730e+05      -2.754026e+02 |       32
     14       6.219850e+05      -1.880382e+02 |       32
     15       6.217979e+05      -1.870333e+02 |       32
     16       6.215447e+05      -2.531883e+02 |       32
     17       6.212342e+05      -3.105289e+02 |       32
     18       6.209923e+05      -2.419338e+02 |       32
     19       6.208482e+05      -1.440869e+02 |       32
     20       6.207353e+05      -1.128937e+02 |       32
     21       6.206315e+05      -1.038165e+02 |       32
     22       6.205214e+05      -1.100818e+02 |       32
     23       6.204318e+05      -8.960418e+01 |       32
     24       6.203590e+05      -7.274825e+01 |       32
     25       6.203035e+05      -5.552296e+01 |       32
     26       6.202541e+05      -4.941743e+01 |       32
     27       6.202156e+05      -3.855043e+01 |       32
     28       6.201858e+05      -2.973184e+01 |       32
     29       6.201601e+05      -2.575419e+01 |       31
     30       6.201398e+05      -2.026913e+01 |       32
     31       6.201243e+05      -1.551326e+01 |       31
     32       6.201145e+05      -9.754741e+00 |       29
     33       6.201070e+05      -7.532646e+00 |       29
     34       6.201018e+05      -5.150767e+00 |       28
     35       6.200983e+05      -3.587423e+00 |       29
     36       6.200944e+05      -3.825136e+00 |       24
     37       6.200922e+05      -2.278537e+00 |       21
     38       6.200910e+05      -1.153672e+00 |       16
     39       6.200905e+05      -5.317898e-01 |        9
     40       6.200900e+05      -4.913016e-01 |       12
     41       6.200896e+05      -4.107827e-01 |       10
     42       6.200893e+05      -2.870228e-01 |        6
     43       6.200891e+05      -1.611227e-01 |        6
     44       6.200890e+05      -1.155037e-01 |        5
     45       6.200889e+05      -1.254407e-01 |        2
     46       6.200888e+05      -4.422454e-02 |        4
     47       6.200888e+05      -6.918271e-02 |        0
     48       6.200888e+05       0.000000e+00 |        0
K-means converged with 48 iterations (objv = 620088.7632676149)
┌ Info: K-means with 32000 data points using 48 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.339858
[ Info: iteration 2, average log likelihood -1.311915
[ Info: iteration 3, average log likelihood -1.278146
[ Info: iteration 4, average log likelihood -1.235795
[ Info: iteration 5, average log likelihood -1.193576
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.152527
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     14
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.127905
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.131129
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│      7
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.096472
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.134518
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.108575
[ Info: iteration 12, average log likelihood -1.117207
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     23
│     24
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.063795
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│      5
│      7
│     14
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.088770
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.126846
[ Info: iteration 16, average log likelihood -1.126209
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.079308
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      5
│      9
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.081606
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.099086
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.088502
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      7
│     14
│     20
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.052881
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     2
│     4
│     5
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.098257
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.109429
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     20
│     23
│     24
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.074243
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│      9
│     14
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.096838
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.090779
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.096632
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.065946
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      5
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.069454
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     21
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.083614
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.076450
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.054364
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      7
│      9
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.046688
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.099195
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.070661
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.067354
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      5
│      9
│     10
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.036487
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.097778
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│     14
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.092542
[ Info: iteration 40, average log likelihood -1.098043
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     10
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.041997
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     14
│     20
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.086369
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.093377
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      7
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.069452
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      9
│     10
│     14
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.049905
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.097216
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      6
│     23
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.047314
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.092590
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      7
│     10
│     14
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.071355
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.119840
┌ Info: EM with 100000 data points 50 iterations avll -1.119840
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0193932    -0.0430448   -0.129589      0.0637794    0.0532555   -0.0944374  -0.0635108    0.00130708   0.0998191   -0.123842    -0.0916222   -0.0127882   0.0883497   -0.0346182    0.0166091   -0.0330151    0.0806171   -0.00881265   0.0914461   -0.139797    -0.029016    -0.0267772    0.0357492   -0.243848     -0.0517996   -0.173692
 -0.177246      0.068275     0.0526316    -0.234137    -0.0805302    0.0119952  -0.127706     0.0861689    0.00191823   0.108639    -0.149901     0.0141684  -0.0914356   -0.13771      0.221526    -0.0636832    0.00737756   0.0135748   -0.144175     0.0981211   -0.0562984    0.215353    -0.0311738    0.0140637    -0.0882381    0.0375547
 -0.00357696    0.0197606   -0.0541856     0.157383     0.0523628   -0.047161    0.0287249   -0.0523868    0.103162     0.202605    -0.0214062    0.168683   -0.0124616    0.0742606    0.0128902    0.0827627   -0.100387     0.0879519    0.0543629    0.0623496    0.0722748   -0.165387    -0.285387     0.0880655    -0.019595    -0.133032
 -0.182109      0.0504838    0.0376395     0.146166    -0.0559807    0.046561   -0.0644837   -0.042716    -0.0808183   -0.0146433    0.171245     0.0257308   0.00869118  -0.132389    -0.160079     0.0521997   -0.161097     0.00209261  -0.0549946   -0.1667       0.173639    -0.23385     -0.0200106   -0.0717974     0.0442051   -0.153649
  0.108912     -0.133575    -0.231181      0.142625    -0.127844    -0.0956073  -0.00944953   0.0533049   -0.0421029   -0.152579    -0.0412592   -0.130278    0.160666     0.041982    -0.126431     0.17385     -0.123884     0.116556    -0.0630777   -0.139738     0.0792353   -0.0147173    0.1606       0.188876     -0.113342    -0.129575
 -0.00489299    0.173366    -0.193036      0.0665173    0.0473938    0.0357096  -0.0592843    0.0399008   -0.0958914    0.0237501   -0.107024     0.027677    0.00810141  -0.0292094   -0.0508266    0.0222343   -0.132114    -0.109314     0.141655    -0.0754669    0.118531     0.0896274    0.0348474   -0.0963004    -0.0412065   -0.0947254
  0.031714      0.00502458   0.0525543     0.0555306   -0.00753692  -0.0688676  -0.0416795   -0.0260816   -0.0414895   -0.0522808   -0.170436    -0.171787    0.0551779    0.0293514    0.289479     0.0117117   -0.119549     0.0439922   -0.0272635    0.0765615   -0.0611168   -0.0958029    0.0190803   -0.114947      0.0297406   -0.0573394
  0.0139356     0.121577    -0.0619351    -0.0306669    0.125169     0.0843166   0.0274155   -0.0280703    0.127788    -0.0452221   -0.0904335    0.17683     0.108265     0.150718     0.034553    -0.179874     0.182169    -0.0308809    0.0242185    0.0969838    0.120156     0.223839     0.0604158    0.0420504    -0.0854129   -0.0774361
  0.0473418     0.113076     0.0560385     0.0606956    0.126109     0.117416    0.0674018    0.0665776   -0.0749818   -0.0479429    0.0374115   -0.14692     0.0487432   -0.0767803   -0.118861     0.053659    -0.119078     0.0331612    0.129035     0.191162    -0.140463     0.0807785    0.102284    -0.00795022    0.0289883   -0.139466
 -0.0494498     0.072342    -0.308553     -0.0390182    0.293579    -0.0306868  -0.109739     0.113671    -0.0773987    0.192564     0.0873158   -0.154325    0.0983225    0.0868093    0.0599802   -0.0673196    0.0876153    0.142791     0.0780528   -0.13161      0.0539858    0.129627    -0.177073     0.0482083     0.166617     0.0832445
  0.104185     -0.00154436   0.115352     -0.0674754    0.0247607    0.0858772   0.0649476    6.6911e-5    0.0772198   -0.0797971    0.00371735  -0.0568149  -0.0675376   -0.0402084   -0.00421609   0.0554376   -0.0659327    0.0776209    0.0831296    0.0795012   -0.00450116   0.0212192    0.0135979   -0.106604     -0.02531      0.0198601
 -0.0122048    -0.117236    -0.202509     -0.122555    -0.119292     0.170005    0.0775628    0.0412616   -0.069099    -0.125119    -0.0632589    0.0700467   0.0658698    0.0346507    0.0102875   -0.0618551    0.106642    -0.0938072    0.147127     0.0234519   -0.0293763    0.223379     0.00447813   0.0833461    -0.00986471   0.0913347
  0.0722468     0.0309565    0.0419753    -0.0351039    0.0548824    0.0482237  -0.15497     -0.127013     0.186092     0.161218    -0.0870711   -0.0413189  -0.145552    -0.104237    -0.178224     0.0297862   -0.111229     0.0643541    0.190749    -0.0309703    0.123523    -0.107496     0.134639    -0.184059      0.0322177    0.03449
 -0.0125085     0.0476127    0.000124717   0.122658    -0.0972285    0.082323    0.109325    -0.154036    -0.196245     0.0824171   -0.0208842    0.0534606  -0.0368633    0.00126142   0.0940266   -0.251579    -0.251305    -0.154188     0.189659    -0.113124     0.0910799    0.0597433   -0.0248056    0.0971465    -0.0646574   -0.0276519
  0.0994965     0.00213691  -0.118329      0.0634024    0.132016     0.0806057  -0.00575584  -0.254789    -0.00456194   0.0405888    0.0361012    0.110672   -0.142024    -0.0937072    0.168975    -0.0306531    0.0327431    0.0846985   -0.0369871   -0.116491     0.00655302   0.0346513    0.203551     0.0279155     0.0263244   -0.151795
  0.115795     -0.0658909   -0.130015      0.285457    -0.0875934    0.0473042  -0.0131732    0.0644616    0.122965    -0.148918     0.0101891   -0.208133   -0.051305    -0.183371     0.00788872  -0.0530224    0.0378338   -0.175356    -0.0018914    0.0939536   -0.00994051  -0.151811     0.109646     0.000364598  -0.070091     0.127342
  0.179361     -0.134052    -0.213535      0.0624189    0.142327     0.0173054  -0.0939263    0.00139035   0.0895802   -0.0176705    0.100151    -0.0555035  -0.0791672   -0.00505839   0.0319133    0.0404145   -0.0185382   -0.0905286   -0.0027871    0.122293     0.00207588  -0.0916799    0.0510886   -0.0649345    -0.169141     0.177043
  0.0274097     0.00289129   0.0203963     0.00105428   0.0254881   -0.0380188  -0.118916    -0.0527685   -0.102502    -0.00795792  -0.105887    -0.0730849  -0.0127317    0.0518289    0.0421307   -0.106555     0.187408    -0.0150538   -0.0222928   -0.0532131    0.0252308    0.0206815   -0.0645684    0.0365066     0.02195     -0.0274883
  0.0880794     0.252879    -0.121361      0.0172377    0.116487     0.0237613  -0.0932509   -0.140475    -0.128987     0.0626986    0.126458    -0.012568    0.0198895   -0.00264149  -0.00336689   0.141409    -0.167964     0.168802    -0.0450141    0.0965941    0.00680829   0.158002    -0.142637     0.0751397    -0.122637     0.161889
 -0.0643126    -0.0292027   -0.0583812    -0.222872    -0.139611     0.0129046  -0.0188263    0.222612    -0.144234    -0.213817     0.208456     0.025557    0.107028     0.0241433   -0.0283087    0.146098    -0.131611     0.0295413    0.120925    -0.00675203  -0.092568     0.0975408    0.173273    -0.0142555     0.141639    -0.0113156
 -0.0779826    -0.00602881   0.0500835    -0.0230024    0.0838377   -0.126775   -0.0544088    0.00593992  -0.0603395   -0.212851    -0.142176    -0.0963181   0.0941786    0.0670752    0.173563    -0.0219505   -0.0895155    0.100264    -0.00699494   0.140863     0.0573315   -0.07136      0.0695384   -0.214818      0.0835492    0.0371765
  0.00227286   -0.0757428    0.0878645    -0.0880983   -0.154414     0.113316    0.188008     0.0588808   -0.0531482   -0.085019    -0.0817616    0.167855    0.116448    -0.102993     0.102812     0.130323     0.0380878    0.124402    -0.159135     0.0922304   -0.0286187   -0.00875602  -0.282642     0.0402604     0.0147842   -0.0642177
 -0.0694599     0.0400712    0.0923491     0.110297     0.0634312   -0.0124771   0.0812474   -0.0201136    0.0203828   -0.0419963   -0.00331393  -0.0583123  -0.0778941   -0.103499    -0.00372854  -0.00769514   0.0824346   -0.118387     0.0681568   -0.0388448   -0.0476364    0.103302     0.0841198   -0.0270045     0.0710972   -0.0510156
  0.012045      0.0546583    0.0319516     0.0293707   -0.0680125   -0.0364418  -0.168625    -0.0529835    0.00488377   0.0111743    0.258479    -0.0594641  -0.125109    -0.0868899    0.0426629    0.0150037   -0.0461631   -0.121382     0.107645    -0.110482     0.0253786   -0.0264769    0.177941     0.0292515    -0.127798     0.00801017
  0.0202109    -0.115686     0.121185      0.0896086   -0.165781    -0.0556987   0.0944651    0.152574     0.153245     0.129786    -0.0389585    0.134202    0.0581987   -0.104731    -0.0769971    0.0127565   -0.14107     -0.0979099    0.074007    -0.00768761  -0.102214     0.025526     0.0277193   -0.0699315     0.121129     0.0286825
 -0.0569057     0.0221371    0.0881546     0.0400745   -0.0373954    0.022955   -0.250045    -0.109704    -0.0292301   -0.105457    -0.105399     0.009343    0.0440107    0.0625799    0.0661206   -0.0832976    0.0598084    0.0392207   -0.0257479   -0.139628     0.0380165   -0.0994009    0.0621718    0.00495175   -0.0109631    0.0822471
 -0.0700548     0.125862     0.0344076    -0.128125     0.0543688   -0.167842   -0.0264744   -0.279024    -0.0290603    0.339996    -0.0719717    0.0269768   0.11663     -0.14864      0.128489     0.042067     0.125504     0.0241393    0.0251983    0.198335     0.0807431    0.0435104   -0.102636     0.034154     -0.235943     0.031288
  0.000962629  -0.117725    -0.132169     -0.0789589   -0.00155669   0.0582754   0.0147553   -0.0628019    0.174058    -0.0604283   -0.0355681    0.168391    0.16154     -0.0346766    0.0701915   -0.0037317   -0.0251801    0.0130368    0.0330989    0.140029    -0.139641     0.1187      -0.105183    -0.0702996     0.0653325    0.228629
 -0.10122      -0.109495    -0.0276561     0.138787    -0.161333     0.080151    0.0424549   -0.0454578   -0.0944782   -0.0460929   -0.0766949    0.191625   -0.0649932   -0.117145    -0.0883814    0.124846     0.115835    -0.037949    -0.05937      0.0437931   -7.60515e-5  -0.173714     0.0925907   -0.148238      0.233486     0.0947144
 -0.0740612     0.0645125   -0.154147      0.0612743    0.154631    -0.21564     0.0361573    0.116768    -0.0198836   -0.0191114    0.00382752   0.02724    -0.103503    -0.0890583    0.0932375    0.0232182   -0.0029876   -0.00163502  -0.0656405    0.236263     0.0822082    0.0885065   -0.12345     -0.0449372     0.0607549   -0.062559
  0.0413026     0.166073    -0.111439      0.0438743   -0.00833639  -0.106764    0.0293236    0.0961829   -0.0165529    0.0766911   -0.0521489   -0.0143522   0.037237     0.0800718    0.0152913    0.0428149    0.0613316    0.0373878    0.0184815    0.220593    -0.0435976    0.0379728    0.0649394    0.0468437     0.0245958    0.0191934
  0.109728      0.076309     0.0106317    -0.126603    -0.145777     0.0608269  -0.0492403    0.18986      0.0847076   -0.0895116   -0.1735      -0.0052898   0.141398    -0.0884267   -0.00428387  -0.107759     0.00711434  -0.0920969   -0.112794    -0.0179786   -0.0814654    0.00980477   0.00779193  -0.0428571    -0.0207675    0.102478[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.072359
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│      ⋮
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.022247
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     10
│     21
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.031986
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     24
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.031863
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│      6
│     10
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.045889
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│     14
│     20
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.035476
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     10
│     21
│     23
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.026928
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      7
│      9
│     14
│     20
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.032765
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│      6
│     10
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.040135
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│      ⋮
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.018098
┌ Info: EM with 100000 data points 10 iterations avll -1.018098
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0391211   -0.0317091    -0.0072507    -0.0937876    0.0646522   -0.0700256    0.155272    0.0165174   -0.0817551    -0.180939     0.108656     0.0673118   -0.0719101     0.0350328   -0.0776968   -0.0387325    -0.115935     0.0184535   -0.0344402   -0.000765535  -0.136657    -0.103543     0.0359059    0.0928882     0.050827    -0.0424687
 -0.146314     0.0339556     0.000705972   0.0481254   -0.0036271    0.0102338    0.263419    0.109369     0.16254      -0.135806    -0.0139167    0.0467783    0.0328233     0.0569708    0.00123801   0.034076     -0.105315     0.0488527    0.0378557    0.0849747     0.155114    -0.0906214   -0.00765293  -0.187006     -0.00629424  -0.156156
 -0.0412668    0.122032     -0.0461683     0.0686968   -0.0168036   -0.0457658   -0.0656249  -0.0389586   -0.0123243     0.108981    -0.0674365    0.0176487    0.023006     -0.0927988   -0.0546959    0.0488979    -0.073546    -0.0978289   -0.0299196   -0.192239     -0.0637598    0.0472108    0.0109011    0.00654335    0.293171    -0.0791885
  0.0237021   -0.110054     -0.104118     -0.074536     0.120751    -0.0484397    0.035421   -0.0646866   -0.175104     -0.00390199   0.152979     0.083823    -0.0962515    -0.0170288   -0.0158662   -0.0264546    -0.00874395   0.0567659   -0.107739     0.10775       0.120412     0.0544245    0.0976853   -0.187696      0.0606706   -0.101957
  0.0506234    0.0506754    -0.0171447    -0.0806632   -0.0724861   -0.139051     0.0462755  -0.110958     0.0465535    -0.1396      -0.131896    -0.0549889   -0.101384     -0.101242     0.100431    -0.120193      0.105479     0.146346    -0.133108    -0.0558728     0.201018    -0.00232136  -0.0882937    0.000745082  -0.19028      0.0109124
  0.0243076   -0.134239     -0.0686508     0.0755451   -0.0343951    0.111237     0.0791165  -0.00780333  -0.0281776    -0.0300934   -0.00479424  -0.0904764   -0.0996492    -0.0166217    0.145534     0.0396197    -0.137987    -0.0515364   -0.0390632    0.0536028    -0.0414586   -0.0456169   -0.00952991   0.228323      0.269229    -0.0089653
  0.00837508  -0.159533      0.00189355   -0.0554327    0.0699842    0.145277     0.022383   -0.107464     0.116879      0.0281732   -0.0569418    0.0534641    0.0690415    -0.00458313  -0.102829     0.116968      0.0481893    0.051339    -0.034948     0.119795     -0.192367     0.0797177   -0.0499278   -0.0651236    -0.0297975   -0.0450358
  0.0758882    0.0964379     0.113727      0.0169405    0.0774054    0.125279     0.0909837   0.112407     0.0428669     0.0606342    0.0148104   -0.0201157   -0.150145      0.0826576    0.0078911    0.0605518    -0.106485    -0.0764      -0.094165     0.0623481     0.0528362   -0.113525     0.032088    -0.064963     -0.0587579   -0.104817
  0.144616     0.0521401    -0.0551047    -0.0845452   -0.02569     -0.0389806    0.0300944  -0.196146    -0.0904668     0.0659521   -0.124745    -0.0510055    0.188684     -0.0229979    0.286247    -0.0409447    -0.0953904    0.0576553   -0.0891972    0.00879498   -0.33378      0.0472081   -0.0534217   -0.15617      -0.0365336   -0.0676131
 -0.0521182   -0.0103147     0.0674783    -3.556e-5    -0.131102    -0.0133308   -0.0912954  -0.197735    -0.0260693    -0.0812603    0.185574    -0.0623591   -0.0437307    -0.0802195   -0.059154    -0.0309148    -0.0565804    0.0524217   -0.0834876    0.0122348     0.123982    -0.0355986    0.0572408    0.0770482    -0.0346027   -0.0524991
  0.00895567  -0.0951441     0.181252     -0.101623     0.148834    -0.119631    -0.0305722  -0.0548227   -0.00779876    0.137213    -0.0148799   -0.0348229    0.0251218    -0.102411    -0.109775    -0.0343029    -0.232121     0.0105103    0.00704397  -0.0208183    -0.0996168    0.0594514   -0.0410043    0.133053     -0.0461912   -0.123579
  0.155141    -0.000990185  -0.0104        0.0317444   -0.164441     0.0423314   -0.193773   -0.0439149    0.0115886     0.0192325   -0.24488     -0.00571308  -0.0034009    -0.0656592   -0.00959992  -0.0119109    -0.103787    -0.0199006    0.112594     0.0104439    -0.00103171  -0.023776     0.0414458    0.0801958     0.00394505   0.0183449
  0.0523667    0.0347966     0.0550987     0.128578    -0.0264184    0.0918721    0.0186188   0.1076       0.0532487    -0.104532    -0.0420604   -0.0779794    0.00604026   -0.0501247   -0.0657228   -0.022278     -0.230373    -0.0231977    0.0297831   -0.000878897  -0.204853    -0.0231265   -0.113466     0.0285993    -0.0672623   -0.0959476
 -0.00433982   0.0682335    -0.00182907   -0.121178    -0.109057     0.0857208    0.246606   -0.0237712   -0.0567677    -0.040508     0.242548     0.19304     -0.121864      0.319836     0.131191    -0.0125489    -0.0921554    0.193026    -0.00730048   0.0608177     0.0676292   -0.0369861   -0.00335491   0.0420895    -0.0558489   -0.186767
 -0.0156191    0.118129     -0.00279973   -0.00353911   0.015955     0.0751741    0.0229608   0.0135061    0.0101622    -0.117728     0.0158081    0.165314    -0.0587033    -0.0579752   -0.177169    -0.204883      0.0561028    0.0245779   -0.133083    -0.114278      0.048744     0.0780831   -0.0596444   -0.0394706    -0.00796567  -0.100401
  0.0787125    0.0294554    -0.186355     -0.0449794    0.0981039   -0.277786     0.0420253  -0.0633355    0.21311       0.12005      0.0487705   -0.0211773   -0.0838319     0.0581138    0.198428    -0.253759      0.0723081    4.03846e-5   0.00204378   0.00760041   -0.0146582    0.0893848   -0.14687     -0.0545789     0.0416564    0.147115
 -0.143905    -0.0268405     0.0133519    -0.119381     0.161803     0.0334946   -0.240645   -0.0316371    0.175835     -0.250804     0.0903349    0.0126391    0.100027     -0.0291834    0.137117    -0.13774      -0.173233    -0.0324392    0.14812      0.29066      -0.0744421   -0.050243     0.112492     0.141019     -0.213041    -0.186086
 -0.0599381   -0.0186431    -0.0957258    -0.178719     0.0286836   -0.0231038    0.036262   -0.0475477   -0.0987501    -0.0626599    0.104109     0.0257867    0.00110705   -0.0593762    0.0894345   -0.0793338    -0.151017     0.0575017   -0.123424    -0.112004     -0.0535162    0.0464653    0.00403422  -0.0576811     0.0491917   -0.0389407
 -0.0270019   -0.0298883     0.0447187     0.0392819    0.114529     0.208149    -0.0272211  -0.00786822   0.101655      0.0297443   -0.0734981   -0.0352453   -0.055977      0.0797393    0.0277741   -0.0843525     0.0443626   -0.170677    -0.0417765    0.0699567    -0.0187935    0.0983173    0.14319     -0.0324395    -0.0985821    0.0300758
 -0.124609    -0.0635543     0.0877686     0.0126784   -0.0880705   -0.0507898   -0.0857996  -0.012979    -0.0786483     0.152485    -0.209737     0.0191064   -0.0539984    -0.0609211    0.0985795    0.138403     -0.0543155   -0.0399648    0.199169     0.0275625    -0.0551422    0.00944976  -0.0151097   -0.17685       0.173939     0.0555429
 -0.0624259   -0.17155      -0.0473167    -0.0571673    0.0424752    0.0791343   -0.101188    0.0665855   -0.0215788    -0.144768    -0.0281005   -0.0187211   -0.0205111    -0.135192    -0.0428202    0.0096162     0.0353161    0.13808     -0.0593382   -0.18858       0.0414       0.0145047    0.172151    -0.00105672   -0.126521     0.070716
  0.0104994    0.0632956     0.102506     -0.174713    -0.00374397   0.0802884    0.0769421   0.0508976   -0.0544236    -0.0293876   -0.0403238    0.0344185   -0.0281234    -0.0282855   -0.0782016    0.127487     -0.0948647   -0.0322771   -0.167417     0.0681604     0.0126313   -0.0187424   -0.0444356   -0.119671      0.133897     0.181777
 -0.0184338    0.093594      0.00767379    0.108475    -0.234212     0.00843347   0.0214601   0.0428393   -0.0581321    -0.0469203   -0.0168718    0.0721157   -0.0300812    -0.113544     0.00963721  -0.000394528  -0.0822529    0.0136572   -0.247088    -0.0381104     0.0168333   -0.165807     0.00653523  -0.0772418     0.231061    -0.0203235
 -0.0187142   -0.113376      0.0925905    -0.0535276    0.11588     -0.0476803    0.0245071   0.0503164    0.00875126    0.0353734   -0.0198304   -0.177235     0.120854     -0.0160955   -0.121735     0.149698     -0.0381668    0.0576166    0.0327018   -0.052451     -0.027589    -0.118151     0.0386036    0.00772582   -0.0598785    0.0695829
 -0.0239197    0.174742      0.0174888     0.0205088    0.0131847    0.0324838    0.0228001  -0.0410514   -0.000852889   0.224083     0.0178671    0.0170562   -0.0764594    -0.0468807    0.178304     0.0256948     0.11084     -0.0660818    0.161981    -0.0386983     0.0479554    0.137001    -0.0907576    0.173193     -0.0717633    0.0392223
  0.0237375   -0.0868765    -0.0976102    -0.0479607   -0.0519767    0.00940726  -0.0984844   0.0386725    0.098562     -0.0608099    0.112707    -0.103039     0.0283608    -0.140333     0.0912179   -0.0262345    -0.0535802   -0.0204314   -0.0330516    0.00750328   -0.0648667   -0.173754     0.0405625    0.0540353     0.0539536    0.064328
  0.10449     -0.00407695    0.026698      0.0919282    0.145895     0.0525993    0.110422   -0.0569966   -0.157842     -0.0970964    0.0982711    0.0783762   -0.12333      -0.131156    -0.155849     0.164603     -0.109351     0.111687     0.0390864   -0.0442569    -0.133816    -0.15194      0.120172    -0.123353      0.0211697    0.0520235
  0.0885334    0.0796808     0.106564      0.047761     0.149738    -0.191519    -0.100318   -0.170879    -0.0126539    -0.0527715   -0.00986642  -0.154052    -0.109261      0.0536277   -0.110301     0.186743     -0.0152187   -0.178699     0.00118858  -0.0628196     0.0372565   -0.0171309   -0.0546898   -0.320498     -0.0402584   -0.00969069
 -0.0290534    0.0693433     0.0979715    -0.0970008    0.104527     0.248487     0.047842    0.0794507    0.109103      0.0298882   -0.155411     0.220095     0.132535      0.019611     0.0788638    0.0248089    -0.00370611  -0.136004    -0.0416394   -0.033486      0.281541     0.0391531   -0.0706992    0.0283349    -0.120662     0.101351
 -0.0454936    0.0522419     0.00856362    0.0589068    0.0170257    0.0722979    0.0600754   0.133253     0.155296      0.129891     0.0277167   -0.0356153    0.0639455    -0.0285668    0.0303875    0.138228     -0.0704624   -0.135903    -0.0386143    0.132818     -0.0350103    0.0529239    0.12339     -0.0900427     0.0936142    0.00286977
  0.0478534    0.0414351    -0.0965765     0.0786318    0.158073    -0.163872    -0.0705417   0.0780496    0.0767319    -0.00776393  -0.3604       0.00304681   0.000993917   0.0347451   -0.114002    -0.0457492     0.0646903    0.141705    -0.0968404   -0.101747      0.0202622    0.0706514   -0.0181811    0.0636141     0.168849     0.0053574
  0.0105058    0.0956365    -0.162425      0.162293     0.0737687    0.0940089   -0.0354225   0.0737696   -0.0377251     0.122412    -0.190888     0.0823706    0.0226025    -0.0305295   -0.100901    -0.101607     -0.09185     -0.0786832   -0.0267411    0.104068     -0.124043    -0.00269921  -0.0857739   -0.00204275   -0.109979    -0.0523692kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4250531139002727
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425073
[ Info: iteration 2, average log likelihood -1.425017
[ Info: iteration 3, average log likelihood -1.424981
[ Info: iteration 4, average log likelihood -1.424943
[ Info: iteration 5, average log likelihood -1.424900
[ Info: iteration 6, average log likelihood -1.424852
[ Info: iteration 7, average log likelihood -1.424801
[ Info: iteration 8, average log likelihood -1.424748
[ Info: iteration 9, average log likelihood -1.424699
[ Info: iteration 10, average log likelihood -1.424656
[ Info: iteration 11, average log likelihood -1.424621
[ Info: iteration 12, average log likelihood -1.424594
[ Info: iteration 13, average log likelihood -1.424574
[ Info: iteration 14, average log likelihood -1.424559
[ Info: iteration 15, average log likelihood -1.424547
[ Info: iteration 16, average log likelihood -1.424536
[ Info: iteration 17, average log likelihood -1.424524
[ Info: iteration 18, average log likelihood -1.424506
[ Info: iteration 19, average log likelihood -1.424474
[ Info: iteration 20, average log likelihood -1.424409
[ Info: iteration 21, average log likelihood -1.424267
[ Info: iteration 22, average log likelihood -1.423960
[ Info: iteration 23, average log likelihood -1.423353
[ Info: iteration 24, average log likelihood -1.422374
[ Info: iteration 25, average log likelihood -1.421242
[ Info: iteration 26, average log likelihood -1.420367
[ Info: iteration 27, average log likelihood -1.419894
[ Info: iteration 28, average log likelihood -1.419688
[ Info: iteration 29, average log likelihood -1.419606
[ Info: iteration 30, average log likelihood -1.419574
[ Info: iteration 31, average log likelihood -1.419561
[ Info: iteration 32, average log likelihood -1.419556
[ Info: iteration 33, average log likelihood -1.419554
[ Info: iteration 34, average log likelihood -1.419553
[ Info: iteration 35, average log likelihood -1.419552
[ Info: iteration 36, average log likelihood -1.419552
[ Info: iteration 37, average log likelihood -1.419552
[ Info: iteration 38, average log likelihood -1.419552
[ Info: iteration 39, average log likelihood -1.419552
[ Info: iteration 40, average log likelihood -1.419552
[ Info: iteration 41, average log likelihood -1.419552
[ Info: iteration 42, average log likelihood -1.419552
[ Info: iteration 43, average log likelihood -1.419552
[ Info: iteration 44, average log likelihood -1.419551
[ Info: iteration 45, average log likelihood -1.419551
[ Info: iteration 46, average log likelihood -1.419551
[ Info: iteration 47, average log likelihood -1.419551
[ Info: iteration 48, average log likelihood -1.419551
[ Info: iteration 49, average log likelihood -1.419551
[ Info: iteration 50, average log likelihood -1.419551
┌ Info: EM with 100000 data points 50 iterations avll -1.419551
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.425073429177003
│     -1.4250169467798715
│      ⋮
└     -1.4195513066454364
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419568
[ Info: iteration 2, average log likelihood -1.419519
[ Info: iteration 3, average log likelihood -1.419487
[ Info: iteration 4, average log likelihood -1.419454
[ Info: iteration 5, average log likelihood -1.419417
[ Info: iteration 6, average log likelihood -1.419375
[ Info: iteration 7, average log likelihood -1.419329
[ Info: iteration 8, average log likelihood -1.419282
[ Info: iteration 9, average log likelihood -1.419235
[ Info: iteration 10, average log likelihood -1.419190
[ Info: iteration 11, average log likelihood -1.419150
[ Info: iteration 12, average log likelihood -1.419114
[ Info: iteration 13, average log likelihood -1.419081
[ Info: iteration 14, average log likelihood -1.419052
[ Info: iteration 15, average log likelihood -1.419025
[ Info: iteration 16, average log likelihood -1.419000
[ Info: iteration 17, average log likelihood -1.418976
[ Info: iteration 18, average log likelihood -1.418953
[ Info: iteration 19, average log likelihood -1.418932
[ Info: iteration 20, average log likelihood -1.418911
[ Info: iteration 21, average log likelihood -1.418891
[ Info: iteration 22, average log likelihood -1.418871
[ Info: iteration 23, average log likelihood -1.418852
[ Info: iteration 24, average log likelihood -1.418833
[ Info: iteration 25, average log likelihood -1.418815
[ Info: iteration 26, average log likelihood -1.418798
[ Info: iteration 27, average log likelihood -1.418782
[ Info: iteration 28, average log likelihood -1.418766
[ Info: iteration 29, average log likelihood -1.418752
[ Info: iteration 30, average log likelihood -1.418739
[ Info: iteration 31, average log likelihood -1.418727
[ Info: iteration 32, average log likelihood -1.418715
[ Info: iteration 33, average log likelihood -1.418705
[ Info: iteration 34, average log likelihood -1.418695
[ Info: iteration 35, average log likelihood -1.418687
[ Info: iteration 36, average log likelihood -1.418679
[ Info: iteration 37, average log likelihood -1.418672
[ Info: iteration 38, average log likelihood -1.418665
[ Info: iteration 39, average log likelihood -1.418659
[ Info: iteration 40, average log likelihood -1.418653
[ Info: iteration 41, average log likelihood -1.418648
[ Info: iteration 42, average log likelihood -1.418644
[ Info: iteration 43, average log likelihood -1.418639
[ Info: iteration 44, average log likelihood -1.418636
[ Info: iteration 45, average log likelihood -1.418632
[ Info: iteration 46, average log likelihood -1.418629
[ Info: iteration 47, average log likelihood -1.418625
[ Info: iteration 48, average log likelihood -1.418623
[ Info: iteration 49, average log likelihood -1.418620
[ Info: iteration 50, average log likelihood -1.418617
┌ Info: EM with 100000 data points 50 iterations avll -1.418617
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.419567573541911
│     -1.4195192519572373
│      ⋮
└     -1.4186173610290642
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418627
[ Info: iteration 2, average log likelihood -1.418578
[ Info: iteration 3, average log likelihood -1.418539
[ Info: iteration 4, average log likelihood -1.418497
[ Info: iteration 5, average log likelihood -1.418447
[ Info: iteration 6, average log likelihood -1.418388
[ Info: iteration 7, average log likelihood -1.418320
[ Info: iteration 8, average log likelihood -1.418246
[ Info: iteration 9, average log likelihood -1.418168
[ Info: iteration 10, average log likelihood -1.418091
[ Info: iteration 11, average log likelihood -1.418019
[ Info: iteration 12, average log likelihood -1.417954
[ Info: iteration 13, average log likelihood -1.417897
[ Info: iteration 14, average log likelihood -1.417847
[ Info: iteration 15, average log likelihood -1.417804
[ Info: iteration 16, average log likelihood -1.417765
[ Info: iteration 17, average log likelihood -1.417730
[ Info: iteration 18, average log likelihood -1.417697
[ Info: iteration 19, average log likelihood -1.417666
[ Info: iteration 20, average log likelihood -1.417637
[ Info: iteration 21, average log likelihood -1.417610
[ Info: iteration 22, average log likelihood -1.417583
[ Info: iteration 23, average log likelihood -1.417559
[ Info: iteration 24, average log likelihood -1.417535
[ Info: iteration 25, average log likelihood -1.417513
[ Info: iteration 26, average log likelihood -1.417493
[ Info: iteration 27, average log likelihood -1.417474
[ Info: iteration 28, average log likelihood -1.417456
[ Info: iteration 29, average log likelihood -1.417439
[ Info: iteration 30, average log likelihood -1.417424
[ Info: iteration 31, average log likelihood -1.417410
[ Info: iteration 32, average log likelihood -1.417397
[ Info: iteration 33, average log likelihood -1.417385
[ Info: iteration 34, average log likelihood -1.417374
[ Info: iteration 35, average log likelihood -1.417363
[ Info: iteration 36, average log likelihood -1.417354
[ Info: iteration 37, average log likelihood -1.417345
[ Info: iteration 38, average log likelihood -1.417336
[ Info: iteration 39, average log likelihood -1.417328
[ Info: iteration 40, average log likelihood -1.417321
[ Info: iteration 41, average log likelihood -1.417314
[ Info: iteration 42, average log likelihood -1.417307
[ Info: iteration 43, average log likelihood -1.417301
[ Info: iteration 44, average log likelihood -1.417294
[ Info: iteration 45, average log likelihood -1.417288
[ Info: iteration 46, average log likelihood -1.417283
[ Info: iteration 47, average log likelihood -1.417277
[ Info: iteration 48, average log likelihood -1.417272
[ Info: iteration 49, average log likelihood -1.417267
[ Info: iteration 50, average log likelihood -1.417262
┌ Info: EM with 100000 data points 50 iterations avll -1.417262
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4186265524893247
│     -1.4185781545031149
│      ⋮
└     -1.4172616135470133
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417268
[ Info: iteration 2, average log likelihood -1.417212
[ Info: iteration 3, average log likelihood -1.417163
[ Info: iteration 4, average log likelihood -1.417108
[ Info: iteration 5, average log likelihood -1.417042
[ Info: iteration 6, average log likelihood -1.416964
[ Info: iteration 7, average log likelihood -1.416875
[ Info: iteration 8, average log likelihood -1.416780
[ Info: iteration 9, average log likelihood -1.416683
[ Info: iteration 10, average log likelihood -1.416589
[ Info: iteration 11, average log likelihood -1.416500
[ Info: iteration 12, average log likelihood -1.416415
[ Info: iteration 13, average log likelihood -1.416337
[ Info: iteration 14, average log likelihood -1.416264
[ Info: iteration 15, average log likelihood -1.416196
[ Info: iteration 16, average log likelihood -1.416133
[ Info: iteration 17, average log likelihood -1.416076
[ Info: iteration 18, average log likelihood -1.416024
[ Info: iteration 19, average log likelihood -1.415977
[ Info: iteration 20, average log likelihood -1.415934
[ Info: iteration 21, average log likelihood -1.415896
[ Info: iteration 22, average log likelihood -1.415861
[ Info: iteration 23, average log likelihood -1.415829
[ Info: iteration 24, average log likelihood -1.415799
[ Info: iteration 25, average log likelihood -1.415772
[ Info: iteration 26, average log likelihood -1.415746
[ Info: iteration 27, average log likelihood -1.415722
[ Info: iteration 28, average log likelihood -1.415700
[ Info: iteration 29, average log likelihood -1.415678
[ Info: iteration 30, average log likelihood -1.415658
[ Info: iteration 31, average log likelihood -1.415639
[ Info: iteration 32, average log likelihood -1.415621
[ Info: iteration 33, average log likelihood -1.415603
[ Info: iteration 34, average log likelihood -1.415586
[ Info: iteration 35, average log likelihood -1.415570
[ Info: iteration 36, average log likelihood -1.415555
[ Info: iteration 37, average log likelihood -1.415540
[ Info: iteration 38, average log likelihood -1.415526
[ Info: iteration 39, average log likelihood -1.415512
[ Info: iteration 40, average log likelihood -1.415499
[ Info: iteration 41, average log likelihood -1.415487
[ Info: iteration 42, average log likelihood -1.415475
[ Info: iteration 43, average log likelihood -1.415463
[ Info: iteration 44, average log likelihood -1.415451
[ Info: iteration 45, average log likelihood -1.415440
[ Info: iteration 46, average log likelihood -1.415430
[ Info: iteration 47, average log likelihood -1.415419
[ Info: iteration 48, average log likelihood -1.415409
[ Info: iteration 49, average log likelihood -1.415399
[ Info: iteration 50, average log likelihood -1.415389
┌ Info: EM with 100000 data points 50 iterations avll -1.415389
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4172683254985616
│     -1.417212091134162
│      ⋮
└     -1.415389393046674
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415388
[ Info: iteration 2, average log likelihood -1.415325
[ Info: iteration 3, average log likelihood -1.415265
[ Info: iteration 4, average log likelihood -1.415196
[ Info: iteration 5, average log likelihood -1.415110
[ Info: iteration 6, average log likelihood -1.415003
[ Info: iteration 7, average log likelihood -1.414874
[ Info: iteration 8, average log likelihood -1.414725
[ Info: iteration 9, average log likelihood -1.414564
[ Info: iteration 10, average log likelihood -1.414400
[ Info: iteration 11, average log likelihood -1.414241
[ Info: iteration 12, average log likelihood -1.414094
[ Info: iteration 13, average log likelihood -1.413962
[ Info: iteration 14, average log likelihood -1.413844
[ Info: iteration 15, average log likelihood -1.413742
[ Info: iteration 16, average log likelihood -1.413653
[ Info: iteration 17, average log likelihood -1.413577
[ Info: iteration 18, average log likelihood -1.413511
[ Info: iteration 19, average log likelihood -1.413454
[ Info: iteration 20, average log likelihood -1.413405
[ Info: iteration 21, average log likelihood -1.413362
[ Info: iteration 22, average log likelihood -1.413323
[ Info: iteration 23, average log likelihood -1.413288
[ Info: iteration 24, average log likelihood -1.413257
[ Info: iteration 25, average log likelihood -1.413228
[ Info: iteration 26, average log likelihood -1.413201
[ Info: iteration 27, average log likelihood -1.413176
[ Info: iteration 28, average log likelihood -1.413153
[ Info: iteration 29, average log likelihood -1.413131
[ Info: iteration 30, average log likelihood -1.413110
[ Info: iteration 31, average log likelihood -1.413090
[ Info: iteration 32, average log likelihood -1.413071
[ Info: iteration 33, average log likelihood -1.413052
[ Info: iteration 34, average log likelihood -1.413035
[ Info: iteration 35, average log likelihood -1.413017
[ Info: iteration 36, average log likelihood -1.413001
[ Info: iteration 37, average log likelihood -1.412984
[ Info: iteration 38, average log likelihood -1.412969
[ Info: iteration 39, average log likelihood -1.412953
[ Info: iteration 40, average log likelihood -1.412938
[ Info: iteration 41, average log likelihood -1.412923
[ Info: iteration 42, average log likelihood -1.412908
[ Info: iteration 43, average log likelihood -1.412894
[ Info: iteration 44, average log likelihood -1.412880
[ Info: iteration 45, average log likelihood -1.412866
[ Info: iteration 46, average log likelihood -1.412852
[ Info: iteration 47, average log likelihood -1.412838
[ Info: iteration 48, average log likelihood -1.412824
[ Info: iteration 49, average log likelihood -1.412810
[ Info: iteration 50, average log likelihood -1.412797
┌ Info: EM with 100000 data points 50 iterations avll -1.412797
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4153880296475547
│     -1.4153247220206733
│      ⋮
└     -1.4127967793027427
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4250531139002727
│     -1.425073429177003
│     -1.4250169467798715
│     -1.4249813274223575
│      ⋮
│     -1.4128241126970418
│     -1.4128104091189297
└     -1.4127967793027427
32×26 Array{Float64,2}:
 -0.0733924   -0.184424    -0.470585    0.279681    0.117779   -0.181009     -0.634051   -0.294736    0.481873    -0.392458    -0.0188552   -0.325162     0.1012      -0.456749   -0.757081     0.327977     0.303818    -0.486705    0.617768    0.23344       0.3971     -0.593076    -0.468578    0.770047     0.237506     0.300141
 -0.634217    -0.29985     -0.575926    0.26947     0.403004   -0.288564     -0.0494435   0.608237    0.306347     0.105662     0.48168      0.0865843    0.304551     0.0989126  -1.08841      0.532991    -0.768399    -0.194673    0.69725     0.349645     -0.287607    0.151042     0.15285    -0.0101541   -0.357153    -0.085502
 -0.359722     0.306011     0.218439    0.211151    0.0354715  -0.127115     -0.0809616  -0.109983    0.00848455   0.059439    -1.01254      0.0595926    0.186349    -0.142444    0.428291     0.758138    -0.474176     0.542652   -0.144251    0.169576     -0.660139    0.32853      0.104311   -0.368858    -0.239425     0.297862
 -0.509347     0.086214    -0.422756   -0.238339    0.592016   -0.0265768     0.434098    0.363896    0.286379     0.361805    -0.200807    -0.104938     0.25669      0.125632    0.259338     0.593314    -0.496943     0.38279     0.728605    0.574324      0.0710017   0.229297    -0.498343    0.51522      0.238045     0.316881
  0.00214695  -0.170345    -0.319205   -0.327843   -0.220621   -0.243839      0.523236    0.513013   -0.147438    -0.432799    -0.355849    -0.621358    -0.0294638   -0.116782    0.298803     0.199069     0.0337753    0.0749315  -0.132382    0.104503      0.0388598  -1.00708     -0.346511   -0.283063    -0.417602     0.451156
 -0.227605    -0.176447    -0.206885   -0.0280591  -0.610646   -0.550522      0.220295   -0.086249    0.0790985   -0.149488    -0.230032    -0.0235847    0.760115     0.0540536  -0.00421936   0.062395     0.0507256    0.417006   -0.335266   -0.0561035     0.0670619  -0.274328     0.0279485   0.546866     0.202759     0.0846722
  0.356537     0.433787    -0.444143   -0.26465     0.643033   -0.692401     -0.033607    0.380814   -0.296745    -0.0762147   -0.303547    -0.293984    -0.197566     0.34946     0.00805563  -0.266856     0.332391     0.276862    0.203581    0.302684     -0.27397    -0.571239     0.649359    0.0285054   -0.0528551   -0.643826
  0.141571     0.374289     0.653566   -0.0988178   0.456747   -0.185232      0.407124    0.443771   -0.172479    -0.155729    -0.0507177   -0.249692     0.0904308   -0.441148    0.661778    -0.00938182   0.0893345   -0.0455088   0.332101   -0.596193      0.178709   -0.786963    -0.239667    0.373036     0.23161     -0.403148
 -0.0182982   -0.267209    -0.454662    0.0552554  -0.146589    0.0572649    -0.157376   -0.346739    0.50705     -0.418983    -0.339904     0.409746    -0.407281    -0.459981   -0.085084     0.0738759   -0.127181    -0.44918    -0.529389   -0.91999      -0.342128    0.254295     0.600834   -0.450518    -0.119836    -0.210371
  0.0241242   -0.171621    -0.193793   -0.0133823   0.429548    0.0424341    -0.126795   -0.173144    0.0338728   -0.327649     0.0713688    0.290354     0.184758    -0.926849    0.188305    -0.122953    -0.143833    -0.17516     0.487257   -0.0424457    -0.127953   -0.145126    -0.0299136   0.0051161   -0.0361895   -0.0946451
  0.263382     0.39183      0.022387   -0.0312144  -0.335418   -0.266174      0.31238    -0.684603   -0.0700932    0.37078      0.766041     0.123216     0.35118      0.837851    0.158408     0.0446232    0.502368     0.0133223   0.237054    0.0474069    -0.37388     0.707889     0.555805   -0.0621734    0.409181    -0.217935
  0.140484     0.243252     0.374462    0.0148333  -0.262854    0.113382      0.153128    0.272092   -0.151072     0.270007    -0.218531    -0.146684    -0.185901     0.616582   -0.0307453   -0.0824525   -0.135449     0.218926   -0.508597   -0.0162532     0.107935    0.136654     0.0507755   0.0151891    0.0948107    0.00332083
 -0.153974    -0.289165     0.333059    0.0546126  -0.482426   -0.102551     -0.0596607   0.133984   -0.906866     0.19856      0.404528    -0.283513     0.356847    -0.147974    0.0336552   -0.370637    -0.117645    -0.0525474  -0.104707   -0.109866      0.407181    0.178976    -0.70783     0.0971675    0.238665    -0.00856863
 -0.0769303   -0.730272     0.0989102   0.0716749  -0.600441    0.546856      0.0473777  -0.48833     0.908238     0.13017      0.412408     0.190827     0.0793338   -0.270902   -0.0782978   -0.377772     0.311338     0.0751477  -0.421206   -0.0197619     0.549724    0.00263258  -0.726417   -0.210695     0.0825098    0.205935
  0.496993     0.154836     0.777919    0.591037   -0.0332913  -0.164285     -0.127096    0.37731    -0.558057     0.12845     -0.229574    -0.164739     0.261032    -0.0603636   0.127227    -0.034307     0.420406     0.160435    0.72634     0.548611      0.248314    0.0161088    0.0333535  -0.0649508    0.0396784    0.403702
  0.0636475   -0.00481928   0.588201    0.345288    1.24559     0.585402     -0.385714    0.377456   -0.28209     -0.17002      0.33018      0.455933    -0.363346    -0.106884   -0.0304657   -0.0958661   -0.145807    -0.25167    -0.157271    0.345976      0.0855598   0.321962    -0.508609    0.0669596    0.00873402   0.252119
  0.224826     0.0245087    0.149481   -0.412035    0.573855   -0.21945       0.0309284  -0.0197121  -0.028421     0.0684258   -0.195339     0.194252    -0.811627    -0.137609   -0.186568     0.567731     0.239233     0.127585    0.043419    0.265993      0.141271   -0.0579697    0.371339   -0.157217     0.669159     0.391921
  0.0394237    0.413654     0.22766    -0.0986998  -0.0660062   1.12512       0.224938   -0.0764644  -0.135913     0.635561    -0.0166072   -0.0727146   -0.612696     0.103316   -0.357276     0.329566    -0.452702    -0.0782088   0.0864295  -0.0664355    -0.0410803   0.11127     -0.370426   -0.48321      0.300762     0.0422427
 -0.150294     0.0353657   -0.252398   -0.126571    0.0665512   0.000117255   0.0994895  -0.0514092   0.128125    -0.133121    -0.00593869   0.0215566   -0.0517071   -0.134033    0.0179878    0.0534962   -0.00621526   0.0748753   0.092544   -0.000563798  -0.157505   -0.1433       0.0895813  -0.052954    -0.0652245   -0.0418799
  0.132056     0.11211      0.338257   -0.0250683   0.0957804  -0.0486259    -0.084352    0.118899   -0.178062     0.167089    -0.0622303   -0.118737    -0.124249     0.175982    0.108853    -0.0275863   -0.0698893   -0.0479859  -0.0834038   0.125746      0.1746      0.062817    -0.139499   -0.027131     0.148816     0.0505964
 -0.53292      0.0149696   -0.341604   -0.817706    0.0941754  -0.0399166    -0.414484   -0.113961    0.0323652   -0.213209     0.178235     0.305795    -0.22554      0.321075   -0.0822208    0.069382    -0.544692     0.16517    -0.48939     0.111059     -0.0899807   0.00618629   0.0864834   0.173904     0.0352915    0.0426321
 -0.43043     -0.212362    -0.840053   -0.438508    0.217721    0.324546      0.671158   -0.457839    0.52671     -0.0955528   -0.193475     0.0128559   -0.36714      0.0130195   0.0900309    0.33652     -0.278614     0.270291   -0.362582   -0.414987     -0.129974   -0.290335    -0.137437   -0.212145     0.0625879   -0.875847
 -0.324559    -0.50385     -0.022213    0.287107   -0.277168    0.501656      0.0188537  -0.410239   -0.0184464    0.0950002    0.441009     0.276461     3.7922e-5   -0.194584   -0.526442     0.396047    -0.130265    -0.186201    0.0923435  -0.199162     -0.102246    0.454808    -0.0477933  -0.125151    -0.198675     0.233419
 -0.384793    -0.797181     0.105249   -0.0309403   0.0677492   0.215036      0.111064   -0.442355    0.136746     0.00249143   0.611732    -0.00128181  -0.132363    -0.245847    0.603823     0.107807    -0.0983898   -0.0191211   0.172844    0.00351762   -0.064596    0.355808    -0.464613    0.00659562   0.125438     0.2013
  0.0179098    0.196249     0.0422742   0.134397   -0.25351    -0.182779     -0.754726   -0.102139    0.0952896   -0.0538876   -0.124966     0.165098    -0.227763     0.63323    -0.0514492   -0.549398     0.0687569   -0.284203   -0.307468    0.335812      0.0192462   0.747887     0.440359   -0.222478    -0.6584      -0.127631
  0.17569      0.145717     0.0645288   0.300515   -0.383598    0.0614383     0.621867    0.0658603   0.269682     0.0995658   -0.276059    -0.246268     0.0863574    0.454763   -0.146635     0.229537     0.11895      0.148266   -0.498515    0.287139      0.245369    0.188459     0.413822   -0.158941    -0.0339811    0.111111
  0.500771    -0.202493    -0.288468    0.255876   -0.0721497   0.0263617    -0.228127   -0.105259    0.168754     0.067282     0.232839     0.565535    -0.21332     -0.132881   -0.160529    -0.392239     0.628014    -0.164399   -0.658232   -0.148394      0.172838   -0.00242067   0.751466    0.00706428  -0.0595282    0.225665
  0.386362     0.0844335    0.65685    -0.271045   -0.645984    0.141417     -0.0146927  -0.479429   -0.37806     -0.238153    -0.237029     0.0296088   -0.00288821  -0.357852    0.318241    -0.372959     0.751972    -0.199596   -0.754596   -0.675457     -0.01381    -0.264374     0.718816   -0.680676     0.0977979   -0.114973
  0.605485     0.104082     0.0157163   0.0998876   0.131862   -0.0479878     0.0125897   0.116917   -0.639122     0.130951     0.432807    -0.156996     0.090919    -0.0721803  -0.336564    -0.269482    -0.499735    -0.725664    0.377646   -0.379966     -0.926819   -0.0691742    0.0793837  -0.0131002    0.0600464   -0.0934105
  0.312133     0.224304    -0.0792187   0.0490123   0.191011   -0.0935161    -0.375457    0.342951    0.164276    -0.318436     0.1456      -0.263115    -0.236605     0.285153   -0.241219    -0.461862     0.0960241   -0.79747     0.261487   -0.183791      0.334339   -0.2174       0.159596    0.497466    -0.21608     -0.335032
  0.157616     0.253151     0.225311    0.193337   -0.225182    0.0929866    -0.306665   -0.0777753   0.199761    -0.0187254   -0.139696     0.154163     0.440245    -0.249962    0.274824    -0.677128    -0.48364     -0.0549214  -0.527872   -0.491769     -0.0992371   0.0209984   -0.437706   -0.0721229   -0.240759    -0.314681
  0.0755974    0.0733046   -0.306836    0.249961    0.245637    0.0153217    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.23043    -0.118464    0.161941    -0.278854    -0.143662     0.213779     0.362547    -0.67111     0.0844671   -0.446646    -0.0806052    0.238947    0.567855    0.220231     -0.283224   -0.061126    -0.0750438  -0.10058     -0.416622    -0.494384[ Info: iteration 1, average log likelihood -1.412783
[ Info: iteration 2, average log likelihood -1.412770
[ Info: iteration 3, average log likelihood -1.412756
[ Info: iteration 4, average log likelihood -1.412743
[ Info: iteration 5, average log likelihood -1.412730
[ Info: iteration 6, average log likelihood -1.412717
[ Info: iteration 7, average log likelihood -1.412704
[ Info: iteration 8, average log likelihood -1.412692
[ Info: iteration 9, average log likelihood -1.412680
[ Info: iteration 10, average log likelihood -1.412667
┌ Info: EM with 100000 data points 10 iterations avll -1.412667
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.174499e+05
      1       7.128753e+05      -2.045746e+05 |       32
      2       6.968996e+05      -1.597562e+04 |       32
      3       6.912056e+05      -5.694016e+03 |       32
      4       6.884119e+05      -2.793752e+03 |       32
      5       6.866099e+05      -1.802016e+03 |       32
      6       6.852864e+05      -1.323472e+03 |       32
      7       6.842905e+05      -9.959269e+02 |       32
      8       6.834752e+05      -8.152156e+02 |       32
      9       6.828304e+05      -6.448664e+02 |       32
     10       6.822931e+05      -5.373210e+02 |       32
     11       6.818560e+05      -4.370787e+02 |       32
     12       6.814702e+05      -3.857863e+02 |       32
     13       6.811104e+05      -3.597407e+02 |       32
     14       6.808087e+05      -3.017756e+02 |       32
     15       6.805450e+05      -2.636444e+02 |       32
     16       6.802976e+05      -2.474360e+02 |       32
     17       6.800792e+05      -2.184083e+02 |       32
     18       6.798868e+05      -1.923780e+02 |       32
     19       6.797303e+05      -1.565059e+02 |       32
     20       6.796000e+05      -1.302679e+02 |       32
     21       6.794672e+05      -1.328754e+02 |       32
     22       6.793411e+05      -1.260517e+02 |       32
     23       6.792265e+05      -1.145685e+02 |       32
     24       6.791128e+05      -1.137278e+02 |       32
     25       6.790038e+05      -1.089618e+02 |       32
     26       6.788987e+05      -1.051265e+02 |       32
     27       6.787910e+05      -1.077061e+02 |       32
     28       6.786858e+05      -1.051874e+02 |       32
     29       6.785851e+05      -1.006998e+02 |       32
     30       6.784855e+05      -9.960065e+01 |       32
     31       6.783746e+05      -1.109370e+02 |       32
     32       6.782609e+05      -1.137183e+02 |       32
     33       6.781520e+05      -1.088411e+02 |       32
     34       6.780481e+05      -1.039228e+02 |       32
     35       6.779497e+05      -9.840681e+01 |       32
     36       6.778552e+05      -9.448753e+01 |       32
     37       6.777697e+05      -8.555912e+01 |       32
     38       6.776892e+05      -8.044986e+01 |       32
     39       6.776143e+05      -7.488607e+01 |       32
     40       6.775463e+05      -6.800797e+01 |       32
     41       6.774838e+05      -6.247188e+01 |       32
     42       6.774279e+05      -5.596714e+01 |       32
     43       6.773814e+05      -4.645455e+01 |       32
     44       6.773339e+05      -4.752931e+01 |       32
     45       6.772845e+05      -4.939304e+01 |       32
     46       6.772436e+05      -4.092288e+01 |       32
     47       6.772085e+05      -3.502486e+01 |       32
     48       6.771745e+05      -3.409037e+01 |       32
     49       6.771404e+05      -3.401997e+01 |       32
     50       6.771060e+05      -3.442187e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 677106.0123581686)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424469
[ Info: iteration 2, average log likelihood -1.419382
[ Info: iteration 3, average log likelihood -1.417918
[ Info: iteration 4, average log likelihood -1.416799
[ Info: iteration 5, average log likelihood -1.415703
[ Info: iteration 6, average log likelihood -1.414789
[ Info: iteration 7, average log likelihood -1.414193
[ Info: iteration 8, average log likelihood -1.413856
[ Info: iteration 9, average log likelihood -1.413659
[ Info: iteration 10, average log likelihood -1.413529
[ Info: iteration 11, average log likelihood -1.413433
[ Info: iteration 12, average log likelihood -1.413355
[ Info: iteration 13, average log likelihood -1.413289
[ Info: iteration 14, average log likelihood -1.413231
[ Info: iteration 15, average log likelihood -1.413179
[ Info: iteration 16, average log likelihood -1.413132
[ Info: iteration 17, average log likelihood -1.413089
[ Info: iteration 18, average log likelihood -1.413048
[ Info: iteration 19, average log likelihood -1.413011
[ Info: iteration 20, average log likelihood -1.412976
[ Info: iteration 21, average log likelihood -1.412943
[ Info: iteration 22, average log likelihood -1.412913
[ Info: iteration 23, average log likelihood -1.412884
[ Info: iteration 24, average log likelihood -1.412857
[ Info: iteration 25, average log likelihood -1.412831
[ Info: iteration 26, average log likelihood -1.412807
[ Info: iteration 27, average log likelihood -1.412784
[ Info: iteration 28, average log likelihood -1.412762
[ Info: iteration 29, average log likelihood -1.412741
[ Info: iteration 30, average log likelihood -1.412722
[ Info: iteration 31, average log likelihood -1.412703
[ Info: iteration 32, average log likelihood -1.412685
[ Info: iteration 33, average log likelihood -1.412668
[ Info: iteration 34, average log likelihood -1.412652
[ Info: iteration 35, average log likelihood -1.412636
[ Info: iteration 36, average log likelihood -1.412622
[ Info: iteration 37, average log likelihood -1.412607
[ Info: iteration 38, average log likelihood -1.412594
[ Info: iteration 39, average log likelihood -1.412581
[ Info: iteration 40, average log likelihood -1.412568
[ Info: iteration 41, average log likelihood -1.412556
[ Info: iteration 42, average log likelihood -1.412544
[ Info: iteration 43, average log likelihood -1.412533
[ Info: iteration 44, average log likelihood -1.412523
[ Info: iteration 45, average log likelihood -1.412512
[ Info: iteration 46, average log likelihood -1.412502
[ Info: iteration 47, average log likelihood -1.412493
[ Info: iteration 48, average log likelihood -1.412484
[ Info: iteration 49, average log likelihood -1.412475
32×26 Array{Float64,2}:
[ Info: iteration 50, average log likelihood -1.412466
┌ Info: EM with 100000 data points 50 iterations avll -1.412466
└ 59.0 data points per parameter
 -0.154679   -0.441675    0.761303    0.164993    0.181839     0.696295     0.017114    -0.0990048   0.0786689    0.121182     0.585017    0.247543     0.0524877  -0.194185    0.457085   -0.413805    0.0101439    0.178088    -0.564167     0.251386     0.284613      0.0796236  -0.810465   -0.00601401   0.0964175     0.40369
  0.214458    0.39337     0.210649   -0.146258    0.448805     0.90484     -0.574568    -0.595257   -0.142348     0.366482     0.073763    0.457287    -0.224077   -0.369218   -0.218107   -0.367858   -0.597179    -0.241177     0.784391     0.110416    -0.177802      0.439936   -0.0542881  -0.0157375    0.477776     -0.237119
  0.274204   -0.0355992   0.305766   -0.188807   -0.75516      0.107341    -0.0640852   -0.651302   -0.304729    -0.167973    -0.176154    0.0760963    0.112612   -0.503655    0.272278   -0.38132     0.698833    -0.127086    -0.875692    -0.671159     0.20965      -0.19751     0.564384   -0.483728     0.0735211     0.0743243
 -0.0137464  -0.0689231  -0.131671    0.013537   -0.00230754   0.00603544   0.00929024  -0.0874938  -0.00266598   0.223927     0.175543   -0.220395     0.0891465  -0.254633    0.1008     -0.195485   -0.302931     0.0622486   -0.0358651   -0.252306     0.229942     -0.275213   -0.685922    0.144016    -0.053456     -0.244694
  0.298361    0.0963278   0.0941768   0.104746   -0.0203534   -0.0843329    0.2286       0.115272    0.049183    -0.105562    -0.0985122  -0.00613015   0.0721831   0.0178647   0.0298046  -0.0358209   0.192575     0.0190978   -0.0240802    0.00208173  -0.0113416    -0.180034    0.251346   -0.0131331    0.0558937     0.058635
  0.799528    0.0579177   0.428586    0.164529   -0.146629     0.639655     0.0783226    0.538388   -0.608673     0.107353     0.0052341  -0.488772    -0.571214    0.120071   -0.0457067  -0.012177   -0.0856136   -0.677706     0.14238     -0.470789    -0.279896     -0.190416   -0.151997   -0.34676      0.180387      0.379883
  0.174313   -0.0472559  -0.0259941   0.203782    0.0580373    0.115256     0.373257    -0.0905271  -0.0195179   -0.127542    -0.045428   -0.393213     0.33537    -0.65455     0.25148    -0.440778    0.418216    -0.0638461    0.94265      0.356889     0.0279292    -0.110462   -0.163683   -0.487166    -0.4385       -0.285354
 -0.350856    0.0360519  -0.240187   -0.433025   -0.200688     0.161039    -1.09331     -0.141393   -0.0616056   -0.196231     0.159265    0.0188546   -0.389522    0.756569   -0.629767   -0.0293214  -0.432939    -0.0582653   -0.693396     0.486889     0.0105188     0.31256    -0.279144   -0.0937691   -0.0324152     0.227079
 -0.0811027  -0.294825   -0.297119    0.165565    0.338413     0.108998    -0.412802    -0.342572    0.32153     -0.68438     -0.0364518   0.0891568   -0.062222   -0.865167   -0.0495745   0.17024     0.199653    -0.4614       0.421986    -0.0141124    0.0190593    -0.153274   -0.0861744   0.193824    -0.0528755     0.274665
 -0.204185    0.357462   -0.221041   -0.0418351  -0.0992349   -0.018955    -0.201014     0.103608    0.177801    -0.135853    -0.212411   -0.147736     0.241899    0.305884    0.15048    -0.337468   -0.3932      -0.176708    -0.189653     0.149554    -0.14407       0.193168    0.134922    0.104564    -0.41139      -0.381884
 -0.535005   -0.275126   -0.517394   -0.321472   -0.0782814   -0.234786     0.197987    -0.663403    0.20523     -0.160398     0.18597     0.478132     0.458378   -0.38529     0.0871817   0.0788406  -0.130669     0.747682    -0.169897     0.0937194    0.064827     -0.236407    0.0545094   0.205748     0.0663078    -0.270126
  0.0594058   0.120851    0.484467   -0.215873    0.35983     -0.157609    -0.33687      0.247059   -0.409251     0.159659    -0.0240635  -0.0318489   -0.428704    0.203721    0.0340981   0.144232   -0.145945    -0.114273     0.0313422    0.351878     0.264855      0.243579   -0.172802   -0.0874841    0.3508        0.158321
  0.484087    0.343892    0.220244    0.303727   -0.202447    -0.026842    -0.279439    -0.0349252   0.177413    -0.162601     0.042671    0.296728     0.3007     -0.502551    0.0276428  -0.782235   -0.501766    -0.200163    -0.428808    -1.0676      -0.577239      0.0345517  -0.131909   -0.15039     -0.0890187    -0.453335
 -0.401571   -0.185926   -0.112961   -0.14471     0.0238398    0.269714    -0.017035    -0.331614    0.104251    -0.0387276    0.15931     0.135187    -0.215318   -0.18229     0.012987    0.250734   -0.0661237    0.0270797    0.00894843  -0.100169    -0.154463      0.145584   -0.0477828  -0.124268     0.0139652     0.133345
  0.0793173   0.162029    0.142204    0.0531224  -0.167959    -0.15912      0.173232     0.0407486  -0.112278     0.237435     0.0558011  -0.0188318    0.117778    0.358685    0.0672633  -0.0704672   0.00868517   0.164976    -0.123063    -0.00237434   0.00523073    0.218081    0.171467   -0.0456645    0.0901849    -0.118183
 -0.100524   -0.216493   -0.0273747   0.771105   -0.572529     0.376307     0.280803    -0.337468    0.322869     0.14899     -0.3499      0.0948598    0.173226   -0.046903   -0.4471      0.186797    0.0575018   -0.0757301   -0.436514     0.0794352    0.29431       0.623103    0.0432296  -0.228064    -0.204202      0.29726
 -0.237999   -0.221814   -0.160968   -0.370476   -0.479072    -0.398211     0.397271     0.288405    0.0654939   -0.424591    -0.372921   -0.287464     0.190691    0.42991     0.152756    0.322013    0.105745     0.140372    -0.518276     0.0924866    0.0334977    -0.358175    0.173916    0.214748     0.0646589     0.408171
  0.299097   -0.445367   -0.28719    -0.342153    0.0406163   -0.0114544    0.467819    -0.502736   -0.349158    -0.101847     0.735485    0.0412566   -0.46443     0.174524   -0.368977    0.220812    0.180799    -0.346192     0.0474363    0.618736    -0.162771      0.541383    0.435388   -0.206614     0.721307      0.207996
 -0.492601    0.285204   -0.442993    0.0159799   0.499021    -0.196786     0.0517716    0.345106    0.69939      0.085294    -0.163855    0.302873    -0.0552289   0.2713     -0.111671    0.582428   -0.689564     0.331883     0.810534     0.590449    -0.230859      0.327816    0.0533487   0.435745    -0.319458      0.173785
  0.120359   -0.296862   -0.407003   -0.18683     0.0442053   -0.224847    -0.186844     0.209415    0.195155    -0.194581     0.96158     0.0789908   -0.0983292   0.0588779  -0.377319   -0.543034    0.318621    -0.624022     0.163458    -0.352963     0.571073     -0.319386   -0.0252441   0.550394     0.010477     -0.539484
 -0.374244   -0.294635   -0.878796   -0.390236    0.151755     0.378417     0.524968    -0.439911    0.724134    -0.215592    -0.405957   -0.0268281   -0.585581   -0.0252965  -0.054483    0.469728   -0.373494     0.00331061  -0.456951    -0.627233    -0.242682     -0.19841    -0.0214326  -0.375117     0.0213244    -0.714539
 -0.289797   -0.556198    0.472868    0.499847   -0.100939     0.450844     0.00385208  -0.217083   -0.367274     0.246306     1.21304     0.0813884    0.0998939   0.0453365  -0.289578    0.23203    -0.350754    -0.454458     0.446143    -0.304715    -0.361909      0.54902    -0.254751    0.0288468   -0.504611      0.0650356
 -0.40067    -0.276189    0.328932   -0.0289669  -0.128811    -0.00786893  -0.177326     0.267304   -0.126309    -0.0117663   -0.905801   -0.0123698    0.36246    -0.499255    0.409197    0.138908   -0.874322     0.422734    -0.388821    -0.0849498   -0.24981       0.0445195  -0.611398   -0.458859    -0.444786      0.0835768
  0.245473   -0.0700428   0.394408    0.588095   -0.189348    -0.558483    -0.628787     0.381341   -0.240779    -0.094918    -0.296555   -0.0567628    0.540483   -0.0482789   0.0680488  -0.131204    0.302847    -0.071548     0.550549     0.308592     0.239093     -0.0348401  -0.210448    0.453053    -0.000887991   0.331261
 -0.369839   -0.154575   -0.282139   -0.23913     0.410865     0.205567     0.526213     0.36841     0.0620246    0.474003     0.0380166  -0.329345     0.310975   -0.306681   -0.11594     0.723731   -0.436329     0.0338019    0.670057     0.211472     0.0666007    -0.17311    -0.666918    0.375995     0.549159      0.398466
  0.301386    0.153616   -0.279666   -0.191951    0.927965    -0.0787576   -0.347742     0.0500134   0.324945     0.194423    -0.465184    0.459901    -0.771687   -0.334505   -0.169403    0.187012    0.254827     0.0373108   -0.521342    -0.0305021    0.000828008  -0.248058    0.437208   -0.0101589    0.522385      0.0321028
  0.343719    0.66776    -0.422462   -0.175546    0.423061    -0.750008    -0.0192921    0.182694   -0.60678     -0.00784589  -0.395111   -0.515351    -0.177829    0.158677   -0.236435    0.22447     0.0665291    0.0136159    0.494099     0.199872    -0.446508     -0.380916    0.761745    0.0322084    0.0851766    -0.360962
  0.0621088   0.26034     0.282104   -0.409006   -0.350804     0.429007     0.618231    -0.0196569   0.0212638    0.965877     0.316177    0.020502    -0.290698    0.907208    0.0562751   0.154679   -0.192469     0.366284    -0.572513    -0.179181     0.141419      0.26797     0.122238   -0.134649     0.252666     -0.301541
  0.0884224   0.510741    0.515229   -0.265945    0.479477    -0.288094     0.320465     0.46393    -0.213542    -0.331327    -0.1383     -0.322067    -0.0114425  -0.161052    0.628758   -0.160577    0.0209988    0.137854     0.226138    -0.430293     0.128304     -0.721367   -0.251584    0.346715     0.136853     -0.49815
 -0.17122    -0.542408   -0.498473   -0.0651122   0.391999    -0.341063    -0.232685     0.341575   -0.185479    -0.389584     0.257251    0.52927      0.0221111  -0.441345   -0.0908511  -0.109595   -0.309869    -0.173429     0.431363    -0.0268282   -0.813202     -0.23416     0.122112   -0.597525    -0.342768     -0.168225
  0.467631    0.308302    0.217247    0.271973    0.0581337   -0.117197    -0.50816      0.0493419   0.133978    -0.0492542   -0.0569508   0.395713    -0.244387    0.579972   -0.0739905  -0.608702    0.519673    -0.155642    -0.360368     0.146034     0.0800988     0.276202    0.809055   -0.159517    -0.617295     -0.127128
  0.358752    0.409109    0.421219    0.505962    0.122769     0.163141     0.644916     0.216932   -0.0278412    0.293773    -0.754028   -0.364225    -0.300648    0.0225215  -0.137848    0.520433    0.226203     0.757897    -0.0947089    0.82746      0.164056     -0.168046    0.0477869  -0.431514     0.136983      0.443762[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412458
[ Info: iteration 2, average log likelihood -1.412450
[ Info: iteration 3, average log likelihood -1.412442
[ Info: iteration 4, average log likelihood -1.412434
[ Info: iteration 5, average log likelihood -1.412427
[ Info: iteration 6, average log likelihood -1.412420
[ Info: iteration 7, average log likelihood -1.412413
[ Info: iteration 8, average log likelihood -1.412406
[ Info: iteration 9, average log likelihood -1.412399
[ Info: iteration 10, average log likelihood -1.412393
┌ Info: EM with 100000 data points 10 iterations avll -1.412393
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
