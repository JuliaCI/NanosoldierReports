Julia Version 1.3.1-pre.13
Commit 8639e5771d (2019-12-07 10:31 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)

   Cloning default registries into `~/.julia`
   Cloning registry from "https://github.com/JuliaRegistries/General.git"
[?25l    Fetching: [>                                        ]  0.0 %    Fetching: [============>                            ]  29.3 %    Fetching: [=========================>               ]  62.1 %[2K[?25h     Added registry `General` to `~/.julia/registries/General`
 Resolving package versions...
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.2
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.0
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed SpecialFunctions â”€â”€â”€ v0.9.0
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed OrderedCollections â”€ v1.1.0
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed Polynomials â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed OpenSpecFun_jll â”€â”€â”€â”€ v0.5.3+1
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.6
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+1
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.21.11
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [f27b6e38] + Polynomials v0.6.0
  [1fd47b50] + QuadGK v2.2.0
  [3cdcf5f2] + RecipesBase v0.7.0
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Building Rmath â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_2HLgeE/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [f27b6e38] Polynomials v0.6.0
  [1fd47b50] QuadGK v2.2.0
  [3cdcf5f2] RecipesBase v0.7.0
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -826674.5466862749, [54753.682014344144, 45246.317985655856], [24114.93736893727 -18113.74502024084 -17842.686425015883; -24229.059065058536 18276.464943915187 17922.928305517387], Array{Float64,2}[[65701.4425571654 642.4463326845917 6467.782958172984; 642.4463326845918 54633.46566289345 -3324.2872841805993; 6467.782958172984 -3324.2872841805993 58654.57174451627], [34093.80097464157 -330.3884105701049 -6086.34687661621; -330.3884105701048 46302.699444084596 3463.133766905665; -6086.34687661621 3463.1337669056657 40816.46114516466]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /workspace/srcdir/julia/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.746087e+03
      1       1.337519e+03      -4.085676e+02 |        7
      2       1.316159e+03      -2.135997e+01 |        2
      3       1.298384e+03      -1.777596e+01 |        2
      4       1.296566e+03      -1.817770e+00 |        0
      5       1.296566e+03       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 1296.5657483200239)
â”Œ Info: K-means with 272 data points using 5 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.085564
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.784882
[ Info: iteration 2, lowerbound -3.679470
[ Info: iteration 3, lowerbound -3.569904
[ Info: iteration 4, lowerbound -3.442495
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.295867
[ Info: iteration 6, lowerbound -3.137948
[ Info: iteration 7, lowerbound -2.997857
[ Info: iteration 8, lowerbound -2.892405
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -2.811432
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.741017
[ Info: iteration 11, lowerbound -2.677033
[ Info: iteration 12, lowerbound -2.628131
[ Info: dropping number of Gaussions to 3
[ Info: iteration 13, lowerbound -2.574548
[ Info: iteration 14, lowerbound -2.520562
[ Info: iteration 15, lowerbound -2.473130
[ Info: iteration 16, lowerbound -2.430806
[ Info: iteration 17, lowerbound -2.393812
[ Info: iteration 18, lowerbound -2.361246
[ Info: iteration 19, lowerbound -2.333408
[ Info: iteration 20, lowerbound -2.313910
[ Info: iteration 21, lowerbound -2.307421
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.302933
[ Info: iteration 23, lowerbound -2.299260
[ Info: iteration 24, lowerbound -2.299256
[ Info: iteration 25, lowerbound -2.299254
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Dec  8 12:05:41 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Dec  8 12:05:49 2019: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Sun Dec  8 12:05:51 2019: EM with 272 data points 0 iterations avll -2.085564
5.8 data points per parameter
, Sun Dec  8 12:05:52 2019: GMM converted to Variational GMM
, Sun Dec  8 12:06:02 2019: iteration 1, lowerbound -3.784882
, Sun Dec  8 12:06:02 2019: iteration 2, lowerbound -3.679470
, Sun Dec  8 12:06:02 2019: iteration 3, lowerbound -3.569904
, Sun Dec  8 12:06:02 2019: iteration 4, lowerbound -3.442495
, Sun Dec  8 12:06:02 2019: dropping number of Gaussions to 7
, Sun Dec  8 12:06:02 2019: iteration 5, lowerbound -3.295867
, Sun Dec  8 12:06:02 2019: iteration 6, lowerbound -3.137948
, Sun Dec  8 12:06:02 2019: iteration 7, lowerbound -2.997857
, Sun Dec  8 12:06:02 2019: iteration 8, lowerbound -2.892405
, Sun Dec  8 12:06:02 2019: dropping number of Gaussions to 6
, Sun Dec  8 12:06:02 2019: iteration 9, lowerbound -2.811432
, Sun Dec  8 12:06:02 2019: dropping number of Gaussions to 4
, Sun Dec  8 12:06:02 2019: iteration 10, lowerbound -2.741017
, Sun Dec  8 12:06:02 2019: iteration 11, lowerbound -2.677033
, Sun Dec  8 12:06:02 2019: iteration 12, lowerbound -2.628131
, Sun Dec  8 12:06:02 2019: dropping number of Gaussions to 3
, Sun Dec  8 12:06:02 2019: iteration 13, lowerbound -2.574548
, Sun Dec  8 12:06:02 2019: iteration 14, lowerbound -2.520562
, Sun Dec  8 12:06:02 2019: iteration 15, lowerbound -2.473130
, Sun Dec  8 12:06:02 2019: iteration 16, lowerbound -2.430806
, Sun Dec  8 12:06:02 2019: iteration 17, lowerbound -2.393812
, Sun Dec  8 12:06:02 2019: iteration 18, lowerbound -2.361246
, Sun Dec  8 12:06:02 2019: iteration 19, lowerbound -2.333408
, Sun Dec  8 12:06:02 2019: iteration 20, lowerbound -2.313910
, Sun Dec  8 12:06:02 2019: iteration 21, lowerbound -2.307421
, Sun Dec  8 12:06:02 2019: dropping number of Gaussions to 2
, Sun Dec  8 12:06:02 2019: iteration 22, lowerbound -2.302933
, Sun Dec  8 12:06:02 2019: iteration 23, lowerbound -2.299260
, Sun Dec  8 12:06:02 2019: iteration 24, lowerbound -2.299256
, Sun Dec  8 12:06:02 2019: iteration 25, lowerbound -2.299254
, Sun Dec  8 12:06:02 2019: iteration 26, lowerbound -2.299254
, Sun Dec  8 12:06:02 2019: iteration 27, lowerbound -2.299253
, Sun Dec  8 12:06:02 2019: iteration 28, lowerbound -2.299253
, Sun Dec  8 12:06:02 2019: iteration 29, lowerbound -2.299253
, Sun Dec  8 12:06:02 2019: iteration 30, lowerbound -2.299253
, Sun Dec  8 12:06:02 2019: iteration 31, lowerbound -2.299253
, Sun Dec  8 12:06:02 2019: iteration 32, lowerbound -2.299253
, Sun Dec  8 12:06:02 2019: iteration 33, lowerbound -2.299253
, Sun Dec  8 12:06:02 2019: iteration 34, lowerbound -2.299253
, Sun Dec  8 12:06:02 2019: iteration 35, lowerbound -2.299253
, Sun Dec  8 12:06:02 2019: iteration 36, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 37, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 38, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 39, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 40, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 41, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 42, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 43, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 44, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 45, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 46, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 47, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 48, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 49, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: iteration 50, lowerbound -2.299253
, Sun Dec  8 12:06:03 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509222601644, 95.95490777398356]
Î² = [178.04509222601644, 95.95490777398356]
m = [4.2503007332698886 79.28686694436156; 2.000229257775348 53.85198717246118]
Î½ = [180.04509222601644, 97.95490777398356]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554748379 -0.007644049042327382; 0.0 0.008581705166333187], [0.37587636119487816 -0.00895312382734675; 0.0 0.01274866477740953]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000006
avll from stats: -0.9959230959375398
avll from llpg:  -0.9959230959375421
avll direct:     -0.995923095937542
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9756432243974992
avll from llpg:  -0.9756432243974992
avll direct:     -0.9756432243974993
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
 -0.0109477   -0.0302755  -0.116241     0.130161    -0.0455114   -0.253373      0.196844     0.0863918   -0.0347501    0.00895451  -0.160386    -0.127567      0.00682453  -0.0174866    0.12845    -0.193474      0.0768884   -0.056053    -0.144984    0.239361     0.0503398    0.00966918  -0.044655     -0.159251    -0.197706     -0.0192853  
  0.162501     0.155334   -0.0337043    0.182644    -0.157919     0.0400544     0.138262     0.0768188   -0.0123836    0.139371     0.0761435   -0.187723     -0.165637     0.0334654   -0.0567709  -0.000995931  -0.249069     0.045731    -0.0399634   0.063288    -0.105802     0.0495835    0.169507      0.123849    -0.132478     -0.063659   
 -0.0134168    0.121428    0.0822279   -0.0672064   -0.029631    -0.0687988     0.0358813   -0.0207302    0.0903487   -0.00943277  -0.159297     0.153263     -0.01296     -0.118291    -0.0609522   0.0633624     0.149962    -0.10274      0.114335    0.0130264    0.0742676   -0.189926    -0.0210811     0.0372878   -0.0216431    -0.119986   
  0.0150202   -0.0742799   0.0826372   -0.132706     0.0739027   -0.0617076     0.158917     0.0824521    0.0325456   -0.00932981   0.0347423   -0.0350199    -0.075125    -0.0257687   -0.0124831   0.0680617    -0.117463     0.0383372    0.0744569   0.0635721   -0.238659     0.00682747  -0.0943098    -0.130046     0.00737743   -0.00440812 
 -0.179394    -0.0476082  -0.167858    -0.0971606    0.0323746   -0.131721      0.0957832   -0.0846697    0.0932951    0.0785085   -0.0292393    0.0250014     0.0595934    0.0590968   -0.0541929   0.00327026    0.0710127   -0.0298527   -0.203955   -0.0356259    0.120101     0.021645     0.102269     -0.0118472   -0.0524648     0.0797202  
  0.26168      0.0381577   0.111823     0.00842239  -0.0220163    0.0385745     0.0262544   -0.11511     -0.0795868    0.216777    -0.0358294   -0.0368507     0.173979     0.0465697    0.046448    0.0322144     0.0112211    0.145341     0.197106    0.0359909    0.148383     0.132104    -0.0555081    -0.101363     0.0508789    -0.076553   
 -0.0575289   -0.076638    0.168488     0.0243475    0.0145221    0.119225     -0.0445878   -0.0704031   -0.0757773   -0.0242196   -0.00611949  -0.051084      0.0516112    0.106737     0.183809    0.0583594    -0.119553    -0.00366823   0.0709526  -0.00288898  -0.10319      0.042752    -0.0348093    -0.0786441   -0.0232466     0.0891857  
  0.0755423    0.0268201  -0.237605     0.0153577    0.00829282  -0.0243376    -0.18908      0.0204373    0.0578708    0.0272046    0.0187726    0.126701      0.0156897   -0.0467935    0.0521683   0.0416365    -0.066379    -0.061065     0.166091    0.125953     0.0343912    0.135101    -0.00743693   -0.0448965    0.13876      -0.0878085  
  0.103661    -0.0136415   0.0279234    0.144451    -0.114019     0.0568196    -0.041266     0.0404027    0.140557     0.0604421    0.119469     0.0252324     0.0447906   -0.157492    -0.182707    0.0879661    -0.0637248    0.0537256   -0.027106    0.134593     0.147558     0.0325185    0.0662588     0.00988703   0.0957824     0.0503511  
 -0.0822645   -0.0100247   0.0418232    0.020973     0.0620297    0.170843     -0.152028     0.103659    -0.135277     0.156413     0.00624765   0.0422564     0.121814    -0.143835    -0.0169097   0.0992918     0.0245661   -0.0632849    0.0158103   0.122492     0.0070038   -0.00747993   0.121724      0.00595495   0.0538419    -0.000818182
 -0.0418258    0.0258337   0.0517081   -0.0730628   -0.23473     -0.0182935     0.0326538    0.0291066    0.0770112   -0.0464325    0.070353     0.176771      0.0612996   -0.00970692   0.0431399  -0.195766      0.0606745   -0.186282     0.134578    0.15746     -0.112898     0.0140545    0.00237466    0.12209      0.0637044    -0.0890673  
  0.0321326   -0.0835189  -0.0394237    0.0661621    0.0594367    0.0656874     0.0479868    0.0709177    0.0729624   -0.126948    -0.0664467    0.0953249    -0.0362182   -0.113015     0.0752861   0.0431215     0.108685    -0.0518517   -0.0318602   0.167689    -0.04853      0.0101359   -0.0476223     0.0570157    0.00296813   -0.0134143  
  0.0428331    0.120509    0.158301    -0.202353     0.0472425    0.149605     -0.101263     0.110775     0.0992187   -0.0100541    0.0420905   -0.112033      0.0490643    0.00374006   0.104327   -0.0978184    -0.101944    -0.029073    -0.150416   -0.0249459    0.0523195    0.196663    -0.0194541    -0.114361     0.0579245    -0.0489567  
 -0.00333716  -0.0509398  -0.00165763  -0.0294986   -0.0589898   -0.145061     -0.217624    -0.0182119    0.104315     0.00175233   0.109293    -0.026695     -0.0385038    0.0639721   -0.118504   -0.206771      0.0355617   -0.195619     0.0205859   0.0164524   -0.133355     0.0644344    0.0229764     0.0405605   -0.0119593    -0.0232849  
  0.00901029   0.0147188  -0.0371667    0.0435586    0.0237857   -0.0421945     0.0972903    0.190287     0.0991881    0.0557847   -0.0148268    0.0399185    -0.0705111    0.0244791   -0.223438   -0.0946936     0.0396207   -0.146208     0.0902243   0.237115    -0.00698772  -0.0149583    0.124704     -0.112395    -0.0633465    -0.031932   
  0.0343333    0.0420364  -0.0756277    0.145281     0.0400122    0.0791237     0.0564457   -0.00999217   0.0702445    0.0340368   -0.0517123    0.072098      0.0677522   -0.0449655   -0.13764     0.141226      0.13886      0.205427     0.0913604   0.24855      0.187224     0.0166383   -0.00504505   -0.0675915   -0.14188       0.0217648  
 -0.0444929    0.166809    0.0040484   -0.0811389    0.0907484   -0.164088     -0.00104915   0.00619961  -0.0609943   -0.0193226   -0.163402     0.140708     -0.0595786   -0.0127054   -0.146706    0.050712      0.0549369    0.018788     0.0457199  -0.0152301    0.0100794    0.105545    -0.170626      0.0452214    0.108038      0.0134418  
 -0.0397133   -0.179259   -0.0230803   -0.105394    -0.0295533    0.0321408     0.116128    -0.185978     0.092941    -0.110104     0.0790345    0.0293741    -0.112845     0.0110925    0.0715374   0.069311     -0.0950953    0.0719609    0.10831    -0.105059    -0.0784398   -0.0201115    0.125148      0.0284971    0.000658593  -0.0654417  
 -0.138137     0.330072    0.179133    -0.0258432    0.0947096    0.144261     -0.198292    -0.022632    -0.070089     0.0896151    0.0596003    0.208081     -0.0629472   -0.0909969    0.160927   -0.101965     -0.0155287   -0.101681     0.0886889   0.0374935    0.12663      0.219657    -0.13469      -0.00548246   0.219356      0.0279997  
  0.00369068   0.0672571   0.0469809    0.160578     0.198549    -0.0845497     0.0706318   -0.148138    -0.0210316   -0.0668297   -0.0492423   -0.0483942    -0.0493559    0.119382     0.0883535  -0.0815051    -0.00401783   0.00724656  -0.0205444   0.00181763   0.077069     0.0125345    0.0863635     0.0523277    0.0717519    -0.164296   
  0.0569575   -0.195893   -0.0394611    0.0513686   -0.0817524    0.0588226     0.0239069    0.0110146    0.0137533    0.0686132   -0.0827992    0.0177002     0.0760818    0.224416    -0.0408851   0.00350411    0.323285     0.149774    -0.0277418  -0.0374369   -0.0257511    0.0358697    0.0505504     0.0254079   -0.0321733     0.12517    
  0.0638534    0.108455    0.038516     0.101952    -0.0565731    0.0728679    -0.0320692   -0.00115223  -0.0284419   -0.0843243   -0.0415179   -0.02311      -0.178242     0.0542431    0.0469074   0.122086      0.0854132    0.00228982  -0.0291136   0.12061     -0.0326224   -0.0586761   -0.386031      0.00275419   0.0732736     0.0023911  
  0.212118     0.160122   -0.154965    -0.117297     0.231387     0.0810141    -0.202597     0.128161     0.0927034   -0.0453733   -0.143593    -0.0196375    -0.273805    -0.0111402   -0.08234    -0.0437682     0.122305     0.107025    -0.0600259  -0.060057     0.198386    -0.122574     0.0390202     0.0074764    0.044802     -0.0100256  
  0.0519658    0.0366704  -0.0585395   -0.071866     0.0545121   -0.011666     -0.0615074   -0.0331062    0.106186     0.121828    -0.0741971    0.0199124    -0.077793     0.0519843   -0.186161    0.0716439    -0.0413176    0.103901     0.0858549  -0.0789651    0.00285536   0.0789934    0.117278      0.146517     0.0392677     0.207219   
  0.0353619   -0.197765    0.134209     0.102112    -0.106248     0.14722      -0.0346728    0.176621     0.156885     0.131786    -0.0903758   -0.0338782    -0.103034    -0.0170698    0.157284    0.0532871     0.038886    -0.02188      0.0753204   0.176333    -0.107581     0.0894266    0.14709      -0.216184    -0.0199697     0.109385   
 -0.0292303   -0.0843692   0.0978778   -0.147184     0.0214446    0.130754     -0.0869026   -0.0741952    0.0330535    0.0132299   -0.0569696    0.024719     -0.0358627    0.0329531    0.0164349  -0.0733806    -0.0034303    0.209712    -0.0105412  -0.011828     0.253073     0.0329281   -0.0565979    -0.054102     0.0124069    -0.0432632  
  0.0921052   -0.0261082   0.139217    -0.243359     0.114437     0.000191184   0.0604236   -0.107431    -0.113195     0.0857454   -0.0317027    0.271702      0.0973413   -0.00428848  -0.025604   -0.123547      0.249227     0.307004     0.078761    0.0511028    0.0623084    0.131895    -0.0449029     0.0838538    0.161086     -0.0785184  
 -0.0304935   -0.076358   -0.0947708    0.0963699    0.0394942    0.204006     -0.00884165   0.0292895    0.00798064  -0.0842249    0.196913     0.0581975     0.127914    -0.143506    -0.0663834   0.318677     -0.144143    -0.115161    -0.226065   -0.0535888   -0.163818    -0.189557    -0.165979     -0.043545    -0.0958541    -0.0654741  
 -0.112363     0.150645    0.15246     -0.182173    -0.137306    -0.218152      0.027281     0.012019     0.0945601    0.153336     0.103697     0.000858961  -0.134629    -0.0365122    0.0227434   0.0273791     0.0137557    0.0494267    0.0292956   0.0279523   -0.0782296    0.197021     0.000957204  -0.0451731   -0.0237246     0.0415676  
 -0.255524    -0.0705798   0.0479694   -0.0274286   -0.0586626   -0.109613      0.0115417   -0.0180502   -0.0548627    0.133412     0.0663871    0.0880384     0.0646089   -0.036284    -0.137742    0.0340378     0.0381999   -0.0521066   -0.0611339   0.153382     0.107566    -0.0515228   -0.00396682    0.0120002    0.0469126     0.0121902  
 -0.111675     0.0587612   0.00789291   0.0137051   -0.151982    -0.109094      0.0224073    0.119646    -0.0612053   -0.110022    -0.0916781   -0.207173      0.0626155    0.00924491  -0.0754709   0.227958      0.154629     0.100342     0.0908633  -0.0390039   -0.0113196   -0.0206099    0.0277212    -0.129146    -0.0641473     0.0950451  
  0.0608026   -0.0155992   0.061383    -0.019594     0.0977611    0.0155891     0.178564    -0.0315418    0.0561397   -0.0537528   -0.0430029    0.279917      0.0248614   -0.128135    -0.107203    0.0948357    -0.0177709   -0.0701948    0.0183495  -0.0312646    0.0400237   -0.105468    -0.186257     -0.112959    -0.0129189     0.03245    kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.3956695576843927
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.395764
[ Info: iteration 2, average log likelihood -1.395660
[ Info: iteration 3, average log likelihood -1.394720
[ Info: iteration 4, average log likelihood -1.385462
[ Info: iteration 5, average log likelihood -1.364839
[ Info: iteration 6, average log likelihood -1.358522
[ Info: iteration 7, average log likelihood -1.357407
[ Info: iteration 8, average log likelihood -1.356851
[ Info: iteration 9, average log likelihood -1.356482
[ Info: iteration 10, average log likelihood -1.356211
[ Info: iteration 11, average log likelihood -1.355999
[ Info: iteration 12, average log likelihood -1.355827
[ Info: iteration 13, average log likelihood -1.355683
[ Info: iteration 14, average log likelihood -1.355558
[ Info: iteration 15, average log likelihood -1.355444
[ Info: iteration 16, average log likelihood -1.355332
[ Info: iteration 17, average log likelihood -1.355216
[ Info: iteration 18, average log likelihood -1.355088
[ Info: iteration 19, average log likelihood -1.354930
[ Info: iteration 20, average log likelihood -1.354702
[ Info: iteration 21, average log likelihood -1.354288
[ Info: iteration 22, average log likelihood -1.353526
[ Info: iteration 23, average log likelihood -1.352967
[ Info: iteration 24, average log likelihood -1.352674
[ Info: iteration 25, average log likelihood -1.352477
[ Info: iteration 26, average log likelihood -1.352318
[ Info: iteration 27, average log likelihood -1.352172
[ Info: iteration 28, average log likelihood -1.352025
[ Info: iteration 29, average log likelihood -1.351866
[ Info: iteration 30, average log likelihood -1.351672
[ Info: iteration 31, average log likelihood -1.351387
[ Info: iteration 32, average log likelihood -1.350935
[ Info: iteration 33, average log likelihood -1.350202
[ Info: iteration 34, average log likelihood -1.348617
[ Info: iteration 35, average log likelihood -1.346898
[ Info: iteration 36, average log likelihood -1.346296
[ Info: iteration 37, average log likelihood -1.346005
[ Info: iteration 38, average log likelihood -1.345744
[ Info: iteration 39, average log likelihood -1.345467
[ Info: iteration 40, average log likelihood -1.345203
[ Info: iteration 41, average log likelihood -1.344963
[ Info: iteration 42, average log likelihood -1.344749
[ Info: iteration 43, average log likelihood -1.344574
[ Info: iteration 44, average log likelihood -1.344439
[ Info: iteration 45, average log likelihood -1.344327
[ Info: iteration 46, average log likelihood -1.344232
[ Info: iteration 47, average log likelihood -1.344164
[ Info: iteration 48, average log likelihood -1.344117
[ Info: iteration 49, average log likelihood -1.344086
[ Info: iteration 50, average log likelihood -1.344066
â”Œ Info: EM with 100000 data points 50 iterations avll -1.344066
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3957640984169881
â”‚     -1.3956596011638118
â”‚      â‹®                 
â””     -1.3440655076712518
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.344218
[ Info: iteration 2, average log likelihood -1.344023
[ Info: iteration 3, average log likelihood -1.343118
[ Info: iteration 4, average log likelihood -1.336169
[ Info: iteration 5, average log likelihood -1.320915
[ Info: iteration 6, average log likelihood -1.313970
[ Info: iteration 7, average log likelihood -1.311988
[ Info: iteration 8, average log likelihood -1.310798
[ Info: iteration 9, average log likelihood -1.309883
[ Info: iteration 10, average log likelihood -1.309153
[ Info: iteration 11, average log likelihood -1.308563
[ Info: iteration 12, average log likelihood -1.308105
[ Info: iteration 13, average log likelihood -1.307574
[ Info: iteration 14, average log likelihood -1.307017
[ Info: iteration 15, average log likelihood -1.306615
[ Info: iteration 16, average log likelihood -1.306324
[ Info: iteration 17, average log likelihood -1.306076
[ Info: iteration 18, average log likelihood -1.305823
[ Info: iteration 19, average log likelihood -1.305537
[ Info: iteration 20, average log likelihood -1.305242
[ Info: iteration 21, average log likelihood -1.304954
[ Info: iteration 22, average log likelihood -1.304691
[ Info: iteration 23, average log likelihood -1.304462
[ Info: iteration 24, average log likelihood -1.304266
[ Info: iteration 25, average log likelihood -1.304104
[ Info: iteration 26, average log likelihood -1.303974
[ Info: iteration 27, average log likelihood -1.303870
[ Info: iteration 28, average log likelihood -1.303788
[ Info: iteration 29, average log likelihood -1.303723
[ Info: iteration 30, average log likelihood -1.303669
[ Info: iteration 31, average log likelihood -1.303623
[ Info: iteration 32, average log likelihood -1.303582
[ Info: iteration 33, average log likelihood -1.303543
[ Info: iteration 34, average log likelihood -1.303506
[ Info: iteration 35, average log likelihood -1.303470
[ Info: iteration 36, average log likelihood -1.303434
[ Info: iteration 37, average log likelihood -1.303398
[ Info: iteration 38, average log likelihood -1.303361
[ Info: iteration 39, average log likelihood -1.303322
[ Info: iteration 40, average log likelihood -1.303282
[ Info: iteration 41, average log likelihood -1.303241
[ Info: iteration 42, average log likelihood -1.303199
[ Info: iteration 43, average log likelihood -1.303157
[ Info: iteration 44, average log likelihood -1.303116
[ Info: iteration 45, average log likelihood -1.303077
[ Info: iteration 46, average log likelihood -1.303040
[ Info: iteration 47, average log likelihood -1.303004
[ Info: iteration 48, average log likelihood -1.302971
[ Info: iteration 49, average log likelihood -1.302939
[ Info: iteration 50, average log likelihood -1.302908
â”Œ Info: EM with 100000 data points 50 iterations avll -1.302908
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3442179856619996
â”‚     -1.3440233939299384
â”‚      â‹®                 
â””     -1.3029081391696227
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.303114
[ Info: iteration 2, average log likelihood -1.302867
[ Info: iteration 3, average log likelihood -1.302164
[ Info: iteration 4, average log likelihood -1.296372
[ Info: iteration 5, average log likelihood -1.280498
[ Info: iteration 6, average log likelihood -1.270054
[ Info: iteration 7, average log likelihood -1.265245
[ Info: iteration 8, average log likelihood -1.261001
[ Info: iteration 9, average log likelihood -1.257174
[ Info: iteration 10, average log likelihood -1.254660
[ Info: iteration 11, average log likelihood -1.252967
[ Info: iteration 12, average log likelihood -1.251999
[ Info: iteration 13, average log likelihood -1.251567
[ Info: iteration 14, average log likelihood -1.251357
[ Info: iteration 15, average log likelihood -1.251206
[ Info: iteration 16, average log likelihood -1.251068
[ Info: iteration 17, average log likelihood -1.250914
[ Info: iteration 18, average log likelihood -1.250700
[ Info: iteration 19, average log likelihood -1.250326
[ Info: iteration 20, average log likelihood -1.249612
[ Info: iteration 21, average log likelihood -1.248471
[ Info: iteration 22, average log likelihood -1.247440
[ Info: iteration 23, average log likelihood -1.247018
[ Info: iteration 24, average log likelihood -1.246864
[ Info: iteration 25, average log likelihood -1.246793
[ Info: iteration 26, average log likelihood -1.246751
[ Info: iteration 27, average log likelihood -1.246721
[ Info: iteration 28, average log likelihood -1.246697
[ Info: iteration 29, average log likelihood -1.246676
[ Info: iteration 30, average log likelihood -1.246657
[ Info: iteration 31, average log likelihood -1.246639
[ Info: iteration 32, average log likelihood -1.246623
[ Info: iteration 33, average log likelihood -1.246608
[ Info: iteration 34, average log likelihood -1.246593
[ Info: iteration 35, average log likelihood -1.246578
[ Info: iteration 36, average log likelihood -1.246564
[ Info: iteration 37, average log likelihood -1.246549
[ Info: iteration 38, average log likelihood -1.246535
[ Info: iteration 39, average log likelihood -1.246519
[ Info: iteration 40, average log likelihood -1.246504
[ Info: iteration 41, average log likelihood -1.246489
[ Info: iteration 42, average log likelihood -1.246474
[ Info: iteration 43, average log likelihood -1.246460
[ Info: iteration 44, average log likelihood -1.246447
[ Info: iteration 45, average log likelihood -1.246435
[ Info: iteration 46, average log likelihood -1.246424
[ Info: iteration 47, average log likelihood -1.246413
[ Info: iteration 48, average log likelihood -1.246402
[ Info: iteration 49, average log likelihood -1.246391
[ Info: iteration 50, average log likelihood -1.246380
â”Œ Info: EM with 100000 data points 50 iterations avll -1.246380
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3031142401609441
â”‚     -1.3028668867101139
â”‚      â‹®                 
â””     -1.2463800905041151
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.246646
[ Info: iteration 2, average log likelihood -1.246350
[ Info: iteration 3, average log likelihood -1.245403
[ Info: iteration 4, average log likelihood -1.234681
[ Info: iteration 5, average log likelihood -1.202039
[ Info: iteration 6, average log likelihood -1.177937
[ Info: iteration 7, average log likelihood -1.168307
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     3
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.164000
[ Info: iteration 9, average log likelihood -1.171026
[ Info: iteration 10, average log likelihood -1.163860
[ Info: iteration 11, average log likelihood -1.159927
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     3
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.157139
[ Info: iteration 13, average log likelihood -1.164583
[ Info: iteration 14, average log likelihood -1.158419
[ Info: iteration 15, average log likelihood -1.155866
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     3
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.154902
[ Info: iteration 17, average log likelihood -1.163728
[ Info: iteration 18, average log likelihood -1.157955
[ Info: iteration 19, average log likelihood -1.155575
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     3
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.154696
[ Info: iteration 21, average log likelihood -1.163583
[ Info: iteration 22, average log likelihood -1.157838
[ Info: iteration 23, average log likelihood -1.155459
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     3
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.154602
[ Info: iteration 25, average log likelihood -1.163521
[ Info: iteration 26, average log likelihood -1.157800
[ Info: iteration 27, average log likelihood -1.155415
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     3
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.154565
[ Info: iteration 29, average log likelihood -1.163492
[ Info: iteration 30, average log likelihood -1.157785
[ Info: iteration 31, average log likelihood -1.155392
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     3
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.154539
[ Info: iteration 33, average log likelihood -1.163467
[ Info: iteration 34, average log likelihood -1.157768
[ Info: iteration 35, average log likelihood -1.155366
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     3
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.154504
[ Info: iteration 37, average log likelihood -1.163421
[ Info: iteration 38, average log likelihood -1.157721
[ Info: iteration 39, average log likelihood -1.155294
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     3
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.154400
[ Info: iteration 41, average log likelihood -1.163282
[ Info: iteration 42, average log likelihood -1.157571
[ Info: iteration 43, average log likelihood -1.155117
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     3
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.154201
[ Info: iteration 45, average log likelihood -1.163075
[ Info: iteration 46, average log likelihood -1.157403
[ Info: iteration 47, average log likelihood -1.154982
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     3
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.154087
[ Info: iteration 49, average log likelihood -1.162989
[ Info: iteration 50, average log likelihood -1.157363
â”Œ Info: EM with 100000 data points 50 iterations avll -1.157363
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2466455355395387
â”‚     -1.2463502210364028
â”‚      â‹®                 
â””     -1.157363488802647 
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.155316
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     5
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.154015
[ Info: iteration 3, average log likelihood -1.153417
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     5
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.137930
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.103743
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.078106
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     16
â”‚     23
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.061975
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.080212
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     24
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.067481
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     16
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.065140
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.065938
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     21
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.073161
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     16
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.064755
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚     23
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.060739
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.078995
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     16
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.071997
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.070298
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.071730
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     16
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.062284
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚     24
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.060795
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.078986
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     16
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.065854
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.065837
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.068801
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     16
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.057685
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚     24
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.054862
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     21
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.071483
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     16
â”‚     24
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.063878
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.064477
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     23
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.049556
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     16
â”‚     21
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.051670
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.081863
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.062791
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     16
â”‚     23
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.044565
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     21
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.061014
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.066605
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     16
â”‚     23
â”‚     24
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.047969
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.071372
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.068217
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     16
â”‚     24
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.046819
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.056011
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.071708
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     16
â”‚     21
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.050295
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚     23
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.059006
[ Info: iteration 45, average log likelihood -1.072457
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     16
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.048394
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     21
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.059804
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.071712
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     16
â”‚     24
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.054742
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.057978
â”Œ Info: EM with 100000 data points 50 iterations avll -1.057978
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.1553157373155918
â”‚     -1.1540148544571578
â”‚      â‹®                 
â””     -1.057978308987484 
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.3956695576843927
â”‚     -1.3957640984169881
â”‚     -1.3956596011638118
â”‚     -1.3947196999459932
â”‚      â‹®                 
â”‚     -1.0717120324219682
â”‚     -1.0547423377776843
â””     -1.057978308987484 
32Ã—26 Array{Float64,2}:
 -0.0530875    0.114303     0.0102363    0.0212916   -0.0992682   -0.158509   -0.0870109   -0.184655    -0.141159     -0.00796145  -0.134386      0.0128142    -0.227734    -0.0050587   -0.220746     0.0542672   -0.021397      0.142846     0.0815898   -0.0343437    0.0182305   -1.17438     -0.186857     0.214475     0.0731865     0.00780293
 -0.0376655    0.279698    -0.0428477    0.0923506    0.0388084   -0.0595728  -0.149928    -0.0531503   -0.00582843   -0.0161609   -0.147805      0.331662     -0.0156343   -0.00132764  -0.287258     0.0618965    0.120062      0.00606268  -0.0229487   -0.0439468    0.0189526    1.02744     -0.146585     0.0653517    0.0981611     0.0218433 
 -0.0459425    0.0956563    0.0345018   -0.147869     0.252173    -0.0971971   0.239862     0.271462     0.00638632   -0.0237024   -0.191011      0.142588      0.00975738  -0.0319022   -0.106376     0.0354117    0.0618964    -0.117254     0.109314     0.00319466  -0.019719    -0.877713    -0.159137    -0.145624     0.0894139     0.0179091 
 -0.0407206    0.0511083    0.00534986  -0.27895      0.212556    -0.17134     0.148664    -0.0166649   -0.0912714    -0.0305387   -0.155398      0.049805     -0.0142924   -0.0170017   -0.0315799    0.0584045    0.00819476    0.0623357    0.165692    -0.00126489   0.0875371    1.38504     -0.178798    -0.0558517    0.160808      0.00943633
 -0.0550935    0.0522975    0.0816917   -0.0390158    0.0152479   -0.0762828   0.0664698   -0.0248404    0.0979295    -0.0105627   -0.164086      0.150275     -0.0222433   -0.0513374   -0.987113     0.0955256    0.125957     -0.0739799    0.102985    -0.0234772    0.00766214  -0.317825    -0.0215358    0.0300155   -0.0207354    -0.152186  
  0.0179303    0.154841     0.0664775   -0.128696    -0.0155757   -0.0617358  -0.0044363   -0.025208     0.0990779    -0.046105    -0.151816      0.152192     -0.00209812  -0.338181     0.806809     0.0152839    0.154454     -0.134497     0.130361     0.046862     0.121877    -0.0762612   -0.0199833    0.041962    -0.0203652    -0.12388   
  0.161429    -0.00951626   0.150663    -0.24107      0.131546    -0.0399125   0.061502    -0.0399236   -0.133926      0.0492442   -0.0634485     0.227391      0.106616    -0.0227446   -0.0297381   -0.168412     0.267951      0.198144     0.0685413    0.110122     0.0517918    0.109284    -0.0504557   -0.0439311    0.149985     -0.414932  
  0.049374    -0.030379     0.132304    -0.235414     0.0995928    0.0877985   0.0579374   -0.16671     -0.0763386     0.143752     0.0133296     0.266748      0.0873368    0.0388306   -0.017742    -0.127408     0.230825      0.403759     0.0814232    0.00821131   0.119421     0.156395    -0.0360255    0.177892     0.178138      0.265198  
 -0.00172312  -0.00168415  -0.0356177    0.0561351   -0.10468     -0.151803    0.130017     0.0643328    0.0184595    -0.0218664   -0.0852397    -0.00256062    0.0235871   -0.00946107   0.0838269   -0.185272     0.0748643    -0.112067    -0.0347484    0.214451    -0.0139211    0.0133184   -0.0199584   -0.0369516   -0.0856725    -0.0332244 
  0.0730004    0.105163     0.0308731    0.0969029   -0.0468765    0.0589789   0.0192879   -0.0259621   -0.000360588  -0.0777871   -0.0368086    -0.013893     -0.176765     0.0675684    0.0366837    0.0864549    0.0941028     0.0268426   -0.00388475   0.103237    -0.0213839   -0.0455997   -0.325049     0.017797     0.0732381     0.00369196
 -0.0826636   -0.0209742    0.0228604    0.00715192   0.0609556    0.168848   -0.182578     0.103342    -0.135414      0.155975     0.000953028   0.0454705     0.117205    -0.109655    -0.0878453    0.110764     0.0180795    -0.0631087    0.00143438   0.110045     0.0238235   -0.0118251    0.114424     0.00901892   0.0451822    -0.0306192 
 -0.049076    -0.0977197    0.0975637    0.0320355    0.0221072    0.115817    0.0397487   -0.0699235   -0.0645408    -0.0391605   -0.0078776    -0.0572156     0.0507434    0.105899     0.19365      0.0152072   -0.116523     -0.00081798   0.0713907   -0.0156247   -0.0989054    0.0448865   -0.043953    -0.0706628   -0.00737459    0.0895274 
 -0.124054     0.26127      0.149077    -0.107324    -0.0246233   -0.0396537  -0.0798593    0.00335149   0.0296482     0.121822     0.0806878     0.0942242    -0.0978535   -0.0869396    0.0790637   -0.0133979    0.000449477  -0.0155852    0.049927     0.0248366    0.0410365    0.203176    -0.0562343   -0.0527947    0.0818487     0.0419437 
 -0.0228236    0.0466844    0.0869059   -0.0266491    0.0682788    0.0610375  -0.0533088   -0.115384    -0.030985     -0.0153498   -0.0454323     0.0226735    -0.047387     0.0795933    0.0622205   -0.0835975    0.0149874     0.115989    -0.00189188   0.00187646   0.209702     0.0377704    0.0150704   -0.0115552    0.0798676    -0.107228  
  0.130189     0.147858     0.0315513   -0.166662     0.15285      0.172376   -0.147098     0.0970224    0.0723513    -0.0477262   -0.0458408    -0.0891167    -0.118006    -0.00164219  -0.032508    -0.0861398    0.00624372    0.0329681   -0.11215     -0.0511745    0.128135     0.0245241    0.00467631  -0.0374369    0.0598205    -0.0503306 
  0.0421713   -0.124065     0.10764      0.0882629   -0.107659     0.132998   -0.0466404    0.16304      0.144595      0.120571    -0.0867938    -0.0450566    -0.110785    -0.0160046    0.141566     0.0407164    0.0392995     0.00882651   0.0568155    0.160388    -0.0540611    0.0766194    0.14956     -0.231417    -0.0161302     0.1019    
 -0.12016     -0.0491229   -0.0737883   -0.0553166   -0.0295706   -0.149541   -0.0791643   -0.0414418    0.106193      0.036832     0.0480962    -0.0407644     0.00727636   0.0529113   -0.0931438   -0.120349     0.0414049    -0.1238      -0.0698248    0.0166261   -0.0189805    0.0457888    0.0528852    0.0144442   -0.0186864     0.0205659 
  0.0126939   -0.0819183   -0.0589644    0.0741565    0.0573171    0.0659797   0.052814     0.0701008    0.0738639    -0.1441      -0.0695993     0.0905328    -0.0365109   -0.111205     0.075601     0.0492661    0.111634     -0.0533119   -0.0163311    0.15983     -0.0244091    0.0644464   -0.0362465    0.0553311    0.0200643    -0.013061  
  0.0519111   -0.188377    -0.0401829    0.054003    -0.109974     0.0613547   0.0184633    0.00980181   0.0175593     0.0764354   -0.0799937     0.0696446     0.0746087    0.233934    -0.0488713    0.00438547   0.286195      0.143926    -0.0784929   -0.0360605    0.00300729   0.0415422    0.0481435    0.0153014   -0.0316304     0.132421  
 -0.0603862   -0.176148    -0.0495262   -0.0975605   -0.0562728    0.0319941   0.117624    -0.135739     0.0961104    -0.0886758    0.081828      0.0489892    -0.104858     0.0145524    0.082868     0.066397    -0.0744139     0.0839279    0.106398    -0.122205    -0.0693277   -0.0231723    0.123708     0.0281724   -0.0246688    -0.0720132 
  0.0457257    0.0451055   -0.0293502   -0.0793351    0.0532212   -0.0171107  -0.0612584   -0.0213605    0.130441      0.117831    -0.0816013     0.0182908    -0.0798255    0.0430746   -0.185683     0.0751292   -0.0573972     0.108711     0.0548767   -0.0932213   -0.0236082    0.0736432    0.120245     0.136266     0.0132956     0.1933    
  0.18575      0.03029      0.141717     0.0140783   -0.0226442    0.0377789   0.025665    -0.120845    -0.114013      0.259626    -0.0354206    -0.0347928     0.180283     0.0413627    0.0488551    0.0309422    0.00932022    0.149663     0.207124     0.0212584    0.119223     0.112594    -0.0141742   -0.101019     0.0485719    -0.0702986 
  0.0541445    0.0274078   -0.197577     0.021458     0.00623461  -0.027593   -0.188709     0.0229675    0.0599117     0.0231494    0.020456      0.128968      0.020186    -0.0398487    0.0506392    0.049757    -0.095597     -0.0755129    0.166293     0.22351      0.0634634    0.131636    -0.0220961   -0.0358158    0.139975     -0.088898  
 -0.236758    -0.061741     0.0258841   -0.0418627   -0.0584915   -0.101844    0.0150067   -0.0182433   -0.0526423     0.136532     0.0606434     0.0954678     0.0625292   -0.0356854   -0.116611     0.0473715    0.0302891    -0.0486023   -0.066225     0.148223     0.100076    -0.0532981   -0.0464905    0.0108647    0.00366098    0.0072    
  0.107105    -0.0225707    0.0299902    0.146775    -0.126763     0.051377    0.00273398   0.0413711    0.141132      0.0632194    0.149929      0.000241135   0.0494594   -0.154683    -0.1949       0.068158    -0.0672175     0.039671    -0.0338398    0.137885     0.147462     0.0116871    0.0902348    0.00313848   0.0716534     0.0536662 
  0.0257957    0.0426059   -0.0710225    0.154913     0.0345374    0.0761368   0.0503073    0.0626891    0.0757038     0.0385066   -0.049205      0.0695405     0.10421     -0.0391128   -0.145254     0.143877     0.130301      0.187077     0.0964258    0.232731     0.243298     0.0217418   -0.00049917  -0.0764108   -0.166258      0.0301079 
 -0.0379471    0.0434833   -0.00887779   0.0356449   -0.0616456   -0.0721178   0.0542906    0.150349     0.022497     -0.0304518   -0.0538517    -0.0646445    -0.00520208   0.0289867   -0.154527     0.0383106    0.0903302    -0.021396     0.0881751    0.104887    -0.024582     0.00594081   0.0752034   -0.108332    -0.0549057     0.0453354 
  0.0118903   -0.0683575    0.0746153   -0.0912984    0.098287    -0.0530449   0.136856     0.082311     0.0342028     0.00111723   0.0483617    -0.0468817    -0.0770079   -0.027623     0.0199028    0.0685477   -0.105172      0.0511095    0.0813265    0.0528049   -0.237019     0.00276985  -0.0899876   -0.133033     0.0244185     0.0012784 
 -0.0394747   -0.0698266   -0.128679     0.0914347    0.0064929    0.197986    0.00161729   0.0304439   -0.00212979   -0.0884674    0.191933      0.036183      0.146292    -0.154805     0.00339867   0.305423    -0.139246     -0.110682    -0.21919     -0.0498398   -0.137159    -0.181153    -0.159193    -0.0450803   -0.0934274    -0.0607492 
  0.0547696   -0.00784394   0.0428831   -0.00585424   0.101792    -0.024932    0.18491     -0.0336072    0.0127212    -0.0659861   -0.0430096     0.259822      0.0577056   -0.166065    -0.137534     0.107443    -0.0185737    -0.071193     0.016968    -0.0393909    0.0376548   -0.094338    -0.168457    -0.108225     0.000631311   0.0335653 
 -0.420585     0.149846    -0.0836532    0.194572    -0.199965    -0.0191088   0.136405     0.0694762   -0.0278513     0.244802     0.0731978    -0.056966     -0.27771      0.0364821   -0.00929075  -0.0174812   -0.245978      0.0552883   -0.0351927    0.0649673   -0.125681     0.0136673    0.182255     0.217997    -0.1944       -0.0600636 
  0.726862     0.153877     0.0542103    0.17109     -0.189963     0.091702    0.136734     0.0825614   -0.00839715    0.113838     0.0797194    -0.275406     -0.0744936   -0.0325937   -0.0841372    0.00847879  -0.255336      0.033249    -0.0463472    0.0624557   -0.0772947    0.0585159    0.163703     0.0287656   -0.0654002    -0.0650636 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     21
â”‚     23
â”‚     24
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.047496
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     16
â”‚     21
â”‚     23
â”‚     24
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.031213
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     21
â”‚     23
â”‚     24
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.031103
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     16
â”‚     21
â”‚     23
â”‚     24
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.035088
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     21
â”‚     23
â”‚     24
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.043059
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     24
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.018752
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     21
â”‚     23
â”‚     24
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.047373
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     16
â”‚     21
â”‚     23
â”‚     24
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.030805
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     21
â”‚     23
â”‚     24
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.031072
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     16
â”‚     21
â”‚     23
â”‚     24
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
kind diag, method kmeans
[ Info: iteration 10, average log likelihood -1.035076
â”Œ Info: EM with 100000 data points 10 iterations avll -1.035076
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.852111e+05
      1       6.569801e+05      -2.282310e+05 |       32
      2       6.290963e+05      -2.788376e+04 |       32
      3       6.123159e+05      -1.678045e+04 |       32
      4       6.034138e+05      -8.902084e+03 |       32
      5       5.991130e+05      -4.300779e+03 |       32
      6       5.961242e+05      -2.988812e+03 |       32
      7       5.937580e+05      -2.366233e+03 |       32
      8       5.919823e+05      -1.775729e+03 |       32
      9       5.905628e+05      -1.419467e+03 |       32
     10       5.893541e+05      -1.208739e+03 |       32
     11       5.884258e+05      -9.282345e+02 |       32
     12       5.876207e+05      -8.050859e+02 |       32
     13       5.868955e+05      -7.252816e+02 |       32
     14       5.861552e+05      -7.402587e+02 |       32
     15       5.852708e+05      -8.843666e+02 |       32
     16       5.843844e+05      -8.864523e+02 |       32
     17       5.838957e+05      -4.886346e+02 |       32
     18       5.836861e+05      -2.096260e+02 |       32
     19       5.835740e+05      -1.120715e+02 |       32
     20       5.834748e+05      -9.927258e+01 |       32
     21       5.833766e+05      -9.812784e+01 |       32
     22       5.832622e+05      -1.144575e+02 |       32
     23       5.830996e+05      -1.625414e+02 |       32
     24       5.829275e+05      -1.721795e+02 |       32
     25       5.827466e+05      -1.808394e+02 |       31
     26       5.826068e+05      -1.398541e+02 |       32
     27       5.825436e+05      -6.313878e+01 |       31
     28       5.825092e+05      -3.439367e+01 |       31
     29       5.824844e+05      -2.483051e+01 |       31
     30       5.824620e+05      -2.240497e+01 |       31
     31       5.824348e+05      -2.715933e+01 |       29
     32       5.824068e+05      -2.801861e+01 |       31
     33       5.823774e+05      -2.945654e+01 |       31
     34       5.823451e+05      -3.226033e+01 |       31
     35       5.823189e+05      -2.617159e+01 |       31
     36       5.822951e+05      -2.383295e+01 |       31
     37       5.822732e+05      -2.192734e+01 |       31
     38       5.822465e+05      -2.668612e+01 |       31
     39       5.822146e+05      -3.192547e+01 |       32
     40       5.821827e+05      -3.189826e+01 |       32
     41       5.821479e+05      -3.481246e+01 |       31
     42       5.821122e+05      -3.567394e+01 |       31
     43       5.820770e+05      -3.518554e+01 |       32
     44       5.820336e+05      -4.335474e+01 |       31
     45       5.819911e+05      -4.249697e+01 |       31
     46       5.819458e+05      -4.533999e+01 |       32
     47       5.818946e+05      -5.118727e+01 |       32
     48       5.818261e+05      -6.852797e+01 |       32
     49       5.817417e+05      -8.439192e+01 |       32
     50       5.816382e+05      -1.034752e+02 |       32
K-means terminated without convergence after 50 iterations (objv = 581638.2233678764)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.296138
[ Info: iteration 2, average log likelihood -1.259252
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.224339
[ Info: iteration 4, average log likelihood -1.199284
[ Info: iteration 5, average log likelihood -1.152593
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.101989
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚     16
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.074457
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      7
â”‚     15
â”‚     18
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.071265
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.085428
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚     10
â”‚     14
â”‚     22
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.058085
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      7
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.079093
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚     19
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.058940
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚     10
â”‚     11
â”‚     15
â”‚     18
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.056771
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     3
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.070023
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚     14
â”‚     16
â”‚     19
â”‚     22
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.050387
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.074629
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     15
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.040160
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     18
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.047260
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.070984
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     16
â”‚     22
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.051248
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      7
â”‚     11
â”‚     14
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.039650
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      5
â”‚     10
â”‚     19
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.060093
[ Info: iteration 23, average log likelihood -1.085654
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      7
â”‚     15
â”‚     18
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.029072
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚     10
â”‚     11
â”‚     16
â”‚     24
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.044387
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.094936
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.061829
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     10
â”‚     15
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.016922
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚     11
â”‚     14
â”‚     16
â”‚     19
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.053297
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.088902
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.063411
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     18
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.027838
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚     10
â”‚     11
â”‚     16
â”‚     19
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.045724
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚     15
â”‚     24
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.070788
[ Info: iteration 35, average log likelihood -1.083832
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     10
â”‚     14
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.021336
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     16
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.065691
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     18
â”‚     19
â”‚     22
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.064895
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.055157
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     14
â”‚     15
â”‚     27
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.018849
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.085208
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.074781
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     10
â”‚     19
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.036614
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      5
â”‚      7
â”‚     11
â”‚      â‹®
â”‚     16
â”‚     27
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.008579
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.110623
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.075676
[ Info: iteration 47, average log likelihood -1.052822
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     22
â”‚     27
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -0.999217
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.101567
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚     19
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.064620
â”Œ Info: EM with 100000 data points 50 iterations avll -1.064620
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0900768    -0.0177895   0.0221509    0.147485    -0.118116     0.0539427   0.00945055    0.0448601    0.138374      0.0617301    0.135632      0.00608534   0.0492549   -0.147987    -0.187477     0.0752774   -0.0490994    0.0467611   -0.0268683     0.136531     0.145887     0.0125331    0.0854432    0.00172893   0.0622594     0.0512606 
  0.188594      0.104158    0.0492517    0.108346    -0.120939     0.0342134   0.0964675    -0.00135648  -0.0469732     0.22708      0.0136319    -0.125267    -0.00726889   0.0236455   -0.013557     0.00740229  -0.14771      0.0892262    0.06018       0.0382607   -0.00427052   0.0635957    0.124556     0.0258808   -0.0491358    -0.0560659 
 -0.0198301     0.0279242   0.0862097   -0.0705185   -0.187744     0.0144691   0.021716      0.0158874    0.0828308    -0.0462062    0.0632109     0.171395     0.0535659   -0.0211135    0.0298903   -0.199601     0.0575587   -0.253943     0.12846       0.203628    -0.108534    -0.0348611    0.0116405    0.135519     0.0519667    -0.0786915 
 -0.108924      0.154115    0.1387      -0.189291    -0.11571     -0.198913    0.0173208     0.0198791    0.102191      0.156832     0.0985903    -0.0065744   -0.109451    -0.0595932    0.0226732    0.0314505   -0.00641403   0.0547502    0.0169877     0.0356695   -0.0773568    0.200563     0.0253288   -0.104274    -0.028981      0.0506706 
 -0.0500363    -0.0502888  -0.00143501  -0.0274546   -0.0729064   -0.144713   -0.216523     -0.0102384    0.115051      0.0019792    0.113711     -0.0633129   -0.0328546    0.0505877   -0.118519    -0.211363    -0.00104656  -0.192761     0.0311643     0.0598015   -0.121744     0.0652427    0.0135204    0.0349375   -0.000426357  -0.0259725 
 -0.0647031    -0.174601   -0.0495268   -0.099734    -0.0548034    0.0319524   0.117272     -0.13676      0.0966661    -0.0854919    0.0809251     0.0465048   -0.103045     0.0150191    0.080101     0.0662049   -0.0740104    0.0822749    0.10624      -0.120992    -0.0674656   -0.0226286    0.123414     0.0283449   -0.0266654    -0.0716788 
  0.0349073    -0.195181    0.131407     0.105949    -0.159042     0.173384   -0.0412967     0.205496     0.165458      0.122704    -0.09086      -0.0403109   -0.0902377   -0.0153335    0.139529     0.0427165    0.0252667    0.0353315    0.0761059     0.17642     -0.0859455    0.0848359    0.142715    -0.252143    -0.020372      0.150329  
 -0.0201975     0.0647423   0.0618143    0.143827     0.183138    -0.0598499   0.0753665    -0.133597    -0.0204837    -0.0283964   -0.03365      -0.0406485   -0.0442539    0.0961393    0.0864352   -0.066239     0.016701     0.00970399  -0.0160339     0.0310322    0.0615756    0.00290838   0.0971291    0.0478883    0.0727925    -0.177038  
 -0.0302891     0.0088227   0.0940835   -0.140919    -0.0119986    0.143287   -0.1038       -0.0792439   -0.0515255     0.0123136   -0.0528134     0.0431898   -0.0499803    0.0737958    0.0296507   -0.0627922    0.00368918   0.208423    -0.00808498   -0.00320006   0.299125     0.0531203   -0.0366211   -0.0636609    0.0645101    -0.0604707 
 -0.231457     -0.0607488  -0.0157921   -0.0493657   -0.0472882   -0.0971622   0.0202221    -0.0135819   -0.036087      0.129577     0.042317      0.0836949    0.0659226   -0.0334853   -0.111902     0.0396735    0.0348938   -0.0465162   -0.0830204     0.122198     0.102856    -0.0417914   -0.0183774    0.00701682  -0.00265568    0.0252529 
 -0.000698413  -0.0642751   0.0644608   -0.0898575    0.097106    -0.077638    0.152054      0.0740325    0.0532048    -0.00263614   0.0443966    -0.0912365   -0.0696647   -0.0181882    0.00715694   0.0626128   -0.101646     0.0363096    0.0646567     0.046278    -0.207976     0.00920259  -0.0642065   -0.127862     0.0237031     0.00561747
  0.208478      0.149509   -0.10741     -0.0891655    0.230109     0.0896622  -0.181728      0.104331     0.0916153    -0.0686684   -0.139966     -0.0345668   -0.266128    -0.0168529   -0.119298    -0.0443208    0.127117     0.0836395   -0.0497571    -0.0532269    0.189782    -0.113574     0.0575452   -0.0045139    0.0491404    -0.001313  
  0.048509     -0.181316   -0.048714     0.0478107   -0.10615      0.0599662   0.0227679     0.00428236   0.0179545     0.0756471   -0.0769715     0.0834918    0.0744387    0.22947     -0.0511208    0.00554172   0.281427     0.137911    -0.0890736    -0.0374672    0.0078883    0.0404182    0.0549271    0.0146196   -0.035772      0.134268  
 -0.0423617    -0.0175515  -0.00635697  -0.0104741    0.0687439    0.0939704  -0.246707      0.0480446   -0.122311      0.124929    -0.00514308    0.0562134    0.0686902   -0.163737    -0.17207      0.15112      0.0539867   -0.0661077   -0.00656137    0.0812462    0.016096     0.0102811    0.100784     0.0221916    0.00689685   -0.00767593
 -0.201484     -0.0339964  -0.186999    -0.0767861    0.0143157   -0.167851    0.118517     -0.0984312    0.0801309     0.0906507   -0.0200863    -0.00436552   0.0498226    0.0494795   -0.0714765   -0.0019921    0.111091    -0.0440693   -0.19921      -0.010965     0.101682     0.0360577    0.0834008   -0.0110795   -0.062406      0.0752611 
 -0.0263302     0.0327752  -0.177699     0.0921338    0.0321307   -0.0267734  -0.121531     -0.00738807   0.12313       0.0598298    0.000658109   0.150215     0.0117983   -0.00754668  -0.0927398    0.077307    -0.0479819   -0.0216672    0.130467      0.248889    -0.0147292    0.0741282    0.0677395    0.0437085    0.133865     -0.0401196 
  0.105817     -0.0203518   0.141572    -0.236116     0.114775     0.0221474   0.0580863    -0.101109    -0.102317      0.0945038   -0.0270202     0.244403     0.0952098    0.0112393   -0.0280009   -0.147751     0.246388     0.292205     0.07339       0.0600073    0.0812658    0.130813    -0.0418789    0.0656469    0.162263     -0.0717819 
  0.11168      -0.0314165   0.146629     0.00527753  -0.0106041    0.0439171  -0.0416378    -0.160399    -0.204436      0.172239     0.0800672     0.0110993    0.0761277    0.040168     0.0895918    0.0321475    0.080948     0.146108     0.214481      0.0592295    0.114774     0.143219    -0.238278    -0.110605     0.0616703    -0.142582  
  0.0532443     0.0276942  -0.20382      0.0205138    0.00747396  -0.0266555  -0.188827      0.0219325    0.0603301     0.0246383    0.0205347     0.131519     0.0203124   -0.0415942    0.0512529    0.0501394   -0.10594     -0.073907     0.1667        0.217682     0.0657324    0.131503    -0.0226667   -0.0349687    0.139287     -0.088821  
  0.0132688    -0.0815484  -0.0582601    0.0717535    0.0577888    0.0641559   0.0525467     0.06992      0.0753841    -0.138764    -0.0692706     0.0933398   -0.0351732   -0.111172     0.0736698    0.0448783    0.112661    -0.0552788   -0.0196233     0.155415    -0.0274691    0.0598736   -0.0348817    0.0547559    0.0173494    -0.011739  
  0.0240328     0.080346    0.0783518   -0.0899869    0.0387303    0.123827   -0.0123355     0.132842     0.0820347     0.0321176    0.0111609    -0.0401264   -0.0118773    0.00986846  -0.0562789   -0.117426    -0.0409964   -0.0892595   -0.036452      0.101094     0.0127798    0.102224     0.0559973   -0.105575     0.00451415   -0.0529273 
  0.0551477     0.0473837   0.00544593  -0.139086     0.0526097   -0.0114583  -0.0605134    -0.0209996    0.160783      0.136088    -0.112588     -0.0130733   -0.106421     0.0733785   -0.17833      0.0872764   -0.0442664    0.232911     0.0588542    -0.190982    -0.0314716    0.069555     0.114048     0.133327    -0.0109316     0.268926  
 -0.0807062     0.0608105   0.00391224   0.0329386   -0.163246    -0.116252    0.0213384     0.141146    -0.0509924    -0.111484    -0.101023     -0.198196     0.0537322    0.0363206   -0.0902086    0.218329     0.163626     0.099338     0.0885872    -0.0303368   -0.0196637    0.00429945   0.0177683   -0.113516    -0.0637161     0.119215  
 -0.0196892     0.101638    0.0740567   -0.0831576   -0.00107702  -0.0676899   0.0310787    -0.0241955    0.100006     -0.0263043   -0.155514      0.150726    -0.011803    -0.194703    -0.100184     0.0560898    0.141245    -0.103136     0.116305      0.0127336    0.0619775   -0.196973    -0.0201841    0.0357349   -0.020492     -0.137455  
 -0.133688      0.372175    0.179816    -0.01876      0.0798788    0.154882   -0.195549     -0.00972423  -0.0613978     0.0754496    0.0591156     0.210365    -0.0686212   -0.121609     0.163399    -0.0837544   -0.00297833  -0.101387     0.0832138     0.00522987   0.186484     0.220987    -0.122972     0.00125161   0.215374      0.020486  
  0.0550475    -0.012354    0.0393339   -0.00894419   0.100661    -0.0169589   0.182059     -0.0314616    0.0149943    -0.0576611   -0.048175      0.275287     0.0578458   -0.171189    -0.139352     0.115448    -0.01792     -0.0746365    0.0180691    -0.0304889    0.0361435   -0.0933632   -0.178645    -0.111164     0.00129787    0.0433783 
 -0.0578188    -0.0810386   0.096296     0.0216234    0.0331049    0.137595   -0.044804     -0.0127615   -0.105956      0.0186128   -0.00569188   -0.033752     0.0760863    0.0598407    0.133879     0.0303156   -0.0990056   -0.0289808    0.0589512     0.010779    -0.0626494    0.0296227    0.013604    -0.0458323    0.00556953    0.0741008 
  0.0168195    -0.0266338  -0.116397     0.122704    -0.064657    -0.284107    0.195626      0.0864651   -0.0285993     0.00950461  -0.186716     -0.131708     0.00746165  -0.00596751   0.112282    -0.182992     0.0857644   -0.0387519   -0.165118      0.231218     0.0454472    0.0294993   -0.0507074   -0.156579    -0.193033     -0.00345868
 -0.0449571     0.128029    0.00365894  -0.0860763    0.104765    -0.123802    0.0494404     0.00807219  -0.0565507    -0.0204519   -0.156483      0.131076    -0.0579176   -0.0141624   -0.152221     0.0523467    0.0431494    0.0217397    0.083598     -0.0175756    0.0262079    0.11638     -0.166552     0.0113534    0.10789       0.014272  
 -0.0480086    -0.0682226  -0.129884     0.0914362    0.00831449   0.20119     0.000322464   0.0316978   -0.000921788  -0.079473     0.182197      0.0406041    0.146618    -0.156952    -0.0177819    0.300232    -0.136832    -0.120336    -0.215368     -0.0390102   -0.145349    -0.178871    -0.147415    -0.044814    -0.0937664    -0.0728339 
  0.0733138     0.103508    0.0213192    0.0991042   -0.05341      0.0597629   0.0236783    -0.0192528    0.00132702   -0.0722019   -0.0391062    -0.0124705   -0.175687     0.0672234    0.0351439    0.090673     0.093133     0.0332225    0.000225285   0.100117    -0.023496    -0.0441423   -0.324304     0.012003     0.0694956     0.00322168
  0.0272936     0.0502539  -0.0700881    0.152228     0.0625942    0.0904515   0.0560171     0.0622984    0.0746974     0.0424294   -0.0571516     0.0823039    0.0908302   -0.0344383   -0.142533     0.135409     0.133725     0.209982     0.104357      0.244319     0.265735     0.0205482   -0.00656041  -0.0979491   -0.194084      0.0317972 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.067505
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     10
â”‚     14
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.993435
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      5
â”‚     10
â”‚     11
â”‚     15
â”‚     16
â”‚     22
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.977251
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     10
â”‚     14
â”‚     24
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.010259
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     10
â”‚     11
â”‚     19
â”‚     21
â”‚     22
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.006557
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      5
â”‚      7
â”‚     10
â”‚     14
â”‚     15
â”‚     16
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.973901
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     10
â”‚     11
â”‚     24
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.022710
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     10
â”‚     14
â”‚     19
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.994448
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      5
â”‚     10
â”‚     11
â”‚     15
â”‚     16
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.989080
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     10
â”‚     14
â”‚     24
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.009506
â”Œ Info: EM with 100000 data points 10 iterations avll -1.009506
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.0207241   -0.0695766    0.0702312   0.265572     0.118025    0.00535734  -0.114824     0.0362484   -0.00273287   0.0823855   -0.0735766   0.0983292   -0.0707589     0.00531593    0.00410551  -0.113078    -0.151292    0.173581    -0.000965935  -0.0358489   -0.0796878   -0.0729524    -0.175714    -0.11954      0.0178441    0.0483109
  0.146489     0.0359075   -0.0074221   0.131783    -0.0321935   0.176428     0.0230677    0.0210236    0.0469088    0.0836241   -0.1062      0.0242581   -0.155194     -0.0570934     0.0381284   -0.0369588    0.0366495  -0.134199    -0.187127     -0.0652261   -0.0212996    0.0105172    -0.0211544    0.0781846    0.0814547    0.0796367
 -0.13884      0.167491     0.114969    0.0419608    0.0508576  -0.065931    -0.0131507    0.066697     0.132677    -0.102001    -0.208148    0.0700011    0.0110209    -0.0864049    -0.1363      -0.019653    -0.0853087  -0.169479     0.00524516   -0.186787    -0.113782     0.0501852     0.17453     -0.00921326   0.145472     0.0735031
 -0.100185    -0.125059    -0.121797   -0.108563     0.0786882   0.0756247   -0.0496393    0.070814    -0.0241362   -0.222107    -0.0184984   0.0133252   -0.112492     -0.119975      0.0235741    0.130354     0.034693    0.0214336   -0.00531494    0.0617484   -0.0407767   -0.136137      0.0651183   -0.0867855    0.105931    -0.0120961
  0.0528837   -0.0331459    0.0193364   0.153667    -0.0712223  -0.169206     0.0681833   -0.00843104   0.028235    -0.00434273   0.0287222   0.0321416   -0.0462748     0.0464495    -0.00179888   0.0022183   -0.109811   -0.055932    -0.0403929     0.0271155   -0.235129    -0.0676864    -0.161303     0.0546045   -0.15566     -0.0391206
 -0.0978237   -0.0302932   -0.137896   -0.127503    -0.0134058   0.063781     0.163139    -0.143657     0.2142      -0.0334293   -0.0489737   0.184212     0.0400098    -0.00436916   -0.123195    -0.0709449   -0.166027   -0.124343     0.114742      0.0750673   -0.00543624   0.231075      0.0267242    0.164128    -0.129665    -0.0806313
  0.220432    -0.00479888  -0.100302    0.0800677   -0.233856   -0.0690562   -0.0484957    0.148027    -0.0472718   -0.177476     0.0173856  -0.21304      0.210913     -0.160259      0.039179     0.19442      0.0217441   0.0266091   -0.00623837    0.0244679   -0.0101449   -0.0615402    -0.124902     0.169827    -0.107428    -0.0439752
 -0.157613    -0.0127502    0.0342822  -0.250888    -0.0203688  -0.00112598  -0.0374797    0.102118     0.103893     0.148823    -0.211281    0.0258081    0.0293879     0.0570375     0.211251    -0.00592193   0.0932359   0.274393     0.00354152    0.0141277   -0.00618327  -0.0799073    -0.0529536    0.0417174   -0.0945776    0.0115228
 -0.0476089    0.10214      0.0128962  -0.00368564  -0.0362911   0.113827    -0.257222    -0.019386    -0.00171501  -0.0778202   -0.0626484   0.0299578   -0.0340672     0.0780015    -0.0968787    0.10338     -0.0575327  -0.0418243    0.0441014    -0.0555785    0.0431562    0.135198      0.0212309   -0.0146499   -0.0979155    0.236395 
 -0.272718    -0.143785     0.150268    0.101696    -0.0153012  -0.036002    -0.0733448    0.109       -0.105412     0.097641     0.0258832   0.016639    -0.124079      0.0282733    -0.0528462    0.161598    -0.139244   -0.0196647    0.00944626   -0.102519    -0.0838386   -0.0325816     0.0910036    0.0190605   -0.0317825   -0.0819158
  0.148984     0.107308     0.146558   -0.0516125    0.0148553  -0.0635466   -0.0970935    0.122925    -0.101021    -0.0537131    0.143759   -0.0352615    0.183763     -0.0451238    -0.0859689   -0.0875179    0.151118   -0.0274568   -0.0877277    -0.105132     0.204082    -0.108092     -0.183612    -0.0142043    0.0522849    0.0531078
 -0.14209      0.0633771   -0.0825099   0.0457613    0.0817262   0.123032     0.0116819    0.0826484   -0.149594     0.0906518    0.102447    0.10221      0.0769458    -0.137362     -0.0247599   -0.047182     0.112731    0.0296372   -0.135787     -0.16357      0.0119151    0.0753501    -0.147169    -0.110807     0.0012055    0.0119289
  0.00859174  -0.00155233  -0.007963    0.096348    -0.0481017   0.175991     0.0486568    0.122996     0.297206     0.356508     0.0532225  -0.041817     0.0950367     0.131318     -0.1017       0.0544546    0.034608   -0.101277    -0.0462623    -0.0585099    0.040304     0.0277715     0.123653    -0.0960106    0.0547406   -0.0599222
  0.103791     0.00663848  -0.039114    0.0629056   -0.138493    0.0687119   -0.161126    -0.0557616   -0.128561     0.137586    -0.0948524  -0.124714     0.172127      0.0479893     0.0715709    0.216709     0.0260044  -0.130433    -0.11367       0.0327905    0.203923     0.00238034    0.132084    -0.0810121    0.0569799   -0.0296387
 -0.0211808    0.0117371    0.0390972  -0.0247478   -0.0271567   0.00975191  -0.0110621   -0.0886752    0.0291411   -0.0128009    0.169413    0.0811397    0.0284999    -0.0151357     0.0204441    0.0105648   -0.0107963  -0.0769464    0.117574      0.0657336    0.121881    -0.0563502    -0.00493296   0.112489    -0.0348419    0.160604 
  0.0453927    0.292815    -0.0124908  -0.0736712   -0.0301107  -0.157861    -0.101303     0.00809194  -0.0226193    0.109529    -0.0355267   0.0684123   -0.0659963     0.0167354    -0.0580844    0.115042    -0.0915046  -0.0618078   -0.02059      -0.0128559    0.134774    -0.00446683   -0.0734429   -0.128946    -0.165048     0.0143549
 -0.108127    -0.03323     -0.0690269   0.00282662   0.0404139   0.0907238    0.0493617    0.00887026  -0.225298     0.0717035    0.0439733  -0.0503424   -0.108029     -0.000607355   0.164437    -0.0195151   -0.0573763   0.0673754    0.0653591     0.133955    -0.0683443    0.137087     -0.148568    -0.0641671    0.0408544    0.0657365
  0.134597    -0.0275735   -0.155985    0.121375    -0.0380838   0.00114403   0.0464016    0.0483393    0.155021    -0.160115    -0.0629917  -0.0315911    0.104372      0.13119       0.0837655    0.046335    -0.260166   -0.113052    -0.0665956     0.0500308    0.190333     0.118803     -0.148103    -0.0506951   -0.17648     -0.109588 
 -0.118176     0.101091     0.022292   -0.0409199    0.034496   -0.273438    -0.0977741   -0.00579302   0.0838715   -0.140984     0.0116415  -0.148018     0.0484478    -0.0104476     0.111475    -0.0758196    0.0287818  -0.033261     0.0149508    -0.0413214    0.0713529   -0.175591     -0.0542059    0.0322662    0.0243355    0.0795441
  0.104855    -0.0586738   -0.0460466   0.002341    -0.092237   -0.0534918   -0.00153013   0.0382733    0.132778     0.0330083    0.151099    0.103203    -0.156052     -0.00385153    0.00204998  -0.0657497    0.147793    0.0433763   -0.0994888    -0.0677078    0.0149604    0.00668372    0.0993565    0.0427632    0.00296377  -0.21267  
  0.0640951    0.0701539   -0.0199109   0.0315731   -0.045599    0.0911084    0.0789123    0.0709013    0.018431     0.0816497   -0.164103   -0.11621      0.0401752     0.103113     -0.157338     0.0296032   -0.168754   -0.163564    -0.207791     -0.0313251   -0.194814    -0.0542014    -0.13452      0.0850256    0.135881    -0.146985 
  0.0263581    0.015693     0.0493127  -0.0549992    0.0473411  -0.0672907    0.178147     0.146056    -0.172802     0.120299     0.0536392   0.0540459    0.0104025     0.00684924   -0.119775    -0.0274482    0.169019   -0.051078    -0.203514      0.159682    -0.00503826   0.0179943     0.129689     0.116709     0.156116    -0.0353185
  0.0543116   -0.0279729    0.106182   -0.0542558   -0.0119075  -0.0747541   -0.021963    -0.00789715   0.0200157   -0.0157626   -0.0388442  -0.0209062    0.0131503     0.0460875    -0.0639998    0.0245836    0.011214    0.0721577   -0.141842     -0.154383     0.0660955    0.0456008     0.0844528    0.0259343   -0.0459314    0.0633943
  0.0670362    0.0674627   -0.0113665  -0.04429     -0.0700607   0.00640169   0.00813411   0.125834    -0.0107266   -0.0725811    0.068869   -0.0800498    0.13922       0.0073139     0.0371408    0.0165643    0.136018   -0.0155643    0.136436     -0.0101952    0.107995    -0.120295      0.057229    -0.160708    -0.0162052   -0.11016  
  0.172385     0.138617     0.0355414  -0.00709052   0.0629012  -0.0512622    0.200395    -0.154625    -0.108616    -0.105463    -0.181899    0.0670859    0.173182     -0.0751449     0.0478684   -0.0326885    0.0322308  -0.0243004    0.124239     -0.00453578  -0.00911078  -0.0472823    -0.110222     0.052264    -0.00321804  -0.048072 
  0.0698125   -0.105535     0.15898     0.0270691   -0.0868113  -0.0746847   -0.028491    -0.0484608   -0.108962    -0.126734     0.108356   -0.0945976    0.00215218   -0.0444108     0.0596289   -0.0822354   -0.22172    -0.0652701   -0.0494172     0.00187126   0.0459533    0.0104919     0.0939248   -0.122967    -0.0465379   -0.103826 
  0.00525227  -0.130455    -0.0188546  -0.154967     0.0907468   0.0926817    0.12913     -0.0192205    0.0312921    0.0395483    0.154941    0.0149      -0.0233304    -0.00820161    0.0769315   -0.0479518    0.041608   -0.211906     0.150899      0.0921536    0.0411449   -0.0140131     0.0283609   -0.0614232    0.186749     0.151753 
 -0.0664732    0.0349106    0.066154   -0.0980274   -0.0806407   0.0316098    0.0479082   -0.0658269    0.0262352    0.179262     0.13092     0.101        0.000946426   0.0405585    -0.107955    -0.10024     -0.0139943   0.0326331    0.141356      0.166357    -0.0177466   -0.0655292    -0.0333304    0.0285235   -0.00582065  -0.0462854
  0.0971031    0.00650514   0.0845227   0.0428332   -0.148762    0.145916    -0.129689     0.107527    -0.0249293    0.0822246    0.127162   -0.0788221   -0.031871      0.0933964    -0.142256    -0.00571871   0.126217   -0.00900972  -0.0543891    -0.0045135    0.0510596    0.000879008   0.0265914    0.0265781   -0.106615     0.0831084
 -0.0132485    0.0631652   -0.118969   -0.101142     0.023657   -0.00681979   0.0824418    0.0671044   -0.127363     0.0512746    0.126773   -0.1487      -0.123938      0.0122544     0.0419419    0.122414    -0.0478837  -0.0190212    0.165364      0.179179    -0.175257     0.0883381    -0.122954    -0.0417706    0.00191003  -0.116423 
 -0.0435234   -0.00481935  -0.0321288   0.0831734    0.0542863   0.0104675   -0.0642553   -0.0247223    0.187339    -0.0246022   -0.125136   -0.00107594  -0.0308967    -0.0356687    -0.00523562   0.132689    -0.120033    0.107672     0.0955182    -0.0146254    0.0958655    0.073808      0.093126     0.222389    -0.01333      0.052457 
 -0.0199696    0.0505104   -0.0271574   0.0247486   -0.0535706  -0.0046045   -0.0210022   -0.059715    -0.095348    -0.074569    -0.0315541  -0.0341308   -0.0298358    -0.0836542    -0.172826     0.00532807  -0.0231365   0.082497     0.0728719    -0.147966     0.119549     0.056903     -0.00166287   0.0315392   -0.107354    -0.0805604kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4194411082349525
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419459
[ Info: iteration 2, average log likelihood -1.419360
[ Info: iteration 3, average log likelihood -1.419267
[ Info: iteration 4, average log likelihood -1.419152
[ Info: iteration 5, average log likelihood -1.419016
[ Info: iteration 6, average log likelihood -1.418870
[ Info: iteration 7, average log likelihood -1.418730
[ Info: iteration 8, average log likelihood -1.418602
[ Info: iteration 9, average log likelihood -1.418472
[ Info: iteration 10, average log likelihood -1.418302
[ Info: iteration 11, average log likelihood -1.418032
[ Info: iteration 12, average log likelihood -1.417586
[ Info: iteration 13, average log likelihood -1.416907
[ Info: iteration 14, average log likelihood -1.416045
[ Info: iteration 15, average log likelihood -1.415209
[ Info: iteration 16, average log likelihood -1.414613
[ Info: iteration 17, average log likelihood -1.414287
[ Info: iteration 18, average log likelihood -1.414134
[ Info: iteration 19, average log likelihood -1.414068
[ Info: iteration 20, average log likelihood -1.414039
[ Info: iteration 21, average log likelihood -1.414026
[ Info: iteration 22, average log likelihood -1.414020
[ Info: iteration 23, average log likelihood -1.414018
[ Info: iteration 24, average log likelihood -1.414016
[ Info: iteration 25, average log likelihood -1.414015
[ Info: iteration 26, average log likelihood -1.414014
[ Info: iteration 27, average log likelihood -1.414013
[ Info: iteration 28, average log likelihood -1.414013
[ Info: iteration 29, average log likelihood -1.414012
[ Info: iteration 30, average log likelihood -1.414012
[ Info: iteration 31, average log likelihood -1.414012
[ Info: iteration 32, average log likelihood -1.414011
[ Info: iteration 33, average log likelihood -1.414011
[ Info: iteration 34, average log likelihood -1.414011
[ Info: iteration 35, average log likelihood -1.414011
[ Info: iteration 36, average log likelihood -1.414010
[ Info: iteration 37, average log likelihood -1.414010
[ Info: iteration 38, average log likelihood -1.414010
[ Info: iteration 39, average log likelihood -1.414010
[ Info: iteration 40, average log likelihood -1.414010
[ Info: iteration 41, average log likelihood -1.414010
[ Info: iteration 42, average log likelihood -1.414010
[ Info: iteration 43, average log likelihood -1.414009
[ Info: iteration 44, average log likelihood -1.414009
[ Info: iteration 45, average log likelihood -1.414009
[ Info: iteration 46, average log likelihood -1.414009
[ Info: iteration 47, average log likelihood -1.414009
[ Info: iteration 48, average log likelihood -1.414009
[ Info: iteration 49, average log likelihood -1.414009
[ Info: iteration 50, average log likelihood -1.414009
â”Œ Info: EM with 100000 data points 50 iterations avll -1.414009
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.419458522514437 
â”‚     -1.4193600410830578
â”‚      â‹®                 
â””     -1.4140089784173915
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414023
[ Info: iteration 2, average log likelihood -1.413935
[ Info: iteration 3, average log likelihood -1.413848
[ Info: iteration 4, average log likelihood -1.413738
[ Info: iteration 5, average log likelihood -1.413608
[ Info: iteration 6, average log likelihood -1.413469
[ Info: iteration 7, average log likelihood -1.413342
[ Info: iteration 8, average log likelihood -1.413237
[ Info: iteration 9, average log likelihood -1.413154
[ Info: iteration 10, average log likelihood -1.413087
[ Info: iteration 11, average log likelihood -1.413031
[ Info: iteration 12, average log likelihood -1.412985
[ Info: iteration 13, average log likelihood -1.412948
[ Info: iteration 14, average log likelihood -1.412920
[ Info: iteration 15, average log likelihood -1.412898
[ Info: iteration 16, average log likelihood -1.412883
[ Info: iteration 17, average log likelihood -1.412873
[ Info: iteration 18, average log likelihood -1.412865
[ Info: iteration 19, average log likelihood -1.412859
[ Info: iteration 20, average log likelihood -1.412855
[ Info: iteration 21, average log likelihood -1.412852
[ Info: iteration 22, average log likelihood -1.412849
[ Info: iteration 23, average log likelihood -1.412847
[ Info: iteration 24, average log likelihood -1.412845
[ Info: iteration 25, average log likelihood -1.412843
[ Info: iteration 26, average log likelihood -1.412842
[ Info: iteration 27, average log likelihood -1.412841
[ Info: iteration 28, average log likelihood -1.412840
[ Info: iteration 29, average log likelihood -1.412839
[ Info: iteration 30, average log likelihood -1.412838
[ Info: iteration 31, average log likelihood -1.412837
[ Info: iteration 32, average log likelihood -1.412836
[ Info: iteration 33, average log likelihood -1.412836
[ Info: iteration 34, average log likelihood -1.412835
[ Info: iteration 35, average log likelihood -1.412835
[ Info: iteration 36, average log likelihood -1.412834
[ Info: iteration 37, average log likelihood -1.412834
[ Info: iteration 38, average log likelihood -1.412834
[ Info: iteration 39, average log likelihood -1.412833
[ Info: iteration 40, average log likelihood -1.412833
[ Info: iteration 41, average log likelihood -1.412832
[ Info: iteration 42, average log likelihood -1.412832
[ Info: iteration 43, average log likelihood -1.412832
[ Info: iteration 44, average log likelihood -1.412832
[ Info: iteration 45, average log likelihood -1.412831
[ Info: iteration 46, average log likelihood -1.412831
[ Info: iteration 47, average log likelihood -1.412831
[ Info: iteration 48, average log likelihood -1.412830
[ Info: iteration 49, average log likelihood -1.412830
[ Info: iteration 50, average log likelihood -1.412830
â”Œ Info: EM with 100000 data points 50 iterations avll -1.412830
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.41402284488665  
â”‚     -1.413935442880661 
â”‚      â‹®                 
â””     -1.4128298124858643
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412839
[ Info: iteration 2, average log likelihood -1.412787
[ Info: iteration 3, average log likelihood -1.412739
[ Info: iteration 4, average log likelihood -1.412682
[ Info: iteration 5, average log likelihood -1.412610
[ Info: iteration 6, average log likelihood -1.412522
[ Info: iteration 7, average log likelihood -1.412420
[ Info: iteration 8, average log likelihood -1.412311
[ Info: iteration 9, average log likelihood -1.412201
[ Info: iteration 10, average log likelihood -1.412096
[ Info: iteration 11, average log likelihood -1.411998
[ Info: iteration 12, average log likelihood -1.411909
[ Info: iteration 13, average log likelihood -1.411827
[ Info: iteration 14, average log likelihood -1.411752
[ Info: iteration 15, average log likelihood -1.411683
[ Info: iteration 16, average log likelihood -1.411620
[ Info: iteration 17, average log likelihood -1.411562
[ Info: iteration 18, average log likelihood -1.411511
[ Info: iteration 19, average log likelihood -1.411465
[ Info: iteration 20, average log likelihood -1.411425
[ Info: iteration 21, average log likelihood -1.411391
[ Info: iteration 22, average log likelihood -1.411362
[ Info: iteration 23, average log likelihood -1.411337
[ Info: iteration 24, average log likelihood -1.411317
[ Info: iteration 25, average log likelihood -1.411300
[ Info: iteration 26, average log likelihood -1.411286
[ Info: iteration 27, average log likelihood -1.411274
[ Info: iteration 28, average log likelihood -1.411264
[ Info: iteration 29, average log likelihood -1.411256
[ Info: iteration 30, average log likelihood -1.411248
[ Info: iteration 31, average log likelihood -1.411241
[ Info: iteration 32, average log likelihood -1.411235
[ Info: iteration 33, average log likelihood -1.411230
[ Info: iteration 34, average log likelihood -1.411225
[ Info: iteration 35, average log likelihood -1.411220
[ Info: iteration 36, average log likelihood -1.411216
[ Info: iteration 37, average log likelihood -1.411211
[ Info: iteration 38, average log likelihood -1.411207
[ Info: iteration 39, average log likelihood -1.411203
[ Info: iteration 40, average log likelihood -1.411200
[ Info: iteration 41, average log likelihood -1.411196
[ Info: iteration 42, average log likelihood -1.411193
[ Info: iteration 43, average log likelihood -1.411189
[ Info: iteration 44, average log likelihood -1.411186
[ Info: iteration 45, average log likelihood -1.411183
[ Info: iteration 46, average log likelihood -1.411180
[ Info: iteration 47, average log likelihood -1.411177
[ Info: iteration 48, average log likelihood -1.411174
[ Info: iteration 49, average log likelihood -1.411171
[ Info: iteration 50, average log likelihood -1.411169
â”Œ Info: EM with 100000 data points 50 iterations avll -1.411169
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.412839460480956 
â”‚     -1.4127871179351226
â”‚      â‹®                 
â””     -1.4111687235582386
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411175
[ Info: iteration 2, average log likelihood -1.411126
[ Info: iteration 3, average log likelihood -1.411083
[ Info: iteration 4, average log likelihood -1.411034
[ Info: iteration 5, average log likelihood -1.410975
[ Info: iteration 6, average log likelihood -1.410903
[ Info: iteration 7, average log likelihood -1.410819
[ Info: iteration 8, average log likelihood -1.410725
[ Info: iteration 9, average log likelihood -1.410626
[ Info: iteration 10, average log likelihood -1.410527
[ Info: iteration 11, average log likelihood -1.410433
[ Info: iteration 12, average log likelihood -1.410344
[ Info: iteration 13, average log likelihood -1.410262
[ Info: iteration 14, average log likelihood -1.410187
[ Info: iteration 15, average log likelihood -1.410118
[ Info: iteration 16, average log likelihood -1.410054
[ Info: iteration 17, average log likelihood -1.409995
[ Info: iteration 18, average log likelihood -1.409941
[ Info: iteration 19, average log likelihood -1.409890
[ Info: iteration 20, average log likelihood -1.409844
[ Info: iteration 21, average log likelihood -1.409802
[ Info: iteration 22, average log likelihood -1.409764
[ Info: iteration 23, average log likelihood -1.409729
[ Info: iteration 24, average log likelihood -1.409697
[ Info: iteration 25, average log likelihood -1.409667
[ Info: iteration 26, average log likelihood -1.409640
[ Info: iteration 27, average log likelihood -1.409615
[ Info: iteration 28, average log likelihood -1.409592
[ Info: iteration 29, average log likelihood -1.409570
[ Info: iteration 30, average log likelihood -1.409550
[ Info: iteration 31, average log likelihood -1.409530
[ Info: iteration 32, average log likelihood -1.409512
[ Info: iteration 33, average log likelihood -1.409494
[ Info: iteration 34, average log likelihood -1.409477
[ Info: iteration 35, average log likelihood -1.409461
[ Info: iteration 36, average log likelihood -1.409446
[ Info: iteration 37, average log likelihood -1.409431
[ Info: iteration 38, average log likelihood -1.409418
[ Info: iteration 39, average log likelihood -1.409404
[ Info: iteration 40, average log likelihood -1.409391
[ Info: iteration 41, average log likelihood -1.409379
[ Info: iteration 42, average log likelihood -1.409368
[ Info: iteration 43, average log likelihood -1.409356
[ Info: iteration 44, average log likelihood -1.409346
[ Info: iteration 45, average log likelihood -1.409336
[ Info: iteration 46, average log likelihood -1.409326
[ Info: iteration 47, average log likelihood -1.409316
[ Info: iteration 48, average log likelihood -1.409307
[ Info: iteration 49, average log likelihood -1.409299
[ Info: iteration 50, average log likelihood -1.409291
â”Œ Info: EM with 100000 data points 50 iterations avll -1.409291
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4111748712354049
â”‚     -1.4111264138764603
â”‚      â‹®                 
â””     -1.409290631619863 
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409290
[ Info: iteration 2, average log likelihood -1.409226
[ Info: iteration 3, average log likelihood -1.409164
[ Info: iteration 4, average log likelihood -1.409090
[ Info: iteration 5, average log likelihood -1.408998
[ Info: iteration 6, average log likelihood -1.408885
[ Info: iteration 7, average log likelihood -1.408752
[ Info: iteration 8, average log likelihood -1.408605
[ Info: iteration 9, average log likelihood -1.408451
[ Info: iteration 10, average log likelihood -1.408296
[ Info: iteration 11, average log likelihood -1.408146
[ Info: iteration 12, average log likelihood -1.408005
[ Info: iteration 13, average log likelihood -1.407874
[ Info: iteration 14, average log likelihood -1.407756
[ Info: iteration 15, average log likelihood -1.407650
[ Info: iteration 16, average log likelihood -1.407556
[ Info: iteration 17, average log likelihood -1.407472
[ Info: iteration 18, average log likelihood -1.407398
[ Info: iteration 19, average log likelihood -1.407332
[ Info: iteration 20, average log likelihood -1.407274
[ Info: iteration 21, average log likelihood -1.407221
[ Info: iteration 22, average log likelihood -1.407173
[ Info: iteration 23, average log likelihood -1.407129
[ Info: iteration 24, average log likelihood -1.407089
[ Info: iteration 25, average log likelihood -1.407053
[ Info: iteration 26, average log likelihood -1.407019
[ Info: iteration 27, average log likelihood -1.406988
[ Info: iteration 28, average log likelihood -1.406959
[ Info: iteration 29, average log likelihood -1.406932
[ Info: iteration 30, average log likelihood -1.406906
[ Info: iteration 31, average log likelihood -1.406883
[ Info: iteration 32, average log likelihood -1.406861
[ Info: iteration 33, average log likelihood -1.406840
[ Info: iteration 34, average log likelihood -1.406821
[ Info: iteration 35, average log likelihood -1.406803
[ Info: iteration 36, average log likelihood -1.406786
[ Info: iteration 37, average log likelihood -1.406770
[ Info: iteration 38, average log likelihood -1.406755
[ Info: iteration 39, average log likelihood -1.406740
[ Info: iteration 40, average log likelihood -1.406727
[ Info: iteration 41, average log likelihood -1.406714
[ Info: iteration 42, average log likelihood -1.406702
[ Info: iteration 43, average log likelihood -1.406691
[ Info: iteration 44, average log likelihood -1.406680
[ Info: iteration 45, average log likelihood -1.406670
[ Info: iteration 46, average log likelihood -1.406660
[ Info: iteration 47, average log likelihood -1.406651
[ Info: iteration 48, average log likelihood -1.406642
[ Info: iteration 49, average log likelihood -1.406634
[ Info: iteration 50, average log likelihood -1.406626
â”Œ Info: EM with 100000 data points 50 iterations avll -1.406626
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4092900848834162
â”‚     -1.4092263781662573
â”‚      â‹®                 
â””     -1.4066261866259249
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4194411082349525
â”‚     -1.419458522514437 
â”‚     -1.4193600410830578
â”‚     -1.4192666162266365
â”‚      â‹®                 
â”‚     -1.4066423573384992
â”‚     -1.406634075974019 
â””     -1.4066261866259249
32Ã—26 Array{Float64,2}:
 -0.469833   -0.4718      -0.0468582  -0.507024   -0.557234      0.085261    -0.725829    0.0337874   -0.0710271    0.713419    -0.600475   -0.511406    0.348112     0.168428    0.0880351   -0.42938     0.537746   -0.399348    0.273701    -0.50917     -0.179208    0.0815411    0.688587    -0.326089    -0.0923776    0.12643  
  0.0848014   0.15223      0.424615   -0.482441   -0.400013     -0.320966    -0.399898   -0.780122     0.413412     0.684617     0.0632705  -0.233375    0.0512645   -0.502879   -0.406481    -0.113875    0.840789   -0.285358    0.219135     0.201672    -0.0138787   0.00283888   0.753991    -0.599694     0.144201    -0.130622 
  0.26508     0.152071    -0.171755   -0.776619    0.482253     -0.218403     0.0175813  -0.255973    -0.491669     0.14952     -0.587423    0.328301   -0.274307    -0.398445    0.284528     0.264265    0.199458    0.22613    -0.194442    -0.0895211    0.249985   -0.292488     0.00886459  -0.141967     0.0976962   -0.099852 
 -0.0166739   0.00586486  -0.132524   -0.178764    0.0930348     0.221684     0.333771    0.0364682    0.208746     0.0474461    0.272123   -0.0880975  -0.0194041    0.181902   -0.221939    -0.0277088   0.279943    0.127484   -0.229615     0.149316    -0.195393   -0.0402483   -0.101675    -0.200826    -0.391182    -0.0562868
 -0.31034    -0.0300979    0.468894    0.678544    0.162467     -0.349609    -0.229896    0.778364    -0.352221     0.342068     0.240819    0.436574   -0.022391     0.179004    0.266736    -0.23242    -0.589286   -0.521814   -0.00453358   0.0521796   -0.394872   -0.323322    -0.105137    -0.0379341   -0.474111    -0.570207 
 -0.429424   -0.187657    -0.0849572   0.577863   -0.238858      0.556238     0.178025    0.326662     0.406543    -0.104525    -0.0824085  -0.301487    0.172134     0.200639   -0.0895775   -0.387536   -0.726125   -0.199511    0.21531     -0.459135     0.359595   -0.498069     0.358654    -0.0878758   -0.110311    -0.144584 
 -0.413142   -0.357039     0.0781708  -0.167303    0.873341      0.478858    -0.43417     0.0222298   -0.111296    -0.330953     0.0361791   0.128348   -0.428671    -1.53084    -0.470492    -0.0957953  -0.325682   -0.588535   -0.138168     0.178345    -0.363428    0.912686    -0.0613222    0.330684    -0.228312    -0.795591 
  0.0783492  -0.376612    -0.356297    0.150124   -0.183352     -0.169715    -0.735121   -0.0866307    0.750781     0.243875    -0.263112   -0.234227   -0.327034     0.310045   -0.0126353   -0.574974   -0.253099    0.565627    0.00193232   0.194459    -0.655666    0.0324963   -0.133449     0.467688    -1.27274     -0.500699 
  0.14083     0.314533    -0.279566    0.477199    0.434735      0.0966848    0.315631    0.327903     0.221488    -0.816266     0.172753    0.51153     0.0383844   -0.101588    0.0606887    0.308582   -0.536862    0.884341   -0.0407002    0.0877136    0.237098    0.0103755   -0.433523     0.947764    -0.310859     0.0949252
 -0.157219   -0.0641837   -1.18342    -0.313484    0.0457626    -0.00308937  -0.240697    0.00810661   0.149467    -0.278246    -0.137866   -0.189288    0.0729383   -0.0216378  -0.174686     0.246657    0.0858722   0.409986    0.233253    -0.00895656   0.101701    0.74919      0.142313     1.19948     -0.344217     0.0515097
  0.518452   -0.00410994   0.254523    0.409731   -0.721484     -0.586667    -0.138222    0.335054     0.394856    -0.198259     0.506058   -0.528253    0.361748    -0.845547    0.314428    -0.0146805  -0.386202    0.094303   -0.0732004    0.489224    -0.0426518  -0.717216     0.379723     1.01774      0.439607    -0.049883 
  0.191452   -0.0138493    0.464965    0.470273   -0.231882     -0.299687    -0.367441    0.0456702   -0.102814    -0.370109    -0.0545679   0.155249    0.0914114   -0.0941644   0.15439      0.301167   -0.0115397   0.0303701   0.319993     0.269865     0.332569    0.528177    -0.075175     0.376708     0.841263     0.520763 
 -0.421386    0.0133598    0.434383    0.596791    0.270438      0.353463     0.136852   -0.168186    -0.986794     0.0183688    0.592961   -0.0346345   0.474635    -0.422496   -0.101867     0.0502812  -0.316092   -0.210669   -0.716642    -0.377702    -0.0215605  -0.183487    -0.0923907   -0.302849     0.828357    -0.126177 
  0.315942    0.115907     1.06938     0.055624   -0.227964      0.219807     0.221811   -0.0692773   -0.103912    -0.125409    -0.128231    0.172966   -0.523764    -0.10171     0.0733594   -0.0155804   0.0330599  -0.596117   -0.495861    -0.0893315   -0.112901   -0.659589     0.0828363   -1.16444      0.522769    -0.066417 
 -0.389477    0.392529    -0.0316878   0.178827   -0.122042      0.00134642  -0.351131   -0.427552    -0.581624    -0.215249    -0.12549     0.0528238  -0.280451     0.535888    0.262894    -0.530136   -0.192889   -0.113193    0.569168    -0.744115     0.507246   -0.140222    -0.392976    -0.201462    -0.00768158  -0.0301827
  0.208742    0.393145    -0.272864   -0.0930022  -0.165126     -0.405569     0.779088   -0.170429    -0.303074     0.0958561    0.354308    0.163962    0.0772586    0.565677    0.0495329    0.544206   -0.0820614  -0.265463    0.446024    -0.051756     0.454942   -0.145108    -0.330323    -0.259336     0.571554     0.326235 
 -0.595532    0.13563     -0.424301   -0.398183    0.0224258    -0.00933265   0.0899346  -0.0671466   -0.0963089    0.504674     0.15156     0.3183     -0.35443      0.363384    0.124957    -0.149226   -0.075751   -0.16003     0.0935702   -0.0238242   -0.442631   -0.459324     0.0531594   -0.0817262   -0.983525    -0.37468  
 -0.0982719   0.24769     -0.259965   -0.424645    0.17222       0.243809     0.477731    0.110728     0.184968     0.573648     0.128484   -0.493365    0.345368     0.081163    0.226338    -0.312401    0.29543     0.271621   -0.279044    -0.203502     0.173583   -0.476199     0.116026    -0.433754    -0.198145    -0.0935057
 -0.0555966   0.161541    -0.247177   -0.376621    0.248038     -0.180794    -0.0391563  -0.112927    -0.368866     0.0466043   -0.326892    0.0567388  -0.400538     0.290417   -0.319381     0.155458    0.584588   -0.0658104  -0.447864    -0.135184    -0.364632    0.406665    -0.250685    -0.373959    -0.391589    -0.0270588
  0.559502    0.0638364   -0.260997   -0.1556     -0.43374      -0.32476     -0.0841791   0.106489     0.771074     0.206639    -0.499156    0.342978   -0.507321     0.0276078  -0.195241     0.105776    0.270978    0.0351102   0.275523     0.186633     0.127192    0.510139    -0.0659254    0.228724    -0.300479     0.152438 
  0.291775    0.167738    -0.218238   -0.261935   -0.142742     -0.583372    -0.790219   -0.437576    -0.528823    -0.22088     -0.0313031  -0.163148    0.00719284  -0.230767    0.360518     0.202755    0.163825    0.0733831  -0.100574     0.0133741   -0.0405941   0.254164     0.0419244    0.345374     0.257383    -0.137656 
  0.232429   -0.163971     0.66996    -0.108944    0.0858883    -0.0836519   -0.236293    0.333962    -0.349223     0.231952    -0.142      -0.0217165   0.0816584   -0.196366    0.830924     0.154256    0.13935     0.174727    0.226664     0.165563     0.52237    -0.224654     0.130511     0.168825     0.495519     0.133278 
  0.0574189  -0.131519     0.394544   -0.0364199  -0.0303282     0.174604    -0.0186896   0.392271     0.225217    -0.0958765   -0.086125   -0.103262   -0.0923679   -0.642489   -0.505763     0.433654    0.250185    0.193227   -0.412342     0.361531    -0.513925    0.0482152    0.576784     0.323732    -0.398662    -0.10615  
  0.0592991  -0.0824889    0.176531    0.419667   -0.296141     -0.42665     -0.486094   -0.0640899   -0.435457    -0.315869    -0.364428    0.555452   -0.544422     0.0540237   0.0354119    0.364737   -0.353452    0.0771401   0.121638     0.10797     -0.534377    0.0769636   -0.257409     0.549098     0.0673705    0.0568827
 -0.19786    -0.100941    -0.0513379   0.374425    0.0192031     0.0854406    0.147003    0.128004    -0.0762011    0.161702    -0.478172    0.201951    0.22179     -0.29855    -0.104106    -0.455374   -0.331843   -0.233206    0.377312    -0.306691     0.41892    -0.172925     0.062369     0.186311    -0.264064    -0.102769 
  0.210847   -0.0981733    0.0761726   0.441644   -0.154745      0.0977774   -0.100932    0.0299384    0.196627    -0.544849     0.383803    0.101558    0.371624     0.0688873  -0.270385     0.147823   -0.440318   -0.362884    0.375832    -0.107771     0.628652    0.17044      0.00270427   0.123502     0.221822     0.0344597
  0.048442    0.102156    -0.143945   -0.116333    0.0137212    -0.137083     0.211135    0.148375     0.0253038   -0.00573898  -0.116583    0.0401893  -0.0815682    0.0522912  -0.0330531    0.16887     0.0542905   0.0314405  -0.0489185   -0.00957521   0.0781386  -0.0332226   -0.0131573   -0.039204     0.0854901    0.0846378
 -0.130909   -0.0405503    0.131719    0.112826    0.00790662    0.201989    -0.238127   -0.0760625    0.00442472  -0.0621906    0.0922387  -0.139949    0.00878291   0.0331097   0.00948653  -0.0921723  -0.0823448  -0.0667218  -0.0319053   -0.0558769   -0.113893   -0.051556    -0.0191342   -0.113045    -0.0431831   -0.0984135
  0.519235   -0.456991     0.0963443  -0.167467    0.196054     -0.0668384    0.211571    0.354159     0.13379      0.0944486    0.15066    -0.194792    0.604431    -0.296667    0.105096     0.245197   -0.322692   -0.140538   -0.479534     0.531651     0.159413    0.304413    -0.124903     0.183615     0.549186     0.618755 
  0.0400616  -0.0548285    0.0717923  -0.0607135  -0.1037        0.530238    -0.356413    0.141069     0.281171    -0.00537118   0.483169   -0.407072    0.3791       0.101603    0.347608    -0.102418   -0.0743708   0.248209   -0.34019      0.463052    -0.515508    0.333719    -0.442375     0.00305608   0.387236     0.130305 
  0.25257    -0.00677628  -0.23283    -0.0705915  -0.000763225   0.556666     0.655715   -0.173718     0.337797    -0.514615     0.0745189  -0.0527875  -0.0513858    0.223696   -0.65054      0.0344324   0.166818   -0.0930887  -0.0188476   -0.029523     0.117437    0.122274    -0.308005    -0.459865    -0.115035     0.144785 
 -0.505125    0.177468     0.348502    0.409095    0.0824463    -0.105506     0.366084    0.116823     0.607923     0.604016     0.663792   -0.156408    0.0871049    0.589095   -0.315763    -0.0354613   0.0664497  -0.231111    0.0994933    0.210313    -0.261605    0.239537     0.194326    -0.258428    -0.00460061   0.166911 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406619
[ Info: iteration 2, average log likelihood -1.406611
[ Info: iteration 3, average log likelihood -1.406605
[ Info: iteration 4, average log likelihood -1.406598
[ Info: iteration 5, average log likelihood -1.406592
[ Info: iteration 6, average log likelihood -1.406586
[ Info: iteration 7, average log likelihood -1.406580
[ Info: iteration 8, average log likelihood -1.406574
[ Info: iteration 9, average log likelihood -1.406569
[ Info: iteration 10, average log likelihood -1.406564
â”Œ Info: EM with 100000 data points 10 iterations avll -1.406564
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.797812e+05
      1       6.924051e+05      -2.873760e+05 |       32
      2       6.827985e+05      -9.606645e+03 |       32
      3       6.784728e+05      -4.325722e+03 |       32
      4       6.759567e+05      -2.516041e+03 |       32
      5       6.741996e+05      -1.757165e+03 |       32
      6       6.729053e+05      -1.294240e+03 |       32
      7       6.719924e+05      -9.129162e+02 |       32
      8       6.712858e+05      -7.066245e+02 |       32
      9       6.706958e+05      -5.899521e+02 |       32
     10       6.701758e+05      -5.200227e+02 |       32
     11       6.697368e+05      -4.390423e+02 |       32
     12       6.693254e+05      -4.113508e+02 |       32
     13       6.689707e+05      -3.547449e+02 |       32
     14       6.686501e+05      -3.205989e+02 |       32
     15       6.683727e+05      -2.773961e+02 |       32
     16       6.681066e+05      -2.660384e+02 |       32
     17       6.678652e+05      -2.414251e+02 |       32
     18       6.676563e+05      -2.088731e+02 |       32
     19       6.674668e+05      -1.895621e+02 |       32
     20       6.672864e+05      -1.803818e+02 |       32
     21       6.671132e+05      -1.732212e+02 |       32
     22       6.669464e+05      -1.667267e+02 |       32
     23       6.667975e+05      -1.489533e+02 |       32
     24       6.666604e+05      -1.370682e+02 |       32
     25       6.665212e+05      -1.392163e+02 |       32
     26       6.663826e+05      -1.386449e+02 |       32
     27       6.662521e+05      -1.304187e+02 |       32
     28       6.661352e+05      -1.169587e+02 |       32
     29       6.660265e+05      -1.087035e+02 |       32
     30       6.659302e+05      -9.626823e+01 |       32
     31       6.658500e+05      -8.019069e+01 |       32
     32       6.657789e+05      -7.114792e+01 |       32
     33       6.657098e+05      -6.907416e+01 |       32
     34       6.656475e+05      -6.228702e+01 |       32
     35       6.655826e+05      -6.491796e+01 |       32
     36       6.655269e+05      -5.570731e+01 |       32
     37       6.654736e+05      -5.326205e+01 |       32
     38       6.654266e+05      -4.699234e+01 |       32
     39       6.653820e+05      -4.462428e+01 |       32
     40       6.653406e+05      -4.139735e+01 |       32
     41       6.652993e+05      -4.130693e+01 |       32
     42       6.652594e+05      -3.990187e+01 |       32
     43       6.652269e+05      -3.247857e+01 |       32
     44       6.651987e+05      -2.822888e+01 |       32
     45       6.651721e+05      -2.658894e+01 |       32
     46       6.651444e+05      -2.774318e+01 |       32
     47       6.651182e+05      -2.611423e+01 |       32
     48       6.650899e+05      -2.837628e+01 |       32
     49       6.650549e+05      -3.494548e+01 |       32
     50       6.650148e+05      -4.008101e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 665014.8347346399)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418616
[ Info: iteration 2, average log likelihood -1.413435
[ Info: iteration 3, average log likelihood -1.412029
[ Info: iteration 4, average log likelihood -1.410958
[ Info: iteration 5, average log likelihood -1.409810
[ Info: iteration 6, average log likelihood -1.408766
[ Info: iteration 7, average log likelihood -1.408073
[ Info: iteration 8, average log likelihood -1.407694
[ Info: iteration 9, average log likelihood -1.407482
[ Info: iteration 10, average log likelihood -1.407346
[ Info: iteration 11, average log likelihood -1.407246
[ Info: iteration 12, average log likelihood -1.407166
[ Info: iteration 13, average log likelihood -1.407100
[ Info: iteration 14, average log likelihood -1.407043
[ Info: iteration 15, average log likelihood -1.406993
[ Info: iteration 16, average log likelihood -1.406949
[ Info: iteration 17, average log likelihood -1.406909
[ Info: iteration 18, average log likelihood -1.406872
[ Info: iteration 19, average log likelihood -1.406838
[ Info: iteration 20, average log likelihood -1.406806
[ Info: iteration 21, average log likelihood -1.406776
[ Info: iteration 22, average log likelihood -1.406747
[ Info: iteration 23, average log likelihood -1.406720
[ Info: iteration 24, average log likelihood -1.406694
[ Info: iteration 25, average log likelihood -1.406669
[ Info: iteration 26, average log likelihood -1.406646
[ Info: iteration 27, average log likelihood -1.406623
[ Info: iteration 28, average log likelihood -1.406601
[ Info: iteration 29, average log likelihood -1.406579
[ Info: iteration 30, average log likelihood -1.406559
[ Info: iteration 31, average log likelihood -1.406540
[ Info: iteration 32, average log likelihood -1.406522
[ Info: iteration 33, average log likelihood -1.406504
[ Info: iteration 34, average log likelihood -1.406488
[ Info: iteration 35, average log likelihood -1.406472
[ Info: iteration 36, average log likelihood -1.406458
[ Info: iteration 37, average log likelihood -1.406444
[ Info: iteration 38, average log likelihood -1.406431
[ Info: iteration 39, average log likelihood -1.406418
[ Info: iteration 40, average log likelihood -1.406406
[ Info: iteration 41, average log likelihood -1.406395
[ Info: iteration 42, average log likelihood -1.406384
[ Info: iteration 43, average log likelihood -1.406374
[ Info: iteration 44, average log likelihood -1.406365
[ Info: iteration 45, average log likelihood -1.406356
[ Info: iteration 46, average log likelihood -1.406347
[ Info: iteration 47, average log likelihood -1.406339
[ Info: iteration 48, average log likelihood -1.406331
[ Info: iteration 49, average log likelihood -1.406323
32Ã—26 Array{Float64,2}:
[ Info: iteration 50, average log likelihood -1.406316
â”Œ Info: EM with 100000 data points 50 iterations avll -1.406316
â”” 59.0 data points per parameter
  0.162663     0.479414   -0.133586   -0.309789    -0.527154    0.88845      0.251126    -0.345233      0.58733     -0.366038     0.0561152    -0.56753     -0.0315635   -0.0885482  -0.430783   -0.447802     -0.0705445     0.31975     -0.912451    -0.312114    0.316786     0.121886    0.0582555   -0.363221    0.257227    -0.149067 
 -0.387633     0.320938    0.178705   -0.163058    -0.146487    0.00372872  -0.00520558   0.240208      0.16622     -0.169991     0.338961     -0.519639     0.154766    -0.388351   -0.30787     0.647166      0.247661      0.107711    -0.546319     0.111096   -0.401243    -0.304901    0.510254     0.133294   -0.101209    -0.247297 
  0.111108    -0.25003     0.221266    0.466336    -0.132445    0.0385938   -0.0855383    0.367019      0.0499062   -0.0351312    0.513676     -0.328213     0.774957    -0.188888    0.368451   -0.0540645    -0.594259     -0.0352314   -0.00857927   0.276058    0.216269    -0.148278   -0.0935606    0.318001    0.69982      0.253777 
  0.447148     0.152012   -0.415259   -0.332288     0.134816    0.389412     0.573522    -0.340353      0.251442    -0.445238    -0.193033     -0.113891    -0.0897384    0.600169   -0.257796    0.297072      0.408832      0.0872416    0.0422332    0.0413016  -0.348927     0.102372   -0.384582    -0.650297   -0.366035    -0.103566 
  0.510147    -0.196172   -0.220756    0.19105     -0.356972    0.0943759    0.623326    -0.0962811     0.148074    -0.261375     0.346511      0.204232     0.440988     0.160379   -0.435591    0.114504     -0.182264     -0.681898     0.353055    -0.1858      0.651709     0.0473236  -0.127998    -0.112903    0.39763      0.267168 
 -0.00518013  -0.0689377   0.0220108  -0.0984288    0.247355    0.346134    -0.695718     0.0385609    -0.420099    -0.355614    -0.132127      0.0821994   -0.149754    -1.18034    -0.270723   -0.531743     -0.502605     -0.778983     0.0207357   -0.0791628  -0.124125     0.795379   -0.0222119    0.408602   -0.120051    -0.579741 
 -0.264573    -0.83684     0.265661   -0.0033862    1.02646     0.340887     0.163894     0.133877      0.17161     -0.0618568    0.320318      0.225451    -0.0887445   -0.533895   -0.644463    0.370574     -0.115921      0.0389095   -0.589666     0.195052   -0.341434     0.369974    0.129574    -0.228043   -0.222606    -0.357022 
 -0.079493    -0.21152     0.0725338  -0.765568    -0.6051     -0.142437    -0.652484    -0.444288     -0.0303905    0.72569     -0.167892     -0.433416     0.36109     -0.17495    -0.0362614  -0.066284      0.856429     -0.280176     0.251293    -0.192626   -0.0219389    0.287899    0.735512    -0.443912    0.312073     0.138576 
 -0.443735    -0.421671    0.0969984  -0.0542384    0.0152657   0.398999     0.100404     0.11556       0.395577     0.34765     -0.467006     -0.526302     0.305144    -0.0541958  -0.311008   -0.793116      0.259636     -0.0811193   -0.0226041   -0.271209   -0.0147925   -0.321088    0.489638    -0.251165   -0.519727     0.180795 
  0.668384    -0.29069     0.185908    0.10972     -0.474763   -0.313884    -0.376433     0.191953      0.171082    -0.0874614   -0.217535     -0.0278368   -0.0145132   -0.682093    0.06437     0.230668      0.135407      0.148323    -0.272377     0.479209   -0.289652     0.142681    0.462603     0.730214   -0.00227538  -0.0143424
 -0.0438239   -0.0733611  -0.112853    0.0710097   -0.12136    -0.0343399   -0.27452      0.0430794     0.0654454    0.0418073   -0.160802      0.00460628  -0.192317    -0.0958825   0.0348236  -0.199668      0.112775      0.114675    -0.00595428   0.0761009  -0.24634     -0.08125     0.131512     0.205621   -0.383375    -0.240014 
  0.169905     0.265075   -0.447325   -0.731031     0.727387    0.0445673    0.241749    -0.109594     -0.195251     0.669208    -0.342063     -0.00404462   0.146863    -0.328802    0.383374   -0.0969822     0.0689313     0.298387     0.0906273   -0.322811    0.579086    -0.40809    -0.0387954   -0.1922     -0.0902097   -0.187414 
 -0.425214    -0.146703    0.153908    0.580872    -0.0260941   0.180235    -0.292936    -0.00741769   -0.153408     0.0761365   -0.0871023     0.027259     0.0906976    0.0305921   0.296742   -0.267808     -0.492925     -0.0934568    0.299208    -0.332577    0.0132152   -0.372801    0.0281109    0.203626   -0.183749    -0.360777 
 -0.285111     0.0359112   0.249995   -0.00959065   0.0394043   0.190225     0.286653     0.493911      0.167253     0.252577     0.581944      0.338565    -0.396317     0.0957459  -0.156343   -0.618719     -0.0661019    -0.265068     0.170654     0.503722   -0.254001    -0.363144   -0.68219     -0.583263   -0.314878     0.0117998
  0.617921    -0.780358   -0.338403   -0.210786    -0.135394   -0.53726     -0.224902    -0.0163407     1.28495      0.667706    -0.382657     -0.148843    -0.339254     0.480477   -0.172965    0.112054      0.0322113     0.46404      0.0482123    0.203647   -0.0325526    0.594547   -0.201415     0.158222   -0.722207     0.0116734
  0.114761    -0.117688    0.115109   -0.0435833    0.0809918   0.0923783   -0.0279746    0.119194      0.0037526   -0.0442526    0.152829     -0.158397     0.201274     0.0188319   0.052186    0.0998549     0.0050165     0.0174024   -0.260077     0.241636   -0.0773105    0.225569   -0.172994    -0.0936172   0.282508     0.300862 
 -0.107366    -0.0477829  -0.140119    0.20755     -0.342866   -0.485144    -0.622842    -0.276618     -0.673851    -0.292322    -0.0544941     0.234687    -0.264142     0.348318    0.421998    0.161209     -0.486035     -0.105652     0.368115    -0.163173   -0.0770285    0.0538864  -0.358228     0.160242    0.321893    -0.157246 
 -0.0402495    0.127128   -0.155279    0.006652    -0.0247432   0.013811     0.0735247    0.000298241   0.06719     -0.0166271   -0.0378705     0.03002     -0.022193     0.0711541  -0.115267   -0.0130748    -0.0906923    -0.0933266    0.123118    -0.17122     0.161256    -0.123288    0.0288515   -0.0850167  -0.116192    -0.140516 
 -0.0409425    0.162933   -0.0745522  -0.169041    -0.0345546  -0.313803    -0.0120753   -0.027183     -0.18139      0.169898    -0.500439      0.305582    -0.702027    -0.0130624  -0.206013    0.0909416     0.417316     -0.00534799  -0.0371359   -0.0375256  -0.376581     0.0539592   0.0394629    0.031971   -0.464287    -0.0307399
 -0.468745     0.262758   -0.25923     0.25106     -0.0036926   0.0760941    0.240603     0.100316     -0.371447    -0.297469    -0.272577      0.0755678   -0.461471     0.649048   -0.192513   -0.140422     -0.159523     -0.136602     0.276804    -1.18836     0.648848    -0.216863   -0.0607121   -0.293017   -0.22124     -0.263307 
 -0.493541     0.0438966  -0.514699   -0.68928     -0.109376    0.0944164   -0.0204214    0.00166284    0.0625351    0.710414     0.208257      0.103097    -0.148896     0.477074    0.262849   -0.308525     -0.0519017    -0.0648822   -0.111342     0.0524948  -0.53369     -0.46029     0.103734    -0.0935592  -1.27034     -0.495035 
 -0.137027     0.275922    0.383221    0.650653    -0.383177   -0.0358557   -0.125825    -0.236098      1.06401      0.370255     0.515932     -0.160142    -0.177084     0.522496   -0.417859   -0.0464769     0.0119576    -0.24458      0.559332     0.364071   -0.287791     0.24466     0.288605    -0.194647   -0.156844    -0.100435 
 -0.317416    -0.0254479  -0.919269   -0.101884     0.0762847  -0.118278    -0.220816     0.378134      0.360701    -0.0735852    0.0499689    -0.0787267    0.189644     0.116789   -0.2737     -0.0370073    -0.140492      0.489801     0.390849     0.0178209   0.26176      0.614592   -0.0305206    0.957238   -0.658173     0.026629 
 -0.674188     0.349824    0.198446    0.461364     0.357924   -0.0102624    0.37363      0.191391     -0.207493     0.853955     0.65929      -0.270345     0.582923     0.465217    0.0802888  -0.249858      0.0550306    -0.303428    -0.501029    -0.275713   -0.253935     0.0292347   0.00387315  -0.581831    0.0479313   -0.243352 
  0.321116     0.312872   -0.126076    0.735254     0.371453    0.0729278    0.339347     0.474118      0.301048    -0.796481     0.151761      0.495389    -0.0295557   -0.0845216   0.0559158   0.279186     -0.743167      0.426721    -0.218383     0.187064   -0.0085039   -0.138018   -0.321571     0.844853   -0.493986    -0.100868 
  0.487001     0.411964   -0.084814   -0.615329     0.487336   -0.685853    -0.679696    -0.311841     -0.63296     -0.144618    -0.000754556   0.212409    -0.228599    -0.168767    0.355283    0.379952      0.348303      0.231063    -0.614718     0.279447   -0.162212     0.305538   -0.20707      0.0332814   0.203405    -0.117917 
 -0.117336     0.490639    0.260975   -0.218391     0.380045   -0.213567     0.8595      -0.0238743    -0.320841    -0.00512282   0.264381      0.33146     -0.00176646   0.224666   -0.143683    0.955899      0.171316      0.170718    -0.0309063    0.370589    0.39043      0.0434574  -0.286619    -0.198149    0.532912     0.651484 
 -0.0334989   -0.229463   -0.384818   -0.1558      -0.0472275   0.370644    -0.142277    -0.475379     -0.00647262  -1.05595     -0.422557      0.225369    -0.465701    -0.320357   -0.343076    0.530118     -0.132114      0.357304     0.230209     0.128135   -0.204665     0.783024   -0.339099     0.946153    0.507956     0.560135 
  0.321837     0.385128    0.527363    0.982507     0.456661    0.34178     -0.314262    -0.716008     -0.468331    -0.431979     0.0355775     0.971428     0.106502     0.303125   -0.417359   -0.411202     -0.320194     -0.152585     0.673653    -0.0762381   1.1011       0.370829   -0.013792    -0.018325   -0.26385      0.476893 
  0.279847     0.915771   -0.243164   -0.307828    -0.98347    -0.344649    -0.11537     -0.185077     -0.279308     0.130652    -0.143287     -0.412377     0.138722     0.351238    0.49651    -0.376814      0.336161     -0.187993     0.811212     0.133537    0.199577    -0.0291818  -0.470411     0.139461    0.251554     0.588972 
  0.146743     0.0792853   0.908298    0.0407872   -0.181084    0.14767      0.0727218   -0.135716     -0.393145     0.0315739   -0.134464      0.153639    -0.317965    -0.257817    0.143506    0.000187617   0.077408     -0.677005    -0.414925    -0.206999   -0.00710457  -0.652219    0.0924984   -1.00932     0.63708     -0.128738 
  0.195846    -0.10174     0.598489    0.103036    -0.0245394  -0.107438     0.00674449   0.432506     -0.0379617   -0.023134    -0.198383      0.020456     0.127085    -0.19405     0.536121    0.166792      0.000204822   0.194853     0.323514     0.0481256   0.610603    -0.204117    0.201021     0.314928    0.545134     0.298012 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406309
[ Info: iteration 2, average log likelihood -1.406302
[ Info: iteration 3, average log likelihood -1.406295
[ Info: iteration 4, average log likelihood -1.406289
[ Info: iteration 5, average log likelihood -1.406282
[ Info: iteration 6, average log likelihood -1.406276
[ Info: iteration 7, average log likelihood -1.406270
[ Info: iteration 8, average log likelihood -1.406264
[ Info: iteration 9, average log likelihood -1.406258
[ Info: iteration 10, average log likelihood -1.406252
â”Œ Info: EM with 100000 data points 10 iterations avll -1.406252
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
