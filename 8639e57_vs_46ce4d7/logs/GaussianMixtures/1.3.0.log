Julia Version 1.3.0
Commit 46ce4d7933 (2019-11-26 06:09 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)

   Cloning default registries into `~/.julia`
   Cloning registry from "https://github.com/JuliaRegistries/General.git"
[?25l    Fetching: [>                                        ]  0.0 %    Fetching: [==============>                          ]  33.2 %    Fetching: [=================================>       ]  80.4 %[2K[?25h     Added registry `General` to `~/.julia/registries/General`
 Resolving package versions...
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.6
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.2
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.21.11
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+1
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed OrderedCollections â”€ v1.1.0
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed SpecialFunctions â”€â”€â”€ v0.9.0
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.0
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed Polynomials â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed OpenSpecFun_jll â”€â”€â”€â”€ v0.5.3+1
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [f27b6e38] + Polynomials v0.6.0
  [1fd47b50] + QuadGK v2.2.0
  [3cdcf5f2] + RecipesBase v0.7.0
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_qvwMfO/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [f27b6e38] Polynomials v0.6.0
  [1fd47b50] QuadGK v2.2.0
  [3cdcf5f2] RecipesBase v0.7.0
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -9.709288103118572e6, [522.53815019525, 99477.46184980476], [-109.63677495087914 -219.59389249313367 -1276.99894808236; 559.5201333427651 112.29970015435168 1138.1264182900775], Array{Float64,2}[[535.0600839654061 141.6890409024961 154.1432334525578; 141.6890409024961 576.5968582842638 493.16607663358093; 154.1432334525578 493.16607663358093 3152.3793584931045], [99935.26104898418 -387.1753334894849 -405.9517719565482; -387.1753334894849 100285.7268233864 -692.1844297713949; -405.9517719565482 -692.1844297713949 96042.02208794183]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.179511e+03
      1       9.110390e+02      -2.684715e+02 |        5
      2       8.093954e+02      -1.016436e+02 |        2
      3       8.065897e+02      -2.805673e+00 |        0
      4       8.065897e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 806.5897107667402)
â”Œ Info: K-means with 272 data points using 4 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.058432
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.765080
[ Info: iteration 2, lowerbound -3.622619
[ Info: iteration 3, lowerbound -3.477987
[ Info: iteration 4, lowerbound -3.330461
[ Info: iteration 5, lowerbound -3.204179
[ Info: iteration 6, lowerbound -3.121762
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.086530
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -3.071250
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -3.052053
[ Info: iteration 10, lowerbound -3.037556
[ Info: iteration 11, lowerbound -3.021793
[ Info: iteration 12, lowerbound -2.999417
[ Info: iteration 13, lowerbound -2.968421
[ Info: iteration 14, lowerbound -2.926589
[ Info: iteration 15, lowerbound -2.871640
[ Info: iteration 16, lowerbound -2.801719
[ Info: iteration 17, lowerbound -2.716956
[ Info: iteration 18, lowerbound -2.622586
[ Info: iteration 19, lowerbound -2.530897
[ Info: iteration 20, lowerbound -2.454787
[ Info: iteration 21, lowerbound -2.398687
[ Info: iteration 22, lowerbound -2.361992
[ Info: dropping number of Gaussions to 3
[ Info: iteration 23, lowerbound -2.331832
[ Info: iteration 24, lowerbound -2.311239
[ Info: iteration 25, lowerbound -2.307862
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.302917
[ Info: iteration 27, lowerbound -2.299260
[ Info: iteration 28, lowerbound -2.299256
[ Info: iteration 29, lowerbound -2.299254
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Dec  8 16:52:22 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Dec  8 16:52:29 2019: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Sun Dec  8 16:52:31 2019: EM with 272 data points 0 iterations avll -2.058432
5.8 data points per parameter
, Sun Dec  8 16:52:33 2019: GMM converted to Variational GMM
, Sun Dec  8 16:52:42 2019: iteration 1, lowerbound -3.765080
, Sun Dec  8 16:52:42 2019: iteration 2, lowerbound -3.622619
, Sun Dec  8 16:52:42 2019: iteration 3, lowerbound -3.477987
, Sun Dec  8 16:52:42 2019: iteration 4, lowerbound -3.330461
, Sun Dec  8 16:52:42 2019: iteration 5, lowerbound -3.204179
, Sun Dec  8 16:52:42 2019: iteration 6, lowerbound -3.121762
, Sun Dec  8 16:52:43 2019: dropping number of Gaussions to 7
, Sun Dec  8 16:52:43 2019: iteration 7, lowerbound -3.086530
, Sun Dec  8 16:52:43 2019: dropping number of Gaussions to 5
, Sun Dec  8 16:52:43 2019: iteration 8, lowerbound -3.071250
, Sun Dec  8 16:52:43 2019: dropping number of Gaussions to 4
, Sun Dec  8 16:52:43 2019: iteration 9, lowerbound -3.052053
, Sun Dec  8 16:52:43 2019: iteration 10, lowerbound -3.037556
, Sun Dec  8 16:52:43 2019: iteration 11, lowerbound -3.021793
, Sun Dec  8 16:52:43 2019: iteration 12, lowerbound -2.999417
, Sun Dec  8 16:52:43 2019: iteration 13, lowerbound -2.968421
, Sun Dec  8 16:52:43 2019: iteration 14, lowerbound -2.926589
, Sun Dec  8 16:52:43 2019: iteration 15, lowerbound -2.871640
, Sun Dec  8 16:52:43 2019: iteration 16, lowerbound -2.801719
, Sun Dec  8 16:52:43 2019: iteration 17, lowerbound -2.716956
, Sun Dec  8 16:52:43 2019: iteration 18, lowerbound -2.622586
, Sun Dec  8 16:52:43 2019: iteration 19, lowerbound -2.530897
, Sun Dec  8 16:52:43 2019: iteration 20, lowerbound -2.454787
, Sun Dec  8 16:52:43 2019: iteration 21, lowerbound -2.398687
, Sun Dec  8 16:52:43 2019: iteration 22, lowerbound -2.361992
, Sun Dec  8 16:52:43 2019: dropping number of Gaussions to 3
, Sun Dec  8 16:52:43 2019: iteration 23, lowerbound -2.331832
, Sun Dec  8 16:52:43 2019: iteration 24, lowerbound -2.311239
, Sun Dec  8 16:52:43 2019: iteration 25, lowerbound -2.307862
, Sun Dec  8 16:52:43 2019: dropping number of Gaussions to 2
, Sun Dec  8 16:52:43 2019: iteration 26, lowerbound -2.302917
, Sun Dec  8 16:52:43 2019: iteration 27, lowerbound -2.299260
, Sun Dec  8 16:52:43 2019: iteration 28, lowerbound -2.299256
, Sun Dec  8 16:52:43 2019: iteration 29, lowerbound -2.299254
, Sun Dec  8 16:52:43 2019: iteration 30, lowerbound -2.299254
, Sun Dec  8 16:52:43 2019: iteration 31, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 32, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 33, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 34, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 35, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 36, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 37, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 38, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 39, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 40, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 41, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 42, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 43, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 44, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 45, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 46, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 47, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 48, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 49, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: iteration 50, lowerbound -2.299253
, Sun Dec  8 16:52:43 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509222607942, 95.95490777392074]
Î² = [178.04509222607942, 95.95490777392074]
m = [4.250300733269378 79.28686694435399; 2.0002292577748197 53.85198717245841]
Î½ = [180.04509222607942, 97.95490777392074]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547478085 -0.007644049042334796; 0.0 0.008581705166323545], [0.3758763611957523 -0.008953123827357011; 0.0 0.012748664777411895]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -0.9983958547502162
avll from llpg:  -0.9983958547502154
avll direct:     -0.9983958547502154
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9815602707245971
avll from llpg:  -0.9815602707245971
avll direct:     -0.9815602707245971
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
  0.0262934  -0.146359     -0.0435679    0.0687471    0.0631487    0.000290796  -0.199195     0.148335      0.0772109    0.0540043   -0.0601167     0.0331807     0.180752      0.0486689   0.0353511    0.0233984    -0.081409     0.0285306   0.081954     0.127386     -0.0107559    0.0876786    0.00379077  -0.0559987    0.00878766   0.0751324 
  0.0783092  -0.113779      0.13396     -0.0977167    0.176691     0.112723     -0.0170973   -0.146708     -0.159583    -0.183409     0.154889     -0.0922695    -0.0971603     0.205033    0.0515206    0.0324445     0.0651947   -0.0058694   0.0858052   -0.108053      4.78734e-5   0.0509021    0.137507     0.104382     0.134515    -0.0155424 
 -0.0808125  -0.0390254    -0.0572475    0.177361    -0.207226     0.13299       0.130199    -0.00862343    0.115232    -0.0823611    0.0639197    -0.1338       -0.000361107   0.0999974  -0.0777205   -0.0185486     0.017535     0.120402    0.153205    -0.161642      0.104488    -0.0164643   -0.14175      0.0157016   -0.0302203    0.0435469 
 -0.11532    -0.000246901   0.00988096  -0.155281    -0.128814     0.0481858    -0.0386481   -0.0496712     0.123455     0.0582857   -0.0587442    -0.0422426    -0.204053     -0.114748   -0.0543554    0.000425325   0.124328     0.0065293   0.214691     0.13919      -0.126432    -0.111481    -0.0396783    0.0576092    0.118515    -0.138714  
  0.150979   -0.122937     -0.108996    -0.150237     0.100918     0.109068     -0.079489    -0.061768     -0.070672    -0.107239    -0.0708519    -0.0493178    -0.0865901     0.0608739  -0.0321916   -0.13827      -0.123045     0.0141595   0.108568    -0.0856554     0.122029     0.0878426    0.140518    -0.066704    -0.052863    -0.0262106 
  0.157326    0.19769      -0.113366     0.0543552   -0.0774029    0.0378597    -0.0346726    0.0956781     0.0115594    0.03846      0.0664044    -0.0465731     0.0097807     0.0511361  -0.0161555   -0.00737118   -0.0196386   -0.0827037  -0.0327843   -0.0681444     0.0879848    0.0980438   -0.151175    -0.0659361    0.177489     0.00731547
 -0.0611423  -0.10611      -0.0336461    0.139279    -0.0976582    0.035653      0.027025     0.196823     -0.00917972   0.0664673   -0.135881     -0.12389       0.00494112   -0.0708014   0.0933138   -0.100359     -0.350071     0.0335882  -0.0647966   -0.138829      0.0551836   -0.135095     0.0457895    0.227895     0.0812431   -0.104569  
 -0.0812403  -0.0262787    -0.129216     0.0559473   -0.0452408   -0.117968      0.0961344    0.153265     -0.0419158   -0.00484866   0.082377     -0.0537124    -0.00697238   -0.123304    0.0303398    0.0726171    -0.0390916   -0.0181763  -0.013274     0.0688965    -0.011328    -0.0300751   -0.139858     0.127714    -0.0733359   -0.0566089 
  0.131603    0.0246823    -0.0734668   -0.0414852    0.0584777    0.0669601     0.189575    -0.188039      0.148915    -0.145133    -0.0571218     0.167993      0.0788808     0.158864    0.0717743    0.0494799     0.143939    -0.189187    0.241628    -0.0898955     0.0463268    0.0130927   -0.00062024  -0.150056    -0.125682     0.00917608
  0.0435359   0.0560103    -0.117766     0.117819     0.0193394    0.103604      0.0189518   -0.056549      0.0294412    0.042723    -0.0828334     0.116056     -0.0558754     0.17541     0.00687102  -0.00535618    0.00449688  -0.0101648   0.052543     0.113825      0.0877039   -0.0163836    0.039423    -0.0129416   -0.131104    -0.138715  
  0.136388   -0.0435374     0.00981086   0.0370195   -0.0700638    0.0527165     0.0488211   -0.0852774    -0.0862935   -0.0218874    0.159001     -0.0684489     0.0695145    -0.0715367   0.129562     0.0355997    -0.0452629   -0.196939   -0.0582025    0.130246      0.104778     0.049318     0.0691306   -0.0872973   -0.0937668    0.0325475 
  0.0845351  -0.189006     -0.0170336   -0.0140871    0.175934    -0.0868798    -0.0556879    0.226286      0.0275863    0.202073    -0.142106     -0.0523476     0.178058      0.0562125  -0.127225     0.00425574   -0.055923     0.0549536   0.0146617   -0.0756648     0.044702     0.0328839    0.0261729   -0.108022     0.0599248    0.133323  
 -0.266442    0.174647     -0.150537    -0.00348325   0.188289     0.0713483    -0.266665    -0.128203     -0.106235    -0.206265     0.000408167  -0.0944158    -0.0364442     0.0638068   0.122164    -0.00833789    0.0606488    0.0360403  -0.120501    -0.059024     -0.0920374   -0.330443    -0.0408302    0.0138309    0.126082     0.114787  
 -0.109088   -0.0613043    -0.0721015    0.0739408   -0.0598053    0.0724235    -0.0381936   -0.0455578     0.0664266   -0.146883    -0.0818254     0.0487671     0.118829      0.0273105   0.115161     0.112004     -0.0192777   -0.127877    0.186009     0.16437      -0.080158     0.110256     0.0265346    0.184935     0.0774505   -0.0298661 
 -0.0411913  -0.0368594     0.0900354    0.212783    -0.109234     0.16399       0.185517    -0.0812267     0.0659301    0.071006    -0.148403      0.055415      0.0310745     0.113878    0.0716062    0.0611255    -0.158652     0.1074     -0.0037508    0.248154     -0.0416992   -0.0020481    0.0686398   -0.00512687  -0.150837     0.0103984 
 -0.140779    0.137505     -0.143694     0.0525284   -0.150177    -0.0574062    -0.145718     0.0831094    -0.0285335   -0.0287596   -0.0069814    -0.130987      0.0110638     0.0117204   0.241606     0.0975715    -0.0682161    0.157415   -0.0980897   -0.00258709    0.00630644   0.0359204    0.128083    -0.0141105   -0.0116532    0.0524136 
 -0.0629846  -0.0740834     0.0758819   -0.0158112    0.0234553    0.0325662    -0.118108    -0.120769      0.106703    -0.0385188   -0.116589      0.061236      0.0334917    -0.0379516   0.110111     0.0401984     0.0123467   -0.0804825   0.207117    -0.0288746    -0.108516     0.0840499    0.210048    -0.016691    -0.016762     0.147333  
  0.0204294   0.0437276     0.0772524    0.0281957    0.0719614   -0.0452973     0.184268     0.110399     -0.118949     0.114764    -0.00925033    0.00823276    0.0106139    -0.124287   -0.0488807   -0.019344      0.133684     0.124569   -0.0718024    0.0470052    -0.0825672    0.0388714    0.00302946   0.0972584   -0.135413    -0.0847993 
  0.147973    0.0733637    -0.0173831    0.0033179    0.0634018   -0.140572      0.0175413    0.08337       0.0391475   -0.170526     0.112915      0.0153045    -0.249648     -0.146559    0.134165     0.0534637    -0.05205      0.0436031  -0.0627819    0.0258024     0.032622     0.073655    -0.12238      0.114063     0.148842     0.153345  
  0.0242886  -0.167889     -0.0309066   -0.0663971    0.0804319   -0.0346122    -0.105422     0.0559416    -0.0186756    0.0307104   -0.0626953    -0.152768      0.111093     -0.226243    0.129409     0.0131787    -0.0324603    0.10888    -0.0378664    0.0298565    -0.169329     0.0645174    0.129206    -0.127892     0.127621     0.117925  
 -0.0591697  -0.088627      0.159196     0.163023     0.195312    -0.0708347    -0.0841298   -0.0122136    -0.115846    -0.00211319  -0.11163      -0.000397291   0.0658357     0.18209    -0.117931     0.0118299     0.122053     0.136708   -0.0416466   -0.0632911    -0.0436683    0.167787     0.0474827    0.0362684    0.0701611    0.0414471 
  0.120731   -0.00591948    0.0331127    0.0812872    0.163647    -0.00332706    0.00124949  -0.173789     -0.216482    -0.11392      0.0285899    -0.0435358     0.0023687    -0.160987   -0.0216056   -0.0225577    -0.30673      0.159125    0.075085     0.135317     -0.0133191    0.147787    -0.223183    -0.017787     0.115683     0.00210086
  0.0748682   0.000609129  -0.00631929  -0.0169752   -0.0861542    0.222752     -0.0547064    0.0061804     0.0942633    0.0372016   -0.0323704    -0.0150817     0.0342526     0.114408   -0.0451648   -0.0479755     0.0273557   -0.105463   -0.00345148   0.197999     -0.051416    -0.0557384   -0.043481     0.316443     0.0907959   -0.0625314 
  0.141251    0.0250624     0.022841     0.262358     0.19853     -0.0739592     0.113167     0.0404863    -0.0866456   -0.0307666   -0.260978     -0.0335183    -0.049784     -0.0857984   0.0840919   -0.144904      0.16509      0.014606    0.0429092   -0.104796     -0.110301     0.0612269   -0.0793779    0.0457364    0.0168954   -4.40342e-5
  0.0448278   0.0900334    -0.0685806   -0.00712527   0.279531    -0.0631854    -0.0319565   -0.113148      0.0254797   -0.177145     0.0360753     0.150097     -0.000930133   0.0397045  -0.0298409    0.0478977     0.00323327  -0.194975   -0.263921    -0.000149641   0.0427766    0.0477736    0.0730069    0.00312369   0.121882     0.0745023 
  0.246324   -0.114548     -0.0626959   -0.0241283   -0.0801643    0.00162768    0.0591045   -0.000797688   0.111475     0.0345871   -0.124514     -0.0858878     0.0729318     0.123271    0.0282877    0.0424169     0.00293369   0.130695    0.0859175   -0.0719799     0.161757     0.0570268    0.0290703    0.118303    -0.00783623   0.113864  
  0.188095   -0.085393     -0.139236     0.0769156   -0.00983961  -0.000812249  -0.240134     0.174624     -0.20479      0.0407956   -0.0108761    -0.136883      0.0874625     0.161344    0.116258     0.0318734     0.0344955    0.0502371  -0.0844272    0.0253738     0.101704    -0.00385058   0.0361017   -0.0409959   -0.0761992   -0.229949  
  0.0909452  -0.0569284    -0.106295    -0.0654789   -0.0122303   -0.0271865     0.0952682    0.0264186    -0.00357031  -0.129556    -0.0640698    -0.175006     -0.0592023     0.206559   -0.0502797   -0.0530037     0.0710856    0.119782    0.0419814   -0.0650317    -0.0769878    0.0370855    0.0497833    0.162724     0.00157053  -0.0704364 
  0.0945463  -0.103877      0.123407    -0.10765      0.0648347   -0.128657     -0.0182648   -0.00847282    0.135392     0.0360689    0.0345785     0.038062     -0.0346157     0.0348813  -0.150165     0.0624043     0.0316501    0.127295   -0.110436    -0.062309     -0.0584163    0.0255071   -0.0207808   -0.259339     0.112013     0.0435747 
  0.0964342   0.0981946    -0.0745228    0.0933508    0.112062     0.105199      0.115537    -0.0173363    -0.221979    -0.0285835    0.137258     -0.12645       0.171526      0.0467962   0.223319     0.0919905    -0.0688168   -0.128283    0.042919    -0.0980877     0.11327     -0.175036     0.10267      0.0311655    0.0711477    0.0963486 
  0.0547868   0.0443169    -0.0511017    0.00571537  -0.119337    -0.0246902    -0.136078    -0.0159622     0.0350292   -0.175815    -0.109093     -0.0501841    -0.199955      0.114053   -0.118701    -0.121425      0.221499     0.0441746   0.0930858    0.0360597     0.0750435    0.0943701    0.0222624   -0.0620383    0.0262303   -0.107368  
 -0.0736248   0.152729     -0.00882069  -0.0768023    0.00985301   0.0775024     0.0096111    0.0360941     0.0331002    0.0798323   -0.293781     -0.00902338   -0.0365124     0.280018   -0.0624852   -0.241646      0.0682495   -0.0174324   0.0370868   -0.135098      0.0676292   -0.123571     0.102522    -0.0688435   -0.10473     -0.198046  kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4189623749817528
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419043
[ Info: iteration 2, average log likelihood -1.418920
[ Info: iteration 3, average log likelihood -1.417427
[ Info: iteration 4, average log likelihood -1.405744
[ Info: iteration 5, average log likelihood -1.391130
[ Info: iteration 6, average log likelihood -1.388300
[ Info: iteration 7, average log likelihood -1.387596
[ Info: iteration 8, average log likelihood -1.386956
[ Info: iteration 9, average log likelihood -1.386281
[ Info: iteration 10, average log likelihood -1.385614
[ Info: iteration 11, average log likelihood -1.385014
[ Info: iteration 12, average log likelihood -1.384510
[ Info: iteration 13, average log likelihood -1.384126
[ Info: iteration 14, average log likelihood -1.383864
[ Info: iteration 15, average log likelihood -1.383700
[ Info: iteration 16, average log likelihood -1.383610
[ Info: iteration 17, average log likelihood -1.383563
[ Info: iteration 18, average log likelihood -1.383537
[ Info: iteration 19, average log likelihood -1.383520
[ Info: iteration 20, average log likelihood -1.383506
[ Info: iteration 21, average log likelihood -1.383494
[ Info: iteration 22, average log likelihood -1.383483
[ Info: iteration 23, average log likelihood -1.383471
[ Info: iteration 24, average log likelihood -1.383458
[ Info: iteration 25, average log likelihood -1.383438
[ Info: iteration 26, average log likelihood -1.383398
[ Info: iteration 27, average log likelihood -1.383306
[ Info: iteration 28, average log likelihood -1.383141
[ Info: iteration 29, average log likelihood -1.382934
[ Info: iteration 30, average log likelihood -1.382750
[ Info: iteration 31, average log likelihood -1.382605
[ Info: iteration 32, average log likelihood -1.382504
[ Info: iteration 33, average log likelihood -1.382425
[ Info: iteration 34, average log likelihood -1.382365
[ Info: iteration 35, average log likelihood -1.382321
[ Info: iteration 36, average log likelihood -1.382291
[ Info: iteration 37, average log likelihood -1.382271
[ Info: iteration 38, average log likelihood -1.382257
[ Info: iteration 39, average log likelihood -1.382245
[ Info: iteration 40, average log likelihood -1.382236
[ Info: iteration 41, average log likelihood -1.382230
[ Info: iteration 42, average log likelihood -1.382224
[ Info: iteration 43, average log likelihood -1.382220
[ Info: iteration 44, average log likelihood -1.382217
[ Info: iteration 45, average log likelihood -1.382215
[ Info: iteration 46, average log likelihood -1.382213
[ Info: iteration 47, average log likelihood -1.382212
[ Info: iteration 48, average log likelihood -1.382211
[ Info: iteration 49, average log likelihood -1.382210
[ Info: iteration 50, average log likelihood -1.382210
â”Œ Info: EM with 100000 data points 50 iterations avll -1.382210
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4190434914134613
â”‚     -1.4189199200545435
â”‚      â‹®                 
â””     -1.3822099322373753
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.382323
[ Info: iteration 2, average log likelihood -1.382200
[ Info: iteration 3, average log likelihood -1.381498
[ Info: iteration 4, average log likelihood -1.374670
[ Info: iteration 5, average log likelihood -1.357412
[ Info: iteration 6, average log likelihood -1.348349
[ Info: iteration 7, average log likelihood -1.346029
[ Info: iteration 8, average log likelihood -1.344994
[ Info: iteration 9, average log likelihood -1.344302
[ Info: iteration 10, average log likelihood -1.343749
[ Info: iteration 11, average log likelihood -1.343294
[ Info: iteration 12, average log likelihood -1.342927
[ Info: iteration 13, average log likelihood -1.342647
[ Info: iteration 14, average log likelihood -1.342440
[ Info: iteration 15, average log likelihood -1.342287
[ Info: iteration 16, average log likelihood -1.342179
[ Info: iteration 17, average log likelihood -1.342103
[ Info: iteration 18, average log likelihood -1.342050
[ Info: iteration 19, average log likelihood -1.342013
[ Info: iteration 20, average log likelihood -1.341986
[ Info: iteration 21, average log likelihood -1.341966
[ Info: iteration 22, average log likelihood -1.341952
[ Info: iteration 23, average log likelihood -1.341941
[ Info: iteration 24, average log likelihood -1.341933
[ Info: iteration 25, average log likelihood -1.341926
[ Info: iteration 26, average log likelihood -1.341921
[ Info: iteration 27, average log likelihood -1.341917
[ Info: iteration 28, average log likelihood -1.341914
[ Info: iteration 29, average log likelihood -1.341911
[ Info: iteration 30, average log likelihood -1.341908
[ Info: iteration 31, average log likelihood -1.341906
[ Info: iteration 32, average log likelihood -1.341904
[ Info: iteration 33, average log likelihood -1.341903
[ Info: iteration 34, average log likelihood -1.341901
[ Info: iteration 35, average log likelihood -1.341900
[ Info: iteration 36, average log likelihood -1.341899
[ Info: iteration 37, average log likelihood -1.341898
[ Info: iteration 38, average log likelihood -1.341897
[ Info: iteration 39, average log likelihood -1.341896
[ Info: iteration 40, average log likelihood -1.341895
[ Info: iteration 41, average log likelihood -1.341895
[ Info: iteration 42, average log likelihood -1.341894
[ Info: iteration 43, average log likelihood -1.341893
[ Info: iteration 44, average log likelihood -1.341893
[ Info: iteration 45, average log likelihood -1.341892
[ Info: iteration 46, average log likelihood -1.341892
[ Info: iteration 47, average log likelihood -1.341892
[ Info: iteration 48, average log likelihood -1.341891
[ Info: iteration 49, average log likelihood -1.341891
[ Info: iteration 50, average log likelihood -1.341891
â”Œ Info: EM with 100000 data points 50 iterations avll -1.341891
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3823234503436632
â”‚     -1.3821999650739218
â”‚      â‹®                 
â””     -1.341890612824784 
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.342051
[ Info: iteration 2, average log likelihood -1.341880
[ Info: iteration 3, average log likelihood -1.341381
[ Info: iteration 4, average log likelihood -1.336795
[ Info: iteration 5, average log likelihood -1.320426
[ Info: iteration 6, average log likelihood -1.306205
[ Info: iteration 7, average log likelihood -1.300573
[ Info: iteration 8, average log likelihood -1.297972
[ Info: iteration 9, average log likelihood -1.296419
[ Info: iteration 10, average log likelihood -1.295052
[ Info: iteration 11, average log likelihood -1.293783
[ Info: iteration 12, average log likelihood -1.292706
[ Info: iteration 13, average log likelihood -1.291734
[ Info: iteration 14, average log likelihood -1.290936
[ Info: iteration 15, average log likelihood -1.290455
[ Info: iteration 16, average log likelihood -1.290176
[ Info: iteration 17, average log likelihood -1.290003
[ Info: iteration 18, average log likelihood -1.289881
[ Info: iteration 19, average log likelihood -1.289779
[ Info: iteration 20, average log likelihood -1.289682
[ Info: iteration 21, average log likelihood -1.289579
[ Info: iteration 22, average log likelihood -1.289458
[ Info: iteration 23, average log likelihood -1.289294
[ Info: iteration 24, average log likelihood -1.289038
[ Info: iteration 25, average log likelihood -1.288591
[ Info: iteration 26, average log likelihood -1.287757
[ Info: iteration 27, average log likelihood -1.286472
[ Info: iteration 28, average log likelihood -1.285141
[ Info: iteration 29, average log likelihood -1.284282
[ Info: iteration 30, average log likelihood -1.284031
[ Info: iteration 31, average log likelihood -1.284010
[ Info: iteration 32, average log likelihood -1.283999
[ Info: iteration 33, average log likelihood -1.283990
[ Info: iteration 34, average log likelihood -1.283981
[ Info: iteration 35, average log likelihood -1.283972
[ Info: iteration 36, average log likelihood -1.283963
[ Info: iteration 37, average log likelihood -1.283955
[ Info: iteration 38, average log likelihood -1.283947
[ Info: iteration 39, average log likelihood -1.283939
[ Info: iteration 40, average log likelihood -1.283931
[ Info: iteration 41, average log likelihood -1.283923
[ Info: iteration 42, average log likelihood -1.283915
[ Info: iteration 43, average log likelihood -1.283907
[ Info: iteration 44, average log likelihood -1.283899
[ Info: iteration 45, average log likelihood -1.283890
[ Info: iteration 46, average log likelihood -1.283881
[ Info: iteration 47, average log likelihood -1.283870
[ Info: iteration 48, average log likelihood -1.283858
[ Info: iteration 49, average log likelihood -1.283843
[ Info: iteration 50, average log likelihood -1.283827
â”Œ Info: EM with 100000 data points 50 iterations avll -1.283827
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3420510028418644
â”‚     -1.3418803768180543
â”‚      â‹®                 
â””     -1.2838266796940383
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.284041
[ Info: iteration 2, average log likelihood -1.283782
[ Info: iteration 3, average log likelihood -1.283173
[ Info: iteration 4, average log likelihood -1.277770
[ Info: iteration 5, average log likelihood -1.262967
[ Info: iteration 6, average log likelihood -1.245645
[ Info: iteration 7, average log likelihood -1.233156
[ Info: iteration 8, average log likelihood -1.225293
[ Info: iteration 9, average log likelihood -1.218511
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.211405
[ Info: iteration 11, average log likelihood -1.223749
[ Info: iteration 12, average log likelihood -1.218415
[ Info: iteration 13, average log likelihood -1.215031
[ Info: iteration 14, average log likelihood -1.211812
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.207785
[ Info: iteration 16, average log likelihood -1.221482
[ Info: iteration 17, average log likelihood -1.216489
[ Info: iteration 18, average log likelihood -1.213293
[ Info: iteration 19, average log likelihood -1.210175
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.206226
[ Info: iteration 21, average log likelihood -1.219622
[ Info: iteration 22, average log likelihood -1.214525
[ Info: iteration 23, average log likelihood -1.211238
[ Info: iteration 24, average log likelihood -1.207847
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.203511
[ Info: iteration 26, average log likelihood -1.217428
[ Info: iteration 27, average log likelihood -1.212622
[ Info: iteration 28, average log likelihood -1.209571
[ Info: iteration 29, average log likelihood -1.206387
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.202266
[ Info: iteration 31, average log likelihood -1.216880
[ Info: iteration 32, average log likelihood -1.212224
[ Info: iteration 33, average log likelihood -1.209308
[ Info: iteration 34, average log likelihood -1.206250
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.202231
[ Info: iteration 36, average log likelihood -1.216828
[ Info: iteration 37, average log likelihood -1.212177
[ Info: iteration 38, average log likelihood -1.209289
[ Info: iteration 39, average log likelihood -1.206262
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.202280
[ Info: iteration 41, average log likelihood -1.216812
[ Info: iteration 42, average log likelihood -1.212161
[ Info: iteration 43, average log likelihood -1.209284
[ Info: iteration 44, average log likelihood -1.206268
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.202300
[ Info: iteration 46, average log likelihood -1.216806
[ Info: iteration 47, average log likelihood -1.212154
[ Info: iteration 48, average log likelihood -1.209280
[ Info: iteration 49, average log likelihood -1.206268
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.202304
â”Œ Info: EM with 100000 data points 50 iterations avll -1.202304
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.284041173058369 
â”‚     -1.2837823225421758
â”‚      â‹®                 
â””     -1.2023041046994032
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.217052
[ Info: iteration 2, average log likelihood -1.212058
[ Info: iteration 3, average log likelihood -1.207885
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.191684
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.159620
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     18
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.147530
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     22
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.138724
[ Info: iteration 8, average log likelihood -1.154595
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     18
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.118502
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.142204
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.152962
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     18
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.128266
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     21
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.123173
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     22
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.145049
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     18
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.118691
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     21
â”‚     22
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.106266
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.150891
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.129647
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     22
â”‚     23
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.108612
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     21
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.133442
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     18
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.129777
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.117052
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.122684
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.138025
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.120633
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     15
â”‚     22
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.126382
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     18
â”‚     21
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.123542
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.122462
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.135485
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     18
â”‚     21
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.120880
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     23
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.118725
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.138336
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     18
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.107245
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     21
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.118768
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     14
â”‚     22
â”‚     23
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.131474
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     15
â”‚     18
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.118060
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.115131
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.138357
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     18
â”‚     23
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.110785
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.120191
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     21
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.134694
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     15
â”‚     18
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.111617
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     23
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.118142
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     14
â”‚     21
â”‚     22
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.132282
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     15
â”‚     18
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.119114
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.121574
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     22
â”‚     23
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.126095
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     18
â”‚     21
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.115955
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.122068
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.134097
â”Œ Info: EM with 100000 data points 50 iterations avll -1.134097
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2170518232649343
â”‚     -1.2120575261029665
â”‚      â‹®                 
â””     -1.1340965587351703
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4189623749817528
â”‚     -1.4190434914134613
â”‚     -1.4189199200545435
â”‚     -1.417426695369477 
â”‚      â‹®                 
â”‚     -1.1159552399116393
â”‚     -1.1220676289677585
â””     -1.1340965587351703
32Ã—26 Array{Float64,2}:
  0.0187008    0.0417626    0.0796828     0.0497416    0.0834822    -0.0771208   0.175153     0.109155    -0.11267      0.0940605  -0.0205652  -0.00618893  -0.00796956  -0.125461    -0.0486495   -0.0369462    0.159811      0.109901    -0.0964614    0.0422816    -0.0918275    0.0382949   -0.000854941   0.0914021   -0.148484    -0.0814586 
  0.09798     -0.10469      0.0646854    -0.109896     0.0666456    -0.131662   -0.0356739   -0.00856739   0.12351      0.0374746   0.0124329   0.041634    -0.0332149    0.0367763   -0.177174     0.0556677    0.000595307   0.161226    -0.0662715   -0.0821388    -0.0682702   -0.0042797   -0.0183947    -0.276373     0.113129     0.0350321 
 -0.0884494   -0.0386221   -0.053807      0.180194    -0.188198      0.121364    0.131527     0.0042468    0.120455    -0.0531441   0.0265723  -0.120099    -0.00565668   0.0582785   -0.0871087   -0.0181702    0.017837      0.110714     0.140704    -0.15705       0.147795    -0.0640157   -0.110843      0.0112744   -0.0152791    0.0494462 
  0.0563572    0.0402459   -0.0558787    -0.0176891   -0.127974     -0.0114758  -0.149996    -0.00466304   0.0349096   -0.167097   -0.107627   -0.0892426   -0.200154     0.113065    -0.077683    -0.120803     0.236864      0.0404248    0.0930638    0.0370205     0.0778539    0.101678     0.0153138    -0.0578471    0.00629436  -0.0657287 
 -0.0850792    0.151754     0.000409063  -0.0741777    0.0257005     0.0903842  -0.0100134    0.0360913    0.0323099    0.0850634  -0.300168   -0.0208812   -0.0406767    0.268357    -0.0806191   -0.239185     0.0661442    -0.0342075    0.0111238   -0.124924      0.02158     -0.127824     0.107534     -0.0787276   -0.10365     -0.162358  
  0.00314144   0.0156572    0.00345673   -0.00533563   0.141793     -0.0182648  -0.0893811   -0.116123     0.0741054   -0.113311   -0.0479846   0.108973    -0.00160471   5.48866e-5   0.0741681    0.0379387    0.00367522   -0.12137     -0.0211421    0.00341309   -0.0408792    0.037202     0.137169     -0.00400919   0.0690557    0.085966  
 -0.200406     0.084538    -0.0691644    -0.0827025    0.0474194     0.058944   -0.161157    -0.0665044    0.0212124   -0.0832497  -0.0290633  -0.0800316   -0.121337    -0.0098374    0.0319793    0.0157201    0.103195      0.0162844    0.0456067    0.0130902    -0.0876031   -0.214183    -0.0329325     0.0453967    0.124344    -0.0238133 
  0.099111    -0.00372169   0.0351171     0.0946225    0.159597     -0.0032668  -0.00826558  -0.141176    -0.197602    -0.118434    0.0055158  -0.0206147    0.00979696  -0.147012    -0.0712913   -0.0249548   -0.259295      0.145322     0.0730909    0.110438     -0.0149989    0.13419     -0.23624      -0.0152566    0.119317     0.00664083
  0.167752    -0.115592    -0.11595      -0.17224      0.077559      0.0952926  -0.0753135   -0.0618276   -0.0653081   -0.10435    -0.070146   -0.0618803   -0.0882292    0.0622628   -0.0301226   -0.134045    -0.0958658     0.00426711   0.118072    -0.095996      0.110974     0.0758117    0.165362     -0.0312484   -0.0477101   -0.0336229 
  0.135033     0.0306777   -0.0714748    -0.0226887    0.0381304     0.0525408   0.187373    -0.190513     0.124041    -0.147558   -0.0189639   0.159367     0.0581564    0.145058     0.0749762    0.0893191    0.120276     -0.200648     0.239358    -0.0537069     0.04745      0.00110693   0.0154798    -0.142228    -0.122469     0.00812296
  0.262324    -0.221778    -0.0349296    -0.0897471   -0.0802941     0.0386809   0.138432     0.0241083    0.0979394    0.0413851  -0.144761   -0.101222     0.165968    -0.780624    -0.0632987    0.0420789    0.03397       0.23936      0.0913771    0.019326      0.235274     0.0324009    0.0105325     0.115771    -0.00428236   0.137197  
  0.308688    -0.00467156  -0.0459045    -0.0149899   -0.0629995    -0.022204   -0.0311368   -0.0192209    0.112324     0.0430856  -0.104851   -0.0741143    0.0151225    1.11382      0.142919     0.0495979    0.00693358    0.189764     0.0783695   -0.171124      0.0632746    0.0748491    0.0114354     0.137327    -0.00432782   0.107232  
 -0.148837    -0.0601111   -0.0882993     0.111106     0.109301      0.0938466  -0.0720471   -0.0703223    0.0376554   -0.0279966  -0.0768637  -1.49482      0.00381945  -0.0387291    0.11558      0.0582428   -0.0161858    -0.0228395    0.18451      0.125626     -0.0113783    0.237258    -0.00731872    0.302876     0.0759986    0.0623417 
 -0.227072    -0.0486561   -0.0648201     0.101076    -0.121166     -0.117547   -0.43848     -0.115622     0.0976982   -0.0735348  -0.0320095  -0.0156128    0.153109     0.172828     0.114812     0.167043    -0.0416629    -0.112977     0.143719     0.224743     -0.0225883    0.0139375    0.0272837     0.178511     0.0736647   -0.0193695 
 -0.0750805   -0.0766312   -0.0784528     0.0336861   -0.178433      0.179912    0.313664     0.0352497    0.158167    -0.279366   -0.116861   -0.442357     0.17302      0.0297474    0.112073     0.181623    -0.00470315   -0.232903     0.287821     0.144571     -0.256476     0.124107     0.0957541    -0.0207194    0.0829904   -0.0183709 
  0.120794    -0.0614217   -0.0516363     0.0577433    0.00783164    0.18957    -0.102982    -0.00651343  -0.248898    -0.188401   -0.0807825   2.15975      0.174583    -0.103048     0.115084     0.0104534   -0.00201733   -0.108736     0.174733     0.11505      -0.0589482    0.039167    -0.00666341    0.289542     0.0791488   -0.0201271 
 -0.194064     0.144286    -0.141416      0.0569165   -0.189667     -0.0669503  -0.147889     0.0755598   -0.0780523   -0.0179964  -0.0142317  -0.135631     0.0119283    0.0192198    0.262945     0.108111    -0.05462       0.154206    -0.118361    -0.000609455   0.00271606   0.0423611    0.11529      -0.0211732   -0.0170316    0.055705  
  0.143028     0.0748784   -0.0230639     0.0116763    0.0718776    -0.101618    0.0269326    0.0772612    0.0139962   -0.175174    0.106804    0.016281    -0.234272    -0.143018     0.134432     0.054528    -0.0452731     0.042523    -0.0748174    0.0160801     0.0270944    0.0678394   -0.106248      0.104359     0.144736     0.158521  
 -0.0125235   -0.0328647   -0.00777582    0.182764    -0.000289971   0.0857959   0.11686      0.029958    -0.0391168    0.0265705  -0.0954148  -0.0515943    0.0363641    0.0116351    0.115947    -0.0379622   -0.166375      0.0253294   -0.00375594  -0.0275415     0.0186713   -0.0770401    0.0359166     0.0942645    0.016535    -0.0148334 
  0.0744957   -0.011521    -0.135963      0.0694405   -0.00439869   -0.0260718  -0.072356     0.122531    -0.148603     0.034202    0.0179115  -0.0948378    0.0550274    0.0320629    0.0865185    0.0584116    0.00751522   -0.00208802  -0.0433335    0.0547889     0.0339329   -0.0374348   -0.0386798     0.0558658   -0.0770122   -0.122358  
 -0.0558826    0.00118757  -0.0082399    -0.027972    -0.0879317     0.242932   -0.0542093    0.00573363   0.0935976    0.082616   -0.0378769  -0.0121089    0.034368     0.110121    -0.0393029   -0.0455442    0.0328405    -0.0799136   -0.00447175   0.194452     -0.046358    -0.0528007   -0.0433513     0.32211      0.0879548   -0.0506634 
  0.109391    -0.0617539   -0.129461     -0.0721498   -0.0207913    -0.0324625   0.0942755    0.0259101   -0.0048542   -0.155643   -0.0511266  -0.179438    -0.0438976    0.18985     -0.0474553   -0.0525546    0.0758079     0.140366     0.0449562   -0.0482575    -0.0808661    0.0329266    0.0541721     0.16528     -0.0027565   -0.0525826 
  0.147817     0.149554    -0.112152      0.0384389   -0.0643411     0.0358562  -0.0341078    0.0882434    0.0351286    0.0366027   0.0744653  -0.0470972   -0.00118048   0.0490487   -0.00762186  -0.0277431   -0.0174334    -0.0975161   -0.0407426   -0.0535291     0.10184      0.096586    -0.158471     -0.0628964    0.173354     0.0241578 
  0.0366932   -0.101579     0.126267     -0.109962     0.168336      0.111074   -0.0137852   -0.143526    -0.142629    -0.171368    0.155907   -0.0914454   -0.0865817    0.216268     0.0513688    0.0396772    0.0360775    -0.0401352    0.0928048   -0.174954      0.0115757    0.0863214    0.116361      0.0861743    0.122653    -0.0167927 
  0.132411    -0.00512868  -0.00405943    0.0194091   -0.17677       0.128797   -0.103964    -0.103912    -0.106449    -0.216187    0.221932   -0.0226886    0.0239651   -0.187098     0.124113     0.0309267   -0.0746367    -0.177795    -0.582131     0.129016      0.108037     0.0529626    0.0624658    -0.0755274   -0.129801     0.128096  
  0.139148    -0.0402436    0.019257      0.03994     -0.0293747     0.0346399   0.12971     -0.0659506   -0.0713182    0.19615     0.115654   -0.103995     0.120794     0.0599852    0.13896      0.0519044   -0.0595933    -0.206354     0.529662     0.115252      0.0994224    0.0413485    0.0875431    -0.107978    -0.134744    -0.160037  
  0.0622061   -0.158157    -0.0152818    -0.0226091    0.211369     -0.0171779  -0.0753694    0.1033      -0.00666577   0.137568   -0.559703   -0.0603442    0.187056    -0.459714    -0.126894     0.0264589   -0.126444      0.0552847    0.181952    -0.0788862     0.0106073    0.030297    -0.00458359   -0.133248     0.0312446    0.0375504 
  0.0763827   -0.195069    -0.0222293    -0.00175968   0.172485     -0.0935039  -0.0334892    0.329855     0.0631179    0.219062    0.141292   -0.0777963    0.187734     0.758023    -0.12325     -0.0337886    0.0081998     0.0949799   -0.0916151   -0.0734653     0.0570826    0.0323439    0.037434     -0.0776535    0.0775117    0.303044  
  0.0249934   -0.166821    -0.0242053    -0.0388368    0.0452061    -0.030722   -0.0948294    0.0602546   -0.0153158    0.0540382  -0.06007    -0.141636     0.115707    -0.199804     0.132699     0.0133721   -0.0215809     0.107147    -0.041589     0.0344379    -0.162686     0.0587459    0.115867     -0.131297     0.133601     0.118837  
 -0.0605186   -0.0827255    0.162674      0.172956     0.215582     -0.0718467  -0.0927205   -0.0099729   -0.116046    -0.0230808  -0.130035   -0.0095062    0.0751503    0.204788    -0.0607853   -0.00822804   0.120746      0.146313    -0.0746228   -0.0671366    -0.0347566    0.159238     0.0477805     0.0493961    0.0647963    0.0423759 
  0.00702133  -0.143395    -0.0440078     0.0771686    0.0695832    -0.0178245  -0.183769     0.135891     0.066941     0.0686647  -0.0134496   0.044988     0.173415     0.0416896    0.03284      0.0317189   -0.0813533    -0.00313643   0.0823896    0.129758     -0.0150396    0.0906941    0.000881673  -0.0331868    0.00869096   0.0870698 
  0.0433967    0.0609432   -0.118376      0.135723     0.0545192     0.0907007   0.046661    -0.0402778    0.0121664    0.0380105  -0.0664997   0.0944693   -0.0598968    0.179824    -0.0268905   -0.0222773    0.0197676    -0.00930689   0.0379957    0.0929808     0.0721559   -0.0636219    0.0358625    -0.00427074  -0.12689     -0.122073  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     14
â”‚     18
â”‚     21
â”‚     22
â”‚     23
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.102152
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     14
â”‚     18
â”‚      â‹®
â”‚     23
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.085474
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     14
â”‚     15
â”‚     18
â”‚     21
â”‚     22
â”‚     23
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.094378
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     14
â”‚     18
â”‚      â‹®
â”‚     23
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.090745
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚     14
â”‚     15
â”‚     18
â”‚     21
â”‚     22
â”‚     23
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.096341
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     14
â”‚     18
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.082814
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚     14
â”‚     15
â”‚     18
â”‚     21
â”‚     22
â”‚     23
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.102050
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     14
â”‚     18
â”‚      â‹®
â”‚     23
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.085126
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     14
â”‚     15
â”‚     18
â”‚     21
â”‚     22
â”‚     23
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.094285
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     14
â”‚     18
â”‚      â‹®
â”‚     23
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.090725
â”Œ Info: EM with 100000 data points 10 iterations avll -1.090725
â”” 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.059855e+05
      1       6.897712e+05      -2.162143e+05 |       32
      2       6.651235e+05      -2.464776e+04 |       32
      3       6.493490e+05      -1.577449e+04 |       32
      4       6.392952e+05      -1.005377e+04 |       32
      5       6.325241e+05      -6.771067e+03 |       32
      6       6.280157e+05      -4.508382e+03 |       32
      7       6.253530e+05      -2.662729e+03 |       32
      8       6.237909e+05      -1.562072e+03 |       32
      9       6.225342e+05      -1.256766e+03 |       32
     10       6.212287e+05      -1.305436e+03 |       32
     11       6.200577e+05      -1.171057e+03 |       32
     12       6.191627e+05      -8.950042e+02 |       32
     13       6.184408e+05      -7.218934e+02 |       32
     14       6.178700e+05      -5.707563e+02 |       32
     15       6.173684e+05      -5.016222e+02 |       32
     16       6.168671e+05      -5.013305e+02 |       32
     17       6.164156e+05      -4.515170e+02 |       32
     18       6.158396e+05      -5.760101e+02 |       32
     19       6.152530e+05      -5.865778e+02 |       32
     20       6.148276e+05      -4.253528e+02 |       32
     21       6.145966e+05      -2.310324e+02 |       32
     22       6.144433e+05      -1.532752e+02 |       32
     23       6.142918e+05      -1.515646e+02 |       32
     24       6.141215e+05      -1.702887e+02 |       32
     25       6.138946e+05      -2.268774e+02 |       32
     26       6.136152e+05      -2.793662e+02 |       31
     27       6.133169e+05      -2.983141e+02 |       32
     28       6.130648e+05      -2.520693e+02 |       32
     29       6.128812e+05      -1.836264e+02 |       32
     30       6.127601e+05      -1.211266e+02 |       31
     31       6.126664e+05      -9.363786e+01 |       32
     32       6.126014e+05      -6.508108e+01 |       31
     33       6.125369e+05      -6.446267e+01 |       31
     34       6.124855e+05      -5.139929e+01 |       31
     35       6.124375e+05      -4.804455e+01 |       31
     36       6.123864e+05      -5.107331e+01 |       30
     37       6.123358e+05      -5.061564e+01 |       30
     38       6.122953e+05      -4.044205e+01 |       30
     39       6.122570e+05      -3.835325e+01 |       32
     40       6.122116e+05      -4.542171e+01 |       32
     41       6.121650e+05      -4.657755e+01 |       32
     42       6.121060e+05      -5.902246e+01 |       32
     43       6.120402e+05      -6.572257e+01 |       32
     44       6.119652e+05      -7.499596e+01 |       31
     45       6.118693e+05      -9.594816e+01 |       32
     46       6.117495e+05      -1.198241e+02 |       31
     47       6.116064e+05      -1.430708e+02 |       31
     48       6.114872e+05      -1.191827e+02 |       31
     49       6.114043e+05      -8.294597e+01 |       32
     50       6.113570e+05      -4.729945e+01 |       31
K-means terminated without convergence after 50 iterations (objv = 611356.9604344815)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.335916
[ Info: iteration 2, average log likelihood -1.309109
[ Info: iteration 3, average log likelihood -1.281324
[ Info: iteration 4, average log likelihood -1.249082
[ Info: iteration 5, average log likelihood -1.214409
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.172521
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     14
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.147635
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.166250
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.148972
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚     24
â”‚     25
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.112913
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      9
â”‚     14
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.132175
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.138100
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     17
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.110623
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      9
â”‚     16
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.097112
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     14
â”‚     19
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.128662
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     13
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.129294
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.099139
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      9
â”‚     14
â”‚     17
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.103715
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     16
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.128944
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚     15
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.115079
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.126738
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      8
â”‚     14
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.092816
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚     17
â”‚     24
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.090008
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     13
â”‚     15
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.123556
[ Info: iteration 25, average log likelihood -1.148089
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     14
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.099224
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚      9
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.085016
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚     15
â”‚     17
â”‚     26
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.109421
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.142162
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     14
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.106034
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      9
â”‚     13
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.108095
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.105249
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚     17
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.091022
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      9
â”‚     14
â”‚     16
â”‚     19
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.106463
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     13
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.127133
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.130021
[ Info: iteration 37, average log likelihood -1.107670
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      2
â”‚      8
â”‚      9
â”‚     14
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.050549
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.166560
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     15
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.138340
[ Info: iteration 41, average log likelihood -1.120133
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     14
â”‚     19
â”‚     24
â”‚     25
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.069745
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      2
â”‚      8
â”‚     17
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.130098
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     15
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.144007
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.121774
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     14
â”‚     19
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.080063
[ Info: iteration 47, average log likelihood -1.137988
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      8
â”‚     15
â”‚     16
â”‚     17
â”‚     26
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.083654
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.140001
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     14
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.140156
â”Œ Info: EM with 100000 data points 50 iterations avll -1.140156
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.16932    -0.0527432    -0.16084      0.0816942    -0.00207273   0.00473086  -0.31265      0.179561     -0.279531     0.0753865    -0.011141     -0.119948      0.0870576    0.153137     0.103684    0.0427115    0.0333746     0.0348733   -0.0745206    0.0402559    0.0763087    0.00579501   0.0403599   -0.0616474   -0.124943    -0.264583   
  0.202484    0.177955     -0.0833563    0.0208464    -0.0450655   -0.00259201  -0.030561     0.0832632     0.0280583   -0.0246131     0.11246      -0.0272572    -0.0893246   -0.0110974    0.0428664   0.00978348  -0.0288123    -0.0696612   -0.0484406   -0.040498     0.103414     0.0952675   -0.17159     -0.00824899   0.182888     0.0927898  
  0.163311   -0.116065     -0.118459    -0.174865      0.0767821    0.0998988   -0.0760317   -0.0608688    -0.0670062   -0.104836     -0.0686067    -0.064894     -0.0923182    0.0624737   -0.0316178  -0.135817    -0.0993393     0.00954091   0.11639     -0.0934085    0.111282     0.0771358    0.1614      -0.027489    -0.0469898   -0.0338653  
  0.0410058   0.107847     -0.0688229    0.0019702     0.270586    -0.0803821   -0.0524066   -0.1125        0.0384292   -0.191069      0.0501895     0.147922     -0.023716     0.044021     0.0266354   0.0478602   -0.000570266  -0.177893    -0.253587     0.0188116    0.031441    -0.0203195    0.0706557    0.00311867   0.151939     0.0307894  
 -0.0920782  -0.0629159    -0.0715955    0.0743709    -0.0573286    0.0787698   -0.0632806   -0.0360561     0.0315429   -0.148671     -0.076273     -0.00617982    0.129451     0.0256109    0.113887    0.115058    -0.0168021    -0.127397     0.198159     0.154952    -0.0956426    0.0989653    0.0319718    0.167274     0.0782789    0.000675666
  0.135815   -0.0259419     0.00734547   0.0287657    -0.0987379    0.0812272    0.00714918  -0.0850885    -0.0867889   -0.0057381     0.168338     -0.061628      0.0706422   -0.0585179    0.128179    0.0402818   -0.0712834    -0.190153    -0.029835     0.119282     0.103425     0.0470076    0.0743986   -0.093009    -0.127876    -0.0109514  
 -0.179916    0.130736     -0.134671     0.0513316    -0.169669    -0.0830512   -0.139239     0.0754823    -0.0627014   -0.0262716    -0.000329545  -0.12268       0.00883476   0.00540982   0.24897     0.102451    -0.056379      0.151359    -0.120426     0.00073954   0.0113603    0.0415756    0.106046    -0.005934    -0.00136174   0.0571076  
  0.283389   -0.0451552    -0.141822    -0.0586908     0.00853966  -0.00738935   0.0440013    0.0203608     0.0275317   -0.166575     -0.0473188    -0.10591       0.00781947   0.192907    -0.0373532  -0.0477335    0.0960786     0.111707     0.0242633   -0.00987357  -0.0698006    0.0219021    0.0229163    0.195149     0.0180672   -0.0998147  
 -0.230078    0.21969      -0.109481     0.015992      0.163542     0.0645527   -0.265377    -0.0837107    -0.101091    -0.22356      -0.00343503   -0.135711     -0.00166689   0.0693333    0.11712    -0.00482638   0.052015      0.0185698   -0.120317    -0.119018    -0.0689132   -0.323829    -0.0438084   -0.0159623    0.186424     0.100627   
  0.0675719  -0.147221      0.0379747   -0.0689771     0.176973     0.0269995   -0.0338386    0.0577593    -0.0464023    0.011207     -0.0275639    -0.0740251     0.0673743    0.184256    -0.0461609   0.0216453   -0.000332095   0.0268821    0.0667115   -0.0979903    0.0291755    0.0839412    0.058242    -0.0129615    0.0757712    0.0847786  
  0.279492   -0.117337     -0.0366614   -0.0631589    -0.0710505    0.00804862   0.051189     0.00433646    0.106671     0.0431487    -0.124621     -0.0914933     0.0925971    0.141365     0.0369774   0.0483584    0.0202208     0.215444     0.084807    -0.0811239    0.154373     0.0511959    0.0114166    0.126656    -0.00544655   0.122502   
 -0.116235    0.000495726  -0.029449    -0.160676     -0.0753085    0.0475848   -0.0562167   -0.0641237     0.119195     0.0263184    -0.0515918    -0.0356042    -0.20221     -0.0762231   -0.0539157   0.0443311    0.11996       0.0134249    0.204898     0.123652    -0.122539    -0.094878    -0.0376071    0.0654469    0.121714    -0.133338   
 -0.101293   -0.143332      0.185709    -0.0301144     0.179102     0.091826    -0.0393487   -0.124849     -0.14138     -0.182071      0.0706434    -0.0467711    -0.172552     0.163836     0.113892    0.0243403   -0.137213      0.0181907    0.0738423   -0.290826    -0.0964565   -0.0850959    0.139529     0.110554     0.1962       0.0172561  
 -0.0891662  -0.0375309    -0.0572432    0.177326     -0.209287     0.115366     0.13056     -0.000201102   0.128585    -0.058127      0.0504208    -0.133683      0.00165137   0.0813196   -0.0870147  -0.0192432    0.0105144     0.113364     0.124865    -0.16579      0.14418     -0.0575125   -0.100277     0.0139885   -0.0276779    0.04681    
  0.0413056   0.0691243    -0.10375      0.131144      0.0156654    0.110168     0.0576141   -0.0500964     0.0406925    0.050924      8.00923e-5    0.104157     -0.0637635    0.234061    -0.0228843  -0.0156859   -0.0249816    -0.0136777    0.0422049    0.116386     0.0810934   -0.164766     0.0445669   -0.0137609   -0.111276    -0.136582   
 -0.0421348  -0.0841483     0.0989897    0.15384       0.207763    -0.0582099   -0.0968731   -0.00465021   -0.102968    -0.000404668  -0.166682      0.0172428     0.0709211    0.210278    -0.0620479  -0.0097273    0.111441      0.11864     -0.0488904   -0.0376215   -0.00932213   0.179671     0.0419135    0.0260182    0.0314039    0.0319142  
 -0.32394    -0.00265346    0.045627     0.0106524    -0.142535     0.320827    -0.0175305    0.00348379    0.0958331    0.202842     -0.0214074    -0.00901363    0.0121556    0.059967    -0.0258718  -0.0213986   -0.0371451    -0.112432    -0.0137614    0.215152    -0.0471416   -0.0573207   -0.0481802    0.277403     0.0824647   -0.0161931  
  0.11393     0.0281834    -0.0254405    0.252362      0.201943    -0.0603807    0.0979293    0.0533512    -0.0884006   -0.0572062    -0.247996     -0.0214027    -0.0423028   -0.0854628    0.0476672  -0.127811     0.148888      0.014261     0.0476256   -0.10827     -0.102944     0.051303    -0.0771774    0.0335709    0.0288406    0.0107449  
  0.101051    0.00131018    0.0346522    0.0948414     0.167503     0.0113815   -0.00784758  -0.158158     -0.216096    -0.123703      0.0175249    -0.0205608     0.00345852  -0.149429    -0.0660682  -0.019999    -0.297988      0.170761     0.0768481    0.143967    -0.00584137   0.122176    -0.236972    -0.0204499    0.140749     0.0115332  
  0.0795617   0.102014     -0.0672651    0.112372      0.113058     0.100584     0.0912171   -0.0307938    -0.211159    -0.0381135     0.133493     -0.126047      0.146834     0.093423     0.21279     0.081672    -0.0616146    -0.11425      0.0201791   -0.104715     0.107348    -0.180404     0.0785453    0.0590971    0.0748713    0.0898527  
 -0.0864706   0.151012     -0.00152051  -0.07595       0.0256975    0.0909041   -0.0129054    0.0366139     0.0330327    0.0866975    -0.298907     -0.0210703    -0.0402152    0.271261    -0.0811516  -0.239394     0.0659554    -0.0345352    0.00916682  -0.125448     0.0220055   -0.127782     0.107681    -0.0804782   -0.103748    -0.163733   
 -0.0790069  -0.0241226    -0.124664     0.0527436    -0.0340597   -0.109522     0.089763     0.117847     -0.00227749   0.00611766    0.0471938    -0.0530581    -0.00298312  -0.121445     0.036291    0.064356    -0.0274797    -0.0148509   -0.015145     0.0715306   -0.0072038   -0.0323411   -0.145404     0.178693    -0.102962    -0.0607945  
  0.113316   -0.00645846   -0.0637887   -0.00503791    0.0402177    0.0388052    0.169826    -0.127197      0.109187    -0.0918804    -0.0127285     0.152736      0.0838277    0.125271     0.0642608   0.0654367    0.0883468    -0.161028     0.206113    -0.00617635   0.0485296    0.0174509    0.0171745   -0.113843    -0.0961596    0.0207128  
  0.0173224  -0.163519     -0.0427828    0.0710377     0.0645418   -0.0257723   -0.273362     0.149493      0.104043     0.135418     -0.020282      0.0810195     0.151004     0.0462996    0.0348114   0.0833709   -0.16257       0.00155096   0.0627656    0.137357    -0.0133464    0.128335     0.0162262   -0.0487764    0.019676     0.0898557  
 -0.0281876  -0.0768573     0.0766083   -0.0140808     0.0193558    0.0409091   -0.123318    -0.119832      0.112172    -0.0363079    -0.132646      0.0718443     0.0219224   -0.0376413    0.127777    0.0267631    0.012435     -0.0707562    0.208718    -0.0133225   -0.106125     0.103355     0.20887     -0.0161994   -0.0148802    0.146003   
  0.21316     0.0434101    -9.67024e-5   0.000723073   0.0912318   -0.103394     0.062447     0.0467206     0.00836868  -0.336575      0.0870591    -0.0671123    -0.292692    -0.031407     0.0574608   0.0129802   -0.0479944     0.0622225   -0.0151221   -0.0103406   -0.0148523    0.0649272   -0.0596735    0.117351     0.106518     0.271504   
  0.0256137   0.0342437     0.0722807    0.032328      0.0790396   -0.0673731    0.161258     0.108779     -0.10519      0.0813175     0.00313242   -0.000398791  -0.0123658   -0.122066    -0.0358539  -0.0279035    0.13386       0.108319    -0.0911989    0.0598956   -0.0879628    0.0381929   -0.00496623   0.102075    -0.128521    -0.0747714  
  0.0563937   0.0408746    -0.0553487   -0.0177671    -0.129973    -0.0103831   -0.152382    -0.00484793    0.0354167   -0.166895     -0.106719     -0.0921333    -0.200057     0.112705    -0.0789463  -0.119995     0.237497      0.0402369    0.0927283    0.037267     0.0782902    0.100659     0.0151051   -0.0577374    0.00703879  -0.0641344  
 -0.0366742  -0.124425     -0.0520621    0.136968     -0.0675536    0.0468247    0.0364927    0.174289     -0.0103581    0.0743914    -0.142719     -0.129892     -0.0364734   -0.0779969    0.0759669  -0.147473    -0.346074      0.03934     -0.065257    -0.125915     0.0575866   -0.131172     0.0426339    0.207265     0.0889828   -0.107407   
 -0.21165    -0.110319      0.1137       0.197124     -0.121542     0.206228     0.227322    -0.0711405     0.0875722    0.0863082    -0.140079      0.0500852     0.0565615    0.108914     0.102683    0.0568342[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
   -0.143778      0.10907      0.00510286   0.26746      0.00246801   0.0103025    0.0713779   -0.0206177   -0.182182    -0.0034054  
  0.0261972  -0.16634      -0.0266409   -0.0357505     0.0446346   -0.0279565   -0.0909909    0.061202     -0.0120392    0.0575211    -0.0560248    -0.139856      0.115874    -0.194224     0.128874    0.011627    -0.0263335     0.106448    -0.0424862    0.0365989   -0.159323     0.0534074    0.115771    -0.128254     0.127458     0.120431   
  0.0898071  -0.105221      0.0681166   -0.113425      0.0640924   -0.128664    -0.0400367   -0.00738852    0.129917     0.0413893     0.0232573     0.0418142    -0.027086     0.0428781   -0.17312     0.0599637   -0.00699225    0.165836    -0.0686072   -0.0764391   -0.0584143   -0.0016473   -0.014156    -0.269177     0.111693     0.0324752  â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.126344
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚     15
â”‚     16
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.068778
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      8
â”‚      9
â”‚     14
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.054496
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚     15
â”‚     16
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.095973
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.081043
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      8
â”‚      9
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.025220
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.119236
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚     15
â”‚     16
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.059601
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      8
â”‚      9
â”‚     14
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.048898
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚     15
â”‚     16
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.095398
â”Œ Info: EM with 100000 data points 10 iterations avll -1.095398
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.0278518   -0.0883747    0.0334054    0.0831128   -0.138843     0.144666     0.120364    -0.0767458   -0.0443415    0.00836702   0.133833     0.0636386    0.147104    -0.0148374   -0.0531443     0.00406257   0.0497437   -0.229971      0.247418    0.171005     0.162499    -0.0874372    0.122009    -0.034523     0.163035     0.0422297 
  0.00833531   0.04103     -0.18236      0.0973485   -0.0365241    0.0048555   -0.100696    -0.132323    -0.162193     0.0429678   -0.0942172   -0.0233653   -0.0960542    0.0268493   -0.220261     -0.126287    -0.13042     -0.124127     -0.116149   -0.00663849  -0.115532    -0.236595    -0.00352816   0.0513976    0.0817927   -0.0546335 
  0.0780456    0.0187076   -0.069863     0.0368232    0.116628     0.0652472   -0.113425    -0.24759     -0.111749     0.0814159    0.0314108    0.0393546   -0.0815663   -0.0786425    0.00159063    0.119598     0.105603    -0.1242        0.169492   -0.0603156   -0.0700543    0.0288643    0.0841352   -0.0737835    0.107384     0.0358026 
  0.0364541   -0.0881119    0.00916722  -0.0212677    0.0370167   -0.058437     0.0188932    0.169384    -0.10938      0.00189984   0.117556     0.00191131   0.105608    -0.0368974    0.0747292     0.325696     0.0562938    0.0964897     0.10707     0.00868337  -0.0654269    0.105721    -0.106384    -0.135683    -0.0464657    0.0478489 
 -0.137719     0.0183061   -0.0804454    0.0587952   -0.0247436   -0.166925    -0.13113      0.0688203   -0.113913    -0.0407125    0.0756577    0.0454777    0.260379     0.0634255   -0.0756195     0.0315438   -0.0368395   -0.0431946    -0.0748617  -0.0925604    0.185208     0.0602144   -0.135324    -0.0957545   -0.0340887   -0.124609  
  0.0800856   -0.0864449    0.064615     0.042633     0.0532436    0.00395057  -0.0995898   -0.0658135   -0.161129    -0.0411794   -0.139225     0.064425    -0.116971     0.0632319   -0.0854806    -0.0758762    0.0973656   -0.0213113     0.032176    0.0647908    0.103834    -0.0107502   -0.00817333   0.0617399   -0.0323329    0.0383726 
 -0.0319284    0.0303398    0.142694    -0.0148417    0.10533     -0.094559     0.0222577    0.09163      0.0887928   -0.112868     0.047083    -0.0337864    0.0301227   -0.0337923    0.00760913   -0.00869893   0.0370803    0.059493      0.0144436  -0.00900505  -0.0629117    0.191575     0.0494173    0.0169298    0.0621254    0.00180409
 -0.0016243   -0.120395     0.0263755    0.0522289    0.0109662    0.0485758   -0.0277771   -0.173852    -0.0496319   -0.0233331    0.0842374   -0.00728788  -0.0301638    0.14683      0.0491311    -0.0555039   -0.0540708    0.0789993    -0.102259   -0.125261    -0.136067     0.0498935   -0.0582928   -0.00933062   0.0432192   -0.241361  
  0.00945241   0.0966769    0.119711     0.216234    -0.0632758    0.0305801    0.0636281    0.0483049   -0.112355     0.0109827    0.0159986    0.15726     -0.0678489    0.0479364    0.0774721     0.169472    -0.116606     0.0594718    -0.070844    0.134513    -0.0781192   -0.0148955   -0.0813194    0.0846179   -0.031618     0.051501  
 -0.218464    -0.030194    -0.0484537    0.315863    -0.0871531    0.0339458    0.09322      0.0720278   -0.065405    -0.00032718   0.0647345   -0.00944092  -0.0383862    0.140907     0.051274      0.0445575    0.0669878   -0.0193663     0.0513887  -0.0697406   -0.102458     0.133927    -0.1132       0.0886975   -0.082467    -0.050154  
 -0.173925    -0.258296    -0.0727758    0.111993     0.138081     0.110399    -0.0656564    0.0349113   -0.0123631    0.081872    -0.213035    -0.171566     0.105859     0.0368617    0.0376335     0.0413043    0.00527928  -0.116548     -0.0324668  -0.0632667   -0.00771051  -0.051135     0.0732597    0.153946    -0.109289    -0.0553848 
  0.0515834   -0.0185141   -0.00653973   0.0321885    0.0960456    0.0749297    0.103193     0.0491744   -0.107385     0.148248    -0.0376632    0.148277     0.0907283    0.0608353   -0.0199944    -0.10595      0.112552    -0.18639       0.164013    0.0786649   -0.0310147   -0.173924    -0.0534895    0.0519896    0.0423468   -0.156501  
 -0.0518865   -0.0831728   -0.135091     0.0243394   -0.00461348   0.133672     0.026377    -0.0995463    0.0721187    0.0488454    0.0352889   -0.130747    -0.0703987   -0.0591309    0.144349      0.147433    -0.117952    -0.00060965    0.14843     0.0904928    0.0713314   -0.0853779   -0.215755    -0.0819919   -0.0900381    0.0967525 
  0.171583    -0.0629797    0.14914     -0.131655     0.0632826   -0.298237    -0.182371     0.145229    -0.0312315   -0.135685     0.0627829   -0.0797193    0.0471832   -0.00775719   0.189616     -0.00997588  -0.119282    -0.0284434     0.0604096  -0.0493126    0.143401     0.0997661   -0.0109484    0.0207909   -0.0897838    0.072187  
 -0.111652    -0.0380558   -0.00991138   0.0738161    0.118723     0.0215925   -0.0873274    0.0905542    0.0789164   -0.0807368    0.0207826   -0.206674    -0.016963     0.123058    -0.0762412     0.0816363   -0.0264488    0.130245      0.053203    0.0278871   -0.0106783    0.0442773   -0.0808186    0.0249668    0.207563    -0.074142  
 -0.121141     0.119795    -0.0164091   -0.0926965    0.0361928    0.22848     -0.060486     0.122405     0.00122941  -0.0323623    0.0779102   -0.0402258   -0.0124747   -0.0726791    0.0736835    -0.158537     0.100539     0.106811      0.166292    0.0359048    0.0180006   -0.0280322   -0.113966     0.152695    -0.105705     0.0195951 
  0.0942233    0.00972251   0.0247495    0.0713426   -0.00813109  -0.00531036   0.0640289    0.0601731    0.11703      0.150928     0.0889638    0.0871151   -0.170594    -0.1496       0.144795     -0.0370795    0.0518769    0.00390569    0.150897   -0.00258548   0.0253774    0.130598    -0.0244377    0.0446463   -0.107484     0.0135535 
  0.00257495   0.15937     -0.124987    -0.129706     0.0745521   -0.0716499   -0.048976     0.243555    -0.0209785   -0.0490565   -0.158142     0.00887177  -0.0584114    0.0254204    0.148715     -0.0321449    0.129051     0.0890811     0.194986   -0.0902509   -0.124198     0.182603     0.0461786   -0.114245     0.0808795   -0.178238  
  0.0288492    0.0353054   -0.139499    -0.0630484   -0.0683093   -0.0922649   -0.00204502   0.013401    -0.00432975  -0.0922159   -0.0868934    0.0415642   -0.11992     -0.0781845   -0.178148      0.113431     0.0723957    0.0942126    -0.0941464  -0.0206096   -0.0762531    0.0678808    0.140077    -0.118133    -0.0077783    0.0158807 
 -0.0510406   -0.19846      0.144981    -0.031059     0.0708078   -0.0458262    0.0168651   -0.227335    -0.0964843   -0.0544084    0.168348    -0.0370163   -0.0150612   -0.0392115    0.00718764    0.0682965   -0.102437    -0.1242       -0.0017594   0.109252     0.0466438    0.0373753   -0.181336    -0.106471    -0.105344    -0.0261173 
  0.0861364   -0.0755336   -0.0614074    0.112525     0.109821    -0.121207     0.145387    -0.0675939    0.026839    -0.00984399   0.0600741   -0.142512     0.0493838   -0.00711115   0.0174737    -0.0350493    0.0535384   -0.0946423     0.0994731  -0.110992     0.202946     0.0261767   -0.0146727    0.0570391   -0.0143079   -0.106605  
 -0.0698769    0.0603664   -0.114993     0.03089      0.0255114   -0.202549    -0.0185765    0.135387    -0.137978     0.0555868   -0.0605255    0.143003    -0.118934     0.0750283   -0.00660526   -0.00399328  -0.0262397   -0.0471004    -0.199278    0.0012921   -0.0285712    0.0657917    0.00954404   0.173605    -0.0786946   -0.0294382 
 -0.0107861    0.0721639    0.0621713    0.0632002    0.174112    -0.019006     0.0509111   -0.0228382    0.0221039    0.156113     0.0577787    0.0777672   -0.0991079    0.0278468   -0.000664739   0.112931     0.0128195   -0.140806      0.0697077   0.0436621   -0.0575342    0.0455522   -0.121214    -0.0619891    0.105188     0.0992572 
  0.0459377   -0.111182    -0.0711235   -0.138692    -0.188678     0.0933433    0.0389496   -0.0795333   -0.00358317  -0.00614858   0.00297546  -0.0751686    0.0265117    0.136487    -0.0799594    -0.0569325    0.0256145   -0.0725974     0.049445   -0.116601     0.0871624    0.0985787   -0.0345395    0.0944335   -0.00612545   0.0217172 
  0.0656661    0.192315     0.0884912    0.00964091   0.0561042    0.04434     -0.113833     0.170506    -0.0372546    0.0355982    0.0171781    0.207872    -0.00933533   0.0388049    0.138934     -0.0403736   -0.101442    -0.0797059    -0.0168641   0.139234     0.139679    -0.037688     0.0279192   -0.124383     0.12309      0.13011   
 -0.180044    -0.0818819   -0.111737     0.01328      0.139191    -0.0127456   -0.170681    -0.188071    -0.0725515    0.0624222    0.0598542    0.0725656   -0.0883291    0.024929    -0.123986     -0.106871     0.19902     -0.0472916     0.0180908   0.0199742    0.0637021   -0.0788461   -0.0238095   -0.103911    -0.0103757    0.09608   
 -0.0775444    0.146263     0.166424    -0.128422    -0.0663212    0.221089    -0.232094    -0.0300216    0.105951    -0.220678    -0.0471911    0.0149125   -0.016979    -0.159661     0.0459449    -0.0415672   -0.0774662   -0.0066548    -0.0519173   0.00379866  -0.0714272    0.00571176   0.0154282    0.189914    -0.0346744   -0.0215701 
 -0.00013186  -0.00638026   0.0184412   -0.0122081   -0.0770273   -0.0591832    0.0739996   -0.0214643    0.0155178    0.155871    -0.0460612   -0.114601    -0.00899739  -0.0724368    0.0428622     0.162045     0.0900719   -0.0837499     0.0522516   0.088095    -0.0116217   -0.11574      0.0681375   -0.0142873    0.0455679   -0.0392884 
 -0.0965154   -0.156661    -0.022397    -0.0195314   -0.0584042   -0.0861625   -0.0772214    0.00913586   0.184043    -0.0370139    0.0372117    0.154855    -0.0126633    0.194091    -0.0605667    -0.115253    -0.0207661    0.210991     -0.0863855  -0.121042    -0.0732667   -0.0793765    0.187972    -0.0906149   -0.0476484    0.00603121
  0.0402824   -0.0863227    0.0601082   -0.227303    -0.090356     0.319912    -0.0432596    0.100293     0.0273258    0.036481     0.00151276   0.01431     -0.24513      0.0794488   -0.16532      -0.0427461    0.0126705   -0.0649319    -0.178945   -0.107092    -0.130293     0.0596563    0.0694562   -0.049174     0.109413    -0.0111761 
 -0.086761    -0.168442     0.0713881    0.0914926   -0.0574872   -0.0332085    0.0692767    0.1557       0.143323     0.0410447   -0.00204563   0.146083     0.143057    -0.0449482   -0.118206     -0.0230898   -0.0986155   -0.121956      0.0273375  -0.0259027   -0.134879    -0.0482359   -0.0195504   -0.042754     0.0134813   -0.0777316 
  0.135824     0.0963255    0.0269921    0.0205507    0.141016    -0.0875086    0.0379782    0.152425     0.172946     0.111083     0.174125    -0.00061088  -0.136203    -0.0810691   -0.149042      0.0651009   -0.0485878    0.000520373   0.0640811   0.267991    -0.0756124    0.0226352    0.0353806    0.0521307   -0.0603008    0.00187812kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.424808200854836
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424828
[ Info: iteration 2, average log likelihood -1.424769
[ Info: iteration 3, average log likelihood -1.424729
[ Info: iteration 4, average log likelihood -1.424682
[ Info: iteration 5, average log likelihood -1.424625
[ Info: iteration 6, average log likelihood -1.424551
[ Info: iteration 7, average log likelihood -1.424440
[ Info: iteration 8, average log likelihood -1.424238
[ Info: iteration 9, average log likelihood -1.423815
[ Info: iteration 10, average log likelihood -1.422972
[ Info: iteration 11, average log likelihood -1.421682
[ Info: iteration 12, average log likelihood -1.420419
[ Info: iteration 13, average log likelihood -1.419665
[ Info: iteration 14, average log likelihood -1.419349
[ Info: iteration 15, average log likelihood -1.419233
[ Info: iteration 16, average log likelihood -1.419192
[ Info: iteration 17, average log likelihood -1.419176
[ Info: iteration 18, average log likelihood -1.419170
[ Info: iteration 19, average log likelihood -1.419167
[ Info: iteration 20, average log likelihood -1.419165
[ Info: iteration 21, average log likelihood -1.419165
[ Info: iteration 22, average log likelihood -1.419164
[ Info: iteration 23, average log likelihood -1.419164
[ Info: iteration 24, average log likelihood -1.419163
[ Info: iteration 25, average log likelihood -1.419163
[ Info: iteration 26, average log likelihood -1.419163
[ Info: iteration 27, average log likelihood -1.419162
[ Info: iteration 28, average log likelihood -1.419162
[ Info: iteration 29, average log likelihood -1.419162
[ Info: iteration 30, average log likelihood -1.419162
[ Info: iteration 31, average log likelihood -1.419161
[ Info: iteration 32, average log likelihood -1.419161
[ Info: iteration 33, average log likelihood -1.419161
[ Info: iteration 34, average log likelihood -1.419161
[ Info: iteration 35, average log likelihood -1.419161
[ Info: iteration 36, average log likelihood -1.419161
[ Info: iteration 37, average log likelihood -1.419161
[ Info: iteration 38, average log likelihood -1.419161
[ Info: iteration 39, average log likelihood -1.419161
[ Info: iteration 40, average log likelihood -1.419161
[ Info: iteration 41, average log likelihood -1.419160
[ Info: iteration 42, average log likelihood -1.419160
[ Info: iteration 43, average log likelihood -1.419160
[ Info: iteration 44, average log likelihood -1.419160
[ Info: iteration 45, average log likelihood -1.419160
[ Info: iteration 46, average log likelihood -1.419160
[ Info: iteration 47, average log likelihood -1.419160
[ Info: iteration 48, average log likelihood -1.419160
[ Info: iteration 49, average log likelihood -1.419160
[ Info: iteration 50, average log likelihood -1.419160
â”Œ Info: EM with 100000 data points 50 iterations avll -1.419160
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4248280968906133
â”‚     -1.4247694296331084
â”‚      â‹®                 
â””     -1.4191602011064295
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419180
[ Info: iteration 2, average log likelihood -1.419119
[ Info: iteration 3, average log likelihood -1.419076
[ Info: iteration 4, average log likelihood -1.419027
[ Info: iteration 5, average log likelihood -1.418970
[ Info: iteration 6, average log likelihood -1.418905
[ Info: iteration 7, average log likelihood -1.418836
[ Info: iteration 8, average log likelihood -1.418768
[ Info: iteration 9, average log likelihood -1.418706
[ Info: iteration 10, average log likelihood -1.418649
[ Info: iteration 11, average log likelihood -1.418599
[ Info: iteration 12, average log likelihood -1.418551
[ Info: iteration 13, average log likelihood -1.418504
[ Info: iteration 14, average log likelihood -1.418455
[ Info: iteration 15, average log likelihood -1.418403
[ Info: iteration 16, average log likelihood -1.418349
[ Info: iteration 17, average log likelihood -1.418293
[ Info: iteration 18, average log likelihood -1.418239
[ Info: iteration 19, average log likelihood -1.418187
[ Info: iteration 20, average log likelihood -1.418140
[ Info: iteration 21, average log likelihood -1.418099
[ Info: iteration 22, average log likelihood -1.418063
[ Info: iteration 23, average log likelihood -1.418031
[ Info: iteration 24, average log likelihood -1.418003
[ Info: iteration 25, average log likelihood -1.417978
[ Info: iteration 26, average log likelihood -1.417955
[ Info: iteration 27, average log likelihood -1.417933
[ Info: iteration 28, average log likelihood -1.417912
[ Info: iteration 29, average log likelihood -1.417891
[ Info: iteration 30, average log likelihood -1.417871
[ Info: iteration 31, average log likelihood -1.417852
[ Info: iteration 32, average log likelihood -1.417833
[ Info: iteration 33, average log likelihood -1.417814
[ Info: iteration 34, average log likelihood -1.417797
[ Info: iteration 35, average log likelihood -1.417781
[ Info: iteration 36, average log likelihood -1.417766
[ Info: iteration 37, average log likelihood -1.417753
[ Info: iteration 38, average log likelihood -1.417741
[ Info: iteration 39, average log likelihood -1.417730
[ Info: iteration 40, average log likelihood -1.417721
[ Info: iteration 41, average log likelihood -1.417713
[ Info: iteration 42, average log likelihood -1.417707
[ Info: iteration 43, average log likelihood -1.417701
[ Info: iteration 44, average log likelihood -1.417697
[ Info: iteration 45, average log likelihood -1.417693
[ Info: iteration 46, average log likelihood -1.417690
[ Info: iteration 47, average log likelihood -1.417688
[ Info: iteration 48, average log likelihood -1.417686
[ Info: iteration 49, average log likelihood -1.417684
[ Info: iteration 50, average log likelihood -1.417683
â”Œ Info: EM with 100000 data points 50 iterations avll -1.417683
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.419179839122793 
â”‚     -1.4191185593908098
â”‚      â‹®                 
â””     -1.4176828296190602
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417696
[ Info: iteration 2, average log likelihood -1.417645
[ Info: iteration 3, average log likelihood -1.417606
[ Info: iteration 4, average log likelihood -1.417562
[ Info: iteration 5, average log likelihood -1.417511
[ Info: iteration 6, average log likelihood -1.417449
[ Info: iteration 7, average log likelihood -1.417379
[ Info: iteration 8, average log likelihood -1.417303
[ Info: iteration 9, average log likelihood -1.417227
[ Info: iteration 10, average log likelihood -1.417156
[ Info: iteration 11, average log likelihood -1.417093
[ Info: iteration 12, average log likelihood -1.417038
[ Info: iteration 13, average log likelihood -1.416991
[ Info: iteration 14, average log likelihood -1.416949
[ Info: iteration 15, average log likelihood -1.416912
[ Info: iteration 16, average log likelihood -1.416878
[ Info: iteration 17, average log likelihood -1.416845
[ Info: iteration 18, average log likelihood -1.416814
[ Info: iteration 19, average log likelihood -1.416783
[ Info: iteration 20, average log likelihood -1.416753
[ Info: iteration 21, average log likelihood -1.416724
[ Info: iteration 22, average log likelihood -1.416697
[ Info: iteration 23, average log likelihood -1.416671
[ Info: iteration 24, average log likelihood -1.416647
[ Info: iteration 25, average log likelihood -1.416626
[ Info: iteration 26, average log likelihood -1.416607
[ Info: iteration 27, average log likelihood -1.416591
[ Info: iteration 28, average log likelihood -1.416576
[ Info: iteration 29, average log likelihood -1.416564
[ Info: iteration 30, average log likelihood -1.416552
[ Info: iteration 31, average log likelihood -1.416542
[ Info: iteration 32, average log likelihood -1.416533
[ Info: iteration 33, average log likelihood -1.416525
[ Info: iteration 34, average log likelihood -1.416517
[ Info: iteration 35, average log likelihood -1.416510
[ Info: iteration 36, average log likelihood -1.416503
[ Info: iteration 37, average log likelihood -1.416496
[ Info: iteration 38, average log likelihood -1.416489
[ Info: iteration 39, average log likelihood -1.416483
[ Info: iteration 40, average log likelihood -1.416477
[ Info: iteration 41, average log likelihood -1.416471
[ Info: iteration 42, average log likelihood -1.416465
[ Info: iteration 43, average log likelihood -1.416459
[ Info: iteration 44, average log likelihood -1.416454
[ Info: iteration 45, average log likelihood -1.416448
[ Info: iteration 46, average log likelihood -1.416443
[ Info: iteration 47, average log likelihood -1.416437
[ Info: iteration 48, average log likelihood -1.416432
[ Info: iteration 49, average log likelihood -1.416426
[ Info: iteration 50, average log likelihood -1.416421
â”Œ Info: EM with 100000 data points 50 iterations avll -1.416421
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.417695963886236 
â”‚     -1.4176449123133983
â”‚      â‹®                 
â””     -1.4164210595106344
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416426
[ Info: iteration 2, average log likelihood -1.416376
[ Info: iteration 3, average log likelihood -1.416333
[ Info: iteration 4, average log likelihood -1.416286
[ Info: iteration 5, average log likelihood -1.416230
[ Info: iteration 6, average log likelihood -1.416163
[ Info: iteration 7, average log likelihood -1.416084
[ Info: iteration 8, average log likelihood -1.415993
[ Info: iteration 9, average log likelihood -1.415894
[ Info: iteration 10, average log likelihood -1.415789
[ Info: iteration 11, average log likelihood -1.415684
[ Info: iteration 12, average log likelihood -1.415582
[ Info: iteration 13, average log likelihood -1.415486
[ Info: iteration 14, average log likelihood -1.415399
[ Info: iteration 15, average log likelihood -1.415320
[ Info: iteration 16, average log likelihood -1.415249
[ Info: iteration 17, average log likelihood -1.415186
[ Info: iteration 18, average log likelihood -1.415130
[ Info: iteration 19, average log likelihood -1.415080
[ Info: iteration 20, average log likelihood -1.415035
[ Info: iteration 21, average log likelihood -1.414995
[ Info: iteration 22, average log likelihood -1.414958
[ Info: iteration 23, average log likelihood -1.414924
[ Info: iteration 24, average log likelihood -1.414892
[ Info: iteration 25, average log likelihood -1.414863
[ Info: iteration 26, average log likelihood -1.414835
[ Info: iteration 27, average log likelihood -1.414809
[ Info: iteration 28, average log likelihood -1.414784
[ Info: iteration 29, average log likelihood -1.414760
[ Info: iteration 30, average log likelihood -1.414737
[ Info: iteration 31, average log likelihood -1.414715
[ Info: iteration 32, average log likelihood -1.414693
[ Info: iteration 33, average log likelihood -1.414673
[ Info: iteration 34, average log likelihood -1.414652
[ Info: iteration 35, average log likelihood -1.414633
[ Info: iteration 36, average log likelihood -1.414613
[ Info: iteration 37, average log likelihood -1.414595
[ Info: iteration 38, average log likelihood -1.414576
[ Info: iteration 39, average log likelihood -1.414559
[ Info: iteration 40, average log likelihood -1.414541
[ Info: iteration 41, average log likelihood -1.414524
[ Info: iteration 42, average log likelihood -1.414508
[ Info: iteration 43, average log likelihood -1.414492
[ Info: iteration 44, average log likelihood -1.414477
[ Info: iteration 45, average log likelihood -1.414462
[ Info: iteration 46, average log likelihood -1.414448
[ Info: iteration 47, average log likelihood -1.414434
[ Info: iteration 48, average log likelihood -1.414422
[ Info: iteration 49, average log likelihood -1.414409
[ Info: iteration 50, average log likelihood -1.414398
â”Œ Info: EM with 100000 data points 50 iterations avll -1.414398
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4164255940227242
â”‚     -1.416376228784475 
â”‚      â‹®                 
â””     -1.4143977126098   
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414395
[ Info: iteration 2, average log likelihood -1.414326
[ Info: iteration 3, average log likelihood -1.414260
[ Info: iteration 4, average log likelihood -1.414185
[ Info: iteration 5, average log likelihood -1.414094
[ Info: iteration 6, average log likelihood -1.413982
[ Info: iteration 7, average log likelihood -1.413849
[ Info: iteration 8, average log likelihood -1.413700
[ Info: iteration 9, average log likelihood -1.413542
[ Info: iteration 10, average log likelihood -1.413385
[ Info: iteration 11, average log likelihood -1.413236
[ Info: iteration 12, average log likelihood -1.413101
[ Info: iteration 13, average log likelihood -1.412981
[ Info: iteration 14, average log likelihood -1.412877
[ Info: iteration 15, average log likelihood -1.412787
[ Info: iteration 16, average log likelihood -1.412707
[ Info: iteration 17, average log likelihood -1.412637
[ Info: iteration 18, average log likelihood -1.412574
[ Info: iteration 19, average log likelihood -1.412517
[ Info: iteration 20, average log likelihood -1.412466
[ Info: iteration 21, average log likelihood -1.412419
[ Info: iteration 22, average log likelihood -1.412376
[ Info: iteration 23, average log likelihood -1.412337
[ Info: iteration 24, average log likelihood -1.412300
[ Info: iteration 25, average log likelihood -1.412266
[ Info: iteration 26, average log likelihood -1.412235
[ Info: iteration 27, average log likelihood -1.412205
[ Info: iteration 28, average log likelihood -1.412177
[ Info: iteration 29, average log likelihood -1.412150
[ Info: iteration 30, average log likelihood -1.412124
[ Info: iteration 31, average log likelihood -1.412100
[ Info: iteration 32, average log likelihood -1.412077
[ Info: iteration 33, average log likelihood -1.412054
[ Info: iteration 34, average log likelihood -1.412033
[ Info: iteration 35, average log likelihood -1.412012
[ Info: iteration 36, average log likelihood -1.411992
[ Info: iteration 37, average log likelihood -1.411973
[ Info: iteration 38, average log likelihood -1.411955
[ Info: iteration 39, average log likelihood -1.411937
[ Info: iteration 40, average log likelihood -1.411920
[ Info: iteration 41, average log likelihood -1.411903
[ Info: iteration 42, average log likelihood -1.411887
[ Info: iteration 43, average log likelihood -1.411872
[ Info: iteration 44, average log likelihood -1.411857
[ Info: iteration 45, average log likelihood -1.411843
[ Info: iteration 46, average log likelihood -1.411829
[ Info: iteration 47, average log likelihood -1.411816
[ Info: iteration 48, average log likelihood -1.411803
[ Info: iteration 49, average log likelihood -1.411790
[ Info: iteration 50, average log likelihood -1.411778
â”Œ Info: EM with 100000 data points 50 iterations avll -1.411778
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4143952427415616
â”‚     -1.4143259988053491
â”‚      â‹®                 
â””     -1.4117782680822843
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.424808200854836 
â”‚     -1.4248280968906133
â”‚     -1.4247694296331084
â”‚     -1.4247287470074381
â”‚      â‹®                 
â”‚     -1.411802759832053 
â”‚     -1.411790305176842 
â””     -1.4117782680822843
32Ã—26 Array{Float64,2}:
  0.270654      0.144128   -0.759121    0.205711    -0.296111    -0.121012     0.554606     0.317703    -0.23399     -0.328453   -0.1546     -0.576644   -0.206635     0.372893   -0.253503     0.138863    -0.358509    -0.165925   -0.390755    0.14367     0.799705      0.0193042   0.0968167   0.0391583    0.134771      0.0492999
 -0.155619     -0.0727796   0.218525    0.0461584   -0.0402643   -0.0397232    0.0959796    0.145407    -0.0685513   -0.0792425  -0.0791953  -0.0471351   0.0310064   -0.0181983  -0.0263685    0.234729    -0.0614882   -0.123287    0.0551894  -0.0434917   0.0592196    -0.0734503  -0.0626954   0.139828    -0.0046759     0.134003 
  0.441686     -0.695393   -0.259748    0.173845    -0.0757251   -0.923678    -0.430292    -0.0279362    0.250974     0.25957    -0.170329   -0.38631     0.213711     0.177761    0.155005    -0.0664068    0.357887     0.360208   -0.604785    0.203591   -0.382213     -0.514716    0.189898   -0.284544     0.0439842     0.590756 
  0.609642     -0.211778    0.105204    0.234257    -0.264539     0.0517265    0.515254     0.0162642    0.0761652   -0.292392   -0.216863    0.532711    0.658075     0.355453   -0.1551       0.0130632   -0.254309     0.678901   -0.386363   -0.177129    0.214094     -0.426134    0.228992   -0.269266    -0.00572889    0.358146 
  0.436268     -0.333466   -0.136329   -0.0176552    0.499041    -0.136356     0.494696    -0.393462    -0.0870946   -0.478239    0.314093   -0.0732621  -0.259196     0.113829   -0.324133     0.0553704    0.282619    -0.225286   -0.903027    0.250694    0.299217      0.567888   -0.254319   -0.623355    -0.652345     -0.0851271
  0.382064     -0.285737   -0.304964    0.336902     0.223541     0.573086    -0.348354    -0.265927     0.374679    -0.151269    0.594334   -0.0586597  -0.0151742    0.254982    0.246878     0.0680763   -0.0721661   -0.106442   -0.545537   -0.402417    0.464553     -0.020566   -0.523393    0.642098    -0.515149     -0.396157 
  0.0128966    -0.223818   -0.209948    0.962771    -0.269506    -0.214972     0.192453     0.395114     0.300708    -0.206414    0.909378    0.0793833   0.0840717   -0.224547    0.0456977    0.431605    -0.0989717   -0.171714    0.181648   -0.952665   -0.569866      0.0235337  -0.725777   -0.283398    -0.15454      -0.241275 
  0.288532     -0.544609    0.0239615   0.689221     0.219236    -0.502988    -0.191114    -0.0540002    0.197583    -0.107145   -0.449597    0.254192   -0.214919    -0.0120314  -0.563162     0.596942    -0.321283    -0.416233   -0.128533    0.0659921  -0.554822     -0.0463215  -0.965838   -0.246608     0.230641      0.275681 
 -0.0699501     0.385947    0.258103   -0.655902     0.00464474  -0.202977    -0.132537     0.218776    -0.0186105    0.115357   -0.303657   -0.33327    -0.297961    -0.113327   -0.0909653    0.00507817  -0.742272     0.405182    0.50679     0.0251701   0.0885866     0.529335    0.445785    0.210329     0.0961527     0.0542481
  0.139187     -0.455542   -0.0740702  -0.657573    -0.0700862   -0.503369    -0.0392903    0.54007     -0.336277    -0.21626     0.0583068  -0.707175   -0.583172    -0.160476    0.0792135   -0.0113256    0.602037    -0.433498    0.109906    0.181121    0.323658      0.537845   -0.114866    0.677736    -0.264848     -0.0253378
 -0.212156      0.0660707   0.172755   -0.436041    -0.0595922   -0.705799     0.00137792  -0.0275702   -0.573344     0.24956    -0.0559035   0.838036   -0.316916    -0.202117   -0.0229546    0.0400547    0.511691     0.174243    0.210377    0.0668386  -0.616681      0.556881    0.37126    -0.51956     -0.514635      0.28209  
 -0.0842313     0.004846   -0.675969   -0.24124     -0.560396    -0.215977    -0.206278    -0.0361447   -0.334556     0.433374    0.277404    0.893135   -0.803835    -0.227508    0.974923    -0.732612     0.403252     0.554677   -0.190036   -0.363798    0.55885       0.440821    0.346979    0.176565    -0.805338     -0.357995 
  0.379628      0.152173   -0.115786    0.203909     0.51774      0.33489     -0.333346    -0.448758     0.152677     0.0602089   0.562136    0.141422   -0.526552    -0.324169   -0.171677    -0.501215     0.166725    -0.0210191  -0.41587     0.175233   -0.0981288     0.420866    0.07705    -0.128658     0.28038      -0.670228 
 -0.851942      0.26871     0.19048    -0.383065     0.26624      0.626102    -0.542404     0.00682482   0.0637019    0.52823     0.187669    0.103448    0.0437612   -0.260462    0.323312    -0.275118     0.054345    -0.11275     1.00771     0.0481728  -0.391894      0.0236143  -0.0928277   0.159839     0.123389     -0.365441 
 -0.403381      0.152388   -0.177739   -0.223316     0.12389      0.271547    -0.607654    -0.740332    -0.239061     0.0712372  -0.0895972   0.650363   -0.476342     0.243076    0.135401    -0.63127     -0.378826    -0.415776   -0.0303629  -0.406851   -0.601518     -0.65678    -0.171456    0.0807094   -0.0666962     0.40901  
  0.0278732     0.097172    0.160349   -0.547765     0.205481     0.358039    -0.198915    -0.664009    -0.356127     0.203142   -0.489996   -0.20701    -0.240422     0.495299    0.307654    -0.576411     0.379128     0.230753   -0.0598559   0.827639    0.538722     -0.28672     0.510186    0.573215    -0.155202      0.0960557
  0.0493202     0.582442   -0.0954873  -0.437184    -0.180078     0.0883145    0.390901    -0.0339087   -0.139328     0.169564    0.382187   -0.871082    0.51392      0.0239616   0.114158    -0.0490748    0.07197     -0.0046874   0.197986   -0.0992972   0.410447     -0.246051    0.0611509  -0.201199    -0.116826     -0.136049 
 -0.0704232     0.860827    0.0456953  -0.233913    -0.0420623    0.954964     0.263178    -0.0324236   -0.206994    -0.40992     0.247992    0.33603     0.271119     0.0707843   0.258583    -0.365324     0.0707456   -0.242186    0.520007   -0.0692078   0.296796      0.449881    0.0865087   0.00455617  -0.0474708    -0.346527 
  0.00968015   -0.151378   -0.0420523   0.502446     0.24212     -0.0400952   -0.058455    -0.35672     -0.00940326  -0.0743252   0.406796   -0.214558   -0.324344    -0.485362    0.0911198    0.142458     0.294557    -0.366911   -0.489522    0.340893   -0.000341459  -0.271184   -0.152813    0.062484     0.544575     -0.405555 
 -0.0584016    -0.222274    0.294371    0.570865    -0.068569     0.261901     0.104597     0.340433     0.261354     0.145299    0.134227   -0.294886    0.948828    -0.234008   -0.549447     0.124132     0.290119    -0.0319589  -0.0207598   0.301613    0.536998      0.107438    0.0248974  -0.209086     0.621814     -0.532348 
 -0.155797     -0.173241    0.211934   -0.133336     0.128789     0.274427     0.186544     0.346432     0.81057     -0.461999   -0.246854    0.208323   -0.499805     0.0437844   0.0891587   -0.0794645    0.109656    -0.0471157   0.0172565   0.381384   -0.329148      0.195524    0.569037   -0.457924     0.0246925    -0.0550635
 -0.337607     -0.0731257   0.569707   -0.114954     0.118499     0.32146     -0.0446056   -0.310216     0.391631    -0.217572    0.138554    0.454409   -0.33235     -0.0541098   0.121798    -0.0940181    0.163582     0.041234   -0.41436     0.219001   -0.589663     -0.110269    0.394202    0.65123      0.164045     -0.250891 
  0.000356664  -0.102182    0.0735568  -0.0540082   -0.196033     0.154263    -0.122584     0.0104456   -0.0724031    0.087888    0.0190909   0.0734269   0.208852    -0.0548597   0.0974954   -0.0657617   -0.0542724    0.0828557   0.107343   -0.0307402   0.125137     -0.110686    0.0489707   0.156697     0.0360494     0.105222 
 -0.100715      0.281415   -0.0147156  -0.108419     0.313014    -0.00439501   0.0475554   -0.148373     0.0233998    0.0307764   0.101648   -0.0688749  -0.269309     0.0756981  -0.00667592   0.00482527  -0.00219098  -0.0874889   0.11468     0.0538169  -0.164055      0.21044     0.0286627  -0.103264    -0.0362291    -0.264473 
 -0.688261     -0.442418    0.326277   -0.194849    -0.660878    -0.116761     0.0827094    0.371486    -0.239728     0.0646657  -0.509884   -0.0798519   0.670271    -0.0766576   0.306784     0.558148     0.197311     0.0339625   0.816493    0.163869    0.0438739    -0.35086    -0.107375   -0.175943     0.0447009     0.520208 
 -0.0459205     0.0529862  -0.274738    0.139119     0.0214765   -0.133588    -0.282579     0.293583    -0.654943     0.751805   -0.203717    0.134614    0.706848     0.226439    0.0743919   -0.0725568   -0.158381     0.171366    0.727024   -0.283403    0.386111     -0.288572    0.18939    -0.137181    -0.0191143     0.423463 
 -0.359813      0.441439    0.28777     0.383602     0.65517      0.146502     0.478986    -0.490241     0.372417    -0.128584    0.0557397  -0.266797    0.286444     0.322216   -0.418453     0.596183    -0.517388     0.0150229   0.0526716  -0.160268   -0.202115     -0.329699   -0.154976   -0.334502    -0.000828858   0.147674 
 -0.279608     -0.127686   -0.0840004   0.507888     0.131705     0.306677    -0.249705    -0.0457137    0.230532     0.0384473  -0.148704   -0.339208    0.111713     0.187528    0.312026     0.0722953   -0.675903    -0.238154    0.299438   -0.152215   -0.0149309    -0.687444   -0.327816    0.790659     0.585483     -0.195966 
  0.0520044    -0.0638099   0.189771   -0.0592647   -0.368162    -0.148409    -0.234679     0.360624    -0.282599     0.125383   -0.123523    0.173048    0.0270121   -0.84389    -0.219455     0.101986    -0.0220674    0.16763     0.172493   -0.357842   -0.242317      0.466874   -0.478183   -0.199645     0.0734086    -0.0835996
  0.188308     -0.296706   -0.0770779  -0.00822256  -0.194551     0.141074    -0.161422     0.588219     0.38871     -0.043511   -0.026477    0.43881    -0.00040978   0.255824   -0.679718     0.0287278    0.410967    -0.0416658   0.0354663  -0.0560671  -0.262245      0.680249    0.0534499  -0.0143561   -0.143456     -0.171696 
  0.208958     -0.409477   -0.278845    0.308671    -0.0749251   -0.370864     0.128678     0.179683     0.0971064    0.0411168  -0.179329   -0.0995331   0.110943     0.264129   -0.106641     0.185494     0.0486699    0.0567216  -0.282108   -0.149964   -0.0379083    -0.434903   -0.186444   -0.197353     0.0879016     0.406792 
 -0.0371384    -0.0742808  -0.282697    0.128896    -0.105212    -0.447524    -0.00311804   0.447614    -0.347073    -0.0796657  -0.103321    0.579289   -0.458055     0.377821    0.257868     0.125734     0.0550051   -0.257871    0.0520119  -0.0995193  -0.162705      0.0667873  -0.112702   -0.0200285   -0.587257      0.449577 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411767
[ Info: iteration 2, average log likelihood -1.411755
[ Info: iteration 3, average log likelihood -1.411744
[ Info: iteration 4, average log likelihood -1.411734
[ Info: iteration 5, average log likelihood -1.411724
[ Info: iteration 6, average log likelihood -1.411713
[ Info: iteration 7, average log likelihood -1.411704
[ Info: iteration 8, average log likelihood -1.411694
[ Info: iteration 9, average log likelihood -1.411685
kind full, method kmeans
[ Info: iteration 10, average log likelihood -1.411676
â”Œ Info: EM with 100000 data points 10 iterations avll -1.411676
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.199852e+05
      1       7.075765e+05      -2.124087e+05 |       32
      2       6.929277e+05      -1.464879e+04 |       32
      3       6.873573e+05      -5.570441e+03 |       32
      4       6.843488e+05      -3.008479e+03 |       32
      5       6.825008e+05      -1.848012e+03 |       32
      6       6.812037e+05      -1.297071e+03 |       32
      7       6.802488e+05      -9.549410e+02 |       32
      8       6.795094e+05      -7.393959e+02 |       32
      9       6.788645e+05      -6.448952e+02 |       32
     10       6.783347e+05      -5.297735e+02 |       32
     11       6.778691e+05      -4.655543e+02 |       32
     12       6.774492e+05      -4.199650e+02 |       32
     13       6.770728e+05      -3.763709e+02 |       32
     14       6.767309e+05      -3.418706e+02 |       32
     15       6.764084e+05      -3.225567e+02 |       32
     16       6.761296e+05      -2.788074e+02 |       32
     17       6.758887e+05      -2.408784e+02 |       32
     18       6.756878e+05      -2.009090e+02 |       32
     19       6.754987e+05      -1.890967e+02 |       32
     20       6.753347e+05      -1.639719e+02 |       32
     21       6.751915e+05      -1.432422e+02 |       32
     22       6.750501e+05      -1.413758e+02 |       32
     23       6.749195e+05      -1.305652e+02 |       32
     24       6.747897e+05      -1.298568e+02 |       32
     25       6.746585e+05      -1.312098e+02 |       32
     26       6.745337e+05      -1.247329e+02 |       32
     27       6.744207e+05      -1.130229e+02 |       32
     28       6.743152e+05      -1.054891e+02 |       32
     29       6.742109e+05      -1.042685e+02 |       32
     30       6.741022e+05      -1.087452e+02 |       32
     31       6.740108e+05      -9.136924e+01 |       32
     32       6.739138e+05      -9.701340e+01 |       32
     33       6.738195e+05      -9.434305e+01 |       32
     34       6.737167e+05      -1.027442e+02 |       32
     35       6.736344e+05      -8.236982e+01 |       32
     36       6.735553e+05      -7.910421e+01 |       32
     37       6.734870e+05      -6.826891e+01 |       32
     38       6.734302e+05      -5.680343e+01 |       32
     39       6.733767e+05      -5.345441e+01 |       32
     40       6.733297e+05      -4.705021e+01 |       32
     41       6.732859e+05      -4.377511e+01 |       32
     42       6.732368e+05      -4.910300e+01 |       32
     43       6.731925e+05      -4.434625e+01 |       32
     44       6.731494e+05      -4.300223e+01 |       32
     45       6.731057e+05      -4.377244e+01 |       32
     46       6.730692e+05      -3.645647e+01 |       32
     47       6.730306e+05      -3.865717e+01 |       32
     48       6.729991e+05      -3.148607e+01 |       32
     49       6.729702e+05      -2.890623e+01 |       32
     50       6.729475e+05      -2.270366e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672947.4677457886)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423769
[ Info: iteration 2, average log likelihood -1.418710
[ Info: iteration 3, average log likelihood -1.417319
[ Info: iteration 4, average log likelihood -1.416253
[ Info: iteration 5, average log likelihood -1.415114
[ Info: iteration 6, average log likelihood -1.414068
[ Info: iteration 7, average log likelihood -1.413363
[ Info: iteration 8, average log likelihood -1.412979
[ Info: iteration 9, average log likelihood -1.412770
[ Info: iteration 10, average log likelihood -1.412637
[ Info: iteration 11, average log likelihood -1.412540
[ Info: iteration 12, average log likelihood -1.412461
[ Info: iteration 13, average log likelihood -1.412394
[ Info: iteration 14, average log likelihood -1.412334
[ Info: iteration 15, average log likelihood -1.412279
[ Info: iteration 16, average log likelihood -1.412229
[ Info: iteration 17, average log likelihood -1.412183
[ Info: iteration 18, average log likelihood -1.412140
[ Info: iteration 19, average log likelihood -1.412100
[ Info: iteration 20, average log likelihood -1.412063
[ Info: iteration 21, average log likelihood -1.412028
[ Info: iteration 22, average log likelihood -1.411996
[ Info: iteration 23, average log likelihood -1.411965
[ Info: iteration 24, average log likelihood -1.411937
[ Info: iteration 25, average log likelihood -1.411911
[ Info: iteration 26, average log likelihood -1.411886
[ Info: iteration 27, average log likelihood -1.411863
[ Info: iteration 28, average log likelihood -1.411841
[ Info: iteration 29, average log likelihood -1.411821
[ Info: iteration 30, average log likelihood -1.411802
[ Info: iteration 31, average log likelihood -1.411784
[ Info: iteration 32, average log likelihood -1.411767
[ Info: iteration 33, average log likelihood -1.411751
[ Info: iteration 34, average log likelihood -1.411735
[ Info: iteration 35, average log likelihood -1.411721
[ Info: iteration 36, average log likelihood -1.411707
[ Info: iteration 37, average log likelihood -1.411694
[ Info: iteration 38, average log likelihood -1.411681
[ Info: iteration 39, average log likelihood -1.411669
[ Info: iteration 40, average log likelihood -1.411657
[ Info: iteration 41, average log likelihood -1.411646
[ Info: iteration 42, average log likelihood -1.411635
[ Info: iteration 43, average log likelihood -1.411624
[ Info: iteration 44, average log likelihood -1.411614
[ Info: iteration 45, average log likelihood -1.411604
[ Info: iteration 46, average log likelihood -1.411595
[ Info: iteration 47, average log likelihood -1.411585
[ Info: iteration 48, average log likelihood -1.411576
[ Info: iteration 49, average log likelihood -1.411567
[ Info: iteration 50, average log likelihood -1.411559
â”Œ Info: EM with 100000 data points 50 iterations avll -1.411559
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.418406    0.227414    0.536009   -0.399205    0.460769     0.612758    0.314159   -0.151546    0.345409    0.040958    0.272099     0.112022   -0.553318    0.138988     0.20768    -0.0670719    0.0568082  -0.0328752   -0.0174687    0.280386   -0.186303    0.0246881   0.599708     0.657776     0.0821499   -0.449043 
  0.0720002  -0.261327    0.020194    0.292595    0.0426221   -0.154506    0.122639    0.0948598   0.0335414  -0.136776   -0.155531    -0.0747752   0.0928918   0.0558733   -0.188139    0.160541     0.0285889  -0.0488928   -0.247387     0.178484    0.0558831  -0.213346   -0.0535248   -0.0232137    0.233814     0.162056 
 -0.0796946  -0.244319   -0.588314    0.0866717   0.14148     -0.848019   -0.355954    0.123861   -0.0231592   0.445484   -0.601232     0.238531   -0.300004    0.75637     -0.112529    0.426706    -0.304621    0.182617    -0.0564745   -0.0329324  -0.364851   -0.07441     0.325064     0.288674    -0.171609     0.69239  
 -0.128042    0.254268   -0.179731   -0.527146   -0.146004    -0.055282   -0.138905   -0.160772   -0.403027    0.0770631   0.441012     0.514439   -0.600185   -0.180568     0.510219   -0.351648     0.277625    0.0238375    0.276136    -0.215384   -0.0414335   0.603516    0.194239     0.00688701  -0.526156    -0.244329 
  0.0163127   0.323543   -0.451848    0.307428   -0.318141    -0.180027    0.483166    0.866979   -0.0273111  -0.3551     -0.141559     0.171224   -0.067517    0.322457     0.0937785   0.106171    -0.0967081  -0.267356     0.296653    -0.304119   -0.0403307   0.153571   -0.265285    -0.554697    -0.1805       0.339403 
 -0.308891    0.318515    0.394857    0.443567    0.0779272    0.871067    0.0599135   0.443967    0.0475177  -0.321156    0.298214     0.234383    0.513507   -0.335417    -0.404724    0.00861415   0.0876789  -0.28785      0.432061     0.146947    0.481819    0.591745   -0.0421728    0.118456     0.554837    -0.87771  
 -0.0658073   0.567524   -0.0139375  -0.127604    0.194173     0.227817    0.389692   -0.250912    0.242358    0.308049   -0.0587029    0.0670174   0.250347    0.415752    -0.453592   -0.40388     -0.0991884   0.562179     0.564883     0.216344   -0.390166    0.394203    0.442145    -1.11934     -0.38913     -0.254967 
 -0.0349618  -0.208626    0.313349   -0.251824    0.0107728    0.382235   -0.237986   -0.284559    0.343791    0.414416    0.194924    -0.584804    0.97229     0.119933    -0.476639   -0.334197     0.538763    0.100351    -0.14205      0.0915863   0.347004   -0.288925    0.0636589   -0.0559133    0.31473     -0.215528 
  0.318967   -0.304923   -0.122665    0.139268   -0.219497     0.312433   -0.823735    0.129813    0.706905   -0.240958   -0.00115783  -0.17229    -0.0521359   0.0769626    0.856017   -0.975833     0.310114    0.0145621    0.338128     0.454594   -0.139245   -0.216606   -0.0955975    0.519167    -0.0278945   -0.131303 
  0.67        0.222565   -0.475282    0.453704   -0.707487     0.654578   -0.252899    0.212306   -0.0324987   0.301189    0.093326    -0.655798    0.0280416   0.642755     0.0831997  -0.0349832   -0.032744    0.177391    -0.613506    -0.353106    0.899232   -0.12463     0.0447504    0.369645     0.238268    -0.1178   
 -0.324979    0.469359   -0.104221    0.270171    0.466887     0.22944     0.423224   -0.410075    0.2047     -0.167901    0.0236281   -0.474004    0.168049    0.113315     0.145612    0.233067    -0.714365   -0.0488459    0.25156     -0.242687    0.0202703  -0.667761   -0.244867     0.201985     0.2686      -0.152658 
  0.0272631   0.460195    0.0524665  -0.325067   -0.252694     0.223881    0.0403891   0.358188   -0.335042    0.322144    0.0919245    0.0664959   0.523955    0.19406      0.154611   -0.0284346   -0.253842    0.302002     0.630537    -0.385656    0.518126    0.111524    0.285193     0.0505269   -0.33775      0.320165 
  0.177824   -0.275542   -0.0394803   0.397054    0.322112     0.327674    0.471965   -0.393942    0.204746   -0.614251    0.491594     0.16334    -0.0755888   0.406997     0.147316    0.254151     0.0198443  -0.0498948   -0.681489    -0.142245    0.134824   -0.0564472  -0.441079    -0.151897    -0.625952    -0.0996398
  0.14276     0.565588    0.301892    0.439057   -0.439789     0.200162    1.03234     0.459346    0.301966    0.24628     0.328455    -0.746532    0.0655043  -1.01976      0.424178    0.817737     0.320397   -0.148985    -0.211296    -0.187129   -0.150855    0.675624   -0.611219    -0.304058     0.252626    -0.741938 
  0.0181464  -0.0114844   0.208737   -0.596388   -0.0257124   -0.462652   -0.442718    0.493892   -0.195262    0.21377    -0.0531958   -0.765224   -0.348294   -0.531614    -0.0901285  -0.0406978   -0.276063    0.0847964    0.505978     0.0352388  -0.0844474   0.631648    0.0176509    0.487746     0.344717    -0.0897654
  0.271133   -0.363438   -0.268698   -0.254592   -0.238742    -0.455305   -0.108401    0.340075   -0.495913    0.0418353  -0.0338586    0.271111   -0.286021    0.0800922    0.0957662  -0.193217     0.654029   -0.131106    -0.153578     0.0919036   0.0117485   0.313825   -0.00604231  -0.0144435   -0.62738      0.228114 
 -0.0481262   0.272027    0.0401599  -0.227881   -0.00472232   0.0721857   0.0296354  -0.0400135  -0.127159    0.0716605   0.0408472   -0.0147058  -0.0349173   0.0254914    0.0809432  -0.0396903   -0.0426252   0.0444237    0.225686    -0.0553445  -0.0477815   0.165484    0.0311861    0.00420821  -0.11584     -0.108778 
  0.196535   -0.284276    0.0195666   0.390205   -0.0781572   -0.169409    0.148515    0.212      -0.0816694   0.0660444  -0.342665     0.139651    0.55001    -0.0325931   -0.21174     0.0913338   -0.207165    0.344345     0.0185554    0.0265022   0.161614   -0.381633    0.0774262   -0.187365     0.389822     0.341892 
 -0.0605109  -0.322451   -0.10635     0.294776    0.0433047    0.0043975  -0.244966   -0.0792127   0.0391612   0.0938669   0.218017    -0.0296927  -0.104232   -0.0250017    0.161521    0.172139    -0.074245   -0.194226    -0.186388    -0.0857264   0.0517965  -0.310708   -0.232373     0.273935     0.141697    -0.0563477
  0.198946   -0.580624    0.0312177   0.819736   -0.321321    -0.332997   -0.242543    0.423077    0.129146   -0.110082    0.362444     0.316557    0.153287   -0.368764    -0.274314    0.198121     0.131723   -0.110908    -0.0110962   -0.598331   -0.511075   -0.225219   -0.702659    -0.117992     0.0628585   -0.0842122
 -0.675426   -0.407419    0.167064   -0.225953   -0.559808    -0.152788    0.0331183   0.404067   -0.371045    0.247782   -0.516654    -0.203132    0.670902   -0.0750937    0.40085     0.494438     0.243011   -0.0636953    0.876935     0.158001    0.208981   -0.391738   -0.021414    -0.140122     0.10926      0.390521 
 -0.240206   -0.292868    0.514917    0.568573    0.45078     -0.339405   -0.0641592  -0.0834133   0.356254   -0.197388   -0.270974    -0.327345    0.242448    0.215555    -0.730284    1.04792     -0.363424   -0.596671     0.114556     0.266133   -0.561014   -0.375951   -0.776371    -0.0630131    0.204984     0.469276 
 -0.499008    0.171036    0.211486   -0.390398   -0.427418     0.33689    -0.738666   -0.341611   -0.0471439  -0.380495   -0.195787     0.57184    -0.328963   -0.247747    -0.23059    -0.812906    -0.396108   -0.171686    -0.0255029   -0.169201   -0.606901   -0.12784     0.00014884   0.359869     0.122656     0.0251617
  0.842568   -0.258811   -0.722359    0.445901   -0.0860904   -0.254932   -0.400267   -0.444615   -0.01416    -0.0492617  -0.766366     0.193799   -0.18823     0.216479    -0.589921    0.259127    -0.850002   -0.425171     0.0844738   -0.14613    -0.0833559   0.604148   -0.997059    -1.25633      0.09382      0.639897 
  0.388677   -0.398669   -0.224111   -0.273385   -0.0793961   -0.845413    0.0469707  -0.603507    0.210143    0.14115     0.125058    -0.303272   -0.0176585   8.23394e-5   0.503273   -0.146825     0.196064    0.544058    -0.735848    -0.109049   -0.383999   -0.865141    0.275893    -0.436411     0.104433     0.343984 
  0.105804   -0.281551    0.102396    0.0370511   0.135506     0.0617394   0.0253641   0.307756    0.59388    -0.24424    -0.0673101    0.188733   -0.298893    0.109009    -0.413025    0.170003     0.225099    0.00787727  -0.150886     0.157385   -0.248372    0.501064    0.0754682   -0.110149     0.0149104   -0.184733 
  0.0362028   0.209746    0.0756016  -0.600622    0.228337     0.220189   -0.128873   -0.539988   -0.48067     0.104903   -0.778314    -0.157031   -0.347898    0.455048     0.354514   -0.538979     0.0969238   0.294544    -0.0621491    0.96252     0.722828   -0.104991    0.42518      0.447023    -0.177395     0.200527 
 -0.591672   -0.0334447   0.497882   -0.40073     0.0944397   -0.396568   -0.0429472   0.0222372  -0.202432    0.239716   -0.17873      0.792224   -0.350013   -0.539858    -0.123361    0.421273     0.05276     0.0684102    0.142246    -0.122452   -0.504908    0.364285    0.122788    -0.593977    -0.334346     0.248552 
  0.419623   -0.237839   -0.20513    -0.0560037  -0.358626    -0.582196    1.15312     0.136528   -0.426076   -0.595346   -0.0618736   -0.495347   -0.243614   -0.144636    -0.778683    0.379253    -0.159126   -0.0518902   -0.535497     0.137742    0.795003    0.349492    0.337514     0.16784      0.00509386  -0.227541 
 -0.163944    0.462206   -0.193817    0.0281379   0.236573     0.162726    0.124205   -0.552855   -0.22973    -0.138459    0.327274    -0.162701    0.0269166  -0.367072     0.151139   -0.260108     0.445476   -0.683043     0.00277309   0.559341    0.101528   -0.115266    0.262627    -0.323638     0.348891    -0.117692 
  0.425912   -0.108413   -0.366408    0.487633    0.841207     0.094769   -0.477042   -0.453132    0.106115    0.116003    0.494343     0.135921   -0.642198   -0.299668    -0.27813    -0.299294     0.134684   -0.215181    -0.790555     0.155246   -0.0213338   0.342689   -0.212848    -0.0715167    0.18782     -0.582915 
 -0.632814    0.112344    0.135958    0.106638    0.458096     0.773928   -1.09075    -0.17413     0.0676194   0.804875   -0.0373214    0.323256    0.329536    0.126128     0.690127   -0.243094    -0.309111   -0.241652     0.811203    -0.320565   -0.700964   -0.456589   -0.221672     0.250145     0.156604    -0.050608 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411550
[ Info: iteration 2, average log likelihood -1.411542
[ Info: iteration 3, average log likelihood -1.411534
[ Info: iteration 4, average log likelihood -1.411526
[ Info: iteration 5, average log likelihood -1.411518
[ Info: iteration 6, average log likelihood -1.411510
[ Info: iteration 7, average log likelihood -1.411503
[ Info: iteration 8, average log likelihood -1.411495
[ Info: iteration 9, average log likelihood -1.411488
[ Info: iteration 10, average log likelihood -1.411481
â”Œ Info: EM with 100000 data points 10 iterations avll -1.411481
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
