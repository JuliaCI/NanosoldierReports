Julia Version 1.5.0-DEV.13
Commit dfcba8768f (2020-01-06 06:02 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed JLD ──────────────── v0.9.1
 Installed Distances ────────── v0.8.2
 Installed FileIO ───────────── v1.2.1
 Installed Parameters ───────── v0.12.0
 Installed BinDeps ──────────── v1.0.0
 Installed BinaryProvider ───── v0.5.8
 Installed Arpack ───────────── v0.4.0
 Installed StatsFuns ────────── v0.9.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed URIParser ────────── v0.4.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed OpenBLAS_jll ─────── v0.3.7+3
 Installed StatsBase ────────── v0.32.0
 Installed Clustering ───────── v0.13.3
 Installed Compat ───────────── v2.2.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed Missings ─────────── v0.4.3
 Installed QuadGK ───────────── v2.3.1
 Installed PDMats ───────────── v0.9.10
 Installed StaticArrays ─────── v0.12.1
 Installed LegacyStrings ────── v0.4.1
 Installed Distributions ────── v0.22.0
 Installed NearestNeighbors ─── v0.4.4
 Installed Blosc ────────────── v0.5.1
 Installed DataStructures ───── v0.17.7
 Installed Rmath ────────────── v0.6.0
 Installed SortingAlgorithms ── v0.3.1
 Installed OrderedCollections ─ v1.1.0
 Installed FillArrays ───────── v0.8.2
 Installed HDF5 ─────────────── v0.12.5
 Installed CMake ────────────── v1.1.2
 Installed DataAPI ──────────── v1.1.0
 Installed SpecialFunctions ─── v0.9.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.0
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+3
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_F1JoRn/Project.toml`
 [no changes]
  Updating `/tmp/jl_F1JoRn/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_hOEdj4/Project.toml`
 [no changes]
  Updating `/tmp/jl_hOEdj4/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_N63Kwh/Project.toml`
 [no changes]
  Updating `/tmp/jl_N63Kwh/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_FatRvc/Project.toml`
 [no changes]
  Updating `/tmp/jl_FatRvc/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_5VwSlA/Project.toml`
 [no changes]
  Updating `/tmp/jl_5VwSlA/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_5VwSlA/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.0
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.8562955312156714e6, [16250.322731575845, 83749.67726842416], [4635.99187018548 -2843.2191989686153 -7020.885155880287; -4414.569986326798 2712.1912455728598 7320.14823666147], [[11997.956880355398 3640.492105335534 3719.0791640521797; 3640.492105335534 12557.018374116806 -3796.0459206508185; 3719.0791640521793 -3796.0459206508185 12206.678859950965], [88331.19987490619 -3505.6445112709102 -4014.3088834324517; -3505.6445112709102 88049.85976146323 3477.213440558047; -4014.3088834324526 3477.2134405580464 87636.06587660678]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.236605e+03
      1       9.089356e+02      -3.276691e+02 |        5
      2       7.899572e+02      -1.189784e+02 |        2
      3       7.871515e+02      -2.805673e+00 |        0
      4       7.871515e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 787.1515144671366)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.056016
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.766935
[ Info: iteration 2, lowerbound -3.637099
[ Info: iteration 3, lowerbound -3.500267
[ Info: iteration 4, lowerbound -3.349073
[ Info: iteration 5, lowerbound -3.197695
[ Info: iteration 6, lowerbound -3.064858
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.961204
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.887098
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.819974
[ Info: iteration 10, lowerbound -2.770014
[ Info: iteration 11, lowerbound -2.743247
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.720054
[ Info: iteration 13, lowerbound -2.691528
[ Info: iteration 14, lowerbound -2.660647
[ Info: iteration 15, lowerbound -2.624076
[ Info: iteration 16, lowerbound -2.583078
[ Info: iteration 17, lowerbound -2.539763
[ Info: iteration 18, lowerbound -2.496686
[ Info: iteration 19, lowerbound -2.456045
[ Info: iteration 20, lowerbound -2.418875
[ Info: iteration 21, lowerbound -2.384970
[ Info: iteration 22, lowerbound -2.354033
[ Info: iteration 23, lowerbound -2.327811
[ Info: iteration 24, lowerbound -2.311069
[ Info: iteration 25, lowerbound -2.307906
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.302916
[ Info: iteration 27, lowerbound -2.299259
[ Info: iteration 28, lowerbound -2.299256
[ Info: iteration 29, lowerbound -2.299254
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Jan  6 19:00:26 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Jan  6 19:00:34 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Mon Jan  6 19:00:37 2020: EM with 272 data points 0 iterations avll -2.056016
5.8 data points per parameter
, Mon Jan  6 19:00:39 2020: GMM converted to Variational GMM
, Mon Jan  6 19:00:47 2020: iteration 1, lowerbound -3.766935
, Mon Jan  6 19:00:47 2020: iteration 2, lowerbound -3.637099
, Mon Jan  6 19:00:47 2020: iteration 3, lowerbound -3.500267
, Mon Jan  6 19:00:47 2020: iteration 4, lowerbound -3.349073
, Mon Jan  6 19:00:47 2020: iteration 5, lowerbound -3.197695
, Mon Jan  6 19:00:47 2020: iteration 6, lowerbound -3.064858
, Mon Jan  6 19:00:48 2020: dropping number of Gaussions to 7
, Mon Jan  6 19:00:48 2020: iteration 7, lowerbound -2.961204
, Mon Jan  6 19:00:48 2020: dropping number of Gaussions to 6
, Mon Jan  6 19:00:48 2020: iteration 8, lowerbound -2.887098
, Mon Jan  6 19:00:48 2020: dropping number of Gaussions to 4
, Mon Jan  6 19:00:48 2020: iteration 9, lowerbound -2.819974
, Mon Jan  6 19:00:48 2020: iteration 10, lowerbound -2.770014
, Mon Jan  6 19:00:48 2020: iteration 11, lowerbound -2.743247
, Mon Jan  6 19:00:48 2020: dropping number of Gaussions to 3
, Mon Jan  6 19:00:48 2020: iteration 12, lowerbound -2.720054
, Mon Jan  6 19:00:48 2020: iteration 13, lowerbound -2.691528
, Mon Jan  6 19:00:48 2020: iteration 14, lowerbound -2.660647
, Mon Jan  6 19:00:48 2020: iteration 15, lowerbound -2.624076
, Mon Jan  6 19:00:48 2020: iteration 16, lowerbound -2.583078
, Mon Jan  6 19:00:48 2020: iteration 17, lowerbound -2.539763
, Mon Jan  6 19:00:48 2020: iteration 18, lowerbound -2.496686
, Mon Jan  6 19:00:48 2020: iteration 19, lowerbound -2.456045
, Mon Jan  6 19:00:48 2020: iteration 20, lowerbound -2.418875
, Mon Jan  6 19:00:48 2020: iteration 21, lowerbound -2.384970
, Mon Jan  6 19:00:48 2020: iteration 22, lowerbound -2.354033
, Mon Jan  6 19:00:48 2020: iteration 23, lowerbound -2.327811
, Mon Jan  6 19:00:48 2020: iteration 24, lowerbound -2.311069
, Mon Jan  6 19:00:48 2020: iteration 25, lowerbound -2.307906
, Mon Jan  6 19:00:48 2020: dropping number of Gaussions to 2
, Mon Jan  6 19:00:48 2020: iteration 26, lowerbound -2.302916
, Mon Jan  6 19:00:48 2020: iteration 27, lowerbound -2.299259
, Mon Jan  6 19:00:48 2020: iteration 28, lowerbound -2.299256
, Mon Jan  6 19:00:48 2020: iteration 29, lowerbound -2.299254
, Mon Jan  6 19:00:48 2020: iteration 30, lowerbound -2.299254
, Mon Jan  6 19:00:48 2020: iteration 31, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 32, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 33, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 34, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 35, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 36, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 37, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 38, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 39, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 40, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 41, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 42, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 43, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 44, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 45, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 46, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 47, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 48, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 49, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: iteration 50, lowerbound -2.299253
, Mon Jan  6 19:00:48 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777392567, 178.0450922260745]
β = [95.95490777392567, 178.0450922260745]
m = [2.0002292577748615 53.85198717245862; 4.250300733269417 79.28686694435454]
ν = [97.95490777392567, 180.0450922260745]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119568374 -0.008953123827356104; 0.0 0.012748664777411744], [0.18404155547478468 -0.007644049042333872; 0.0 0.00858170516632394]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000013
avll from stats: -1.0075268803346649
avll from llpg:  -1.0075268803346569
avll direct:     -1.0075268803346569
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9992720977049862
avll from llpg:  -0.9992720977049862
avll direct:     -0.9992720977049862
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0127967    -0.0579982    0.0601392    0.0398349    -0.0936104  -0.0575899    0.0729      -0.017263    0.00306379    0.0644303    0.0238942    0.0193337    -0.0231316    0.0654002   -0.169731     -0.268736      0.200939    -0.0124119    0.0972661   -0.017939    0.0415935    0.14917     -0.135968     0.0268491   -0.0424738     0.0336991
  0.150949      0.212186    -0.0214466   -0.00211226   -0.0672962   0.228872     0.151685    -0.0548359   0.027664      0.0491305    0.0237454   -0.0121278     0.0161761   -0.0148646   -0.0586625     0.0594726     0.0801073    0.0822104    0.0999139   -0.115954    0.088287     0.0210079   -0.00301602  -0.0316123   -0.154207     -0.0231844
  0.0252203    -0.0734582   -0.125131     0.25142       0.133897    0.196743     0.0960722   -0.0161005  -0.0489399    -0.163692    -0.0801147    0.0219991    -0.0915543    0.19963     -0.084116      0.0812209    -0.118682    -0.0887938    0.0767136   -0.109398   -0.0679863   -0.14811      0.0141569   -0.0800072    0.109155     -0.0999618
 -0.132925     -0.184022    -0.102278    -0.0945369     0.0699727   0.0939795    0.0168524   -0.255743   -0.208172      0.0857965   -0.00068183  -0.0507229    -0.0346037   -0.0322773   -0.156787     -0.0292659     0.0409354   -0.0140986    0.0957498   -0.0576289  -0.00515693   0.0355187    0.0514208    0.0362139   -0.0395702    -0.0890203
 -0.0370212     0.0632621   -0.128247    -0.200338      0.0603933   0.0236309    0.0119156   -0.302217    0.0225715     0.0598859    0.0245851   -0.108205     -0.057252    -0.0393303   -0.0631893    -0.000787764  -0.00803908  -0.0244644    0.19548     -0.0292247   0.0836828    0.0737849   -0.126365    -0.0580159   -0.146253      0.00466615
  0.101517     -0.177471    -0.00634184  -0.110894     -0.0481586  -0.163903     0.00863887   0.0283252   0.0585125    -0.0725646   -0.0331909   -0.0878034    -0.13741     -0.0291314    0.181048      0.00245477   -0.0906442    0.00988179  -0.0222391    0.0808745   0.0495295   -0.031645    -0.0139766    0.131276    -0.0590712     0.22605
  0.012683     -0.1451      -0.095217    -0.0951538    -0.141732   -0.178865    -0.161185     0.0710111   0.120585      0.116976    -0.122277     0.00796158   -0.0777542    0.0583372   -0.147105     -0.108112     -0.0426215    0.0738725    0.0100262   -0.203322    0.0549617   -0.0315903   -0.0529639    0.173585     0.0894715     0.257859
 -0.0963733    -0.044195     0.214917    -0.208372     -0.0457733   0.0569186    0.0868888    0.252496   -0.0330797    -0.0336004   -0.0567776    0.257606      0.0195539    0.00661924   0.0911028     0.132024      0.14426     -0.137542    -0.139969    -0.0178144   0.0279265    0.00197059  -0.0438364    0.0484153   -0.0203631    -0.0327999
  0.00657278   -0.0354431    0.163632     0.0206891    -0.119017   -0.0900222    0.149575     0.0930177   0.0763182    -0.100604    -0.17791     -0.151267      0.00997997   0.0788836    0.02624       0.106639     -0.0290237   -0.0734653   -0.171202     0.0299371  -0.0755039    0.0369423    0.0502528    0.0140069    0.000171614   0.0200623
  0.119914     -0.021575    -0.0193885   -0.073506     -0.0565962  -0.115824     0.100948    -0.20981     0.0935607    -0.136483     0.0384916   -0.0588272    -0.00412447   0.0400666   -0.000526815  -0.172876     -0.147392    -0.241059     0.055969     0.0284251   0.0825195   -0.0557462   -0.197143    -0.00905221   0.0394376     0.116055
  0.108753      0.103322     0.0036867   -0.0573677    -0.244223   -0.0614388    0.0882453    0.0477472   0.0123108    -0.0335451    0.0234986   -0.00867177    0.0232078    0.162691    -0.00267354    0.0819751     0.0127529    0.152107     0.0963722    0.151234   -0.0657729    0.191276     0.126547     0.0039833   -0.0525883    -0.0947849
  0.0366807     0.136478     0.0835274   -0.0220782     0.0723947   0.00268992   0.0879896   -0.115536   -0.153495      0.0777094    0.111175     0.0540375     0.0191273    0.0314306   -0.151535     -0.0187642    -0.0108534   -0.0850925    0.00618103   0.0253799   0.149208    -0.0120805   -0.147367     0.0702529   -0.0540771     0.134565
  0.12383       0.0361667    0.0482823   -0.088333     -0.0867579   0.247479     0.0486618   -0.0423534  -0.0559148     0.0816744    0.0520419    0.0664789     0.100019    -0.316854     0.160618     -0.0468799     0.190666    -0.0622197    0.0035773    0.0913404   0.263885    -0.228428     0.0697207    0.204458     0.0359171    -0.0687624
  0.00921623   -0.042211     0.0305405    0.159855      0.039563   -0.0312359   -0.154314     0.15414     0.184317     -0.0242988   -0.0958987   -0.0196211     0.0157948    0.0203311    0.046194      0.219445     -0.190058     0.0140683   -0.0824753    0.0994082  -0.104339     0.0698541   -0.0215037    0.184392    -0.141684      0.170954
  0.00486519   -0.00833917  -0.102544    -0.000579349   0.1844      0.0481014   -0.1512      -0.078202    0.0253467    -0.222822     0.0540821   -0.107695      0.123243    -0.0580301   -0.0163852     0.00504557    0.0104588    0.00760412  -0.138405     0.0646842   0.132687     0.0364783    0.123426    -0.111467    -0.023359     -0.072924
 -0.0877233    -0.0477515   -0.10635      0.138697      0.0249193  -0.0561187    0.0108105    0.0162646  -0.108323      0.0809808   -0.100616     0.162968      0.0533631    0.00779668   0.0176036    -0.0163584    -0.104695    -0.0457786   -0.0754867    0.0199417   0.00448045   0.0209505    0.142574    -0.0885096   -0.074415      0.120764
  0.0858916    -0.081137     0.0558188   -0.0967361    -0.0248205   0.00127951   0.191997     0.048292   -0.0850439     0.0842565    0.133436    -0.0142555    -0.108116    -0.0335915   -0.0597492     0.153302      0.0801318    0.0646193   -0.0829783   -0.110834    0.0188642   -0.0880839   -0.0267851   -0.160526     0.114055      0.0053691
 -0.0219297    -0.169969    -0.0426521    0.113726     -0.0273838  -0.0320597   -0.0631434   -0.0300725  -0.287142     -0.0431284    0.0232728   -0.0402851    -0.118129    -0.0778727   -0.0442213     0.0263445    -0.0720298    0.0619214   -0.0999945   -0.136778   -0.0865962    0.110351    -0.0354042   -0.0733037    0.0750556    -0.134321
 -0.107359      0.106236    -0.00622152   0.0731108    -0.10863     0.0993121   -0.0726218   -0.110603   -0.0500924     0.00969788  -0.0335974   -0.0357474     0.0561187   -0.18009     -0.0566723    -0.115264     -0.0383875    0.162545    -0.0330573    0.162931    0.0222042   -0.00180135  -0.0318641   -0.0541203   -0.0149464     0.12476
  0.0816215     0.00685602   0.00229296  -0.176063     -0.030449   -0.0997425    0.0674244   -0.0681405  -0.0702891     0.0586141   -0.104792    -0.216622      0.0443964   -0.178346     0.19993      -0.103022      0.00430238   0.0792797   -0.0480071   -0.125551   -0.06697     -0.012848     0.045639    -0.0586263    0.0141928    -0.0490176
  0.0742773     0.0617221    0.0638552    0.0357162    -0.0024314  -0.0493576   -0.191213     0.0836589  -0.112762      0.0661016    0.0179225   -0.137784     -0.0668482   -0.10799     -0.264565      0.0560499    -0.0857766    0.0991789   -0.0682063   -0.124819   -0.0936004   -0.081688    -0.140032    -0.018444    -0.0517695    -0.116626
 -0.0607437    -0.0356913    0.0137326   -0.00476519   -0.0371388   0.154365    -0.00554617   0.0884512  -0.0438037     0.122454    -0.190606     0.000850651   0.0982958   -0.0406612   -0.0278503    -0.0158371     0.0913235   -0.0190954   -0.179993    -0.120948    0.076085    -0.0251776   -0.042914     0.0833652    0.0691445    -0.0626897
  0.0246657     0.0501527   -0.21148     -0.061962     -0.0873854   0.0871411   -0.1166       0.0269335  -0.0540514     0.0261971    0.0884103   -0.073735      0.00695499  -0.039215     0.0128579    -0.0581922    -0.018535    -0.0516847    0.161753     0.140908    0.0977822   -0.178294     0.130994    -0.0366763    0.0415669    -0.00674795
 -0.000308262  -0.0624401    0.127879     0.00525884   -0.131217    0.217704     0.136309    -0.0309439  -0.0176373     0.0547931   -0.100341    -0.0494461     0.0786539   -0.0360061    0.0508265     0.057669      0.0431299   -0.0877092    0.0639293   -0.0221152   0.0645078    0.0521296   -0.0306051    0.162182    -0.184467     -0.101828
 -0.276801      0.184474     0.0446322    0.085232     -0.0128182  -0.00922564  -0.0392086    0.0164226   0.111567     -0.145274    -0.232816     0.00728581    0.27268     -0.00785178  -0.129324     -0.256913     -0.0294886   -0.0295363   -0.164309    -0.0501471   0.154963     0.0144056    0.0501682    0.033287    -0.0713465    -0.0942225
  0.00962983    0.0795908    0.0228649   -0.0084407     0.0681151   0.00223845   0.0319666   -0.0437713   0.122448      0.0112438    0.0969213    0.0116458    -0.00244169  -0.0618045   -0.0709365    -0.0321158    -0.122662     0.0449647   -0.0387927    0.122294   -0.127648     0.0286824   -0.116633     0.231285    -0.126791     -0.0261975
 -0.0798458    -0.260882     0.10099     -0.185054      0.0472123   0.0143623   -0.063495     0.0389482  -0.0258447    -0.00605072  -0.00832016   0.0365637    -0.0484935   -0.196657     0.114746      0.016968     -0.0105739    0.111388    -0.00473815  -0.0229899  -0.075386    -0.0313889   -0.0563808    0.102342    -0.117627     -0.0975292
 -0.0942521    -0.28748      0.239783    -0.0573641    -0.012713    0.0099778    0.0706067   -0.149544    0.000952247   0.00659309   0.0430042    0.0281075     0.0889262    0.040754     0.0285045    -0.0160049     0.268964    -0.0209763   -0.0150059   -0.070206   -0.0354579   -0.00127928  -0.0579402   -0.0745765   -0.0170879     0.120166
  0.0838773    -0.0355217   -0.0209947   -0.193408     -0.111515    0.0701391    0.0366686   -0.165328    0.208983      0.0245005   -0.171299    -0.0638321     0.226324    -0.0526223   -0.0454039     0.0615051     0.0422227    0.15422      0.196727    -0.0785284   0.156574     0.126199     0.162931     0.171733    -0.00533351   -0.0355492
  0.11578       0.0334117    0.129831     0.0465555     0.0705219  -0.121404    -0.130768     0.205667    0.0236418     0.0324077    0.0693303    0.213423     -0.0979272    0.00976156   0.0533158     0.0362822     0.109215     0.0974432   -0.131402     0.0240469  -0.0713106   -0.158899    -0.00373942   0.0416112    0.0581538    -0.0742364
 -0.0689846    -0.0887083   -0.00621887   0.0521561     0.120812   -0.0268622    0.131033     0.1383      0.0444429     0.0476905   -0.0682723   -0.0906272     0.00597855  -0.0919154    0.0662014     0.0410663     0.0639257   -0.12651     -0.0535723   -0.156374    0.0914489    0.0751348    0.0998932    0.0468097   -0.0697936    -0.0318133
 -0.120039      0.064393     0.0123559   -0.0688261     0.0687371   0.0692877   -0.124871     0.0124804  -0.140568     -0.0286378    0.0190919   -0.167626     -0.021273    -0.0405619   -0.114341      0.0366104    -0.0883872   -0.168821    -0.143767    -0.0108789  -0.0967678   -0.164724     0.140437    -0.027165     0.00949435    0.0269191kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4117432648047092
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411827
[ Info: iteration 2, average log likelihood -1.411741
[ Info: iteration 3, average log likelihood -1.411210
[ Info: iteration 4, average log likelihood -1.406508
[ Info: iteration 5, average log likelihood -1.395054
[ Info: iteration 6, average log likelihood -1.387521
[ Info: iteration 7, average log likelihood -1.385805
[ Info: iteration 8, average log likelihood -1.385141
[ Info: iteration 9, average log likelihood -1.384659
[ Info: iteration 10, average log likelihood -1.384216
[ Info: iteration 11, average log likelihood -1.383752
[ Info: iteration 12, average log likelihood -1.383225
[ Info: iteration 13, average log likelihood -1.382517
[ Info: iteration 14, average log likelihood -1.381362
[ Info: iteration 15, average log likelihood -1.379938
[ Info: iteration 16, average log likelihood -1.378347
[ Info: iteration 17, average log likelihood -1.376922
[ Info: iteration 18, average log likelihood -1.376006
[ Info: iteration 19, average log likelihood -1.375358
[ Info: iteration 20, average log likelihood -1.374833
[ Info: iteration 21, average log likelihood -1.374377
[ Info: iteration 22, average log likelihood -1.373952
[ Info: iteration 23, average log likelihood -1.373534
[ Info: iteration 24, average log likelihood -1.373104
[ Info: iteration 25, average log likelihood -1.372655
[ Info: iteration 26, average log likelihood -1.372231
[ Info: iteration 27, average log likelihood -1.371869
[ Info: iteration 28, average log likelihood -1.371581
[ Info: iteration 29, average log likelihood -1.371363
[ Info: iteration 30, average log likelihood -1.371208
[ Info: iteration 31, average log likelihood -1.371106
[ Info: iteration 32, average log likelihood -1.371042
[ Info: iteration 33, average log likelihood -1.371002
[ Info: iteration 34, average log likelihood -1.370978
[ Info: iteration 35, average log likelihood -1.370964
[ Info: iteration 36, average log likelihood -1.370955
[ Info: iteration 37, average log likelihood -1.370950
[ Info: iteration 38, average log likelihood -1.370946
[ Info: iteration 39, average log likelihood -1.370944
[ Info: iteration 40, average log likelihood -1.370942
[ Info: iteration 41, average log likelihood -1.370941
[ Info: iteration 42, average log likelihood -1.370940
[ Info: iteration 43, average log likelihood -1.370940
[ Info: iteration 44, average log likelihood -1.370939
[ Info: iteration 45, average log likelihood -1.370939
[ Info: iteration 46, average log likelihood -1.370939
[ Info: iteration 47, average log likelihood -1.370939
[ Info: iteration 48, average log likelihood -1.370939
[ Info: iteration 49, average log likelihood -1.370939
[ Info: iteration 50, average log likelihood -1.370939
┌ Info: EM with 100000 data points 50 iterations avll -1.370939
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.411826690494032
│     -1.4117410266420483
│      ⋮
└     -1.3709386773987857
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.371060
[ Info: iteration 2, average log likelihood -1.370944
[ Info: iteration 3, average log likelihood -1.370474
[ Info: iteration 4, average log likelihood -1.366564
[ Info: iteration 5, average log likelihood -1.353965
[ Info: iteration 6, average log likelihood -1.342842
[ Info: iteration 7, average log likelihood -1.339612
[ Info: iteration 8, average log likelihood -1.338060
[ Info: iteration 9, average log likelihood -1.336833
[ Info: iteration 10, average log likelihood -1.335912
[ Info: iteration 11, average log likelihood -1.335277
[ Info: iteration 12, average log likelihood -1.334863
[ Info: iteration 13, average log likelihood -1.334590
[ Info: iteration 14, average log likelihood -1.334383
[ Info: iteration 15, average log likelihood -1.334203
[ Info: iteration 16, average log likelihood -1.334024
[ Info: iteration 17, average log likelihood -1.333838
[ Info: iteration 18, average log likelihood -1.333638
[ Info: iteration 19, average log likelihood -1.333416
[ Info: iteration 20, average log likelihood -1.333177
[ Info: iteration 21, average log likelihood -1.332936
[ Info: iteration 22, average log likelihood -1.332715
[ Info: iteration 23, average log likelihood -1.332518
[ Info: iteration 24, average log likelihood -1.332343
[ Info: iteration 25, average log likelihood -1.332185
[ Info: iteration 26, average log likelihood -1.332039
[ Info: iteration 27, average log likelihood -1.331906
[ Info: iteration 28, average log likelihood -1.331793
[ Info: iteration 29, average log likelihood -1.331700
[ Info: iteration 30, average log likelihood -1.331630
[ Info: iteration 31, average log likelihood -1.331580
[ Info: iteration 32, average log likelihood -1.331543
[ Info: iteration 33, average log likelihood -1.331513
[ Info: iteration 34, average log likelihood -1.331489
[ Info: iteration 35, average log likelihood -1.331469
[ Info: iteration 36, average log likelihood -1.331450
[ Info: iteration 37, average log likelihood -1.331433
[ Info: iteration 38, average log likelihood -1.331417
[ Info: iteration 39, average log likelihood -1.331401
[ Info: iteration 40, average log likelihood -1.331385
[ Info: iteration 41, average log likelihood -1.331368
[ Info: iteration 42, average log likelihood -1.331351
[ Info: iteration 43, average log likelihood -1.331333
[ Info: iteration 44, average log likelihood -1.331314
[ Info: iteration 45, average log likelihood -1.331293
[ Info: iteration 46, average log likelihood -1.331271
[ Info: iteration 47, average log likelihood -1.331248
[ Info: iteration 48, average log likelihood -1.331224
[ Info: iteration 49, average log likelihood -1.331201
[ Info: iteration 50, average log likelihood -1.331177
┌ Info: EM with 100000 data points 50 iterations avll -1.331177
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3710599526643725
│     -1.3709435498674134
│      ⋮
└     -1.3311768418109804
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.331334
[ Info: iteration 2, average log likelihood -1.331148
[ Info: iteration 3, average log likelihood -1.330754
[ Info: iteration 4, average log likelihood -1.327964
[ Info: iteration 5, average log likelihood -1.316593
[ Info: iteration 6, average log likelihood -1.300552
[ Info: iteration 7, average log likelihood -1.292464
[ Info: iteration 8, average log likelihood -1.288797
[ Info: iteration 9, average log likelihood -1.287013
[ Info: iteration 10, average log likelihood -1.286102
[ Info: iteration 11, average log likelihood -1.285546
[ Info: iteration 12, average log likelihood -1.285143
[ Info: iteration 13, average log likelihood -1.284807
[ Info: iteration 14, average log likelihood -1.284505
[ Info: iteration 15, average log likelihood -1.284229
[ Info: iteration 16, average log likelihood -1.283963
[ Info: iteration 17, average log likelihood -1.283675
[ Info: iteration 18, average log likelihood -1.283345
[ Info: iteration 19, average log likelihood -1.283018
[ Info: iteration 20, average log likelihood -1.282764
[ Info: iteration 21, average log likelihood -1.282571
[ Info: iteration 22, average log likelihood -1.282402
[ Info: iteration 23, average log likelihood -1.282209
[ Info: iteration 24, average log likelihood -1.281940
[ Info: iteration 25, average log likelihood -1.281525
[ Info: iteration 26, average log likelihood -1.280891
[ Info: iteration 27, average log likelihood -1.280162
[ Info: iteration 28, average log likelihood -1.279620
[ Info: iteration 29, average log likelihood -1.279325
[ Info: iteration 30, average log likelihood -1.279191
[ Info: iteration 31, average log likelihood -1.279129
[ Info: iteration 32, average log likelihood -1.279100
[ Info: iteration 33, average log likelihood -1.279084
[ Info: iteration 34, average log likelihood -1.279074
[ Info: iteration 35, average log likelihood -1.279067
[ Info: iteration 36, average log likelihood -1.279062
[ Info: iteration 37, average log likelihood -1.279058
[ Info: iteration 38, average log likelihood -1.279054
[ Info: iteration 39, average log likelihood -1.279051
[ Info: iteration 40, average log likelihood -1.279048
[ Info: iteration 41, average log likelihood -1.279045
[ Info: iteration 42, average log likelihood -1.279042
[ Info: iteration 43, average log likelihood -1.279039
[ Info: iteration 44, average log likelihood -1.279037
[ Info: iteration 45, average log likelihood -1.279034
[ Info: iteration 46, average log likelihood -1.279031
[ Info: iteration 47, average log likelihood -1.279028
[ Info: iteration 48, average log likelihood -1.279025
[ Info: iteration 49, average log likelihood -1.279021
[ Info: iteration 50, average log likelihood -1.279017
┌ Info: EM with 100000 data points 50 iterations avll -1.279017
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3313344692462987
│     -1.3311479539543745
│      ⋮
└     -1.279016746398611
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.279210
[ Info: iteration 2, average log likelihood -1.278975
[ Info: iteration 3, average log likelihood -1.277455
[ Info: iteration 4, average log likelihood -1.262957
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.229685
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.212955
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.200192
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.193443
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.187844
[ Info: iteration 10, average log likelihood -1.197300
[ Info: iteration 11, average log likelihood -1.183409
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.167270
[ Info: iteration 13, average log likelihood -1.207570
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.186155
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.180805
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.190965
[ Info: iteration 17, average log likelihood -1.189037
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.167996
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.193144
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.188204
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.180726
[ Info: iteration 22, average log likelihood -1.190511
[ Info: iteration 23, average log likelihood -1.175035
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.158156
[ Info: iteration 25, average log likelihood -1.212760
[ Info: iteration 26, average log likelihood -1.189039
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.168543
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.180898
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.179696
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.183937
[ Info: iteration 31, average log likelihood -1.190599
[ Info: iteration 32, average log likelihood -1.171220
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.149687
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.183260
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.186238
[ Info: iteration 36, average log likelihood -1.186259
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.161029
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.198216
[ Info: iteration 39, average log likelihood -1.187131
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.162500
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.161335
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.197077
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.181828
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.173932
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.177006
[ Info: iteration 46, average log likelihood -1.189308
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.164404
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.164610
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.183192
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.171171
┌ Info: EM with 100000 data points 50 iterations avll -1.171171
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2792102253225552
│     -1.2789745853400523
│      ⋮
└     -1.1711714652678296
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     5
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.184717
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.169864
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.160008
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     20
│     21
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.144201
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     15
│     17
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.125525
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     25
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.111022
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     17
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.110313
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     19
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.098289
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.077118
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.111695
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     15
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.106617
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.076910
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     20
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.084846
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.100441
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.093637
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     19
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.107643
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     20
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.087899
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.078974
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     15
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.117696
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     19
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.097302
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.081368
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.103973
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     15
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.109598
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     19
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.081663
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      5
│      6
│      ⋮
│     20
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.086747
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.095530
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     15
│     17
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.101400
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     19
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.094218
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     20
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.082373
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.087185
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     15
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.112568
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     19
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.094262
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.079895
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.103831
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     15
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.109481
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.081514
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     20
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.096251
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.090628
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     17
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.097724
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     19
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.102093
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     20
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.086751
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.079005
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     15
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.117691
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     19
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.097262
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.081343
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.103955
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     15
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.109589
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     19
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.081652
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      5
│      6
│      ⋮
│     20
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.086738
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.095519
┌ Info: EM with 100000 data points 50 iterations avll -1.095519
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1847171293166447
│     -1.1698644553667275
│      ⋮
└     -1.0955194647793776
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4117432648047092
│     -1.411826690494032
│     -1.4117410266420483
│     -1.411210355247675
│      ⋮
│     -1.0816524930973357
│     -1.086737553409043
└     -1.0955194647793776
32×26 Array{Float64,2}:
  0.0216501   -0.0929011  -0.117791      0.258795     0.0773671    0.217294      0.0804466  -0.0146279  -0.049443    -0.169533    -0.0740175    0.0243296    -0.0906522    0.19834     -0.0914338    0.0753944    -0.121856    -0.0877657    0.0809102   -0.115081   -0.0683939  -0.126418     0.00263245  -0.146124     0.105563    -0.0972912
  0.00397015  -0.112681   -0.0872012    -0.101479    -0.11931     -0.157381     -0.11829     0.0637611   0.120858     0.0922018   -0.116361    -0.00656451   -0.0656186    0.0406358   -0.153514    -0.138782     -0.0422488    0.0749922    0.0120458   -0.189001    0.0515976  -0.0220964   -0.0380442    0.174743     0.0875249    0.242756
  0.0977197    0.0701634  -0.0163698    -0.0828732   -0.27135     -0.0422198     0.0655708   0.0345088  -0.0475089   -0.0195799    0.0196151    0.00618288    0.0127982    0.139064     0.0576776    0.0744236     0.0437714    0.160901     0.0868499    0.132926   -0.0852871   0.187978     0.106151    -0.00929421  -0.0576355   -0.110542
 -0.195205    -0.0431887   0.0708165    -0.0357102    0.012158    -0.00639607   -0.0495077   0.0334294   0.0475399   -0.0836876   -0.130437     0.0179828     0.0780556   -0.103958    -0.0199062   -0.146077     -0.0175122    0.0286442   -0.0921415   -0.0576897   0.052655   -0.018548    -0.019537     0.0708604   -0.0968004   -0.0992258
 -0.0934242   -0.0124696   0.211233     -0.219398     0.241021     0.0116029     0.0876532   0.256591   -0.0759893   -0.0436491   -0.0574178    0.168002      0.0219598   -0.30775      0.091025     0.0516458     0.14635     -0.0506648   -0.141117    -0.0565716   0.0444622   0.00793451  -0.100712     0.101516    -0.0651272    0.0119699
 -0.101369    -0.0535076   0.241439     -0.191774    -0.44271      0.137692      0.0871532   0.241231   -0.0167646   -0.0749241   -0.0467822    0.389294      0.0193073    0.314125     0.0910977    0.22757       0.137802    -0.225513    -0.125773     0.0411216   0.0198586  -0.0169501    0.0487319   -0.0225304    0.0145925   -0.0794192
 -0.112903     0.10453    -0.0632173     0.0726625   -0.104031     0.0449172    -0.0265251  -0.108518   -0.0461004    0.0334988   -0.0355554   -0.03176      -0.00268029  -0.147881     0.196156    -0.108337     -0.0375458    0.163511    -0.0415388    0.14724    -0.53026    -0.0110645   -0.0197003   -0.0550519   -0.0107518    0.153195
 -0.103262     0.105388    0.0412547     0.0685948   -0.11336      0.200926     -0.111932   -0.105282   -0.0547812    0.00479307  -0.033652    -0.0315428     0.108834    -0.176001    -0.377432    -0.116873     -0.0382465    0.162976    -0.022052     0.173185    0.581362    0.0269597   -0.0472569   -0.056666    -0.0363327    0.192613
 -0.0782995   -0.341045    0.258868     -0.0545213    0.0133476    0.0203313     0.0809287  -0.152374   -0.0270702   -0.0197275    0.0373674    0.0695879     0.181481     0.0441165    0.0228962    0.0125456     0.234271     0.0279032   -0.0104863   -0.0863439  -0.0498843  -0.00778788  -0.429899     0.113555    -0.109756     0.132128
 -0.100945    -0.221761    0.197479     -0.0440488   -0.00903703  -0.000302697   0.0617713  -0.148595    0.018325     0.024642     0.0420924   -0.0745716     0.038172     0.042901     0.038704    -0.029127      0.280688    -0.0240382   -0.0237093   -0.0438089  -0.021387    0.025236     0.275944    -0.259332     0.0235423    0.111403
  0.148413     0.125271    0.0720596    -0.0467427    0.0340279   -0.031746      0.089075   -0.498015   -0.144721     0.249218     0.11165      0.0896175     0.0345082    0.0451772   -0.140658    -0.00639885    0.0846863   -0.103269    -0.00605666   0.0799934   0.144034    0.123078    -0.144983     0.0491354   -0.0282841    0.128561
 -0.188187     0.140858    0.0875635     0.0127306    0.0976585    0.0758617     0.0925728   0.319839   -0.162546    -0.0851455    0.110585    -0.000662723   0.00397362   0.0364819   -0.177121    -0.0434893    -0.163787    -0.0632008    0.0186903   -0.0592056   0.149942   -0.100949    -0.0746532    0.15917     -0.140123     0.139789
  0.0761741   -0.614695   -0.00964817   -0.190429    -0.106027     0.0630441     0.0365387  -0.0569074   0.356577     0.0283862   -0.161524    -0.0626901     0.218197    -0.0895653   -0.040307     0.0661008    -0.00533253   0.103061     0.208757    -0.170619    0.155031    0.173782     0.118552     0.11304     -0.00264185   0.0233103
  0.080749     0.545174   -0.0176769    -0.196463    -0.109927     0.0899213     0.0395457  -0.252805    0.161729     0.0195805   -0.173776    -0.05419       0.231363    -0.015373    -0.0560594    0.0531499     0.0760368    0.157208     0.219411    -0.0213286   0.161529    0.131325     0.195365     0.181716    -0.00739506  -0.0801389
  0.140559     0.214832   -0.000692675  -0.00497381  -0.0675055    0.235262      0.147256   -0.0580531   0.0125539    0.0376572    0.00726774  -0.0167869     0.0038145   -0.0143913   -0.0589934    0.0269184     0.0719098    0.0898626    0.105616    -0.128477    0.0881894   0.0200538   -0.00593108  -0.0351207   -0.144626    -0.0215228
  0.0152163    0.0180322  -0.220617     -0.0698616   -0.0758413    0.0709625    -0.123973    0.0258966  -0.0575494    0.035148     0.071117    -0.0764556     0.00637509  -0.0301306    0.0157398   -0.0443106    -0.0148867   -0.0611217    0.158121     0.129851    0.0853842  -0.183644     0.134342    -0.00600755   0.0393686   -0.00672507
 -0.00107015  -0.0199067  -0.0992517    -0.00154681   0.172475     0.0567504    -0.132103   -0.0351461   0.0103867   -0.144117     0.0161878   -0.0902984     0.109039    -0.0668297    0.00156535   0.0549478     0.0228793   -0.00248007  -0.133799     0.0674101   0.141023    0.0181844    0.0972945   -0.0672892   -0.0599215   -0.0711127
 -0.0804312   -0.0984254  -0.00234991    0.0537118    0.131614    -0.041372      0.15869     0.149693    0.00743055   0.0650104   -0.0486369   -0.0939382     0.020062    -0.148073     0.0828248    0.0368439     0.0623527   -0.124383    -0.0182173   -0.161039    0.134932    0.0570109    0.0903026    0.086103    -0.0788306   -0.0268131
  0.0129499    0.0681522   0.0158137    -0.00885483   0.0729242    0.0106529     0.0356171  -0.0491077   0.120843     0.0181422    0.0978465    0.0143493    -0.053494    -0.0209459   -0.133218    -0.0317188    -0.111945     0.0773627   -0.048054     0.148064   -0.122571    0.0353775   -0.115378     0.210439    -0.125439    -0.0277544
 -0.0233276   -0.178599   -0.0420346     0.11427     -0.0376529   -0.0253503    -0.0714804   0.0116515  -0.285399    -0.120407     0.024186    -0.00467465   -0.112155    -0.0889523   -0.0316403   -0.00514625   -0.0623034    0.0538238   -0.115528    -0.141164   -0.0814444   0.0600246   -0.00388463  -0.0453736    0.0671656   -0.124658
  0.0691332    0.0613597   0.0622332     0.0292026   -0.00245519  -0.0698243    -0.185       0.0890644  -0.125601     0.101516     0.0281161   -0.14311      -0.066673    -0.0988184   -0.273271     0.0357101    -0.0797579    0.0969326   -0.0671499   -0.158424   -0.0868892  -0.0737682   -0.150757    -0.00781692  -0.0882841   -0.103629
  0.114268     0.0211527  -0.00993419   -0.186032    -0.0304774   -0.115508      0.0753826  -0.0725371  -0.0582803    0.0765961   -0.103021    -0.216767      0.046184    -0.200154     0.194375    -0.0903731     0.00639197   0.0779039   -0.0126704   -0.122804   -0.0622819  -0.0140548    0.0325236   -0.0272043    0.0153728   -0.0432564
  0.00912966  -0.0581206   0.0254716     0.15617      0.0373748   -0.0325246    -0.152008    0.134369    0.18168     -0.00977068  -0.0835962   -0.012725      0.0284085   -0.00135357   0.0335014    0.205951     -0.16484      0.0100955   -0.0770977    0.0848147  -0.0969573   0.0695023   -0.0209433    0.18247     -0.124616     0.155901
 -0.081235     0.0164728  -0.0482352    -0.107727     0.0829487    0.0299466    -0.0393665  -0.135504   -0.118967     0.0176384    0.022069    -0.14153      -0.0535217   -0.0549424   -0.0656026    0.017097     -0.0482938   -0.0976329    0.0186145   -0.0458274  -0.0166562  -0.0301291    0.00727908  -0.080221    -0.0567663    0.00668375
 -0.126935    -0.183308   -0.0833448    -0.083146     0.0531379    0.134888      0.0124443  -0.246423   -0.19891      0.0898317   -0.0047246   -0.0477042    -0.0143788   -0.0388786   -0.115749    -0.0148787     0.048587    -0.0069574    0.109452    -0.056036   -0.0362706   0.0185578    0.0838122    0.0342264   -0.0707252   -0.0797168
 -0.0376159    0.0147335   0.11643       0.00916477  -0.156067     0.203479      0.137968   -0.0294205  -0.00521602   0.0490322   -0.0962707   -0.0253688     0.0739417   -0.048271     0.0722791    0.0592311     0.0416419   -0.082615     0.0608608   -0.033752    0.0483294   0.0643381    0.0241498    0.164113    -0.166979    -0.0548342
  0.110638     0.0379158   0.113985      0.0541611    0.0649025   -0.143331     -0.104616    0.189377    0.0590771    0.0329731    0.0649614    0.194363     -0.100136     0.0135359    0.0711927    0.034718      0.0811223    0.0915374   -0.134561     0.0211446  -0.0911343  -0.151206    -0.0103471    0.0331882    0.0559734   -0.0380513
 -0.0111787   -0.0727264   0.0232494     0.0211074   -0.0942862   -0.0521449     0.0770848  -0.0300552   0.0170622    0.0630827    0.0239787    0.0181894    -0.0036774    0.0795156   -0.174643    -0.270132      0.198303    -0.0150863    0.118999    -0.0373401   0.0457679   0.150942    -0.141922     0.0300249   -0.00617759   0.0485366
  0.12109      0.0636191   0.0494035    -0.0885443   -0.0712052    0.245193      0.0543339  -0.0413039  -0.0623394    0.0872823    0.0557101    0.0544223     0.110852    -0.313612     0.167744    -0.000653965   0.183751    -0.0246511    0.0169245    0.0826301   0.254882   -0.229525     0.067862     0.192387     0.0572144   -0.0860678
  0.0851143   -0.0810379   0.054106     -0.0991784    0.019361     0.00694626    0.151461    0.0304825  -0.0921547    0.0734663    0.137208    -0.0227829    -0.139552    -0.0160995   -0.0859777    0.178516      0.0853704    0.0647574   -0.0762634   -0.115582    0.0420961  -0.0839906   -0.0252097   -0.156635     0.14239     -0.0285677
 -0.0439895   -0.0357076   0.0263247     0.0473857   -0.0739338   -0.00478015    0.0558142   0.0752175  -0.0146601    0.0328945   -0.184276    -0.0170643     0.0500774    0.0222449    0.00939116   0.0336389    -0.0218346   -0.0251811   -0.152637    -0.0196142  -0.0159392   0.0164983    0.0430162    0.00112146  -0.00417527   0.0391245
  0.103966    -0.0919996  -0.013775     -0.06184     -0.0518793   -0.134967      0.0613654  -0.082637    0.0824164   -0.108773    -0.0053765   -0.0550194    -0.0674653    0.00327908   0.0754493   -0.103569     -0.108863    -0.113644     0.021088     0.0651644   0.058578   -0.0343544   -0.120341     0.0252373   -0.00796987   0.154505[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     15
│     17
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.101391
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      5
│      6
│      ⋮
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.064762
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.079166
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.057280
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.097381
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      5
│      6
│      ⋮
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.067011
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.084381
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.062977
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     20
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.091987
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      5
│      6
│      ⋮
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.069397
┌ Info: EM with 100000 data points 10 iterations avll -1.069397
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.445959e+05
      1       6.864099e+05      -2.581861e+05 |       32
      2       6.593947e+05      -2.701515e+04 |       32
      3       6.440804e+05      -1.531428e+04 |       32
      4       6.351617e+05      -8.918723e+03 |       32
      5       6.300103e+05      -5.151367e+03 |       32
      6       6.266833e+05      -3.327042e+03 |       32
      7       6.243924e+05      -2.290891e+03 |       32
      8       6.226648e+05      -1.727559e+03 |       32
      9       6.213875e+05      -1.277295e+03 |       32
     10       6.202745e+05      -1.113023e+03 |       32
     11       6.192730e+05      -1.001573e+03 |       32
     12       6.185487e+05      -7.242083e+02 |       32
     13       6.181334e+05      -4.153013e+02 |       32
     14       6.178952e+05      -2.382610e+02 |       32
     15       6.177354e+05      -1.598002e+02 |       31
     16       6.175941e+05      -1.412551e+02 |       31
     17       6.174635e+05      -1.306641e+02 |       32
     18       6.173296e+05      -1.338720e+02 |       32
     19       6.172150e+05      -1.146393e+02 |       32
     20       6.171493e+05      -6.569097e+01 |       31
     21       6.171217e+05      -2.756145e+01 |       30
     22       6.171070e+05      -1.466952e+01 |       30
     23       6.170975e+05      -9.568899e+00 |       28
     24       6.170916e+05      -5.821442e+00 |       28
     25       6.170872e+05      -4.445221e+00 |       25
     26       6.170825e+05      -4.709281e+00 |       28
     27       6.170771e+05      -5.341812e+00 |       27
     28       6.170731e+05      -4.087553e+00 |       25
     29       6.170703e+05      -2.797117e+00 |       25
     30       6.170671e+05      -3.129108e+00 |       22
     31       6.170649e+05      -2.195440e+00 |       16
     32       6.170637e+05      -1.268102e+00 |       14
     33       6.170629e+05      -8.161634e-01 |       13
     34       6.170622e+05      -6.052778e-01 |       11
     35       6.170620e+05      -2.731307e-01 |        9
     36       6.170616e+05      -3.222799e-01 |        8
     37       6.170615e+05      -1.834096e-01 |        6
     38       6.170613e+05      -1.647209e-01 |        8
     39       6.170610e+05      -2.761912e-01 |        8
     40       6.170607e+05      -3.123813e-01 |        7
     41       6.170604e+05      -3.408658e-01 |        9
     42       6.170600e+05      -3.468437e-01 |        6
     43       6.170599e+05      -1.665589e-01 |        6
     44       6.170596e+05      -2.120889e-01 |        8
     45       6.170595e+05      -1.934308e-01 |        7
     46       6.170593e+05      -1.402354e-01 |        7
     47       6.170590e+05      -3.175334e-01 |        6
     48       6.170587e+05      -2.483803e-01 |        5
     49       6.170586e+05      -1.840082e-01 |        6
     50       6.170584e+05      -1.649450e-01 |        5
K-means terminated without convergence after 50 iterations (objv = 617058.3983313064)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.332805
[ Info: iteration 2, average log likelihood -1.302523
[ Info: iteration 3, average log likelihood -1.274023
[ Info: iteration 4, average log likelihood -1.241545
[ Info: iteration 5, average log likelihood -1.201959
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.151413
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     21
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.139408
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.133902
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.086411
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.094954
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     13
│     20
│     21
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.083127
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.143875
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.093075
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.065046
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     13
│     21
│     23
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.067069
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.135229
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.079385
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     15
│     19
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.073327
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     23
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.109552
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.101070
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│     12
│     13
│     15
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.052127
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     19
│     20
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.098289
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.136991
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.098630
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     12
│     13
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.058767
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     15
│     19
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.081545
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.117532
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.104245
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     12
│     13
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.062469
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     15
│     19
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.094319
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.121631
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.075606
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│     12
│     13
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.068818
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.096209
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     20
│     21
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.106004
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.116472
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.098143
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     15
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.059517
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      8
│     21
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.051649
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.137743
[ Info: iteration 41, average log likelihood -1.133818
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.076378
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      8
│     12
│     13
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.050402
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.136258
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.094928
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.086180
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      8
│     12
│     13
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.057625
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.115231
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.093081
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     20
│     23
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.067721
┌ Info: EM with 100000 data points 50 iterations avll -1.067721
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.078145    -0.0145156   -0.013785    -0.193542     -0.107918      0.0768796     0.0381587   -0.157609    0.256015     0.0237738   -0.167789    -0.0583304    0.22498      -0.0516566   -0.0484305    0.059253     0.0364425     0.130969     0.214113    -0.0943091    0.158238    0.152604     0.158057     0.148524    -0.00497804   -0.0302287
 -0.105607    -0.0646374   -0.112147     0.13973      -0.000537296  -0.0401448    -0.011752     0.0166072  -0.105688     0.0831942   -0.144487     0.162653     0.0676965     0.00656492   0.0281695   -0.00343428  -0.109451     -0.0346187   -0.0684699    0.0172856   -0.0375051   0.0454783    0.131857    -0.104281    -0.0698809     0.0781166
 -0.0843757   -0.218982     0.0771912   -0.166864      0.0265221     0.00504388   -0.0758659    0.0380083  -0.009457    -0.0170904   -0.0203307    0.0300434   -0.0386582    -0.141016     0.0917878   -0.0135675    0.000531238   0.109479    -0.0115545   -0.0161763   -0.0458672  -0.0206025   -0.0479715    0.0993725   -0.118684     -0.101058
 -0.0786454    0.0834916    0.452656     0.219823      0.0912844    -0.400313     -0.259123     0.113846    0.184171    -0.0359894   -0.0533836    0.120119    -0.173793      0.0179197   -0.0610974   -0.0400094    0.0135013     0.0368075   -0.110483    -0.00598251  -0.0994488  -0.0425428    0.0874661    0.102448    -0.00831203   -0.0865013
 -0.134991    -0.0447645    0.0333323   -0.0593199     0.489129      0.0887562     0.053016     0.0142049  -0.423595    -0.00608229  -0.0187427   -0.124797     0.0245249    -0.0789569   -0.289242    -0.0327588   -0.040732     -0.0948062   -0.117449    -0.055308    -0.0333338  -0.0920684    0.150592     0.0766566   -0.312739      0.0105605
  0.103359    -0.172936    -0.00260751  -0.0946814    -0.0467519    -0.169474      0.0216675    0.0316992   0.0651039   -0.105471    -0.0648185   -0.0851438   -0.134609     -0.0318991    0.165276    -0.00267261  -0.0843994     0.0117716   -0.0319399    0.106124     0.0223936  -0.0286599   -0.0175686    0.112833    -0.0554229     0.217702
 -0.0639664   -0.0740077   -0.0222107    0.0428407     0.133983     -0.0175909     0.0945476    0.108141   -0.0048037    0.0134324   -0.0282746   -0.0896956    0.0356646    -0.122017     0.0715977    0.0415318    0.0628729    -0.0980624   -0.044376    -0.138567     0.133936    0.0483609    0.0904406    0.0549233   -0.0630277    -0.0375618
 -0.00258113  -0.0303078    0.176397     0.0184497    -0.155246     -0.0994393     0.134004     0.108924    0.0758242   -0.076583    -0.18375     -0.14804      0.00691007    0.0819059    0.0223056    0.104911    -0.0331034    -0.0289345   -0.182161     0.0283248   -0.0707649   0.0361699    0.0385737    0.011608    -0.000863681   0.0158036
 -0.0106972    0.132603     0.079496    -0.0184031     0.0643687     0.0201022     0.0906863   -0.108278   -0.15328      0.0904964    0.111083     0.0471124    0.0203989     0.0408513   -0.15798     -0.0228101   -0.0337616    -0.0844723    0.0056737    0.0147136    0.147054    0.0173069   -0.11225      0.103026    -0.0816547     0.134282
  0.0897553   -0.0782393    0.0531693   -0.0958609     0.021874      0.0131644     0.144761     0.0276062  -0.0928399    0.0713369    0.133441    -0.0200274   -0.128634     -0.019835    -0.0805485    0.17037      0.090145      0.0638144   -0.0787995   -0.113797     0.0522236  -0.0859249   -0.0189057   -0.146553     0.138105     -0.0260556
 -0.0700011    0.0667937    0.0564022    0.0370782    -0.144234      0.175265      0.045936    -0.0678003  -0.0250882    0.0304582   -0.0638892   -0.0338498    0.0633913    -0.102742    -0.00170325  -0.0236517    0.00272102    0.0350573    0.01682      0.0598069    0.0302542   0.0361609   -0.00719202   0.0545265   -0.100817      0.0554664
 -0.124807    -0.171423    -0.0852251   -0.0834172     0.0482832     0.137396      0.0216454   -0.248488   -0.204155     0.0798057   -0.00426232  -0.0537946   -0.00839032   -0.0329144   -0.0975013   -0.0275334    0.0500921    -0.00160086   0.112399    -0.0487308   -0.0275124   0.0263592    0.0718752    0.0355836   -0.0524678    -0.0875225
  0.0142227    0.0753737    0.016264    -0.00718738    0.0746295     0.000864338   0.0388005   -0.0464466   0.123685     0.0143659    0.0915712    0.0140464   -0.0461739    -0.0225408   -0.142244    -0.0336482   -0.113064      0.0793689   -0.0413209    0.150461    -0.126234    0.0410389   -0.120605     0.2031      -0.126218     -0.0267503
  0.0214023   -0.0169049    0.114734    -0.0270043    -0.0385833     0.128098      0.109018    -0.102205    0.00776134   0.014082     0.0164039   -0.00915678   0.0628031     0.0133014   -0.0152127    0.00216352   0.161563      0.0487308    0.0420623   -0.0925861    0.0328456   0.0145133   -0.0353334   -0.0561299   -0.0947953     0.0436931
  0.124629     0.0662682    0.0471013   -0.0885172    -0.0768357     0.249127      0.0461396   -0.0426161  -0.0615631    0.0839824    0.0396745    0.053642     0.112251     -0.323386     0.170456    -0.00860507   0.18497      -0.0247019    0.0137494    0.0898765    0.263784   -0.228455     0.0604355    0.204554     0.0481088    -0.084916
  0.00897535  -0.055677     0.0272527    0.157456      0.0393583    -0.032463     -0.151023     0.138693    0.187261    -0.00876318  -0.0850029   -0.0128045    0.028867      0.00299031   0.0339893    0.205066    -0.170539      0.0111091   -0.0750905    0.0941725   -0.0991027   0.0749533   -0.0207471    0.180494    -0.134527      0.164678
  0.0144849    0.0178994   -0.222189    -0.0714346    -0.0736299     0.069867     -0.123752     0.0275884  -0.0612864    0.0286926    0.0720229   -0.0769657    0.00258927   -0.0317449    0.0131407   -0.0470205   -0.0140685    -0.0576777    0.156364     0.131136     0.0871322  -0.17933      0.131407    -0.00674077   0.0400658    -0.00702496
 -0.038579     0.0895802   -0.152072    -0.188575      0.0804561     0.00973469    0.0495525   -0.32353     0.011154     0.0456124    0.0237511   -0.108326    -0.0642868    -0.0416215   -0.0603927   -0.0030427   -0.00900195   -0.0277432    0.19766     -0.0491634    0.0840932   0.0360064   -0.133055    -0.0610958   -0.166944      0.0414425
  0.0857767    0.0623991    0.127211     0.0599362     0.0791699    -0.17254      -0.118031     0.180835    0.0597382    0.0204614    0.0472132    0.190517    -0.0854913     0.012661     0.0547061    0.0113632    0.085246      0.0838426   -0.138889     0.0181981   -0.0620206  -0.134842    -0.00721571   0.0531959    0.0476292    -0.0359747
  0.0676045    0.0590889    0.0560255    0.0293412    -0.00249475   -0.0626463    -0.183881     0.0819009  -0.115565     0.100177     0.0413805   -0.143977    -0.0622572    -0.0910969   -0.276209     0.0413365   -0.0769876     0.0948141   -0.0710264   -0.149355    -0.0755607  -0.0717057   -0.132086    -0.00912061  -0.102397     -0.101694
 -0.00341017  -0.00970959  -0.109542    -0.000926147   0.178979      0.0584046    -0.142199    -0.058632    0.00816629  -0.160488     0.00229454  -0.0949328    0.133842     -0.083406     0.00453664   0.0513765   -0.00399875    0.00211934  -0.131514     0.121632     0.124932    0.0387957    0.0897131   -0.0899466   -0.0504933    -0.0696034
  0.121595    -0.0147637   -0.0247828   -0.0291159    -0.068913     -0.137116      0.109108    -0.190551    0.0930341   -0.119284     0.0353308   -0.0440004   -0.0267123     0.0397379   -0.00680545  -0.186633    -0.144632     -0.240383     0.0567195    0.0340207    0.0912025  -0.0522217   -0.204492    -0.0288607    0.0376676     0.0922308
 -0.119746     0.0110103    0.042096    -0.0691038     0.104983      0.059611     -0.11925      0.0225971  -0.171563    -0.0114228    0.0155856   -0.188666    -0.0178053    -0.0397487   -0.0712196    0.0277439   -0.0845504    -0.194998    -0.138658    -0.0334015   -0.0954112  -0.137082     0.149976    -0.0879517    0.0141469     0.0281502
  0.00241517  -0.123863    -0.0929078   -0.109508     -0.105185     -0.166772     -0.13525      0.0654899   0.124773     0.108256    -0.128402    -0.00796061  -0.0810765     0.0394515   -0.163116    -0.14284     -0.0421162     0.0701694    0.00954645  -0.201084     0.0442033  -0.0214875   -0.036956     0.18639      0.090777      0.266373
 -0.275953     0.185694     0.0321593    0.121311     -0.0578495    -0.018435      0.00175444   0.011368    0.123733    -0.125543    -0.25285      0.00610035   0.233306     -0.0213596   -0.123458    -0.259429    -0.045441     -0.0349806   -0.145421    -0.0671859    0.134132    0.0317225    0.0711525    0.0330255   -0.0714906    -0.0896504
 -0.0128246   -0.0710678    0.0235301    0.0195062    -0.0938414    -0.0530225     0.0814224   -0.0270647   0.0191812    0.0601979    0.0240109    0.0172107   -0.000738131   0.0834943   -0.175169    -0.270053     0.199855     -0.017539     0.110041    -0.0369371    0.0476282   0.148257    -0.143466     0.0283423   -0.00583739    0.0489546
  0.0222935   -0.0857663   -0.117605     0.253374      0.0692014     0.220237      0.0822005   -0.0139064  -0.0491996   -0.165123    -0.0736654    0.0217225   -0.0893743     0.198688    -0.0910722    0.0728988   -0.120535     -0.0878995    0.0807292   -0.113097    -0.0698257  -0.118667     0.00379379  -0.140274     0.105145     -0.0965326
  0.0909225    0.116243    -0.0189552   -0.0341469    -0.310958     -0.0545615     0.0915861    0.0530259   0.0277627   -0.0473144    0.00591767   0.00208497   0.0191767     0.150092    -0.00615849   0.0389884    0.0518701     0.147377     0.0606861    0.118324    -0.056442    0.153625     0.0964976   -0.0548662   -0.0469727    -0.111609
 -0.0964415   -0.0287375    0.22618     -0.204177     -0.10414       0.0885612     0.085673     0.239515   -0.0484491   -0.0583243   -0.0505137    0.269283     0.0212752     0.00469299   0.0896504    0.132707     0.139694     -0.127454    -0.128369    -0.00344054   0.0323346   0.00170519  -0.0206547    0.043349    -0.0225853    -0.0321809
 -0.0598398   -0.0384348    0.00442606  -0.0161302    -0.0356723     0.160622      0.0046922    0.0919683  -0.0465745    0.122346    -0.17937     -0.0171276    0.129073     -0.0390514   -0.0329054   -0.0406567    0.0892309    -0.0184907   -0.178364    -0.121779     0.0833953  -0.0408989   -0.0367693    0.0797744    0.0657012    -0.00540396
 -0.0307043   -0.1671      -0.0424661    0.11129      -0.0369832    -0.0262458    -0.0571737    0.0145567  -0.247543    -0.0906853    0.0221011   -0.0258036   -0.114266     -0.0911652   -0.0380518    0.019532    -0.0594112     0.0619737   -0.0992769   -0.139309    -0.0859248   0.0766591   -0.0370777   -0.0602532    0.0693343    -0.122311
  0.114277     0.0234792   -0.00878612  -0.186254     -0.0304673    -0.11455       0.0726707   -0.0734017  -0.0587909    0.0757731   -0.103377    -0.21651      0.0458426    -0.199225     0.196951    -0.0902056    0.00686328    0.0779029   -0.0117524   -0.119999    -0.0607442  -0.0150794    0.0315743   -0.026582     0.0149706    -0.0418969[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     12
│     13
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.094055
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     12
│     13
│     19
│     25
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.051179
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      5
│      8
│     12
│      ⋮
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.032089
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│     12
│     13
│     15
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.049026
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     12
│     13
│     19
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.066901
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      5
│      8
│     12
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.036257
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     12
│     13
│     15
│     19
│     21
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.048390
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│     12
│     13
│     19
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.044521
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      8
│     12
│     13
│     19
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.047310
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      8
│     12
│     13
│     15
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.023780
┌ Info: EM with 100000 data points 10 iterations avll -1.023780
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.122039    -0.0430289     0.107394      0.0423797    0.0255872   -0.0812945     0.0366545    -0.171402    -0.0223252    0.11327     -0.115767     0.0809236    2.39427e-5   0.0274035   -0.254206     0.0590893   -0.0428508   -0.0383879   -0.224571     0.0166386   -0.0778831   -0.0252174    0.150096    -0.070361     -0.0335332     0.0775178
  0.0209458   -0.0627575    -0.121594      0.0911035    0.00425186  -0.0263615     0.0138517    -0.0424396    0.0443407    0.0252364    0.107484     0.0807893    0.100543     0.0674313   -0.0467628    0.139418    -0.00650507  -0.0258871    0.208728    -0.125936    -0.128648    -0.0773434   -0.0944228   -0.0328842     0.00946984    0.08343
 -0.102813     0.111359      0.105221     -0.0883418   -0.022635    -0.0750581     0.0704876     0.0600135    0.107087    -0.113606     0.13313     -0.0491056    0.0358575    0.187613    -0.0198324    0.149649     0.0265877    0.0734047   -0.148616    -0.167665     0.0235797    0.0286263    0.124582    -0.0263832     0.203992     -0.0621799
 -0.109768    -0.110469      0.0851608    -0.0966081   -0.0523072    0.126336      0.0897477    -0.0329555    0.135115    -0.0541676    0.0663859    0.0121981   -0.00125818  -0.0403853    0.0523975    0.0236757   -0.00221655   0.00665851  -0.0922728    0.0105199    0.00017585  -0.115633     0.214602     0.104293     -0.0629658     0.161158
 -0.0976701    0.0624906     0.038709      0.0754306    0.0160316    0.0113078     0.1577       -0.0307953    0.106722     0.0204434    0.280574    -0.0483979    0.0771259   -0.0202391    0.084804     0.00946682   0.089339    -0.0262559    0.0324375   -0.168598    -0.0166646    0.0430275    0.0927071    0.0232191     0.00573679    0.194393
  0.0988153   -0.0671175    -0.0242156    -0.0803382   -0.0505036    0.0749615     0.0783281     0.0274639   -0.0501112    0.160564    -0.247201     0.00247094  -0.00981172   0.17822     -0.134981    -0.102842     0.129062     0.0521732   -0.140571    -0.0971868    0.00212353   0.12453      0.119624    -0.0846135     0.085616      0.14876
 -0.211281    -0.0640198    -0.0336388    -0.0090535    0.0359635    0.106728     -0.0162805     0.0352687   -0.106721    -0.231105     0.0207525   -0.0890386   -0.166563    -0.0768084   -0.125334     0.0819588   -0.0664078   -0.0502898    0.0788183   -0.0115162    0.0930886   -0.0156887    0.140615     0.0165742     0.11557      -0.0741492
  0.0782608   -0.214312      0.219379     -0.0300672   -0.103474    -0.0500879     0.133318      0.155797    -0.00242394  -0.0788149    0.098766     0.0860044    0.169718    -0.169009     0.0983978   -0.16948     -0.158857    -0.060492     0.0286163    0.0126125    0.226538    -0.0620618    0.159011     0.0224963     0.0290679    -0.0648804
 -0.071799     0.20505       0.269551      0.0620584    0.0561515   -0.0510548     0.210102      0.0104416   -0.147115     0.0975345   -0.0893003   -0.0398199   -0.109262     0.137826    -0.00967696  -0.0195063   -0.00138105   0.00156415  -0.231089    -0.0077538    0.0902326   -0.127232     0.00505934  -0.125239      0.0225444     0.0305633
 -0.065731     0.00415515   -0.0717651    -0.00805668   0.0668373   -0.198335     -0.0496924    -0.0264835    0.0623659   -0.0286486    0.0806137   -0.0344204   -0.0787826    0.0314208    0.0847265   -0.0358459   -0.0661775   -0.150428     0.23491     -0.0120615   -0.143395    -0.0286889   -0.130846     0.0313862    -0.0649754    -0.091937
  0.147448    -0.0416618    -0.0259957    -0.0907734    0.00822328  -0.0631386     0.115128     -0.0627021   -0.0419323    0.308469     0.0867979    0.159973    -0.108703     0.0591964   -0.144744     0.0534037    0.0972866   -0.0574736    0.0539005   -0.00949483   0.0012778    0.0390799    0.0499207    0.0512925    -0.0132        0.180401
  0.0936492   -0.00257863    0.0256688    -0.0753396   -0.0150348   -0.023014      0.0497166    -0.0552239    0.0812177   -0.217708    -0.0275736    0.0093159    0.0184639    0.0103291    0.0178675    0.0792543    0.0254287    0.0504154   -0.0380447    0.0196684    0.055765    -0.0524558    0.0846127    0.190951     -0.000296665  -0.00149569
 -0.0786478    0.0411914     0.0087276     0.0909559    0.158629     0.00434784   -0.124297     -0.0841467    0.0870554   -0.144917    -0.0430547   -0.0759461    0.0472524    0.0157264   -0.0887629   -0.0666553   -0.0587791   -0.0886159    0.0146783   -0.0189718    0.0973868    0.0775678   -0.119703    -0.0947032     0.0656378     0.049221
 -0.0723947    0.0324416     0.0754725    -0.100525     0.0549625   -0.0529897    -0.0476002    -0.0188919   -0.177345    -0.172299    -0.0166475   -0.152243     0.113686    -0.0834392    0.0322988   -0.0795939    0.1248      -0.0252858    0.0301955   -0.0831723    0.116537    -0.168376    -0.111593     0.105987      0.0538679     0.108498
  0.0981051   -0.206753      0.028109     -0.0466426   -0.0248994    0.105566      0.014805     -0.177188    -0.0789856   -0.0889519    0.0623631   -0.254858     0.0511737    0.004952     0.130297    -0.101891     0.232119     0.00194931  -0.121697     0.145203    -0.0304165    0.0169074    0.108615     0.186012     -0.0907562     0.178435
  0.0365199    0.0030824     0.0809747     0.189175     0.103733     0.0300421     0.0456055     0.106361    -0.0281852   -0.126285     0.0405613   -0.0832423    0.0197526    0.230964    -0.0503162    0.0629319    0.188656     0.0366005    0.0507535   -0.175736     0.251103    -0.00171377  -0.159596     0.0288152    -0.0525854    -0.105629
 -0.168017    -0.176504      0.000689752  -0.240451     0.0172565    0.108897      0.0588487     0.0692856   -0.0851756    0.00754664  -0.0215312    0.310331    -0.136853     0.0852116    0.0862513    0.137271    -0.0307561   -0.0905538   -0.0657346    0.15638     -0.0790661   -0.162519    -0.146019    -0.000567518   0.15802       0.280167
 -0.0519217   -0.0124504     0.0318137    -0.148779     0.148556     0.167304     -0.0726493     0.0684305    0.120875     0.141941    -0.02087      0.188908     0.0363588   -0.0623525    0.266708    -0.0817439   -0.0297596    0.12576      2.82568e-5  -0.214174     0.0372529   -0.0295536    0.0900673   -0.0335147    -0.0627828     0.127063
  0.0178062   -0.174507     -0.142936     -0.133737    -0.264948     0.0900065     0.0829971    -0.0186126    0.0698297   -0.023308     0.0320901   -3.93144e-5   0.0246036    0.246703    -0.0206099    0.15913      0.0548101    0.105497    -0.113336     0.0876422   -0.11548     -0.00440712   0.246033    -0.0848162    -0.0228072     0.0576411
  0.148275    -0.0291443    -0.0129717    -0.092762     0.126525    -0.109648      0.120882      0.0119103   -0.00846142  -0.149639    -0.0514856   -0.012436    -0.104144    -0.111295     0.0908541   -0.122054     0.130701    -0.139586    -0.100721    -0.108746    -0.0248294   -0.138216    -0.0595299   -0.236249     -0.0687854     0.143285
 -0.0767652    0.0157695    -0.0286183     0.0175481   -0.0209045    0.053435      0.0799737     0.00109619  -0.16148     -0.0056837   -0.0397671    0.0724216   -0.0977596    0.00351266   0.00863015   0.0985211    0.12572     -0.0608906    0.134794     0.0181145    0.0914004    0.0478286    0.0392254    0.0317047     0.058567     -0.255305
  0.0198748    0.102846      0.160187     -0.0522248    0.0971489    0.0910267    -0.000838321   0.0282342   -0.0120916    0.249084    -0.101627     0.136258     0.0519235   -0.159767    -0.124126     0.0704251   -0.0622102   -0.0148317    0.0156967   -0.151063     0.128048    -0.0545886    0.0563859   -0.137727      0.0511452     0.0654549
  0.0557641    0.0891491     0.233547      0.0710994   -0.149777    -0.110851      0.254574      0.0120112   -0.0158363    0.0193506    0.110172    -0.128707    -0.133336     0.0175967   -0.135739     0.103606     0.0148341    0.0210046    0.0971279   -0.105728     0.116214    -0.0862634    0.0945792   -0.0260202    -0.0224649    -0.077053
  0.00818962   0.00157299   -0.0873257    -0.0507676    0.025889     0.0745897     0.169993     -0.0717157    0.0482388    0.0652837    0.0124089   -0.162475    -0.0778878   -0.0156472    0.00347555   0.0276211    0.0329751   -0.0815411    0.0749966    0.0858172    0.0790163   -0.0306729    0.185255     0.0330424     0.0667103     0.0176009
 -0.187901     0.0234201    -0.0324174     0.140586     0.164573     0.0253289    -0.0531992    -0.096658     0.14378      0.0396665   -0.173665    -0.0273421    0.00081207   0.12385     -0.0542773   -0.00992116   0.0157375   -0.0345693    0.037208     0.0444557    0.113964     0.169384     0.114183    -0.046571     -0.0523006    -0.0119263
  0.0420936   -0.0511755    -0.0635454    -0.0827224   -0.083306    -0.0652081     0.0894363     0.0750725    0.0404501    0.0186568    0.112782     0.0439871   -0.0509241    0.116166    -0.0399003   -0.0879414   -0.0625008   -0.0261413    0.0222263    0.059203     0.0925055    0.133949     0.228511     0.0271192     0.0841198     0.0130052
  0.0223486    0.109847      0.0690194    -0.173469     0.0877245    0.0664645    -0.00902719   -0.146673    -0.0778787    0.0265966    0.00475517   0.0994013   -0.0382339   -0.0192931   -0.148083    -0.0646825    0.0612193   -0.0678497   -0.0798385   -0.111287     0.191295     0.0745739    0.0870931   -0.0240774    -0.0821462     0.122025
  0.0514738    0.000499034  -0.103518     -0.13097     -0.083358     0.000649349   0.107434      0.203651    -0.083589     0.100338    -0.129314    -0.0199731    0.0254222    0.00544536  -0.00465059  -0.0253439   -0.163784    -0.0508606    0.133008     0.0712679    0.0720163   -0.051458     0.00667723   0.00158796   -0.0321325    -0.00917958
  0.0899863    6.13089e-5    0.0421447    -0.114802    -0.0198113   -0.192499     -0.0371186     0.0726999    0.0557055    0.0686408    0.0256386   -0.0762928   -0.0467848   -0.115844     0.0747847    0.152033     0.0543123   -0.0266581    0.12752     -0.150453     0.0549714   -0.0710536    0.185905     0.0373796     0.273914      0.0058433
  0.0025349   -0.0876096    -0.120097      0.162828     0.0334845    0.148267     -0.024902     -0.195581     0.00421764   0.15722      0.0548988   -0.0225413   -0.11979     -0.177909    -0.0067758    0.00864551   0.025549    -0.131212    -0.0244395   -0.0413666    0.00676984   0.191771     0.0288505    0.0692021    -0.08274      -0.00726283
 -0.103301    -0.07822      -0.0376367     0.0202779   -0.0941595   -0.300036     -0.0621587    -0.0291969   -0.071655    -0.074694     0.12895      0.125851    -0.0957763    0.0536538    0.0654043   -0.0199072    0.0196496    0.225657     0.106933    -0.0816346   -0.125065     0.0172263   -0.103901     0.135539     -0.166575     -0.0281949
 -0.0421963   -0.0122903     0.0697045     0.156779    -0.00465327  -0.00522985    0.0754408     0.215685    -0.0625751   -0.0547097    0.096879     0.0226508   -0.0354731   -0.0204528    0.0372651   -0.110404    -0.0718274    0.112413    -0.00851932  -0.238483    -0.0699658    0.023597     0.0443096    0.122606     -0.0323632     0.0185887kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4220158811033037
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422038
[ Info: iteration 2, average log likelihood -1.421954
[ Info: iteration 3, average log likelihood -1.421891
[ Info: iteration 4, average log likelihood -1.421820
[ Info: iteration 5, average log likelihood -1.421740
[ Info: iteration 6, average log likelihood -1.421651
[ Info: iteration 7, average log likelihood -1.421551
[ Info: iteration 8, average log likelihood -1.421429
[ Info: iteration 9, average log likelihood -1.421247
[ Info: iteration 10, average log likelihood -1.420924
[ Info: iteration 11, average log likelihood -1.420341
[ Info: iteration 12, average log likelihood -1.419418
[ Info: iteration 13, average log likelihood -1.418291
[ Info: iteration 14, average log likelihood -1.417336
[ Info: iteration 15, average log likelihood -1.416784
[ Info: iteration 16, average log likelihood -1.416543
[ Info: iteration 17, average log likelihood -1.416451
[ Info: iteration 18, average log likelihood -1.416416
[ Info: iteration 19, average log likelihood -1.416403
[ Info: iteration 20, average log likelihood -1.416398
[ Info: iteration 21, average log likelihood -1.416396
[ Info: iteration 22, average log likelihood -1.416394
[ Info: iteration 23, average log likelihood -1.416394
[ Info: iteration 24, average log likelihood -1.416394
[ Info: iteration 25, average log likelihood -1.416393
[ Info: iteration 26, average log likelihood -1.416393
[ Info: iteration 27, average log likelihood -1.416393
[ Info: iteration 28, average log likelihood -1.416393
[ Info: iteration 29, average log likelihood -1.416392
[ Info: iteration 30, average log likelihood -1.416392
[ Info: iteration 31, average log likelihood -1.416392
[ Info: iteration 32, average log likelihood -1.416392
[ Info: iteration 33, average log likelihood -1.416392
[ Info: iteration 34, average log likelihood -1.416392
[ Info: iteration 35, average log likelihood -1.416392
[ Info: iteration 36, average log likelihood -1.416392
[ Info: iteration 37, average log likelihood -1.416392
[ Info: iteration 38, average log likelihood -1.416392
[ Info: iteration 39, average log likelihood -1.416392
[ Info: iteration 40, average log likelihood -1.416392
[ Info: iteration 41, average log likelihood -1.416392
[ Info: iteration 42, average log likelihood -1.416392
[ Info: iteration 43, average log likelihood -1.416391
[ Info: iteration 44, average log likelihood -1.416391
[ Info: iteration 45, average log likelihood -1.416391
[ Info: iteration 46, average log likelihood -1.416391
[ Info: iteration 47, average log likelihood -1.416391
[ Info: iteration 48, average log likelihood -1.416391
[ Info: iteration 49, average log likelihood -1.416391
[ Info: iteration 50, average log likelihood -1.416391
┌ Info: EM with 100000 data points 50 iterations avll -1.416391
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4220379987366583
│     -1.4219539281026163
│      ⋮
└     -1.4163913483594819
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416413
[ Info: iteration 2, average log likelihood -1.416325
[ Info: iteration 3, average log likelihood -1.416259
[ Info: iteration 4, average log likelihood -1.416184
[ Info: iteration 5, average log likelihood -1.416101
[ Info: iteration 6, average log likelihood -1.416015
[ Info: iteration 7, average log likelihood -1.415933
[ Info: iteration 8, average log likelihood -1.415864
[ Info: iteration 9, average log likelihood -1.415810
[ Info: iteration 10, average log likelihood -1.415769
[ Info: iteration 11, average log likelihood -1.415738
[ Info: iteration 12, average log likelihood -1.415714
[ Info: iteration 13, average log likelihood -1.415694
[ Info: iteration 14, average log likelihood -1.415678
[ Info: iteration 15, average log likelihood -1.415664
[ Info: iteration 16, average log likelihood -1.415650
[ Info: iteration 17, average log likelihood -1.415637
[ Info: iteration 18, average log likelihood -1.415624
[ Info: iteration 19, average log likelihood -1.415611
[ Info: iteration 20, average log likelihood -1.415596
[ Info: iteration 21, average log likelihood -1.415580
[ Info: iteration 22, average log likelihood -1.415563
[ Info: iteration 23, average log likelihood -1.415545
[ Info: iteration 24, average log likelihood -1.415526
[ Info: iteration 25, average log likelihood -1.415506
[ Info: iteration 26, average log likelihood -1.415485
[ Info: iteration 27, average log likelihood -1.415465
[ Info: iteration 28, average log likelihood -1.415446
[ Info: iteration 29, average log likelihood -1.415427
[ Info: iteration 30, average log likelihood -1.415410
[ Info: iteration 31, average log likelihood -1.415395
[ Info: iteration 32, average log likelihood -1.415382
[ Info: iteration 33, average log likelihood -1.415370
[ Info: iteration 34, average log likelihood -1.415360
[ Info: iteration 35, average log likelihood -1.415352
[ Info: iteration 36, average log likelihood -1.415344
[ Info: iteration 37, average log likelihood -1.415337
[ Info: iteration 38, average log likelihood -1.415332
[ Info: iteration 39, average log likelihood -1.415327
[ Info: iteration 40, average log likelihood -1.415322
[ Info: iteration 41, average log likelihood -1.415318
[ Info: iteration 42, average log likelihood -1.415315
[ Info: iteration 43, average log likelihood -1.415311
[ Info: iteration 44, average log likelihood -1.415308
[ Info: iteration 45, average log likelihood -1.415306
[ Info: iteration 46, average log likelihood -1.415303
[ Info: iteration 47, average log likelihood -1.415301
[ Info: iteration 48, average log likelihood -1.415298
[ Info: iteration 49, average log likelihood -1.415296
[ Info: iteration 50, average log likelihood -1.415294
┌ Info: EM with 100000 data points 50 iterations avll -1.415294
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4164131486216935
│     -1.4163253693030002
│      ⋮
└     -1.415294245858637
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415303
[ Info: iteration 2, average log likelihood -1.415259
[ Info: iteration 3, average log likelihood -1.415223
[ Info: iteration 4, average log likelihood -1.415182
[ Info: iteration 5, average log likelihood -1.415132
[ Info: iteration 6, average log likelihood -1.415071
[ Info: iteration 7, average log likelihood -1.414996
[ Info: iteration 8, average log likelihood -1.414909
[ Info: iteration 9, average log likelihood -1.414818
[ Info: iteration 10, average log likelihood -1.414727
[ Info: iteration 11, average log likelihood -1.414643
[ Info: iteration 12, average log likelihood -1.414567
[ Info: iteration 13, average log likelihood -1.414500
[ Info: iteration 14, average log likelihood -1.414439
[ Info: iteration 15, average log likelihood -1.414384
[ Info: iteration 16, average log likelihood -1.414333
[ Info: iteration 17, average log likelihood -1.414285
[ Info: iteration 18, average log likelihood -1.414241
[ Info: iteration 19, average log likelihood -1.414200
[ Info: iteration 20, average log likelihood -1.414163
[ Info: iteration 21, average log likelihood -1.414130
[ Info: iteration 22, average log likelihood -1.414099
[ Info: iteration 23, average log likelihood -1.414071
[ Info: iteration 24, average log likelihood -1.414046
[ Info: iteration 25, average log likelihood -1.414024
[ Info: iteration 26, average log likelihood -1.414003
[ Info: iteration 27, average log likelihood -1.413985
[ Info: iteration 28, average log likelihood -1.413969
[ Info: iteration 29, average log likelihood -1.413954
[ Info: iteration 30, average log likelihood -1.413941
[ Info: iteration 31, average log likelihood -1.413929
[ Info: iteration 32, average log likelihood -1.413918
[ Info: iteration 33, average log likelihood -1.413909
[ Info: iteration 34, average log likelihood -1.413900
[ Info: iteration 35, average log likelihood -1.413892
[ Info: iteration 36, average log likelihood -1.413884
[ Info: iteration 37, average log likelihood -1.413877
[ Info: iteration 38, average log likelihood -1.413871
[ Info: iteration 39, average log likelihood -1.413865
[ Info: iteration 40, average log likelihood -1.413859
[ Info: iteration 41, average log likelihood -1.413854
[ Info: iteration 42, average log likelihood -1.413849
[ Info: iteration 43, average log likelihood -1.413844
[ Info: iteration 44, average log likelihood -1.413840
[ Info: iteration 45, average log likelihood -1.413835
[ Info: iteration 46, average log likelihood -1.413831
[ Info: iteration 47, average log likelihood -1.413827
[ Info: iteration 48, average log likelihood -1.413823
[ Info: iteration 49, average log likelihood -1.413819
[ Info: iteration 50, average log likelihood -1.413816
┌ Info: EM with 100000 data points 50 iterations avll -1.413816
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4153033346732802
│     -1.4152585570030918
│      ⋮
└     -1.4138158365487015
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413821
[ Info: iteration 2, average log likelihood -1.413770
[ Info: iteration 3, average log likelihood -1.413723
[ Info: iteration 4, average log likelihood -1.413669
[ Info: iteration 5, average log likelihood -1.413602
[ Info: iteration 6, average log likelihood -1.413518
[ Info: iteration 7, average log likelihood -1.413416
[ Info: iteration 8, average log likelihood -1.413299
[ Info: iteration 9, average log likelihood -1.413171
[ Info: iteration 10, average log likelihood -1.413040
[ Info: iteration 11, average log likelihood -1.412911
[ Info: iteration 12, average log likelihood -1.412790
[ Info: iteration 13, average log likelihood -1.412679
[ Info: iteration 14, average log likelihood -1.412579
[ Info: iteration 15, average log likelihood -1.412491
[ Info: iteration 16, average log likelihood -1.412414
[ Info: iteration 17, average log likelihood -1.412348
[ Info: iteration 18, average log likelihood -1.412291
[ Info: iteration 19, average log likelihood -1.412242
[ Info: iteration 20, average log likelihood -1.412199
[ Info: iteration 21, average log likelihood -1.412161
[ Info: iteration 22, average log likelihood -1.412127
[ Info: iteration 23, average log likelihood -1.412096
[ Info: iteration 24, average log likelihood -1.412069
[ Info: iteration 25, average log likelihood -1.412043
[ Info: iteration 26, average log likelihood -1.412020
[ Info: iteration 27, average log likelihood -1.411999
[ Info: iteration 28, average log likelihood -1.411979
[ Info: iteration 29, average log likelihood -1.411960
[ Info: iteration 30, average log likelihood -1.411942
[ Info: iteration 31, average log likelihood -1.411926
[ Info: iteration 32, average log likelihood -1.411910
[ Info: iteration 33, average log likelihood -1.411895
[ Info: iteration 34, average log likelihood -1.411880
[ Info: iteration 35, average log likelihood -1.411866
[ Info: iteration 36, average log likelihood -1.411852
[ Info: iteration 37, average log likelihood -1.411839
[ Info: iteration 38, average log likelihood -1.411827
[ Info: iteration 39, average log likelihood -1.411815
[ Info: iteration 40, average log likelihood -1.411803
[ Info: iteration 41, average log likelihood -1.411791
[ Info: iteration 42, average log likelihood -1.411780
[ Info: iteration 43, average log likelihood -1.411769
[ Info: iteration 44, average log likelihood -1.411759
[ Info: iteration 45, average log likelihood -1.411749
[ Info: iteration 46, average log likelihood -1.411739
[ Info: iteration 47, average log likelihood -1.411730
[ Info: iteration 48, average log likelihood -1.411721
[ Info: iteration 49, average log likelihood -1.411712
[ Info: iteration 50, average log likelihood -1.411704
┌ Info: EM with 100000 data points 50 iterations avll -1.411704
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.413821440985676
│     -1.4137697060771472
│      ⋮
└     -1.4117037971347544
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411704
[ Info: iteration 2, average log likelihood -1.411638
[ Info: iteration 3, average log likelihood -1.411575
[ Info: iteration 4, average log likelihood -1.411500
[ Info: iteration 5, average log likelihood -1.411407
[ Info: iteration 6, average log likelihood -1.411289
[ Info: iteration 7, average log likelihood -1.411146
[ Info: iteration 8, average log likelihood -1.410983
[ Info: iteration 9, average log likelihood -1.410807
[ Info: iteration 10, average log likelihood -1.410629
[ Info: iteration 11, average log likelihood -1.410460
[ Info: iteration 12, average log likelihood -1.410307
[ Info: iteration 13, average log likelihood -1.410172
[ Info: iteration 14, average log likelihood -1.410055
[ Info: iteration 15, average log likelihood -1.409954
[ Info: iteration 16, average log likelihood -1.409867
[ Info: iteration 17, average log likelihood -1.409792
[ Info: iteration 18, average log likelihood -1.409727
[ Info: iteration 19, average log likelihood -1.409670
[ Info: iteration 20, average log likelihood -1.409620
[ Info: iteration 21, average log likelihood -1.409575
[ Info: iteration 22, average log likelihood -1.409536
[ Info: iteration 23, average log likelihood -1.409501
[ Info: iteration 24, average log likelihood -1.409469
[ Info: iteration 25, average log likelihood -1.409441
[ Info: iteration 26, average log likelihood -1.409415
[ Info: iteration 27, average log likelihood -1.409391
[ Info: iteration 28, average log likelihood -1.409369
[ Info: iteration 29, average log likelihood -1.409348
[ Info: iteration 30, average log likelihood -1.409329
[ Info: iteration 31, average log likelihood -1.409310
[ Info: iteration 32, average log likelihood -1.409293
[ Info: iteration 33, average log likelihood -1.409277
[ Info: iteration 34, average log likelihood -1.409261
[ Info: iteration 35, average log likelihood -1.409246
[ Info: iteration 36, average log likelihood -1.409232
[ Info: iteration 37, average log likelihood -1.409218
[ Info: iteration 38, average log likelihood -1.409205
[ Info: iteration 39, average log likelihood -1.409192
[ Info: iteration 40, average log likelihood -1.409179
[ Info: iteration 41, average log likelihood -1.409167
[ Info: iteration 42, average log likelihood -1.409155
[ Info: iteration 43, average log likelihood -1.409143
[ Info: iteration 44, average log likelihood -1.409132
[ Info: iteration 45, average log likelihood -1.409120
[ Info: iteration 46, average log likelihood -1.409109
[ Info: iteration 47, average log likelihood -1.409099
[ Info: iteration 48, average log likelihood -1.409088
[ Info: iteration 49, average log likelihood -1.409077
[ Info: iteration 50, average log likelihood -1.409067
┌ Info: EM with 100000 data points 50 iterations avll -1.409067
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4117040316641603
│     -1.411638089038072
│      ⋮
└     -1.4090670884118017
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4220158811033037
│     -1.4220379987366583
│     -1.4219539281026163
│     -1.4218908081620247
│      ⋮
│     -1.409087912973309
│     -1.4090774257345602
└     -1.4090670884118017
32×26 Array{Float64,2}:
 -0.148085     0.404519   -0.309005   -0.278404    -0.305784   -0.418902    0.266787     0.0281661    0.606609     0.207027    -0.15227    -0.714759     0.884776    0.012314     0.0238011     0.371277    -0.122103    0.0911063    0.173929    0.304687    -0.0726323   -0.118384   -0.131261      0.270694   -0.171454    -0.235512
  0.0226486    0.172233   -0.262139    0.0114158   -0.197967   -0.15356     0.111541    -0.131376    -0.230305    -0.135886     0.0656922  -0.0047269   -0.293083   -0.0122447   -0.070357      0.0597989   -0.107811   -0.00262731  -0.151458   -0.0752564   -0.0856887    0.0570099   0.100314     -0.209206   -0.0916403    0.25791
 -0.490904     0.104977   -0.341025   -0.316816    -0.10888    -0.223821    0.150169     1.05239     -0.566146    -0.219482     0.496974    0.157532    -0.0282503  -0.438762     0.577928      0.21849      0.0418915   0.17497      0.0197045   0.218967    -0.64549      0.602268   -0.312123     -0.139239   -0.578913    -0.361318
 -0.779078    -0.0769508  -0.239449   -0.0687457    0.274457   -0.316646   -0.0297745    0.628597     0.517782     0.360414    -0.161532    0.543503    -0.250997    0.245565     0.041681     -0.256374     0.0624358  -0.137561     0.237074    0.0794836   -0.309594     0.0996582   0.054627      0.736547   -0.190337     0.124954
  0.471651    -0.527906    0.637056    0.126916     0.321628    0.0204708   0.0258706   -0.453723    -0.433146    -0.106218    -0.865354   -0.117037    -0.347424   -0.0687974   -0.351664     -0.150352    -0.979659   -0.0391298   -0.185986   -0.84873      0.243013    -0.696866    0.148308      0.217303   -0.0523576   -0.407743
  0.011279    -1.06591     0.856443    0.455009     0.222533   -0.0123482  -0.378882     0.274918    -0.251003    -0.422227    -0.230966   -0.518711     0.294658   -0.156342    -0.362386     -0.214474     0.601559    0.217443    -0.106069   -0.175179     0.366362    -0.114628    0.123415      0.287648    0.268003    -0.51289
 -0.129318     0.0994056   0.832271   -0.369815     0.20094     0.509357    0.299533     0.547044    -0.398114     0.134154     0.185412    0.00387599   0.342573    0.274825     1.19709      -0.138461     0.486064    0.0586118    0.181081   -0.302665     0.18964     -0.823742   -0.374279     -0.10925     0.556271    -0.181948
 -0.203227     0.229264   -0.0945013  -0.797423     0.511492    0.140065   -0.178722     0.0398578   -0.794587     0.00633177   0.0519007  -0.162765     0.654329   -0.660847     0.424209      0.520471    -0.225789   -0.190688    -0.50498     0.0209801    0.859281    -0.545285    0.215006     -0.412086    0.255589    -0.0399451
  0.245919    -0.0651827   0.113403   -0.00118341   0.0371503  -0.356231    0.0163249   -0.307255     0.590558     0.127527    -0.014247    0.183912    -0.337754   -0.439209    -0.44915       0.409036    -0.379018    0.242364    -0.0798786  -0.0178822    0.0958889    0.0307423  -0.0860782     0.726975    0.243955    -0.00325198
  0.284216     0.0589611   0.0721615   0.324718     0.0190701  -0.102343    0.0954446   -0.634438     0.641939     0.646631    -0.455506   -0.476831     0.0562811   1.01001     -0.59219      -0.0804466    0.154181    0.243992    -0.0945139  -0.082656    -0.204999    -0.181443    0.345062      0.395375    0.524575     0.297003
  0.0816318    0.514363   -0.335048    0.232322     0.08623    -0.277412    0.109826    -0.444164     0.207662    -0.302712     0.389004    0.318883    -0.299924    0.170725    -0.70546       0.134108    -0.498085   -0.624066    -0.0536354  -0.749825    -0.128357     0.552545    0.371198     -0.0543001  -0.315887     0.175039
 -0.554088     0.0124304  -0.479943    0.101342     0.478172   -0.726758    0.109257     0.0502693    0.505753    -0.343366     0.442391    0.278145     0.252326   -0.385499    -0.760825      0.413427     0.321941   -0.36239     -0.406569    0.14748      0.357531     0.813166    0.232205      0.0829059   0.514953    -0.0201272
  0.118197     0.392427   -0.135925    0.266209    -0.556767    0.0350512   0.199295    -0.128103     0.0219979    0.348939     0.371574    0.280205    -0.513847    0.325178     0.494774     -0.490416    -0.600045    0.545931     0.665588    0.00340775  -0.62445     -0.222376   -0.469009      0.467558   -0.345714     0.578235
  0.546817    -0.061247    0.192927    0.0967057   -0.0904016   0.0514434   0.180749    -0.265759     0.741597    -0.119747     0.26264     0.635672    -0.406631    0.645809    -0.280324     -0.351242     0.375296   -0.070121     0.814694   -0.583962    -0.542571     0.689546   -0.192419     -0.0830292  -0.178151     0.175468
  0.246041    -0.18389     0.03259     0.193606     0.189288    1.22118     0.341854    -0.0526623    0.00180186   0.0133772    0.334116   -0.390467    -0.247541    0.215611     0.437175     -0.111808     0.514006    0.13852     -0.171357    0.0131222    0.23565      0.756016    0.179111     -0.247107    0.145065    -0.140964
  0.117554    -0.320194   -0.284133   -0.0366159   -0.260718    0.564393    0.275855    -0.127461     0.452571     0.0686204    0.440982    0.403855    -0.0429919  -0.333766     0.000207119  -0.22714     -0.0229844  -0.32088     -0.0924063   0.874158     0.339661    -0.147673    0.303108      0.0697896  -0.00349716   0.243734
 -0.419991     0.142433   -0.149323    0.478255    -0.478617   -0.11815    -0.0315261    0.133637    -0.0580509   -0.650384     0.150328   -0.538373     0.0793501   0.272233    -0.13001      -0.669571     0.0637735   0.374613    -0.121429    0.240076    -0.0544751   -0.0337081   0.1657       -0.0980473  -0.536619    -0.356112
 -0.132447     0.460678    0.486603    0.415742    -0.0060995  -0.156809   -0.176386    -0.130085    -0.515597    -0.488908    -0.142244   -0.46259      0.0603211   0.00651355  -0.367646      0.628187    -0.325622   -0.11208     -0.186208    0.167215     0.176638    -0.0614249   0.130282     -0.212659    0.0154498   -0.828523
 -0.0160577   -0.212975   -0.537685    0.414028    -0.322027   -0.108445   -0.0991644   -0.0500392   -0.329155     0.124198    -0.651197   -0.324118    -0.376579   -0.149034    -0.0752206     0.0608445   -0.440812    0.346412    -0.369673    0.229192     0.0378764   -0.0481262   0.112288      0.216371   -0.273971     0.239541
 -0.375312     0.11812    -0.178045   -0.107304    -0.775747    0.094171    0.0382288   -0.00601088  -0.349895     0.370677    -0.756452   -0.15909     -0.0183196   0.401525     0.215241      0.368551     0.45434    -0.00915677   0.362072    0.104563    -0.140858    -0.389276    0.220518     -0.635111   -0.277969     0.550152
 -0.0506554   -0.114588   -0.0325561   0.079677     0.110152    0.111035   -0.0320133   -0.0347745   -0.0263186    0.14847     -0.112741   -0.367227     0.0420764  -0.177737    -0.0169174     0.0240416   -0.109309    0.153322    -0.203551    0.0811358    0.0169764   -0.0721823   0.0744792     0.127436   -0.00711132  -0.102363
 -0.00928963  -0.0439513   0.16818    -0.0990961    0.0646274  -0.29478    -0.00181648   0.0258351   -0.0601312   -0.0906824   -0.0437786   0.329476    -0.184728    0.0401314   -0.161053      0.102431    -0.0204413  -0.223335     0.115923   -0.250078     0.0286135   -0.0194683   0.0208658    -0.0410359   0.027293     0.0627343
  0.0123149    0.0153123  -0.105429   -0.204882    -0.100707    0.257817    0.0662984    0.0359607    0.303379    -0.0794639    0.204354    0.302308    -0.142754    0.399837     0.208366     -0.0172918    0.383228   -0.0183295    0.378931    0.21854     -0.515352     0.360573   -0.00101361   -0.115029   -0.0785804    0.118995
 -0.235899     0.245016   -0.131183    0.0875956   -0.247506    0.360916    0.257361    -0.0958671    0.0323845    0.024189     0.169321    0.0718395    0.0374582   0.235929     0.0714186    -0.0919963    0.388481   -0.0784388   -0.14952     0.140598     0.537567     0.0626723   0.225666     -0.195445    0.0198924    0.330161
  0.502957    -0.14252    -0.220239   -0.686828    -0.066223   -0.323223    0.109605    -0.0329833    0.31321     -0.168655    -0.188463   -0.741141     0.671589    0.046267     0.201676      0.00353399  -0.283107    0.211566     0.29191    -0.0672162   -0.0653477   -0.080216   -0.000224649  -0.132255    0.0319544    0.0776652
 -0.0331961    0.147427    0.19582     0.099324     0.21252    -0.485131    0.341848     0.109039    -0.0976784   -0.046689     0.245883   -0.149586     0.359719   -0.0208468    0.671784     -0.164577    -0.0955164  -0.0260025    0.402382   -0.53309      0.00892281  -0.340665   -0.0888346     0.562172    0.492775     0.0675169
  0.483342     0.0168883   0.581367   -0.516012    -0.0843269   0.246243    0.0302711   -0.312109     0.289414    -0.284152     0.935164    0.153668     0.634092   -0.426007    -0.0395259    -0.183715     0.279429   -0.100052     0.366789   -0.0972365    0.313933    -0.308812   -0.341978     -0.277896    0.0967634   -0.157783
  0.792145    -0.394586    0.363011   -0.325265     0.223053    0.358584    0.0348864   -0.183452    -0.0571125    0.86721     -0.15374     0.279033    -0.237043   -0.425415     0.0243865     0.0877905    0.299717    0.0969731    0.218185   -0.385945     0.166923    -0.37109     0.0881127    -0.409423    0.503703     0.629167
  0.0485665   -0.03739     0.331831   -0.552995     0.817394    0.0985728  -0.266095     0.364775    -0.240839     0.525372    -0.031874    0.0954409   -0.0604194   0.0517001    0.053641      0.0540909    0.0880028   0.107522    -0.363809   -0.35074     -0.276475     0.0190998  -0.369771     -0.45532    -0.181025     0.27534
 -0.186035    -0.71303     0.301248   -0.240261     0.354755   -0.0736162   0.111129     0.352439    -0.481193    -0.343907    -0.0837796   0.0959904    0.157033    0.152239     0.0196395    -0.39379      0.318001   -0.536506    -0.213185   -0.199503     0.234656     0.104178    0.521783     -0.141332    0.00395364  -0.164718
  0.220129    -0.0149879  -0.266447   -0.334054     0.113375    0.4422     -0.117207     0.102565    -0.197475    -0.34852     -0.263235    1.70797     -0.125404    0.0761563    0.34604       1.09403     -0.11022    -1.57838     -0.113433    0.0978386    0.174462    -0.13441    -0.992641      0.422112    0.445268     0.188381
 -0.174848     0.12375     0.293568    0.265718     0.241082    0.109674   -0.385729     0.00685366  -0.859974    -0.25706      0.628039    1.27462     -0.864505   -0.308798    -0.100808      0.188027     0.172139   -0.342199    -0.186203   -0.32139      0.532878     0.123897    0.043159     -0.0630608   0.234167     0.212042[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409057
[ Info: iteration 2, average log likelihood -1.409047
[ Info: iteration 3, average log likelihood -1.409037
[ Info: iteration 4, average log likelihood -1.409027
[ Info: iteration 5, average log likelihood -1.409017
[ Info: iteration 6, average log likelihood -1.409008
[ Info: iteration 7, average log likelihood -1.408998
[ Info: iteration 8, average log likelihood -1.408988
[ Info: iteration 9, average log likelihood -1.408979
[ Info: iteration 10, average log likelihood -1.408970
┌ Info: EM with 100000 data points 10 iterations avll -1.408970
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.523326e+05
      1       7.021379e+05      -2.501947e+05 |       32
      2       6.907051e+05      -1.143279e+04 |       32
      3       6.863021e+05      -4.403026e+03 |       32
      4       6.839702e+05      -2.331887e+03 |       32
      5       6.823989e+05      -1.571274e+03 |       32
      6       6.812488e+05      -1.150183e+03 |       32
      7       6.804272e+05      -8.215703e+02 |       32
      8       6.797524e+05      -6.747507e+02 |       32
      9       6.791722e+05      -5.802719e+02 |       32
     10       6.786327e+05      -5.394859e+02 |       32
     11       6.782069e+05      -4.257654e+02 |       32
     12       6.778150e+05      -3.919061e+02 |       32
     13       6.774547e+05      -3.602982e+02 |       32
     14       6.771071e+05      -3.475716e+02 |       32
     15       6.767864e+05      -3.207672e+02 |       32
     16       6.765054e+05      -2.809372e+02 |       32
     17       6.762540e+05      -2.514641e+02 |       32
     18       6.760169e+05      -2.371184e+02 |       32
     19       6.757921e+05      -2.247286e+02 |       32
     20       6.755908e+05      -2.013749e+02 |       32
     21       6.754211e+05      -1.696458e+02 |       32
     22       6.752554e+05      -1.656807e+02 |       32
     23       6.750952e+05      -1.602240e+02 |       32
     24       6.749477e+05      -1.475267e+02 |       32
     25       6.747977e+05      -1.499697e+02 |       32
     26       6.746757e+05      -1.220372e+02 |       32
     27       6.745684e+05      -1.072497e+02 |       32
     28       6.744641e+05      -1.043625e+02 |       32
     29       6.743704e+05      -9.362747e+01 |       32
     30       6.742816e+05      -8.878879e+01 |       32
     31       6.742035e+05      -7.813227e+01 |       32
     32       6.741287e+05      -7.478456e+01 |       32
     33       6.740619e+05      -6.680471e+01 |       32
     34       6.739902e+05      -7.169148e+01 |       32
     35       6.739205e+05      -6.971330e+01 |       32
     36       6.738434e+05      -7.713875e+01 |       32
     37       6.737655e+05      -7.792178e+01 |       32
     38       6.736934e+05      -7.209848e+01 |       32
     39       6.736221e+05      -7.127232e+01 |       32
     40       6.735478e+05      -7.431634e+01 |       32
     41       6.734832e+05      -6.458074e+01 |       32
     42       6.734301e+05      -5.307855e+01 |       32
     43       6.733743e+05      -5.583969e+01 |       32
     44       6.733177e+05      -5.651669e+01 |       32
     45       6.732653e+05      -5.244459e+01 |       32
     46       6.732138e+05      -5.153248e+01 |       32
     47       6.731662e+05      -4.761816e+01 |       32
     48       6.731274e+05      -3.875975e+01 |       32
     49       6.730928e+05      -3.462992e+01 |       32
     50       6.730635e+05      -2.929428e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 673063.4688942943)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420609
[ Info: iteration 2, average log likelihood -1.415527
[ Info: iteration 3, average log likelihood -1.413928
[ Info: iteration 4, average log likelihood -1.412636
[ Info: iteration 5, average log likelihood -1.411488
[ Info: iteration 6, average log likelihood -1.410695
[ Info: iteration 7, average log likelihood -1.410256
[ Info: iteration 8, average log likelihood -1.410019
[ Info: iteration 9, average log likelihood -1.409873
[ Info: iteration 10, average log likelihood -1.409771
[ Info: iteration 11, average log likelihood -1.409692
[ Info: iteration 12, average log likelihood -1.409626
[ Info: iteration 13, average log likelihood -1.409571
[ Info: iteration 14, average log likelihood -1.409522
[ Info: iteration 15, average log likelihood -1.409478
[ Info: iteration 16, average log likelihood -1.409439
[ Info: iteration 17, average log likelihood -1.409403
[ Info: iteration 18, average log likelihood -1.409370
[ Info: iteration 19, average log likelihood -1.409339
[ Info: iteration 20, average log likelihood -1.409311
[ Info: iteration 21, average log likelihood -1.409285
[ Info: iteration 22, average log likelihood -1.409261
[ Info: iteration 23, average log likelihood -1.409238
[ Info: iteration 24, average log likelihood -1.409216
[ Info: iteration 25, average log likelihood -1.409195
[ Info: iteration 26, average log likelihood -1.409175
[ Info: iteration 27, average log likelihood -1.409156
[ Info: iteration 28, average log likelihood -1.409137
[ Info: iteration 29, average log likelihood -1.409119
[ Info: iteration 30, average log likelihood -1.409102
[ Info: iteration 31, average log likelihood -1.409086
[ Info: iteration 32, average log likelihood -1.409070
[ Info: iteration 33, average log likelihood -1.409054
[ Info: iteration 34, average log likelihood -1.409039
[ Info: iteration 35, average log likelihood -1.409024
[ Info: iteration 36, average log likelihood -1.409010
[ Info: iteration 37, average log likelihood -1.408996
[ Info: iteration 38, average log likelihood -1.408982
[ Info: iteration 39, average log likelihood -1.408969
[ Info: iteration 40, average log likelihood -1.408955
[ Info: iteration 41, average log likelihood -1.408943
[ Info: iteration 42, average log likelihood -1.408930
[ Info: iteration 43, average log likelihood -1.408918
[ Info: iteration 44, average log likelihood -1.408906
[ Info: iteration 45, average log likelihood -1.408894
[ Info: iteration 46, average log likelihood -1.408882
[ Info: iteration 47, average log likelihood -1.408871
[ Info: iteration 48, average log likelihood -1.408860
[ Info: iteration 49, average log likelihood -1.408849
[ Info: iteration 50, average log likelihood -1.408838
┌ Info: EM with 100000 data points 50 iterations avll -1.408838
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.619497    -0.086072     0.106806     0.0628826   0.0368005    0.110071    -0.203924     0.435438   -0.560356    0.334957    -0.631292     -0.583356    0.285335    0.00665844   0.455051    0.0849361     0.15715      0.362103   -0.451648     0.51371     0.411402    -0.614041    -0.0538689    0.153062     -0.0546795   0.106109
 -0.260917     0.355899    -0.0919211    0.361379    0.583878    -0.394895     0.0330658    0.355782    0.0281507  -0.00695461  -0.498219     -0.2551     -0.726103    0.983546    -0.216001    0.28932      -0.191307    -0.0567388  -0.118328    -0.267586   -0.735246     0.282646     0.143925    -0.0672905     0.0109814   0.119887
 -0.225148    -0.0299459   -0.268631     0.334624   -0.490244    -0.00388249  -0.154917     0.0928552   0.0790977  -0.727432     0.121488     -0.552545    0.163575    0.212727    -0.191466   -0.47502      -0.0627031    0.340535   -0.066717     0.316573   -0.153055     0.266419     0.19693     -0.103642     -0.536929   -0.47573
  0.110443    -0.979359     0.653654     0.101374    0.340802    -0.111122    -0.208405     0.210838   -0.299121   -0.47772     -0.102047     -0.488599    0.414167   -0.137012    -0.286445   -0.160929      0.499078     0.166926   -0.102257    -0.329264    0.327816     0.1103       0.103792     0.34648       0.316891   -0.801984
  0.761492     0.526066    -0.243123     0.483192   -0.538019    -0.296423     0.708908    -0.4006      0.512963   -0.168174     0.400528     -0.0287871  -0.359281    0.148941    -0.450064   -0.166683     -0.380941     0.298316    0.295044    -0.560423   -0.348361     0.483709    -0.371988     0.540825     -0.0719872   0.336775
 -0.751783    -0.137629    -0.300603     0.436707    0.283461    -0.719904     0.0243664    0.253842    0.391542   -0.284125    -0.00781026   -0.0174234   0.328743   -0.328179    -0.848844    0.776091      0.16468     -0.516177   -0.451908     0.0427946   0.222598     0.711729     0.335523     0.12318       0.462378    0.0916888
 -0.180677     0.306188    -0.101154    -0.210577    0.416212     0.240453    -0.274564     0.0954618  -0.819947   -0.253781     0.103924      1.44062    -0.324338   -0.210901     0.333895    0.747293     -0.080657    -0.63528    -0.0773902   -0.376474    0.544353    -0.120528    -0.474981     0.12217       0.348181    0.0519523
  0.0159613    0.126793     0.511616    -0.389875    0.467514    -0.11095      0.30571      0.198684   -0.223429    0.0578786    0.245918     -0.12585     0.495111    0.00447889   1.01339    -0.120533      0.00721769  -0.116949    0.388557    -0.874757    0.0890818   -0.41064     -0.0284041    0.269061      0.6596      0.120515
 -0.349964    -0.150127     0.10416      0.0534229  -0.0411601    0.150575     0.247431     0.33483    -0.985048   -0.139153     0.0206727    -0.15299    -0.0438896   0.310799     0.203511   -0.440037      0.487721    -0.373365   -0.304538    -0.27918     0.116671     0.205908     0.190746    -0.596006     -0.150284   -0.0440811
  0.170311    -0.885203    -0.225743    -0.664263    0.236138     0.264117     0.200344     0.461124    0.0573763   0.244454    -0.295839      0.0922359  -0.0715449  -0.498363     0.19297     0.0215874    -0.146056    -0.190908   -0.133354     0.280949    0.00545389  -0.181182     0.253569    -0.299255      0.107958    0.305989
 -0.304661     0.186042     0.277228    -0.494744    0.357823     0.136044     0.0200954    0.363804    0.323444   -0.453924     0.794881      0.233099    0.438586    0.155653     0.207866   -0.184296      0.708773    -0.472305    0.0597917    0.133746   -0.206405     0.0599119   -0.361492    -0.123567      0.0520342  -0.262171
 -0.647146     0.706064    -0.156535     0.104088   -0.408575    -1.17272      0.369477    -0.0952418  -0.452704   -0.310741    -0.0668828     0.0622043  -0.215841    0.10434     -0.121335   -0.224037     -0.358256     0.13383     0.132497    -0.178878   -0.0127353   -0.624306    -0.0883868    0.179434     -0.293496    0.387355
 -0.362849     0.146208    -0.687686    -0.0525273  -0.222547    -0.0237221    0.313864    -0.324928    0.395831   -0.320516     0.85174       0.492192   -0.469185   -0.307237     0.0678979   0.110453      0.257542    -0.0144584   0.129498     0.571675    0.420053     0.142333     0.0850481    0.00917305    0.648921    0.300934
 -0.256079     0.631712    -0.815723    -0.800748   -0.00248015  -0.146972     0.232449     0.344601    0.430421    0.371916     0.229062     -0.0908263   0.476115   -0.26359      0.460213    0.308965     -0.0313998    0.143932   -0.476762     0.132062   -0.131848     0.351922    -0.00766354   0.208634     -0.401473    0.299723
  0.28353      0.162792    -0.0361774    0.0284146   0.31134     -0.23966     -0.110815    -0.451415    0.235896   -0.409393     0.542798      0.593077   -0.234964    0.0365335   -0.720815   -0.0549853    -0.202744    -0.564398    0.118853    -0.735208    0.0752598    0.576507     0.235085    -0.222679     -0.0753579   0.0635587
  0.0332802    0.160139    -0.00835855   0.238111   -0.084406    -0.0163554   -0.0644727   -0.11286     0.430058   -0.0478126    0.125385      0.5833     -0.608474   -0.436305    -0.660906    0.254832     -0.565032    -0.0977334  -0.358056     0.471667    0.00223965   0.00939624   0.216822     0.831582     -0.237199   -0.419318
  0.219029    -0.0224904   -0.142208     0.0774873  -0.245028    -0.0485354    0.122508    -0.679757    0.928588    0.488988    -0.377126     -0.615921    0.420213    0.54126     -0.313486   -0.247752      0.0278497    0.198206   -0.00772966   0.0672568  -0.034897    -0.286012     0.38174      0.517087      0.300699    0.341945
  0.180097     0.218492     0.0682813    0.119645   -0.390226     0.294966     0.0138789   -0.166664   -0.144319    0.256934     0.130432      0.17612    -0.526832    0.204053     1.03289    -0.40828      -0.761598     0.417564    0.72632      0.170212   -0.878095    -0.215318    -0.300305     0.462051     -0.578663    0.55697
  0.254068    -0.663023     0.136196     0.406976    0.0829063   -0.103517     0.0786174   -0.291557   -0.475554    0.076194    -1.25312      -0.161847   -0.558833    0.0495828   -0.384767   -0.217702     -0.792799     0.127038   -0.24752     -0.538967    0.0952239   -0.369724     0.227624     0.263797     -0.127947   -0.284202
  0.179373    -0.00395073   0.0143601    0.248404    0.107687     0.994858     0.475275    -0.123583    0.348766    0.0593343    0.246753     -0.24948    -0.216815    0.389189     0.393977   -0.149676      0.502437     0.274426   -0.154486     0.129324    0.220372     0.631236     0.195633    -0.000646304   0.184783    0.0246753
 -0.29822      0.337794    -0.306236    -0.0277467  -0.607259     0.304159     0.0357305   -0.155957    0.0236825   0.228599    -0.296148      0.151411    0.0128444   0.472555    -0.040333    0.274136      0.340651    -0.132561    0.200022     0.392851    0.134318     0.0253459    0.433509    -0.479508     -0.256223    0.355667
  0.387672    -0.27731      0.300437    -0.0819255   0.241102    -0.231515    -0.0948791   -0.3777      0.226919    0.59928     -0.415366      0.103085   -0.434619   -0.147676    -0.41188     0.433595     -0.144007     0.242497   -0.00195855  -0.334646    0.120193    -0.247014    -0.0948945    0.298811      0.525225    0.429509
  0.16673      0.318657     0.275971    -0.0358238   0.21208      0.0487761   -0.095843    -0.39201    -0.554261   -0.244437    -0.0591068    -0.664197    0.20112    -0.424266    -0.225061    0.515969     -0.484157    -0.150125   -0.51582     -0.0544151   0.609689    -0.249416     0.226637    -0.41172       0.12022    -0.469077
 -0.0686551    0.354838    -0.0171247   -0.239666   -0.187127    -0.748643     0.0716546    0.179557    0.27517    -0.0136749   -0.232966     -0.570916    0.824103    0.042474    -0.0595249   0.633393     -0.36345     -0.0443389   0.474484     0.247584   -0.106747    -0.103893    -0.313667     0.239423     -0.0970273  -0.671307
 -0.177693    -0.0172435   -0.115244     0.165654    0.0121891   -0.116579     0.00544018   0.119244   -0.0252492   0.0522448   -0.00712331   -0.0710582  -0.0667857  -0.208914     0.0345466  -0.000949666  -0.122915     0.132192   -0.0797313    0.0696215  -0.0307189   -0.00358019  -0.013976     0.354124     -0.0843947  -0.12176
  0.438115    -0.261918     0.0695085    0.22652    -0.929379     0.209406    -0.00404886  -0.0796049  -0.355975    0.0789699   -0.127846     -0.304899   -0.161142    0.0516668    0.368734    0.245671      0.535414     0.381636    0.442428    -0.155426   -0.431627    -0.504781    -0.231903    -0.722458     -0.155048    0.503144
  0.150839    -0.107928     0.171149    -0.207692    0.0722985   -0.00737594   0.0648939   -0.0617133   0.0351764  -0.0560313   -0.000121999   0.0778894   0.0614424   0.204689    -0.022309   -0.0233817     0.115533    -0.150001    0.127483    -0.191304    0.00257751   0.0284294    0.074122    -0.18489       0.0555155   0.122169
  0.670729    -0.0657735    0.481111    -0.595494   -0.211031     0.297525     0.176251    -0.426       0.226306    0.081189     0.688264      0.114722    0.564947   -0.598968     0.0527832  -0.290875      0.136708     0.116717    0.44169      0.160652    0.529607    -0.501062    -0.235298    -0.228882      0.173725   -0.0110712
 -0.0259587    0.0881687   -0.169427    -0.103858   -0.0671447    0.230726     0.0457667   -0.034726   -0.152467   -0.112517     0.257274      0.0936172  -0.154515   -0.0459299    0.0304401   0.0486721     0.0980772   -0.143911   -0.0627696    0.117503    0.107634     0.220733     0.19895     -0.389318     -0.0595602   0.0792418
  0.408017    -0.108212     0.389745    -0.576835    0.854678     0.378809    -0.386897     0.158691   -0.362414    0.710988     0.240394      0.200713    0.0197267  -0.0695419   -0.0698063   0.129147      0.195036     0.0845111  -0.243376    -0.608331   -0.158033     0.0437025   -0.233543    -0.768802     -0.292834    0.356517
  0.00625882  -0.512724     0.948791     0.563802    0.267103     0.288701    -0.137289     0.0576602  -0.40021    -0.389533     0.443717      0.640923   -0.394701   -0.0147649   -0.0796848  -0.48714       0.308878    -0.472457   -0.232282    -0.0141598   0.568538    -0.227022     0.412759     0.0944906     0.238881    0.225353
 -0.432902    -0.282044    -0.0998326    0.053994   -0.0119527   -0.0910282    0.00886899   0.472001    0.651368    0.429981     0.0740938     0.987522   -0.324703    0.455896     0.0290114  -0.513732      0.448708    -0.0677952   0.655469    -0.0391937  -0.551372     0.260574    -0.0921943    0.451328     -0.244521    0.331521[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408828
[ Info: iteration 2, average log likelihood -1.408818
[ Info: iteration 3, average log likelihood -1.408808
[ Info: iteration 4, average log likelihood -1.408798
[ Info: iteration 5, average log likelihood -1.408789
[ Info: iteration 6, average log likelihood -1.408779
[ Info: iteration 7, average log likelihood -1.408771
[ Info: iteration 8, average log likelihood -1.408762
[ Info: iteration 9, average log likelihood -1.408754
[ Info: iteration 10, average log likelihood -1.408746
┌ Info: EM with 100000 data points 10 iterations avll -1.408746
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
