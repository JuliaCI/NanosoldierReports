Julia Version 1.5.0-DEV.11
Commit 18783434e9 (2020-01-04 00:48 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed Arpack_jll ───────── v3.5.0+2
 Installed GaussianMixtures ─── v0.3.0
 Installed CMake ────────────── v1.1.2
 Installed JLD ──────────────── v0.9.1
 Installed Blosc ────────────── v0.5.1
 Installed StatsFuns ────────── v0.9.3
 Installed QuadGK ───────────── v2.3.1
 Installed BinDeps ──────────── v1.0.0
 Installed Parameters ───────── v0.12.0
 Installed Missings ─────────── v0.4.3
 Installed DataAPI ──────────── v1.1.0
 Installed SpecialFunctions ─── v0.9.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed Rmath ────────────── v0.6.0
 Installed OrderedCollections ─ v1.1.0
 Installed HDF5 ─────────────── v0.12.5
 Installed URIParser ────────── v0.4.0
 Installed Compat ───────────── v2.2.0
 Installed Arpack ───────────── v0.4.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed NearestNeighbors ─── v0.4.4
 Installed SortingAlgorithms ── v0.3.1
 Installed LegacyStrings ────── v0.4.1
 Installed StatsBase ────────── v0.32.0
 Installed Clustering ───────── v0.13.3
 Installed FillArrays ───────── v0.8.2
 Installed DataStructures ───── v0.17.7
 Installed BinaryProvider ───── v0.5.8
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed OpenBLAS_jll ─────── v0.3.7+3
 Installed FileIO ───────────── v1.2.1
 Installed Distributions ────── v0.22.0
 Installed PDMats ───────────── v0.9.10
 Installed Distances ────────── v0.8.2
 Installed StaticArrays ─────── v0.12.1
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.0
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+3
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_54s1ja/Project.toml`
 [no changes]
  Updating `/tmp/jl_54s1ja/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_6nYEbC/Project.toml`
 [no changes]
  Updating `/tmp/jl_6nYEbC/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_ldpP23/Project.toml`
 [no changes]
  Updating `/tmp/jl_ldpP23/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_EzVaFL/Project.toml`
 [no changes]
  Updating `/tmp/jl_EzVaFL/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_hkgjkU/Project.toml`
 [no changes]
  Updating `/tmp/jl_hkgjkU/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_hkgjkU/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.0
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.874683008336837e6, [22007.74678125333, 77992.25321874667], [16325.12728796528 14326.674078211996 -1896.989753566369; -16296.120049543673 -14660.663515106085 1814.1183867890031], [[32431.722162155413 14137.481033026246 -187.41034943762332; 14137.481033026246 47685.13998978347 1959.5816356380044; -187.41034943762338 1959.5816356380042 22565.737466670835], [67432.70820782124 -13445.39167243737 556.9876199358939; -13445.39167243737 52134.99457284221 -2058.7667947742866; 556.9876199358939 -2058.766794774287 77676.41004211576]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.623174e+03
      1       1.083597e+03      -5.395770e+02 |        8
      2       9.377801e+02      -1.458169e+02 |        4
      3       8.556271e+02      -8.215305e+01 |        3
      4       7.976478e+02      -5.797927e+01 |        0
      5       7.976478e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 797.6478151662823)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.055522
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.809618
[ Info: iteration 2, lowerbound -3.689220
[ Info: iteration 3, lowerbound -3.555679
[ Info: iteration 4, lowerbound -3.398832
[ Info: iteration 5, lowerbound -3.234131
[ Info: iteration 6, lowerbound -3.081457
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.952220
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.843411
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.749812
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.658981
[ Info: iteration 11, lowerbound -2.578997
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.506050
[ Info: iteration 13, lowerbound -2.439395
[ Info: iteration 14, lowerbound -2.389143
[ Info: iteration 15, lowerbound -2.351491
[ Info: iteration 16, lowerbound -2.324557
[ Info: iteration 17, lowerbound -2.309623
[ Info: iteration 18, lowerbound -2.308512
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302915
[ Info: iteration 20, lowerbound -2.299259
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Jan  7 03:19:27 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Jan  7 03:19:35 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Tue Jan  7 03:19:38 2020: EM with 272 data points 0 iterations avll -2.055522
5.8 data points per parameter
, Tue Jan  7 03:19:40 2020: GMM converted to Variational GMM
, Tue Jan  7 03:19:48 2020: iteration 1, lowerbound -3.809618
, Tue Jan  7 03:19:48 2020: iteration 2, lowerbound -3.689220
, Tue Jan  7 03:19:48 2020: iteration 3, lowerbound -3.555679
, Tue Jan  7 03:19:48 2020: iteration 4, lowerbound -3.398832
, Tue Jan  7 03:19:48 2020: iteration 5, lowerbound -3.234131
, Tue Jan  7 03:19:48 2020: iteration 6, lowerbound -3.081457
, Tue Jan  7 03:19:49 2020: dropping number of Gaussions to 7
, Tue Jan  7 03:19:49 2020: iteration 7, lowerbound -2.952220
, Tue Jan  7 03:19:49 2020: dropping number of Gaussions to 6
, Tue Jan  7 03:19:49 2020: iteration 8, lowerbound -2.843411
, Tue Jan  7 03:19:49 2020: dropping number of Gaussions to 5
, Tue Jan  7 03:19:49 2020: iteration 9, lowerbound -2.749812
, Tue Jan  7 03:19:49 2020: dropping number of Gaussions to 4
, Tue Jan  7 03:19:49 2020: iteration 10, lowerbound -2.658981
, Tue Jan  7 03:19:49 2020: iteration 11, lowerbound -2.578997
, Tue Jan  7 03:19:49 2020: dropping number of Gaussions to 3
, Tue Jan  7 03:19:49 2020: iteration 12, lowerbound -2.506050
, Tue Jan  7 03:19:49 2020: iteration 13, lowerbound -2.439395
, Tue Jan  7 03:19:49 2020: iteration 14, lowerbound -2.389143
, Tue Jan  7 03:19:49 2020: iteration 15, lowerbound -2.351491
, Tue Jan  7 03:19:49 2020: iteration 16, lowerbound -2.324557
, Tue Jan  7 03:19:49 2020: iteration 17, lowerbound -2.309623
, Tue Jan  7 03:19:49 2020: iteration 18, lowerbound -2.308512
, Tue Jan  7 03:19:49 2020: dropping number of Gaussions to 2
, Tue Jan  7 03:19:49 2020: iteration 19, lowerbound -2.302915
, Tue Jan  7 03:19:49 2020: iteration 20, lowerbound -2.299259
, Tue Jan  7 03:19:49 2020: iteration 21, lowerbound -2.299256
, Tue Jan  7 03:19:49 2020: iteration 22, lowerbound -2.299254
, Tue Jan  7 03:19:49 2020: iteration 23, lowerbound -2.299254
, Tue Jan  7 03:19:49 2020: iteration 24, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 25, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 26, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 27, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 28, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 29, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 30, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 31, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 32, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 33, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 34, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 35, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 36, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 37, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 38, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 39, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 40, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 41, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 42, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 43, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 44, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 45, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 46, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 47, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 48, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 49, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: iteration 50, lowerbound -2.299253
, Tue Jan  7 03:19:49 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601396, 95.95490777398604]
β = [178.04509222601396, 95.95490777398604]
m = [4.250300733269909 79.28686694436183; 2.0002292577753695 53.851987172461286]
ν = [180.04509222601396, 97.95490777398604]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484358 -0.007644049042327234; 0.0 0.00858170516633351], [0.37587636119484386 -0.0089531238273462; 0.0 0.012748664777409387]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999994
avll from stats: -0.9850021072770594
avll from llpg:  -0.9850021072770576
avll direct:     -0.9850021072770576
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9980289014742334
avll from llpg:  -0.9980289014742332
avll direct:     -0.9980289014742332
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0157721     0.076779    -0.0195839    0.0164674    0.110568    0.0214898    -0.0800959    0.0394883   -0.20683     -0.017748     0.028531      0.231455    -0.178375    0.186636     0.0723852    -0.00327018    0.0834204    0.0449769    0.0842082    0.0884652   0.075069    -0.0503461   -0.00176143  -0.119876     0.183946     -0.103963
 -0.039785     -0.101915     0.0577195    0.0562013   -0.149432    0.129818     -0.0199232    0.0394851    0.0699835   -0.08496      0.080274     -0.0618462   -0.0486404   0.0234159    0.0726807    -0.121768      0.107544    -0.0555737   -0.145745    -0.0216393  -0.00749225  -0.0596453   -0.0654082    0.0774835    0.0188012    -0.0172481
  0.0850064     0.0542199    0.125591    -0.042318    -0.0262373   0.164906     -0.0460817    0.0201514    0.0230989    0.0443499    0.0369505     0.135868     0.10031    -0.0623866   -0.160617      0.0522372     0.0213336    0.209127     0.0933274   -0.0161261  -0.0544166    0.118071     0.00435184  -0.0670105   -0.117998      0.0168608
 -0.0298959    -0.214687    -0.0689855   -0.0316939   -0.0422161   0.102945     -0.0440772   -0.142732    -0.0170348   -0.139801     0.0756225     0.158002    -0.075133    0.037966    -0.116362     -0.113775     -0.0870045   -0.119769    -0.0940363   -0.137696   -0.0384682    0.00328614   0.0665509   -0.084092    -0.0404138     0.182304
 -0.000285575  -0.120498    -0.0174269    0.0661434    0.0262489  -0.0218394    -0.233458     0.0820701   -0.0332602    0.102638     0.173505      0.00889985  -0.0134312  -0.10937     -0.0757481    -0.000562242   0.00323486   0.0478355    0.0359301   -0.154857   -0.048419     0.180729     0.129714    -0.177024     0.1222        0.0916428
 -0.141837     -0.052878     0.125521     0.0767142    0.152241   -0.0672207     0.110931     0.102786    -0.0170404   -0.0311122    0.156893      0.126886     0.0909033   0.115564     0.229315     -0.00828118    0.0328403    0.0091667    0.067548     0.0803633   0.116293    -0.142156     0.198752     0.156625    -0.112947     -0.0324278
  0.0118898     0.0255742    0.0764765    0.103105     0.0923162  -0.115899     -0.229679    -0.0273315   -0.0305491    0.116582    -0.0222919     0.0997751    0.0245377  -0.313906    -0.0664736    -0.000231571  -0.12958     -0.143735    -0.103163    -0.021615    0.0999435    0.0826619   -0.0853105   -0.17639      0.101401      0.0651427
  0.0191361    -0.0158802   -0.110398     0.0261727    0.0236964   0.053512     -0.117066     0.192938     0.0273826   -0.136268    -0.106865     -0.00146574   0.0358605  -0.0699615    0.151055     -0.0254783     0.170093    -0.137064     0.0261139    0.142692   -0.108326     0.0921861   -0.150291    -0.0755882    0.00672103    0.0777455
  0.186332      0.0897058   -0.226724     0.0975132   -0.110041   -0.0929102    -0.086953    -0.0510042   -0.112633     0.106977     0.0748083     0.099175    -0.0535019   0.0491653    0.152991      0.0259798     0.167185    -0.13664     -0.0714679   -0.132929   -0.1308       0.183882    -0.00104503  -0.0799535    0.0805194    -0.252983
 -0.00157096    0.0159664    0.0692797   -0.0251411   -0.193229   -0.107385     -0.0460126   -0.0829373    0.0995346    0.0871205    0.113927      0.0734754    0.0711124   0.15457     -0.0018887     0.0827121    -0.112301    -0.0667727    0.00254119  -0.0575636  -0.0520009    0.00992978   0.0440145    0.219463     0.061248     -0.168748
  0.104318      0.162427     0.0318851    0.0154567   -0.0127989   0.051521     -0.0831152    0.0969781    0.10988     -0.0734372   -0.161318     -0.0538788    0.103836    0.190557     0.159269      0.0634822    -0.193878    -0.050807     0.0498131    0.102246   -0.0563595    0.079423     0.0372377   -0.0475309    0.137108     -0.0597737
 -0.132528      0.130146     0.00676548  -0.0304656   -0.0286742  -0.201934     -0.0738561    0.017473     0.00245643  -0.0721162    0.0374659     0.133223     0.0747029   0.0622434   -0.0392954     0.0593405    -0.116741     0.0129098    0.120851     0.0350807   0.150443    -0.0324374    0.108486    -0.110579     0.0356886     0.0472007
 -0.162368     -0.125108    -0.0152435   -0.126605     0.072833    0.156211     -0.0242231   -0.157755    -0.200125     0.0149924    0.0272917    -0.155993     0.0702819  -0.129839     0.0452861     0.207069     -0.0461433   -0.115437    -0.0201387    0.204714   -0.107397     0.0195339    0.00316874  -0.208204    -0.172568      0.0253787
 -0.136366      0.0872519   -0.0707963    0.0498125    0.0715771  -0.0978244    -0.0578815   -0.0147973    0.0708848   -0.140579    -0.0257192    -0.0668625   -0.123593   -0.0333665   -0.00125855    0.0546835    -0.235571    -0.0584626    0.0523648    0.0545885   0.0775833   -0.0620459    0.0632827   -0.0628164   -0.119377      0.113243
  0.142587      0.00146057  -0.090191     0.195299     0.148893    0.0375072     0.0225504    0.0514666    0.0434668   -0.184328     0.0836551    -0.0600797    0.0444977   0.0191849   -0.0087485    -0.0208663     0.138645     0.0149074    0.0823866    0.0473043   0.209215     0.246587     0.017995    -0.0689664    0.133642     -0.173275
 -0.092743      0.156241     0.0506045    0.140839    -0.0119065   0.0149106     0.00394479  -0.152959    -0.128556     0.0807152    0.0730703    -0.262273     0.0390217   0.0690461    0.00476943   -0.0108533     0.0174672   -0.104609    -0.120572    -0.011446    0.0131998    0.0256954   -0.0236918   -0.0134314   -0.037788     -0.14598
 -0.0104073    -0.101471    -0.147594    -0.166578     0.0113398   0.0167042     0.0251638    0.0797498   -0.00408871  -0.135419    -0.0553921     0.035854     0.0655602  -0.049744    -0.0145523    -0.144525     -0.0324662   -0.0707683    0.0595387   -0.0458175   0.141164     0.0405717    0.18475      0.0107902   -0.0404261     0.106189
  0.00892614   -0.101107    -0.265627    -0.0486854    0.10034    -0.0162236    -0.0926214    0.0793951   -0.0878169   -0.0804009    0.0309917    -0.0179972    0.0450454  -0.00532612   0.0185906    -0.0209263    -0.0995806    0.122754     0.00883358  -0.0981004   0.104372    -0.0591774    0.00921286  -0.00217385   0.0269036    -0.17589
 -0.0902923    -0.0591091   -0.0672687    0.0804777    0.0157213   0.0443911    -0.00869703  -0.0789159   -0.10607     -0.0318378   -0.142529     -0.00198582   0.0127675   0.0864113    0.103858     -0.0766456     0.0322747   -0.0117481   -0.058279    -0.161566    0.0316249   -0.0353682    0.0938232    0.198165    -0.139831     -0.15133
  0.0189089    -0.0905834   -0.00859146   0.0716365    0.0430203   0.00838509    0.110802    -0.00305784  -0.0435101    0.0523874    0.108788     -0.113757     0.233456    0.0306174    0.00367547   -0.00350942   -0.0690024    0.0669877    0.0080802    0.0145148  -0.0909791   -0.118781     0.108536     0.134699    -0.129352      0.0045055
 -0.0281731     0.00348705   0.137632     0.0138232   -0.066776   -0.0519727    -0.116723     0.08244      0.249457     0.182458     0.136718      0.105138     0.0288159   0.192467    -0.127434      0.0658521     0.0940164   -0.00762148   0.0557979    0.149386   -0.189175     0.0528488   -0.155327     0.0825771    0.000643816  -0.0499907
  0.112781      0.0871555   -0.172759    -0.00177097   0.072372   -0.0199315     0.0913438   -0.136429     0.0121843   -0.0338159    0.00355974   -0.13582     -0.0235788   0.020906    -0.0411496     0.0283709    -0.0614995   -0.0273537   -0.072162     0.044307   -0.0321814   -0.0155189   -0.0417297    0.0357449    0.0618707    -0.0784266
  0.0512388    -0.0275778   -0.101221    -0.0172889   -0.0294534   0.0180363     0.00715532   0.00701233  -0.178728    -0.0265519   -0.085457     -0.0390062    0.0114224  -0.125399    -0.16214       0.0360237    -0.12639      0.0935166   -0.00611033  -0.108435    0.19761     -0.122083     0.108599     0.0299402   -0.104671      0.0304113
 -0.0180285    -0.0313614    0.0948115   -0.0513404    0.0232106   0.00764484   -0.00494826   0.236007    -0.0427669    0.140787     0.00832605   -0.207976     0.0318922  -0.0107081    0.147692     -0.0494552    -0.113232     0.00816688  -0.104223     0.0943671  -0.0415481   -0.0350073   -0.068939     0.0161249    0.0618809     0.00510047
  0.0261773    -0.154783     0.0558582    0.22548      0.0378056   0.183952      0.0388217   -0.075593    -0.0897907   -0.09487     -0.0914673     0.199699    -0.0758072   0.0305024    0.000388192   0.123665      0.0962118   -0.0790861   -0.0136916   -0.0263005  -0.016442     0.208776     0.127634    -0.10123     -0.25473      -0.199165
  0.0466161     0.0756237   -0.0330197    0.0464785    0.0010879  -0.024921      0.0464092   -0.0691463    0.0641801   -0.108282    -0.0317665    -0.0131392   -0.0944916   0.202607    -0.141435      0.0567748     0.0995159    0.0376197    0.0373017   -0.0389153  -0.0382179    0.0407748   -0.00340286  -0.0198777   -0.0258997     0.183775
  0.0377113    -0.0242392   -0.111911    -0.0802653   -0.148968   -0.000388479  -0.0292421    0.0631051   -0.0330669   -0.11449     -0.0980753    -0.160421    -0.154019    0.118246     0.0175551    -0.0260754     0.14871     -0.110776    -0.15039     -0.077722    0.0572948    0.0095599    0.113311     0.0677041   -0.145015      0.0773501
  0.192145     -0.0431568   -0.0138263    0.040056    -0.0317191   0.17134       0.00204109  -0.118761     0.00478936  -0.00930109   0.0396459    -0.0881834   -0.030168    0.0801638    0.0152651    -0.00135333   -0.0751031   -0.00126275  -0.129913    -0.0566704  -0.103305     0.0616876    0.17864     -0.220461    -0.0238253     0.120845
 -0.233485      0.101646     0.00751684   0.147124     0.107833    0.00663276   -0.105363     0.0939388   -0.021142     0.0588218   -0.167234      0.0225694   -0.123905   -0.0303003   -0.00787004   -0.0941945    -0.0451019    0.0780526    0.0311527   -0.123817    0.031623     0.0611494   -0.0100273    0.0297438    0.0285142    -0.093702
 -0.0445756     0.115677     0.0280447   -0.0231839    0.0484897   0.103883      0.0836695    0.115952    -0.156919     0.0884075    0.000592366  -0.0187897   -0.0118613   0.00818149  -0.131608      0.0255002    -0.0588928    0.132345    -0.0766121   -0.0751524   0.0462972    0.0121067   -0.0849208    0.11065     -0.026802     -0.147131
  0.00518983    0.108929     0.00304556  -0.0113236    0.141226    0.091985      0.0784285    0.161274     0.0353706    0.0294887   -0.146412      0.0563521   -0.0416336   0.0124439   -0.118398      0.129631      0.0069673    0.180544     0.00638747  -0.0375604   0.0298947   -0.215965     0.00894656   0.0881609    0.0864959     0.121796
 -0.0666972    -0.0778426    0.135172    -0.00644166   0.226037    0.115111     -0.0145268   -0.129613     0.0390516   -0.00148738   0.0783842    -0.0536009   -0.0102571  -0.00203374  -0.0281867    -0.0944791     0.0895871    0.0617458    0.168408    -0.0405763   0.0506804   -0.0293846   -0.0518586   -0.0666262    0.138836      0.100899kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3940800422114328
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.394147
[ Info: iteration 2, average log likelihood -1.394081
[ Info: iteration 3, average log likelihood -1.393490
[ Info: iteration 4, average log likelihood -1.386523
[ Info: iteration 5, average log likelihood -1.370312
[ Info: iteration 6, average log likelihood -1.364060
[ Info: iteration 7, average log likelihood -1.362548
[ Info: iteration 8, average log likelihood -1.361532
[ Info: iteration 9, average log likelihood -1.360759
[ Info: iteration 10, average log likelihood -1.360179
[ Info: iteration 11, average log likelihood -1.359724
[ Info: iteration 12, average log likelihood -1.359259
[ Info: iteration 13, average log likelihood -1.358533
[ Info: iteration 14, average log likelihood -1.357448
[ Info: iteration 15, average log likelihood -1.356569
[ Info: iteration 16, average log likelihood -1.356016
[ Info: iteration 17, average log likelihood -1.355580
[ Info: iteration 18, average log likelihood -1.355174
[ Info: iteration 19, average log likelihood -1.354763
[ Info: iteration 20, average log likelihood -1.354430
[ Info: iteration 21, average log likelihood -1.354185
[ Info: iteration 22, average log likelihood -1.354000
[ Info: iteration 23, average log likelihood -1.353840
[ Info: iteration 24, average log likelihood -1.353671
[ Info: iteration 25, average log likelihood -1.353441
[ Info: iteration 26, average log likelihood -1.353077
[ Info: iteration 27, average log likelihood -1.352731
[ Info: iteration 28, average log likelihood -1.352541
[ Info: iteration 29, average log likelihood -1.352454
[ Info: iteration 30, average log likelihood -1.352410
[ Info: iteration 31, average log likelihood -1.352385
[ Info: iteration 32, average log likelihood -1.352368
[ Info: iteration 33, average log likelihood -1.352357
[ Info: iteration 34, average log likelihood -1.352349
[ Info: iteration 35, average log likelihood -1.352344
[ Info: iteration 36, average log likelihood -1.352340
[ Info: iteration 37, average log likelihood -1.352337
[ Info: iteration 38, average log likelihood -1.352334
[ Info: iteration 39, average log likelihood -1.352333
[ Info: iteration 40, average log likelihood -1.352332
[ Info: iteration 41, average log likelihood -1.352331
[ Info: iteration 42, average log likelihood -1.352330
[ Info: iteration 43, average log likelihood -1.352329
[ Info: iteration 44, average log likelihood -1.352329
[ Info: iteration 45, average log likelihood -1.352329
[ Info: iteration 46, average log likelihood -1.352328
[ Info: iteration 47, average log likelihood -1.352328
[ Info: iteration 48, average log likelihood -1.352328
[ Info: iteration 49, average log likelihood -1.352328
[ Info: iteration 50, average log likelihood -1.352328
┌ Info: EM with 100000 data points 50 iterations avll -1.352328
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3941471900978222
│     -1.394081367514821
│      ⋮
└     -1.3523277739814004
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.352487
[ Info: iteration 2, average log likelihood -1.352344
[ Info: iteration 3, average log likelihood -1.351376
[ Info: iteration 4, average log likelihood -1.342513
[ Info: iteration 5, average log likelihood -1.322626
[ Info: iteration 6, average log likelihood -1.311928
[ Info: iteration 7, average log likelihood -1.308434
[ Info: iteration 8, average log likelihood -1.306761
[ Info: iteration 9, average log likelihood -1.305785
[ Info: iteration 10, average log likelihood -1.305153
[ Info: iteration 11, average log likelihood -1.304680
[ Info: iteration 12, average log likelihood -1.304285
[ Info: iteration 13, average log likelihood -1.303938
[ Info: iteration 14, average log likelihood -1.303627
[ Info: iteration 15, average log likelihood -1.303348
[ Info: iteration 16, average log likelihood -1.303082
[ Info: iteration 17, average log likelihood -1.302814
[ Info: iteration 18, average log likelihood -1.302548
[ Info: iteration 19, average log likelihood -1.302273
[ Info: iteration 20, average log likelihood -1.301981
[ Info: iteration 21, average log likelihood -1.301673
[ Info: iteration 22, average log likelihood -1.301349
[ Info: iteration 23, average log likelihood -1.301038
[ Info: iteration 24, average log likelihood -1.300835
[ Info: iteration 25, average log likelihood -1.300722
[ Info: iteration 26, average log likelihood -1.300642
[ Info: iteration 27, average log likelihood -1.300575
[ Info: iteration 28, average log likelihood -1.300515
[ Info: iteration 29, average log likelihood -1.300458
[ Info: iteration 30, average log likelihood -1.300403
[ Info: iteration 31, average log likelihood -1.300353
[ Info: iteration 32, average log likelihood -1.300309
[ Info: iteration 33, average log likelihood -1.300270
[ Info: iteration 34, average log likelihood -1.300235
[ Info: iteration 35, average log likelihood -1.300206
[ Info: iteration 36, average log likelihood -1.300181
[ Info: iteration 37, average log likelihood -1.300159
[ Info: iteration 38, average log likelihood -1.300142
[ Info: iteration 39, average log likelihood -1.300127
[ Info: iteration 40, average log likelihood -1.300114
[ Info: iteration 41, average log likelihood -1.300103
[ Info: iteration 42, average log likelihood -1.300094
[ Info: iteration 43, average log likelihood -1.300085
[ Info: iteration 44, average log likelihood -1.300078
[ Info: iteration 45, average log likelihood -1.300071
[ Info: iteration 46, average log likelihood -1.300065
[ Info: iteration 47, average log likelihood -1.300060
[ Info: iteration 48, average log likelihood -1.300055
[ Info: iteration 49, average log likelihood -1.300050
[ Info: iteration 50, average log likelihood -1.300046
┌ Info: EM with 100000 data points 50 iterations avll -1.300046
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3524865436531155
│     -1.352344059089928
│      ⋮
└     -1.3000455623143221
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.300248
[ Info: iteration 2, average log likelihood -1.300056
[ Info: iteration 3, average log likelihood -1.299102
[ Info: iteration 4, average log likelihood -1.291409
[ Info: iteration 5, average log likelihood -1.275538
[ Info: iteration 6, average log likelihood -1.263288
[ Info: iteration 7, average log likelihood -1.257841
[ Info: iteration 8, average log likelihood -1.254641
[ Info: iteration 9, average log likelihood -1.251709
[ Info: iteration 10, average log likelihood -1.248886
[ Info: iteration 11, average log likelihood -1.245747
[ Info: iteration 12, average log likelihood -1.242098
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.237680
[ Info: iteration 14, average log likelihood -1.250988
[ Info: iteration 15, average log likelihood -1.242192
[ Info: iteration 16, average log likelihood -1.239053
[ Info: iteration 17, average log likelihood -1.237635
[ Info: iteration 18, average log likelihood -1.236256
[ Info: iteration 19, average log likelihood -1.234263
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.231665
[ Info: iteration 21, average log likelihood -1.245089
[ Info: iteration 22, average log likelihood -1.238420
[ Info: iteration 23, average log likelihood -1.236085
[ Info: iteration 24, average log likelihood -1.235069
[ Info: iteration 25, average log likelihood -1.234032
[ Info: iteration 26, average log likelihood -1.232501
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.230275
[ Info: iteration 28, average log likelihood -1.243041
[ Info: iteration 29, average log likelihood -1.237085
[ Info: iteration 30, average log likelihood -1.235131
[ Info: iteration 31, average log likelihood -1.234310
[ Info: iteration 32, average log likelihood -1.233532
[ Info: iteration 33, average log likelihood -1.232543
[ Info: iteration 34, average log likelihood -1.231386
[ Info: iteration 35, average log likelihood -1.229993
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.227961
[ Info: iteration 37, average log likelihood -1.242760
[ Info: iteration 38, average log likelihood -1.236908
[ Info: iteration 39, average log likelihood -1.234899
[ Info: iteration 40, average log likelihood -1.233995
[ Info: iteration 41, average log likelihood -1.233084
[ Info: iteration 42, average log likelihood -1.231940
[ Info: iteration 43, average log likelihood -1.230596
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.228795
[ Info: iteration 45, average log likelihood -1.242661
[ Info: iteration 46, average log likelihood -1.236905
[ Info: iteration 47, average log likelihood -1.234892
[ Info: iteration 48, average log likelihood -1.233971
[ Info: iteration 49, average log likelihood -1.233047
[ Info: iteration 50, average log likelihood -1.231891
┌ Info: EM with 100000 data points 50 iterations avll -1.231891
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.300247652352576
│     -1.3000557217633697
│      ⋮
└     -1.2318913329333543
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.230774
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.228660
[ Info: iteration 3, average log likelihood -1.230034
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.222040
[ Info: iteration 5, average log likelihood -1.198004
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.167797
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.155575
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.155043
[ Info: iteration 9, average log likelihood -1.151087
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.144670
[ Info: iteration 11, average log likelihood -1.154250
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.145826
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.146096
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.149500
[ Info: iteration 15, average log likelihood -1.151044
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.142569
[ Info: iteration 17, average log likelihood -1.152223
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.144010
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.144677
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.148175
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.146365
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.143674
[ Info: iteration 23, average log likelihood -1.150683
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.141585
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.141337
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.143594
[ Info: iteration 27, average log likelihood -1.156060
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.142769
[ Info: iteration 29, average log likelihood -1.150430
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.142023
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.142493
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.146152
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.144250
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.141964
[ Info: iteration 35, average log likelihood -1.149469
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.141109
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.141857
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.145989
[ Info: iteration 39, average log likelihood -1.144196
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.138786
[ Info: iteration 41, average log likelihood -1.149038
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.141073
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.141781
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.145878
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.143992
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.141865
[ Info: iteration 47, average log likelihood -1.149444
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.141106
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.141826
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.145997
┌ Info: EM with 100000 data points 50 iterations avll -1.145997
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.23077362482984
│     -1.2286602471520665
│      ⋮
└     -1.1459972731529888
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.144514
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.138655
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.143097
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      8
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.124442
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     16
│     19
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.080636
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     18
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.058352
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.046294
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     23
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.064069
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     19
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.054662
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.045267
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.033252
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.044586
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     23
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.033510
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.056688
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.035913
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.044005
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     23
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.029302
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.051668
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.041720
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     23
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.055553
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.038178
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.063311
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.029436
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.035433
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.055964
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.048498
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.028961
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.066110
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.050679
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.039841
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.043098
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.054953
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.038506
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.052003
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.048941
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.038394
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.049869
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.057615
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.032580
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.049959
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.043980
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.048986
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.046621
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.045011
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.045212
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.062467
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.041900
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.036427
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.052755
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.054311
┌ Info: EM with 100000 data points 50 iterations avll -1.054311
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.144513609652184
│     -1.138654825244737
│      ⋮
└     -1.0543113888398232
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3940800422114328
│     -1.3941471900978222
│     -1.394081367514821
│     -1.3934899355296662
│      ⋮
│     -1.0364273362404723
│     -1.0527548032572174
└     -1.0543113888398232
32×26 Array{Float64,2}:
 -0.132348     0.0317489   -0.0710833    0.0319176    0.0903171    -0.0950567   -0.0493026    -0.0121778    0.0651275   -0.12247     -0.534847     0.00110385  -0.13684      0.0327807  -0.0647906     0.0460805    -0.204447     -0.100405      0.0712464   0.167396     0.039782    -0.0576226    0.0403719   -0.052863    -0.149825      0.0896032
 -0.126375     0.120681    -0.0748206    0.0547353    0.0462409    -0.0753342   -0.0553803    -0.0173354    0.0703785   -0.143033     0.573133    -0.131382    -0.108827    -0.093071   -0.0432558     0.0594119    -0.345388     -0.0381902     0.0396882   0.058914     0.097914    -0.0663815    0.0911014   -0.0662115   -0.0240477     0.151633
 -0.0152905    0.0182278    0.110152     0.103012     0.169039     -0.0941873   -0.233782     -0.0196067   -0.0283769    0.101378    -0.0146039    0.0951957    0.0255505   -0.297961   -0.0374729     0.000964019  -0.13225      -0.148699     -0.0909286  -0.0257786    0.106767     0.0804789   -0.0601629   -0.182572     0.0979081     0.0499813
  0.0541487    0.00625468   0.0348221    0.0239344   -0.00252969    0.0275731   -0.160123      0.0962376    0.0340111    0.0301885    0.00607291  -0.0308992    0.0473016    0.0340599   0.0292118     0.0430802    -0.0756905     0.00176379    0.0559301  -0.0352429   -0.0632754    0.139746     0.0817602   -0.114642     0.130372      0.0165555
  0.459685    -0.092159     0.0563809    0.224073     0.0350207     0.155436     0.0465624    -0.151621    -0.0897094   -0.0533281   -0.161637     0.183855    -0.0750664    0.0168766   0.00268254    0.0777884     0.0936155    -0.0607819     0.0134044  -0.950603    -0.38709      0.205209     0.125773     0.322899    -0.262686     -0.228392
  0.0591893   -0.275709     0.05591      0.246699     0.0338        0.197468     0.0591121     0.0304225   -0.0892109   -0.0865022   -0.0222762    0.200845    -0.0734743    0.0596151   0.0329043     0.182788      0.0936471    -0.0559774    -0.0496453  -0.00186695   1.46892      0.213457     0.120034    -0.361279    -0.244661     -0.0933131
 -0.761028    -0.13493      0.0536793    0.189562     0.0431029     0.198329     0.045991      0.262164    -0.0890707   -0.148029    -0.0512177    0.195299    -0.075665     0.095107   -0.0278935     0.260465      0.0922706    -0.0985197    -0.0700423  -0.241023    -0.953118     0.222999     0.151308    -0.879403    -0.245423     -0.22946
 -0.12555     -0.142562     0.054314     0.234628     0.0560403     0.164237     0.073014     -0.418748    -0.0900716   -0.132273    -0.0247615    0.185123    -0.0738616    0.0401844  -0.0096942     0.10393       0.0939186    -0.114771      0.121709    2.05184     -0.710432     0.210766     0.134428     0.087963    -0.251753     -0.36914
  0.171906    -0.0454052   -0.00355394   0.0418911   -0.000738676   0.170131    -0.000301841  -0.125821     0.012374     0.0257356    0.0291258   -0.105166    -0.0300204    0.0693431   0.0136453    -0.00541624   -0.0487717     0.0454635    -0.129519   -0.0353487   -0.106125     0.0675232    0.176417    -0.185857     0.000587812   0.120709
 -0.0199733    0.00085164   0.137357     0.0178973   -0.0397885    -0.0620243   -0.114391      0.0835311    0.247245     0.175006     0.138019     0.10799      0.0478463    0.164356   -0.126708      0.0639034     0.111337      0.0247084     0.0491311   0.146811    -0.182482     0.0530049   -0.160886     0.0799754    0.0137533    -0.0403914
 -0.0158789   -0.102365    -0.0117938    0.0841325    0.069355      0.00582639   0.108928      0.00333982  -0.0400155    0.0502549    0.102899    -0.106856     0.230804     0.043315    0.000875479   0.00143345   -0.0745684     0.10913       0.0120218   0.0132399   -0.089147    -0.118932     0.132769     0.138625    -0.114813      0.00615459
 -0.0366576    0.0951153   -0.0015313    0.00163519   0.0704057     0.0466693    0.0167084     0.0921109   -0.109955     0.00363396  -0.0471038    0.139718    -0.126618     0.117161   -0.0112873     0.0617395     0.0541948     0.122131      0.0550456   0.0184446    0.0562321   -0.137674     0.00277455  -0.0124158    0.150444     -0.00111565
 -0.0651892    0.045046     0.0547403    0.0532521    0.0369194     0.100039    -0.0762437     0.0576809   -0.0146484    0.0550296   -0.0625601    0.0674769   -0.00562768  -0.0218944  -0.0719534    -0.0414948    -0.0111407     0.154119      0.0744597  -0.0716343   -0.0137299    0.0896069   -0.0133896   -0.0132367   -0.0816098    -0.0455471
  0.0196601   -0.0304302   -0.0452298   -0.0555841    0.0719885     0.0474724    0.00443534   -0.00107772  -0.0504584   -0.0489562   -0.0221191   -0.0192954    0.0416018   -0.0587443  -0.0687051    -0.0779485    -0.0464662     0.000852394   0.051673   -0.0641784    0.134607    -0.0282755    0.0996825   -0.00599729  -0.0236831     0.0848958
  0.0381386   -0.0188164   -0.109119     0.0209837    0.00703551    0.0543465   -0.0954187     0.187729     0.0291687   -0.135304    -0.0877224   -0.0138727    0.0339104   -0.0785734   0.149296     -0.0210218     0.16794      -0.148929      0.0458585   0.143379    -0.105582     0.0814206   -0.245318    -0.0778623    0.00877049    0.140095
 -0.138986     0.114699     0.0213632   -0.0432291   -0.0296747    -0.188356    -0.0494422     0.0189878    0.00282604  -0.0589073    0.0273401    0.13665      0.0738585    0.0668882  -0.0377141     0.0509751    -0.12053       0.00743463    0.131666    0.0375771    0.145234    -0.0290337    0.102178    -0.0873156    0.0148408     0.0408735
 -0.146211    -0.135101    -0.0697474   -0.0413252    0.0656669     0.229961    -0.0222558    -0.102815    -0.187257    -0.10267      0.0271977   -0.0479812   -0.870804    -0.132425   -0.00594321    0.217789     -0.0439907    -0.107497     -0.0100981   0.238992    -0.107654    -0.0072091    0.165252    -0.207527    -0.187959      0.0223639
 -0.1776      -0.125851     0.0188003   -0.275628     0.0437009     0.0886593   -0.0245321    -0.287886    -0.214181     0.0904826    0.0272429   -0.262597     1.22644     -0.12145     0.0816266     0.200956     -0.0346319    -0.150193     -0.017953    0.156375    -0.113939     0.0342895   -0.287749    -0.206772    -0.165893      0.0477058
  0.0367069   -0.0917101   -0.112352    -0.198455    -0.140858      0.0314971   -0.0473428    -0.0999065   -0.0548895   -0.292156     0.0124145   -0.280489    -0.153749     0.0628445  -0.38115      -0.0746719     0.0704298    -0.138437     -0.150395   -0.139867     0.13099      0.087645     0.0747928    0.0678741   -0.166684      0.120323
  0.0398645    0.103706    -0.0715819    0.10188     -0.14835      -0.0356134   -0.00472732    0.184943    -0.00566344   0.147407    -0.194131     0.00510361  -0.13968      0.137883    0.622457      0.0277102     0.190153     -0.0728835    -0.136594    0.0485004    0.0471597   -0.0794931    0.155526     0.0662493   -0.0984971     0.142704
 -0.0388841   -0.103632     0.0630256   -0.00242952  -0.107079      0.128561    -0.00905501    0.033883     0.102982    -0.738102     0.0608741   -0.113084    -0.0722349    0.0500271   0.0239843    -0.123788      0.0890089    -0.0423109    -0.177371    0.00244749  -0.00227408  -0.163201    -0.242012     0.0533459    0.0164843    -0.0179655
 -0.0371586   -0.095768     0.051347     0.136169    -0.182077      0.137895    -0.00581522    0.0459175    0.0615136    0.612731     0.0904888    0.0468493   -0.0346281    0.016747    0.153514     -0.123744      0.0984413    -0.0816856    -0.159709   -0.0338141    0.0427032   -0.0295297    0.0124309    0.109821     0.0278339    -0.0170056
  0.108219     0.107201    -0.160242    -0.0224762    0.0812222    -0.0285037    0.0441818    -0.108251     0.0256173   -0.0309986   -0.0309482   -0.0801521   -0.0247234    0.0227967  -0.0548681     0.0391373    -0.0489348    -0.0213001    -0.0723458   0.0476046   -0.0222184   -0.0201015   -0.0380096    0.048333     0.0810826    -0.070277
 -0.0344837    0.143588     0.0292683   -0.0169506    0.0485312     0.107576     0.094312      0.110239    -0.137382     0.0575176   -0.0121225   -0.0429371    0.00943306   0.0220445  -0.091786      0.033668     -0.0480761     0.126902     -0.0679882  -0.0843522    0.0478853    0.00992011  -0.06922      0.128883     0.0175409    -0.157901
  0.190813     0.0679177   -0.23929      0.10642     -0.124691     -0.118465    -0.0792024    -0.0444233   -0.112588     0.113409     0.0742041    0.0977322   -0.0485164    0.0419097   0.158849      0.0289548     0.191861     -0.137421     -0.0681561  -0.141182    -0.129277     0.167987     0.0230266   -0.0773871    0.0854696    -0.250903
 -0.0175946   -0.207131    -0.0239813   -0.0243196   -0.0588192     0.145059    -0.0342094    -0.136905     0.0257869   -0.134718     0.0734426    0.180161    -0.0610046    0.0684964  -0.11715      -0.0858296    -0.0818305    -0.138043     -0.09269    -0.105898    -0.0420198   -0.0497023    0.0727229   -0.082192    -0.0408996     0.179259
 -0.0411679    0.0792759    0.0679632    0.0454892    0.00177467    0.0122252   -0.00276705    0.0533503   -0.071337     0.0958592    0.0456667   -0.249939     0.0351722    0.0136485   0.101614     -0.02121      -0.0500837    -0.0511196    -0.135012    0.0107929   -0.00485195   0.00307877  -0.0435961    0.00746938   0.0273807    -0.0937182
  0.0288247    0.0584703    0.0147946    0.0217594   -0.0992308    -0.0684175   -0.00951665   -0.0781482    0.0963953   -0.0169203    0.0452356    0.0404559   -0.0262872    0.163336   -0.0708218     0.054797     -0.0175179    -0.0198552     0.0298417  -0.0422307   -0.0277838   -0.0116177    0.0306661    0.124133     0.00587394   -0.00509974
 -0.090909    -0.059212    -0.0506034    0.0634018    0.0180896     0.0355099   -0.0141214    -0.077044    -0.175909    -0.0235515   -0.157122     0.0341689   -0.0116973    0.0786733   0.102957     -0.0660845    -0.000906223   0.0276809    -0.0682953  -0.165629    -0.0450207   -0.0249251    0.101352     0.201659    -0.137497     -0.133787
 -0.00340867  -0.107009    -0.29027     -0.0398369    0.11558      -0.015797    -0.098434      0.0767001   -0.108835    -0.0871655    0.0302839   -0.00780856  -0.00266505  -0.0099371   0.0180996     0.0240738    -0.0908446     0.137478      0.0394221  -0.0995932    0.0841196   -0.0526668    0.0150733   -0.0173681    0.0262658    -0.162849
  0.127082     0.00251377  -0.0941502    0.211581     0.144941      0.0405857    0.0459226     0.0505959    0.0440979   -0.180652     0.0863168   -0.0640878    0.0528689    0.0190401  -0.00947549   -0.0415792     0.147987      0.0159426     0.0666856   0.0346414    0.140487     0.248002     0.0275052   -0.0651346    0.127923     -0.173033
 -0.138462    -0.0539125    0.110893     0.0786309    0.150031     -0.0576015    0.13239       0.108124    -0.0520894   -0.0222391    0.173837     0.129463     0.0921143    0.192982    0.234042     -0.00908327    0.0484789     0.00916822    0.0680653   0.0825284    0.13004     -0.143125     0.193147     0.154017    -0.106804     -0.0623984[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.031230
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.016580
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.028574
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.018095
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.029537
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.015377
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.031195
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.016255
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.028522
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.017968
┌ Info: EM with 100000 data points 10 iterations avll -1.017968
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.405396e+05
      1       6.606408e+05      -1.798988e+05 |       32
      2       6.328362e+05      -2.780461e+04 |       32
      3       6.168212e+05      -1.601503e+04 |       32
      4       6.069196e+05      -9.901588e+03 |       32
      5       5.987745e+05      -8.145035e+03 |       32
      6       5.914997e+05      -7.274811e+03 |       32
      7       5.869704e+05      -4.529331e+03 |       32
      8       5.835599e+05      -3.410508e+03 |       32
      9       5.811015e+05      -2.458388e+03 |       32
     10       5.800182e+05      -1.083338e+03 |       32
     11       5.794261e+05      -5.920194e+02 |       32
     12       5.790539e+05      -3.722289e+02 |       32
     13       5.787785e+05      -2.753651e+02 |       32
     14       5.785665e+05      -2.120440e+02 |       32
     15       5.783800e+05      -1.864819e+02 |       32
     16       5.781900e+05      -1.899825e+02 |       32
     17       5.780202e+05      -1.697988e+02 |       31
     18       5.778991e+05      -1.211269e+02 |       31
     19       5.777647e+05      -1.344076e+02 |       31
     20       5.776208e+05      -1.438736e+02 |       31
     21       5.774697e+05      -1.510809e+02 |       32
     22       5.772644e+05      -2.053553e+02 |       32
     23       5.769939e+05      -2.704504e+02 |       32
     24       5.767134e+05      -2.805391e+02 |       32
     25       5.765460e+05      -1.674427e+02 |       31
     26       5.764762e+05      -6.974100e+01 |       30
     27       5.764472e+05      -2.900976e+01 |       30
     28       5.764285e+05      -1.871696e+01 |       31
     29       5.764145e+05      -1.403294e+01 |       26
     30       5.764012e+05      -1.322718e+01 |       30
     31       5.763800e+05      -2.127657e+01 |       32
     32       5.763507e+05      -2.922521e+01 |       31
     33       5.763143e+05      -3.643379e+01 |       26
     34       5.762708e+05      -4.349675e+01 |       31
     35       5.762133e+05      -5.745288e+01 |       31
     36       5.761597e+05      -5.363201e+01 |       29
     37       5.761309e+05      -2.881710e+01 |       31
     38       5.761134e+05      -1.751052e+01 |       25
     39       5.761022e+05      -1.122673e+01 |       24
     40       5.760951e+05      -7.058974e+00 |       19
     41       5.760925e+05      -2.592980e+00 |       24
     42       5.760902e+05      -2.320114e+00 |       18
     43       5.760886e+05      -1.606845e+00 |       15
     44       5.760873e+05      -1.246721e+00 |       15
     45       5.760867e+05      -6.634740e-01 |       15
     46       5.760862e+05      -4.203370e-01 |        7
     47       5.760860e+05      -2.229369e-01 |        5
     48       5.760858e+05      -1.927156e-01 |        6
     49       5.760857e+05      -1.625654e-01 |        6
     50       5.760855e+05      -1.435945e-01 |        6
K-means terminated without convergence after 50 iterations (objv = 576085.5254261857)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.292919
[ Info: iteration 2, average log likelihood -1.258348
[ Info: iteration 3, average log likelihood -1.226409
[ Info: iteration 4, average log likelihood -1.192397
[ Info: iteration 5, average log likelihood -1.147645
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.087077
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      6
│      9
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.035354
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     10
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.047209
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│     12
│     23
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.058295
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.085180
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      6
│      9
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.045232
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.072008
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     11
│     21
│     22
│     24
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.027394
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.068667
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      6
│      9
│     10
│     18
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.017886
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.102856
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     17
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.041610
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      6
│     20
│      ⋮
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -0.998849
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     18
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.041265
[ Info: iteration 20, average log likelihood -1.111435
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.043120
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│     12
│     20
│     22
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -0.996040
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      6
│      9
│     10
│     11
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.032180
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.073775
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.035519
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      6
│      9
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.995531
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.096062
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.048382
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      9
│     10
│     17
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.010504
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      6
│     11
│      ⋮
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.021650
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.075417
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.054041
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.042680
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      6
│     12
│     20
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -0.999717
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.057238
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      9
│     17
│     18
│     24
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.017208
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.064145
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      6
│     11
│     12
│     22
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.021901
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.082343
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      9
│     10
│     17
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.015588
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.052786
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      6
│     12
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.020091
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      9
│     20
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.024885
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     17
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.041255
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.061552
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      6
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.024042
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      9
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.024156
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     20
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.031803
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.032416
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      6
│      9
│      ⋮
│     22
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -0.991835
┌ Info: EM with 100000 data points 50 iterations avll -0.991835
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0927631    -0.0768132     0.13446     -0.0135795   -0.0176785   -0.00436144  -0.140801    -0.022055     0.0213796    0.115174    0.0859553    0.132431     0.0861562   -0.0168691    0.0491276    0.00439162    0.0105363   -0.0592747    -0.00274584  -0.072816   -0.0692931   0.0901027    0.051745    -0.0936141    -0.0400629    -0.0494133
  0.0423084    -0.160272      0.0548142    0.227036     0.040575     0.178585     0.0558604   -0.0638291   -0.0899573   -0.0932616  -0.0862364    0.193574    -0.0759252    0.0456737    0.00106938   0.149613      0.0965528   -0.0770315    -0.00826931  -0.158161   -0.0423024   0.215781     0.133642    -0.122844     -0.257537     -0.221803
 -0.0172682     0.0189282     0.117834     0.105374     0.180504    -0.0957347   -0.240013    -0.0207288   -0.0312094    0.109202   -0.013289     0.104814     0.0235012   -0.306519    -0.0433619    0.000535476  -0.133296    -0.15244      -0.0981076   -0.0313348   0.113122    0.0813353   -0.0636934   -0.184521      0.105846      0.0501077
  0.0472841     0.0117674     0.0643367   -0.0255424   -0.16991     -0.176593    -0.0423103   -0.0775431    0.137948     0.108679    0.152862     0.0683722    0.0733615    0.125535    -0.0147078    0.0786517    -0.182797    -0.115428      0.0485853   -0.0575873  -0.0177023   0.0218343    0.051952     0.312635      0.0575229    -0.22974
 -0.0154113     0.0231954    -0.032097     0.030329     0.118491    -0.0450746    0.0940151   -0.0139208   -0.0343827   -0.0276      0.0797269    0.0185379    0.0271422    0.100704     0.0911471    0.0114571    -0.00214599  -0.00797338   -0.00247273   0.060316    0.0495663  -0.0781154    0.0711273    0.101566     -0.0155572    -0.0684411
  0.00490389    0.116044      0.0036807   -0.0170194    0.0424899    0.07986      0.0940481    0.160944     0.0487489    0.0273315  -0.147133     0.0525706   -0.044062     0.0126157   -0.11964      0.130142     -0.00747291   0.184705      0.00496273  -0.0475076   0.0280722  -0.212892     0.0112089    0.0882398     0.0928882     0.111744
 -0.00394674   -0.10687      -0.287048    -0.0403665    0.113344    -0.0159265   -0.0985091    0.0774715   -0.110038    -0.0889979   0.030365    -0.00737359  -0.00160227  -0.00998491   0.018462     0.0240647    -0.0903601    0.13796       0.0369686   -0.100063    0.085075   -0.0539245    0.0151442   -0.016642      0.0260664    -0.16337
 -0.0773961     0.182942      0.0547441    0.139968    -0.0255273    0.00890908  -0.0254172   -0.127661    -0.0893117    0.0584589   0.0859639   -0.27099      0.0390143    0.0579431    0.0298633   -0.00256877    0.0114987   -0.101504     -0.144801    -0.022579    0.0271632   0.040245    -0.0233018   -0.000278282  -0.0101454    -0.16253
 -0.0137755    -0.110579     -0.0134054    0.089941     0.0530477    0.00108009   0.110718    -0.00411583  -0.041781     0.0516083   0.109432    -0.11295      0.236726     0.0442695    0.00310425  -0.00306595   -0.0769876    0.0973333     0.00979028   0.0199661  -0.0907492  -0.116378     0.139838     0.143851     -0.120994      0.0049412
  0.036903      0.000699087  -0.0892571   -0.0514625   -0.142548    -0.00564453  -0.0276799    0.0439355   -0.036034    -0.0854794  -0.0884742   -0.14439     -0.144804     0.0969818    0.0886241   -0.0296018     0.139229    -0.103332     -0.148815    -0.0507219   0.0960465   0.00166847   0.113328     0.0659939    -0.134491      0.147951
 -0.0114779    -0.00215473    0.134326     0.0165355   -0.048885    -0.074675    -0.114772     0.0825708    0.248514     0.185575    0.144076     0.108481     0.0466693    0.157982    -0.126786     0.0673408     0.101895     0.0190696     0.0480747    0.155386   -0.189969    0.0634247   -0.14867      0.0801045     0.0198606    -0.0455479
 -0.0684009     0.0830317    -0.00530444   0.0150302    0.0998458    0.0221017   -0.0356497    0.0402779   -0.214668    -0.0147165   0.0371074    0.207358    -0.174428     0.203487     0.0695349    0.00709491    0.109602     0.0660316     0.0842235    0.0764618   0.0738939  -0.0619642   -0.00696788  -0.0855181     0.185747     -0.0961171
  0.0366477    -0.021248     -0.109435     0.0220543    0.00302599   0.0529203   -0.089587     0.185571     0.0285146   -0.136143   -0.0886794   -0.0117424    0.0342556   -0.07892      0.147819    -0.0250611     0.166043    -0.149249      0.0431328    0.140348   -0.105031    0.0823276   -0.243639    -0.079621      0.00900099    0.134672
  0.0373444     0.108591     -0.0429248    0.0523458    0.00224565  -0.0105252    0.00550791  -0.0658091    0.0684733   -0.111928   -0.0299644    0.00103957  -0.108046     0.19708     -0.140708     0.0715444     0.12806      0.0367546     0.0489205   -0.026699   -0.0284077  -0.00592514   0.00340015  -0.0346382    -0.0621685     0.186564
 -0.0679934    -0.0469377     0.125402     0.0243335    0.235368     0.113829    -0.0175792   -0.112037     0.0300739    0.0138106   0.0732105   -0.0573034    0.00372147  -0.00203723  -0.0279963   -0.0946024     0.0481699    0.0407414     0.119041    -0.0322572   0.0492148  -0.0345192   -0.0498894   -0.0632116     0.111914      0.110405
  0.107238      0.176148      0.0281156   -0.0232935   -0.0260923    0.0471479   -0.0819189    0.0857858    0.108984    -0.0732725  -0.180657    -0.0727924    0.112527     0.189817     0.137605     0.0748301    -0.203049    -0.0430665     0.0636539    0.121251   -0.0650941   0.0754232    0.0341935   -0.0431683     0.135853     -0.0612195
  0.0787423     0.00231725    0.0966798   -0.0543972   -0.0382285    0.205017    -0.0356429    0.017656    -0.00974109   0.0539952   0.0348116    0.126432     0.117291    -0.0449705   -0.155526     0.0399296     0.0155343    0.240789      0.111646    -0.0230465  -0.0487577   0.0988657   -0.0256255   -0.0510744    -0.180837     -0.00926393
  0.178142     -0.044118     -0.00493805   0.0444307   -0.0111364    0.17126      0.00121546  -0.123873     0.0111914    0.034209    0.0298991   -0.09788     -0.0291407    0.0729951    0.0135876   -0.00207051   -0.0604289    0.0432452    -0.130175    -0.0327474  -0.112532    0.0743239    0.180764    -0.190566     -0.000858238   0.121453
 -0.0366232    -0.0999443     0.0565738    0.0660533   -0.144682     0.134037    -0.00178929   0.0390255    0.0793858   -0.0518028   0.0756781   -0.03377     -0.0532064    0.0320101    0.0853748   -0.123186      0.0938517   -0.0615328    -0.169386    -0.0166147   0.020253   -0.0966681   -0.10941      0.0812394     0.0224187    -0.01784
  0.0612826     0.0681103    -0.0885454   -0.00960056  -0.0131361    0.00484026   0.00293261   0.0184587   -0.191447    -0.0249185  -0.0679479   -0.0539612    0.00809823  -0.116597    -0.157449    -0.00163174   -0.158        0.0949675    -0.0386848   -0.103696    0.200594   -0.103674     0.110902     0.0436616    -0.152069      0.0492064
  0.186945      0.0609311    -0.235667     0.103164    -0.123724    -0.115137    -0.0800217   -0.0470945   -0.112715     0.111436    0.0747891    0.100855    -0.0485055    0.0402702    0.153812     0.0281324     0.186977    -0.137238     -0.069191    -0.14666    -0.12835     0.16739      0.025335    -0.0813393     0.0824746    -0.240124
 -0.155289     -0.128737     -0.0337284   -0.140892     0.0527256    0.167412    -0.0228065   -0.185329    -0.197629    -0.0161321   0.0268114   -0.146061     0.0112897   -0.127753     0.0267769    0.20793      -0.0387834   -0.12151      -0.0170681    0.200614   -0.108899    0.0130491   -0.0253847   -0.201636     -0.177787      0.0354539
 -0.0132033    -0.0282571     0.0746959   -0.049107     0.0218033    0.00854227   0.016583     0.237447    -0.0430914    0.125978    0.00463552  -0.210524     0.0321921   -0.0239729    0.168054    -0.0486073    -0.114819    -0.000832279  -0.116417     0.0512662  -0.0332023  -0.0360164   -0.0627079    0.00590817    0.0618442    -0.0200516
 -0.131388      0.113888      0.00634593  -0.0560938   -0.0350131   -0.199947    -0.0570929    0.0224652   -0.012444    -0.0506358   0.0255364    0.129912     0.0761249    0.0560735   -0.0464844    0.0545113    -0.113327     0.0131256     0.128931     0.0247543   0.146532   -0.0273463    0.12135     -0.088738      0.0243642     0.04412
 -0.0185334    -0.200793     -0.0133818   -0.0316768   -0.0826337    0.130699    -0.0378429   -0.13117      0.0601953   -0.122442    0.0778396    0.177561    -0.0490477    0.0881217   -0.102388    -0.0860559    -0.0896659   -0.151446     -0.0822718   -0.102446   -0.0426373  -0.0606981    0.0670449   -0.0428876    -0.0240933     0.188526
 -0.0444273     0.158846      0.0302715   -0.0262682    0.0362116    0.129702     0.120942     0.098375    -0.157033     0.0742192  -0.0026784   -0.0455297    0.00574533   0.0165235   -0.0984794    0.0273801    -0.0491634    0.128042     -0.0767942   -0.0946663   0.0405677   0.0133267   -0.128313     0.171762      0.0383778    -0.262684
  0.000311621  -0.121582      0.0396272    0.0755613    0.00835194  -0.0177113   -0.21789      0.0959041   -0.0338955    0.112359    0.171027     0.00513104  -0.00582948  -0.111513    -0.0707246    0.0150221     0.0255457    0.040709      0.028601    -0.188193   -0.053365    0.192203     0.133966    -0.164083      0.104115      0.0840607
  0.0745947    -0.0989434    -0.13717     -0.167203     0.00921834   0.0463676    0.0171042    0.0768639   -0.00440172  -0.128563   -0.0515362    0.034395     0.0775483   -0.0555118   -0.0169085   -0.13639      -0.0350201   -0.0938662     0.0594984   -0.0460532   0.137897    0.0413617    0.20088      0.0117923    -0.0413743     0.0795946
 -0.223068      0.090483      0.0057146    0.176955     0.130053     0.0232374   -0.106639     0.104331    -0.0239149    0.0605461  -0.174334     0.00513019  -0.131612     0.00801898   0.00821417  -0.110342     -0.0489585    0.0997582     0.0390186   -0.121327    0.0316643   0.0668547   -0.00160952   0.0269716     0.0337902    -0.0932369
  0.124733      0.00221814   -0.0930832    0.211501     0.145399     0.0402526    0.0466843    0.050144     0.0438416   -0.180581    0.0877369   -0.0630474    0.0526756    0.0189635   -0.00888364  -0.0420274     0.152803     0.0164353     0.0647965    0.034847    0.142344    0.248038     0.0306945   -0.065031      0.127256     -0.173482
 -0.0786944    -0.0581092    -0.0462906    0.0621247    0.00221127   0.0268216   -0.0155115   -0.0763984   -0.151332    -0.0248905  -0.143083     0.0380109    0.00185239   0.0832412    0.0919485   -0.0632904    -0.00278788   0.0300766    -0.0661179   -0.15325    -0.0456853  -0.0250058    0.0987257    0.204167     -0.123305     -0.152639
 -0.127987      0.0806948    -0.0721258    0.044186     0.0675865   -0.083218    -0.0526911   -0.0136749    0.064519    -0.133234    0.0518546   -0.0673943   -0.121517    -0.0346762   -0.0554363    0.053168     -0.278378    -0.0659325     0.0536882    0.108721    0.0706824  -0.0615529    0.0676819   -0.0597962    -0.0795853     0.122123[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.101629
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     24
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.017302
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│     10
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.963658
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      9
│     12
│     24
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.023956
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     17
│     20
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.018139
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      9
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.953989
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│     12
│     20
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.062869
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     24
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.032018
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│     10
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.970159
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     12
│     24
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.030132
┌ Info: EM with 100000 data points 10 iterations avll -1.030132
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.000765086  -0.0371724    0.0368198  -0.0186725    0.0636066     0.0657132    0.0297496     0.0590663  -0.0209482    0.0142205    0.258229      0.025719    -0.0679284    0.00684734   0.130601     0.033095    -0.0625833   0.0910965   -0.0523441   0.153611    -0.0700844    0.090621    -0.0186816    0.224138    -0.093238     0.0713755
  0.111155     -0.040733    -0.109099    0.0528063   -0.173193      0.0161971    0.0296095    -0.0352384   0.0356036    0.0107597   -0.13652      -0.0458992   -0.0187509    0.0485148   -0.00713197   0.080945     0.235281   -0.393073     0.138078   -0.0829962   -0.148995     0.17714      0.0959322   -0.097789    -0.0523721   -0.165076
  0.0218721     0.109162    -0.0433033   0.0693576    0.00931746   -0.0423492    0.0444256     0.0913387  -0.179802    -0.172716     0.0162429    -0.0453787    0.00471118   0.141885     0.105392    -0.065712     0.194135   -0.0723583   -0.17614     0.00743399   0.155297    -0.224459     0.0532759   -0.144325     0.0540187   -0.00310757
  0.0994821    -0.0504655   -0.0338496   0.0444032   -0.0298532    -0.0381628   -0.0285254    -0.0195703   0.116007    -0.0964771    0.115392      0.183925     0.00340681  -0.0857448    0.11725     -0.0575646   -0.0453678  -0.0455985   -0.0359795  -0.189869    -0.102771     0.212378    -0.176936    -0.115564     0.0218167   -0.112971
 -0.227135     -0.0632159   -0.0442405   0.076568    -0.160254      0.23018     -0.0692804     0.123835    0.0637929    0.168812     0.0500068     0.203717    -0.0137223    0.0613953   -0.0103955    0.00109455   0.0437433  -0.102622    -0.0241715   0.0523022   -0.00736035   0.00756144   0.0600911    0.211476     0.0889922    0.0404355
 -0.07227      -0.0953306    0.0734312   0.0178352    0.0524349     0.031606    -0.0268903     0.0386492  -0.061015     0.1431      -0.0543536    -0.0302326    0.052517    -0.0134789    0.0355134    0.0967525   -0.0175704  -0.126855    -0.150733   -0.0691035   -0.125709    -0.0881211   -0.0698829   -0.0948605    0.123667     0.054071
 -0.0524559    -0.0171316    0.0394156   0.00566584  -0.074197     -0.189498     0.0245418    -0.0843275   0.0483411   -0.0413881   -0.113694     -0.133897     0.0233122    0.100205     0.0811571   -0.0330709    0.0442481  -0.00499482  -0.0603117  -0.137344    -0.129385    -0.151508     0.0586014    0.0363505    0.0155476    0.0808974
 -0.0411825     0.0688576    0.0846759  -0.140805    -0.140908     -0.0773495   -0.0099797     0.185426   -0.117599    -0.0740719    0.0139951     0.12488     -0.0521744    0.0105644    0.0651833    0.100845    -0.119015    0.067753     0.0630769  -0.00770946  -0.0635055   -0.0731798    0.08246     -0.196068    -0.0262583    0.194802
  0.175247      0.114571    -0.0731978   0.16963      0.0898942     0.0159919    0.105468      0.0108469   0.0870909   -0.147328    -0.174554     -0.0657111    0.135274    -0.0746894    0.0266968    0.135533     0.0253501   0.257613    -0.10074     0.052107     0.103258    -0.140558     0.0354239   -0.0641278    0.0122705    0.0585468
 -0.0488748     0.101098    -0.145715   -0.0992742   -0.20123      -0.0276016    0.200747     -0.128406    0.015385     0.00158801  -0.0713765     0.0173349    0.0827963   -0.0162528    0.161875    -0.188571    -0.148182   -0.0309535    0.0964329  -0.0593894    0.0152077   -0.0520485   -0.0468788   -0.0253656   -0.196337     0.00763481
 -0.125465     -0.131809    -0.0237988  -0.0469187   -0.127608      0.175372    -0.00739238   -0.0248277  -0.080909    -0.0139985   -0.0703865    -0.0400056    0.0719114   -0.0916445   -0.2196      -0.0744877    0.0467386  -0.179049    -0.0199366  -0.0751139    0.154406     0.168442     0.16368      0.0174733   -0.113581    -0.0211096
  0.00561123    0.171074     0.0806428   0.183436    -0.0618678     0.0359487   -0.0127164    -0.105981    0.0763353    0.0440229   -0.0145824    -0.147058     0.0662455   -0.194026    -0.0726668   -0.00876685   0.139091   -0.19283     -0.0653504  -0.0971282    0.0334637   -0.152194    -0.118462    -0.0772766    0.100899     0.115316
  0.0942555    -0.0147525   -0.0285716  -0.0310942    0.0912803     0.148208     0.0591743     0.168217    0.00561104   0.0557651    0.113965     -0.0758125    0.00396     -0.0117868    0.0221434    0.035138    -0.0548003  -0.130001     0.0145485  -0.125593    -0.0475942    0.151546    -0.0142055   -0.0370043    0.0848661   -0.0629655
 -0.116885     -0.0244531    0.053115    0.0557711   -0.224414     -0.0932065    0.0279901     0.0218593  -0.11907     -0.0787054    0.230191     -0.148681    -0.100912     0.00898083   0.0108288   -0.047665    -0.0741447  -0.0438451   -0.0636252  -0.00291724   0.104925    -0.0298839    0.145368    -0.162162     0.133695    -0.00464976
 -0.0222134    -0.0776568   -0.0754889  -0.11991      0.000606023   0.00945201   0.0823972     0.0330057   0.0636201   -0.118709     0.0684929    -0.0548262    0.044791    -0.0300187   -0.11146      0.158776    -0.0145778   0.108698    -0.118348   -0.125357    -0.0290383    0.145371    -0.00428393  -0.0222647    0.0884536    0.12047
  0.00897409   -0.0244593   -0.216029   -0.185947     0.179983      0.0241304    0.000793404  -0.162009   -0.104137    -0.0641237   -0.0208279     0.0546688    0.0260884    0.0285664   -0.0352453    0.062805     0.155968   -0.0463211    0.0843815  -0.0112585   -0.110815    -0.238369    -0.119039     0.134252     0.0603057    0.069924
 -0.0316622    -0.0807216   -0.0726607  -0.163257     0.0801285     0.0298782   -0.0738607    -0.0913427  -0.0693764    0.0615497    0.14398       0.178653     0.0226593    0.0872118   -0.134742     0.00501478  -0.163647    0.0200648   -0.0463663  -0.090266    -0.165537    -0.116029    -0.114972     0.115706     0.0495815    0.0326846
  0.063178     -0.00977361  -0.222775   -0.102777    -0.0257047     0.0736087   -0.0535121    -0.0358418  -0.203598     0.0412112    0.125775      0.0890385    0.0681307    0.0261469    0.0824865   -0.0209146   -0.128752   -0.043588     0.199663    0.0764218   -0.14134     -0.163692    -0.0623953    0.0155804    0.0993536   -0.0627667
  0.0047237     0.00880692  -0.0316456   0.1558       0.0321205     0.13319     -0.0734169    -0.135515    6.56368e-5   0.0724434   -0.114537      0.117563     0.233498    -0.133836     0.0992668    0.00797468  -0.0634386  -0.171618     0.170395    0.0827272    0.10581     -0.137884     0.02909      0.0638174   -0.0813957    0.159908
 -0.0626315     0.092283     0.12843     0.145393     0.0364934     0.0167919   -0.0531241    -0.16762    -0.145481    -0.0553079   -0.0555971     0.151876    -0.0178343    0.0718934   -0.0963158   -0.0254261   -0.0140351   0.0853767    0.108495   -0.015137    -0.0934322   -0.210186     0.160861     0.16274      0.0429607    0.0723562
  0.181887      0.0919946   -0.0249157  -0.0223878   -0.0533139     0.0277836    0.0254315     0.0407644  -0.0924683    0.0150512    0.0246252     0.0085233   -0.0513633   -0.0602536   -0.113527     0.155874    -0.0528268   0.0586714    0.113303    0.0215355   -0.0985983   -0.0664891   -0.24748     -0.0182629   -0.143309    -0.133872
  0.0708403    -0.127253     0.191039    0.111435    -0.00611136   -0.0467293    0.00559771    0.0910309   0.0874864   -0.0717415   -0.112264     -0.0368603   -0.0853934    0.00447301  -0.0888968    0.0546361    0.0685329   0.0466658   -0.172383   -0.0198007    0.0106969   -0.191488     0.190868    -0.121448    -0.0155671   -0.16849
 -0.0555469    -0.117059    -0.0540812   0.010503     0.0963389     0.0665609   -0.15855      -0.027808    0.0919048    0.00874657   0.0192738     0.00410663  -0.00569272  -0.0350259   -0.103762    -0.0418426    0.0609988   0.0824772    0.0655804   0.00798733   0.160152    -0.198382    -0.0150629   -0.163303     0.0980758   -0.0774233
 -0.0791963    -0.0432445    0.209208   -0.0405689   -0.0956123    -0.0806545   -0.039975     -0.0949533  -0.0438473    0.102881     0.0774573     0.131046    -0.00467253  -0.0052111   -0.143327    -0.0270718    0.0267541   0.149398     0.172612   -0.00735071   0.0123289   -0.134146     0.0816502   -0.00538906  -0.00822382  -0.109107
 -0.0615214    -0.070443     0.0554373  -0.0257394   -0.0116884     0.145897     0.103792      0.194871   -0.0525489   -0.0623779   -0.139567      0.0520978    0.102555    -0.0491985   -0.0200388    0.00316882   0.0717184   0.16284     -0.0210158   0.0729044   -0.106906     0.101596    -0.0208329    0.138894    -0.0637      -0.0279595
 -0.0665099    -0.0156202    0.0658886  -0.0938777   -0.0212753     0.00388663   0.0298117    -0.200446    0.151714    -0.163232     0.000589413   0.269028     0.0281623   -0.0223553    0.0915896   -0.0220074    0.0857923  -0.0557612   -0.15027    -0.0689733   -0.100398     0.00720779   0.0510047   -0.020604     0.0173018    0.194614
  0.0701594     0.03791     -0.124743   -0.127388     0.0153027     0.107448     0.0643097    -0.0560487   0.0244996    0.149305     0.0476865     0.00894124  -0.0244195    0.0095749    0.0942145   -0.0612279   -0.0610143  -0.0147341   -0.0377558   0.022035    -0.0196734    0.131891     0.0485904    0.00422743   0.148514    -0.00132541
  0.00253313    0.0419369    0.106756   -0.037042     0.0430907     0.177293    -0.00877541   -0.0807254   0.0641965    0.0601155   -0.0748609    -0.117182     0.00924584   0.0728185   -0.0566574    0.0824066    0.139711   -0.098274    -0.0741596  -0.0516878   -0.0438274   -0.0242705    0.0300946   -0.00583317   0.205121     0.0123219
 -0.0282917     0.140919     0.0592545  -0.120736     0.203866      0.0906008   -0.018928      0.0905544   0.166979    -0.044355     0.00724945   -0.0612373   -0.160418    -0.120041    -0.0772127    0.0744355   -0.130346   -0.124102    -0.186854   -0.0504755    0.0297494   -0.057535    -0.0544735    0.067976    -0.107832    -0.0271977
 -0.0382359     0.0214234   -0.0231341   0.0895938   -0.116661     -0.0628864    0.240963      0.0510749  -0.0500184   -0.11384     -0.102588      0.0564085   -0.196312    -0.0980219   -0.0652582   -0.0364827   -0.054299   -0.108304    -0.0851     -0.0533658    0.0692528    0.0546107    0.0444608    0.0890915   -0.022047     0.0133015
  0.0110305     0.165133    -0.0549687  -0.0353535    0.14398      -0.0234512    0.0777208     0.0495052  -0.123544     0.0710186   -0.0418388     0.0619359   -0.190299     0.0882826   -0.00776603  -0.0909606    0.094778   -0.0541969    0.0941155  -0.0929324   -0.0752105   -0.14203      0.0194516    0.0196628   -0.0179246   -0.0890481
 -0.161946      0.0852991    0.0304702   0.137987     0.10084      -0.0982693    0.0705604     0.0447408  -0.0492397    0.0595102   -0.0166632    -0.213775    -0.128052    -0.084367    -0.0798703   -0.0311849   -0.1408     -0.0509622   -0.25779     0.0957871   -0.0193021   -0.0261485   -0.0111012   -0.034605     0.0900989    0.0522782kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4206115713651692
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420630
[ Info: iteration 2, average log likelihood -1.420572
[ Info: iteration 3, average log likelihood -1.420524
[ Info: iteration 4, average log likelihood -1.420462
[ Info: iteration 5, average log likelihood -1.420381
[ Info: iteration 6, average log likelihood -1.420277
[ Info: iteration 7, average log likelihood -1.420140
[ Info: iteration 8, average log likelihood -1.419943
[ Info: iteration 9, average log likelihood -1.419616
[ Info: iteration 10, average log likelihood -1.419047
[ Info: iteration 11, average log likelihood -1.418160
[ Info: iteration 12, average log likelihood -1.417104
[ Info: iteration 13, average log likelihood -1.416234
[ Info: iteration 14, average log likelihood -1.415731
[ Info: iteration 15, average log likelihood -1.415498
[ Info: iteration 16, average log likelihood -1.415399
[ Info: iteration 17, average log likelihood -1.415358
[ Info: iteration 18, average log likelihood -1.415340
[ Info: iteration 19, average log likelihood -1.415333
[ Info: iteration 20, average log likelihood -1.415329
[ Info: iteration 21, average log likelihood -1.415328
[ Info: iteration 22, average log likelihood -1.415327
[ Info: iteration 23, average log likelihood -1.415326
[ Info: iteration 24, average log likelihood -1.415326
[ Info: iteration 25, average log likelihood -1.415326
[ Info: iteration 26, average log likelihood -1.415326
[ Info: iteration 27, average log likelihood -1.415325
[ Info: iteration 28, average log likelihood -1.415325
[ Info: iteration 29, average log likelihood -1.415325
[ Info: iteration 30, average log likelihood -1.415325
[ Info: iteration 31, average log likelihood -1.415325
[ Info: iteration 32, average log likelihood -1.415325
[ Info: iteration 33, average log likelihood -1.415325
[ Info: iteration 34, average log likelihood -1.415325
[ Info: iteration 35, average log likelihood -1.415325
[ Info: iteration 36, average log likelihood -1.415324
[ Info: iteration 37, average log likelihood -1.415324
[ Info: iteration 38, average log likelihood -1.415324
[ Info: iteration 39, average log likelihood -1.415324
[ Info: iteration 40, average log likelihood -1.415324
[ Info: iteration 41, average log likelihood -1.415324
[ Info: iteration 42, average log likelihood -1.415324
[ Info: iteration 43, average log likelihood -1.415324
[ Info: iteration 44, average log likelihood -1.415324
[ Info: iteration 45, average log likelihood -1.415324
[ Info: iteration 46, average log likelihood -1.415324
[ Info: iteration 47, average log likelihood -1.415324
[ Info: iteration 48, average log likelihood -1.415324
[ Info: iteration 49, average log likelihood -1.415324
[ Info: iteration 50, average log likelihood -1.415324
┌ Info: EM with 100000 data points 50 iterations avll -1.415324
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4206298185986932
│     -1.4205722445010465
│      ⋮
└     -1.4153239796614738
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415342
[ Info: iteration 2, average log likelihood -1.415282
[ Info: iteration 3, average log likelihood -1.415232
[ Info: iteration 4, average log likelihood -1.415169
[ Info: iteration 5, average log likelihood -1.415089
[ Info: iteration 6, average log likelihood -1.414995
[ Info: iteration 7, average log likelihood -1.414896
[ Info: iteration 8, average log likelihood -1.414802
[ Info: iteration 9, average log likelihood -1.414724
[ Info: iteration 10, average log likelihood -1.414663
[ Info: iteration 11, average log likelihood -1.414616
[ Info: iteration 12, average log likelihood -1.414579
[ Info: iteration 13, average log likelihood -1.414547
[ Info: iteration 14, average log likelihood -1.414519
[ Info: iteration 15, average log likelihood -1.414491
[ Info: iteration 16, average log likelihood -1.414464
[ Info: iteration 17, average log likelihood -1.414437
[ Info: iteration 18, average log likelihood -1.414410
[ Info: iteration 19, average log likelihood -1.414383
[ Info: iteration 20, average log likelihood -1.414357
[ Info: iteration 21, average log likelihood -1.414332
[ Info: iteration 22, average log likelihood -1.414310
[ Info: iteration 23, average log likelihood -1.414290
[ Info: iteration 24, average log likelihood -1.414273
[ Info: iteration 25, average log likelihood -1.414258
[ Info: iteration 26, average log likelihood -1.414246
[ Info: iteration 27, average log likelihood -1.414236
[ Info: iteration 28, average log likelihood -1.414227
[ Info: iteration 29, average log likelihood -1.414220
[ Info: iteration 30, average log likelihood -1.414213
[ Info: iteration 31, average log likelihood -1.414208
[ Info: iteration 32, average log likelihood -1.414203
[ Info: iteration 33, average log likelihood -1.414199
[ Info: iteration 34, average log likelihood -1.414195
[ Info: iteration 35, average log likelihood -1.414191
[ Info: iteration 36, average log likelihood -1.414187
[ Info: iteration 37, average log likelihood -1.414184
[ Info: iteration 38, average log likelihood -1.414181
[ Info: iteration 39, average log likelihood -1.414178
[ Info: iteration 40, average log likelihood -1.414175
[ Info: iteration 41, average log likelihood -1.414173
[ Info: iteration 42, average log likelihood -1.414170
[ Info: iteration 43, average log likelihood -1.414167
[ Info: iteration 44, average log likelihood -1.414165
[ Info: iteration 45, average log likelihood -1.414163
[ Info: iteration 46, average log likelihood -1.414160
[ Info: iteration 47, average log likelihood -1.414158
[ Info: iteration 48, average log likelihood -1.414156
[ Info: iteration 49, average log likelihood -1.414154
[ Info: iteration 50, average log likelihood -1.414152
┌ Info: EM with 100000 data points 50 iterations avll -1.414152
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4153419994728158
│     -1.415282302580254
│      ⋮
└     -1.4141516142633364
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414159
[ Info: iteration 2, average log likelihood -1.414109
[ Info: iteration 3, average log likelihood -1.414063
[ Info: iteration 4, average log likelihood -1.414008
[ Info: iteration 5, average log likelihood -1.413939
[ Info: iteration 6, average log likelihood -1.413852
[ Info: iteration 7, average log likelihood -1.413746
[ Info: iteration 8, average log likelihood -1.413624
[ Info: iteration 9, average log likelihood -1.413498
[ Info: iteration 10, average log likelihood -1.413376
[ Info: iteration 11, average log likelihood -1.413268
[ Info: iteration 12, average log likelihood -1.413179
[ Info: iteration 13, average log likelihood -1.413108
[ Info: iteration 14, average log likelihood -1.413054
[ Info: iteration 15, average log likelihood -1.413013
[ Info: iteration 16, average log likelihood -1.412982
[ Info: iteration 17, average log likelihood -1.412958
[ Info: iteration 18, average log likelihood -1.412938
[ Info: iteration 19, average log likelihood -1.412923
[ Info: iteration 20, average log likelihood -1.412909
[ Info: iteration 21, average log likelihood -1.412898
[ Info: iteration 22, average log likelihood -1.412888
[ Info: iteration 23, average log likelihood -1.412879
[ Info: iteration 24, average log likelihood -1.412871
[ Info: iteration 25, average log likelihood -1.412864
[ Info: iteration 26, average log likelihood -1.412857
[ Info: iteration 27, average log likelihood -1.412850
[ Info: iteration 28, average log likelihood -1.412845
[ Info: iteration 29, average log likelihood -1.412839
[ Info: iteration 30, average log likelihood -1.412834
[ Info: iteration 31, average log likelihood -1.412829
[ Info: iteration 32, average log likelihood -1.412824
[ Info: iteration 33, average log likelihood -1.412819
[ Info: iteration 34, average log likelihood -1.412815
[ Info: iteration 35, average log likelihood -1.412811
[ Info: iteration 36, average log likelihood -1.412807
[ Info: iteration 37, average log likelihood -1.412803
[ Info: iteration 38, average log likelihood -1.412799
[ Info: iteration 39, average log likelihood -1.412795
[ Info: iteration 40, average log likelihood -1.412791
[ Info: iteration 41, average log likelihood -1.412787
[ Info: iteration 42, average log likelihood -1.412784
[ Info: iteration 43, average log likelihood -1.412780
[ Info: iteration 44, average log likelihood -1.412776
[ Info: iteration 45, average log likelihood -1.412772
[ Info: iteration 46, average log likelihood -1.412769
[ Info: iteration 47, average log likelihood -1.412765
[ Info: iteration 48, average log likelihood -1.412761
[ Info: iteration 49, average log likelihood -1.412757
[ Info: iteration 50, average log likelihood -1.412752
┌ Info: EM with 100000 data points 50 iterations avll -1.412752
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414159488189788
│     -1.4141086072883544
│      ⋮
└     -1.4127524414960633
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412757
[ Info: iteration 2, average log likelihood -1.412702
[ Info: iteration 3, average log likelihood -1.412652
[ Info: iteration 4, average log likelihood -1.412596
[ Info: iteration 5, average log likelihood -1.412530
[ Info: iteration 6, average log likelihood -1.412451
[ Info: iteration 7, average log likelihood -1.412358
[ Info: iteration 8, average log likelihood -1.412254
[ Info: iteration 9, average log likelihood -1.412143
[ Info: iteration 10, average log likelihood -1.412032
[ Info: iteration 11, average log likelihood -1.411924
[ Info: iteration 12, average log likelihood -1.411823
[ Info: iteration 13, average log likelihood -1.411732
[ Info: iteration 14, average log likelihood -1.411650
[ Info: iteration 15, average log likelihood -1.411577
[ Info: iteration 16, average log likelihood -1.411513
[ Info: iteration 17, average log likelihood -1.411457
[ Info: iteration 18, average log likelihood -1.411408
[ Info: iteration 19, average log likelihood -1.411365
[ Info: iteration 20, average log likelihood -1.411327
[ Info: iteration 21, average log likelihood -1.411292
[ Info: iteration 22, average log likelihood -1.411261
[ Info: iteration 23, average log likelihood -1.411231
[ Info: iteration 24, average log likelihood -1.411204
[ Info: iteration 25, average log likelihood -1.411178
[ Info: iteration 26, average log likelihood -1.411154
[ Info: iteration 27, average log likelihood -1.411130
[ Info: iteration 28, average log likelihood -1.411108
[ Info: iteration 29, average log likelihood -1.411086
[ Info: iteration 30, average log likelihood -1.411066
[ Info: iteration 31, average log likelihood -1.411046
[ Info: iteration 32, average log likelihood -1.411027
[ Info: iteration 33, average log likelihood -1.411008
[ Info: iteration 34, average log likelihood -1.410991
[ Info: iteration 35, average log likelihood -1.410974
[ Info: iteration 36, average log likelihood -1.410957
[ Info: iteration 37, average log likelihood -1.410942
[ Info: iteration 38, average log likelihood -1.410927
[ Info: iteration 39, average log likelihood -1.410913
[ Info: iteration 40, average log likelihood -1.410899
[ Info: iteration 41, average log likelihood -1.410886
[ Info: iteration 42, average log likelihood -1.410874
[ Info: iteration 43, average log likelihood -1.410862
[ Info: iteration 44, average log likelihood -1.410850
[ Info: iteration 45, average log likelihood -1.410840
[ Info: iteration 46, average log likelihood -1.410829
[ Info: iteration 47, average log likelihood -1.410819
[ Info: iteration 48, average log likelihood -1.410810
[ Info: iteration 49, average log likelihood -1.410801
[ Info: iteration 50, average log likelihood -1.410792
┌ Info: EM with 100000 data points 50 iterations avll -1.410792
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412756646965437
│     -1.4127015291623943
│      ⋮
└     -1.4107920996524894
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410792
[ Info: iteration 2, average log likelihood -1.410731
[ Info: iteration 3, average log likelihood -1.410673
[ Info: iteration 4, average log likelihood -1.410606
[ Info: iteration 5, average log likelihood -1.410525
[ Info: iteration 6, average log likelihood -1.410423
[ Info: iteration 7, average log likelihood -1.410301
[ Info: iteration 8, average log likelihood -1.410161
[ Info: iteration 9, average log likelihood -1.410009
[ Info: iteration 10, average log likelihood -1.409854
[ Info: iteration 11, average log likelihood -1.409702
[ Info: iteration 12, average log likelihood -1.409558
[ Info: iteration 13, average log likelihood -1.409425
[ Info: iteration 14, average log likelihood -1.409305
[ Info: iteration 15, average log likelihood -1.409196
[ Info: iteration 16, average log likelihood -1.409098
[ Info: iteration 17, average log likelihood -1.409010
[ Info: iteration 18, average log likelihood -1.408930
[ Info: iteration 19, average log likelihood -1.408859
[ Info: iteration 20, average log likelihood -1.408794
[ Info: iteration 21, average log likelihood -1.408735
[ Info: iteration 22, average log likelihood -1.408681
[ Info: iteration 23, average log likelihood -1.408631
[ Info: iteration 24, average log likelihood -1.408586
[ Info: iteration 25, average log likelihood -1.408543
[ Info: iteration 26, average log likelihood -1.408504
[ Info: iteration 27, average log likelihood -1.408467
[ Info: iteration 28, average log likelihood -1.408432
[ Info: iteration 29, average log likelihood -1.408400
[ Info: iteration 30, average log likelihood -1.408369
[ Info: iteration 31, average log likelihood -1.408340
[ Info: iteration 32, average log likelihood -1.408312
[ Info: iteration 33, average log likelihood -1.408286
[ Info: iteration 34, average log likelihood -1.408261
[ Info: iteration 35, average log likelihood -1.408237
[ Info: iteration 36, average log likelihood -1.408215
[ Info: iteration 37, average log likelihood -1.408193
[ Info: iteration 38, average log likelihood -1.408172
[ Info: iteration 39, average log likelihood -1.408152
[ Info: iteration 40, average log likelihood -1.408132
[ Info: iteration 41, average log likelihood -1.408114
[ Info: iteration 42, average log likelihood -1.408096
[ Info: iteration 43, average log likelihood -1.408079
[ Info: iteration 44, average log likelihood -1.408062
[ Info: iteration 45, average log likelihood -1.408046
[ Info: iteration 46, average log likelihood -1.408031
[ Info: iteration 47, average log likelihood -1.408017
[ Info: iteration 48, average log likelihood -1.408003
[ Info: iteration 49, average log likelihood -1.407989
[ Info: iteration 50, average log likelihood -1.407976
┌ Info: EM with 100000 data points 50 iterations avll -1.407976
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4107919723849058
│     -1.410730928865838
│      ⋮
└     -1.4079762060755086
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4206115713651692
│     -1.4206298185986932
│     -1.4205722445010465
│     -1.4205238579528712
│      ⋮
│     -1.4080026513557786
│     -1.407989171174803
└     -1.4079762060755086
32×26 Array{Float64,2}:
  0.305207    0.406464    0.232037     0.194681   -0.425688    -0.234434   -0.246414     -0.0306696    0.410569    0.170209    0.291142    -0.102558    -0.478429      0.235543    0.673207   -0.154131   -0.413354   -0.699725    -0.301918   -0.229185    0.0331079   0.229444      0.219262     0.589634   -0.135019   -0.206907
 -0.0279921   0.0604769  -0.10873     -0.0575708   0.522724    -0.305891   -0.38236       0.0724323    0.0505824  -0.810326    0.205781    -0.159649     0.657274      0.258938    0.47793    -0.22483    -0.293427   -0.676243    -0.394972   -0.0623703   0.068085    0.0737246    -0.0409392    0.337253   -0.0920585   0.266366
 -0.179218   -0.258936    0.0246418    0.0498543  -0.574269    -0.318497   -0.442285     -0.409641     0.0391471  -0.255921    0.639932    -0.255582     0.401405     -0.438848    0.130774    0.0632303   0.758236   -0.218696    -0.343963   -0.819984    0.218313    0.379876     -0.134213     0.53789     0.233075    0.0988353
  0.601776    0.28311     0.543252    -0.44481    -0.00688929  -0.129119   -0.513333     -0.963855     0.273102   -0.137945    0.222038     0.362439     0.173073      0.151632    0.0631041  -0.125402    0.55322    -0.207513     0.437659    0.0606238   0.365792    0.374712     -0.216577     0.578828    0.478575    0.00750737
  0.875222   -0.127143   -0.709769    -0.503684    0.121577     0.210544   -0.436066      0.0974779   -0.513266    0.569774   -0.237097    -0.0856242    0.141372     -0.261762    0.320534    0.409694    0.0940655  -1.07178     -0.123705   -0.451791   -0.217752   -0.409108     -0.219751     0.0601783   0.325151    0.268907
  0.110442   -0.408458   -0.113139    -0.627049    0.534788    -0.345511    0.142398      0.39512     -0.254588    0.459163   -0.22341      0.355997     0.0679703    -0.0678627   0.06936    -0.321898    0.294491    0.25829      0.756545   -0.86046    -0.191648   -0.152525      0.0205685    0.781563   -0.251884    0.46179
 -0.266427    0.125862    0.394045    -0.144313   -0.164043     0.390216    0.0542421     0.0589835    0.143211    0.39931     0.263773     0.0637849   -0.0980825    -0.478626   -0.351337    0.324814    0.232886   -0.284271     0.498372   -0.51776     0.617958   -0.282064     -0.331874    -0.278451   -0.0882211   0.853702
  0.012265    0.230326    0.173783    -0.287638    0.0813044    0.0692117  -0.0885468     0.14038     -0.0226332   0.0660231   0.0258384   -0.107602     0.165636      0.66606    -0.247566   -0.0795434   0.24769    -0.0801348    0.0991722  -0.638576   -0.117659    0.198467      0.562141     0.0308705  -0.920183    0.421904
 -0.687659   -0.872446   -0.544004     0.214785    0.166255    -0.3477      0.000917772   0.229254    -0.323533   -0.315382    0.208418     0.345822    -0.091965     -0.469868   -0.304545   -0.478129    0.256217    0.0148618   -0.660062    0.400614    0.0390617  -0.390418     -0.595783    -0.155366    0.156156   -0.22103
 -0.606539   -0.515266   -0.197559     0.226553   -0.342995    -0.246138    0.139767      1.02585     -0.291818   -0.0195712   0.0944076   -0.515       -0.189829     -0.560832   -0.0403187   0.395369   -0.800101    0.061678    -0.796342   -0.409827   -0.387419   -0.181561      0.113231    -0.538652   -0.51666     0.0276699
  0.189534    0.183616    0.181762     0.0287056  -0.114728     0.0634156  -0.346344      0.154986     0.0224997  -0.186269    0.0553292   -0.269672     0.120879     -0.0272845   0.0552675   0.228962   -0.240718   -0.0953386   -0.148348    0.0276246   0.180709    0.120111     -0.381303    -0.118795    0.280138    0.215498
 -0.0296082  -0.08058    -0.587596     0.106044   -0.182127     0.179632    0.688641     -0.393743    -0.175145    0.155938   -0.120858     0.117743    -0.0645372    -0.588077    0.285544    0.063841   -0.132708    0.0268339   -0.104619    0.281889   -0.2563     -0.331916      0.205578    -0.138647    0.486326   -0.625542
 -0.304024    0.0311923   0.43179      0.423567    0.0108971    0.465389    0.447308     -0.577509     0.522124    0.372366   -0.171021     0.563914    -0.151305      0.446793   -0.0648906  -0.553739   -0.128051   -0.452201     0.183554    0.77444     0.0734848  -0.544201      0.0757889   -0.36862    -0.129204    0.0313469
 -0.939756    0.0791493   0.750729     0.125347    0.0707675   -0.538112    0.0394436    -0.0587998    0.340969   -0.275783    0.0640247    0.27709     -0.0939114     0.410201   -0.147574   -0.248742    0.0168411   0.978327     0.367957    0.373232   -0.137691    0.343298      0.0187084    0.109257   -0.0437591  -0.167697
  0.463641   -0.012526   -0.527331    -0.0649972  -0.0255752   -0.332806   -0.207984      0.0996167    0.0319779  -0.179943   -0.273753    -0.180977    -0.000875521   0.448331    0.175686   -0.175003    0.103364    0.326773    -0.307218    0.279011   -0.977594   -0.0498833    -0.247882     0.612615    0.373991   -0.852574
  0.0358492  -0.314646   -0.278785     0.360441    0.778375    -0.0300757   0.209595     -0.12852      0.11811    -0.0342845  -0.359536     0.276676    -0.361546      0.40007     0.0258833  -0.217734   -0.0774536   0.310175    -0.142804    0.33184    -0.746435   -0.298685      0.994222     0.33816    -0.30043    -0.507248
  0.610341    0.328238   -0.147524     0.237403    0.827132     0.12059    -0.112693      0.0870078    0.34865     0.210194   -0.334295     0.190142    -0.650401     -0.191132   -0.171219   -0.233475   -0.14214     0.125336     0.318313   -0.0492414  -0.214689   -1.07602      -0.18468      0.130891   -0.0176558   0.0753703
  0.397056    0.706321    0.179889    -0.0459265   0.238173     0.282376    0.00637138    0.00776935   0.0150106   0.26477    -0.461977     0.487358    -0.0380988     0.195379    0.378666    0.638697   -0.59195    -0.0442713    0.371285    0.294468   -0.0452474   0.35921      -0.0372003   -0.345354    0.153677    0.44054
  0.197382   -0.2236     -0.203178    -0.0516845  -0.238534     0.275219    0.113125     -0.364108    -0.0604328   0.708048   -0.140735     0.628152    -0.31994      -0.489117   -0.245454    0.0272024   0.278668    0.289986     0.37204     0.100403   -0.296908    0.244421     -0.00631061  -0.278711    0.303135   -0.293651
  0.201565   -0.324073    0.561558     0.537743   -0.542173     0.124319    0.264803      0.0463022    0.0879948   0.468467   -0.345031     0.0155936    0.0314736    -0.388448    0.101383    0.644455    0.188875    0.0363639   -0.232033   -0.411322    0.20488     0.422372     -0.214729    -0.164889    0.013542   -0.410268
 -0.221055   -0.37331    -0.0509763   -0.155723    0.106748    -0.153949    0.0885604     0.117026    -0.0913166  -0.193147    0.123974     0.100635     0.108353     -0.266619   -0.0317724   0.073835    0.0143128   0.0294605   -0.130665   -0.0589012  -0.0284588  -0.000870372  -0.106272    -0.120518   -0.0453737   0.0182348
  0.192897    0.298618    0.0746495   -0.116145   -0.0538082    0.0805792  -0.0577208    -0.0733535    0.053441    0.095194    0.00860222  -0.00722602  -0.0193924     0.0754773  -0.0346825   0.02678     0.0134223  -0.118369     0.209759   -0.164905    0.028236   -0.00123815    0.0183283    0.158234   -0.0234128   0.193006
 -0.217601    0.0628541   0.143739     0.453738   -0.00853014   0.101295    0.123257     -0.0149562   -0.0307959   0.151853   -0.328279     0.0165251   -0.293835      0.251461    0.0891545  -0.195277   -0.128524    0.00641252  -0.204202    0.238813   -0.133109   -0.231777      0.289348     0.022185   -0.0272528  -0.268319
  0.0640735  -0.13472     0.144551     0.65525    -0.0580493    0.544236   -0.52245      -0.203339     0.117363   -0.0259832  -0.0742731   -0.0110847    0.900345      0.0470024  -0.114355    0.213879    0.413927   -0.00630685   0.037748    0.205854   -0.235077   -0.134917     -0.294466    -0.124009    0.300003    0.176915
 -0.263688    0.0979855  -0.305368    -0.318897    0.0434457    0.270375   -0.0556837    -0.0933276   -0.0346384  -0.365609    0.161765    -0.0679976    0.0719269     0.451721   -0.432596   -0.804489    0.613939   -0.149797     0.445766   -0.38347     0.0619721  -0.200017     -0.00982028   0.207188   -0.150454    0.233806
 -0.563088   -0.21109     0.0484666   -0.341103   -0.660874    -0.0667317   0.439767     -0.193994    -0.615777   -0.0311768   0.00281844  -0.17348      0.0279298     0.405007   -0.102304   -0.146458    0.286116    0.118055    -0.183301   -0.0846456   0.146342    0.273624      0.860136    -0.0591708  -0.143366   -0.160922
 -0.265991   -0.289481    0.240965     0.0555693   0.00931675  -0.23383     0.358904      0.351841    -0.518941   -0.503077   -0.646633     0.255969    -0.0794836     0.14608    -0.184392   -0.0404414   0.0980031  -0.00492239  -0.29911    -0.294886    0.516478    0.183911      0.157392     0.879381    0.322147   -0.0423469
  0.254374    0.483073   -0.102946    -0.339916   -0.0264867   -0.227948   -0.164522      0.679127    -0.180539   -0.181903    0.316932    -0.454702    -0.59406      -0.0915823  -0.406901    0.179168   -0.0434261   0.550233    -0.319031   -0.137774    0.49828     0.0310929    -0.062571     0.65004     0.1019     -0.0183203
 -0.12924     0.0723691   0.00887902  -0.0445466  -0.176181     0.269487    0.120367     -0.149602    -0.0496236  -0.466174    0.285422    -0.262717     0.0685164     0.0697533  -0.701471    0.356027   -0.547068   -0.245051    -0.939576    0.22683     0.487774   -0.139894      0.0650689   -0.751492   -0.0713041   0.0349956
 -0.261769    0.29577    -0.289012     0.0173306  -0.356302    -0.369757   -0.141765      0.1316       0.205398   -0.253846    0.193882    -0.176782    -0.188704     -0.210015    0.510997   -0.144084   -0.366732   -0.390883    -0.327278    0.613841    0.373553   -0.217598     -0.579434    -0.452821    0.430104   -0.147364
  0.422409    0.243375   -9.81336e-5  -0.131851    0.0802274    0.107972   -0.0997947    -0.178981     0.0505221  -0.0534927   0.693602    -0.741741     0.448879     -0.279643    0.0810708   0.18575    -0.288759    0.505278     0.24759     0.246958   -0.570585   -0.190963     -0.0463355   -0.660711   -0.113516    0.0683494
 -0.219159   -0.399274   -0.233715    -0.124985    0.180171     0.599886    0.818997      0.196656    -0.0764024  -0.0889817  -0.243571    -0.0300847    0.0718283    -0.222096   -0.268846    0.338078   -0.192327    0.0750793    0.224033    0.160551   -0.361301   -0.231172      0.204283    -0.756614   -0.0503445  -0.116993[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407964
[ Info: iteration 2, average log likelihood -1.407952
[ Info: iteration 3, average log likelihood -1.407940
[ Info: iteration 4, average log likelihood -1.407929
[ Info: iteration 5, average log likelihood -1.407918
[ Info: iteration 6, average log likelihood -1.407908
[ Info: iteration 7, average log likelihood -1.407898
[ Info: iteration 8, average log likelihood -1.407888
[ Info: iteration 9, average log likelihood -1.407879
[ Info: iteration 10, average log likelihood -1.407870
┌ Info: EM with 100000 data points 10 iterations avll -1.407870
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.446244e+05
      1       6.975923e+05      -2.470321e+05 |       32
      2       6.866436e+05      -1.094872e+04 |       32
      3       6.820542e+05      -4.589348e+03 |       32
      4       6.793939e+05      -2.660337e+03 |       32
      5       6.777471e+05      -1.646793e+03 |       32
      6       6.765488e+05      -1.198282e+03 |       32
      7       6.756455e+05      -9.033478e+02 |       32
      8       6.749391e+05      -7.064151e+02 |       32
      9       6.743234e+05      -6.156287e+02 |       32
     10       6.738066e+05      -5.168496e+02 |       32
     11       6.733440e+05      -4.626187e+02 |       32
     12       6.729409e+05      -4.030981e+02 |       32
     13       6.725963e+05      -3.445426e+02 |       32
     14       6.723074e+05      -2.889479e+02 |       32
     15       6.720489e+05      -2.584615e+02 |       32
     16       6.718281e+05      -2.208516e+02 |       32
     17       6.716309e+05      -1.971713e+02 |       32
     18       6.714511e+05      -1.798068e+02 |       32
     19       6.712826e+05      -1.684908e+02 |       32
     20       6.711291e+05      -1.535056e+02 |       32
     21       6.709843e+05      -1.447639e+02 |       32
     22       6.708464e+05      -1.378843e+02 |       32
     23       6.707023e+05      -1.441733e+02 |       32
     24       6.705558e+05      -1.464342e+02 |       32
     25       6.703986e+05      -1.572482e+02 |       32
     26       6.702107e+05      -1.878936e+02 |       32
     27       6.700379e+05      -1.727756e+02 |       32
     28       6.698863e+05      -1.515932e+02 |       32
     29       6.697288e+05      -1.575598e+02 |       32
     30       6.695824e+05      -1.463162e+02 |       32
     31       6.694369e+05      -1.455314e+02 |       32
     32       6.693176e+05      -1.193185e+02 |       32
     33       6.692129e+05      -1.046715e+02 |       32
     34       6.691233e+05      -8.965493e+01 |       32
     35       6.690446e+05      -7.863525e+01 |       32
     36       6.689723e+05      -7.229345e+01 |       32
     37       6.689028e+05      -6.953968e+01 |       32
     38       6.688331e+05      -6.966361e+01 |       32
     39       6.687674e+05      -6.573972e+01 |       32
     40       6.687000e+05      -6.740957e+01 |       32
     41       6.686284e+05      -7.161458e+01 |       32
     42       6.685595e+05      -6.883480e+01 |       32
     43       6.684976e+05      -6.197291e+01 |       32
     44       6.684431e+05      -5.446421e+01 |       32
     45       6.683919e+05      -5.115328e+01 |       32
     46       6.683465e+05      -4.547308e+01 |       32
     47       6.683002e+05      -4.625710e+01 |       32
     48       6.682593e+05      -4.086768e+01 |       32
     49       6.682186e+05      -4.076911e+01 |       32
     50       6.681773e+05      -4.124137e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 668177.3311301003)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419571
[ Info: iteration 2, average log likelihood -1.414586
[ Info: iteration 3, average log likelihood -1.413341
[ Info: iteration 4, average log likelihood -1.412499
[ Info: iteration 5, average log likelihood -1.411616
[ Info: iteration 6, average log likelihood -1.410717
[ Info: iteration 7, average log likelihood -1.409991
[ Info: iteration 8, average log likelihood -1.409519
[ Info: iteration 9, average log likelihood -1.409229
[ Info: iteration 10, average log likelihood -1.409033
[ Info: iteration 11, average log likelihood -1.408884
[ Info: iteration 12, average log likelihood -1.408764
[ Info: iteration 13, average log likelihood -1.408662
[ Info: iteration 14, average log likelihood -1.408577
[ Info: iteration 15, average log likelihood -1.408504
[ Info: iteration 16, average log likelihood -1.408441
[ Info: iteration 17, average log likelihood -1.408387
[ Info: iteration 18, average log likelihood -1.408340
[ Info: iteration 19, average log likelihood -1.408298
[ Info: iteration 20, average log likelihood -1.408261
[ Info: iteration 21, average log likelihood -1.408227
[ Info: iteration 22, average log likelihood -1.408196
[ Info: iteration 23, average log likelihood -1.408168
[ Info: iteration 24, average log likelihood -1.408142
[ Info: iteration 25, average log likelihood -1.408118
[ Info: iteration 26, average log likelihood -1.408095
[ Info: iteration 27, average log likelihood -1.408073
[ Info: iteration 28, average log likelihood -1.408053
[ Info: iteration 29, average log likelihood -1.408034
[ Info: iteration 30, average log likelihood -1.408016
[ Info: iteration 31, average log likelihood -1.407998
[ Info: iteration 32, average log likelihood -1.407981
[ Info: iteration 33, average log likelihood -1.407965
[ Info: iteration 34, average log likelihood -1.407950
[ Info: iteration 35, average log likelihood -1.407935
[ Info: iteration 36, average log likelihood -1.407921
[ Info: iteration 37, average log likelihood -1.407907
[ Info: iteration 38, average log likelihood -1.407893
[ Info: iteration 39, average log likelihood -1.407880
[ Info: iteration 40, average log likelihood -1.407868
[ Info: iteration 41, average log likelihood -1.407856
[ Info: iteration 42, average log likelihood -1.407844
[ Info: iteration 43, average log likelihood -1.407833
[ Info: iteration 44, average log likelihood -1.407821
[ Info: iteration 45, average log likelihood -1.407811
[ Info: iteration 46, average log likelihood -1.407800
[ Info: iteration 47, average log likelihood -1.407790
[ Info: iteration 48, average log likelihood -1.407780
[ Info: iteration 49, average log likelihood -1.407770
[ Info: iteration 50, average log likelihood -1.407761
┌ Info: EM with 100000 data points 50 iterations avll -1.407761
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.12419     -0.0241983   0.0320791   -0.115061    -0.24324      -0.724078    -0.577584     0.092115    0.183909    0.0617473   -0.308497   -0.0834711   0.0958899   0.899195    0.336385    -0.395073   -0.0337955    0.501384     0.055954    0.107442   -0.91487     0.299015    -0.214469    0.767708     0.243051     -0.772877
  1.03468      0.476039   -0.00915652  -0.0241697    0.560951     -0.0955638   -0.0251483    0.356137    0.314442    0.150558     0.0170439  -0.298021   -0.566143   -0.264935   -0.321119    -0.0132121  -0.217384     0.35994      0.282783   -0.320117   -0.173275   -0.789109    -0.137136    0.240822    -0.0239536    -0.00692815
  0.28364      0.521576    0.752991    -0.294151    -0.351977     -0.29108     -0.275463     0.0966575   0.115051    0.536155    -0.604923    0.743664   -0.76218     0.349984   -0.0292697    0.319365    0.601302    -0.153048    -0.185176   -0.602132    0.0940725   0.00302869  -0.64668     0.390201    -0.5139        0.526279
 -0.385936     0.0126111   0.180821    -0.0188548    0.0448827     0.4873       0.237625    -0.290389    0.169534    0.391602     0.295463    0.359134   -0.105698   -0.740637   -0.293889     0.358962    0.199947    -0.584119     0.381435   -0.342395    0.837875   -0.638091    -0.134681   -0.429292     0.123896      0.864921
  0.271692     0.604202    0.26519      0.128112     0.284806      0.249243     0.00777804   0.102459    0.0808084   0.229826    -0.366041    0.397566   -0.135183   -0.010924    0.326892     0.622393   -0.907972     0.0445427    0.249516    0.49675    -0.0416159   0.280812    -0.149168   -0.47109      0.19289       0.333399
  0.0102493   -0.0246752   0.101613     0.330413     0.366322      0.224389     0.275507    -0.150465    0.215879    0.0388154   -0.491185    0.255934   -0.36701     0.685836   -0.10022     -0.401883   -0.288776    -0.0901473    0.122077    0.887459   -0.371614   -0.66683      0.518801   -0.0570512   -0.426376     -0.0989784
  0.0677369   -0.59244    -0.0758549   -0.308062    -0.209457     -0.25987      0.034011    -0.495611    0.231521   -0.566322     0.241155    0.392429    0.341678   -0.0730676   0.0195393    0.0426963  -0.193509    -0.620596    -0.343034    0.187902    0.295622    0.414038     0.320752    0.435696     0.626412     -0.553416
 -0.283435    -0.59856    -0.22068      0.165239    -0.302211     -0.219963    -0.143204    -0.328679    0.109261    0.179386     0.548348   -0.256354   -0.16758    -0.264013    0.0873818   -0.463783    0.643764    -0.576925    -0.0205944  -0.377408   -0.341889   -0.468999     0.0377923   0.594633    -0.0669569    -0.198128
  0.752834    -0.0667514  -0.567564    -0.366551     0.373801      0.117567    -0.418236     0.184613   -0.264356    0.393029    -0.335753   -0.11701     0.222623   -0.219752    0.408725     0.360536   -0.153466    -0.935937    -0.113271   -0.334884   -0.175417   -0.252426    -0.319539    0.0774585    0.235604      0.314288
 -0.0512988   -0.214901   -0.344743     0.333381     0.900771     -0.104781     0.0630065   -0.0707077   0.128109   -0.18662     -0.251984    0.286043   -0.0342453   0.123969    0.246756    -0.336268    0.0529706    0.189861    -0.261719    0.148132   -0.820947   -0.270022     0.393531    0.409495    -0.0809843    -0.504501
 -0.535312    -0.209089   -0.261772    -0.156432     0.00655941   -0.441446     0.160152     0.692068   -0.155642   -0.594035     0.36952    -0.264571   -0.290012   -0.28324    -0.225056    -0.153837   -0.451003    -0.122258    -0.55407     0.103035    0.433868   -0.239456    -0.492106   -0.127737    -0.0865849     0.000309603
 -0.477724    -0.576191   -0.205317     0.254233     0.295375      0.0472669   -0.22636     -0.143833   -0.259458   -0.0599869   -0.173814    0.718485    0.277676   -0.314844   -0.189456    -0.122973    0.266528     0.072851    -0.128464    0.494956   -0.0582343  -0.0518668   -0.670458   -0.405638     0.39583      -0.0370194
  0.337842     0.852185    0.0612852    0.113753    -0.403888     -0.0280886   -0.40458      0.0204002   0.475334    0.0131124    0.775714   -0.340251   -0.747354    0.296671    0.688066    -0.371438   -0.437877    -0.32056     -0.530257   -0.0596438   0.128899    0.0748858    0.0428031   0.179025    -0.0394878    -0.0735204
 -0.647912    -0.439812   -0.447525     0.0914921   -0.120861      0.242148     0.452109     0.497678   -0.195388   -0.00358676  -0.136531   -0.23222    -0.0975042  -0.280394    0.0976771    0.16341    -0.539224    -0.103504    -0.437441   -0.255308   -0.408703   -0.259994     0.502657   -0.759161    -0.389723     -0.00396443
  0.0967504   -0.185116    0.28379      0.180499    -0.307883     -0.147661     0.0159149    0.0938329   0.0511161   0.123549     0.0578475   0.0854247   0.152888   -0.542353    0.245715     0.43573     0.152309    -0.0516544   -0.105195   -0.349758    0.170417    0.570294    -0.267843    0.0772778   -0.0501851     0.00313868
  0.00553431   0.224261    0.396964    -0.0218293   -0.00327675   -0.18778     -0.28176     -0.0172661   0.183361   -0.877029     0.127457   -0.532423    0.833301    0.515747    0.247473     0.0668342  -0.279704    -0.48083     -0.376956   -0.300828    0.15561     0.0576664   -0.168255    0.269316    -0.251291      0.407111
 -0.398516     0.042253    0.254117    -0.403812    -0.711913     -0.00423277   0.42946     -0.109619   -0.81145     0.150622    -0.0412354  -0.0228163   0.0787562   0.600746    0.0020725    0.152974    0.230866     0.00524663   0.0247205  -0.145958    0.243874    1.00286      0.869553   -0.203961    -0.206893     -0.0440079
  0.00459555  -0.483888   -0.0797036   -0.815771     0.652195     -0.358293     0.288372     0.654111   -0.364677    0.398178    -0.144258    0.431959    0.0152078  -0.131773   -0.00799423  -0.311309    0.112165     0.316969     0.837517   -1.03051    -0.0280079  -0.100477    -0.064338    0.787294    -0.255542      0.551813
 -0.154743     0.09905    -0.287334    -0.403074     0.301752      0.106529    -0.476074    -0.0801068   0.187778   -0.0463694    0.111906    0.135845    0.277312    0.593358   -0.285219    -0.721593    0.433773    -0.523176     0.205032   -0.639298    0.182818    0.0448637    0.624535    0.256641    -0.980154      0.59651
  0.496453    -0.334575   -0.331682     0.00278013  -0.128559      0.365598     0.492262    -0.276888    0.0999178   0.829071    -0.359106    0.432825   -0.459012   -0.581204   -0.203925     0.271009    0.156709     0.492348     0.162072    0.168636   -0.545142    0.106856     0.18122    -0.228088     0.143779     -0.657494
 -0.0411462    0.0784322   0.0112907   -0.0294447    0.0414937     0.028236    -0.00269417  -0.032298    0.0106362  -0.0228575   -0.0166      0.0609432  -0.0346465   0.0305274   0.00509842  -0.0488783  -0.0438957   -0.0705511    0.0416067   0.019026   -0.0529412  -0.0800006    0.0167788   0.0119146    0.0151047     0.0407473
  0.0706462    0.260596   -0.185336     0.136454    -0.162712      0.10515     -0.0285286   -0.303998    0.0826236  -0.192351     0.240495   -0.374213    0.317492   -0.116606   -0.0921728    0.355528   -0.355373     0.0636311   -0.504177    0.77267    -0.174019   -0.312136    -0.0966489  -0.746446     0.172648     -0.330055
  0.0692745    0.174574   -0.736261     0.0880155   -0.665072      0.0167253    0.387677    -0.180803   -0.317949   -0.0319799   -0.0866126  -0.0883413  -0.252607   -0.369932    0.369123    -0.121091   -0.0614291   -0.0791004   -0.0896314   0.485563   -0.121524   -0.579178    -0.254414   -0.099021     1.0154       -0.575765
 -0.0125218    0.572172    0.52578      0.0577171    0.150964     -0.0823635    0.0336454   -0.611639    0.284589   -0.110641    -0.0713017   0.497982   -0.0866583   0.407194    0.181058    -0.499756    0.56367      0.101999     0.791692    0.407158    0.412256    0.181495    -0.324795    0.418873     0.474759      0.0723197
 -0.0424766    0.282885    0.111845    -0.275479    -0.145477      0.385525    -0.215872    -0.0696927   0.28529     0.00601994   0.83294    -0.174653    0.154521   -0.0753046  -0.460278    -0.0772159   0.332438     0.122487     0.922001   -0.0485249  -0.178617    0.105648    -0.235324   -0.312077    -0.352646      0.430326
 -0.137082     0.0863473   0.0463435    0.118835    -0.000226033  -0.188841     0.130357     0.300657   -0.410914   -0.215796    -0.54462     0.142075   -0.470408    0.262744   -0.0382387   -0.215755    0.0324258   -0.00653033  -0.376826   -0.25774     0.401403   -0.0293627    0.423743    0.885579     0.141778     -0.127046
 -0.276156    -0.156456    0.92532      0.590285    -0.352157      0.633613     0.180545     0.0251778   0.138993    0.683906    -0.277963   -0.195389   -0.0324392   0.11248    -0.283829     0.0367667  -0.00804311  -0.0988244   -0.034989   -0.383336    0.215129   -0.114589     0.102305   -0.416343    -0.077749     -0.161535
  0.606795     0.347115   -0.107517    -0.0872708   -0.0314958     0.537514    -0.464725    -0.461472   -0.0842348   0.606151    -0.198588    0.258309    0.457306    0.275535    0.115758     0.202536    0.437534    -0.0476388    0.757931   -0.149385   -0.346577   -0.17489      0.266988    0.0790526    0.382088      0.339333
 -1.04881     -0.229581    0.574964     0.135131     0.0297589    -0.422778     0.376739    -0.0835494   0.276687   -0.385068     0.26173     0.0977356  -0.159954    0.137857   -0.370194    -0.217968   -0.0127373    1.01243      0.0403858   0.37713    -0.0881177   0.213488     0.320982    0.0127222   -0.261578     -0.147957
 -0.0345368   -0.269609   -0.267068    -0.277202     0.128818      0.193727     0.396476     0.050569   -0.359352   -0.344557    -0.0974975  -0.230507    0.173517    0.127133   -0.545764    -0.098098    0.469078     0.435049    -0.0466293  -0.319644   -0.0437894  -0.250625     0.237878    0.00593071  -0.000317287  -0.012183
  0.131381    -0.0922237   0.0864309   -0.063697    -0.205562      0.175525     0.0608228    0.276339   -0.175983    0.0827895    0.1186     -0.446338    0.13799    -0.188787   -0.117281     0.416205   -0.350932    -0.105705    -0.191555   -0.139847   -0.0181635   0.0486379   -0.0433159  -0.447517    -0.229065      0.161497
  0.212161     0.20582    -0.0641038   -0.139323    -0.330745     -0.0822413   -0.687176    -0.185977   -0.135223   -0.444796     0.453948   -0.327096    0.465474   -0.281693   -0.0576658    0.203955    0.69618      0.146211    -0.259082   -0.539863    0.456468    0.375291    -0.360938    0.294561     0.645943      0.315916[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407752
[ Info: iteration 2, average log likelihood -1.407743
[ Info: iteration 3, average log likelihood -1.407735
[ Info: iteration 4, average log likelihood -1.407726
[ Info: iteration 5, average log likelihood -1.407718
[ Info: iteration 6, average log likelihood -1.407710
[ Info: iteration 7, average log likelihood -1.407703
[ Info: iteration 8, average log likelihood -1.407695
[ Info: iteration 9, average log likelihood -1.407688
[ Info: iteration 10, average log likelihood -1.407681
┌ Info: EM with 100000 data points 10 iterations avll -1.407681
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
