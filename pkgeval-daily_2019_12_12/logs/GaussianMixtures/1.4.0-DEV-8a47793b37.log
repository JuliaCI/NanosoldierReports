Julia Version 1.4.0-DEV.591
Commit 8a47793b37 (2019-12-12 10:31 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed URIParser ────────── v0.4.0
 Installed PDMats ───────────── v0.9.10
 Installed CMake ────────────── v1.1.2
 Installed Compat ───────────── v2.2.0
 Installed OrderedCollections ─ v1.1.0
 Installed SpecialFunctions ─── v0.9.0
 Installed Clustering ───────── v0.13.3
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed ScikitLearnBase ──── v0.5.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed BinDeps ──────────── v1.0.0
 Installed FileIO ───────────── v1.2.0
 Installed Distributions ────── v0.21.11
 Installed LegacyStrings ────── v0.4.1
 Installed StatsBase ────────── v0.32.0
 Installed StatsFuns ────────── v0.9.2
 Installed DataStructures ───── v0.17.6
 Installed Rmath ────────────── v0.6.0
 Installed QuadGK ───────────── v2.3.1
 Installed StaticArrays ─────── v0.12.1
 Installed Parameters ───────── v0.12.0
 Installed HDF5 ─────────────── v0.12.5
 Installed FillArrays ───────── v0.8.2
 Installed Missings ─────────── v0.4.3
 Installed Blosc ────────────── v0.5.1
 Installed Arpack ───────────── v0.4.0
 Installed NearestNeighbors ─── v0.4.4
 Installed DataAPI ──────────── v1.1.0
 Installed BinaryProvider ───── v0.5.8
 Installed Arpack_jll ───────── v3.5.0+2
 Installed SortingAlgorithms ── v0.3.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed Distances ────────── v0.8.2
 Installed JLD ──────────────── v0.9.1
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
Status `/tmp/jl_ZDvWUU/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
┌ Warning: Replacing docs for `FileIO.filename :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
┌ Warning: Replacing docs for `FileIO.file_extension :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
[ Info: Testing Data
(100000, -2.0480344802398428e6, [32132.090733634275, 67867.90926636574], [437.30012783679473 9236.703121101318 -3969.9774691635303; -645.1037739292245 -8665.46671856737 4334.718022277864], [[30930.40233548215 -2272.0328565035843 2966.737108437686; -2272.0328565035843 12712.769962242019 11846.523536846023; 2966.737108437686 11846.523536846023 25248.54858269041], [68717.91668736462 2520.9531166418124 -2711.8150220312873; 2520.9531166418124 86841.1438253084 -11470.409352487271; -2711.8150220312873 -11470.409352487271 74796.84035981605]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.676759e+03
      1       1.013913e+03      -6.628454e+02 |        8
      2       9.780889e+02      -3.582451e+01 |        0
      3       9.780889e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 978.0889177334152)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.077309
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.717174
[ Info: iteration 2, lowerbound -3.557167
[ Info: iteration 3, lowerbound -3.389548
[ Info: iteration 4, lowerbound -3.206646
[ Info: iteration 5, lowerbound -3.027962
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.863409
[ Info: iteration 7, lowerbound -2.729661
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.619677
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.528226
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.455138
[ Info: iteration 11, lowerbound -2.397772
[ Info: iteration 12, lowerbound -2.357409
[ Info: iteration 13, lowerbound -2.328391
[ Info: iteration 14, lowerbound -2.311172
[ Info: iteration 15, lowerbound -2.307833
[ Info: dropping number of Gaussions to 2
[ Info: iteration 16, lowerbound -2.302918
[ Info: iteration 17, lowerbound -2.299260
[ Info: iteration 18, lowerbound -2.299256
[ Info: iteration 19, lowerbound -2.299254
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Dec 12 18:25:27 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Dec 12 18:25:35 2019: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Thu Dec 12 18:25:37 2019: EM with 272 data points 0 iterations avll -2.077309
5.8 data points per parameter
, Thu Dec 12 18:25:39 2019: GMM converted to Variational GMM
, Thu Dec 12 18:25:48 2019: iteration 1, lowerbound -3.717174
, Thu Dec 12 18:25:48 2019: iteration 2, lowerbound -3.557167
, Thu Dec 12 18:25:48 2019: iteration 3, lowerbound -3.389548
, Thu Dec 12 18:25:48 2019: iteration 4, lowerbound -3.206646
, Thu Dec 12 18:25:48 2019: iteration 5, lowerbound -3.027962
, Thu Dec 12 18:25:49 2019: dropping number of Gaussions to 7
, Thu Dec 12 18:25:49 2019: iteration 6, lowerbound -2.863409
, Thu Dec 12 18:25:49 2019: iteration 7, lowerbound -2.729661
, Thu Dec 12 18:25:49 2019: dropping number of Gaussions to 5
, Thu Dec 12 18:25:49 2019: iteration 8, lowerbound -2.619677
, Thu Dec 12 18:25:49 2019: dropping number of Gaussions to 4
, Thu Dec 12 18:25:49 2019: iteration 9, lowerbound -2.528226
, Thu Dec 12 18:25:49 2019: dropping number of Gaussions to 3
, Thu Dec 12 18:25:49 2019: iteration 10, lowerbound -2.455138
, Thu Dec 12 18:25:49 2019: iteration 11, lowerbound -2.397772
, Thu Dec 12 18:25:49 2019: iteration 12, lowerbound -2.357409
, Thu Dec 12 18:25:49 2019: iteration 13, lowerbound -2.328391
, Thu Dec 12 18:25:49 2019: iteration 14, lowerbound -2.311172
, Thu Dec 12 18:25:49 2019: iteration 15, lowerbound -2.307833
, Thu Dec 12 18:25:49 2019: dropping number of Gaussions to 2
, Thu Dec 12 18:25:49 2019: iteration 16, lowerbound -2.302918
, Thu Dec 12 18:25:49 2019: iteration 17, lowerbound -2.299260
, Thu Dec 12 18:25:49 2019: iteration 18, lowerbound -2.299256
, Thu Dec 12 18:25:49 2019: iteration 19, lowerbound -2.299254
, Thu Dec 12 18:25:49 2019: iteration 20, lowerbound -2.299254
, Thu Dec 12 18:25:49 2019: iteration 21, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 22, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 23, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 24, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 25, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 26, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 27, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 28, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 29, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 30, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 31, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 32, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 33, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 34, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 35, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 36, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 37, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 38, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 39, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 40, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 41, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 42, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 43, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 44, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 45, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 46, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 47, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 48, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 49, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: iteration 50, lowerbound -2.299253
, Thu Dec 12 18:25:49 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601382, 95.95490777398618]
β = [178.04509222601382, 95.95490777398618]
m = [4.25030073326991 79.28686694436185; 2.000229257775371 53.8519871724613]
ν = [180.04509222601382, 97.95490777398618]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484735 -0.007644049042327438; 0.0 0.008581705166333458], [0.37587636119484036 -0.008953123827345958; 0.0 0.01274866477740938]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999993
avll from stats: -1.0111512869877775
avll from llpg:  -1.0111512869877781
avll direct:     -1.011151286987778
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9819340291280511
avll from llpg:  -0.9819340291280511
avll direct:     -0.9819340291280511
sum posterior: 100000.00000000001
32×26 Array{Float64,2}:
 -0.147964     0.0245927   -0.0772458  -0.0705096    0.0590008    0.000562264  -0.0727165    0.143644     0.0905812    0.00352944    0.0851858   -0.164678     0.116276     0.0118137    0.0846118   0.00350353  -0.190722    -0.0162761     0.0181182     0.168199     0.0816903     0.130398     0.000509375  -0.0477295   0.198038     0.171062
  0.0843577   -0.00872233  -0.126985   -0.0352853   -0.0779193    0.0531174     0.131288    -0.0325624    0.0112968    0.0642521    -0.191577    -0.0627753    0.0350114    0.0790221    0.0333865   0.0101158    0.153976    -0.00102996   -0.180323     -0.00697486  -0.0771087     0.0184495    0.0556888     0.0026895   0.0316399   -0.152491
  0.15476     -0.00530365  -0.010823   -0.020631     0.0554347   -0.146324      0.0516192   -0.087227    -0.114471     0.0121777     0.246105    -0.0737406   -0.127439     0.0190323    0.0985615  -0.0832254    0.0295618    0.00099216   -0.236668     -0.101974     0.123267      0.084801     0.146484     -0.135838   -0.0925974    0.0214627
 -0.00234766  -0.0192522    0.0808427   0.0635817    0.0933608    0.145899      0.00535082   0.109693     0.290935    -0.172821     -0.123783     0.0793128    0.055669     0.0832698    0.163558   -0.077105    -0.186033    -0.0793338    -0.143719      0.120053     0.0375307    -0.103874     0.0956275    -0.0121228   0.133627     0.0935199
 -0.187831    -0.0153235    0.0751473  -0.147487    -0.190211    -0.0123751     0.0761936   -0.0242055    0.0761941   -0.0214165    -0.169318     0.0502766   -0.0234715    0.0698433    0.153306    0.202964     0.00257356   0.0202258    -0.174546      0.0613301   -0.00148713    0.00695464   0.0738408     0.145145    0.0723756   -0.140631
 -0.00107336   0.00917502   0.184915    0.0012003    0.0434135   -0.101844      0.170823    -0.0975908   -0.0754273    0.0495134     0.0729912    0.0994387    0.0890451    0.00551083   0.083621   -0.0306191   -0.169534     0.0304212    -0.0823767    -0.0531147   -0.0896827    -0.0586781    0.0227449    -0.174497   -0.0624119    0.0667741
 -0.0271777    0.0759182   -0.151333    0.110248     0.0527087   -0.0102392    -0.0218521    0.0421603    0.120937     0.0630759    -0.131532     0.0297518   -0.0342325   -0.0784545   -0.0523434  -0.17941     -0.112074    -0.033861     -0.07708       0.126399     0.0716408     0.00680444   0.117372      0.1029      0.228665     0.00489013
  0.167564     0.140503     0.0809571   0.0855488   -0.0266079    0.125394     -0.165387    -0.168981     0.0892247   -0.0795188    -0.0116645   -0.141405     0.00904959  -0.0815443   -0.172811   -0.107081     0.00188387   0.000986836  -0.03285      -0.0204506   -0.186586      0.057224    -0.0388476     0.0548024   0.0955292    0.145074
  0.0225687    0.0706947   -0.177094    0.00177364   0.0820574   -0.065871      0.12381     -0.00352965  -0.0497657    0.0875634    -0.0363752    0.0122442    0.0190817    0.0812543   -0.0700076  -0.0111937    0.096365     0.0922317     0.0720814     0.00300123  -0.108956      0.0904159    0.0480733    -0.0349752  -0.0369818    0.057997
  0.121273    -0.173578    -0.0126204  -0.0570735   -0.104027    -0.221792      0.0042409    0.109945    -0.0234016    0.2224       -0.0334368   -0.165306    -0.120914    -0.101987    -0.0109144   0.046785    -0.229697     0.0192309    -0.0123561    -0.00830672  -0.124488      0.0226527    0.0844719     0.125949   -0.135448    -0.210685
 -0.00660675  -0.203294    -0.158895   -0.0189844    0.076879     0.0332491     0.00319428   0.0225747    0.0295164    0.0810311    -0.100579    -0.0634226    0.137024    -0.0424258    0.0604719   0.169963     0.014968    -0.128815      0.0275127    -0.0118845    0.0961194    -0.0188221    0.0484626    -0.014273    0.102092    -0.0210031
  0.028263    -0.0876168    0.0658227   0.174801    -0.0298234   -0.0337697    -0.00884253   0.0799879   -0.104469     0.000266022   0.0223685    0.129171     0.0526026    0.144778    -0.0443463  -0.0947313   -0.0983816   -0.276016     -0.0496661    -0.106562     0.0831836    -0.0454801    0.250782     -0.0863348  -0.0297052   -0.121201
 -0.17441      0.0625541   -0.100723    0.0494915    0.00446193  -0.105371      0.0362674    0.0691082   -0.0997112   -0.1038        0.0886815    0.0813736    0.00972397  -0.156818     0.051052   -0.0755276   -0.0300387    0.0277881     0.0888137     0.0299584    0.0622719     0.101837    -0.0369516    -0.0757608   0.0763742    0.0330197
 -0.0269886   -0.0457049   -0.0104185  -0.0651955   -0.0236454    0.131588      0.0413468    0.0513612   -0.102602    -0.255573      0.140845     0.232589     0.136315    -0.0331764   -0.202709   -0.0372708   -0.0473904    0.041176     -0.000548467   0.207677     0.0985723    -0.170554     0.0932618    -0.0771929  -0.0176097    0.0520012
 -0.0939545    0.0656077   -0.0616842  -0.0178404   -0.0301984   -0.0259873     0.0696062    0.100042    -0.120236    -0.0283809     0.0444432   -0.0934765    0.0450238    0.0991393   -0.104621    0.0387088   -0.063187     0.0605072    -0.0443625     0.0599318   -0.0894031    -0.021873    -0.0917705    -0.136994    0.0437534   -0.083636
 -0.0976483   -0.0235825   -0.0892016  -0.146942    -0.110358    -0.081504      0.138911    -0.00121739  -0.0499531    0.0028011    -0.016614    -0.133953    -0.0660263   -0.00800148  -0.062025    0.0939944    0.00586115  -0.078776      0.182979     -0.0973326   -0.0087704     0.112243    -0.109024      0.153666   -0.00165431  -0.0146714
 -0.13499     -0.00825879   0.107152    0.103474    -0.0631599    0.140891      0.0622269    0.112898     0.058702    -0.0211613    -0.0234648   -0.066023    -0.0566041   -0.0812802    0.0583499  -0.00905172  -0.0502826   -0.145753      0.0393048     0.218432    -0.232617     -0.0276951    0.183861     -0.129183    0.00476118  -0.0754667
 -0.00523166  -0.0464843   -0.110469   -0.13407     -0.125595    -0.0230228     0.056797    -0.0128721   -0.0500538    0.0739451     0.0612796   -0.0108679    0.226637    -0.0281681   -0.131751    0.0472533    0.0128332   -0.21299      -0.0202097     0.0277242    0.0314648    -0.109436    -0.0667605    -0.197354   -0.101805     0.202942
 -0.081792    -0.0889969   -0.0414828   0.0904962    0.13361     -0.0809117     0.0308322   -0.2248      -0.238233     0.10526      -0.0966362   -0.00741519  -0.0178533    0.0126295   -0.152216   -0.265401     0.0960978    0.0250573    -0.0433619    -0.0255108    0.0341343    -0.0289808   -0.0391406     0.0669924  -0.0328187   -0.029945
  0.173314     0.0552473   -0.0629493   0.156548    -0.0667361   -0.171635      0.155453     0.0930888   -0.244122     0.105922      0.0703485   -0.0310494   -0.013779     0.12183     -0.0219024  -0.218165     0.0254369   -0.00164193   -0.0579093    -0.176077    -0.0516498     0.00495526   0.0314761     0.116773   -0.0803563    0.0879381
 -0.0347974    0.0723805   -0.109084    0.00673419   0.0376341    0.0847647    -0.165047    -0.198424    -0.0990797    0.0537331     0.150553     0.0733482    0.0123505    0.0947386    0.0901543  -0.219654    -0.0941418    0.0520784    -0.0639056    -0.188494     0.000578015  -0.0513648   -0.0174873     0.0135896  -0.0588673    0.103169
 -0.0422479   -0.080029    -0.0726472  -0.0788473   -0.050751    -0.0428456     0.0488529   -0.16402     -0.0341907    0.0274055    -0.0384342    0.00706644   0.0558198   -0.0259709    0.052875   -0.131627     0.0103678   -0.0375758    -0.0616882     0.10011     -0.18595      -0.0228952   -0.129556     -0.199233   -0.143453    -0.0976523
 -0.161878    -0.00707941  -0.123984   -0.202346     0.134502     0.206957     -0.071975    -0.171813     0.00536913   0.126803     -0.00140905  -0.0188429    0.0208403   -0.019283    -0.08192    -0.0582729    0.0152441   -0.0922489    -0.0560811     0.0359909    0.211369      0.0921496    0.0536411    -0.172679    0.154447    -0.205973
 -0.0888596   -0.0378192   -0.112432   -0.0968556   -0.0602447   -0.126         0.221662     0.0966369   -0.0192882    0.00319912   -0.0875035    0.166706    -0.0105478   -0.10632      0.0152339  -0.0220951   -0.00170024   0.147506      0.0877848     0.0237996    0.027855      0.0302388    0.0552231    -0.0471546  -0.0435365   -0.00546249
 -0.0161807   -0.00642541   0.0872175   0.0451544   -0.0120596   -0.0581836    -0.0266585   -0.0178573    0.0847073    0.027276     -0.100756    -0.0108126    0.0267532    0.0544572   -0.0260263  -0.0968483   -0.010569    -0.167852      0.00943495   -0.0839312   -0.0393053     0.153276     0.120573     -0.196578   -0.0100699   -0.00766848
  0.0112031    0.109207     0.211367    0.0720988    0.00991698   0.0854556     0.107974    -0.16476     -0.0581165   -0.125367     -0.069722     0.104931     0.0663532   -0.00484062   0.0831285  -0.0221111    0.152428     0.0485498     0.0769196    -0.00113171  -0.00572931    0.172771    -0.0417337    -0.20074     0.00307083  -0.016908
 -0.0543292   -0.00658008   0.0911867  -0.142494    -0.0314898    0.10661       0.0231304   -0.00774297   0.0510376   -0.0200655    -0.00814639  -0.0536979   -0.0831749    0.0363611    0.0550759  -0.105246     0.0296491    0.0289078     0.0186852     0.054259    -0.0784899    -0.00593033   0.0587405    -0.115052   -0.0710718    0.220169
  0.120828    -0.0566102   -0.114438    0.0948097    0.108315    -0.0760751    -0.0639485   -0.115759     0.0440996    0.0983929    -0.171212    -0.0354332    0.0499053   -0.0160271    0.0605203  -0.0406825    0.305928    -0.129743     -0.0910333     0.0115693    0.135596      0.167951     0.0420056     0.205283   -0.0219311   -0.248388
  0.100817     0.00553513  -0.044622    0.0304949    0.0418815   -0.0784338    -0.0952652    0.201326     0.12227      0.0805092    -0.05033      0.158615    -0.0704885    0.0252227    0.0617921   0.0661568    0.0977391    0.104922     -0.199203      0.0874143    0.0255918    -0.0162746    0.0235456    -0.0763154   0.180384    -0.078888
 -0.0895043    0.00166816  -0.177996   -0.172793     0.101541     0.0754607    -0.133292     0.0271762    0.0760776    0.0644334    -0.205181     0.108702    -0.0413965   -0.0912987    0.0413256  -0.0319704    0.0384442    0.00990657   -0.145536     -0.225516    -0.0715634    -0.138866     0.0713845     0.0352067  -0.111721    -0.0690088
  0.224104    -0.0876299   -0.0805848   0.0140128    0.0297735    0.0183991    -0.0749665    0.0188012    0.00280845   0.0702646     0.0852029    0.0217309   -0.0704662   -0.156257     0.154733    0.128593     0.0861148    0.0961008    -0.0480522    -0.163524     0.0426923     0.0139529   -0.0847825     0.115807    0.182999    -0.089214
 -0.088034     0.0118497   -0.0988698   0.0908027   -0.0789046    0.000947084  -0.0450976   -0.213429     0.0173526    0.242165      0.0509979    0.186742    -0.0852277    0.0252913    0.132134    0.126361    -0.168787     0.06721       0.005888      0.114922     0.193971     -0.0118723    0.101478      0.14606    -0.085979    -0.0964736kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3826578075823004
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.382734
[ Info: iteration 2, average log likelihood -1.382627
[ Info: iteration 3, average log likelihood -1.381657
[ Info: iteration 4, average log likelihood -1.373030
[ Info: iteration 5, average log likelihood -1.355729
[ Info: iteration 6, average log likelihood -1.350458
[ Info: iteration 7, average log likelihood -1.349484
[ Info: iteration 8, average log likelihood -1.349046
[ Info: iteration 9, average log likelihood -1.348789
[ Info: iteration 10, average log likelihood -1.348587
[ Info: iteration 11, average log likelihood -1.348389
[ Info: iteration 12, average log likelihood -1.348212
[ Info: iteration 13, average log likelihood -1.348076
[ Info: iteration 14, average log likelihood -1.347977
[ Info: iteration 15, average log likelihood -1.347900
[ Info: iteration 16, average log likelihood -1.347835
[ Info: iteration 17, average log likelihood -1.347779
[ Info: iteration 18, average log likelihood -1.347729
[ Info: iteration 19, average log likelihood -1.347684
[ Info: iteration 20, average log likelihood -1.347644
[ Info: iteration 21, average log likelihood -1.347607
[ Info: iteration 22, average log likelihood -1.347574
[ Info: iteration 23, average log likelihood -1.347543
[ Info: iteration 24, average log likelihood -1.347514
[ Info: iteration 25, average log likelihood -1.347486
[ Info: iteration 26, average log likelihood -1.347459
[ Info: iteration 27, average log likelihood -1.347431
[ Info: iteration 28, average log likelihood -1.347400
[ Info: iteration 29, average log likelihood -1.347363
[ Info: iteration 30, average log likelihood -1.347314
[ Info: iteration 31, average log likelihood -1.347245
[ Info: iteration 32, average log likelihood -1.347160
[ Info: iteration 33, average log likelihood -1.347079
[ Info: iteration 34, average log likelihood -1.347014
[ Info: iteration 35, average log likelihood -1.346965
[ Info: iteration 36, average log likelihood -1.346930
[ Info: iteration 37, average log likelihood -1.346903
[ Info: iteration 38, average log likelihood -1.346882
[ Info: iteration 39, average log likelihood -1.346866
[ Info: iteration 40, average log likelihood -1.346852
[ Info: iteration 41, average log likelihood -1.346841
[ Info: iteration 42, average log likelihood -1.346831
[ Info: iteration 43, average log likelihood -1.346823
[ Info: iteration 44, average log likelihood -1.346815
[ Info: iteration 45, average log likelihood -1.346808
[ Info: iteration 46, average log likelihood -1.346802
[ Info: iteration 47, average log likelihood -1.346796
[ Info: iteration 48, average log likelihood -1.346791
[ Info: iteration 49, average log likelihood -1.346786
[ Info: iteration 50, average log likelihood -1.346780
┌ Info: EM with 100000 data points 50 iterations avll -1.346780
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.382733620587501
│     -1.3826270687885636
│      ⋮
└     -1.3467801803908153
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.346890
[ Info: iteration 2, average log likelihood -1.346762
[ Info: iteration 3, average log likelihood -1.346193
[ Info: iteration 4, average log likelihood -1.340908
[ Info: iteration 5, average log likelihood -1.325878
[ Info: iteration 6, average log likelihood -1.316545
[ Info: iteration 7, average log likelihood -1.314056
[ Info: iteration 8, average log likelihood -1.312665
[ Info: iteration 9, average log likelihood -1.311491
[ Info: iteration 10, average log likelihood -1.310468
[ Info: iteration 11, average log likelihood -1.309598
[ Info: iteration 12, average log likelihood -1.308868
[ Info: iteration 13, average log likelihood -1.308223
[ Info: iteration 14, average log likelihood -1.307592
[ Info: iteration 15, average log likelihood -1.306951
[ Info: iteration 16, average log likelihood -1.306340
[ Info: iteration 17, average log likelihood -1.305811
[ Info: iteration 18, average log likelihood -1.305379
[ Info: iteration 19, average log likelihood -1.305047
[ Info: iteration 20, average log likelihood -1.304798
[ Info: iteration 21, average log likelihood -1.304601
[ Info: iteration 22, average log likelihood -1.304432
[ Info: iteration 23, average log likelihood -1.304271
[ Info: iteration 24, average log likelihood -1.304105
[ Info: iteration 25, average log likelihood -1.303921
[ Info: iteration 26, average log likelihood -1.303712
[ Info: iteration 27, average log likelihood -1.303486
[ Info: iteration 28, average log likelihood -1.303239
[ Info: iteration 29, average log likelihood -1.302957
[ Info: iteration 30, average log likelihood -1.302616
[ Info: iteration 31, average log likelihood -1.302113
[ Info: iteration 32, average log likelihood -1.301299
[ Info: iteration 33, average log likelihood -1.300505
[ Info: iteration 34, average log likelihood -1.299961
[ Info: iteration 35, average log likelihood -1.299525
[ Info: iteration 36, average log likelihood -1.299070
[ Info: iteration 37, average log likelihood -1.298564
[ Info: iteration 38, average log likelihood -1.298051
[ Info: iteration 39, average log likelihood -1.297573
[ Info: iteration 40, average log likelihood -1.297159
[ Info: iteration 41, average log likelihood -1.296833
[ Info: iteration 42, average log likelihood -1.296564
[ Info: iteration 43, average log likelihood -1.296362
[ Info: iteration 44, average log likelihood -1.296231
[ Info: iteration 45, average log likelihood -1.296153
[ Info: iteration 46, average log likelihood -1.296103
[ Info: iteration 47, average log likelihood -1.296066
[ Info: iteration 48, average log likelihood -1.296036
[ Info: iteration 49, average log likelihood -1.296007
[ Info: iteration 50, average log likelihood -1.295978
┌ Info: EM with 100000 data points 50 iterations avll -1.295978
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3468897062511187
│     -1.346762257307201
│      ⋮
└     -1.2959782998354556
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.296079
[ Info: iteration 2, average log likelihood -1.295893
[ Info: iteration 3, average log likelihood -1.295063
[ Info: iteration 4, average log likelihood -1.288830
[ Info: iteration 5, average log likelihood -1.272563
[ Info: iteration 6, average log likelihood -1.257287
[ Info: iteration 7, average log likelihood -1.249923
[ Info: iteration 8, average log likelihood -1.246286
[ Info: iteration 9, average log likelihood -1.244150
[ Info: iteration 10, average log likelihood -1.242609
[ Info: iteration 11, average log likelihood -1.241325
[ Info: iteration 12, average log likelihood -1.240328
[ Info: iteration 13, average log likelihood -1.239654
[ Info: iteration 14, average log likelihood -1.239224
[ Info: iteration 15, average log likelihood -1.238937
[ Info: iteration 16, average log likelihood -1.238732
[ Info: iteration 17, average log likelihood -1.238584
[ Info: iteration 18, average log likelihood -1.238468
[ Info: iteration 19, average log likelihood -1.238360
[ Info: iteration 20, average log likelihood -1.238242
[ Info: iteration 21, average log likelihood -1.238104
[ Info: iteration 22, average log likelihood -1.237944
[ Info: iteration 23, average log likelihood -1.237771
[ Info: iteration 24, average log likelihood -1.237604
[ Info: iteration 25, average log likelihood -1.237470
[ Info: iteration 26, average log likelihood -1.237382
[ Info: iteration 27, average log likelihood -1.237328
[ Info: iteration 28, average log likelihood -1.237297
[ Info: iteration 29, average log likelihood -1.237279
[ Info: iteration 30, average log likelihood -1.237267
[ Info: iteration 31, average log likelihood -1.237259
[ Info: iteration 32, average log likelihood -1.237252
[ Info: iteration 33, average log likelihood -1.237246
[ Info: iteration 34, average log likelihood -1.237240
[ Info: iteration 35, average log likelihood -1.237235
[ Info: iteration 36, average log likelihood -1.237230
[ Info: iteration 37, average log likelihood -1.237224
[ Info: iteration 38, average log likelihood -1.237218
[ Info: iteration 39, average log likelihood -1.237212
[ Info: iteration 40, average log likelihood -1.237205
[ Info: iteration 41, average log likelihood -1.237198
[ Info: iteration 42, average log likelihood -1.237190
[ Info: iteration 43, average log likelihood -1.237182
[ Info: iteration 44, average log likelihood -1.237173
[ Info: iteration 45, average log likelihood -1.237164
[ Info: iteration 46, average log likelihood -1.237156
[ Info: iteration 47, average log likelihood -1.237149
[ Info: iteration 48, average log likelihood -1.237143
[ Info: iteration 49, average log likelihood -1.237138
[ Info: iteration 50, average log likelihood -1.237133
┌ Info: EM with 100000 data points 50 iterations avll -1.237133
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2960787434269216
│     -1.295892940309437
│      ⋮
└     -1.2371334312068252
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.237302
[ Info: iteration 2, average log likelihood -1.237075
[ Info: iteration 3, average log likelihood -1.235737
[ Info: iteration 4, average log likelihood -1.224481
[ Info: iteration 5, average log likelihood -1.196352
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.166376
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.156581
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.163687
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.155775
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.143866
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.145452
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.174833
[ Info: iteration 13, average log likelihood -1.159026
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.137665
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      3
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.135270
[ Info: iteration 16, average log likelihood -1.179593
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.154502
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.149016
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.139219
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.157471
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.163425
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.151754
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.137476
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.133627
[ Info: iteration 25, average log likelihood -1.174422
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.152087
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.153511
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.141997
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.140862
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.170334
[ Info: iteration 31, average log likelihood -1.155909
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.135749
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.149128
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.154840
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.156039
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.155996
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.145010
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.141476
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.149558
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.159483
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.142591
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.148499
[ Info: iteration 43, average log likelihood -1.164046
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.140889
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.157936
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.147097
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.143071
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.159313
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.149619
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.147480
┌ Info: EM with 100000 data points 50 iterations avll -1.147480
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2373024335421756
│     -1.2370752460707206
│      ⋮
└     -1.1474803598114982
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.145840
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.134479
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│     13
│     14
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.123795
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.114189
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.092398
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.074466
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.047410
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│     15
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.076588
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.037136
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.068892
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.048331
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.075201
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.039095
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.057243
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.030280
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.069547
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.051951
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.060224
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.041545
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.059067
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.031884
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.062650
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.036694
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     18
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.059960
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.048111
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.059461
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.034904
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.061534
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.057490
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     18
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.046726
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.029138
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      6
│     15
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.068528
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.044374
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.042732
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.039116
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.063230
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.041864
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.044524
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.039857
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.065140
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.048874
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     18
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.040527
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.052133
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│     15
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.066737
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.025993
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.054667
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.054261
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│     15
│     18
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.067035
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.022053
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.052991
┌ Info: EM with 100000 data points 50 iterations avll -1.052991
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1458399668712727
│     -1.134478795485699
│      ⋮
└     -1.052991210781201
32×26 Array{Float64,2}:
  0.139028      0.0854485   -0.0629074   0.154862    -0.0672246   -0.171043      0.211029     0.132574     -0.158802     0.0769722    0.00505907  -0.068431    -0.457692      0.0873809┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3826578075823004
│     -1.382733620587501
│     -1.3826270687885636
│     -1.3816568155983528
│      ⋮
│     -1.0670350818040968
│     -1.0220530517420776
└     -1.052991210781201
    0.0282501  -0.231152    -0.00358422    0.0129211   -0.238061    -0.173406     0.0138007   -0.0502652   -0.461935     0.111862   -0.110279     0.0361707
  0.193265      0.0356399   -0.0621544   0.15541     -0.0659481   -0.171499      0.127482     0.0828657    -0.264908     0.18011      0.10279     -0.0229746    0.539778      0.173767    -0.0866413  -0.209579     0.0711362    -0.0241957    0.122759    -0.181774    -0.0193985   -0.0155896    0.540811     0.0992919  -0.0429882    0.143673
 -0.138585     -0.184775    -0.136888   -0.00301455   0.132914     0.0247741    -0.0543791    0.0392021    -0.0208636    0.0713699   -0.094466    -0.0905224    0.0128335    -0.00915503   0.0276911   0.167632     0.0200387    -0.0445501   -0.411398    -0.00944654   0.0866868   -0.0190384    0.0481004   -0.069977    0.208583    -0.051215
  0.0895393    -0.223186    -0.189069   -0.0224563    0.0228375    0.0596292     0.0185992   -0.000109061   0.0784326    0.102065    -0.0982848   -0.0154773    0.267027     -0.0882699    0.0570911   0.171331     0.0352497    -0.12492      0.439089    -0.013712     0.111468    -0.018329     0.0432602    0.0898156  -0.0153366    0.00792965
 -0.0855967     0.00568227  -0.0979324   0.0922017   -0.0759995    0.000706884  -0.0724857   -0.210429      0.0550234    0.238235     0.0622823    0.182075    -0.0846258     0.0189669    0.121669    0.11953     -0.178084      0.0522705    0.00644631   0.111936     0.179759    -0.0148177    0.0797128    0.157365   -0.0864992   -0.0863324
 -0.0476449    -0.0767055   -0.0705217  -0.0855915   -0.0435894   -0.0409359     0.0386797   -0.151548     -0.0289667    0.0051679   -0.0593039    0.0081048    0.0506654    -0.0392418    0.0732936  -0.163106    -0.000729565  -0.0595371   -0.0128627    0.0909555   -0.210606    -0.0204019   -0.0901134   -0.188178   -0.134758    -0.0715925
 -0.0897307    -0.00381858  -0.178799   -0.162697     0.0931877    0.0746792    -0.159052     0.0321957     0.0551325    0.0641585   -0.21012      0.111045    -0.0489299    -0.0809529    0.0537363  -0.0025004    0.0343736     0.0208549   -0.160356    -0.226975    -0.0715124   -0.0837459    0.0546021    0.0121932  -0.118854    -0.0688146
 -0.123404     -0.00369988   0.0913785   0.0740135   -0.0413191    0.14059       0.0726872    0.11247       0.0813336   -0.0262597   -0.0216599   -0.0663441   -0.0648101    -0.079724     0.055109   -0.00457713  -0.0750509    -0.144843     0.0257797    0.215699    -0.269634    -0.0151463    0.180849    -0.130747    0.00709626  -0.0702628
  0.0361483     0.0428478   -0.14486    -0.0278983   -0.00257581  -0.0167841     0.120565    -0.025882     -0.0181431    0.0521716   -0.103408    -0.0247955    0.0245979     0.0722756   -0.0223905  -0.00197079   0.118008      0.046992    -0.0529793    0.00275903  -0.0896963    0.0509021    0.0125019   -0.0262401   0.0136918   -0.0397926
  0.154127      0.121677     0.0440602   0.0857988   -0.0204473    0.112467     -0.165371    -0.162654      0.108483    -0.0909606   -0.0591445   -0.133286    -0.0114459    -0.0841027   -0.176799   -0.0813391   -0.0109319    -0.00542266  -0.0159942   -0.0236903   -0.200896     0.0545555   -0.0444126    0.0746087   0.125548     0.146851
 -0.0262928    -0.00832787   0.101572    0.0537468   -0.0126156   -0.0432471    -0.0200136    0.0151684     0.0988821   -0.0115476   -0.0774974   -0.00810888   0.0233623     0.046409    -0.0194571  -0.105656     0.00631203   -0.158595     0.0125622   -0.0719526   -0.028135     0.128674     0.108092    -0.193533   -6.56629e-5  -0.00164096
 -0.123254     -0.0499117   -0.0682592  -0.0564935    0.138305     0.0395502    -0.0226333   -0.193479     -0.127166     0.124052    -0.0631314   -0.0130734    0.00181068    0.0106535   -0.134374   -0.180257     0.0400179     0.00648581  -0.0628519    0.00881533   0.115825     0.0206303    0.00523611  -0.0595065   0.0558299   -0.104382
  0.0176165    -0.11103      0.06283     0.172426    -0.091937    -0.0348373    -0.00819855   0.107139     -0.0925214   -0.0175688    0.0197751    0.189119    -0.119161      0.0424918   -0.0247254  -0.0963308   -0.0996501    -0.247053    -0.0407717   -0.161611     0.0930093   -0.0610499   -0.548378    -0.0924934  -0.0288275   -0.0711659
  0.0591572    -0.0717953    0.0622494   0.17409     -0.0370578   -0.0487122    -0.00681088   0.0337943    -0.120912    -0.00463506   0.0205147    0.147377     0.0401469     0.169391    -0.116435   -0.0960216   -0.101075     -0.257849    -0.0526105   -0.0901659    0.0868355   -0.0363981    0.509895    -0.0870914  -0.0266058   -0.157782
 -0.102491      0.0659985   -0.0694246  -0.0347079   -0.0174911   -0.00974056    0.072285     0.107492     -0.0941369   -0.0260409    0.0280323   -0.078384     0.0338451     0.0878274   -0.132047    0.0485114   -0.0592942     0.0465698   -0.0422162    0.0675534   -0.0748384   -0.0235627   -0.0994792   -0.136512    0.050305    -0.0901351
 -0.085741      0.0261753   -0.0795567  -0.0769261    0.0583473   -0.00199579   -0.0305872    0.15414       0.103117    -0.00782289   0.108297    -0.164546     0.127239      0.0113243    0.0827548   0.00575111  -0.19187       0.0162412    0.0198674    0.172899     0.0766056    0.14005      0.00853013  -0.0519608   0.207218     0.162661
 -0.0212451     0.0408018   -0.125526    0.00653964  -0.0118301    0.0830154    -0.1632      -0.200822     -0.087615     0.0464954    0.172159     0.0727479   -0.000874553   0.11368      0.0831093  -0.231738    -0.083631      0.0405915   -0.0561721   -0.178546     0.007697    -0.0522658   -0.0277066    0.0128249  -0.0588887    0.105915
  0.103509      0.0123519   -0.0463245   0.0827941    0.0373312   -0.0770545    -0.0936295    0.193205      0.139281     0.088875    -0.0398685    0.144076    -0.0726311     0.0281634    0.0571022   0.0185654    0.0834617     0.0808778   -0.185834     0.079826     0.0127018   -0.0203191    0.0316663   -0.0802473   0.171737    -0.0619775
 -0.177605      0.067897    -0.138612    0.048065    -0.0126025   -0.130894      0.0382694    0.0680572    -0.133215    -0.0994122    0.0857649    0.0802665    0.0101032    -0.167999     0.0678772  -0.0785478   -0.0368654     0.0492274    0.05591      0.0591393    0.0667189    0.101111    -0.0362939   -0.0761461   0.0762152    0.0197831
 -0.000296766   0.0858459   -0.168383    0.115265     0.00877282   0.0206145    -0.0364031    0.040556      0.137248     0.0764237   -0.12484      0.0319021   -0.0294507    -0.077789    -0.0610977  -0.180273    -0.135575     -0.0414151   -0.069479     0.13494      0.124233     0.0119798    0.120742     0.102095    0.226731     0.0264686
 -0.324571     -0.100051    -0.106899   -0.134514    -0.134816    -0.103602      0.0113721   -0.0269694    -0.0180616    0.0714704    0.0940525   -0.0077484    0.291        -0.0508745   -0.123677    0.0513064    0.00869299   -0.30766     -0.0201107    0.11937      0.0309965   -0.101767    -0.065051    -0.209576   -0.0976167    0.13765
  0.37006       0.0273207   -0.119298   -0.133923    -0.108047     0.0581458     0.0922972   -0.0172422    -0.0886652    0.0776781    0.01641     -0.0232842    0.175114     -0.066024    -0.104658    0.0465841    0.0283934    -0.127608    -0.0204666   -0.060718     0.0253544   -0.111941    -0.0638651   -0.178648   -0.120667     0.25515
 -0.0827053    -0.00181742  -0.257622    0.186821     0.292358    -0.134913      0.291371    -0.0598804     0.00582646   0.0505081    0.0691722    0.0855926    0.158358     -0.0258756    0.0521941  -0.0289671   -0.146198      0.0352635   -0.102041    -0.0733475   -0.152306    -0.0631829    0.047816    -0.176874   -0.0283609   -0.0304619
  0.136851      0.018801     0.62527    -0.104583    -0.157028    -0.0551686     0.0326901   -0.125338     -0.177181     0.0472242    0.0859412    0.120712     0.0215732     0.0627065    0.0995154  -0.0421036   -0.185493      0.0208447   -0.0637785   -0.0619896   -0.00461537  -0.0440284    0.0331462   -0.161873   -0.0770996    0.0665678
 -0.169943     -0.0708805    0.0501542  -0.255542    -0.179571     0.214026      0.0377043   -0.0123407    -0.107211    -0.680386     0.151746     0.310614    -0.0297404     0.0859746    0.195704    0.233029    -0.0246881    -0.0089203    0.0784841    0.119648     0.0555032    0.084053     0.0911789    0.0710402  -0.206457    -0.23073
 -0.175051     -0.05934      0.0849432  -0.118795    -0.181092    -0.0879109     0.0743477   -0.0369484     0.112507     0.260022    -0.252553    -0.0684313   -0.0176173     0.0610387    0.133526    0.146504     0.0050088     0.0256665   -0.249084     0.0721758   -0.0797789   -0.0437112    0.0622653    0.126859    0.12415     -0.0502582
  0.0135347    -0.00645996   0.0429549  -0.107143    -0.022712     0.066086      0.0352871   -0.0483046    -0.00750281  -0.0153174    0.0150631   -0.0237252   -0.105029      0.0475833    0.0566002  -0.144472     0.026182      0.0492695   -0.0343053    0.0118242   -0.078809     0.0130297    0.055023    -0.0915699  -0.0681194    0.227726
  0.159613     -0.0037244   -0.0179826  -0.00885963   0.124173    -0.150265      0.0561329   -0.069832     -0.121494     0.0122606    0.279292    -0.0651173   -0.146125      0.0134274    0.0840622  -0.116984     0.0103994    -0.0316253   -0.23004     -0.138518     0.0938921    0.0778361    0.200847    -0.157111   -0.0797403    0.00186489
 -0.0303799    -0.0262192   -0.024006   -0.0123556    0.00872531  -0.00155661    0.13855      0.153243      0.113115    -0.0936972   -0.126378     0.126513     0.0201713    -0.00543517   0.0751273  -0.0588488   -0.0796094     0.0539886   -0.00107356   0.0695615    0.00802908  -0.0350357    0.0965291   -0.0293508   0.0413909    0.0582319
  0.00866407    0.117384     0.0951585   0.00899227  -0.0244779    0.111798      0.060943    -0.0573724    -0.0827764   -0.161974     0.0158053    0.168607     0.0868561    -0.0242303   -0.0488654  -0.0363451    0.0336943     0.043307     0.0423846    0.0984096    0.0425775    0.00233387   0.0293169   -0.113476    0.00370968   0.0114813
 -0.00778886   -0.0729787   -0.0501141  -0.0598447   -0.131478    -0.140294      0.0832923    0.0549167    -0.0343997    0.113408    -0.0347148   -0.143327    -0.0978788    -0.0198953   -0.0358823   0.0678528   -0.102617     -0.0355645    0.0951583   -0.0441189   -0.0784151    0.0500368   -0.00818457   0.128681   -0.0512412   -0.110218
  0.15851      -0.0836397   -0.111185    0.0756301    0.0673156   -0.0144588    -0.0690957   -0.0554859     0.0459765    0.0859276   -0.0769555   -0.00592573  -0.00861808   -0.131034     0.107584    0.0394181    0.1792       -0.0125287   -0.0757282   -0.0770874    0.0811053    0.0909486   -0.0245391    0.152594    0.113184    -0.168193[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.040542
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.026072
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.020269
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.033111
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.031757
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.013681
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.040348
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.024839
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.020122
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.033061
┌ Info: EM with 100000 data points 10 iterations avll -1.033061
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind diag, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.586827e+05
      1       6.574773e+05      -2.012054e+05 |       32
      2       6.254007e+05      -3.207661e+04 |       32
      3       6.060617e+05      -1.933897e+04 |       32
      4       5.943376e+05      -1.172415e+04 |       32
      5       5.876646e+05      -6.672964e+03 |       32
      6       5.829128e+05      -4.751796e+03 |       32
      7       5.793455e+05      -3.567279e+03 |       32
      8       5.769054e+05      -2.440141e+03 |       32
      9       5.751649e+05      -1.740456e+03 |       32
     10       5.736949e+05      -1.470023e+03 |       32
     11       5.726223e+05      -1.072651e+03 |       32
     12       5.719990e+05      -6.233049e+02 |       32
     13       5.716547e+05      -3.442879e+02 |       32
     14       5.714547e+05      -1.999677e+02 |       32
     15       5.713243e+05      -1.303712e+02 |       32
     16       5.712467e+05      -7.764252e+01 |       32
     17       5.712079e+05      -3.875575e+01 |       32
     18       5.711876e+05      -2.030653e+01 |       32
     19       5.711756e+05      -1.199980e+01 |       28
     20       5.711687e+05      -6.902677e+00 |       29
     21       5.711643e+05      -4.403028e+00 |       25
     22       5.711601e+05      -4.256144e+00 |       27
     23       5.711569e+05      -3.129254e+00 |       27
     24       5.711549e+05      -1.999205e+00 |       19
     25       5.711540e+05      -9.589043e-01 |       11
     26       5.711537e+05      -2.422469e-01 |        6
     27       5.711536e+05      -1.181873e-01 |        6
     28       5.711536e+05      -7.448014e-02 |        2
     29       5.711535e+05      -4.246669e-02 |        2
     30       5.711535e+05      -3.504532e-02 |        0
     31       5.711535e+05       0.000000e+00 |        0
K-means converged with 31 iterations (objv = 571153.4725154911)
┌ Info: K-means with 32000 data points using 31 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.293336
[ Info: iteration 2, average log likelihood -1.260058
[ Info: iteration 3, average log likelihood -1.223238
[ Info: iteration 4, average log likelihood -1.177420
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.126262
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.087205
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     17
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.070447
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│     13
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.061829
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.093134
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.067959
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     21
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.070526
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     13
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.075856
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      4
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.055921
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      6
│      8
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.034677
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.121292
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     13
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.066567
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      4
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.073302
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      6
│     10
│     21
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.033451
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.079324
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      9
│     13
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.041286
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     20
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.051922
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│      6
│     10
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.042402
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.078297
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     13
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.026224
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│      9
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.065538
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      6
│     10
│     21
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.060713
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.088342
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      5
│     13
│     16
│     17
│     18
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.028539
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      8
│      9
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.079966
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     10
│     21
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.064997
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.082205
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      4
│     18
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.029997
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      6
│      8
│     10
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.027067
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.120311
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.079981
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     18
│     21
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.022133
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│      5
│      6
│     10
│     13
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.060407
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.090108
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      9
│     12
│     17
│     21
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.033203
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     18
│     24
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.065244
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     10
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.073937
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      4
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.075358
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.047359
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      5
│     18
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.031539
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      9
│     10
│     17
│     20
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.066634
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.097804
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     13
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.053189
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│     18
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.042418
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      6
│     10
│     20
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.055532
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      9
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
32×26 Array{Float64,2}[ Info: iteration 50, average log likelihood -1.092424
┌ Info: EM with 100000 data points 50 iterations avll -1.092424
└ 59.0 data points per parameter
:
  0.113591    -0.0231016    -0.0892844   0.163108     0.0744749  -0.056115    -0.042504     -0.124466     0.0852307    0.112914    -0.175945    -0.0386435    0.0490138    0.0186855    0.0424178    -0.0413605    0.327624     -0.141151    -0.143028     0.0153078    0.190597     0.153397     0.0545448    0.226173    -0.0489566   -0.244194
 -0.0467383   -0.0447224    -0.11135    -0.0649572   -0.0690932  -0.128658     0.253246      0.164145    -0.0356705   -0.0263219   -0.111445     0.165914    -0.0241857   -0.106078     0.0039151    -0.0132073    0.000251482   0.16151      0.113754     0.0244456    0.00304728   0.0261509    0.0704955   -0.0312123   -0.041215     0.0248548
 -0.170191    -0.0662466     0.116614   -0.147189    -0.166637   -0.0464189    0.0898863    -0.0477232    0.113513     0.0168559   -0.169062     0.0206346   -0.018667     0.0925069    0.159204      0.265033    -0.0119594     0.00263119  -0.221602     0.181955    -0.0798737   -0.0127354    0.0772803    0.184295     0.0787107   -0.17867
 -0.0854755   -0.043178     -0.159992   -0.157516     0.0694769   0.0505276   -0.12331       0.00597343   0.0712335    0.0768166   -0.180168     0.166352    -0.100374    -0.104819     0.0861514     0.0108461    0.0116076     0.0394182   -0.26512     -0.190097    -0.0471917   -0.0731422    0.0715675    0.106133    -0.226909    -0.0597387
  0.114772    -0.105389     -0.0874534  -0.00528684   0.0146438   0.00124625  -0.0521707    -0.022654     0.014484     0.0790646   -0.00893577   0.0199259   -0.0447669   -0.208828     0.161239      0.107474     0.0728536     0.0656771   -0.0514816   -0.143709     0.0348926    0.0421109   -0.0569349    0.107297     0.236067    -0.116776
  0.0177746   -0.0778417    -0.113276   -0.0708109   -0.0818682  -0.0130308    0.0502205    -0.0336399   -0.0510079    0.0731808    0.0291471   -0.0361544    0.416697    -0.0764639   -0.113403      0.052598     0.00794083   -0.232359    -0.0150746    0.0272675    0.0535454   -0.0727844    0.00581064  -0.207025    -0.0976242    0.232891
 -0.177367     0.0679737    -0.137822    0.0480948   -0.0124767  -0.130715     0.0381984     0.0676119   -0.132058    -0.0990661    0.0861003    0.0801931    0.0101375   -0.16782      0.0679057    -0.0788899   -0.0370481     0.0491071    0.0554759    0.0578292    0.066873     0.101165    -0.036194    -0.0760611    0.0762665    0.01916
  0.104312     0.00702805   -0.0459048   0.0868815    0.0513158  -0.0711863   -0.0949986     0.202143     0.177079     0.0993418   -0.024875     0.144159    -0.069209     0.0256935    0.0535294     0.0473579    0.0972625     0.0875509   -0.179347     0.0663615    0.0250514   -0.0179857    0.0253209   -0.0809726    0.173089    -0.0773849
  0.157235     0.12041       0.0498645   0.085704    -0.0208206   0.111051    -0.165387     -0.162317     0.110666    -0.0917443   -0.0553835   -0.128856    -0.0163361   -0.0868499   -0.178237     -0.083267    -0.014272     -0.00358118  -0.0205225   -0.0246799   -0.199602     0.0567927   -0.0449515    0.0768856    0.125618     0.1471
  0.070308    -0.0997332     0.0352609   0.120883    -0.0294021  -0.0338992    0.000269014   0.0722125   -0.124269     0.0013817    0.0113266    0.137469    -0.162679     0.142472    -0.081342     -0.0403523   -0.0742064    -0.275375    -0.0461611   -0.119541     0.0728697   -0.0287317    0.18419     -0.0974681   -0.0224263   -0.214792
  0.00155298   0.00666992    0.072002    0.0498569    0.102198    0.13694      0.00296133    0.129338     0.281876    -0.167617    -0.142336     0.0785468    0.0717245    0.10758      0.163923     -0.109933    -0.17194      -0.071605    -0.13073      0.120014     0.0283813   -0.101301     0.118732    -0.0198718    0.137444     0.0881014
 -0.123418    -0.00968432    0.0799221   0.0834811   -0.0332148   0.133531     0.0474125     0.115565     0.101749    -0.0436244   -0.0292069   -0.059378    -0.0646854   -0.0778707    0.0570986     0.00397131  -0.0795385    -0.145421     0.0191135    0.192221    -0.243188    -0.00515515   0.177245    -0.143497     0.0392343   -0.0708256
 -0.0765984    0.000718999  -0.15971    -0.223064     0.0996353   0.0601122   -0.180424      0.0436088    0.0367009    0.0671639   -0.268122     0.0970731   -0.0627552   -0.0806573    0.0389313    -0.0281645    0.0780739     0.0108824   -0.192546    -0.209072    -0.0664201   -0.0663276    0.0593035    0.00250986  -0.105193    -0.0760376
  0.0311848    0.00757195    0.195794    0.0306527    0.0526942  -0.0910067    0.15066      -0.0935855   -0.0923089    0.0495731    0.0768556    0.101698     0.0883884    0.020612     0.0772359    -0.0353156   -0.165962      0.0256735   -0.0813369   -0.0650811   -0.0772666   -0.053802     0.0386708   -0.169145    -0.0550911    0.0182583
 -0.00221567   0.0628739    -0.171722    0.00564734   0.0829814  -0.0763026    0.114799     -0.00583292  -0.0493337    0.0727098   -0.0349247    0.0148651    0.0161133    0.0824319   -0.0737456    -0.0127143    0.0806268     0.0846555    0.0623686   -0.0121477   -0.102579     0.0774138    0.0423915   -0.0341203   -0.0255123    0.0487982
 -0.0244511   -0.0241322     0.077694    0.0233894   -0.0503577  -0.0424314   -0.0335842     0.0824677    0.00740274  -0.0243029   -0.180928     0.048644     0.00402336   0.0419685    0.0346645    -0.0739948    0.0433243    -0.010546    -0.0886443   -0.00133248  -0.0702332    0.104162     0.0540798   -0.10604      0.0527921    0.0196605
 -0.0506783   -0.0270998     0.0480414  -0.140715    -0.0482772   0.0955207    0.0283279    -0.0120581    0.0230775   -0.0225424   -0.00401854  -0.00176409  -0.0848496    0.0465235    0.0552167    -0.127276     0.0228361     0.0289562   -0.0193795    0.0516317   -0.0959063    0.011572     0.0754734   -0.104516    -0.061938     0.223425
  0.161553    -0.164448      0.016842    0.0345292   -0.0724432  -0.215671     0.00318044    0.0643706    0.00584304   0.216234    -0.0687455   -0.133314    -0.0920779   -0.0496359    0.000543445   0.0239951   -0.228404      0.0432017   -0.0368485    0.0164411   -0.185923     0.0129753    0.0783904    0.0859032   -0.133755    -0.175775
  0.0909963    0.00526475   -0.118296   -0.0495516   -0.0839695   0.0283817    0.127159     -0.0498048    0.0154898    0.0406575   -0.18904     -0.0816385    0.036277     0.0696628    0.0325491     0.0187613    0.153617      0.00013977  -0.199028    -0.00826332  -0.0750579    0.0165516   -0.0147766   -0.0125834    0.0470028   -0.168605
 -0.0446555   -0.229268     -0.158735   -0.0303998    0.0854412   0.0253949    0.0318297     0.00612482   0.0419314    0.0961526   -0.0777213   -0.179363     0.17042     -0.0492478    0.074021      0.172129     0.0227824    -0.063058     0.123737    -0.0356149    0.0922183    0.00713342   0.0538824    0.0706772    0.237541    -0.00921523
 -0.00564654   0.690735      0.219749    0.100658    -0.0901233   0.082082     0.115633     -0.138753    -0.07721     -0.132732    -0.104745     0.160647     0.0796788    0.00439533   0.0898972    -0.0122494    0.138425      0.0444931    0.204695     0.0450752   -0.0169343    0.177418    -0.0237812   -0.280211    -0.00288001  -0.00545484
 -0.0997766    0.0454678    -0.0670332  -0.0442749    0.0146354  -0.0068238    0.0198662     0.12747      0.00233654  -0.0150463    0.0664881   -0.104874     0.0756104    0.0543755   -0.0288339     0.0215486   -0.121362      0.012255    -0.0129211    0.111804     0.0105306    0.0507628   -0.0394931   -0.0944112    0.117928     0.0238801
 -0.0797829    0.00342919   -0.0422222   0.0828618   -0.0618092  -0.00867168  -0.0664363    -0.192721     0.0819512    0.197843     0.0353293    0.14057     -0.0752919    0.0256397    0.0957427     0.0741382   -0.138818     -0.00702381   0.00731224   0.0812186    0.131824     0.0218614    0.0898098    0.0775076   -0.0715447   -0.0639374
  0.158729     0.0383216    -0.0602075   0.147436    -0.0647097  -0.150378     0.131375      0.10937     -0.198902     0.112064     0.0451245   -0.0337306    0.0201996    0.128446    -0.0260436    -0.195923     0.025524     -0.0214794   -0.0440465   -0.17174      0.00218965  -0.040461     0.0512329    0.0952742   -0.0756075    0.0689577
 -0.0194553    0.0527804    -0.125805    0.00472552  -0.0139771   0.0807331   -0.160829     -0.195142    -0.0873803    0.0484069    0.171393     0.0726081   -0.00092648   0.11444      0.0813078    -0.23075     -0.0793434     0.0432335   -0.0558367   -0.175326     0.00675991  -0.0530631   -0.0267357    0.0112115   -0.0566346    0.101577
 -0.0273682   -0.045133     -0.0371679  -0.0376984   -0.0212507   0.133194     0.019966      0.0651402   -0.104374    -0.237994     0.139996     0.232738     0.13235     -0.0544286   -0.201445     -0.0379039   -0.0893661     0.0290827    0.0184522    0.184983     0.0975127   -0.169059    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
 0.103089    -0.0373025   -0.0061413    0.0215017
 -0.0119202    0.0822568    -0.161111    0.10331     -0.0026716   0.0155312   -0.0212772     0.0417225    0.137527     0.0704509   -0.129419     0.0374575   -0.02842     -0.0764784   -0.0577436    -0.176361    -0.127243     -0.0437698   -0.0672995    0.120598     0.115301     0.0130195    0.1196       0.0964096    0.219405     0.0305521
 -0.0518046   -0.0737258    -0.0738722  -0.08485     -0.043011   -0.0414924    0.0311144    -0.15929     -0.0322796    0.014659    -0.0696665    0.00696062   0.050317    -0.0359763    0.0760819    -0.159736     0.00199043   -0.0644135   -0.00790502   0.0788697   -0.214776    -0.0212757   -0.0940147   -0.193137    -0.141253    -0.0875013
 -0.06853     -0.0560917    -0.0695909  -0.102419    -0.146227   -0.110712     0.101615      0.0362589   -0.0406084    0.0696811   -0.0175614   -0.131572    -0.0887088   -0.00215745  -0.0415274     0.0782866   -0.0310886    -0.0664001    0.128577    -0.0594857   -0.0363517    0.0658766   -0.0432611    0.139569    -0.0211173   -0.0776015
  0.157205    -0.30027       0.0127787  -0.0271062    0.109633   -0.0992512    0.0618712    -0.105059    -0.127115    -0.00645625   0.184636    -0.0808304   -0.140526     0.0398081    0.0913674    -0.108018     0.0453454     0.00658908  -0.2643      -0.156613     0.0553123    0.07463      0.104089    -0.184199    -0.0597541    0.034733
 -0.156314    -0.00778591   -0.0891102  -0.201961     0.129739    0.153012    -0.0770811    -0.174505    -0.00505265   0.149266    -0.0219228   -0.0114676    0.0205326    0.00624486  -0.09164      -0.0809792    0.00324955   -0.0612108   -0.0813729    0.0423489    0.2067       0.0763821    0.0503886   -0.181957     0.146909    -0.186517
 -0.0868125   -0.0925236    -0.0414975   0.0918965    0.141054   -0.0794861    0.0328641    -0.206766    -0.244442     0.0972882   -0.0932937   -0.0145283   -0.0174416    0.0119312   -0.176343     -0.275883     0.0775149     0.0704967   -0.043669    -0.0278892    0.0165978   -0.0293296   -0.0371988    0.0653893   -0.0370162   -0.00307205┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.074266
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      8
│     12
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.999849
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.990076
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      8
│      9
│     12
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.995605
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     12
│     17
│     23
│     24
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.005450
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.975336
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     23
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.033374
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.961704
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      6
│     10
│     12
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.004948
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      8
│     12
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.012687
┌ Info: EM with 100000 data points 10 iterations avll -1.012687
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0870051    0.0438176     0.0194624   -0.170166     0.0786153   -0.148922     0.00306931  -0.0960063    0.143863    -0.0812289   -0.0460352    0.0664079    0.0646669   -0.100094    0.000457326   0.0661302   -0.0523248    -0.0787009    0.0226324    0.00175609  -0.0396006    0.0852371   -0.0157271    -0.036385     0.149247     0.0724756
  0.037832     0.150527     -0.00348366  -0.123404     0.0187418    0.156883     0.0280655   -0.0293277   -0.0289008   -0.0480533   -0.229159    -0.138954     0.050039     0.044744   -0.00709021    0.165335    -0.0512386    -0.0852086   -0.106232     0.00422194   0.0405425   -0.0639683    0.0386264     0.105051     0.095186     0.0162122
 -0.0881927   -0.0472985    -0.118847    -0.056031    -0.12064     -0.112476     0.0349894    0.0283616    0.032899     0.0190056    0.00498804  -0.105364     0.0694573   -0.206936   -0.0993665     0.177753    -0.0944492     0.0546036    0.0195203    0.0412947   -0.0752674    0.128168     0.243921     -0.0681423    0.151698     0.0353569
  0.012593    -0.0344749    -0.0723279   -0.249327    -0.0556236   -0.102542    -0.16567      0.0799719   -0.0982302   -0.0761735    0.0898201    0.00450337  -0.0522821   -0.0183457   0.128502     -0.0763644    0.0928864    -0.0281104    0.0570928    0.0943046   -0.123401     0.108324     0.1143        0.202333    -0.00149669  -0.0906084
  0.0219145    0.107632      0.179236     0.110299    -0.0346151    0.0176379    0.009359     0.0990469   -0.102309     0.120847     0.0710488    0.0602894   -0.0783906    0.0676145  -0.105617     -0.178212    -0.183363     -0.0921333    0.064157     0.119543    -0.0419342    0.0085141   -0.200081     -0.0419539    0.0213764   -0.0719586
 -0.0143668   -0.0135697    -0.00875826  -0.0563178   -0.0494724   -0.0879068    0.130249    -0.0111561   -0.0585369   -0.164201    -0.116679     0.127691     0.154048     0.154986    0.201954      0.0858638    0.063877      0.0870009    0.048695     0.0678613    0.0675211    0.0386498   -0.0413971     0.099367    -0.0174912   -0.227318
 -0.151693     0.0656935    -0.080933    -0.135406     0.0677991   -0.0954649   -0.127052     0.0198731    0.0290271   -0.16175     -0.101014    -0.0428133   -0.0163579    0.141353    0.213265      0.0981129    0.0596583    -0.180924    -0.130542     0.0164538    0.0562975    0.0938114   -0.0125528     0.05947     -0.0183145    0.00850138
 -0.0635082   -0.0169166     0.0415227    0.0136939    0.16835      0.00276491  -0.0610242   -0.0649131    0.107541     0.105051     0.055977     0.0540567   -0.0386983    0.0946306  -0.0614495    -0.0513389   -0.0212211    -0.0166478    0.0195059    0.179223    -0.0718883   -0.0780195    0.0858399     0.0884814   -0.0110009   -0.102377
 -0.0395943    0.0954382    -0.010302     0.0786886   -0.0933149    0.100311     0.0109032    0.0953153    0.0601083   -0.274642    -0.213673    -0.086506     0.0467889   -0.22185     0.00100799    0.185201    -0.147415      0.0263392    0.112812     0.0152912    0.120557     0.011673     0.0990372     0.125129     0.0835095    0.14147
  0.0350684    0.140246      0.0576597    0.13327      0.0785848   -0.0894067   -0.0947853    0.0241663    0.0328795    0.00810588  -0.0193881   -0.0150561    0.0927794   -0.0699482   0.19968      -0.0416733    0.0171738    -0.0575926   -0.0197838   -0.101539     0.0928166   -0.0170919    0.119717     -0.117442    -0.00281331   0.00482745
 -0.124356    -0.0623012    -0.0456678   -0.0450798    0.073868     0.108318    -0.183694     0.00407866   0.0926543    0.0809506   -0.0547152   -0.0906151   -0.0454734   -0.0659191  -0.147083      0.0262663   -0.0381713    -0.142143     0.15209     -0.265356     0.0662065    0.0691075    0.0489267    -0.048854    -0.125672    -0.0584618
 -0.0255901    0.0264056    -0.060032     0.170673     0.0649618    0.21088      0.0307889   -0.0334573    0.00568833   0.141624     0.0630137    0.151918     0.15285     -0.311808    0.143131     -0.0489401    0.0393349    -0.100009    -0.0458955   -0.05765     -0.130567     0.0060916   -0.0224465     0.134154     0.0662903   -0.0523443
  0.0464007    0.143172     -0.115329    -0.135891     0.234072    -0.00313919   0.124401     0.127748    -0.0364533   -0.0984399    0.047089     0.0314507    0.115346     0.0322748   0.0170071     0.0410723    0.0211379    -0.136073    -0.128448    -0.0415017    0.145657     0.0631921   -0.217895     -0.0342728   -0.00650734  -0.142418
 -0.0303783    0.00743067   -0.165467     0.0250175    0.0214936    0.1011      -0.0482794   -0.0405229   -0.0168528   -0.0427447   -0.121086     0.169078    -0.0638446   -0.164179    0.00556966   -0.00753783   0.00948686    0.0449798    0.192563     0.00244532  -0.120639     0.0550655   -0.0813527    -0.149741     0.119747     0.121063
  0.0529931   -0.201348     -0.0720455    0.0741098   -0.274889     0.00816524   0.0604042   -0.106765     0.113124     0.0216341   -0.0157438    0.196532    -0.0327747    0.0419534  -0.0180195    -0.10895     -0.0924626     0.0287712   -0.041465     0.1341       0.125971    -0.132815    -0.155384     -0.0783367    0.0304062    0.0265271
  0.0664628    0.155671      0.0527677    0.149299     0.064938     0.0607757    0.1455      -0.126363    -0.0267764   -0.19184     -0.00142191  -0.0609189    0.0794101    0.0127885  -0.194535     -0.107221     0.00749819    0.158714    -0.108709    -0.129318     0.0466563    0.200185    -0.000462405   0.0196018   -0.0428909    0.056788
  0.160586    -0.000280104   0.0116623   -0.00588581  -0.175397    -0.19947      0.235501    -0.0999706    0.0508899    0.140276    -0.00336105  -0.0770523   -0.14672      0.0967978   0.0817009     0.0336539    0.0298319    -0.123435     0.00578592  -0.156552    -0.0834485   -0.056912    -0.00834655    0.0156711   -0.0153881   -0.026814
 -0.100136    -0.11544      -0.100614    -0.129865    -0.0800993   -0.0222809   -0.0157392    0.0638086   -0.0793693   -0.0132339    0.156071    -0.0400083    0.0214455    0.0871394   0.0457762     0.186751    -0.136982     -0.00301922   0.0593763   -0.122792    -0.110539    -0.0662389    0.0932243    -0.0443379   -0.160919    -0.0964523
  0.00198464   0.163265     -0.0440738    0.130585     0.0292901   -0.134057    -0.0680589    0.0997942    0.153318     0.0239405    0.171177    -0.15151      0.201997     0.1492      0.0407099     0.0195793    0.072754     -0.0431157   -0.0751201   -0.0907227   -0.0537512   -0.00530802  -0.0123579     0.00313128  -0.225855    -0.105073
 -0.0391958    0.10752       0.125245     0.0436638    0.129428     0.0554058    0.115965     0.192527    -0.016162    -0.0938777   -0.0472711   -0.0588741    0.11104     -0.14069     0.11327      -0.316708    -0.000360231  -0.020543    -0.104638    -0.0740811    0.0413845   -0.0228862    0.0600362     0.0647064   -0.133206    -0.0681385
 -0.0379042   -0.0763328    -0.129785     0.0665646   -0.12419     -0.004961     0.0356383   -0.0207929    0.0238499    0.0707423    0.0356842    0.00501754  -0.0681279    0.0491881  -0.0674757     0.119012    -0.069598     -0.00827746  -0.107005    -0.0588684    0.0248726   -0.0685916    0.0204298     0.120582    -0.0908208   -0.167922
  0.0500217   -0.104885     -0.0715225    0.136817    -0.12129      0.186134    -0.204744    -0.0884629    0.173604    -0.218943     0.0252595   -0.0156147   -0.073116     0.0991142   0.105521      0.00591366  -0.0844376     0.0187107   -0.00459594  -0.0243581   -0.0765219    0.0556499    0.0441252     0.0380355    0.0631551    0.0763928
 -0.00477263  -0.0724615    -0.133362     0.0408037   -0.0198223   -0.0573923    0.160069    -0.0525887   -0.0722866    0.0339872    0.0341427    0.0405203    0.00601832   0.0274954   0.110013      0.0230908    0.0828361     0.0237995    0.0457133   -0.167379    -0.0543508    0.0674276    0.0896734    -0.0861489    0.0315293   -0.0354045
  0.0176078   -0.100527     -0.0506305   -0.0724001   -0.0361034   -0.134852    -0.142981    -0.0169922   -0.0272826   -0.0708575    0.0559677   -0.219439     0.0257467    0.120081    0.214945      0.117784     0.0222966    -0.0467609    0.00653783  -0.139952    -0.00324092   0.0672337   -0.0915013     0.0099146   -0.117428    -0.0599219
 -0.126817    -0.0338356     0.0590342   -0.0367421   -0.119045     0.14912      0.075621     0.117416     0.0699258    0.14129      0.0289975   -0.109317     0.0245934   -0.0648604   0.0430231    -0.0138481   -0.0990575    -0.187965    -0.0718968    0.036798    -0.0208769   -0.0896851   -0.0710909    -0.0126888    0.0135685   -0.0427824
 -0.00718007   0.00231827   -0.111301     0.113304    -0.110423    -0.00790357  -0.0388654    0.0758722   -0.0115566   -0.0518394    0.00350882   0.0962978   -0.125662    -0.0647373   0.103844     -0.133984    -0.17484       0.198519    -0.221741     0.0608501    0.120849    -0.144372    -0.0847301    -0.00728462  -0.0624603   -0.0433177
 -0.00656869  -0.0299667    -0.153822     0.0889227   -0.205513     0.00209339   0.0396069    0.054747    -0.0624948    0.0407614    0.0772988   -0.0577454   -0.0180022    0.125764   -0.00407117   -0.108059     0.130236     -0.0563033   -0.110191    -0.0742485    0.0447172   -0.00428182  -0.152109      0.00396441   0.0264563   -0.074201
 -0.108707    -0.176244      0.128979     0.0168414   -0.0472649    0.0458838    0.0614818    0.0134555    0.0100682   -0.0422293   -0.0360782    0.079927    -0.0507522    0.0165286   0.0463741     0.0570382   -0.0697934    -0.276582     0.0734045    0.0756905    0.0252555    0.097086    -0.129158      0.129653     0.0931052   -0.0939274
  0.122744     0.0651842    -0.015864     0.0823403   -0.0330166    0.0679937    0.133802     0.0447497    0.041829    -0.0707983   -0.0988894    0.0336223    0.124743     0.0216272  -0.0184441    -0.0147627   -0.0919109     0.192866    -0.132174     0.0163449   -0.107951     0.107393     0.140367      0.0752766   -0.0176234    0.0321048
 -0.155182    -0.079037     -0.071387     0.00977087  -0.134405    -0.165406     0.0109069   -0.0402421   -0.116096    -0.0636682   -0.0263958   -0.081696    -0.0918033    0.227756    0.135341     -0.133776     0.149004     -0.0478003   -0.128403    -0.0924064   -0.0904708    0.0198476   -0.0545168    -0.00317144   0.154971     0.131594
 -0.15808     -0.0656076     0.231044     0.0751106   -0.00121149  -0.0532677   -0.0846894    0.137253    -0.0890354   -0.0214551    0.0483311    0.0928584   -0.0474461   -0.100437   -0.0826616    -0.085778    -0.13329       0.0359294    0.0856359   -0.0512972   -0.128333     0.0130403   -0.130276     -0.0134808   -0.0823183   -0.101438
  0.0305241    0.0285958    -0.137254     0.0860221    0.094753     0.0476475    0.165899    -0.280173    -0.0251234    0.0601463    0.226272     0.0587858    0.104683     0.0706806   0.0220646    -0.0272578   -0.108476      0.00919494  -0.0962832    0.153397     0.035591     0.113448    -0.141051      0.0999457   -0.120377    -0.147462kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4247466083316498
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424766
[ Info: iteration 2, average log likelihood -1.424673
[ Info: iteration 3, average log likelihood -1.424600
[ Info: iteration 4, average log likelihood -1.424521
[ Info: iteration 5, average log likelihood -1.424430
[ Info: iteration 6, average log likelihood -1.424329
[ Info: iteration 7, average log likelihood -1.424217
[ Info: iteration 8, average log likelihood -1.424081
[ Info: iteration 9, average log likelihood -1.423882
[ Info: iteration 10, average log likelihood -1.423545
[ Info: iteration 11, average log likelihood -1.422978
[ Info: iteration 12, average log likelihood -1.422139
[ Info: iteration 13, average log likelihood -1.421154
[ Info: iteration 14, average log likelihood -1.420308
[ Info: iteration 15, average log likelihood -1.419784
[ Info: iteration 16, average log likelihood -1.419531
[ Info: iteration 17, average log likelihood -1.419425
[ Info: iteration 18, average log likelihood -1.419382
[ Info: iteration 19, average log likelihood -1.419364
[ Info: iteration 20, average log likelihood -1.419357
[ Info: iteration 21, average log likelihood -1.419354
[ Info: iteration 22, average log likelihood -1.419353
[ Info: iteration 23, average log likelihood -1.419352
[ Info: iteration 24, average log likelihood -1.419351
[ Info: iteration 25, average log likelihood -1.419351
[ Info: iteration 26, average log likelihood -1.419351
[ Info: iteration 27, average log likelihood -1.419351
[ Info: iteration 28, average log likelihood -1.419351
[ Info: iteration 29, average log likelihood -1.419351
[ Info: iteration 30, average log likelihood -1.419350
[ Info: iteration 31, average log likelihood -1.419350
[ Info: iteration 32, average log likelihood -1.419350
[ Info: iteration 33, average log likelihood -1.419350
[ Info: iteration 34, average log likelihood -1.419350
[ Info: iteration 35, average log likelihood -1.419350
[ Info: iteration 36, average log likelihood -1.419350
[ Info: iteration 37, average log likelihood -1.419350
[ Info: iteration 38, average log likelihood -1.419350
[ Info: iteration 39, average log likelihood -1.419350
[ Info: iteration 40, average log likelihood -1.419350
[ Info: iteration 41, average log likelihood -1.419350
[ Info: iteration 42, average log likelihood -1.419350
[ Info: iteration 43, average log likelihood -1.419350
[ Info: iteration 44, average log likelihood -1.419350
[ Info: iteration 45, average log likelihood -1.419350
[ Info: iteration 46, average log likelihood -1.419350
[ Info: iteration 47, average log likelihood -1.419350
[ Info: iteration 48, average log likelihood -1.419350
[ Info: iteration 49, average log likelihood -1.419350
[ Info: iteration 50, average log likelihood -1.419350
┌ Info: EM with 100000 data points 50 iterations avll -1.419350
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.424765654753273
│     -1.424672719526867
│      ⋮
└     -1.4193495470877586
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419368
[ Info: iteration 2, average log likelihood -1.419273
[ Info: iteration 3, average log likelihood -1.419198
[ Info: iteration 4, average log likelihood -1.419116
[ Info: iteration 5, average log likelihood -1.419024
[ Info: iteration 6, average log likelihood -1.418928
[ Info: iteration 7, average log likelihood -1.418839
[ Info: iteration 8, average log likelihood -1.418763
[ Info: iteration 9, average log likelihood -1.418705
[ Info: iteration 10, average log likelihood -1.418662
[ Info: iteration 11, average log likelihood -1.418632
[ Info: iteration 12, average log likelihood -1.418611
[ Info: iteration 13, average log likelihood -1.418597
[ Info: iteration 14, average log likelihood -1.418586
[ Info: iteration 15, average log likelihood -1.418577
[ Info: iteration 16, average log likelihood -1.418571
[ Info: iteration 17, average log likelihood -1.418566
[ Info: iteration 18, average log likelihood -1.418561
[ Info: iteration 19, average log likelihood -1.418557
[ Info: iteration 20, average log likelihood -1.418554
[ Info: iteration 21, average log likelihood -1.418551
[ Info: iteration 22, average log likelihood -1.418548
[ Info: iteration 23, average log likelihood -1.418545
[ Info: iteration 24, average log likelihood -1.418542
[ Info: iteration 25, average log likelihood -1.418539
[ Info: iteration 26, average log likelihood -1.418537
[ Info: iteration 27, average log likelihood -1.418534
[ Info: iteration 28, average log likelihood -1.418531
[ Info: iteration 29, average log likelihood -1.418528
[ Info: iteration 30, average log likelihood -1.418525
[ Info: iteration 31, average log likelihood -1.418522
[ Info: iteration 32, average log likelihood -1.418519
[ Info: iteration 33, average log likelihood -1.418516
[ Info: iteration 34, average log likelihood -1.418513
[ Info: iteration 35, average log likelihood -1.418510
[ Info: iteration 36, average log likelihood -1.418506
[ Info: iteration 37, average log likelihood -1.418503
[ Info: iteration 38, average log likelihood -1.418499
[ Info: iteration 39, average log likelihood -1.418495
[ Info: iteration 40, average log likelihood -1.418491
[ Info: iteration 41, average log likelihood -1.418487
[ Info: iteration 42, average log likelihood -1.418482
[ Info: iteration 43, average log likelihood -1.418478
[ Info: iteration 44, average log likelihood -1.418473
[ Info: iteration 45, average log likelihood -1.418467
[ Info: iteration 46, average log likelihood -1.418462
[ Info: iteration 47, average log likelihood -1.418456
[ Info: iteration 48, average log likelihood -1.418450
[ Info: iteration 49, average log likelihood -1.418444
[ Info: iteration 50, average log likelihood -1.418438
┌ Info: EM with 100000 data points 50 iterations avll -1.418438
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4193683417002982
│     -1.4192728433341426
│      ⋮
└     -1.418438054782495
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418445
[ Info: iteration 2, average log likelihood -1.418376
[ Info: iteration 3, average log likelihood -1.418315
[ Info: iteration 4, average log likelihood -1.418247
[ Info: iteration 5, average log likelihood -1.418166
[ Info: iteration 6, average log likelihood -1.418072
[ Info: iteration 7, average log likelihood -1.417971
[ Info: iteration 8, average log likelihood -1.417866
[ Info: iteration 9, average log likelihood -1.417764
[ Info: iteration 10, average log likelihood -1.417666
[ Info: iteration 11, average log likelihood -1.417574
[ Info: iteration 12, average log likelihood -1.417491
[ Info: iteration 13, average log likelihood -1.417417
[ Info: iteration 14, average log likelihood -1.417354
[ Info: iteration 15, average log likelihood -1.417301
[ Info: iteration 16, average log likelihood -1.417258
[ Info: iteration 17, average log likelihood -1.417222
[ Info: iteration 18, average log likelihood -1.417193
[ Info: iteration 19, average log likelihood -1.417168
[ Info: iteration 20, average log likelihood -1.417146
[ Info: iteration 21, average log likelihood -1.417126
[ Info: iteration 22, average log likelihood -1.417107
[ Info: iteration 23, average log likelihood -1.417088
[ Info: iteration 24, average log likelihood -1.417071
[ Info: iteration 25, average log likelihood -1.417054
[ Info: iteration 26, average log likelihood -1.417037
[ Info: iteration 27, average log likelihood -1.417022
[ Info: iteration 28, average log likelihood -1.417007
[ Info: iteration 29, average log likelihood -1.416993
[ Info: iteration 30, average log likelihood -1.416980
[ Info: iteration 31, average log likelihood -1.416968
[ Info: iteration 32, average log likelihood -1.416957
[ Info: iteration 33, average log likelihood -1.416947
[ Info: iteration 34, average log likelihood -1.416937
[ Info: iteration 35, average log likelihood -1.416929
[ Info: iteration 36, average log likelihood -1.416921
[ Info: iteration 37, average log likelihood -1.416914
[ Info: iteration 38, average log likelihood -1.416908
[ Info: iteration 39, average log likelihood -1.416902
[ Info: iteration 40, average log likelihood -1.416897
[ Info: iteration 41, average log likelihood -1.416892
[ Info: iteration 42, average log likelihood -1.416888
[ Info: iteration 43, average log likelihood -1.416883
[ Info: iteration 44, average log likelihood -1.416880
[ Info: iteration 45, average log likelihood -1.416876
[ Info: iteration 46, average log likelihood -1.416873
[ Info: iteration 47, average log likelihood -1.416870
[ Info: iteration 48, average log likelihood -1.416867
[ Info: iteration 49, average log likelihood -1.416864
[ Info: iteration 50, average log likelihood -1.416862
┌ Info: EM with 100000 data points 50 iterations avll -1.416862
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4184453675167115
│     -1.418375574774212
│      ⋮
└     -1.4168618159413682
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416868
[ Info: iteration 2, average log likelihood -1.416813
[ Info: iteration 3, average log likelihood -1.416763
[ Info: iteration 4, average log likelihood -1.416707
[ Info: iteration 5, average log likelihood -1.416639
[ Info: iteration 6, average log likelihood -1.416557
[ Info: iteration 7, average log likelihood -1.416461
[ Info: iteration 8, average log likelihood -1.416352
[ Info: iteration 9, average log likelihood -1.416237
[ Info: iteration 10, average log likelihood -1.416122
[ Info: iteration 11, average log likelihood -1.416011
[ Info: iteration 12, average log likelihood -1.415909
[ Info: iteration 13, average log likelihood -1.415818
[ Info: iteration 14, average log likelihood -1.415739
[ Info: iteration 15, average log likelihood -1.415671
[ Info: iteration 16, average log likelihood -1.415613
[ Info: iteration 17, average log likelihood -1.415565
[ Info: iteration 18, average log likelihood -1.415525
[ Info: iteration 19, average log likelihood -1.415492
[ Info: iteration 20, average log likelihood -1.415464
[ Info: iteration 21, average log likelihood -1.415440
[ Info: iteration 22, average log likelihood -1.415420
[ Info: iteration 23, average log likelihood -1.415402
[ Info: iteration 24, average log likelihood -1.415387
[ Info: iteration 25, average log likelihood -1.415372
[ Info: iteration 26, average log likelihood -1.415359
[ Info: iteration 27, average log likelihood -1.415346
[ Info: iteration 28, average log likelihood -1.415334
[ Info: iteration 29, average log likelihood -1.415322
[ Info: iteration 30, average log likelihood -1.415311
[ Info: iteration 31, average log likelihood -1.415300
[ Info: iteration 32, average log likelihood -1.415289
[ Info: iteration 33, average log likelihood -1.415278
[ Info: iteration 34, average log likelihood -1.415268
[ Info: iteration 35, average log likelihood -1.415257
[ Info: iteration 36, average log likelihood -1.415247
[ Info: iteration 37, average log likelihood -1.415237
[ Info: iteration 38, average log likelihood -1.415226
[ Info: iteration 39, average log likelihood -1.415216
[ Info: iteration 40, average log likelihood -1.415206
[ Info: iteration 41, average log likelihood -1.415195
[ Info: iteration 42, average log likelihood -1.415185
[ Info: iteration 43, average log likelihood -1.415175
[ Info: iteration 44, average log likelihood -1.415165
[ Info: iteration 45, average log likelihood -1.415155
[ Info: iteration 46, average log likelihood -1.415146
[ Info: iteration 47, average log likelihood -1.415136
[ Info: iteration 48, average log likelihood -1.415127
[ Info: iteration 49, average log likelihood -1.415117
[ Info: iteration 50, average log likelihood -1.415108
┌ Info: EM with 100000 data points 50 iterations avll -1.415108
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4168677990670155
│     -1.4168127489204687
│      ⋮
└     -1.4151082407113464
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415107
[ Info: iteration 2, average log likelihood -1.415043
[ Info: iteration 3, average log likelihood -1.414982
[ Info: iteration 4, average log likelihood -1.414911
[ Info: iteration 5, average log likelihood -1.414823
[ Info: iteration 6, average log likelihood -1.414712
[ Info: iteration 7, average log likelihood -1.414579
[ Info: iteration 8, average log likelihood -1.414426
[ Info: iteration 9, average log likelihood -1.414261
[ Info: iteration 10, average log likelihood -1.414094
[ Info: iteration 11, average log likelihood -1.413932
[ Info: iteration 12, average log likelihood -1.413781
[ Info: iteration 13, average log likelihood -1.413646
[ Info: iteration 14, average log likelihood -1.413526
[ Info: iteration 15, average log likelihood -1.413423
[ Info: iteration 16, average log likelihood -1.413333
[ Info: iteration 17, average log likelihood -1.413256
[ Info: iteration 18, average log likelihood -1.413190
[ Info: iteration 19, average log likelihood -1.413133
[ Info: iteration 20, average log likelihood -1.413083
[ Info: iteration 21, average log likelihood -1.413038
[ Info: iteration 22, average log likelihood -1.412998
[ Info: iteration 23, average log likelihood -1.412962
[ Info: iteration 24, average log likelihood -1.412929
[ Info: iteration 25, average log likelihood -1.412898
[ Info: iteration 26, average log likelihood -1.412869
[ Info: iteration 27, average log likelihood -1.412842
[ Info: iteration 28, average log likelihood -1.412817
[ Info: iteration 29, average log likelihood -1.412793
[ Info: iteration 30, average log likelihood -1.412770
[ Info: iteration 31, average log likelihood -1.412748
[ Info: iteration 32, average log likelihood -1.412728
[ Info: iteration 33, average log likelihood -1.412708
[ Info: iteration 34, average log likelihood -1.412689
[ Info: iteration 35, average log likelihood -1.412670
[ Info: iteration 36, average log likelihood -1.412652
[ Info: iteration 37, average log likelihood -1.412635
[ Info: iteration 38, average log likelihood -1.412618
[ Info: iteration 39, average log likelihood -1.412602
[ Info: iteration 40, average log likelihood -1.412586
[ Info: iteration 41, average log likelihood -1.412570
[ Info: iteration 42, average log likelihood -1.412555
[ Info: iteration 43, average log likelihood -1.412540
[ Info: iteration 44, average log likelihood -1.412525
[ Info: iteration 45, average log likelihood -1.412511
[ Info: iteration 46, average log likelihood -1.412497
[ Info: iteration 47, average log likelihood -1.412482
[ Info: iteration 48, average log likelihood -1.412468
[ Info: iteration 49, average log likelihood -1.412454
[ Info: iteration 50, average log likelihood -1.412441
┌ Info: EM with 100000 data points 50 iterations avll -1.412441
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4151069376362946
│     -1.4150434425342047
│      ⋮
└     -1.4124405040447765
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4247466083316498
│     -1.424765654753273
│     -1.424672719526867
│     -1.4246003884217115
│      ⋮
│     -1.4124683575294166
│     -1.412454404962511
└     -1.4124405040447765
32×26 Array{Float64,2}:
  0.0904811  -0.272036     0.0788595  -0.0952899   -0.0197586  -0.145486   -0.28762      -0.24194      0.175243    -0.0738958  -0.11172     0.129879    -0.1806      -0.0462982   0.170057     -0.0448442  -0.350572    0.03499     0.0978202    0.106846     0.186499   -0.259792    0.00749625   0.23141     0.129358     0.289196
 -0.277462   -0.0447939    0.0650843   0.0811628    0.181669   -0.279726    0.156977      0.166679    -0.0240594    0.659846   -0.381581   -0.0548222   -0.0467149    0.0934601   0.201177     -0.373162   -0.261185    0.133208    0.316983    -0.0529523    0.355305    0.106046   -0.217899    -0.305156    0.140063     0.0349885
 -0.136198    0.189576     0.264302    0.25248     -0.19275    -0.254778    0.108086     -0.398232     0.182734    -0.16853     0.212576   -0.284728    -0.634419     0.0372867   0.833492      0.0228582   0.0128113  -0.457432   -0.0111363    0.291764     0.255296    0.0808613  -0.0202732   -0.262934    0.278155     0.128173
  0.0300838   0.0823528    0.459974   -0.349602     0.112687    0.0802522  -0.138342     -0.729839    -0.111155     0.0533501  -0.309436   -0.325389     0.694352    -0.220868    0.589238      0.0945986   0.0220861  -0.360323    0.352814     0.256061     0.0161008  -0.0338388  -0.0695147    0.0239517  -0.241325     0.032854
 -0.11706     0.107144    -0.213619   -0.0702896   -0.1261     -0.139538    0.249787     -0.182423    -0.311402    -0.2631      0.49984    -0.0549958    0.199475     0.0779463  -0.153407     -0.189181   -0.0155823  -0.187577   -0.304728    -0.109637    -0.209579   -0.181326   -0.180899    -0.214122    0.0563858   -0.0911886
  0.294824    0.391051     0.123525   -0.554934    -0.0958567  -0.408823    0.228519      0.0931676    0.132969    -0.234578    0.264695    0.53781      0.147605     0.156072    0.0217744     0.122035   -0.0852075   0.131309    0.403811    -0.506595    -0.789662    0.0300339  -0.158139    -0.842207    0.267015     0.634382
 -0.639753    0.302597    -0.0405294   0.56142     -0.441648    0.517687    0.503376     -0.114446    -0.368231     0.304237   -0.193976    0.00166979   0.495714    -0.300818   -0.399385     -0.188533    0.0997139  -0.259609   -0.355707     0.0789112   -0.489009    0.201912   -0.13204     -0.968263   -0.128704     0.0970291
  0.0977382   0.119356     0.139977    0.596208     0.227051   -0.291256    0.407865      0.0856137   -0.535815     0.0750365  -0.122221    0.362547     0.0435168    0.592876   -0.327931      0.41376     0.214592   -0.55824    -0.136237     0.477079    -0.618096   -0.38982    -0.45818     -0.658941   -0.126647    -0.0671995
 -0.117944    0.0888178   -0.0172069   0.101688     0.268365   -0.0411792  -0.277512      0.0559819    0.0942021   -0.0152537  -0.0405048  -0.0562314    0.290361    -0.418372   -0.360704     -0.680676    0.0967327   0.119961   -0.604587    -0.235699     0.21492    -0.339899    0.44892      0.294527    0.00345358   0.0946915
 -0.191581    0.268446    -0.14052    -0.179198    -0.320357    0.175771   -0.177826      0.106996     0.471193    -0.240806    0.102073   -0.0389524   -0.00179839  -0.400471   -0.0858448    -0.638589   -0.359286    0.07851     0.336323    -0.308816     0.271197    0.861965    0.350702     0.151148    0.277179    -0.00539527
  0.422926   -0.00234311  -0.307078    0.337393    -0.0574295   0.210655    1.06849      -0.231341     0.257414     0.377966    0.341754   -0.130066    -0.227776     0.112837    0.20972       0.224478   -0.191318    0.464164    0.00873056   0.123134     0.13477     0.0299733  -0.69621      0.0921923   0.0212581    0.20559
  0.269205    0.0662125   -0.101508   -0.279194     0.302275   -0.507809    0.54122      -0.0871632    0.513299     0.357209    0.430314    0.140162    -0.684964     0.0557247  -0.481247     -0.0752811   0.0933543   0.231147   -0.0761789   -0.119605     0.0823132   0.1701      0.468306     0.23397    -0.208971     0.18422
  0.144398    0.0354807   -0.195053    0.0192201   -0.0400818   0.300607    0.068986      0.246468    -0.133632    -0.212303   -0.167225    0.374319     0.20881     -0.444881   -0.132029      0.317883   -0.102857   -0.0658248   0.361108     0.14622     -0.0978422   0.246177    0.0500609   -0.387915   -0.124632    -0.137374
 -0.162399   -0.103539     0.0506688   0.0870213    0.0158916   0.282505    0.102469      0.105736    -0.102212     0.633475   -0.577294   -0.0269434    0.222659    -0.178777   -0.345972      0.154131    0.271298   -0.0294781  -0.107384     0.242117    -0.243443    0.16136     0.0775392    0.294372   -0.553562    -0.46232
  0.140065   -0.668956    -0.013124   -0.307976    -0.499787    0.238536   -0.146782      0.108306    -0.123071    -0.383792    0.183043    0.162298     0.0256384    0.601476    0.0482656     0.313295    0.145517   -0.108963    0.0581984   -0.322798    -0.283881    0.358646    0.219628     0.247352   -0.137157    -0.10694
  0.0599577   0.286408    -0.116267    0.33806      0.0406584   0.202324   -0.176935      0.466381     0.0870118   -0.279779    0.107445   -0.145906    -0.107676     0.224134    0.0983824     0.222651    0.264662    0.24254    -0.269192    -0.165673    -0.148868    0.0190685  -0.12802      0.281943   -0.00765777  -0.247069
 -0.247314   -0.967861     0.413184    0.0229572   -0.44168     0.114899    0.0501806    -0.246891    -0.173723     0.311365   -0.969593    0.180117     0.176589    -0.22903     0.108503     -0.300061   -0.483522   -0.127002   -0.0535354   -0.228951     0.337644    0.0998477  -0.140002    -0.440795   -0.10958      0.66895
 -0.463426   -0.293169    -0.0540558  -0.767531    -0.345324   -0.391795    0.105555     -0.648667    -0.359818    -0.13288     0.377363    0.269328     0.028287    -0.173501   -0.0804472    -0.356793   -0.120033   -0.507245    0.160735     0.252005     0.179705    0.203539    0.503298    -0.359646   -0.0202028    0.173843
  0.525517    0.159656    -0.0937798   0.23706     -0.0403168  -0.0800809  -0.064677      0.440043     0.0898961   -0.284581   -0.381532    0.185651    -0.160752    -0.541988    0.166104      0.594826    0.0523207  -0.316       0.681523     0.406789    -0.212825    0.06095    -0.201324    -0.6203     -0.16225      0.148301
 -0.356537    0.479953    -0.0395692   0.227351    -0.289278   -0.124808    0.1886        0.373763     0.201448    -0.157255    0.324896    0.130381    -0.218299     0.281929    0.0146863    -0.182816    0.0874973  -0.172209    0.012052    -0.229351    -0.0710294   1.05679     0.299669    -0.518911    0.137679    -0.309024
 -0.623055   -0.414313    -0.521778    0.514783    -0.140081   -0.0443492   0.135296     -0.249374    -0.444077     0.0137855  -0.0259116  -0.584882    -0.0261726   -0.245398    0.390487     -0.0394336   0.245112   -0.645982   -0.392352     0.257546     0.430726   -0.234248    0.186598     0.354689    0.103629    -0.969287
 -0.567564   -0.322235    -0.41729     0.218923    -0.274375    0.742789   -0.0769473     0.00473959   0.374282     0.244502    0.277733   -0.462392     0.21724      0.0838758  -0.000920122   0.856856    0.465231   -0.265679   -0.662869     0.0716093    0.538819    0.383175    0.205913     0.358518   -0.123791     0.110661
 -0.0692128  -0.552711    -0.186691    0.116216    -0.611854    0.411808   -0.044502     -0.269467     0.0672047    0.604244    0.0178459   0.091734     0.4458      -0.33452    -0.650868     -0.0846107  -0.0206825   0.504552   -0.284592     0.211838    -0.235776    0.0117693  -0.208648     0.645838   -0.466396    -0.0614756
  0.321608    0.168809     0.0879253  -0.177516     0.683917    0.238435    0.000822221   0.00156305   0.00430184   0.366959   -0.247275    0.113741     0.376873    -0.0981561  -0.347869      0.102027    0.15471     0.213408   -0.180286     0.0183964   -0.105726   -0.175358   -0.0277485    0.195116   -0.403627    -0.102553
 -0.357302   -0.671961    -0.24882     0.00117113  -0.628363   -0.275898   -0.185194     -0.419421     0.145985    -0.975027   -0.29611     0.559106    -0.643809     0.65633     0.23149       0.0471509  -0.817151    0.313282    0.611189     0.575195    -0.217826   -0.72168    -0.291233     0.147234    0.793613    -0.0733167
  0.266248    0.7537      -0.146359    0.223233    -0.216317    0.227294   -0.0474732    -0.230591    -0.0701869   -1.01255     0.164874   -0.122593     0.668332     0.068275    0.326969      0.326664   -0.154459   -0.189096    0.104176     0.00509258  -0.622987   -0.404171   -0.321031     0.73601     0.222077    -0.407302
  0.134103    0.292096    -0.20163     0.651431    -0.252184   -0.119018    0.161775      0.20095     -0.110648    -0.538757    0.711766   -0.134612    -0.0891795    0.0940165  -0.0662909    -0.307025   -0.334109    0.075193   -0.46        -0.426116     0.202944   -0.527144   -0.422302    -0.243189    0.495656     0.52077
 -0.442537    0.0762752   -0.315466   -0.289167    -0.288798   -0.243221   -0.217547     -0.151462    -0.118118     0.707847    0.146682   -0.275728    -0.274147     0.760151    0.405641     -0.342496   -0.0998231   0.5313     -0.428195    -0.25578     -0.0362442  -0.545308   -0.498789     0.459755    0.768064     0.310944
  0.37031    -0.232385     0.26857    -0.229984     0.267678   -0.733255   -0.378257      0.385611    -0.747977    -0.34202    -0.445575   -0.22075      0.0712607    0.236994    0.182305     -0.109009    0.0216319  -0.387668    0.222572    -0.446237    -0.42324    -0.401547    0.322403     0.225397   -0.787415    -1.19383
  0.183468    0.378057     0.0432165  -0.364043     0.84151    -0.647286   -0.318687      0.397295     0.305718    -0.492075    0.175606   -0.0333524   -0.245807     0.118534    0.301963     -0.117592    0.296031    0.207625    0.0434264   -0.0885013    0.0467557  -0.286616    0.252397     0.311955    0.417972    -0.500573
  0.066877   -0.0602673    0.470228   -0.189485     0.879715   -0.0610129  -0.347883      0.645446     0.284175     0.467748   -0.557108   -0.480253    -0.548625     0.470064    0.450939      0.635414   -0.204958   -0.12348     0.344689    -0.170402     0.638743    0.0320638  -0.116602     0.207761   -0.230883    -0.127053
  0.668658   -0.362946    -0.302662   -0.586876     0.0326671   0.414064   -0.536678     -0.0490504    0.418037    -0.461177   -0.0587169  -0.0445578   -0.477859    -0.17466     0.271919      0.24784    -0.288527    0.421591    0.226392    -0.0544033    0.534365    0.338853    0.0818733    1.2925     -0.125566    -0.126037[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412427
[ Info: iteration 2, average log likelihood -1.412413
[ Info: iteration 3, average log likelihood -1.412399
[ Info: iteration 4, average log likelihood -1.412385
[ Info: iteration 5, average log likelihood -1.412371
[ Info: iteration 6, average log likelihood -1.412357
[ Info: iteration 7, average log likelihood -1.412342
[ Info: iteration 8, average log likelihood -1.412328
[ Info: iteration 9, average log likelihood -1.412313
[ Info: iteration 10, average log likelihood -1.412299
┌ Info: EM with 100000 data points 10 iterations avll -1.412299
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.160242e+05
      1       7.024377e+05      -2.135865e+05 |       32
      2       6.919939e+05      -1.044385e+04 |       32
      3       6.875355e+05      -4.458325e+03 |       32
      4       6.851456e+05      -2.389930e+03 |       32
      5       6.836563e+05      -1.489345e+03 |       32
      6       6.825599e+05      -1.096377e+03 |       32
      7       6.816393e+05      -9.206061e+02 |       32
      8       6.808981e+05      -7.412136e+02 |       32
      9       6.802918e+05      -6.063100e+02 |       32
     10       6.797684e+05      -5.233408e+02 |       32
     11       6.793381e+05      -4.302617e+02 |       32
     12       6.789481e+05      -3.900446e+02 |       32
     13       6.786284e+05      -3.196848e+02 |       32
     14       6.783481e+05      -2.802894e+02 |       32
     15       6.781034e+05      -2.447624e+02 |       32
     16       6.778776e+05      -2.257438e+02 |       32
     17       6.776629e+05      -2.147396e+02 |       32
     18       6.774641e+05      -1.988059e+02 |       32
     19       6.772851e+05      -1.789964e+02 |       32
     20       6.771107e+05      -1.743666e+02 |       32
     21       6.769526e+05      -1.581371e+02 |       32
     22       6.768067e+05      -1.458817e+02 |       32
     23       6.766893e+05      -1.173658e+02 |       32
     24       6.765807e+05      -1.086477e+02 |       32
     25       6.764715e+05      -1.092215e+02 |       32
     26       6.763697e+05      -1.017473e+02 |       32
     27       6.762739e+05      -9.584132e+01 |       32
     28       6.761913e+05      -8.261990e+01 |       32
     29       6.761269e+05      -6.437778e+01 |       32
     30       6.760704e+05      -5.649923e+01 |       32
     31       6.760063e+05      -6.409906e+01 |       32
     32       6.759466e+05      -5.963678e+01 |       32
     33       6.758938e+05      -5.286977e+01 |       32
     34       6.758455e+05      -4.822650e+01 |       32
     35       6.758022e+05      -4.335627e+01 |       32
     36       6.757569e+05      -4.526423e+01 |       32
     37       6.757080e+05      -4.896641e+01 |       32
     38       6.756620e+05      -4.600598e+01 |       32
     39       6.756186e+05      -4.335054e+01 |       32
     40       6.755794e+05      -3.919909e+01 |       32
     41       6.755429e+05      -3.647272e+01 |       32
     42       6.755031e+05      -3.984124e+01 |       32
     43       6.754662e+05      -3.693077e+01 |       32
     44       6.754288e+05      -3.737289e+01 |       32
     45       6.753914e+05      -3.738853e+01 |       32
     46       6.753560e+05      -3.538711e+01 |       32
     47       6.753225e+05      -3.348338e+01 |       32
     48       6.752896e+05      -3.292595e+01 |       32
     49       6.752534e+05      -3.623009e+01 |       32
     50       6.752168e+05      -3.658319e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 675216.7854193848)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424011
[ Info: iteration 2, average log likelihood -1.419005
[ Info: iteration 3, average log likelihood -1.417722
[ Info: iteration 4, average log likelihood -1.416812
[ Info: iteration 5, average log likelihood -1.415821
[ Info: iteration 6, average log likelihood -1.414818
[ Info: iteration 7, average log likelihood -1.414050
[ Info: iteration 8, average log likelihood -1.413585
[ Info: iteration 9, average log likelihood -1.413318
[ Info: iteration 10, average log likelihood -1.413147
[ Info: iteration 11, average log likelihood -1.413021
[ Info: iteration 12, average log likelihood -1.412921
[ Info: iteration 13, average log likelihood -1.412837
[ Info: iteration 14, average log likelihood -1.412764
[ Info: iteration 15, average log likelihood -1.412700
[ Info: iteration 16, average log likelihood -1.412644
[ Info: iteration 17, average log likelihood -1.412594
[ Info: iteration 18, average log likelihood -1.412548
[ Info: iteration 19, average log likelihood -1.412507
[ Info: iteration 20, average log likelihood -1.412470
[ Info: iteration 21, average log likelihood -1.412435
[ Info: iteration 22, average log likelihood -1.412403
[ Info: iteration 23, average log likelihood -1.412373
[ Info: iteration 24, average log likelihood -1.412346
[ Info: iteration 25, average log likelihood -1.412319
[ Info: iteration 26, average log likelihood -1.412294
[ Info: iteration 27, average log likelihood -1.412271
[ Info: iteration 28, average log likelihood -1.412249
[ Info: iteration 29, average log likelihood -1.412227
[ Info: iteration 30, average log likelihood -1.412207
[ Info: iteration 31, average log likelihood -1.412187
[ Info: iteration 32, average log likelihood -1.412169
[ Info: iteration 33, average log likelihood -1.412151
[ Info: iteration 34, average log likelihood -1.412134
[ Info: iteration 35, average log likelihood -1.412117
[ Info: iteration 36, average log likelihood -1.412101
[ Info: iteration 37, average log likelihood -1.412086
[ Info: iteration 38, average log likelihood -1.412072
[ Info: iteration 39, average log likelihood -1.412058
[ Info: iteration 40, average log likelihood -1.412044
[ Info: iteration 41, average log likelihood -1.412031
[ Info: iteration 42, average log likelihood -1.412018
[ Info: iteration 43, average log likelihood -1.412006
[ Info: iteration 44, average log likelihood -1.411994
[ Info: iteration 45, average log likelihood -1.411982
[ Info: iteration 46, average log likelihood -1.411970
[ Info: iteration 47, average log likelihood -1.411959
[ Info: iteration 48, average log likelihood -1.411947
[ Info: iteration 49, average log likelihood -1.411936
[ Info: iteration 50, average log likelihood -1.411925
┌ Info: EM with 100000 data points 50 iterations avll -1.411925
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.184268    -0.0627245   0.0613881    0.317167     0.0576187     0.0557965    0.0432446   -0.147284     -0.105175     0.372739    0.0281242   0.108092      0.205769   -0.223134    -0.828412    -0.265596    0.348137     0.334458     -0.86459     0.206058    -0.130482    -0.0131279    0.000283593   0.374147    -0.551437   -0.182318
  0.173055    -0.734555    0.519662    -0.54234      0.0307648     0.142178    -0.135541    -0.373537     -0.121721     0.0533986  -0.444416    0.298177      0.583454   -0.0141699    0.262044     0.046684    0.0924564    0.0284394     0.166777   -0.455374     0.133114    -0.00330983   0.308016      0.0164949   -0.139406    0.56045
  0.543717     0.176581    0.31054     -0.12114      0.374532     -0.475665    -0.0868693    0.328251     -0.711131    -0.347487   -0.0341778  -0.366508      0.268893    0.36282      0.133239    -0.247831   -0.0864202   -0.0733694     0.0979753  -0.732947    -0.48346     -0.444402    -0.127976      0.197496    -0.362527   -0.93843
 -0.0131129   -0.037751   -0.128595     0.0313113   -0.105208      0.0932981   -0.0108366    0.111507     -0.106812    -0.113839    0.0444247   0.0922595     0.147057    0.00809986  -0.273895    -0.0303906   0.00402402  -0.0207905    -0.107348   -0.124243    -0.169646     0.0172448    0.0103266     0.0609442   -0.0417371  -0.108476
 -0.256763     0.292214   -0.226869    -0.0258723   -0.346714      0.411642     0.0310882   -0.0228832     0.271458    -0.406491    0.149277    0.150962      0.249878   -0.462118    -0.352592    -0.358646   -0.286427    -0.245248      0.209576   -0.0472456    0.0620683    1.24287      0.718418     -0.0386454    0.0360082  -0.105711
 -0.758277     0.214506    0.0703016   -0.080842     0.0554012    -0.448183     0.0916412   -0.0956339     0.00603961   0.410113   -0.111874    0.113045      0.0422717  -0.0737153    0.385284    -0.428771   -0.252482    -0.210472      0.346867    0.0421936    0.334576     0.333987    -0.0108922    -0.491156     0.242934   -0.019969
 -0.463412    -0.15329     0.274059    -0.253585    -0.190944     -0.306142    -0.518081    -0.585978     -0.444767    -0.210921   -0.267665   -0.179098      0.490369   -0.502269     0.333875    -0.432686    0.0637747   -0.844108     -0.0263843   0.40526     -0.147803    -0.339475     0.355148     -0.00945944  -0.206474   -0.389809
  0.143084     0.240246    0.279035     0.33822      0.000563025   0.0432692    0.389912     0.154946     -0.347378    -0.0633996  -0.25757     0.417025      0.198665    0.00501612  -0.206909     0.434264    0.266282    -0.660517      0.253651    0.318504    -0.648892     0.128659    -0.250518     -0.935029    -0.316448   -0.0242307
 -0.00091996  -0.310226   -0.219325    -0.0484702   -0.0967943     0.584311     0.0906765   -0.000527838  -0.11778      0.565801   -0.376322    0.218201      0.716186   -0.26426     -0.54247      0.19393     0.0581992    0.155528     -0.120833    0.145228    -0.211036    -0.121568    -0.0624703     0.290136    -0.513627   -0.233917
  0.715435     0.353365   -0.438727    -0.00917089   0.776153     -0.108522     0.98044     -0.300576      0.117824     0.31644     0.10192    -0.22031       0.0163324   0.218183     0.254605     0.532843    0.230275     0.316797      0.27326     0.340048     0.048244    -0.176202    -0.328623      0.291997    -0.0958799  -0.0960214
 -0.357834    -1.0117      0.295734     0.404985    -0.552022      0.0299895   -0.125735    -0.118415     -0.566563    -0.109094   -0.978684    0.388466      0.170663    0.0242117   -0.202347    -0.143996   -1.06533     -0.0587144    -0.266781   -0.17982      0.241948    -0.174579    -0.502972     -0.352946     0.271788    0.562686
  0.319864    -0.0551017  -0.17075      0.701815     0.0228679    -0.0443756    0.594729     0.823167      0.377624     0.350315    0.371344    0.185038     -0.821667    0.437117    -0.425317     0.195683   -0.113504     0.344949     -0.395007   -0.454885    -0.00628714   0.343514    -0.299377     -0.146141     0.138049    0.0635944
 -0.560301    -0.187122   -0.293041    -0.282167    -0.642407      0.735973    -0.339371    -0.407176      0.251572     0.382939    0.20263    -0.332907      0.140785    0.176202    -0.00628156  -0.10477    -0.245182     0.8338       -0.368573   -0.25472     -0.118635     0.16156      0.0267873     0.667868     0.271287    0.543665
 -0.100774     0.298341   -0.402701     0.296336     0.164797     -0.175911    -0.495914     0.440411      0.199303    -0.55675     0.215157    0.339333      0.0547082   0.335998     0.135512     0.120247   -0.124767    -0.093224     -0.337425   -0.289907    -0.423535    -0.835759     0.071898      0.100153     0.868188    0.213494
  0.109535    -0.358178   -0.063738    -1.07153      0.0939291    -0.59425      0.162041    -0.237445      0.341523     0.013371    0.497599    0.492422     -0.383013    0.450523    -0.334894    -0.0784214   0.222569    -0.232803      0.272493   -0.268747    -0.312489     0.120064     0.52365       0.0757921   -0.125326    0.0797039
 -0.507051    -0.663553   -0.447691     0.609385    -0.672775      0.239092     0.499331    -0.0680795     0.11949      0.163834   -0.523091   -0.585126     -0.272754    0.125795     0.382706    -0.0260262   0.506883    -0.732545     -0.503712   -0.065024     0.121557     0.00419311   0.526361      0.120775     0.16136    -0.644129
 -0.222876     0.182601    0.0901353    0.136073     0.365552     -0.0973898   -0.134119    -0.114207      0.391784    -0.0738617   0.463804   -0.414987     -0.470875    0.0647706    0.312731    -0.492851   -0.0594843    0.0234457    -0.390372    0.00906626   0.742436     0.0660531    0.308771      0.779044     0.365591   -0.268153
  0.0321712   -0.341224    0.424637    -0.260861     0.675307     -0.118597    -0.534209     0.726514      0.130512     0.370943   -0.637048   -0.36033      -0.616979    0.510211     0.498785     0.787231   -0.0652196   -0.355524      0.373214   -0.139372     0.511588     0.256        0.0751956     0.277779    -0.362275   -0.342154
  0.378625     0.48009     0.0108307   -0.0134072   -0.0351111     0.307608     0.0810444   -0.664665      0.256437    -0.516875   -0.22061     0.0498776     0.45821    -0.130196     0.419395     0.556117   -0.566163    -0.418502      0.603195    0.489551    -0.319495    -0.282285    -0.295476      0.363894     0.101576   -0.0382115
 -0.274669    -0.185405   -0.233254     0.0262519   -0.777151      0.13938      0.138483    -0.211691     -0.276523    -0.479859    0.774518   -0.0732181     0.192748    0.40409      0.135064     0.469138    0.232579    -0.402162     -0.0831162   0.0184335   -0.226345     0.276189    -0.057488      0.0536888   -0.0108673  -0.39901
  0.713287    -0.226957   -0.21229     -0.113297    -0.108051      0.501839    -0.427848     0.301532      0.233048    -0.670197   -0.211119   -0.142882     -0.204144   -0.126169     0.4185       0.420108    0.246729     0.579875     -0.0875005  -0.114816    -0.0519914    0.0946784   -0.000767436   0.834017    -0.404902   -0.0909841
 -0.485038     0.644018    0.077692     0.469221    -0.220297      0.0722776    0.530612    -0.197987     -0.0900696    0.419581   -0.0113467  -0.16366       0.305265    0.138743    -0.0608262   -0.566148    0.0807836    0.114924     -0.356169   -0.299299    -0.287321    -0.207961    -0.296953     -1.04213      0.244266    0.592153
 -0.259971     0.508602   -0.106148     0.0409024    0.476073     -0.139959    -0.145548     0.760849      0.351539    -0.0505944  -0.167326    0.0607451     0.02966     0.154931     0.151197     0.0480405   0.391236     0.285615      0.0213431  -0.0136486   -0.121067     0.305001     0.198108      0.0239487   -0.132128   -0.598788
 -0.138349    -0.670583    0.142577    -0.014289    -0.625255      0.00424672   0.726298    -0.670217      0.262875     0.611779   -0.346275   -0.114744     -0.362455   -0.311681     0.216623    -0.249661   -0.123473     0.160529      0.189912    0.421535     0.497144     0.589324    -0.212873     -0.357709    -0.521745    0.404943
  0.540009     0.262121    0.240704    -0.390045     0.816728     -0.05836     -0.533934     0.158164      0.191791     0.149213   -0.276055    0.278135      0.0712705  -0.466428    -0.450732    -0.320071   -0.344521     0.348705      0.349521    0.0474436    0.272213    -0.0194854    0.22416       0.013948    -0.25363     0.323424
  0.386116    -0.0176269   0.0293101   -0.331425    -0.579046     -0.286614    -0.338293     0.486938      0.393306    -0.214078   -0.0516152   0.219789     -0.364763   -0.0625144    0.170294    -0.1464     -0.243651     0.125163      0.836235   -0.604627    -0.0838534    0.633945    -0.0311163    -0.212875     0.597838    0.193136
 -0.232805    -0.403514   -0.285916    -0.235762     0.0944083    -0.696981    -0.194126    -0.191054     -0.216166     0.12139    -0.0268789  -0.0365764    -0.492625    0.459655     0.273207    -0.120293   -0.289247    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
 0.399842      0.123133    0.297663     0.249007    -1.04029     -0.51205       0.518381     0.461813   -0.0976621
  0.372931     0.328514   -0.271169     0.0479788   -0.334236     -0.31304      0.507228    -0.297973     -0.199208    -0.496071    0.990315   -0.172598     -0.0470461  -0.134157    -0.0315635   -0.364641   -0.334032     0.000461108  -0.265887   -0.347272     0.11014     -0.304473    -0.44399      -0.336984     0.342302    0.505054
  0.0768297   -0.0149241   0.227524     0.0496971    0.0273189    -0.0744395   -0.00509618  -0.245553      0.179513     0.0533083  -0.0557075  -0.168111     -0.220457    0.0385366    0.472921     0.0430872  -0.105249    -0.0801382     0.0375213   0.137585     0.15552     -0.0778378   -0.0823738     0.0262654    0.0411092   0.197363
  0.0700116    0.241048    0.00315605   0.0177776    0.0138282    -0.277273    -0.0559784    0.109792      0.0270208   -0.39014     0.156415    0.000388163  -0.195475    0.0865285    0.164724    -0.0397841   0.012735    -0.0244907     0.0575932  -0.0610277   -0.0145426    0.0675375   -0.0165409    -0.172538     0.21902    -0.0440746
 -0.314662     0.05482    -0.696348     0.347896    -0.295726      0.489801     0.228931     0.295656     -0.422131     0.0611968  -0.117168   -0.0674776     0.0251163  -0.507976     0.0511425    0.31448    -0.0926194    0.112397     -0.0502013   0.495483     0.257007    -0.117426    -0.282512     -0.387092     0.0902932  -0.189044
 -0.0750653    0.0638217   0.254152     0.343833     0.810724      0.38368      0.073503     0.25799       0.0228517    0.647653   -0.215487   -1.21559       0.524282   -0.607453     0.243483     0.405088    0.343042    -0.854138     -0.642684   -0.372739     0.663833    -0.0133404   -0.111903      0.311605    -0.488641   -0.136648[ Info: iteration 1, average log likelihood -1.411914
[ Info: iteration 2, average log likelihood -1.411903
[ Info: iteration 3, average log likelihood -1.411893
[ Info: iteration 4, average log likelihood -1.411882
[ Info: iteration 5, average log likelihood -1.411872
[ Info: iteration 6, average log likelihood -1.411862
[ Info: iteration 7, average log likelihood -1.411853
[ Info: iteration 8, average log likelihood -1.411843
[ Info: iteration 9, average log likelihood -1.411834
[ Info: iteration 10, average log likelihood -1.411826
┌ Info: EM with 100000 data points 10 iterations avll -1.411826
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
