Julia Version 1.5.0-DEV.0
Commit 13d1bd4689 (2019-12-31 18:18 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed DataAPI ──────────── v1.1.0
 Installed Blosc ────────────── v0.5.1
 Installed Compat ───────────── v2.2.0
 Installed Rmath ────────────── v0.6.0
 Installed GaussianMixtures ─── v0.3.0
 Installed OrderedCollections ─ v1.1.0
 Installed DataStructures ───── v0.17.6
 Installed Clustering ───────── v0.13.3
 Installed NearestNeighbors ─── v0.4.4
 Installed Arpack ───────────── v0.4.0
 Installed BinaryProvider ───── v0.5.8
 Installed Arpack_jll ───────── v3.5.0+2
 Installed OpenBLAS_jll ─────── v0.3.7+2
 Installed FillArrays ───────── v0.8.2
 Installed StatsFuns ────────── v0.9.3
 Installed URIParser ────────── v0.4.0
 Installed CMake ────────────── v1.1.2
 Installed SortingAlgorithms ── v0.3.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed FileIO ───────────── v1.2.1
 Installed HDF5 ─────────────── v0.12.5
 Installed SpecialFunctions ─── v0.9.0
 Installed PDMats ───────────── v0.9.10
 Installed Distances ────────── v0.8.2
 Installed LegacyStrings ────── v0.4.1
 Installed BinDeps ──────────── v1.0.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed Missings ─────────── v0.4.3
 Installed Parameters ───────── v0.12.0
 Installed StatsBase ────────── v0.32.0
 Installed StaticArrays ─────── v0.12.1
 Installed QuadGK ───────────── v2.3.1
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed JLD ──────────────── v0.9.1
 Installed Distributions ────── v0.21.11
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+2
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_mZILx3/Project.toml`
 [no changes]
  Updating `/tmp/jl_mZILx3/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_v9ZMrB/Project.toml`
 [no changes]
  Updating `/tmp/jl_v9ZMrB/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_MvNfA8/Project.toml`
 [no changes]
  Updating `/tmp/jl_MvNfA8/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_9H1N5S/Project.toml`
 [no changes]
  Updating `/tmp/jl_9H1N5S/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_EHeec4/Project.toml`
 [no changes]
  Updating `/tmp/jl_EHeec4/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_EHeec4/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -7.451751614042185e6, [21908.066846825513, 78091.93315317448], [15522.707060136856 11768.418111916584 653.3443855599883; -15615.052633011688 -12018.951974901622 -737.3419354885497], [[20442.03236776586 -1633.6396046073028 -675.6430435800553; -1633.6396046073028 20240.59162594662 -1150.732131220444; -675.6430435800551 -1150.732131220444 21942.45160667159], [79018.11530474483 1319.1409455503588 1306.2387209363656; 1319.1409455503588 79171.47147990267 863.8814427256732; 1306.2387209363656 863.8814427256733 78194.79027314516]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.884513e+03
      1       1.452133e+03      -4.323800e+02 |        4
      2       1.358303e+03      -9.383015e+01 |        3
      3       1.255806e+03      -1.024973e+02 |        0
      4       1.255806e+03       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 1255.8059417088639)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.086525
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.719716
[ Info: iteration 2, lowerbound -3.576630
[ Info: iteration 3, lowerbound -3.408212
[ Info: iteration 4, lowerbound -3.200202
[ Info: iteration 5, lowerbound -2.986115
[ Info: iteration 6, lowerbound -2.809304
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.685925
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.598916
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.535880
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.483654
[ Info: iteration 11, lowerbound -2.439246
[ Info: iteration 12, lowerbound -2.402740
[ Info: iteration 13, lowerbound -2.369834
[ Info: iteration 14, lowerbound -2.340648
[ Info: iteration 15, lowerbound -2.318265
[ Info: iteration 16, lowerbound -2.307808
[ Info: dropping number of Gaussions to 2
[ Info: iteration 17, lowerbound -2.303023
[ Info: iteration 18, lowerbound -2.299262
[ Info: iteration 19, lowerbound -2.299257
[ Info: iteration 20, lowerbound -2.299255
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Jan  1 05:59:23 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Jan  1 05:59:30 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Wed Jan  1 05:59:33 2020: EM with 272 data points 0 iterations avll -2.086525
5.8 data points per parameter
, Wed Jan  1 05:59:35 2020: GMM converted to Variational GMM
, Wed Jan  1 05:59:43 2020: iteration 1, lowerbound -3.719716
, Wed Jan  1 05:59:43 2020: iteration 2, lowerbound -3.576630
, Wed Jan  1 05:59:43 2020: iteration 3, lowerbound -3.408212
, Wed Jan  1 05:59:43 2020: iteration 4, lowerbound -3.200202
, Wed Jan  1 05:59:43 2020: iteration 5, lowerbound -2.986115
, Wed Jan  1 05:59:43 2020: iteration 6, lowerbound -2.809304
, Wed Jan  1 05:59:44 2020: dropping number of Gaussions to 7
, Wed Jan  1 05:59:44 2020: iteration 7, lowerbound -2.685925
, Wed Jan  1 05:59:44 2020: dropping number of Gaussions to 5
, Wed Jan  1 05:59:44 2020: iteration 8, lowerbound -2.598916
, Wed Jan  1 05:59:44 2020: dropping number of Gaussions to 4
, Wed Jan  1 05:59:44 2020: iteration 9, lowerbound -2.535880
, Wed Jan  1 05:59:44 2020: dropping number of Gaussions to 3
, Wed Jan  1 05:59:44 2020: iteration 10, lowerbound -2.483654
, Wed Jan  1 05:59:44 2020: iteration 11, lowerbound -2.439246
, Wed Jan  1 05:59:44 2020: iteration 12, lowerbound -2.402740
, Wed Jan  1 05:59:44 2020: iteration 13, lowerbound -2.369834
, Wed Jan  1 05:59:44 2020: iteration 14, lowerbound -2.340648
, Wed Jan  1 05:59:44 2020: iteration 15, lowerbound -2.318265
, Wed Jan  1 05:59:44 2020: iteration 16, lowerbound -2.307808
, Wed Jan  1 05:59:44 2020: dropping number of Gaussions to 2
, Wed Jan  1 05:59:44 2020: iteration 17, lowerbound -2.303023
, Wed Jan  1 05:59:44 2020: iteration 18, lowerbound -2.299262
, Wed Jan  1 05:59:44 2020: iteration 19, lowerbound -2.299257
, Wed Jan  1 05:59:44 2020: iteration 20, lowerbound -2.299255
, Wed Jan  1 05:59:44 2020: iteration 21, lowerbound -2.299254
, Wed Jan  1 05:59:44 2020: iteration 22, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 23, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 24, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 25, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 26, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 27, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 28, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 29, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 30, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 31, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 32, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 33, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 34, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 35, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 36, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 37, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 38, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 39, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 40, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 41, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 42, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 43, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 44, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 45, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 46, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 47, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 48, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: iteration 49, lowerbound -2.299253
, Wed Jan  1 05:59:44 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398604, 178.04509222601396]
β = [95.95490777398604, 178.04509222601396]
m = [2.0002292577753695 53.851987172461286; 4.250300733269909 79.28686694436183]
ν = [97.95490777398604, 180.04509222601396]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948416 -0.008953123827346005; 0.0 0.012748664777409342], [0.18404155547484816 -0.007644049042327562; 0.0 0.00858170516633351]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999994
avll from stats: -0.981025060976163
avll from llpg:  -0.9810250609761634
avll direct:     -0.9810250609761634
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -1.0037307337841321
avll from llpg:  -1.0037307337841321
avll direct:     -1.0037307337841321
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.000451899   0.211221      0.0643752    -0.0406852    0.0146259   -0.169764     -0.190865     0.0465368   -0.0683253    0.0422438    0.050056    -0.0116303     0.0493482    0.1701       0.102788     0.0711698   -0.151903   -0.0533145  -0.0493189   -0.0987317    -0.0304761    0.0990025   -0.193848     0.0796761    0.0358557   -0.0686434
  0.0545375    -0.0886539    -0.144398      0.0159479   -0.0688838   -0.00982621   -0.147139     0.110342    -0.071274    -0.258529     0.180583     0.00259992   -0.0489937   -0.0454872    0.106065     0.0330408   -0.0642926   0.114382   -0.148906     0.00189007    0.188627     0.0489379    0.00958427   0.0216481    0.077803    -0.114124
 -0.00992404   -0.0544522     0.121236     -0.204731    -0.0296276   -0.0423885    -0.147738    -0.0654083   -0.0290961   -0.0236871    0.133668    -0.00663831    0.00053259  -0.018818     0.113469    -0.0775955    0.116226    0.0336629   0.0461933    0.128914     -0.122617    -0.028363    -0.054802     0.0837978    0.146526    -0.221191
 -0.127863      0.0557873    -0.0700684     0.0722431    0.0208426   -0.0184184    -0.232865    -0.00758627  -0.0955576    0.0624291   -0.0651214    0.110182      0.131811     0.0599125   -0.0152964   -0.104528     0.109968    0.0227984  -0.239106     0.111528     -0.0827       0.0517622   -0.122436    -0.00115476  -0.0641738    0.0836304
  0.107758      0.0177211    -0.059408      0.0129636   -0.0107746   -0.166843     -0.0245371    0.0356726    0.0238972   -0.10651      0.0587119    0.119654      0.0468028   -0.0420159   -0.0699228   -0.0469548   -0.10085    -0.0326558   0.0185813   -0.0492729    -0.137845    -0.0276649   -0.142067    -0.0676144   -0.0511381   -0.0670634
 -0.0802142    -0.0242432    -0.00354324    0.0299195    0.0493466   -0.0700083     0.0762757   -0.123466     0.052099     0.0394022    0.0406891   -0.187023     -0.0806078    0.0733631    0.102837     0.00873852  -0.106795    0.180569   -0.0558161   -0.0362861    -0.0061976    0.059169     0.247815    -0.120595    -0.0639222   -0.193277
 -0.0658608    -0.114461      0.0460692    -0.223088    -0.0332471    0.00933633    0.0353416   -0.0105495   -0.0766841    0.122597     0.0910409   -0.146497     -0.00861254  -0.059644    -0.0880211   -0.0742023    0.221244    0.103416    0.0267757   -0.0680391    -0.0484634   -0.0438554    0.0429329    0.0453826   -0.066838     0.0464232
 -0.15725       0.0580524    -0.118005      0.0354233   -0.0936755    0.063144      0.0919864   -0.0312551    0.0193954   -0.147397     0.224784     0.0856508     0.0106251   -0.0517441   -0.0879017    0.056495     0.0796072   0.0762208  -0.171151     0.00960024    0.0150657    0.0072433   -0.0577789   -0.13878      0.00345941  -0.0449691
  0.00304364   -0.162661     -0.124358     -0.0272547   -0.0836898   -0.0154119     0.205566    -0.0790624    0.0333058   -0.236886    -0.0223447   -0.0154201     0.202354     0.00878514  -0.0617415   -0.0577028   -0.0806551  -0.0156227  -0.157409    -0.120016     -0.0268306    0.09191     -0.19063     -0.0434745    0.00551266   0.151732
 -0.122774      0.143232     -0.116202     -0.0122145   -0.0827702   -0.130682     -0.00172516  -0.0583104   -0.165334     0.00255504  -0.106983    -0.13084       0.0956036   -0.108484    -0.0484128   -0.0882501   -0.100139    0.050536    0.01724     -0.144331      0.0248838   -0.132797     0.0496599   -0.00109913   0.189859     0.0208245
 -0.0906978    -0.00707321    0.183689      0.0956211    0.0258065   -0.0561797     0.136497    -0.0288226   -0.00147191   0.060113     0.0504123    0.0102024     0.0517248    0.155837    -0.080391     0.0346093    0.100532    0.272983   -0.0463932    0.0565935     0.0631137    0.0953021   -0.0970156    0.043755     0.07349      0.0865954
 -0.025949      0.146422      0.0554312    -0.0413116   -0.204344    -0.0628254     0.0184637   -0.00846265   0.0501191    0.0858049    0.106443    -0.0305589    -0.138064    -0.147428     0.171048     0.0177835    0.0284739   0.0758281  -0.0563792   -0.122799      0.0307621   -0.0760446   -0.063487     0.0289071    0.0389261   -0.0559373
  0.021108      0.110314     -0.0406297    -0.0164309    0.256831    -0.0663048    -0.0696727    0.0896535    0.0205808    0.0521532    0.152972     0.150684      0.0468817    0.037875     0.0980253   -0.0804396    0.118498   -0.0672737  -0.0182112    0.103376     -0.0544163   -0.216572     0.10794     -0.0732255    0.0417337   -0.162399
 -0.0205936     0.0215612     0.0334964     0.0228086    0.0557771   -0.000443559   0.0398319    0.0562894   -0.0277595   -0.102851     0.0835761   -0.0238646    -0.0830846    0.0267434    0.0244724   -0.290755    -0.138835   -0.0630666   0.0168661    0.0744733    -0.0409293   -0.0560226   -0.0359115   -0.02162     -0.108115     0.0650138
 -0.130121     -0.042503      0.0218411    -0.00866125   0.178431    -0.158216      0.035382     0.05789      0.00860152   0.0368112   -0.0376744    0.160751      0.064879     0.101779     0.00917073   0.0474481    0.132267    0.190835    0.0745293   -0.0698039     0.0434712    0.0181077   -0.128185     0.00714589  -0.146827     0.0169335
 -0.0954883     0.0275047     0.261682      0.0269433    0.0588415    0.0174142     0.170282     0.017525     0.13624     -0.0114467    0.0516196    0.0687446     0.0808927   -0.0584709   -0.00562155  -0.0799189    0.0474825  -0.0710471   0.0972096   -0.0278881     0.0918163   -0.210341    -0.108434    -0.0426624   -0.126566    -0.00769136
 -0.0180931     0.105749      0.0172533     0.159918     0.0783325    0.188324      0.019631     0.104708     0.0271974   -0.0169569   -0.011365    -0.145201      0.0107718    0.155446     0.0861605   -0.187968    -0.0264275   0.134064    0.0402452   -0.0789933    -0.108689    -0.108165     0.00745653  -0.0786246    0.155042    -0.0858384
 -0.0425209     0.114878     -0.0216212     0.0546549    0.061192    -0.147416      0.0540669    0.0271816   -0.108177     0.00952321   0.0250659   -0.237787      0.0757859    0.170456     0.0771709   -0.276345     0.0909278   0.0291525   0.0632062   -0.109821     -0.0496249    0.0120998   -0.0201869   -0.0170283   -0.0453306    0.00741354
 -0.137626      0.0949929     0.179363      0.0961986    0.0207584   -0.0475201     0.0352593    0.157049     0.0375662   -0.0477984    0.0376226   -0.01065      -0.0153299   -0.00305319   0.0394293    0.0196479    0.195876   -0.0217368  -0.0251349   -0.0903217     0.120542     0.00230174   0.121249    -0.180331     0.120754    -0.0105474
 -0.054094     -0.0110773     0.0897869    -0.00262409  -0.0731167    0.168792     -0.0770987   -0.0461254    0.0471783    0.0896337   -0.0850421   -0.0781624     0.0207347    0.0349589    0.114162    -0.0306219   -0.0550747   0.0375593  -0.0868185   -0.088987      0.200589     0.0100747   -0.00970892   0.10125     -0.0408117    0.0321388
  0.0165636     0.046928     -0.0302562     0.198409    -0.0491822   -0.16905      -0.296421     0.0814324    0.126144     0.0749325    0.192047     0.00991751   -0.106437     0.0188322   -0.0691222   -0.0723933    0.183557   -0.103126   -0.102077    -0.0430299     0.0372872   -0.119422    -0.125417    -0.203486    -0.0948237    0.237632
  0.214243     -0.175007      0.0678603     0.237271     0.125289    -0.0614784     0.0576586    0.125296     0.136098     0.128296     0.00611578  -0.0905657    -0.10816      0.17841     -0.0109935    0.0280518    0.0511456  -0.2336     -0.22137     -0.000956549  -0.0642165    0.0979361   -0.0489302    0.00311148  -0.0907775   -0.230399
  0.0005792     0.000559927   0.0618043    -0.112469     0.0483537    0.00961679    0.202397    -0.0241797   -0.0366695   -0.232221    -0.115607    -0.139199     -0.0761784   -0.0640693    0.147277    -0.141983    -0.0606189  -0.190965   -0.0959087    0.0512478     0.00958183   0.048832     0.0460309   -0.0418311    0.0777555   -0.0422016
  0.0545564    -0.0856824     0.161048      0.0554258    0.0534262    0.019331      0.0838325   -0.0416465    0.0234331   -0.0485233   -0.128487     0.014402     -0.134218     0.16395      0.0147026    0.071879    -0.136192    0.0598265  -0.156094     0.0557792     0.0152365    0.0414441    0.0271823    0.031711    -0.062622    -0.00230226
  0.0927471     0.197478      0.0635826     0.0680323   -0.0714541   -0.102078     -0.0287628   -0.217032    -0.210191    -0.173207     0.0978556    0.0889732     0.0175361    0.0733649    0.0214356    0.0120091    0.0998314  -0.104818   -0.0596988    0.0181886    -0.123195    -0.0168194    0.110072    -0.120421     0.0629856    0.122559
  0.0980717     0.00177453    0.000469777   0.0981737    0.026903    -0.0488977     0.0177131    0.00455801   0.15613     -0.0689627   -0.163885    -0.101166     -0.0441779   -0.0557341   -0.0192037    0.023276     0.02663    -0.0535524  -0.108291     0.022302     -0.0358827   -0.0643718   -0.147961     0.0312923    0.0371145    0.019978
  0.0689465     0.0958826    -0.164622      0.0837375    0.106333    -0.0468663    -0.0386511   -0.0798782   -0.234135    -0.038867    -0.142158    -0.165484      0.0435769   -0.0124896    0.0248397   -0.00492747  -0.158638   -0.134791    0.0968632   -0.0143889     0.140702    -0.0331198   -0.166173     0.0279202    0.0470611    0.0477616
  0.0608674    -0.00477544    0.0502492    -0.098562     0.0576218   -0.000967267   0.0557859    0.134291    -0.0298127   -0.0188083    0.0566284    0.0610312    -0.0106987   -0.200316    -0.0552592   -0.161689    -0.0169668  -0.0116513   0.0190961   -0.0618367     0.197772     0.27786      0.0377319   -0.146057     0.0649496    0.0126854
  0.112058      0.222451      0.167538     -0.173256    -0.00126699   0.050167     -0.147497    -0.0948798    0.0196589   -0.0103824   -0.215112     0.00654734    0.0696802    0.0659092    0.055525     0.0598777   -0.019618    0.170724    0.156747     0.0324697     0.0411754    0.028782     0.050527    -0.0311502   -0.0962248    0.103945
 -0.00364956   -0.12502       0.139859      0.072664     0.0242667   -0.0657335     0.0949558    0.0347253   -0.0495667   -0.0597481   -0.110991     0.000827375   0.162559    -0.0969823    0.0168349   -0.123185    -0.0594209  -0.0403854  -0.00171666   0.137391     -0.0586168    0.0666341   -0.0301505   -0.0180391   -0.0650229    0.078783
 -0.0189824    -0.0416246     0.0807484     0.0393914    0.0461842   -0.0436443    -0.0680034    0.106396    -0.0191927    0.0682981    0.0444346   -0.042427      0.021384    -0.154778     0.136633     0.139517     0.0548445   0.12872    -0.0425066   -0.0844572     0.108143    -0.161532     0.0444874   -0.0588434   -0.0575446    0.0302624
 -0.137394      0.0888403    -0.0598212    -0.224377     0.0289126    0.143503     -0.0417581    0.10687      0.127707     0.108317     0.0604496   -0.098484      0.168087     0.0752489    0.179324     0.0272543   -0.0502353  -0.0766561  -0.0501092   -0.0938934    -0.0137484   -0.13706      0.148108     0.0906397    0.046472     0.0467906kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4376984287317585
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.437790
[ Info: iteration 2, average log likelihood -1.437704
[ Info: iteration 3, average log likelihood -1.437258
[ Info: iteration 4, average log likelihood -1.432246
[ Info: iteration 5, average log likelihood -1.416693
[ Info: iteration 6, average log likelihood -1.408606
[ Info: iteration 7, average log likelihood -1.407070
[ Info: iteration 8, average log likelihood -1.406428
[ Info: iteration 9, average log likelihood -1.406041
[ Info: iteration 10, average log likelihood -1.405756
[ Info: iteration 11, average log likelihood -1.405481
[ Info: iteration 12, average log likelihood -1.405246
[ Info: iteration 13, average log likelihood -1.405112
[ Info: iteration 14, average log likelihood -1.405047
[ Info: iteration 15, average log likelihood -1.405014
[ Info: iteration 16, average log likelihood -1.404996
[ Info: iteration 17, average log likelihood -1.404986
[ Info: iteration 18, average log likelihood -1.404980
[ Info: iteration 19, average log likelihood -1.404976
[ Info: iteration 20, average log likelihood -1.404973
[ Info: iteration 21, average log likelihood -1.404972
[ Info: iteration 22, average log likelihood -1.404970
[ Info: iteration 23, average log likelihood -1.404969
[ Info: iteration 24, average log likelihood -1.404968
[ Info: iteration 25, average log likelihood -1.404968
[ Info: iteration 26, average log likelihood -1.404967
[ Info: iteration 27, average log likelihood -1.404967
[ Info: iteration 28, average log likelihood -1.404966
[ Info: iteration 29, average log likelihood -1.404966
[ Info: iteration 30, average log likelihood -1.404966
[ Info: iteration 31, average log likelihood -1.404965
[ Info: iteration 32, average log likelihood -1.404965
[ Info: iteration 33, average log likelihood -1.404965
[ Info: iteration 34, average log likelihood -1.404965
[ Info: iteration 35, average log likelihood -1.404964
[ Info: iteration 36, average log likelihood -1.404964
[ Info: iteration 37, average log likelihood -1.404964
[ Info: iteration 38, average log likelihood -1.404964
[ Info: iteration 39, average log likelihood -1.404964
[ Info: iteration 40, average log likelihood -1.404964
[ Info: iteration 41, average log likelihood -1.404963
[ Info: iteration 42, average log likelihood -1.404963
[ Info: iteration 43, average log likelihood -1.404963
[ Info: iteration 44, average log likelihood -1.404963
[ Info: iteration 45, average log likelihood -1.404963
[ Info: iteration 46, average log likelihood -1.404963
[ Info: iteration 47, average log likelihood -1.404963
[ Info: iteration 48, average log likelihood -1.404963
[ Info: iteration 49, average log likelihood -1.404963
[ Info: iteration 50, average log likelihood -1.404963
┌ Info: EM with 100000 data points 50 iterations avll -1.404963
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4377904524093168
│     -1.437704287042289
│      ⋮
└     -1.4049626991080528
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405051
[ Info: iteration 2, average log likelihood -1.404982
[ Info: iteration 3, average log likelihood -1.404753
[ Info: iteration 4, average log likelihood -1.402260
[ Info: iteration 5, average log likelihood -1.389509
[ Info: iteration 6, average log likelihood -1.373525
[ Info: iteration 7, average log likelihood -1.367677
[ Info: iteration 8, average log likelihood -1.365098
[ Info: iteration 9, average log likelihood -1.363418
[ Info: iteration 10, average log likelihood -1.362125
[ Info: iteration 11, average log likelihood -1.361113
[ Info: iteration 12, average log likelihood -1.360407
[ Info: iteration 13, average log likelihood -1.359951
[ Info: iteration 14, average log likelihood -1.359652
[ Info: iteration 15, average log likelihood -1.359441
[ Info: iteration 16, average log likelihood -1.359285
[ Info: iteration 17, average log likelihood -1.359165
[ Info: iteration 18, average log likelihood -1.359064
[ Info: iteration 19, average log likelihood -1.358969
[ Info: iteration 20, average log likelihood -1.358868
[ Info: iteration 21, average log likelihood -1.358747
[ Info: iteration 22, average log likelihood -1.358588
[ Info: iteration 23, average log likelihood -1.358368
[ Info: iteration 24, average log likelihood -1.358075
[ Info: iteration 25, average log likelihood -1.357743
[ Info: iteration 26, average log likelihood -1.357448
[ Info: iteration 27, average log likelihood -1.357226
[ Info: iteration 28, average log likelihood -1.357065
[ Info: iteration 29, average log likelihood -1.356959
[ Info: iteration 30, average log likelihood -1.356891
[ Info: iteration 31, average log likelihood -1.356846
[ Info: iteration 32, average log likelihood -1.356817
[ Info: iteration 33, average log likelihood -1.356797
[ Info: iteration 34, average log likelihood -1.356783
[ Info: iteration 35, average log likelihood -1.356773
[ Info: iteration 36, average log likelihood -1.356765
[ Info: iteration 37, average log likelihood -1.356758
[ Info: iteration 38, average log likelihood -1.356753
[ Info: iteration 39, average log likelihood -1.356747
[ Info: iteration 40, average log likelihood -1.356742
[ Info: iteration 41, average log likelihood -1.356738
[ Info: iteration 42, average log likelihood -1.356733
[ Info: iteration 43, average log likelihood -1.356728
[ Info: iteration 44, average log likelihood -1.356723
[ Info: iteration 45, average log likelihood -1.356717
[ Info: iteration 46, average log likelihood -1.356711
[ Info: iteration 47, average log likelihood -1.356703
[ Info: iteration 48, average log likelihood -1.356694
[ Info: iteration 49, average log likelihood -1.356683
[ Info: iteration 50, average log likelihood -1.356667
┌ Info: EM with 100000 data points 50 iterations avll -1.356667
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4050509316059332
│     -1.4049823602588194
│      ⋮
└     -1.3566667469893563
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.356834
[ Info: iteration 2, average log likelihood -1.356621
[ Info: iteration 3, average log likelihood -1.356174
[ Info: iteration 4, average log likelihood -1.352602
[ Info: iteration 5, average log likelihood -1.339276
[ Info: iteration 6, average log likelihood -1.324508
[ Info: iteration 7, average log likelihood -1.317718
[ Info: iteration 8, average log likelihood -1.315017
[ Info: iteration 9, average log likelihood -1.313534
[ Info: iteration 10, average log likelihood -1.312554
[ Info: iteration 11, average log likelihood -1.311740
[ Info: iteration 12, average log likelihood -1.310853
[ Info: iteration 13, average log likelihood -1.309710
[ Info: iteration 14, average log likelihood -1.308261
[ Info: iteration 15, average log likelihood -1.306761
[ Info: iteration 16, average log likelihood -1.305591
[ Info: iteration 17, average log likelihood -1.304788
[ Info: iteration 18, average log likelihood -1.304201
[ Info: iteration 19, average log likelihood -1.303708
[ Info: iteration 20, average log likelihood -1.303232
[ Info: iteration 21, average log likelihood -1.302720
[ Info: iteration 22, average log likelihood -1.302290
[ Info: iteration 23, average log likelihood -1.302057
[ Info: iteration 24, average log likelihood -1.301920
[ Info: iteration 25, average log likelihood -1.301810
[ Info: iteration 26, average log likelihood -1.301706
[ Info: iteration 27, average log likelihood -1.301589
[ Info: iteration 28, average log likelihood -1.301410
[ Info: iteration 29, average log likelihood -1.301050
[ Info: iteration 30, average log likelihood -1.300372
[ Info: iteration 31, average log likelihood -1.299530
[ Info: iteration 32, average log likelihood -1.298925
[ Info: iteration 33, average log likelihood -1.298650
[ Info: iteration 34, average log likelihood -1.298542
[ Info: iteration 35, average log likelihood -1.298497
[ Info: iteration 36, average log likelihood -1.298477
[ Info: iteration 37, average log likelihood -1.298466
[ Info: iteration 38, average log likelihood -1.298461
[ Info: iteration 39, average log likelihood -1.298457
[ Info: iteration 40, average log likelihood -1.298455
[ Info: iteration 41, average log likelihood -1.298453
[ Info: iteration 42, average log likelihood -1.298451
[ Info: iteration 43, average log likelihood -1.298450
[ Info: iteration 44, average log likelihood -1.298450
[ Info: iteration 45, average log likelihood -1.298449
[ Info: iteration 46, average log likelihood -1.298448
[ Info: iteration 47, average log likelihood -1.298448
[ Info: iteration 48, average log likelihood -1.298447
[ Info: iteration 49, average log likelihood -1.298446
[ Info: iteration 50, average log likelihood -1.298446
┌ Info: EM with 100000 data points 50 iterations avll -1.298446
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3568337278388407
│     -1.3566210598672814
│      ⋮
└     -1.2984459108710715
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.298662
[ Info: iteration 2, average log likelihood -1.298421
[ Info: iteration 3, average log likelihood -1.297501
[ Info: iteration 4, average log likelihood -1.286956
[ Info: iteration 5, average log likelihood -1.253510
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.225322
[ Info: iteration 7, average log likelihood -1.219311
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.201560
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.214148
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.215941
[ Info: iteration 11, average log likelihood -1.211311
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.198904
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.200466
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.201880
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.208203
[ Info: iteration 16, average log likelihood -1.208174
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.196194
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.197364
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.198997
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.206063
[ Info: iteration 21, average log likelihood -1.205716
[ Info: iteration 22, average log likelihood -1.192962
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.183195
[ Info: iteration 24, average log likelihood -1.220576
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.200445
[ Info: iteration 26, average log likelihood -1.199906
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.188643
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.209957
[ Info: iteration 29, average log likelihood -1.206379
[ Info: iteration 30, average log likelihood -1.193057
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.184067
[ Info: iteration 32, average log likelihood -1.218929
[ Info: iteration 33, average log likelihood -1.199069
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.188511
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.194155
[ Info: iteration 36, average log likelihood -1.212499
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.195379
[ Info: iteration 38, average log likelihood -1.199046
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.188173
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.197772
[ Info: iteration 41, average log likelihood -1.210418
[ Info: iteration 42, average log likelihood -1.194526
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.185818
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.209779
[ Info: iteration 45, average log likelihood -1.203948
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.190544
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.195961
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.203387
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.200124
[ Info: iteration 50, average log likelihood -1.200792
┌ Info: EM with 100000 data points 50 iterations avll -1.200792
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2986618469156723
│     -1.298421445519788
│      ⋮
└     -1.200792247571812
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.189868
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.183305
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.186927
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.162380
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.137066
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.129101
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.130165
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│     11
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.117387
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.121487
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.113627
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.130379
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.119816
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     11
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.114447
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.111986
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.136033
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.123296
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.117294
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.103728
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     20
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.123396
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.132645
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.120908
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.106237
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.123294
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.108130
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.120356
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.099554
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.117700
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.106993
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.111130
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.096282
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.116674
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.106385
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.110842
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.096120
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.116654
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.106358
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.110831
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.096112
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.116651
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.106356
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.110829
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.096110
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.116649
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.106355
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.110827
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.096109
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.116648
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.106354
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.110825
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.096108
┌ Info: EM with 100000 data points 50 iterations avll -1.096108
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1898675941591326
│     -1.1833045399154707
│      ⋮
└     -1.0961084168145667
32×26 Array{Float64,┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4376984287317585
│     -1.4377904524093168
│     -1.437704287042289
│     -1.4372575481648906
│      ⋮
│     -1.1063542415741026
│     -1.1108253177268428
└     -1.0961084168145667
2}:
  0.205413     -0.0150815   -0.477615    0.0321409    0.0495818    0.0816691    0.00271161  -0.1266      -0.0591234    0.0425262    0.065287    -0.182955    -0.0508369     0.106222     0.0145806   0.0111635    0.00579519   0.0819469  -0.0528489   -0.0533987     0.0452608    0.0466918    0.197292    -0.120733     -0.0632998   -0.201478
 -0.241921     -0.0256113    0.506914    0.0260925    0.0495022   -0.268615     0.050454    -0.111298     0.15225      0.0408435    0.0234797   -0.182103    -0.0812941     0.0581589    0.177708    0.0114337   -0.190163     0.37315    -0.0513675   -0.0332156    -0.0524536    0.0702496    0.36488     -0.110523     -0.0617395   -0.150396
  0.185004     -0.175748     0.0440771   0.230188     0.123748    -0.0812822    0.0598176    0.11405      0.140556     0.139018    -0.0421276   -0.121139    -0.111762      0.15313     -0.0360163   0.0171546    0.0593794   -0.223879   -0.234286     0.0144879    -0.0752305    0.0985639   -0.0495703   -0.000188448  -0.114058    -0.185203
  0.0788817     0.182487     0.0624692   0.0731512   -0.0676954   -0.0989454   -0.0252423   -0.214191    -0.206002    -0.173894     0.0997774    0.076433     0.0213094     0.0453276    0.0170504   0.0145006    0.10233     -0.106201   -0.028364    -0.0205077    -0.14191     -0.00949333   0.132732    -0.119962      0.0594732    0.125286
 -0.0210931     0.164112     0.112941   -0.108177    -0.17984     -0.116587     0.00723639  -0.0103991   -0.00797098   0.147984     0.101949    -0.121072    -0.116217     -0.172413     0.17334     0.0117879   -0.159851    -0.246376   -0.123534    -0.0487109     0.0879002   -0.213161     0.0458543    0.0299626     0.0435321   -0.0901694
 -0.0305332     0.138408    -0.0117154   0.0361459   -0.239785    -0.0442681    0.0214109   -0.00778965   0.0830351    0.0270812    0.129665     0.124281    -0.165693     -0.191455     0.166009    0.0237074    0.167287     0.470972   -0.0484688   -0.198911     -0.0274342    0.0669278   -0.208426     0.0309991     0.0606786   -0.134213
 -0.0630121     0.0302527    0.0868081   0.00262239  -0.0724409    0.162549    -0.0850463   -0.04621      0.0366061    0.0830253   -0.0853738   -0.0797973    0.0320342     0.0501059    0.0974791  -0.0268762   -0.0995551    0.0440522  -0.0821148    0.0054987     0.188008     0.0143264   -0.00354057   0.0906776    -0.0416222    0.0321157
 -0.0667333     0.070616     0.0507317   0.164007    -0.0144983   -0.109069    -0.122721     0.11626      0.0768923    0.0100998    0.135509    -0.00803118  -0.0764973     0.0109881   -0.0189512  -0.0203995    0.24685     -0.0553669  -0.0703576   -0.082922      0.0746612   -0.0408992    0.00438556  -0.189098      0.00128163   0.139616
 -0.0695985    -0.159914     0.0589923  -0.193776    -0.0332362    0.00726462   0.0151644   -0.0253171   -0.0714591    0.109298     0.10032     -0.128035    -0.00543569   -0.0659839   -0.0616516  -0.0639006    0.197188     0.115709    0.0385956   -0.137951     -0.0555922   -0.060562     0.0228525    0.0335802    -0.0789916    0.0440785
 -0.00403959   -0.0208579    0.065254   -0.110968     0.0482986    0.0178959    0.202917    -0.0347193   -0.0170923   -0.218383    -0.116331    -0.141901    -0.0766326    -0.0815681    0.148507   -0.156088    -0.0802539   -0.189511   -0.0977186    0.058705      0.0419407    0.0293145    0.0405362   -0.0318323     0.0777276   -0.0417017
 -0.110169      0.0382358    0.112351    0.0368336    0.0374384    0.00353182  -0.0342842   -0.00323481   0.0267705    0.0505499   -0.0254661    0.0847522    0.106115      0.00175222  -0.0201641  -0.0921189    0.0701785   -0.027134   -0.046366     0.0205442     0.0282358   -0.0703199   -0.106935     0.0159148    -0.0950559    0.0315378
  0.0185677    -0.108839    -0.019858    0.0353096   -0.00129129  -0.044638    -0.0202451    0.06003     -0.0619408   -0.154251     0.0190484    0.00104098   0.06461      -0.0743234    0.0533762  -0.052699    -0.0733596    0.0239768  -0.0742602    0.070559      0.0554607    0.0344854   -0.0222584   -0.00159462   -0.00422948  -0.0115419
 -0.0284571    -0.1669      -0.12832    -0.0289435   -0.0411613   -0.00448669   0.211878    -0.0782484    0.0360672   -0.248721    -0.00768548  -0.0276695    0.193016      0.00901891  -0.0563994  -0.0531363   -0.0718663   -0.0145589  -0.151413    -0.119804     -0.0137244    0.101828    -0.181437    -0.0465549    -0.00266217   0.103098
  0.0780292     0.0803053   -0.149836    0.0855262    0.101555    -0.0543978   -0.00365894  -0.0846773   -0.234785    -0.0358734   -0.135187    -0.206916     0.0478669    -0.00902941   0.0321327  -0.00694525  -0.135633    -0.128681    0.118179    -0.0126926     0.154753    -0.0266197   -0.166505     0.0386744     0.0798257    0.0666646
  0.100054      0.00453298   0.0137372   0.102919     0.0221787   -0.0476146    0.00727101  -5.72965e-5   0.182527    -0.0586157   -0.153532    -0.0967312   -0.0453667    -0.0711451   -0.0405029   0.0270824    0.0586041   -0.0664127  -0.136593     0.0246969    -0.0701902   -0.0705263   -0.143288     0.0133266     0.0737514    0.024726
 -0.0433587     0.0094478    0.0571961  -0.0937116    0.0609918    0.0814336    0.011794     0.0396789    0.0683352    0.044001    -0.0216962   -0.0512386    0.0219019     0.184779     0.101506    0.0480518   -0.0886643   -0.0159492  -0.0914354   -0.0202482    -0.00678708  -0.0457565    0.0884314    0.0841574    -0.0165384    0.0120835
 -0.124008      0.155599    -0.111907   -0.0104965   -0.0769326   -0.204132    -0.00910153  -0.241946    -0.364563     0.0030347   -0.106934    -0.130416     0.141507     -0.119793    -0.191727   -0.0238384   -0.116109     0.053818    0.0972096   -0.143197      0.0238266   -0.251894    -0.735948    -0.0028116     0.127246     0.0172073
 -0.126265      0.146507    -0.114031   -0.0137445   -0.0720089   -0.0387308   -0.022287     0.10183     -0.0143292    0.00114668  -0.107218    -0.130473     0.0899319    -0.120139     0.0835302  -0.160043    -0.0647814    0.0486676  -0.122676    -0.143075      0.0212538   -0.0833276    0.863907     0.00209426    0.229395     0.00593146
 -0.00383247    0.220274     0.102906   -0.0414162    0.0297386   -0.184975    -0.239432     0.0262565   -0.0586419    0.0560954    0.0310577   -0.00525518   0.0488116     0.176127     0.0926094   0.0716447   -0.146238    -0.0455006  -0.00479625  -0.100735     -0.0317919    0.0993279   -0.165439     0.100612      0.0412354   -0.0691313
  0.0604421    -0.0276948    0.042574   -0.0964982    0.0688068   -0.0229741    0.0229074    0.127136    -0.0387064    0.00800469   0.0519887    0.0588386    0.0686854    -0.204275    -0.0429606  -0.136904    -0.0183979   -0.0102907   0.014594    -0.0526578     0.22514      0.309685     0.0634975   -0.108327      0.0497269    0.0123754
 -0.000204052   0.11807     -0.0520361  -0.0224844    0.268575    -0.0662827   -0.0792555    0.0954287    0.0142727    0.0531218    0.0568867    0.142367     0.0353394     0.0337467    0.097991   -0.066111     0.0891575   -0.06819    -0.00599267   0.103391     -0.0324708   -0.182602     0.108524    -0.0414577     0.0419481   -0.142009
 -0.097098     -0.0636961    0.110998    0.0405366    0.114611    -0.12648      0.0840968    0.0251961    0.00993822   0.0486896    0.00340769   0.0809794    0.076417      0.110502    -0.0254535   0.0293049    0.100297     0.235278    0.00384157   0.000382551   0.0548492    0.0645142   -0.113431     0.0258403    -0.0316663    0.0466006
  0.381252     -0.0434437   -0.0899269  -0.151058    -0.00934227  -0.523463    -0.300058     0.0346482    0.158589    -0.170791     0.0598609    0.0525239    0.0465271     0.209805    -0.0676722  -0.163832     0.0145916   -0.0345994  -0.30075     -0.0659226    -0.160141    -0.015736    -0.145376    -0.0653333    -0.117312    -0.0533755
 -0.10563       0.0492151   -0.045075    0.300252    -0.0160426    0.187055     0.273603     0.0355985   -0.0151383   -0.0139046    0.0605151    0.177284     0.0515816    -0.357716    -0.0684259   0.0784394   -0.23269     -0.0300346   0.335088    -0.0294736    -0.0939797   -0.0171525   -0.134209    -0.0682232     0.0392847   -0.0879789
 -0.172167      0.0476961   -0.0699787   0.021113    -0.0864963    0.0746321    0.0911607   -0.0136904    0.0157978   -0.153996     0.212633     0.0844055    0.000282032  -0.0793192   -0.0682178   0.0381918    0.073159     0.074777   -0.154486     0.0300403     0.00584387   0.0210051   -0.0976863   -0.147628     -0.00953932  -0.0425266
 -0.00199824   -0.0213428    0.105513   -0.122819     0.0128819   -0.055628    -0.101873     0.0428912   -0.0154833    0.0183809    0.0844872   -0.0221205    0.0187441    -0.0833296    0.124485    0.0193013    0.0872507    0.0672753   0.0132979    0.0197131     0.0118186   -0.0734246   -0.00497586   0.0138992     0.0946832   -0.0837401
 -0.250656      0.065798     0.0488459   0.015429     0.0756552   -0.115438     0.0407893   -0.0170961   -0.177962     0.0133492    0.103359    -0.24399      0.0754779     0.171302    -0.16597    -0.280929     0.126106    -0.0524899   0.04539      0.117611     -0.0705053    0.0379107   -0.095908    -0.0165991    -0.330372     0.00124844
  0.0888446     0.138578    -0.106299    0.0719466    0.027936    -0.259732     0.058834     0.021394    -0.0931362    0.0177685    0.0433183   -0.210176     0.0756241     0.154422     0.243657   -0.267503     0.0701198    0.0938586   0.0751305   -0.270425     -0.0222574   -0.0871994   -0.0499156   -0.0165397     0.130715     0.00808246
 -0.0312191     0.0154498    0.0331317   0.0412108    0.0573888    0.026686     0.040418     0.0587493   -0.0424644   -0.0939387    0.0868781   -0.0210705   -0.0880176     0.0284442    0.0221132  -0.28937     -0.135022    -0.044892    0.0218201    0.083211     -0.0584947   -0.0548899   -0.00619938  -0.0490763    -0.106721     0.0133972
 -0.0158055     0.0911151    0.0562252   0.162086     0.0593621    0.203252     0.0337368    0.105931    -0.00636339  -0.0196651    0.020619    -0.161668     0.0158626     0.15185      0.0658405  -0.201241    -0.0418939    0.137115    0.0555235   -0.0885815    -0.103567    -0.108051    -0.00182869  -0.0518348     0.164324    -0.0761357
  0.0686852     0.195586     0.155474   -0.985703     0.216715     0.0380306   -3.18191e-5  -0.0697021    0.0271773   -0.0194157   -0.108051     0.00906049   0.0608676     0.0687014    0.203668    0.0552444   -0.0239625    0.394677    0.179692     0.0232124    -0.00299179   0.0108669    0.080674    -0.0147114     0.0429441    0.135722
  0.117405      0.243298     0.179535    0.452038    -0.165015     0.0572789   -0.219596    -0.0843438    0.0167826    0.00640796  -0.246246     0.00140213   0.079145      0.0721531   -0.0752597   0.0212752   -0.0264905    0.0358837   0.162996     0.0345892     0.070507     0.0768997    0.0341536   -0.0253276    -0.208839     0.101193[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.116646
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.099275
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.095453
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.081980
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.116514
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.099151
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.095444
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.081970
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.116513
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.099150
┌ Info: EM with 100000 data points 10 iterations avll -1.099150
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.314560e+05
      1       7.211145e+05      -2.103416e+05 |       32
      2       6.948704e+05      -2.624410e+04 |       32
      3       6.812179e+05      -1.365250e+04 |       32
      4       6.722894e+05      -8.928440e+03 |       32
      5       6.659707e+05      -6.318753e+03 |       32
      6       6.609931e+05      -4.977577e+03 |       32
      7       6.565834e+05      -4.409717e+03 |       32
      8       6.536346e+05      -2.948817e+03 |       32
      9       6.520820e+05      -1.552536e+03 |       32
     10       6.511523e+05      -9.297732e+02 |       32
     11       6.504738e+05      -6.784087e+02 |       32
     12       6.496754e+05      -7.984391e+02 |       32
     13       6.486096e+05      -1.065814e+03 |       32
     14       6.474201e+05      -1.189462e+03 |       32
     15       6.462389e+05      -1.181263e+03 |       32
     16       6.452611e+05      -9.777213e+02 |       32
     17       6.447312e+05      -5.298975e+02 |       32
     18       6.445268e+05      -2.044669e+02 |       32
     19       6.444431e+05      -8.366967e+01 |       32
     20       6.443874e+05      -5.570001e+01 |       32
     21       6.443530e+05      -3.439886e+01 |       32
     22       6.443328e+05      -2.019056e+01 |       31
     23       6.443199e+05      -1.294995e+01 |       29
     24       6.443084e+05      -1.147620e+01 |       31
     25       6.442986e+05      -9.809734e+00 |       30
     26       6.442919e+05      -6.659122e+00 |       28
     27       6.442854e+05      -6.567352e+00 |       27
     28       6.442758e+05      -9.547310e+00 |       27
     29       6.442599e+05      -1.590274e+01 |       27
     30       6.442405e+05      -1.941126e+01 |       29
     31       6.442100e+05      -3.054222e+01 |       29
     32       6.441780e+05      -3.195939e+01 |       31
     33       6.441385e+05      -3.951607e+01 |       31
     34       6.440693e+05      -6.915478e+01 |       31
     35       6.439541e+05      -1.152001e+02 |       32
     36       6.437584e+05      -1.957000e+02 |       32
     37       6.434809e+05      -2.775116e+02 |       32
     38       6.432443e+05      -2.366498e+02 |       32
     39       6.430659e+05      -1.783567e+02 |       32
     40       6.428981e+05      -1.678557e+02 |       32
     41       6.427621e+05      -1.359907e+02 |       32
     42       6.426184e+05      -1.436643e+02 |       32
     43       6.424993e+05      -1.191334e+02 |       32
     44       6.423886e+05      -1.107008e+02 |       31
     45       6.423051e+05      -8.342318e+01 |       32
     46       6.422313e+05      -7.387584e+01 |       32
     47       6.421678e+05      -6.349075e+01 |       32
     48       6.421151e+05      -5.268483e+01 |       31
     49       6.420704e+05      -4.473447e+01 |       30
     50       6.420339e+05      -3.645974e+01 |       31
K-means terminated without convergence after 50 iterations (objv = 642033.8934621471)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.359725
[ Info: iteration 2, average log likelihood -1.323935
[ Info: iteration 3, average log likelihood -1.285598
[ Info: iteration 4, average log likelihood -1.237708
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.178103
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.154025
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     14
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.140373
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.142349
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│      9
│     10
│     17
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.120508
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.157927
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     14
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.114071
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│     12
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.128355
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      9
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.144565
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.143442
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.110359
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      6
│      9
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.067732
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      8
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.182600
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.168943
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.118706
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│      7
│      9
│     15
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.100186
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     13
│     14
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.133529
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      8
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.154389
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.138597
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      6
│      7
│      9
│      ⋮
│     15
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.080443
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.157902
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.166183
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      8
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.115158
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     15
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.081620
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     13
│     14
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.159127
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.157657
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.119380
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     12
│     15
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.103763
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     13
│     14
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.120070
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     10
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.130650
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     17
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.118307
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     15
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.150202
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     12
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.117145
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│      7
│     13
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.091784
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│      9
│     17
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.134196
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     10
│     15
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.148790
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.137534
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.119407
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│      7
│      9
│     13
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.065244
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      4
│      5
│     10
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.115561
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     12
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.184637
[ Info: iteration 46, average log likelihood -1.170481
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│      9
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.097120
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     12
│     13
│     14
│     15
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.102123
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│     10
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.143708
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.142716
┌ Info: EM with 100000 data points 50 iterations avll -1.142716
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0055357    -0.0383963    0.107989     0.0467681    0.0622194    0.00284485  -0.00865188  -0.0286351    0.00466322  -0.0131608   -0.0965143    0.0205566   -0.0526931     0.149896    -0.00419667   0.037389    -0.0748381    0.039435    -0.179257     0.061504     0.0112095    0.0529254   -0.0168438     0.0287418    -0.0590359     0.00345354
 -0.125269      0.154069    -0.113204    -0.0120879   -0.0744634   -0.113799    -0.0138434   -0.0759994   -0.184746     0.00107253  -0.105133    -0.128425     0.113542     -0.115815    -0.0537251   -0.0908133   -0.0911055    0.0494482   -0.00321853  -0.141005     0.0257386   -0.161263     0.0579783     0.000263961   0.173658      0.0175403
 -0.00450783   -0.00954954   0.0901604    0.0108353    0.0359533   -0.0429834   -0.096464     0.10713     -0.00488362   0.0517277    0.0524561   -0.0353095    0.0300763    -0.137781     0.12709      0.123715     0.0640955    0.12446     -0.0364018   -0.0811888    0.0884799   -0.181551     0.0210641    -0.0669626    -0.0348719     0.0198295
 -0.149676      0.0910119   -0.0674073   -0.22756      0.0213363    0.146824    -0.00671746   0.102583     0.103757     0.199935     0.0656793   -0.0885444    0.158084      0.189594     0.158702     0.0137813   -0.0578943   -0.067676    -0.0538254   -0.0936741   -0.0336701   -0.144479     0.0943191     0.141034      0.0449271     0.0470176
  0.00535411   -0.0319665    0.0440949   -0.155388     0.0141787    0.0229851    0.159834    -0.013934    -0.0308807   -0.224756    -0.0416024   -0.103219    -0.0618749    -0.0808847    0.143343    -0.153035    -0.146855    -0.283652    -0.116901     0.0705252    0.0942671    0.0352492    0.0262125    -0.0452318     0.0736001    -0.0482423
 -0.0960034    -0.0766996    0.04246     -0.0101515    0.232586    -0.203996     0.0383711    0.0718663    0.0197739    0.0357155   -0.0363544    0.158184     0.106553      0.0970455    0.0129969    0.0207691    0.125067     0.183576     0.114566    -0.0635439    0.047794     0.0115269   -0.121458      0.00209923   -0.144164      0.0162727
 -0.201633      0.0442774   -0.07299      0.0366184   -0.101005     0.075237     0.0910452   -0.0248576    0.0142171   -0.162445     0.217563     0.0750953    0.00986933   -0.0664595   -0.0659534    0.040944     0.0782052    0.0673101   -0.14772      0.0184941   -0.00761979   0.012716    -0.111861     -0.147432     -0.0238401    -0.0552599
  0.0762871     0.0800667   -0.150177     0.0853342    0.100031    -0.0530419   -0.00259398  -0.0846895   -0.234641    -0.0367917   -0.135399    -0.206632     0.0483398    -0.00918249   0.0313648   -0.00724887  -0.135929    -0.127052     0.117782    -0.0126674    0.154121    -0.0269079   -0.166517      0.0386549     0.0800062     0.0666105
  0.135834      0.00245007  -0.0689662    0.0735645   -0.0119109   -0.162078    -0.010117     0.0349802    0.0717198   -0.094292     0.0608958    0.115311     0.0499343    -0.0752049   -0.0687136   -0.0393156   -0.10795     -0.0318311    0.0197458   -0.0495736   -0.125123    -0.0157613   -0.13897      -0.0663989    -0.0407816    -0.0690806
 -0.0431517     0.0428836    0.0920418   -0.0113451   -0.0418993    0.144252    -0.0571048   -0.0720299    0.0131908    0.0380042   -0.0678265   -0.0725554    0.000937642   0.0253458    0.129404    -0.0485944   -0.223822     0.0516792   -0.107822     0.0227692    0.246784     0.0258744    0.0184277     0.111387     -0.0210305    -0.0260911
 -0.0673163    -0.150699     0.0555473   -0.185975    -0.0257768    0.0125843    0.0326509   -0.0277053   -0.0708907    0.065891     0.0768629   -0.120766    -0.0025254    -0.0653431   -0.0272141   -0.0703852    0.197068     0.0980655    0.0202729   -0.120138    -0.051104    -0.0551061    0.0217583     0.0279041    -0.0626368     0.0352309
 -0.00181769    0.00710597   0.0650119   -0.120358     0.0197771    0.0537748    0.0507798    0.102168     0.0122655   -0.070187     0.033531     0.00120703   0.0446337    -0.124518     0.0294989   -0.11424      0.0471289    0.0191775   -0.0121279   -0.0654937    0.178303     0.235009    -0.00741886   -0.226969      0.0127504    -0.0582236
 -0.000654907   0.0261019   -0.0517833    0.215205    -0.0446842   -0.100415    -0.205718     0.0530788    0.0935078    0.0566073    0.142874    -0.0405324   -0.0979024     0.0223693   -0.0397155   -0.0697722    0.15439     -0.106043    -0.0978432   -0.0373691    0.0774589   -0.0886942   -0.100966     -0.136764     -0.0952071     0.206438
  0.00352317    0.108964    -0.0681662   -0.036476     0.240795    -0.0549424   -0.0469842    0.09376      0.0132482    0.0195121    0.0400785    0.114301     0.0213888     0.0186194    0.0972372   -0.0780246    0.0701306   -0.0726391   -0.0105824    0.109286    -0.0437431   -0.167773     0.0873299    -0.0403791     0.045411     -0.157728
  0.00398006   -0.0523465    0.122055    -0.361136    -0.0200592   -0.0800929   -0.150775    -0.0675519   -0.0273889   -0.0134184    0.124437    -0.0202499   -0.0318031    -0.0135864    0.138489    -0.0696207    0.120243     0.0223383    0.0237549    0.212414    -0.125302     0.0184731   -0.0631427     0.145561      0.28668      -0.209791
 -0.151052      0.0879643    0.178238     0.07757      0.024258    -0.0393897    0.0156221    0.153201     0.0268747   -0.0489396    0.0466231   -0.0097801   -0.0197591     0.0147908    0.0391705    0.0298949    0.248768    -0.00941373  -0.0395056   -0.0840055    0.109976     0.0365835    0.146504     -0.169202      0.108108      0.0156832
  0.0301473    -0.0636328   -0.156883     0.0298374   -0.045782    -0.00500407  -0.122081     0.114214    -0.0565516   -0.233933     0.149605    -0.0200469   -0.027379     -0.0516561    0.0961643    0.0563485   -0.0921826    0.208976    -0.182016     0.00670298   0.215571     0.0380612    0.00966389    0.0232353     0.0659746    -0.0947784
  0.186953     -0.176102     0.0432081    0.224323     0.123328    -0.0838771    0.0596263    0.112778     0.140155     0.141427    -0.0412775   -0.12165     -0.103373      0.16232     -0.037122     0.0164002    0.0605558   -0.228676    -0.234823     0.0101344   -0.0785149    0.0970015   -0.0519475     0.00373039   -0.114497     -0.187476
 -0.0918913    -0.0355837    0.158273     0.0807997    0.0194543   -0.0533271    0.119533    -0.0165329   -0.00638518   0.0596094    0.0375773   -0.00121952   0.0347054     0.115318    -0.0536986    0.0326491    0.0727258    0.259906    -0.0861182    0.0540695    0.0559177    0.105056    -0.0921737     0.0447859     0.070574      0.070057
  0.02849       0.031488     0.0651464    0.0683711   -0.0240272   -0.0798708    0.0158813   -0.0932858   -0.119134    -0.128936     0.00407683   0.0372976    0.0821802    -0.0229637    0.0263254   -0.0544804    0.027233    -0.0714198   -0.021547     0.0441466   -0.0791389    0.00990605   0.0371934    -0.0639836    -0.000464058   0.091869
 -0.0167438     0.0908787    0.0513052    0.16735      0.0514729    0.198273     0.0249121    0.105598    -0.0114891   -0.0208864    0.0187931   -0.164736     0.0262043     0.148086     0.0707572   -0.195624    -0.043853     0.151336     0.0482059   -0.0922484   -0.106804    -0.108052     0.000854213  -0.0460569     0.165248     -0.0779741
 -0.0560169     0.108674    -0.0373287    0.0502305    0.0510922   -0.19698      0.0505893    0.00462298  -0.127237     0.0149695    0.0683702   -0.22324      0.0757306     0.161984     0.0726961   -0.272669     0.0909467    0.0284529    0.0586629   -0.0991663   -0.0424763   -0.0353546   -0.067468     -0.0162055    -0.0595771     0.00472858
 -0.0305567     0.0168167    0.0322811    0.0418884    0.0580161    0.0273883    0.0402065    0.0588794   -0.0426112   -0.0933347    0.0867161   -0.0217458   -0.0869375     0.0284526    0.0222464   -0.288514    -0.134878    -0.0441516    0.021565     0.0824715   -0.0587301   -0.0548367   -0.00433884   -0.0470583    -0.106628      0.0132565
  0.102616      0.0100312    0.00330229   0.0714242    0.022934    -0.0251241    0.00322134   0.0063091    0.179423    -0.0410082   -0.133078    -0.0973352   -0.019493     -0.0723157   -0.0103196    0.0275585    0.053308    -0.0661449   -0.1201       0.00579577  -0.0742912   -0.0795867   -0.116246      0.0177544     0.0585859     0.0248667
 -0.0184936    -0.23948     -0.122996    -0.0208555   -0.066209    -0.0301652    0.189165    -0.0691887    0.0331207   -0.395347    -0.00323803  -0.0287196    0.187841     -0.0161515   -0.0543968   -0.058488    -0.067507    -0.0121757   -0.154904    -0.122179    -0.0173745    0.179352    -0.161551     -0.0488431    -0.00179552    0.117887
 -0.124827      0.0129768   -0.0808032    0.060315     0.00814544  -0.00734261  -0.257117    -0.00802592  -0.0962483    0.0829061   -0.0418916    0.0830658    0.112141      0.0287505   -0.0216931   -0.140058     0.115386     0.0247154   -0.159913     0.0786415   -0.0626685    0.0497444   -0.103675      0.032869     -0.0172473     0.0258259
 -0.017907     -0.0272433    0.0170819    0.0237762    0.0408535   -0.0765654    0.0144233   -0.125766     0.0407209    0.0375837    0.0289398   -0.168177    -0.054705      0.0783534    0.102607     0.0101423   -0.091787     0.248801    -0.0563652   -0.0383632    0.00871547   0.0529049    0.269526     -0.100154     -0.0630407    -0.158446
 -0.0835664     0.0185252    0.308969    -0.00765165   0.056733     0.0354027    0.212752     0.0146415    0.128984    -0.0545194    0.0117981    0.0411586    0.0673076    -0.0471019    0.00511154  -0.0826473    0.0135746   -0.0904499    0.110547    -0.0489262    0.107379    -0.203804    -0.0913893     0.025979     -0.101864     -0.0188841
  0.0591851    -0.00807737   0.0419451   -0.0955932    0.0613172    0.0119209    0.0498873    0.134198    -0.0211122   -0.00439516   0.0607157    0.0607047    0.0727167    -0.198101    -0.0367672   -0.138862    -0.0112731   -0.0125397    0.013344    -0.0533451    0.216817     0.273295     0.0593347    -0.108091      0.0644328     0.01258
  0.0906558     0.211888     0.163506    -0.227723     0.00979127   0.0474615   -0.119376    -0.0752063    0.0209873   -0.00719436  -0.173763     0.00355418   0.0724256     0.0684188    0.0633495    0.0387083   -0.0257628    0.199372     0.157578     0.0277273    0.0339245    0.0416655    0.0576439    -0.0202894    -0.0845751     0.11409
 -0.00333931    0.219022     0.0983065   -0.0427171    0.0306726   -0.181662    -0.236507     0.0307743   -0.0566451    0.0549622    0.0347297   -0.00371201   0.0486874     0.169578     0.0944441    0.0718229   -0.15294     -0.0465416   -0.00125056  -0.0956139   -0.0270666    0.102262    -0.164294      0.0949379     0.0437112    -0.0676679
 -0.0253848     0.153838     0.0485542   -0.0370337   -0.212137    -0.0793148    0.0149932   -0.00883999   0.0386039    0.0913894    0.115825    -0.00312662  -0.139239     -0.180199     0.169501     0.0174031    0.00118578   0.103741    -0.0839545   -0.122394     0.0327291   -0.07699     -0.0786597     0.0306259     0.0516251    -0.114716[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.141274
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│      7
│     12
│     13
│     15
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.063312
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.041289
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      6
│      7
│      8
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.097050
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│     12
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.081052
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.041846
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│     17
│     19
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.078466
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      6
│      7
│      8
│      ⋮
│     15
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.068101
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.062161
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      6
│      7
│     12
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.072956
┌ Info: EM with 100000 data points 10 iterations avll -1.072956
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.178194     0.0531572    0.190266     0.0391909   -0.160162    -0.122773     0.0154377   -0.0397835   -0.141448   -0.133344     0.0166121    -0.114112    -0.0371016   -0.0260243    0.0273246     0.0414141   -0.0760798    0.010015    -0.0857797   -0.0674103    0.170433     0.0630339    0.0600078   -0.0406712    0.0306836    0.0310414
  0.0396922   -0.0471635   -0.157481    -0.0609914   -0.00146885  -0.0176246    0.0281388    0.15235      0.0303291   0.0736776   -0.130386     -0.0281846    0.256251     0.0720421    0.0449759    -0.0283446   -0.0271545    0.0328374    0.0251106   -0.0159738   -0.00844643   0.0682709   -0.00174643  -0.227818    -0.0777798   -0.0381298
 -0.0210006   -0.0190272   -0.097623     0.0416771    0.114602    -0.057552     0.00387637   0.0574389    0.0848201  -0.0123276   -0.0774623     0.0155903    0.0854653   -0.0160282   -0.176348     -0.0553426    0.0407628   -0.214048     0.00142083  -0.0563038    0.110714    -0.0444382    0.0312743   -0.226178    -0.102062    -0.0117863
 -0.138686     0.0865593    0.0260156   -0.0291046    0.186626    -0.0310913    0.176261    -0.0515372   -0.0646449  -0.142162     0.00191952   -0.00735145  -0.0819145   -0.0109755    0.0306377     0.104137     0.0526477    0.0442132    0.125518     0.02275     -0.103275     0.0723598   -0.215719    -0.0768937    0.0840164   -0.0445938
 -0.0914475   -0.0935117   -0.0795448   -0.0644651   -0.116009     0.0650399   -0.0084743    0.150681     0.111223    0.151415    -0.0317998     0.00504523  -0.0896533    0.060163    -0.05702      -0.0409478    0.00553642   0.0344866    0.0521405   -0.0969306    0.0645064    0.0259109   -0.0682345   -0.0691513   -0.119426     0.0974268
 -0.0517266   -0.0969013    0.0397408    0.0348549   -0.0829102    0.168343    -0.0136802    0.118935    -0.0642448   0.0205287   -0.106343      0.0175561    0.0329184    0.053481    -0.0819338     0.04588      0.0311776    0.126208    -0.0523594    0.103255    -0.17304      0.0160775    0.0224237    0.0170928    0.025884    -0.0489222
 -0.022145     0.00390698   0.0508621   -0.0389012    0.160226    -0.031501     0.146579     0.0464136   -0.174338    0.0135398    0.0709765     0.0665867   -0.0273181    0.0198477    0.0360263    -0.0295032   -0.0509103   -0.0199178   -0.0167081    0.0215857   -0.1131       0.0417472   -0.058362     0.0435343   -0.02801      0.00584927
  0.0582087   -0.00722607   0.127879    -0.0356024    0.0160008    0.151434     0.0722118    0.109339    -0.0121798   0.15574      0.120444      0.0111698    0.0483246   -0.0659317   -0.0828068    -0.0308533    0.028908    -0.0812668   -0.00938595  -0.0419361   -0.0483313   -0.157258     0.0369266   -0.12764     -0.0662526    0.000807005
 -0.11882      0.144668    -0.0865024   -0.110074     0.109521     0.00183706  -0.0268459    0.00448708   0.0395721  -0.0994111    0.0330886     0.0301689   -0.0598832    0.0163166    0.0856007    -0.0424469   -0.0882082   -0.141516     0.184125     0.0618118   -0.123894     0.0478158    0.0211353    0.0360323   -0.00791093   0.0857081
  0.0110565    0.0890439   -0.0594577    0.0869537   -0.0124549    0.146787     0.0978946    0.114489     0.0461945  -0.173134     0.118474     -0.0182154   -0.061904     0.00338968  -0.14633      -0.0252201   -0.0861966    0.130007    -0.233036     0.00728967   0.0573896    0.0756112   -0.0450706   -0.108124    -0.0331902    0.1478
  0.0223675   -0.0253049   -0.0700247   -0.0798338   -0.0649669   -0.0976283    0.0134619    0.0853522   -0.0392557  -0.106428     0.0666642     0.0275923   -0.0478622   -0.05211      0.00372446    0.0448727    0.0260021   -0.369332    -0.070816     0.103378    -0.0031978    0.174257    -0.0467881   -0.057089    -0.114548    -0.0325781
 -0.168613    -0.0311883    0.0247144    0.012546    -0.0597889    0.0507499    0.0411891    0.00955968  -0.0887311  -0.0651889   -0.104694     -0.0455361    0.129566    -0.164471    -0.0262853     0.0407108   -0.0793934    0.0340314   -0.017749    -0.0837957   -0.0139139   -0.0368464   -0.0711721    0.00230891  -0.0623862   -0.0305417
  0.153547    -0.017015    -0.122946     0.0423353    0.0533833   -0.0090683   -0.129981     0.246291     0.207801   -0.155604    -0.00518482   -0.137639    -0.138739    -0.106377    -0.131747     -0.0687273   -0.0648108    0.0439844   -0.0528646   -0.0948395   -0.0212492   -0.00701995   0.0609809   -0.0247718    0.142928     0.0190752
 -0.192041     0.0849137    0.235702     0.0664424   -0.0294268    0.0359693    0.203645    -0.019717    -0.0642029  -0.0846344   -0.0918366     0.0862341   -0.0436927   -0.047036    -0.0189354    -0.1909       0.116072     0.151331    -0.012645    -0.102085     0.0884263   -0.147386     0.00854492  -0.0899759    0.176541    -0.189662
  0.0701251    0.154072    -0.0280971   -0.0276226   -0.114285    -0.00840579  -0.0508195    0.109762    -0.0847196   0.0811886   -0.0740601     0.0322376    0.0359955   -0.0697126    0.0378823    -0.059176    -0.0669474   -0.0858224    0.111117    -0.133996     0.0108093   -0.0388993   -0.0318263    0.0367525   -0.10269     -0.0195664
  0.0709532   -0.121084     0.033948     0.0480605   -0.0869336   -0.171903     0.126485    -0.0103779    0.110482   -0.0822051    0.199595     -0.0846449   -0.0290624    0.0582552    0.00996667   -0.100585     0.174556     0.0758639   -0.063879     0.108844    -0.0854077   -0.0821953    0.0594724   -0.0199487    0.0646263    0.00358917
  0.136806     0.0882898    0.157814    -0.0808764   -0.0582716   -0.0861929   -0.0247166   -0.0314278   -0.115711   -0.0419427    0.0615037    -0.0871611    0.0295788   -0.0718716    0.113241      0.0458549    0.0194224   -0.00832594  -0.0759253   -0.0395625   -0.0968793   -0.0455653   -0.252705     0.12081     -0.0389744    0.0194087
 -0.131392     0.12083     -0.217176    -0.193479    -0.031307    -0.110031     0.0140244    0.0219196   -0.0816249   0.0224264   -0.0117963     0.0187086    0.15821      0.0983523   -0.186939      0.0165791   -0.021244    -0.0569838   -0.127836     0.0620312    0.0174404   -0.189037    -0.130295    -0.252109     0.101225    -0.0947189
 -0.0770104    0.057558     0.0968906   -0.094246     0.0583118   -0.0468428   -0.0439503   -0.0785877    0.142488   -0.175124     0.101055      0.0131069    0.209634     0.0444696   -0.079343     -0.0748302    0.0107844    0.0227622   -0.278738     0.21979     -0.0737217   -0.0311369   -0.00178256  -0.040237     0.0743922    0.106804
  0.00932552   0.126503    -0.101561    -0.139782    -0.189634     0.0789288    0.0297107    0.0386816   -0.0520234   0.281229    -0.0397842     0.179998     0.0152989    0.00681749  -0.0367291     0.141343    -0.0399944    0.0286273   -0.0153715   -0.0972773    0.102174     0.0920991   -0.1638       0.24567      0.040984     0.0346251
  0.0443407   -0.0705425   -0.118927     0.190037     0.110829    -0.0264912   -0.0145788    0.0335394    0.0506381  -0.299341    -0.180086      0.0175988   -0.0291771    0.0473815   -0.0104601    -0.0385395    0.184245    -0.112318     0.145091    -0.175772    -0.124584     0.00657335  -0.0903435   -0.0374711    0.173643    -0.055256
  0.0707146   -0.147297     0.164276    -0.0651969    0.0231812   -0.0744659    0.0896769   -0.0926679   -0.0742588   0.108781    -0.00774956    0.00717857   0.0117433    0.04373     -0.0709781     0.00486745  -0.0208292    0.00313142  -0.00783427  -0.119835     0.0528417   -0.179174     0.18612     -0.035727     0.130246     0.110812
  0.0395139   -0.0377054    0.0114119   -0.102653    -0.0499869   -0.0293285    0.119065    -0.166497     0.0119293  -0.0647808    0.2361       -0.0534211   -0.115206    -0.00465198   0.00620415    0.041443    -0.0155249   -0.00201252  -0.193468    -0.102477    -0.053959    -0.0532537   -0.0179094   -0.0849357    0.0482292    0.0506772
 -0.0554736   -0.0215903   -0.00568051  -0.0766415   -0.217375     0.0159963    0.0410521    0.154487    -0.0798334   0.00865332   0.128735     -0.0734379   -0.150781     0.0504941   -0.0158248    -0.024714    -0.13707     -0.0388611    0.00396795   0.0507016    0.0865881   -0.227539     0.0911116   -0.0864203   -0.0952393    0.108328
  0.0172417    0.173696     0.0543984   -0.20667      0.333189    -0.0975948    0.0936887   -0.120311    -0.165534    0.105948    -0.000788909   0.0513791   -0.103467     0.0956111    0.0477992    -0.00889401  -0.0108432    0.143317     0.0942107    0.0101327   -0.150383     0.0119503    0.0428785    0.14387      0.0262721    0.0502365
  0.366169    -0.154461     0.171304     0.0173351   -0.0172654   -0.0818826    0.0907513    0.0525431    0.0196796  -0.124524     0.042749     -0.0331064   -0.0553783   -0.0220175   -0.0346138    -0.0788974    0.0370767    0.00828461  -0.108249     0.227004    -0.165575     0.201261    -0.00927542  -0.112061    -0.0971958    0.0456426
 -0.176069    -0.038518    -0.130655     0.00680062  -0.190149    -0.1136      -0.0915881   -0.292936    -0.182366    0.0140668   -0.0290216    -0.142212     0.00816089   0.0742346    0.0498594     0.207937     0.198197     0.0668499    0.082262    -0.340528     0.0555577    0.242107     0.0184898    0.00175231  -0.0325063   -0.0846367
 -0.0824823    0.0728968    0.0420922    0.192759    -0.232696    -0.0122716   -0.0173247   -0.0358821    0.0980342   0.0054865    0.00566877   -0.0409636    0.0555705   -0.0527007   -0.046838     -0.0105637   -0.0411503    0.118154    -0.0602259    0.0089911   -0.0831166   -0.073563     0.0174999   -0.0778954    0.0892061   -0.0395404
 -0.155486     0.023992     0.221654     0.112783     0.0859062   -0.0726103    0.16905     -0.0433426    0.0623864  -0.144241    -0.135811      0.161416     0.0545479   -0.0235848   -0.0918447     0.13758      0.084166     0.0669748    0.0709435   -0.0594738    0.0493986   -0.140228    -0.0410116   -0.0682359    0.091591     0.0366362
  0.0955265   -0.0958652   -0.0618114    0.0328147    0.0833665    0.0927232    0.0542789   -0.0228118   -0.01112     0.0775281   -0.201438     -0.0836888   -0.0912075    0.067875     0.0236034    -0.128832     0.0752645   -0.0271276   -0.0168181    0.0376545    0.126216    -0.0228448   -0.0474777    0.102581     0.18379      0.0888507
 -0.0466666   -0.0652047    0.0145678   -0.099452     0.025795    -0.0387557   -0.0530674    0.0369637   -0.007369   -0.0989362   -0.208142     -0.0420079    0.0898675    0.0435039    0.0763169     0.0585002   -0.198494    -0.010369    -0.0730308    0.0976766    0.0797877   -0.0879653   -0.0336359   -0.149792     0.0832006   -0.0130624
 -0.0598291   -0.00332037  -0.0798134   -0.120046    -0.228939    -0.196614    -0.0671483   -0.148382    -0.0731571   0.0779502    0.0798697     0.0623509   -0.223347    -0.0364531   -0.000562228   0.143918     0.137599    -0.102562    -0.0494406    0.250577     0.0183385    0.0763512    0.187638    -0.0813081   -0.17177      0.0947688kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4276575104328815
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427679
[ Info: iteration 2, average log likelihood -1.427615
[ Info: iteration 3, average log likelihood -1.427569
[ Info: iteration 4, average log likelihood -1.427514
[ Info: iteration 5, average log likelihood -1.427443
[ Info: iteration 6, average log likelihood -1.427342
[ Info: iteration 7, average log likelihood -1.427180
[ Info: iteration 8, average log likelihood -1.426885
[ Info: iteration 9, average log likelihood -1.426330
[ Info: iteration 10, average log likelihood -1.425408
[ Info: iteration 11, average log likelihood -1.424260
[ Info: iteration 12, average log likelihood -1.423300
[ Info: iteration 13, average log likelihood -1.422758
[ Info: iteration 14, average log likelihood -1.422520
[ Info: iteration 15, average log likelihood -1.422425
[ Info: iteration 16, average log likelihood -1.422387
[ Info: iteration 17, average log likelihood -1.422371
[ Info: iteration 18, average log likelihood -1.422364
[ Info: iteration 19, average log likelihood -1.422360
[ Info: iteration 20, average log likelihood -1.422358
[ Info: iteration 21, average log likelihood -1.422357
[ Info: iteration 22, average log likelihood -1.422356
[ Info: iteration 23, average log likelihood -1.422356
[ Info: iteration 24, average log likelihood -1.422355
[ Info: iteration 25, average log likelihood -1.422355
[ Info: iteration 26, average log likelihood -1.422354
[ Info: iteration 27, average log likelihood -1.422354
[ Info: iteration 28, average log likelihood -1.422353
[ Info: iteration 29, average log likelihood -1.422353
[ Info: iteration 30, average log likelihood -1.422353
[ Info: iteration 31, average log likelihood -1.422352
[ Info: iteration 32, average log likelihood -1.422352
[ Info: iteration 33, average log likelihood -1.422352
[ Info: iteration 34, average log likelihood -1.422352
[ Info: iteration 35, average log likelihood -1.422352
[ Info: iteration 36, average log likelihood -1.422352
[ Info: iteration 37, average log likelihood -1.422351
[ Info: iteration 38, average log likelihood -1.422351
[ Info: iteration 39, average log likelihood -1.422351
[ Info: iteration 40, average log likelihood -1.422351
[ Info: iteration 41, average log likelihood -1.422351
[ Info: iteration 42, average log likelihood -1.422351
[ Info: iteration 43, average log likelihood -1.422351
[ Info: iteration 44, average log likelihood -1.422351
[ Info: iteration 45, average log likelihood -1.422351
[ Info: iteration 46, average log likelihood -1.422351
[ Info: iteration 47, average log likelihood -1.422351
[ Info: iteration 48, average log likelihood -1.422351
[ Info: iteration 49, average log likelihood -1.422351
[ Info: iteration 50, average log likelihood -1.422350
┌ Info: EM with 100000 data points 50 iterations avll -1.422350
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4276789464832302
│     -1.4276147907260812
│      ⋮
└     -1.4223504772748325
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422372
[ Info: iteration 2, average log likelihood -1.422305
[ Info: iteration 3, average log likelihood -1.422257
[ Info: iteration 4, average log likelihood -1.422202
[ Info: iteration 5, average log likelihood -1.422136
[ Info: iteration 6, average log likelihood -1.422060
[ Info: iteration 7, average log likelihood -1.421979
[ Info: iteration 8, average log likelihood -1.421899
[ Info: iteration 9, average log likelihood -1.421827
[ Info: iteration 10, average log likelihood -1.421765
[ Info: iteration 11, average log likelihood -1.421714
[ Info: iteration 12, average log likelihood -1.421672
[ Info: iteration 13, average log likelihood -1.421636
[ Info: iteration 14, average log likelihood -1.421604
[ Info: iteration 15, average log likelihood -1.421575
[ Info: iteration 16, average log likelihood -1.421549
[ Info: iteration 17, average log likelihood -1.421525
[ Info: iteration 18, average log likelihood -1.421502
[ Info: iteration 19, average log likelihood -1.421481
[ Info: iteration 20, average log likelihood -1.421461
[ Info: iteration 21, average log likelihood -1.421443
[ Info: iteration 22, average log likelihood -1.421426
[ Info: iteration 23, average log likelihood -1.421410
[ Info: iteration 24, average log likelihood -1.421397
[ Info: iteration 25, average log likelihood -1.421385
[ Info: iteration 26, average log likelihood -1.421375
[ Info: iteration 27, average log likelihood -1.421366
[ Info: iteration 28, average log likelihood -1.421359
[ Info: iteration 29, average log likelihood -1.421352
[ Info: iteration 30, average log likelihood -1.421347
[ Info: iteration 31, average log likelihood -1.421343
[ Info: iteration 32, average log likelihood -1.421339
[ Info: iteration 33, average log likelihood -1.421336
[ Info: iteration 34, average log likelihood -1.421334
[ Info: iteration 35, average log likelihood -1.421332
[ Info: iteration 36, average log likelihood -1.421330
[ Info: iteration 37, average log likelihood -1.421328
[ Info: iteration 38, average log likelihood -1.421326
[ Info: iteration 39, average log likelihood -1.421325
[ Info: iteration 40, average log likelihood -1.421324
[ Info: iteration 41, average log likelihood -1.421323
[ Info: iteration 42, average log likelihood -1.421321
[ Info: iteration 43, average log likelihood -1.421320
[ Info: iteration 44, average log likelihood -1.421319
[ Info: iteration 45, average log likelihood -1.421318
[ Info: iteration 46, average log likelihood -1.421318
[ Info: iteration 47, average log likelihood -1.421317
[ Info: iteration 48, average log likelihood -1.421316
[ Info: iteration 49, average log likelihood -1.421315
[ Info: iteration 50, average log likelihood -1.421314
┌ Info: EM with 100000 data points 50 iterations avll -1.421314
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4223716291913253
│     -1.4223051702386436
│      ⋮
└     -1.4213140848761416
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421330
[ Info: iteration 2, average log likelihood -1.421279
[ Info: iteration 3, average log likelihood -1.421245
[ Info: iteration 4, average log likelihood -1.421208
[ Info: iteration 5, average log likelihood -1.421166
[ Info: iteration 6, average log likelihood -1.421118
[ Info: iteration 7, average log likelihood -1.421064
[ Info: iteration 8, average log likelihood -1.421004
[ Info: iteration 9, average log likelihood -1.420940
[ Info: iteration 10, average log likelihood -1.420874
[ Info: iteration 11, average log likelihood -1.420808
[ Info: iteration 12, average log likelihood -1.420744
[ Info: iteration 13, average log likelihood -1.420684
[ Info: iteration 14, average log likelihood -1.420629
[ Info: iteration 15, average log likelihood -1.420580
[ Info: iteration 16, average log likelihood -1.420536
[ Info: iteration 17, average log likelihood -1.420496
[ Info: iteration 18, average log likelihood -1.420459
[ Info: iteration 19, average log likelihood -1.420424
[ Info: iteration 20, average log likelihood -1.420391
[ Info: iteration 21, average log likelihood -1.420359
[ Info: iteration 22, average log likelihood -1.420328
[ Info: iteration 23, average log likelihood -1.420299
[ Info: iteration 24, average log likelihood -1.420270
[ Info: iteration 25, average log likelihood -1.420244
[ Info: iteration 26, average log likelihood -1.420219
[ Info: iteration 27, average log likelihood -1.420195
[ Info: iteration 28, average log likelihood -1.420174
[ Info: iteration 29, average log likelihood -1.420153
[ Info: iteration 30, average log likelihood -1.420135
[ Info: iteration 31, average log likelihood -1.420117
[ Info: iteration 32, average log likelihood -1.420101
[ Info: iteration 33, average log likelihood -1.420085
[ Info: iteration 34, average log likelihood -1.420070
[ Info: iteration 35, average log likelihood -1.420056
[ Info: iteration 36, average log likelihood -1.420042
[ Info: iteration 37, average log likelihood -1.420029
[ Info: iteration 38, average log likelihood -1.420016
[ Info: iteration 39, average log likelihood -1.420003
[ Info: iteration 40, average log likelihood -1.419990
[ Info: iteration 41, average log likelihood -1.419978
[ Info: iteration 42, average log likelihood -1.419965
[ Info: iteration 43, average log likelihood -1.419953
[ Info: iteration 44, average log likelihood -1.419941
[ Info: iteration 45, average log likelihood -1.419929
[ Info: iteration 46, average log likelihood -1.419918
[ Info: iteration 47, average log likelihood -1.419907
[ Info: iteration 48, average log likelihood -1.419896
[ Info: iteration 49, average log likelihood -1.419885
[ Info: iteration 50, average log likelihood -1.419874
┌ Info: EM with 100000 data points 50 iterations avll -1.419874
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.421329562631899
│     -1.4212791168411218
│      ⋮
└     -1.419874499228164
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419874
[ Info: iteration 2, average log likelihood -1.419816
[ Info: iteration 3, average log likelihood -1.419764
[ Info: iteration 4, average log likelihood -1.419707
[ Info: iteration 5, average log likelihood -1.419639
[ Info: iteration 6, average log likelihood -1.419557
[ Info: iteration 7, average log likelihood -1.419462
[ Info: iteration 8, average log likelihood -1.419354
[ Info: iteration 9, average log likelihood -1.419241
[ Info: iteration 10, average log likelihood -1.419126
[ Info: iteration 11, average log likelihood -1.419017
[ Info: iteration 12, average log likelihood -1.418916
[ Info: iteration 13, average log likelihood -1.418826
[ Info: iteration 14, average log likelihood -1.418745
[ Info: iteration 15, average log likelihood -1.418674
[ Info: iteration 16, average log likelihood -1.418611
[ Info: iteration 17, average log likelihood -1.418555
[ Info: iteration 18, average log likelihood -1.418505
[ Info: iteration 19, average log likelihood -1.418460
[ Info: iteration 20, average log likelihood -1.418419
[ Info: iteration 21, average log likelihood -1.418382
[ Info: iteration 22, average log likelihood -1.418348
[ Info: iteration 23, average log likelihood -1.418316
[ Info: iteration 24, average log likelihood -1.418287
[ Info: iteration 25, average log likelihood -1.418260
[ Info: iteration 26, average log likelihood -1.418234
[ Info: iteration 27, average log likelihood -1.418210
[ Info: iteration 28, average log likelihood -1.418187
[ Info: iteration 29, average log likelihood -1.418165
[ Info: iteration 30, average log likelihood -1.418144
[ Info: iteration 31, average log likelihood -1.418124
[ Info: iteration 32, average log likelihood -1.418104
[ Info: iteration 33, average log likelihood -1.418086
[ Info: iteration 34, average log likelihood -1.418068
[ Info: iteration 35, average log likelihood -1.418050
[ Info: iteration 36, average log likelihood -1.418034
[ Info: iteration 37, average log likelihood -1.418017
[ Info: iteration 38, average log likelihood -1.418002
[ Info: iteration 39, average log likelihood -1.417987
[ Info: iteration 40, average log likelihood -1.417972
[ Info: iteration 41, average log likelihood -1.417958
[ Info: iteration 42, average log likelihood -1.417944
[ Info: iteration 43, average log likelihood -1.417930
[ Info: iteration 44, average log likelihood -1.417917
[ Info: iteration 45, average log likelihood -1.417905
[ Info: iteration 46, average log likelihood -1.417892
[ Info: iteration 47, average log likelihood -1.417880
[ Info: iteration 48, average log likelihood -1.417868
[ Info: iteration 49, average log likelihood -1.417857
[ Info: iteration 50, average log likelihood -1.417845
┌ Info: EM with 100000 data points 50 iterations avll -1.417845
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4198738587467852
│     -1.4198158474302986
│      ⋮
└     -1.4178453707055583
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417845
[ Info: iteration 2, average log likelihood -1.417786
[ Info: iteration 3, average log likelihood -1.417734
[ Info: iteration 4, average log likelihood -1.417677
[ Info: iteration 5, average log likelihood -1.417608
[ Info: iteration 6, average log likelihood -1.417525
[ Info: iteration 7, average log likelihood -1.417426
[ Info: iteration 8, average log likelihood -1.417310
[ Info: iteration 9, average log likelihood -1.417181
[ Info: iteration 10, average log likelihood -1.417044
[ Info: iteration 11, average log likelihood -1.416904
[ Info: iteration 12, average log likelihood -1.416766
[ Info: iteration 13, average log likelihood -1.416634
[ Info: iteration 14, average log likelihood -1.416512
[ Info: iteration 15, average log likelihood -1.416401
[ Info: iteration 16, average log likelihood -1.416302
[ Info: iteration 17, average log likelihood -1.416212
[ Info: iteration 18, average log likelihood -1.416133
[ Info: iteration 19, average log likelihood -1.416062
[ Info: iteration 20, average log likelihood -1.415998
[ Info: iteration 21, average log likelihood -1.415940
[ Info: iteration 22, average log likelihood -1.415888
[ Info: iteration 23, average log likelihood -1.415840
[ Info: iteration 24, average log likelihood -1.415796
[ Info: iteration 25, average log likelihood -1.415755
[ Info: iteration 26, average log likelihood -1.415716
[ Info: iteration 27, average log likelihood -1.415681
[ Info: iteration 28, average log likelihood -1.415647
[ Info: iteration 29, average log likelihood -1.415615
[ Info: iteration 30, average log likelihood -1.415585
[ Info: iteration 31, average log likelihood -1.415556
[ Info: iteration 32, average log likelihood -1.415528
[ Info: iteration 33, average log likelihood -1.415502
[ Info: iteration 34, average log likelihood -1.415476
[ Info: iteration 35, average log likelihood -1.415452
[ Info: iteration 36, average log likelihood -1.415428
[ Info: iteration 37, average log likelihood -1.415406
[ Info: iteration 38, average log likelihood -1.415384
[ Info: iteration 39, average log likelihood -1.415363
[ Info: iteration 40, average log likelihood -1.415342
[ Info: iteration 41, average log likelihood -1.415323
[ Info: iteration 42, average log likelihood -1.415303
[ Info: iteration 43, average log likelihood -1.415285
[ Info: iteration 44, average log likelihood -1.415267
[ Info: iteration 45, average log likelihood -1.415249
[ Info: iteration 46, average log likelihood -1.415232
[ Info: iteration 47, average log likelihood -1.415216
[ Info: iteration 48, average log likelihood -1.415199
[ Info: iteration 49, average log likelihood -1.415184
[ Info: iteration 50, average log likelihood -1.415168
┌ Info: EM with 100000 data points 50 iterations avll -1.415168
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.417844789492617
│     -1.4177863650703486
│      ⋮
└     -1.41516808491936
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4276575104328815
│     -1.4276789464832302
│     -1.4276147907260812
│     -1.4275686981242541
│      ⋮
│     -1.415199365895063
│     -1.415183542726839
└     -1.41516808491936
32×26 Array{Float64,2}:
 -0.10695      -0.24774    -0.182381   -0.459644     0.12113     0.523232     -0.0459039   -0.231603    -0.145072    0.113516   -0.573059    0.0318157   -0.289905     0.162466    0.221513   -0.0891648    0.32405    -0.529658   -0.213326    0.452333    -0.517964   -0.0882084  -0.00842269  -0.203003    0.246563   -0.37546
  0.307451     -0.49836     0.152329   -0.230042     0.35749     0.757093      0.00193355  -0.120426    -0.981737    0.204214   -0.337168   -0.162322    -0.555618     0.481412    0.0110608   0.375481     0.371893   -0.475956    0.236596   -0.481863    -0.906184   -0.496087   -0.374933     0.204286    0.306338    0.180061
 -0.190787     -0.303229   -0.0124994  -0.176843    -0.279053    0.384689     -0.671193     0.614426    -0.0829094   0.0049832  -0.827682    0.0854686   -0.201737     0.0348064  -0.182515   -0.160934    -0.133363    0.435683   -0.284526    0.463033     0.407174    0.186409   -0.326835     0.502783    0.223192    0.451162
  0.307261     -0.768198    0.0301829  -0.429016     0.0634668  -0.0500175    -0.304269     0.120812    -0.083083    0.527876   -0.117595   -0.242611     0.24571      0.391437   -0.138458   -0.149098    -0.0285029   0.634215   -0.727884    0.101554    -0.0617119   0.0307466  -0.0787406    0.50785     0.763962    0.316768
 -0.451236      0.0977769   0.249289    0.0250746   -0.0585776  -0.218083      0.124204    -0.128014    -0.14018     0.131605   -0.434887   -0.11904     -0.0272611   -0.0469475   0.0631978  -0.0419696    0.192816   -0.0670474   0.0914226   0.197549     0.189816   -0.023445    0.170883     0.200992    0.0657528   0.333137
 -0.404022      0.125513    0.439751   -0.128953    -0.386099   -0.201652     -0.327981    -0.276174    -0.0264174   0.0178733   0.418033    0.14636     -0.323627     0.281259   -0.150151   -0.0026995    0.114827    0.0618705  -0.0741612  -0.243252    -0.186108    0.0583664  -0.276036     0.0388618  -0.0327744   0.0473451
  0.0827437     0.199557   -0.496197   -0.175483     0.375056   -0.21945       0.319271     0.0950876    0.0917055  -0.146942    0.072527   -0.140098     0.0437974    0.155232    0.0399137  -0.160985    -0.298627    0.0664301  -0.111114    0.062853    -0.0557092  -0.50051    -0.140484     0.0787857   0.154828    0.150961
 -0.0651864    -0.0608122  -0.360275   -0.0878367    0.27099    -0.0575374     0.231554     0.472807     0.131249   -0.0228525  -0.0219113  -0.301099    -0.118069     0.0863935  -0.271976    0.0560878   -0.464549   -0.0552638   0.224545   -0.345213     0.251693    0.490091    0.186271     0.0443752  -0.134211   -0.106076
 -0.271963      0.45245    -0.276964   -0.0497593    0.50947     0.132535     -0.4291      -0.131054     0.339141   -0.25859    -0.598423    0.426733     0.0571347    0.232721    0.403162    0.0399498   -0.439684    0.184216    0.339214    0.230493     0.222035   -0.313743   -0.458688     0.150627   -0.364392    0.350719
 -0.125942      0.0585122  -0.0732929   0.140974    -0.441946   -0.408111     -0.00279433  -0.427368     0.0188482  -0.225848   -0.307       0.258332     0.579098     0.782715    0.637439   -0.361107     0.12843    -0.216771    0.0340302  -0.192152     0.14615    -0.0540937  -0.173395    -0.458404    0.73264     0.360501
  0.0567213     0.392444   -0.0398239  -0.0104608   -0.345692   -0.140321     -0.0463316   -0.228792     0.0998165   0.188287   -0.225533    0.0265699    0.182716    -0.244031    0.458005   -0.18416      0.508576    0.134696   -0.583632    0.52674     -0.265719   -0.694915   -0.436661    -0.0809254   0.243884    0.0883975
  0.350785      0.217497   -0.243001    0.217956    -0.156481   -0.439375      0.328503     0.132307     0.261997   -0.196632    0.42067     0.0205128    0.455035    -0.105051    0.612898    0.343222    -0.194117    0.498114    0.0786264   0.0262425   -0.162764    0.428033   -0.488945    -0.486979   -0.177809    0.150637
 -0.0152867     0.0657954  -0.226794    0.265741     0.265114    0.295631      0.692555    -0.185499    -0.305315   -0.742887    0.0537037   0.249946    -0.0821543   -0.399761   -0.358584    0.00167998   0.0936584  -0.172745   -0.0584756   0.0400873    0.375481   -0.633301   -0.148376    -0.376108    0.383586   -0.303723
 -0.0663599     0.0925586  -0.0250457  -0.123166     0.311938    0.210417      0.792854    -0.137842    -0.208606    0.511584    0.291178    0.074448     0.13837     -0.205857   -0.681949    0.358781     0.431987    0.155488   -0.0428157  -0.518831    -0.179701   -0.268803    0.234684    -0.413404    0.269052   -0.136166
  0.23556       0.168565    0.280034    0.354064    -0.505693    0.147878     -0.0886554   -0.031056     0.261009   -0.413788    0.161534   -0.153023     0.0728607   -0.304559   -0.112745   -0.369457     0.198824   -0.267219    0.147459   -0.118398     0.145094   -0.0474619   0.139556    -0.13646    -0.0472588  -0.193368
  0.147277     -0.211149    0.115993    0.00784549  -0.0433813   0.118227     -0.00590915   0.0628341   -0.116238    0.0105138   0.0156202   0.0770099   -0.00518351  -0.01653     0.0219492   0.184698     0.0246748   0.0282565  -0.103878    0.0682623   -0.107467    0.147141    0.0466322   -0.215794   -0.0394942  -0.101867
 -0.14975      -0.312031   -0.317978   -0.513085     0.410971    0.223188      0.0643374   -0.0904234    0.627673    0.399784   -0.655218   -0.221896    -0.38125      0.351041   -0.549275    0.584937    -0.490137    0.513333    0.886187   -0.315674     0.107365    0.31581    -0.287735     0.112003   -0.0862971  -0.81659
  0.438217     -1.06354    -0.325898    0.048887     0.834385   -0.103521      0.59865      0.890012     0.0363633   0.578687   -0.878225    0.33017     -0.341834     0.141172   -0.350484   -0.32257     -0.721991    0.0720339  -0.082849    0.0192645    0.0755763   0.311764    0.213082    -0.277373    0.380684   -0.258061
  0.62369      -0.66941     0.641036    0.269859     0.5678     -0.232337      0.00695335   0.549464    -0.213125   -0.132535    0.23845    -0.0459899   -0.715067    -0.582841   -0.343303    0.215228    -0.386749    0.483007   -0.171713    0.130007    -0.40275    -0.109988   -0.368675     0.248729   -0.371908    0.103898
 -0.000381302  -0.25548    -0.207821   -0.0416752    0.874864    0.393081     -0.496103     0.147461     0.124779   -0.438793    0.0285025   0.115984     0.0503789   -0.346916   -0.224008    0.503857    -0.515677   -0.354117   -0.54151     0.0329323   -0.555927    0.616081    0.37863      0.0404003  -0.248963    0.0555054
  0.153012     -0.619846    0.437492    0.319147    -0.367169   -0.0440634     0.251628     0.0606287   -0.977364   -0.136016    0.431274   -0.0193989    0.0211663   -0.183383   -0.0997456   0.044022     0.237225   -0.161677   -0.389828    0.302543    -0.0597408   0.279025    0.7168      -0.190924    0.113344    0.117732
  0.289404     -0.620208    0.841896   -0.030823    -0.591507   -0.000348483  -0.445711     0.318209    -0.0872672  -0.0441715   0.192956    0.401798    -0.0782662    0.276878   -0.400024    0.253184     0.0815885   0.15635     0.0120549  -0.454743    -0.0992729   0.466576   -0.0972603   -0.46887     0.190914   -0.14325
  0.299414      0.429007   -0.462219   -0.308805    -0.641657   -0.0561531    -0.048624     0.344503     0.301922    0.704809    0.234984   -0.288044     0.0256514    0.359242   -0.243422   -0.696939     0.302264    0.409488    0.246517   -0.356552    -0.0269658   0.212151   -0.147574    -0.114613   -0.0438238  -0.555471
 -0.144418     -0.170936   -0.349351   -0.642354    -0.152889    0.0471593     0.199102    -0.00729157   0.302793    0.845827    0.560859   -0.292241    -0.0572843   -0.109284    0.0910847   0.768302     0.247698    0.565741   -0.119756    0.376117    -0.723197    0.0524148  -0.537486    -0.0676045  -0.0999573  -0.0974517
 -0.0844946     0.108409    0.0311545   0.127343    -0.116641    0.17863      -0.0509163   -0.085105    -0.0155525  -0.146505   -0.378318    0.0310487    0.0128973   -0.177169    0.235559   -0.211061     0.225897   -0.170085   -0.195884    0.258927     0.12606    -0.246463   -0.055427     0.0775177   0.0859027   0.153608
 -0.0322704     0.298194   -0.430045   -0.361048     0.460888   -0.156393      0.643922    -0.0256183    0.0250461  -0.507585    0.160738   -0.103273     0.145378     0.300586   -0.144723   -0.290766    -0.284065   -0.0304325  -0.124512   -0.0305767   -0.0310592  -0.701344   -0.313037    -0.162897    0.386588    0.14491
 -0.0421207     0.458036   -0.0932399   0.688138    -0.195311   -0.050467      0.0781216   -0.0470887    0.359672    0.0521043  -0.298363   -0.153404     0.53311     -0.688806    0.442213    0.0544314    0.372517    0.340885    0.218412    0.0347574    0.0674651   0.35961     0.407444    -0.471783   -0.608545   -0.651939
 -0.0388577     0.308262   -0.0703916   0.457495    -0.114065   -0.132754      0.670667    -0.393248    -0.0223486  -0.240206    0.252676   -0.00592042   0.0596486   -0.160992    0.165457    0.3421       0.14887    -0.968699    0.487272   -0.293309    -0.0501624  -0.0350501   0.51379     -0.371629   -0.661937   -0.153056
 -0.300009     -0.0660676   0.922806   -0.0691555   -0.242745   -0.48102      -0.469806    -0.168335    -0.0234177   0.315304   -0.175258   -0.144795    -0.137298     0.125991    0.232184    0.17108     -0.125366   -0.065085    0.109393   -0.00932121   0.199851    0.225501   -0.0792654    0.752138   -0.400219    0.491023
 -0.647679      0.64347     0.0863552   0.0565376   -0.57043    -0.0911564    -0.409986    -0.350414    -0.0578639  -0.515719    0.944174   -0.459812    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.21784     -0.0288909   0.341005    0.0725099    0.297345    0.0107272   0.244612   -0.349671     0.0433501   0.333788   -0.465075     0.378604   -0.385676    0.0898437
 -0.1697        0.0104788  -0.102724    0.284894     0.276411    0.196828     -0.339472     0.334932    -0.343169   -0.371649   -0.206344    0.307975    -0.143775    -0.0603378  -0.675489   -0.595455    -0.357446   -0.7854      0.106877   -0.673946     0.814298    0.507781    1.08987      0.0489307  -0.0957731   0.0949394
 -0.414039      0.248514    0.217142   -0.441349     0.0367099  -0.613194     -0.0181826    0.204716     0.0875025   0.215415    0.980648    0.0442292   -0.138549    -0.175734   -0.588046    0.186387    -0.350648    0.0735137   0.1083      0.14422      0.409533    0.0395272   0.805841     0.0195075  -0.536913    0.170849[ Info: iteration 1, average log likelihood -1.415153
[ Info: iteration 2, average log likelihood -1.415138
[ Info: iteration 3, average log likelihood -1.415124
[ Info: iteration 4, average log likelihood -1.415109
[ Info: iteration 5, average log likelihood -1.415095
[ Info: iteration 6, average log likelihood -1.415082
[ Info: iteration 7, average log likelihood -1.415068
[ Info: iteration 8, average log likelihood -1.415055
[ Info: iteration 9, average log likelihood -1.415042
[ Info: iteration 10, average log likelihood -1.415029
┌ Info: EM with 100000 data points 10 iterations avll -1.415029
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.351674e+05
      1       7.124387e+05      -2.227288e+05 |       32
      2       6.980435e+05      -1.439516e+04 |       32
      3       6.934470e+05      -4.596507e+03 |       32
      4       6.911301e+05      -2.316855e+03 |       32
      5       6.896808e+05      -1.449321e+03 |       32
      6       6.886987e+05      -9.821053e+02 |       32
      7       6.879223e+05      -7.764596e+02 |       32
      8       6.872639e+05      -6.583888e+02 |       32
      9       6.866878e+05      -5.760965e+02 |       32
     10       6.861830e+05      -5.047672e+02 |       32
     11       6.857350e+05      -4.480055e+02 |       32
     12       6.853369e+05      -3.981125e+02 |       32
     13       6.849880e+05      -3.489081e+02 |       32
     14       6.846806e+05      -3.073836e+02 |       32
     15       6.844121e+05      -2.685471e+02 |       32
     16       6.841834e+05      -2.286662e+02 |       32
     17       6.839700e+05      -2.134090e+02 |       32
     18       6.837794e+05      -1.905526e+02 |       32
     19       6.836269e+05      -1.524800e+02 |       32
     20       6.834691e+05      -1.578897e+02 |       32
     21       6.833207e+05      -1.483489e+02 |       32
     22       6.831743e+05      -1.463635e+02 |       32
     23       6.830397e+05      -1.346860e+02 |       32
     24       6.829031e+05      -1.365693e+02 |       32
     25       6.827728e+05      -1.302494e+02 |       32
     26       6.826383e+05      -1.344954e+02 |       32
     27       6.825066e+05      -1.317807e+02 |       32
     28       6.823910e+05      -1.155216e+02 |       32
     29       6.822872e+05      -1.038700e+02 |       32
     30       6.821878e+05      -9.934235e+01 |       32
     31       6.820995e+05      -8.829060e+01 |       32
     32       6.820181e+05      -8.142242e+01 |       32
     33       6.819519e+05      -6.617006e+01 |       32
     34       6.818863e+05      -6.564753e+01 |       32
     35       6.818250e+05      -6.130607e+01 |       32
     36       6.817669e+05      -5.804796e+01 |       32
     37       6.817141e+05      -5.283293e+01 |       32
     38       6.816592e+05      -5.494112e+01 |       32
     39       6.815992e+05      -6.000915e+01 |       32
     40       6.815378e+05      -6.135403e+01 |       32
     41       6.814771e+05      -6.073882e+01 |       32
     42       6.814216e+05      -5.549755e+01 |       32
     43       6.813743e+05      -4.731520e+01 |       32
     44       6.813355e+05      -3.879957e+01 |       32
     45       6.813039e+05      -3.153752e+01 |       32
     46       6.812790e+05      -2.495441e+01 |       32
     47       6.812529e+05      -2.611225e+01 |       32
     48       6.812261e+05      -2.676569e+01 |       32
     49       6.811985e+05      -2.755033e+01 |       32
     50       6.811732e+05      -2.535097e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 681173.1842978874)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426773
[ Info: iteration 2, average log likelihood -1.421790
[ Info: iteration 3, average log likelihood -1.420461
[ Info: iteration 4, average log likelihood -1.419472
[ Info: iteration 5, average log likelihood -1.418399
[ Info: iteration 6, average log likelihood -1.417370
[ Info: iteration 7, average log likelihood -1.416646
[ Info: iteration 8, average log likelihood -1.416243
[ Info: iteration 9, average log likelihood -1.416021
[ Info: iteration 10, average log likelihood -1.415878
[ Info: iteration 11, average log likelihood -1.415774
[ Info: iteration 12, average log likelihood -1.415689
[ Info: iteration 13, average log likelihood -1.415618
[ Info: iteration 14, average log likelihood -1.415556
[ Info: iteration 15, average log likelihood -1.415501
[ Info: iteration 16, average log likelihood -1.415452
[ Info: iteration 17, average log likelihood -1.415409
[ Info: iteration 18, average log likelihood -1.415370
[ Info: iteration 19, average log likelihood -1.415335
[ Info: iteration 20, average log likelihood -1.415303
[ Info: iteration 21, average log likelihood -1.415274
[ Info: iteration 22, average log likelihood -1.415248
[ Info: iteration 23, average log likelihood -1.415223
[ Info: iteration 24, average log likelihood -1.415201
[ Info: iteration 25, average log likelihood -1.415180
[ Info: iteration 26, average log likelihood -1.415160
[ Info: iteration 27, average log likelihood -1.415142
[ Info: iteration 28, average log likelihood -1.415125
[ Info: iteration 29, average log likelihood -1.415109
[ Info: iteration 30, average log likelihood -1.415093
[ Info: iteration 31, average log likelihood -1.415079
[ Info: iteration 32, average log likelihood -1.415065
[ Info: iteration 33, average log likelihood -1.415051
[ Info: iteration 34, average log likelihood -1.415039
[ Info: iteration 35, average log likelihood -1.415027
[ Info: iteration 36, average log likelihood -1.415015
[ Info: iteration 37, average log likelihood -1.415004
[ Info: iteration 38, average log likelihood -1.414993
[ Info: iteration 39, average log likelihood -1.414982
[ Info: iteration 40, average log likelihood -1.414972
[ Info: iteration 41, average log likelihood -1.414962
[ Info: iteration 42, average log likelihood -1.414952
[ Info: iteration 43, average log likelihood -1.414943
[ Info: iteration 44, average log likelihood -1.414933
[ Info: iteration 45, average log likelihood -1.414924
[ Info: iteration 46, average log likelihood -1.414915
[ Info: iteration 47, average log likelihood -1.414906
[ Info: iteration 48, average log likelihood -1.414898
[ Info: iteration 49, average log likelihood -1.414889
32×26 Array[ Info: iteration 50, average log likelihood -1.414880
┌ Info: EM with 100000 data points 50 iterations avll -1.414880
└ 59.0 data points per parameter
{Float64,2}:
 -0.209598    0.736711    -0.255647   -0.166362     -0.269215    -0.116133    0.33466    -0.164681    -0.0492191   -0.224255     0.0727035  -0.223319    0.411827    -0.131951    0.283443   -0.368631     0.530867    -0.386708    -0.403843     0.0354169   0.0489981   -0.779676    0.0463889  -0.238915     0.0954974   0.107004
 -0.111288   -0.427199     0.721873   -0.000208664  -0.0212357   -0.0373649  -0.258732   -0.296196     0.329873     0.00180835   0.162243    0.426338   -0.336843     0.19507     0.0203777   0.35692      0.00665646  -0.564886    -0.44805      0.032625   -0.921868     0.408241   -0.0929773  -0.384896    -0.0631017   0.0584278
  0.631472   -0.956618     0.274152   -0.0320045     0.756675    -0.247746   -0.259966    0.548204    -0.14249      0.250854     0.272568    0.0367609  -0.356217    -0.189142   -0.409786    0.256289    -0.544272     0.549917    -0.433528     0.20714    -0.634435     0.276034   -0.0887076   0.232529    -0.249706   -0.0577775
 -0.180543    0.766576    -0.254544    0.059121      0.432835     0.131705   -0.380292   -0.0453244    0.747754    -0.0156739   -0.437249    0.0010441   0.0474544   -0.176191    0.294216    0.036835     0.0780831   -0.00882744   0.128853     0.0388735  -0.0306927   -0.2499     -0.227337    0.142634    -0.720837    0.0115592
  0.0894153  -0.00183096  -0.45407    -0.0963848     0.493404    -0.166453    0.510976    0.196262    -0.0210993   -0.111498    -0.0186321  -0.181083    0.0441356    0.0957802  -0.176019    0.00558739  -0.388655     0.0470598   -0.121039    -0.149069    0.0660692   -0.2211      0.0398574   0.0713629    0.138581    0.149686
  0.369815   -0.124899     1.11821     0.834381     -0.247328     0.0979819   0.114696    0.030288    -0.00542007  -0.486047    -0.217169    0.347791   -0.109415    -0.206129   -0.520703   -0.473682     0.239255    -0.752979     0.749386    -0.562063    0.192618    -0.377503    0.452591    0.0821553   -0.242607   -0.0699121
  0.0191345   0.112592    -0.231654   -0.00206547   -0.16638     -0.260217   -0.151104   -0.429817     0.217814    -0.0656864   -0.408041    0.273408    0.624556     0.820003    0.60133    -0.381804    -0.0061465    0.0813165    0.0824206   -0.0641409   0.0319749   -0.171719   -0.333444   -0.328951     0.63906     0.100908
  0.199647   -0.0449831    0.442242   -0.129671     -0.771942    -0.345465    0.162447   -0.37799      0.242835     0.678554     0.174089   -0.105946   -0.247438     0.361297    0.310429    0.173114     0.47662      0.599698     0.207362     0.0814207  -0.526293    -0.726027   -1.21524     0.109841     0.0678915   0.00616383
  0.299033   -0.0270274    0.038008    0.0650767    -0.370909     0.101036   -0.440776    0.12132     -0.276436    -0.101701    -0.268346    0.0302692   0.118838    -0.215111    0.363078   -0.529679     0.311827     0.18591     -0.980437     0.622855   -0.168283    -0.427608   -0.120221    0.0359603    0.416321    0.401168
  0.277037    0.158258    -0.185574    0.0404045    -0.441106     0.426935   -0.0835887   0.394919     0.139623     0.676768     0.130397   -0.213319    0.17116     -0.347794   -0.311028   -0.0849528    0.591901     0.39048      0.202687    -0.363069    0.0172799    0.7291      0.395085   -0.437555    -0.169303   -0.677663
 -0.0421514  -0.589648     0.0314047  -0.335615     -0.102166     0.282409   -0.57139     0.308224     0.114902     0.448728    -0.700132   -0.0551389  -0.170417     0.114748   -0.338453   -0.00484247  -0.0236785    0.388138    -0.230633     0.187447    0.340476     0.294817   -0.205126    0.660116     0.469381    0.195601
 -0.171969    0.21863      0.278656    0.696664     -0.4809      -0.832      -0.154448   -0.0114466    0.200186    -0.0806418    0.267546   -0.209164    0.483596    -0.297875    0.8236      0.270386    -0.0515167    0.435115     0.101748    -0.064985    0.267187     0.496889    0.0253461  -0.0131081   -0.794494   -0.108008
 -0.0736425  -0.370834     0.508443    0.252195      0.281441     0.100616    0.368502    0.22408     -0.592415    -0.183503     0.225303   -0.340229   -0.662521    -1.01542    -0.222537    0.417735     0.0130537   -0.148748    -0.141065     0.265351    0.135011    -0.23813     0.323804    0.376474    -0.476005    0.0356782
 -0.150628   -0.0654243   -0.306867    0.1607        0.574643     0.443063   -0.386567    0.357576    -0.168444    -0.587382    -0.12199     0.169877    0.0297817   -0.196333   -0.486185   -0.137374    -0.525456    -0.691867    -0.249975    -0.339505    0.333612     0.764393    0.929795   -0.0663736   -0.136192    0.099885
 -0.437478    0.0288157    0.124396   -0.219195      0.401112    -0.122816   -0.232796   -0.440877    -0.220999    -0.626495    -0.472204    0.370729   -0.170924     0.225945    0.298879    0.0921027   -0.656455    -0.0462817    0.0296287    0.510756    0.176662    -0.594213   -0.387806    0.421328     0.117317    0.675885
 -0.476826    0.112823     0.588286    0.488637     -0.808186    -0.330099    0.250559   -0.36549     -0.0188608    0.0314773   -0.0317079  -0.209885    0.391672    -0.0717494   0.120132   -0.248458     0.551342    -0.63223      0.117048     0.414594    0.323009     0.184713    0.48567     0.100812     0.361341    0.127098
 -0.143896    0.268923     0.0907187   0.0439355    -0.0542551    0.0828713   0.387142   -0.318343    -0.176808    -0.0708542    0.115714    0.0684038  -0.00861303  -0.235023   -0.212528    0.0662161    0.383228    -0.0476133   -0.00827887  -0.14375    -0.0210095   -0.272069    0.0169166  -0.314784     0.0712284  -0.135262
 -0.380934    0.384142     0.294966   -0.382708      0.0186896   -0.664065    0.0874006   0.257704     0.173516     0.196368     0.670194    0.142469   -0.0151901   -0.0835425  -0.61045    -0.0207466   -0.338622     0.0394022    0.154019    -0.17711     0.686202    -0.0983705   0.318349    0.167646    -0.31012     0.305712
  0.24257     0.34782     -0.43709     0.0540973    -0.407314     0.217533    0.340249    0.854875    -0.0413815   -0.150573     0.206565   -0.471593   -0.0218077    0.73896     0.321242   -0.328274    -0.315252     0.420976     0.477954    -0.235351    0.508483    -0.190225   -0.569232    0.409098     0.195938    0.377468
  0.01091     0.0763312   -0.741077    0.298664      0.604437     0.306593    0.996095   -0.408557     0.00754532  -0.246944    -0.0437625   0.333365    0.0379595   -0.318186   -0.314352    0.144759     0.14012     -0.223212    -0.113983     0.0433156  -0.106212    -0.697914   -0.0760024  -0.515228     0.368417   -0.513506
 -0.740072    0.537527     0.15344    -0.300623     -0.508668     0.0182419  -0.641714   -0.399865     0.090146    -0.115734     0.641941   -0.316618   -0.369635    -0.0133152   0.0394952   0.0464476    0.198206    -0.114322     0.229802    -0.299112   -0.151093     0.569234   -0.16883     0.53818     -0.330523   -0.0683352
 -0.0539418  -0.238807     0.212229   -0.0473891    -0.194936    -0.0720346  -0.244583    0.0613789   -0.0376116    0.0898712    0.013827    0.0153506  -0.046218     0.109956    0.0177254   0.0657632    0.0286561    0.0906379   -0.0726713   -0.0234435  -0.0307739    0.362269   -0.0347808   0.0080773   -0.0700071   0.141232
  0.231879   -0.691128     0.430261    0.156626     -0.576979    -0.122029    0.198587    0.398428    -0.639595    -0.289006     0.26385     0.150822   -0.25032      0.156213   -0.152673   -0.153101    -0.172456     0.00228007  -0.153954    -0.30975     0.13625      0.148906    0.0574469  -0.652042     0.433086   -0.172723
  0.566758   -0.0415774    0.0475288   0.338875     -0.0879729    0.0763072  -0.114221    0.167652     0.318551    -0.499876     0.358805   -0.0223599   0.145269    -0.270937   -0.0673503   0.0376318   -0.150609     0.0941283   -0.0752699   -0.122317   -0.0660152    0.0654138  -0.198262   -0.264241    -0.119301   -0.215301
  0.0421584  -0.408363    -0.438957   -0.416217      0.906446    -0.0253056   0.409486    0.539357     0.440802     0.407737    -0.760443    0.01616    -0.226525     0.324871   -0.337234    0.113035    -0.908889     0.223834     0.570772    -0.151858    0.233398     0.289931   -0.0730944   0.00392404  -0.0145155  -0.537439
 -0.110563   -0.274408     0.419654   -0.159193      0.246418    -0.0732111   0.0210034  -0.165408    -0.490527     0.15289      0.0218972   0.456565    0.681922     0.235481   -0.43047     0.723959     0.409388     0.70017      0.12898     -0.220036   -0.160807     0.421283    0.153928   -0.421732     0.449358    0.59279
  0.314357    0.0933218   -0.100303    0.358276     -0.00802137  -0.0290013   0.713925   -0.660754    -0.287316     0.059201     0.304339    0.132763    0.197676     0.0128652   0.328453    0.484649     0.133146    -0.749823     0.818926    -0.105464   -0.135413     0.359561    0.622312   -0.41489     -0.73569    -0.159267
 -0.137315   -0.0770492    0.139107   -0.0864548    -0.121041    -0.0450943  -0.182156    0.0783817   -0.0131749    0.096265    -0.135696   -0.0164926  -0.120388     0.140524    0.0541717  -0.0340153   -0.0284041    0.0222277   -0.00421818   0.115266   -0.00394961   0.120465    0.0137164   0.0980188   -0.033578    0.0853884
 -0.21178     0.548862    -0.490341    0.339972     -0.407509    -0.149601    0.509448    0.00176722   0.344134    -0.774204    -0.0260265  -0.1478      0.0374037   -0.155051    0.586797   -0.304237     0.0375627   -0.455933     0.486527     0.0250719   0.320995     0.206706   -0.232674   -0.612747    -0.0784182  -0.0859076
  0.34233     0.0761399   -0.483667   -0.760828     -0.132831    -0.252376    0.138828   -0.125923     0.136321     0.31393      0.521589   -0.304177   -0.0529051    0.759129   -0.652019   -0.42206     -0.242959     0.312764     0.167767    -0.220371   -0.234125    -0.113075    0.234315   -0.353356     0.221085   -0.865955
  0.0075693   0.0980363   -0.609934   -0.597067     -0.0243684   -0.0883523   0.376103    0.232757     0.0898153    0.314332     0.117621   -0.31924    -0.0118664   -0.208419    0.307316    0.257269     0.153346     0.409751    -0.399145     0.361982   -0.761836     0.0985477  -0.486554   -0.49246      0.168721    0.0311233
  0.0142499  -0.524137     0.0547088  -0.372955      0.354187     0.884575   -0.015724   -0.164753    -0.705234     0.156575    -0.501079   -0.173122   -0.445185     0.41738    -0.0731898   0.21851      0.359388    -0.588735     0.0231276   -0.128072   -0.616637    -0.474208   -0.0984533   0.228767     0.361088   -0.0456057[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414872
[ Info: iteration 2, average log likelihood -1.414863
[ Info: iteration 3, average log likelihood -1.414855
[ Info: iteration 4, average log likelihood -1.414846
[ Info: iteration 5, average log likelihood -1.414838
[ Info: iteration 6, average log likelihood -1.414830
[ Info: iteration 7, average log likelihood -1.414822
[ Info: iteration 8, average log likelihood -1.414813
[ Info: iteration 9, average log likelihood -1.414805
[ Info: iteration 10, average log likelihood -1.414797
┌ Info: EM with 100000 data points 10 iterations avll -1.414797
└ 59.0 data points per parameter
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 | [ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
       0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
