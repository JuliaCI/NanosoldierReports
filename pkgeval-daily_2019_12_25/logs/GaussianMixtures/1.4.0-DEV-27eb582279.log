Julia Version 1.4.0-DEV.660
Commit 27eb582279 (2019-12-23 19:29 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Distances ────────── v0.8.2
 Installed JLD ──────────────── v0.9.1
 Installed BinDeps ──────────── v1.0.0
 Installed QuadGK ───────────── v2.3.1
 Installed Distributions ────── v0.21.11
 Installed FillArrays ───────── v0.8.2
 Installed CMakeWrapper ─────── v0.2.3
 Installed OrderedCollections ─ v1.1.0
 Installed Rmath ────────────── v0.6.0
 Installed Missings ─────────── v0.4.3
 Installed NearestNeighbors ─── v0.4.4
 Installed DataStructures ───── v0.17.6
 Installed StatsBase ────────── v0.32.0
 Installed LegacyStrings ────── v0.4.1
 Installed HDF5 ─────────────── v0.12.5
 Installed Compat ───────────── v2.2.0
 Installed URIParser ────────── v0.4.0
 Installed FileIO ───────────── v1.2.0
 Installed SpecialFunctions ─── v0.9.0
 Installed Arpack ───────────── v0.4.0
 Installed StaticArrays ─────── v0.12.1
 Installed CMake ────────────── v1.1.2
 Installed PDMats ───────────── v0.9.10
 Installed Blosc ────────────── v0.5.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed Parameters ───────── v0.12.0
 Installed SortingAlgorithms ── v0.3.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed StatsFuns ────────── v0.9.3
 Installed Clustering ───────── v0.13.3
 Installed BinaryProvider ───── v0.5.8
 Installed DataAPI ──────────── v1.1.0
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_AjizPn/Project.toml`
 [no changes]
  Updating `/tmp/jl_AjizPn/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_3D35SI/Project.toml`
 [no changes]
  Updating `/tmp/jl_3D35SI/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_uCKnvA/Project.toml`
 [no changes]
  Updating `/tmp/jl_uCKnvA/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_Z6csn8/Project.toml`
 [no changes]
  Updating `/tmp/jl_Z6csn8/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_EFPPi8/Project.toml`
 [no changes]
  Updating `/tmp/jl_EFPPi8/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_EFPPi8/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.063931754807003e6, [48259.114761019526, 51740.885238980474], [-22227.202024177346 -1118.3876227732535 -83.03158382407955; 22426.78164790638 978.953636702225 102.95249465330207], [[72777.69936795608 -3642.431168113691 11967.720411507584; -3642.4311681136915 48902.18935475612 -6246.031967245854; 11967.720411507584 -6246.031967245854 59300.979287858005], [27149.12865380629 3578.50915968492 -11518.340220997288; 3578.5091596849197 50710.5632048123 6299.56873780085; -11518.340220997288 6299.56873780085 41623.7230466661]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.196640e+03
      1       8.752532e+02      -3.213863e+02 |        3
      2       8.465514e+02      -2.870186e+01 |        0
      3       8.465514e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 846.5513845069181)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.082182
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.821855
[ Info: iteration 2, lowerbound -3.683593
[ Info: iteration 3, lowerbound -3.518647
[ Info: iteration 4, lowerbound -3.311766
[ Info: iteration 5, lowerbound -3.090938
[ Info: iteration 6, lowerbound -2.895509
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.748512
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.651249
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.583997
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.521303
[ Info: iteration 11, lowerbound -2.469819
[ Info: iteration 12, lowerbound -2.427472
[ Info: iteration 13, lowerbound -2.390651
[ Info: iteration 14, lowerbound -2.358376
[ Info: iteration 15, lowerbound -2.331107
[ Info: iteration 16, lowerbound -2.312681
[ Info: iteration 17, lowerbound -2.307534
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302922
[ Info: iteration 19, lowerbound -2.299260
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Dec 25 14:47:04 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Dec 25 14:47:13 2019: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Wed Dec 25 14:47:15 2019: EM with 272 data points 0 iterations avll -2.082182
5.8 data points per parameter
, Wed Dec 25 14:47:17 2019: GMM converted to Variational GMM
, Wed Dec 25 14:47:26 2019: iteration 1, lowerbound -3.821855
, Wed Dec 25 14:47:26 2019: iteration 2, lowerbound -3.683593
, Wed Dec 25 14:47:26 2019: iteration 3, lowerbound -3.518647
, Wed Dec 25 14:47:26 2019: iteration 4, lowerbound -3.311766
, Wed Dec 25 14:47:26 2019: iteration 5, lowerbound -3.090938
, Wed Dec 25 14:47:26 2019: iteration 6, lowerbound -2.895509
, Wed Dec 25 14:47:26 2019: dropping number of Gaussions to 7
, Wed Dec 25 14:47:26 2019: iteration 7, lowerbound -2.748512
, Wed Dec 25 14:47:26 2019: dropping number of Gaussions to 6
, Wed Dec 25 14:47:26 2019: iteration 8, lowerbound -2.651249
, Wed Dec 25 14:47:26 2019: dropping number of Gaussions to 4
, Wed Dec 25 14:47:26 2019: iteration 9, lowerbound -2.583997
, Wed Dec 25 14:47:26 2019: dropping number of Gaussions to 3
, Wed Dec 25 14:47:26 2019: iteration 10, lowerbound -2.521303
, Wed Dec 25 14:47:26 2019: iteration 11, lowerbound -2.469819
, Wed Dec 25 14:47:26 2019: iteration 12, lowerbound -2.427472
, Wed Dec 25 14:47:26 2019: iteration 13, lowerbound -2.390651
, Wed Dec 25 14:47:26 2019: iteration 14, lowerbound -2.358376
, Wed Dec 25 14:47:26 2019: iteration 15, lowerbound -2.331107
, Wed Dec 25 14:47:26 2019: iteration 16, lowerbound -2.312681
, Wed Dec 25 14:47:26 2019: iteration 17, lowerbound -2.307534
, Wed Dec 25 14:47:26 2019: dropping number of Gaussions to 2
, Wed Dec 25 14:47:26 2019: iteration 18, lowerbound -2.302922
, Wed Dec 25 14:47:26 2019: iteration 19, lowerbound -2.299260
, Wed Dec 25 14:47:26 2019: iteration 20, lowerbound -2.299256
, Wed Dec 25 14:47:26 2019: iteration 21, lowerbound -2.299254
, Wed Dec 25 14:47:26 2019: iteration 22, lowerbound -2.299254
, Wed Dec 25 14:47:26 2019: iteration 23, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 24, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 25, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 26, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 27, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 28, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 29, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 30, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 31, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 32, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 33, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 34, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 35, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 36, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 37, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 38, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 39, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 40, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 41, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 42, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 43, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 44, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 45, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 46, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 47, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 48, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 49, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: iteration 50, lowerbound -2.299253
, Wed Dec 25 14:47:26 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260139, 95.95490777398608]
β = [178.0450922260139, 95.95490777398608]
m = [4.25030073326991 79.28686694436185; 2.00022925777537 53.85198717246128]
ν = [180.0450922260139, 97.95490777398608]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484843 -0.007644049042327528; 0.0 0.008581705166333562], [0.3758763611948425 -0.008953123827346046; 0.0 0.012748664777409296]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -1.0150033013360114
avll from llpg:  -1.015003301336012
avll direct:     -1.015003301336012
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.976662961766014
avll from llpg:  -0.9766629617660142
avll direct:     -0.9766629617660142
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0237409     0.0256243   -0.0140278   0.0338723    0.131648     0.198599     -0.0526915    -0.0197335    -0.0955283   0.00853902  -0.0479681    -0.0818481     0.0462534   0.0839338    0.0506872  -0.0200763    0.0135662    0.0503028    0.0816576    -0.0719801   -0.0115917    -0.00310984  -0.033696     0.0230567  -0.0444446   -0.126513
 -0.102865     -0.163203     0.0904946  -0.128112    -0.0758253    0.0376662    -0.0396792     0.0406725    -0.177253   -0.00561013   0.00340419    0.0783957     0.0197144  -0.039391    -0.0185243  -0.106784    -0.0312292    0.160493     0.0281641     0.0833265   -0.00542625    0.00473797   0.0180728    0.0792472  -0.087477     0.090948
  0.011892      0.0555986   -0.0917742   0.0674288    0.0194955    0.157115      0.0453453    -0.0356925     0.0869002  -0.157666     0.0569568     0.100103      0.103408   -0.0585227    0.12515    -0.0318403   -0.0512046    0.11705     -0.0816357     0.0323343   -0.113508     -0.0184518    0.0358637   -0.0788056  -0.0277249    0.189321
  0.085915      0.0883895   -0.0277871   0.136435     0.0328419    0.0914699     0.213889     -0.00447196    0.106811    0.0209664   -0.116758     -0.0313057     0.023713   -0.00478032  -0.13524     0.0865529    0.0938672   -0.0806055    0.0797392    -0.00911595   0.000685945  -0.133474     0.0453325   -0.131672    0.011759     0.0426496
 -0.17324      -0.151245     0.0813277   0.0986369    0.00786706   0.139709     -0.114062      0.0467171     0.133175   -0.237631    -0.184084      0.0343486    -0.290992   -0.146858    -0.139694   -0.0587916    0.0598246   -0.061377     0.0320032     0.227351     0.0278645     0.0673187   -0.0568002    0.0433918  -0.0469333    0.06945
  0.0849724    -0.0912414    0.135183    0.0501762    0.156036    -0.0576781     0.0477699    -0.0369618    -0.0413775   0.0236352    0.0797266     0.0784315     0.0182767  -0.0306812   -0.0496879   0.0890566   -0.0384159    0.247903    -0.124028      0.023571    -0.0603368    -0.0978418   -0.199597     0.142758    0.176928    -0.0144934
 -0.0356974    -0.0191527    0.0575032  -0.0412504    0.0462549   -0.0208528     0.02352      -0.0788252     0.202796    0.0139613    0.297619      0.0605678    -0.0534643  -0.103836    -0.0407575   0.220334     0.173079    -0.130669     0.0572492     0.0875737    0.0493962     0.0451021   -0.0814032    0.0219991   0.00368667  -0.119442
 -0.00309457   -0.0424801   -0.100209    0.0167446    0.152098    -0.165442     -0.0475834    -0.124022     -0.0469952   0.139704    -0.0346945     0.0285527    -0.0950095  -0.0830474    0.047437    0.0248595    0.0572832    0.0864016   -0.138227     -0.04985      0.0536062     0.026208     0.0676779    0.106862    0.0678992   -0.0387017
 -0.0915998    -0.0809176    0.10979    -0.0123358    0.00213586  -0.156936     -0.0479866    -0.0316429    -0.0889912   0.0408214   -0.237088     -0.107228      0.0144527  -0.0308138    0.0477543   0.00904785   0.116904     0.0621318   -0.0838319     0.0398472   -0.195834      0.0795109   -0.158493     0.126387    0.0793896   -0.0852484
 -0.0960263    -0.042938    -0.264679   -0.117535    -0.048783     0.0262663    -0.0101915    -0.017066      0.0704078   0.0812341   -0.0586605     0.0608143     0.0369598  -0.0514749    0.0107546  -0.118432     0.129749     0.0134182    0.0833481     0.0556843    0.0391385     0.035423    -0.00500995  -0.113787   -0.0222225    0.172573
  0.0940293     0.139402    -0.113363    0.0223595   -0.0567941    0.0108557     0.0999743    -0.0709234    -0.113774   -0.0621493   -0.0742593     0.00323149    0.0619652  -0.0476546    0.0308121   0.0122775    0.119704     0.307145    -0.0196135     0.0932728    0.186597     -0.0066046   -0.150273    -0.0616855   0.0718386    0.210149
 -0.122686      0.0550285   -0.0798703  -0.0180668    0.085609    -0.0175359     0.0214407     0.0736868     0.120485    0.0787519    0.095143      0.0292142     0.0140515  -0.0211217    0.0500346  -0.0154059   -0.0103165   -0.059757    -0.185057     -0.0798041   -0.105971     -0.136639     0.0208139   -0.0452717   0.0377002    0.0990011
  0.0854971     0.0883038   -0.159119    0.0486715    0.0588306   -0.116101     -0.0355258     0.0354758     0.01389     0.0372996   -0.226421     -0.0162961    -0.0981589   0.242367    -0.012884   -0.186595     0.0142228   -0.156452     0.169363      0.0352811   -0.167603     -0.0250458    0.0642595   -0.11088     0.0343403    0.0545979
  0.0833443     0.0506794   -0.0703819   0.0240921   -0.12382      0.0228085    -0.109917      0.0118528    -0.0116927   0.0196843    0.0762636    -0.170309      0.192024    0.0252002    0.0277231   0.00153529  -0.043793     0.0238771    0.0572214     0.0587816    0.0619143     0.0655373   -0.0352721   -0.0677681  -0.00088508   0.139208
  0.0470452    -0.0170922    0.105225    0.0237579    0.146482    -0.120919      0.0613442     0.020137     -0.125857    0.0870408   -0.0649345    -0.0412916    -0.0917863  -0.059625    -0.177069   -0.057567     0.118486     0.0238345   -0.0321632     0.0351853    0.0369171    -4.5183e-5   -0.120808     0.102905   -0.086442    -0.0145874
  0.15826       0.0775807    0.0407998  -0.00310718  -0.244593     0.15104      -0.0064951    -0.19068      -0.166516   -0.0977173    0.0385185     0.0570271     0.117618    0.0289985   -0.0119837   0.062679    -0.133711    -0.187208     0.166672      0.16621     -0.00949549   -0.127215     0.219275     0.0368444  -0.0573946    0.00347383
  0.0217827    -0.124001     0.112633   -0.0192484   -0.0491918   -0.0190905    -0.0680415     0.0949344     0.0870483   0.079359     0.0678001     0.0262193     0.0377195  -0.119293    -0.0168771   0.0317608   -0.0598406   -0.0398956    0.0232932    -0.0533623    0.0815392     0.242311    -0.132375     0.0518073  -0.162219    -0.0202179
 -0.0184637     0.0650163   -0.0836097   0.00170094  -0.176473    -0.00843664    0.0244583     0.0262992     0.085159   -0.0559986   -0.0637829     0.0104899     0.13996     0.0367328    0.0867007   0.00341844   0.0264927    0.0873636    0.000972581  -0.139587    -0.0071213    -0.00127076   0.0354858   -0.137272    0.0708337   -0.0254397
  0.21159      -0.128816     0.0618733  -0.116815     0.0721857    0.172316     -0.00226212    0.132486      0.0608155  -0.055855     0.213123      0.00233772   -0.0325622  -0.0967614    0.0344914  -0.0484943    0.0158637    0.0504025    0.00258544    0.0583084   -0.172592     -0.0207121    0.0602195   -0.04603    -0.185302    -0.0967965
  0.257344     -0.0984107   -0.0591089   0.0665863   -0.106113    -0.250356     -0.0155625     0.0319973    -0.0356218   0.129283    -0.000812601   0.169292      0.082455    0.0780283   -0.0892589   0.0305777    0.0527367   -0.072615     0.0191163     0.00505905   0.0551635     0.0192541    0.0711464   -0.112917    0.00808109   0.10009
  0.0992054    -0.0602581   -0.0511622   0.00945671   0.0115084    0.186708     -0.0699013     0.000911766  -0.0609497  -0.0990382    0.0211467     0.223962     -0.0230286  -0.0245431   -0.146522   -0.0191475   -0.0352991    0.165658     0.0929396    -0.134179    -0.00266038    0.0916364    0.126058    -0.0924568  -0.124822     0.0554629
 -0.263388      0.179935    -0.0854181  -0.0487193    0.0794723    0.123371     -0.176251      0.165451     -0.119823   -0.0419263    0.0698761    -0.0361532    -0.10084     0.0310614    0.0440626  -0.125872     0.111047    -0.0724089   -0.200164      0.088248    -0.102207      0.0853222   -0.0665795   -0.0375693   0.0277322   -0.0861502
 -0.000342145   0.067955     0.216169    0.0537463    0.0626264    0.0151109     0.0862941     0.0692286     0.0108463  -0.201714     0.141024     -0.170707     -0.215201    0.00862235  -0.0518933  -0.0244013   -0.137304     0.0191735    0.0324591    -0.135167     0.292877     -0.0774067   -0.112861    -0.050277   -0.0180856    0.206593
  0.00419116    0.227386    -0.0712017  -0.0400397    0.101399     0.0207959     0.0887464    -0.0652088    -0.0634649  -0.171491     0.0370907    -0.190508      0.115599    0.0582004   -0.0833973   0.176538     0.017573    -0.180034    -0.105853      0.0636876    0.029361     -0.135213     0.0555539   -0.0992366   0.0333948   -0.0197771
 -0.0106797    -0.013915    -0.101244   -0.053259    -0.0185195   -0.000387322  -0.000274555  -0.139992     -0.134561   -0.0925421   -0.0554124    -0.148444      0.10287    -0.0479923    0.0539026  -0.147842     0.0293926    0.096389     0.184554     -0.200746     0.136777     -0.0963826   -0.0265136   -0.051611   -0.130992    -0.0059008
 -0.0349215    -0.0160142    0.0597963  -0.0463637   -0.144076     0.146299      0.0740004     0.094216     -0.046018    0.0233103   -0.236843      0.154553     -0.0295728  -0.0405839   -0.0148744  -0.0285739   -0.0183453   -0.0582779    0.0251083     0.0670091    0.0815421    -0.0895408    0.10699     -0.0250726   0.0152438    0.0696408
 -0.00381096    0.127767    -0.228047   -0.0678466   -0.0448009   -0.0268338     0.0340172    -0.0102199     0.0813972  -0.0592326    0.025702      0.122978      0.0749641  -0.0925964   -0.114994   -0.154489    -0.0391938   -0.0572101   -0.152985      0.023785    -0.0101236    -0.018408     0.0732796    0.012685   -0.0505192   -0.00657333
  0.234766     -0.00889487   0.0220891   0.0266582   -0.104684    -0.0181012     0.040243      0.0718266    -0.0597338  -0.103524     0.144833      0.112312     -0.0403002   0.0582545    0.058159   -0.0153561   -0.02185     -0.0612964   -0.0741785     0.0666165   -0.0718975     0.141785     0.0411751    0.0868169  -0.0112789    0.0026951
  0.234981     -0.0838178    0.107281   -0.00190405   0.0404121   -0.0576476    -0.031324     -0.0272133     0.0903486  -0.0941516    0.0467113     0.0475481     0.0399773   0.0493292    0.0287565   0.200219     0.0233279   -0.109932     0.0475314    -0.155631    -0.0891916    -0.104784    -0.172611    -0.0516155   0.086961    -0.0413876
 -0.0796568     0.0385598    0.104616   -0.11655     -0.0988792    0.0473691     0.129738     -0.0943094     0.0211764  -0.0698802    0.108655     -0.000235466   0.0360019  -0.0823567   -0.0796443   0.0877711   -0.0743191   -0.00275836  -0.059984      0.171644    -0.027504      0.0302476   -0.00699136  -0.128578    0.0265847   -0.0290654
 -0.0382354     0.168246    -0.0462408  -0.131852    -0.0268502   -0.0606734     0.00299922    0.0806759     0.0519987   0.0874253    0.0535753    -0.0555368     0.0664157  -0.227677     0.101956    0.0576193   -0.00517563   0.190238    -0.0773309     0.261697     0.120019     -0.0707507    0.107455     0.0203992   0.332696    -0.0856027
  0.136697     -0.132978     0.001607    0.00455279   0.0198921   -0.0619095     0.0158894     0.190463      0.0555979  -0.00510144  -0.00721756   -0.081558     -0.0125277   0.0783512   -0.0184885  -0.0251059   -0.126804    -0.243995    -0.0565982     0.0484584   -0.0861353    -0.0136235   -0.080789     0.0462423  -0.125982    -0.0876937kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3934323844200245
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.393507
[ Info: iteration 2, average log likelihood -1.393408
[ Info: iteration 3, average log likelihood -1.392027
[ Info: iteration 4, average log likelihood -1.382178
[ Info: iteration 5, average log likelihood -1.365423
[ Info: iteration 6, average log likelihood -1.357523
[ Info: iteration 7, average log likelihood -1.354533
[ Info: iteration 8, average log likelihood -1.353083
[ Info: iteration 9, average log likelihood -1.352337
[ Info: iteration 10, average log likelihood -1.351874
[ Info: iteration 11, average log likelihood -1.351536
[ Info: iteration 12, average log likelihood -1.351243
[ Info: iteration 13, average log likelihood -1.350958
[ Info: iteration 14, average log likelihood -1.350730
[ Info: iteration 15, average log likelihood -1.350581
[ Info: iteration 16, average log likelihood -1.350485
[ Info: iteration 17, average log likelihood -1.350419
[ Info: iteration 18, average log likelihood -1.350369
[ Info: iteration 19, average log likelihood -1.350328
[ Info: iteration 20, average log likelihood -1.350291
[ Info: iteration 21, average log likelihood -1.350258
[ Info: iteration 22, average log likelihood -1.350225
[ Info: iteration 23, average log likelihood -1.350194
[ Info: iteration 24, average log likelihood -1.350164
[ Info: iteration 25, average log likelihood -1.350140
[ Info: iteration 26, average log likelihood -1.350120
[ Info: iteration 27, average log likelihood -1.350106
[ Info: iteration 28, average log likelihood -1.350095
[ Info: iteration 29, average log likelihood -1.350088
[ Info: iteration 30, average log likelihood -1.350084
[ Info: iteration 31, average log likelihood -1.350081
[ Info: iteration 32, average log likelihood -1.350079
[ Info: iteration 33, average log likelihood -1.350078
[ Info: iteration 34, average log likelihood -1.350077
[ Info: iteration 35, average log likelihood -1.350077
[ Info: iteration 36, average log likelihood -1.350076
[ Info: iteration 37, average log likelihood -1.350076
[ Info: iteration 38, average log likelihood -1.350076
[ Info: iteration 39, average log likelihood -1.350076
[ Info: iteration 40, average log likelihood -1.350076
[ Info: iteration 41, average log likelihood -1.350076
[ Info: iteration 42, average log likelihood -1.350076
[ Info: iteration 43, average log likelihood -1.350076
[ Info: iteration 44, average log likelihood -1.350076
[ Info: iteration 45, average log likelihood -1.350076
[ Info: iteration 46, average log likelihood -1.350076
[ Info: iteration 47, average log likelihood -1.350076
[ Info: iteration 48, average log likelihood -1.350076
[ Info: iteration 49, average log likelihood -1.350076
[ Info: iteration 50, average log likelihood -1.350076
┌ Info: EM with 100000 data points 50 iterations avll -1.350076
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3935066601644346
│     -1.3934082950670017
│      ⋮
└     -1.3500757477380003
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.350210
[ Info: iteration 2, average log likelihood -1.350091
[ Info: iteration 3, average log likelihood -1.349433
[ Info: iteration 4, average log likelihood -1.343749
[ Info: iteration 5, average log likelihood -1.330014
[ Info: iteration 6, average log likelihood -1.320578
[ Info: iteration 7, average log likelihood -1.317593
[ Info: iteration 8, average log likelihood -1.316249
[ Info: iteration 9, average log likelihood -1.315157
[ Info: iteration 10, average log likelihood -1.314055
[ Info: iteration 11, average log likelihood -1.313010
[ Info: iteration 12, average log likelihood -1.312077
[ Info: iteration 13, average log likelihood -1.311134
[ Info: iteration 14, average log likelihood -1.310040
[ Info: iteration 15, average log likelihood -1.308732
[ Info: iteration 16, average log likelihood -1.307396
[ Info: iteration 17, average log likelihood -1.306370
[ Info: iteration 18, average log likelihood -1.305756
[ Info: iteration 19, average log likelihood -1.305397
[ Info: iteration 20, average log likelihood -1.305167
[ Info: iteration 21, average log likelihood -1.305003
[ Info: iteration 22, average log likelihood -1.304875
[ Info: iteration 23, average log likelihood -1.304772
[ Info: iteration 24, average log likelihood -1.304689
[ Info: iteration 25, average log likelihood -1.304622
[ Info: iteration 26, average log likelihood -1.304571
[ Info: iteration 27, average log likelihood -1.304531
[ Info: iteration 28, average log likelihood -1.304500
[ Info: iteration 29, average log likelihood -1.304474
[ Info: iteration 30, average log likelihood -1.304454
[ Info: iteration 31, average log likelihood -1.304435
[ Info: iteration 32, average log likelihood -1.304415
[ Info: iteration 33, average log likelihood -1.304392
[ Info: iteration 34, average log likelihood -1.304361
[ Info: iteration 35, average log likelihood -1.304317
[ Info: iteration 36, average log likelihood -1.304250
[ Info: iteration 37, average log likelihood -1.304156
[ Info: iteration 38, average log likelihood -1.304043
[ Info: iteration 39, average log likelihood -1.303931
[ Info: iteration 40, average log likelihood -1.303838
[ Info: iteration 41, average log likelihood -1.303770
[ Info: iteration 42, average log likelihood -1.303723
[ Info: iteration 43, average log likelihood -1.303689
[ Info: iteration 44, average log likelihood -1.303663
[ Info: iteration 45, average log likelihood -1.303644
[ Info: iteration 46, average log likelihood -1.303629
[ Info: iteration 47, average log likelihood -1.303618
[ Info: iteration 48, average log likelihood -1.303608
[ Info: iteration 49, average log likelihood -1.303601
[ Info: iteration 50, average log likelihood -1.303595
┌ Info: EM with 100000 data points 50 iterations avll -1.303595
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.350210276025879
│     -1.3500908541425722
│      ⋮
└     -1.3035945672037004
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.303800
[ Info: iteration 2, average log likelihood -1.303595
[ Info: iteration 3, average log likelihood -1.302779
[ Info: iteration 4, average log likelihood -1.295778
[ Info: iteration 5, average log likelihood -1.277127
[ Info: iteration 6, average log likelihood -1.263157
[ Info: iteration 7, average log likelihood -1.257388
[ Info: iteration 8, average log likelihood -1.254745
[ Info: iteration 9, average log likelihood -1.253386
[ Info: iteration 10, average log likelihood -1.252615
[ Info: iteration 11, average log likelihood -1.252100
[ Info: iteration 12, average log likelihood -1.251680
[ Info: iteration 13, average log likelihood -1.251315
[ Info: iteration 14, average log likelihood -1.251037
[ Info: iteration 15, average log likelihood -1.250856
[ Info: iteration 16, average log likelihood -1.250736
[ Info: iteration 17, average log likelihood -1.250649
[ Info: iteration 18, average log likelihood -1.250583
[ Info: iteration 19, average log likelihood -1.250529
[ Info: iteration 20, average log likelihood -1.250483
[ Info: iteration 21, average log likelihood -1.250439
[ Info: iteration 22, average log likelihood -1.250393
[ Info: iteration 23, average log likelihood -1.250344
[ Info: iteration 24, average log likelihood -1.250294
[ Info: iteration 25, average log likelihood -1.250243
[ Info: iteration 26, average log likelihood -1.250190
[ Info: iteration 27, average log likelihood -1.250134
[ Info: iteration 28, average log likelihood -1.250072
[ Info: iteration 29, average log likelihood -1.250006
[ Info: iteration 30, average log likelihood -1.249938
[ Info: iteration 31, average log likelihood -1.249868
[ Info: iteration 32, average log likelihood -1.249795
[ Info: iteration 33, average log likelihood -1.249721
[ Info: iteration 34, average log likelihood -1.249653
[ Info: iteration 35, average log likelihood -1.249589
[ Info: iteration 36, average log likelihood -1.249533
[ Info: iteration 37, average log likelihood -1.249481
[ Info: iteration 38, average log likelihood -1.249432
[ Info: iteration 39, average log likelihood -1.249379
[ Info: iteration 40, average log likelihood -1.249317
[ Info: iteration 41, average log likelihood -1.249238
[ Info: iteration 42, average log likelihood -1.249130
[ Info: iteration 43, average log likelihood -1.248983
[ Info: iteration 44, average log likelihood -1.248795
[ Info: iteration 45, average log likelihood -1.248584
[ Info: iteration 46, average log likelihood -1.248372
[ Info: iteration 47, average log likelihood -1.248166
[ Info: iteration 48, average log likelihood -1.247986
[ Info: iteration 49, average log likelihood -1.247853
[ Info: iteration 50, average log likelihood -1.247755
┌ Info: EM with 100000 data points 50 iterations avll -1.247755
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3038001007741986
│     -1.3035950084878432
│      ⋮
└     -1.2477545615385846
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.247930
[ Info: iteration 2, average log likelihood -1.247633
[ Info: iteration 3, average log likelihood -1.246664
[ Info: iteration 4, average log likelihood -1.234819
[ Info: iteration 5, average log likelihood -1.194557
[ Info: iteration 6, average log likelihood -1.165892
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.153837
[ Info: iteration 8, average log likelihood -1.163707
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.153305
[ Info: iteration 10, average log likelihood -1.164724
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.152847
[ Info: iteration 12, average log likelihood -1.163463
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.153342
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.158010
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.153566
[ Info: iteration 16, average log likelihood -1.167988
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.154887
[ Info: iteration 18, average log likelihood -1.158965
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.147906
[ Info: iteration 20, average log likelihood -1.163008
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.150396
[ Info: iteration 22, average log likelihood -1.155152
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.145571
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.157005
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.152322
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.155144
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.151549
[ Info: iteration 28, average log likelihood -1.160366
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.149368
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.159093
[ Info: iteration 31, average log likelihood -1.161811
[ Info: iteration 32, average log likelihood -1.150801
[ Info: iteration 33, average log likelihood -1.143478
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.138310
[ Info: iteration 35, average log likelihood -1.169483
[ Info: iteration 36, average log likelihood -1.153312
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.145271
[ Info: iteration 38, average log likelihood -1.154949
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.145563
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.157226
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.151643
[ Info: iteration 42, average log likelihood -1.160200
[ Info: iteration 43, average log likelihood -1.149142
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.141767
[ Info: iteration 45, average log likelihood -1.169903
[ Info: iteration 46, average log likelihood -1.153370
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.145167
[ Info: iteration 48, average log likelihood -1.154849
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.145634
[ Info: iteration 50, average log likelihood -1.157166
┌ Info: EM with 100000 data points 50 iterations avll -1.157166
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2479300231536636
│     -1.2476330386330625
│      ⋮
└     -1.1571662055569276
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.145963
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.142266
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.138049
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│     25
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.112473
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     14
│     21
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.084192
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     20
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.084185
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.067931
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     14
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.053228
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.053071
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     14
│     24
│     27
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.049946
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.049673
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     14
│     20
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.061886
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.051829
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     14
│     24
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.052425
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.049970
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     14
│     24
│     27
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.051313
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.049744
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     14
│     20
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.051321
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.049370
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     14
│     24
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.051592
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.049595
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│      9
│     14
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.050914
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.049526
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     14
│     20
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.051173
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.049287
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     14
│     24
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.051523
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.049566
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│      9
│     14
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.050885
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.049505
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     14
│     20
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.051161
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.049278
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     14
│     24
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.051515
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.049560
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     14
│     24
│     27
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.050887
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.049494
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     14
│     20
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.051157
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.049274
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     14
│     24
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.051518
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.049558
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     14
│     24
│     27
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.050878
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.049491
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     14
│     20
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.051160
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.049271
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│      9
│     14
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.051510
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.049560
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     14
│     24
│     27
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.050876
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.049488
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│      9
│     14
│     20
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.051152
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.049272
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     14
│     24
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.051508
┌ Info: EM with 100000 data points 50 iterations avll -1.051508
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1459629420972373
│     -1.1422663655679748
│      ⋮
└     -1.051507739419765
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3934323844200245
│     -1.3935066601644346
│     -1.3934082950670017
│     -1.3920274187875592
│      ⋮
│     -1.0511515124955855
│     -1.0492720912387015
└     -1.051507739419765
32×26 Array{Float64,2}:
  0.027601      0.0606518    -0.124897   -1.00193     -0.15725     -0.0228891     0.0622563    0.0210681    0.0937671  -0.0664235   -0.054651     0.0101334     0.137851     0.0368095    0.0964267    0.00435217  -0.00225536  -0.0145849    0.0735001   -0.108582    -0.00270495  -0.127313     0.105169     0.0662895    0.0778933    -0.0263188
 -0.0755334     0.0598711    -0.0587429   0.730908    -0.199598     0.00253193    0.0171769    0.0288692    0.0880094  -0.0508189   -0.0608727    0.0104397     0.142193     0.0350464    0.0828787    0.00409649   0.0488885    0.152168    -0.0294971   -0.151547     0.00044876   0.064485    -0.0271806   -0.261337     0.0575577    -0.0237787
  0.112062      0.0809759    -0.162626    0.0461285    0.0546505   -0.101368     -0.038796     0.0583703   -0.132456    0.0642793   -0.184655    -0.00817728   -0.100471     0.285206     0.0196981   -0.191667     0.0229488   -0.0654434    0.151153     0.0546516   -0.191263    -0.0195635    0.0505783   -0.0457711    0.0292224     0.0474845
  0.0211461     0.113029     -0.144599    0.0547915    0.060168    -0.131649     -0.0313577   -0.0300204    0.147504    0.00892585  -0.223724    -0.0506767    -0.0937523    0.191929    -0.094287    -0.161693     0.0203894   -0.420853     0.201918    -0.0316464   -0.122717    -0.0189758    0.0463719   -0.114407     0.0474807     0.0995071
 -0.171199     -0.130339     -1.15666     0.141639     0.0341493    0.121191     -0.0901377    0.0231637    0.129701   -0.239511    -0.207304    -0.0667711    -0.285318    -0.193147    -0.123276    -0.0534337   -0.0481486   -0.109669     0.0882521    0.24097      0.0294868    0.108775    -0.0069105    0.0353193   -0.111094      0.115794
 -0.175629     -0.128465      1.31792     0.057453    -0.00615643   0.143773     -0.141082     0.0787222    0.174841   -0.236451    -0.17861      0.170195     -0.280908    -0.130846    -0.15378     -0.104789     0.171419     0.0679026   -0.0152733    0.219637     0.0217959    0.0177109   -0.0992214    0.0355887    0.0220325     0.0138613
 -0.130796     -0.0828199     0.129034    0.026709    -0.034083    -0.177476     -0.0551864   -0.0315185   -0.30404     0.0913007   -0.584838     0.00108263    0.0396492   -0.0308984    0.041634    -0.0410873    0.120038     0.0616413    0.158541    -0.367847    -0.196075     0.113665    -0.164188     0.142107     0.260301     -0.0975913
 -0.0963649    -0.093254      0.0921802  -0.0636148    0.0515528   -0.130883     -0.0511616   -0.0312169    0.120783   -0.0453034    0.138213    -0.20043      -0.00816365  -0.0310102    0.0660373   -0.00690957   0.117539     0.0819868   -0.350516     0.350587    -0.195665     0.103733    -0.156083     0.112708    -0.0574846    -0.0838934
  0.0686968     0.0474086    -0.548986    0.0295023   -0.0127837   -0.057635     -0.0353265   -0.125436    -0.0960548  -0.0355251   -0.039441    -0.115804      0.0885525   -0.0491217    0.0440988   -0.175086    -0.0058598    0.0932424    0.0379162   -0.180297     0.128929    -0.115373    -0.0558045   -0.0509341   -0.116781     -0.0158584
 -0.0795573    -0.0275366     0.538783   -0.131914    -0.0196382    0.0503635    -0.0045838   -0.157713    -0.158278   -0.0387964   -0.113189    -0.203322      0.19375      0.043054     0.0727756   -0.0715245    0.0709902    0.0803759    0.419747    -0.23414      0.130936    -0.0689529    0.0328404   -0.0542462   -0.162591      0.00544427
  0.1139        0.0461114     0.116753    0.0277885   -0.072725     0.0262128     0.0213525   -0.0805154   -0.153419   -0.0279892    0.00197964   0.0209503     0.0285727   -0.0307929   -0.0861956    0.00388522  -0.00816761  -0.109431     0.0776977    0.113944     0.0104871   -0.0715443    0.0744818    0.0696873   -0.0790933     0.00544547
 -0.0986347     0.0566972     0.0242268  -0.069234    -0.0018128   -0.0193107     0.0697684   -0.0181735    0.0741194   0.0125401    0.0761384    0.0159123     0.0135398   -0.0575669   -0.0136662    0.00284804  -0.0574195   -0.071609    -0.132286     0.0505105   -0.0633861   -0.0699084    0.00460671  -0.0839966    0.0333133     0.0366253
  0.099341      0.088494     -0.0971504   0.0658375   -0.0721961    0.0502087     0.10199     -0.0740587   -0.113347   -0.0614106   -0.07512      0.000950697   0.0635299   -0.0446114    0.0373205    0.010648     0.129222     0.299154     0.00631752   0.142348     0.184084     0.00762723  -0.146651    -0.0674613    0.0734336     0.174619
  0.000237532   0.066966      0.201833    0.0526666    0.0602582   -0.000440764   0.0746615    0.0888517   -0.0030381  -0.191753     0.143722    -0.170249     -0.233385     0.0189318   -0.0509137   -0.0315061   -0.137479     0.0192455    0.0466822   -0.147394     0.293331    -0.0780392   -0.113557    -0.0458772   -0.0176844     0.20285
  0.0979273     0.0535558    -0.0511516   0.0296188   -0.133951     0.0360227    -0.113126     0.00433545  -0.009421    0.0177779    0.0798605   -0.177139      0.189389     0.027761     0.0420965   -0.0331147   -0.0438298    0.0286585    0.0714662    0.059812     0.0421672    0.059804    -0.0419273   -0.0791528    0.000412692   0.14077
  0.0121472     0.0556469    -0.0424932   0.0854679    0.0992172    0.110573      0.079372    -0.0300571    0.0142454   0.0802568   -0.0888665   -0.0436745     0.0754652    0.0480766   -0.04248      0.0285437    0.0571678    0.0229543    0.0582907   -0.00778345  -0.00261099  -0.0447022    0.00479029  -0.0483818   -0.0141569    -0.040279
 -0.181299      0.0629702    -0.176682   -0.0823912    0.0102893    0.0787888    -0.0772748    0.0580764   -0.0147637   0.041613     0.00754867   0.0188402    -0.035486    -0.00429468  -0.00407846  -0.106198     0.123886    -0.00523085  -0.0359569    0.0735728   -0.0247125    0.0377156   -0.0643285   -0.0707448   -0.00871924    0.0298699
  0.0309342    -0.00854747    0.0170621   0.0606871    0.0957422    0.0427343     0.0497082   -0.0286596    0.0387909  -0.0752575    0.0704242    0.111216      0.0790117   -0.0454807    0.052949     0.020295    -0.0494148    0.194554    -0.136716     0.0310173   -0.103735    -0.0584794   -0.0633409    0.0206369    0.060198      0.118091
  0.0651241    -0.000296276  -0.10898    -0.0306813   -0.00843732  -0.0546741     0.0257256    0.0892664    0.0565314  -0.0399134   -0.00339795   0.0281758     0.0280289   -0.00644139  -0.0662634   -0.105928    -0.0819215   -0.133495    -0.0882119    0.0390995   -0.0435491   -0.0119783   -0.0134202    0.0395426   -0.0899478    -0.0473823
 -0.103318     -0.157363      0.0922682  -0.129066    -0.0489559    0.0330474    -0.019969     0.038574    -0.179402    0.00111244   0.0011605    0.085753      0.0573412   -0.0400187    0.0224063   -0.0796801   -0.0348522    0.159356     0.0323383    0.0657776   -0.0162169    0.0107792    0.0379666    0.0638284   -0.102783      0.0798696
 -0.046866     -0.0721546     0.0621525  -0.0499988   -0.152425     0.140012      0.0719969    0.083398    -0.0406075   0.0328539   -0.264899     0.182823     -0.0422008   -0.0423557    0.0121379   -0.0306678   -0.0433408   -0.0597798    0.0202126    0.0209615    0.0756173   -0.0978246    0.120535    -0.0253314   -0.0027135     0.0713114
  0.183475     -0.094321      0.0993328   0.00843819   0.0605261   -0.0655809    -0.00974683  -0.0189084    0.0473608  -0.108813     0.0574015    0.00947011    0.0340944    0.052112    -0.0379625    0.207447     0.0136433   -0.0887494    0.0558394   -0.164733    -0.0895928   -0.108933    -0.163972    -0.0887285    0.124649     -0.0374403
 -0.00709697   -0.0561785    -0.0805207  -0.0117317    0.0778095   -0.128612     -0.044517    -0.123464    -0.0482437   0.123382    -0.0376774    0.0267287    -0.0967166   -0.0978123    0.0351199    0.0258249    0.106719     0.0707032   -0.137858    -0.090694     0.0517601    0.0227661    0.092429     0.104434     0.0712462    -0.0834045
  0.0127606     0.265801     -0.0652127  -0.0382145    0.135596    -0.00650617    0.0838572   -0.0705537   -0.0639835  -0.152578     0.0389877   -0.211288      0.0937364    0.0505382   -0.086617     0.177501     0.0705438   -0.179301    -0.110329     0.0605734    0.0260624   -0.13534      0.0939918   -0.079865     0.0108282     0.0186438
  0.229027     -0.11588       0.0888315  -0.110738     0.0580889    0.175378     -0.004094     0.14054      0.0550766  -0.0675274    0.205491     0.00271836   -0.0330589   -0.0893564    0.0270782   -0.0560641    0.0191675    0.0479981    0.0155098    0.0430136   -0.164589    -0.0491637    0.0725472   -0.0292908   -0.188189     -0.0918761
 -0.0360678     0.147067     -0.0445962  -0.0943173   -0.025496    -0.059346      0.00262991   0.0879984    0.0402893   0.107405     0.0556955   -0.0551266     0.0612761   -0.225785     0.104403     0.0488196    0.00153532   0.189491    -0.0443829    0.23095      0.115303    -0.0652379    0.0554987   -0.0164772    0.313928     -0.0802486
 -0.0368727    -0.0230138     0.0284618   0.170238     0.0650739   -0.020901      0.0676417   -0.139463     0.15464     0.0987952    0.290504     0.0283701    -0.0576773   -0.146331    -0.0359775    0.152562     0.129981    -0.136272     0.184842     0.0886289    0.0593901    0.00252402  -0.0841286   -0.34353      0.0408824    -0.0489516
 -0.0577695    -0.00550562    0.0896492  -0.23981      0.0185623   -0.0210108    -0.0473314   -0.0140762    0.184134   -0.0446228    0.276426     0.0819423    -0.0525115   -0.0196998   -0.0538779    0.189437     0.177999    -0.143978    -0.0299927    0.0903465    0.0388451    0.0956419   -0.0832657    0.334194    -0.0393829    -0.13531
  0.104251     -0.0552373    -0.0675196   0.00821695   0.0148932    0.170729     -0.0656043    0.0020622   -0.0608454  -0.177641     0.0181129    0.23409      -0.0470829   -0.0314499   -0.144324    -0.0206631   -0.0751642    0.164829     0.0921803   -0.129849    -0.00755232   0.0914479    0.0897357   -0.136426    -0.150122      0.0582841
  0.0306691    -0.137121      0.109806   -0.00975423  -0.0731522   -0.0396339    -0.0642276    0.090775     0.0808007   0.0590934    0.0611448    0.023572      0.039999    -0.0481278   -0.0233663    0.0274958   -0.0608577   -0.0372412    0.0355526   -0.0553371    0.0775127    0.238311    -0.131443     0.00777492  -0.145208     -0.0193887
  0.24414      -0.161754     -0.0562005   0.0655367   -0.1358      -0.254318     -0.0169959    0.0318344   -0.0453116   0.0961535   -0.013802     0.153129      0.0727362    0.0863293   -0.0976105    0.0967342    0.0505296   -0.0728077    0.0108568   -0.00552505   0.0522747    0.0196751    0.0681997   -0.129751     0.014445      0.0966256
  0.232534     -0.00226161    0.0256849   0.0262793   -0.092567    -0.0117378     0.0407955    0.0570767   -0.0759869  -0.0961674    0.149574     0.110366     -0.0232663    0.0518661    0.0567257   -0.0243797   -0.0253479   -0.0648378   -0.0541665    0.0843059   -0.0449379    0.141523     0.0149018    0.0749055   -0.00892627    0.00606184[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.049549
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.028958
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.041024
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.036565
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.041626
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.028109
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.049476
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.028907
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.040994
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.036519
┌ Info: EM with 100000 data points 10 iterations avll -1.036519
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.538110e+05
      1       6.650188e+05      -1.887922e+05 |       32
      2       6.354625e+05      -2.955631e+04 |       32
      3       6.158086e+05      -1.965383e+04 |       32
      4       6.027674e+05      -1.304121e+04 |       32
      5       5.968890e+05      -5.878398e+03 |       32
      6       5.941076e+05      -2.781467e+03 |       32
      7       5.928336e+05      -1.273960e+03 |       32
      8       5.921273e+05      -7.062902e+02 |       32
      9       5.916453e+05      -4.820357e+02 |       32
     10       5.912249e+05      -4.203516e+02 |       32
     11       5.907810e+05      -4.439578e+02 |       32
     12       5.902236e+05      -5.573637e+02 |       32
     13       5.895795e+05      -6.440698e+02 |       32
     14       5.887709e+05      -8.086771e+02 |       32
     15       5.878657e+05      -9.051959e+02 |       32
     16       5.870237e+05      -8.419689e+02 |       32
     17       5.863521e+05      -6.715736e+02 |       32
     18       5.857767e+05      -5.754063e+02 |       32
     19       5.853288e+05      -4.479655e+02 |       32
     20       5.849917e+05      -3.370491e+02 |       32
     21       5.847379e+05      -2.537623e+02 |       32
     22       5.845813e+05      -1.566554e+02 |       32
     23       5.844730e+05      -1.082666e+02 |       32
     24       5.843819e+05      -9.110671e+01 |       32
     25       5.843138e+05      -6.813293e+01 |       31
     26       5.842496e+05      -6.421838e+01 |       31
     27       5.841737e+05      -7.588820e+01 |       31
     28       5.840678e+05      -1.059059e+02 |       29
     29       5.839876e+05      -8.020343e+01 |       30
     30       5.839473e+05      -4.029132e+01 |       31
     31       5.839307e+05      -1.662327e+01 |       27
     32       5.839251e+05      -5.564520e+00 |       27
     33       5.839207e+05      -4.377808e+00 |       23
     34       5.839185e+05      -2.222900e+00 |       17
     35       5.839166e+05      -1.906254e+00 |       20
     36       5.839140e+05      -2.591347e+00 |       23
     37       5.839115e+05      -2.461331e+00 |       18
     38       5.839092e+05      -2.337838e+00 |       23
     39       5.839061e+05      -3.050295e+00 |       21
     40       5.839022e+05      -3.942232e+00 |       26
     41       5.838968e+05      -5.358570e+00 |       28
     42       5.838867e+05      -1.017847e+01 |       28
     43       5.838780e+05      -8.642853e+00 |       27
     44       5.838664e+05      -1.157193e+01 |       27
     45       5.838506e+05      -1.588255e+01 |       30
     46       5.838280e+05      -2.259460e+01 |       30
     47       5.838027e+05      -2.528150e+01 |       32
     48       5.837530e+05      -4.965206e+01 |       29
     49       5.836641e+05      -8.893401e+01 |       30
     50       5.835564e+05      -1.077391e+02 |       29
K-means terminated without convergence after 50 iterations (objv = 583556.3608358626)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.297820
[ Info: iteration 2, average log likelihood -1.264674
[ Info: iteration 3, average log likelihood -1.232634
[ Info: iteration 4, average log likelihood -1.193971
[ Info: iteration 5, average log likelihood -1.145615
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     16
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.089273
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     13
│     17
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.087900
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.095615
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.068882
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.047903
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     16
│     17
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.029500
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      5
│     23
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.079234
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.092402
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.054252
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     17
│     22
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.042638
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.084833
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.075087
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     17
│     24
│     27
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.016153
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      8
│     13
│     19
│     22
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.055144
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.117324
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.098023
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.042158
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│     13
│     17
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.023976
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      8
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.079325
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.083798
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     22
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.071476
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     13
│     17
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.042355
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.066457
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      8
│     16
│     19
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.035758
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     22
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.091086
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     17
│     24
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.057111
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      3
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.077735
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     16
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.049319
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      8
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.064893
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     17
│     19
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.044507
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     16
│     23
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.065826
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      5
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.078093
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.068183
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     17
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.039112
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.047987
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.097358
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.074057
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      8
│     13
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.022838
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     16
│     17
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.052018
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      5
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.090853
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.078318
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     13
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.051842
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      8
│     16
│     23
│     25
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.031189
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      5
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.089177
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.084215
┌ Info: EM with 100000 data points 50 iterations avll -1.084215
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0872778    0.0951382  -0.159158     0.0492883    0.0557464  -0.112143    -0.0365734    0.0245759    -0.0324969    0.0421659   -0.200646     -0.0236922    -0.0983652    0.253367    -0.013198    -0.184838     0.0200171   -0.19829     0.167954     0.0286459    -0.17265      -0.0199221     0.0536548   -0.0816035    0.0447959    0.0643691
 -0.00337886   0.0619753   0.205245     0.0615533    0.0481894  -0.0202822    0.0688447    0.117324      0.0157076   -0.191879     0.149431     -0.161233     -0.262559     0.0193081   -0.0496829   -0.0300099   -0.134206     0.0258479   0.0548075   -0.166175      0.282247     -0.0737648    -0.110018    -0.0423876   -0.0187041    0.207255
 -0.00352302  -0.145905    0.0245786   -0.0131897   -0.0560643  -0.0482489    0.00502404   0.0141628    -0.0826396    0.0784798   -0.219865      0.0744168     0.0315707   -0.00916503   0.0327741   -0.0782159    0.127357    -0.0129116   0.0163135    0.152681     -0.090699     -0.0428163    -0.0404934    0.00885166   0.0329211    0.00762855
  0.0144416    0.659838   -0.0581492   -0.02505      0.191184    0.0655938    0.061888    -0.0321026    -0.0799676   -0.127748     0.0307427    -0.338635      0.118802     0.0484257   -0.0938714    0.257869     0.0962718   -0.130865   -0.123131     0.032837      0.0203411    -0.0850003     0.0864417   -0.0659474   -0.00283274  -0.00134652
  0.204025    -0.54269    -0.0546101    0.0138408   -0.17516    -0.372823     0.0111218    0.000258234  -0.0624801    0.0660094   -0.0139025     0.25092       0.0682133    0.0911942   -0.103362     0.0918786    0.0464697   -0.0792603   0.0118181   -0.000567506   0.0554848    -0.0254066     0.0810276   -0.20234      0.0106391    0.122988
  0.230117    -0.122274    0.0889853   -0.112945     0.0563809   0.179159    -0.00479612   0.135419      0.057855    -0.0695715    0.206156      0.00230174   -0.0299332   -0.0862119    0.0293944   -0.0570335    0.0187863    0.0480893   0.0123541    0.0443229    -0.166982     -0.0446809     0.082599    -0.0334511   -0.185497    -0.0954754
  0.102849    -0.0640104  -0.0631851    0.00777944   0.013673    0.164756    -0.0647566    0.00306736   -0.0611526   -0.170643     0.0192571     0.233358     -0.0439828   -0.0308194   -0.14327     -0.0188134   -0.0770415    0.162139    0.0913951   -0.128501     -0.00594487    0.0905684     0.0896715   -0.139605    -0.148428     0.0582593
  0.0432707   -0.141745    0.0964782   -0.00703821  -0.0688784  -0.0650262   -0.0571991    0.0759857     0.0846467    0.0518034    0.0631174     0.0135849     0.0382926   -0.0386637   -0.0283352    0.0245832   -0.0673617   -0.0512928   0.0448006   -0.0456992     0.0841346     0.206029     -0.110943    -0.0143352   -0.12547     -0.00994091
  0.0922552    0.0559075  -0.0488883    0.0306286   -0.133562    0.0447111   -0.11098      0.00452259   -0.00759599   0.0150469    0.0813845    -0.178884      0.187645     0.0285791    0.04123     -0.0375363   -0.0435855    0.0273662   0.0669627    0.0565734     0.0412864     0.056153     -0.0451961   -0.0797464    0.00126354   0.142513
  0.00260702   0.0129601  -0.0461382   -0.0467863   -0.0157825  -0.00862331  -0.0217351   -0.139817     -0.124703    -0.0339874   -0.0768217    -0.156905      0.139583    -0.00915766   0.0577049   -0.127771     0.0288165    0.0867179   0.216289    -0.205826      0.129279     -0.0929608    -0.0145582   -0.0524321   -0.137658    -0.00595782
  0.0383139   -0.0196724   0.106612     0.0318919    0.137233   -0.12903      0.0598874    0.0498319    -0.122086     0.0534762   -0.0500563    -0.0363264    -0.0891501   -0.076135    -0.173303    -0.0607843    0.127602     0.0341045  -0.012165     0.034141      0.0396876    -0.000260957  -0.112929     0.108725    -0.0921153    0.0201269
 -0.171774    -0.133817    0.00960063   0.0982217    0.01331     0.13489     -0.119583     0.0518835     0.146817    -0.23798     -0.191555      0.046295     -0.284918    -0.16116     -0.136951    -0.0818921    0.056044    -0.0270356   0.0373466    0.226326      0.0248334     0.0654723    -0.0476466    0.0410411   -0.0487631    0.066382
  0.148175     0.118255    0.106481     0.0208344   -0.23208     0.136953    -0.005442    -0.175487     -0.161467    -0.102537     0.0387221     0.0582206     0.122944     0.0172463   -0.0111475    0.0546025   -0.122998    -0.217503    0.144264     0.170885     -0.0131698    -0.12569       0.21766      0.0249849   -0.0564575   -0.00279495
 -0.267754     0.182991   -0.0838377   -0.046973     0.063771    0.107089    -0.165121     0.171224     -0.123436    -0.0243815    0.0691974    -0.0364591    -0.127344     0.0374632    0.0205746   -0.116965     0.112217    -0.0688297  -0.15936      0.0914254    -0.102908      0.0519914    -0.0612203   -0.0375167    0.010894    -0.100535
 -0.0780173    0.0537841   0.10411     -0.119528    -0.0944492   0.00580495   0.106437    -0.0913048     0.0362071   -0.0562688    0.0686683    -0.000488062   0.0245041   -0.104987    -0.0800901    0.0658089   -0.053451    -0.0060044  -0.0411897    0.175821     -0.0258796     0.0356009    -0.00798836  -0.131294     0.0419989   -0.026405
 -0.111773    -0.0853416   0.105809    -0.0173167    0.0161717  -0.151396    -0.0498766   -0.0296658    -0.0998735    0.0280261   -0.206016     -0.0957221     0.015761    -0.0319658    0.0500807    0.00828112   0.112205     0.068246   -0.103231    -0.0549511    -0.189479      0.0992639    -0.149022     0.122614     0.101984    -0.0885716
 -0.10686     -0.172666    0.0939917   -0.119044    -0.0312794   0.0403103   -0.00750294   0.0240181    -0.174731    -0.00834205  -0.000171097   0.0761914     0.072732    -0.0305952    0.0142445   -0.112229    -0.0204222    0.121928    0.0438387    0.0677865    -0.0164197    -0.00526901    0.04723      0.116383    -0.0992995    0.0712723
  0.0966888    0.0877385  -0.0829052    0.0649348   -0.0659359   0.0497398    0.099693    -0.0753081    -0.112961    -0.0627809   -0.0655913    -0.00356983    0.0598716   -0.0427147    0.0362839    0.0101636    0.122657     0.287372    0.00423954   0.132071      0.185725      0.00533437   -0.14459     -0.0706863    0.0699023    0.172837
 -0.0410121   -0.0176098   0.0585503   -0.0338444    0.0444608  -0.019441     0.0142161   -0.0795436     0.169848     0.0273453    0.284715      0.0603629    -0.0520897   -0.0754943   -0.0407702    0.179848     0.157401    -0.138575    0.0672097    0.0880072     0.0540961     0.0489446    -0.0813527    0.0013952   -0.00326983  -0.0877668
 -0.00448775  -0.0554659  -0.0797067   -0.0117668    0.0785374  -0.127382    -0.0441589   -0.123126     -0.0503211    0.121217    -0.03692       0.0287045    -0.0960557   -0.0967762    0.0353797    0.0254997    0.105191     0.0705833  -0.13795     -0.0924043     0.0492817     0.0224448     0.090562     0.102889     0.0691551   -0.0815704
 -0.0054407    0.112209   -0.214281    -0.0672481   -0.0480315  -0.0478028    0.00858459  -0.00650899    0.0569393   -0.069618     0.0125752     0.129629      0.0737275   -0.0898364   -0.116333    -0.181746    -0.0444329   -0.0487563  -0.131638     0.027462      0.0199823    -0.0303368     0.0735168    0.0122572   -0.0638911    0.00179812
 -0.0369154    0.147825   -0.0461643   -0.101888    -0.0294549  -0.0618355    0.00422923   0.0857177     0.0415232    0.112501     0.0564953    -0.0551448     0.063817    -0.230837     0.103499     0.0488174   -0.00159583   0.187043   -0.0476598    0.230198      0.121611     -0.0632459     0.0631817   -0.0189161    0.317266    -0.0839112
  0.0364041    0.0760357  -0.0766687    0.119192     0.0448608   0.0911335    0.180079    -0.0521378     0.0983987    0.120446    -0.111641     -0.0118175     0.044928     0.0301079   -0.0996769    0.0623087    0.0787405   -0.034082    0.0614288    0.0247336     0.00910852   -0.0927063     0.0339639   -0.0954319    5.11241e-5   0.0172697
  0.0853581   -0.0876701   0.135032     0.047729     0.153778   -0.0779459    0.0570266   -0.0385058    -0.0443877    0.0379153    0.0721072     0.0862098     0.0419369   -0.0144457   -0.037538     0.090441    -0.0195341    0.214489   -0.136568     0.0305538    -0.0888038    -0.101944     -0.184596     0.145561     0.179255     0.0291484
 -0.141402     0.079949   -0.0720393   -0.015945     0.0870875  -0.0476214    0.0515322    0.0635128     0.119239     0.0765363    0.118734      0.0323644     0.00693339  -0.0138354    0.0716921   -0.099564    -0.089797    -0.155098   -0.238793    -0.0787162    -0.100494     -0.177658      0.0208784   -0.0509271   -0.00595733   0.128253
 -0.105605    -0.0333475  -0.27219     -0.114345    -0.0553709   0.0439838   -0.00366751  -0.0348732     0.0896346    0.0781099   -0.0436448     0.0610942     0.039929    -0.0320477   -0.00848799  -0.106106     0.132883     0.0331196   0.0777621    0.0618448     0.0438222     0.019033     -0.0550469   -0.109711    -0.0299345    0.148555
  0.227575    -0.101047    0.0859361    0.00865873   0.0439335  -0.0536817   -0.0123781   -0.0217037     0.066379    -0.105469     0.0410287     0.012712      0.0258658    0.0506335   -0.0325071    0.206035     0.00511813  -0.0851442   0.0516826   -0.1451       -0.0847234    -0.117224     -0.181769    -0.0825754    0.138457    -0.0318025
  0.188527    -0.0599706   0.0124568    0.015062    -0.0374253  -0.0468889    0.0357245    0.124251     -0.0109527   -0.053495     0.0686364     0.0226928    -0.0215588    0.0651675    0.0241303   -0.0222418   -0.0708477   -0.138148   -0.0508795    0.06359      -0.0701825     0.0709108    -0.0442432    0.0723752   -0.0688868   -0.0401481
 -0.0318187   -0.0807927   0.060007    -0.0396788   -0.140883    0.13442      0.0740248    0.0861898    -0.0396692    0.0268      -0.241322      0.184219     -0.0432648   -0.038739     0.0115127   -0.0260822   -0.0465667   -0.0700201   0.0257004    0.00605481    0.0773007    -0.0848792     0.120289    -0.0411461   -0.007573     0.0680209
 -0.0561942    0.0358025   0.0041336    0.0421322    0.208639    0.219325    -0.093202    -0.00141951   -0.159392     0.0394742   -0.0495456    -0.113046      0.129758     0.0805823    0.0398016   -0.0269114   -0.0112135    0.117627    0.113646    -0.0612437     0.0244975     0.0112922    -0.0176393    0.0115321   -0.0365926   -0.118178
 -0.030729     0.064103   -0.0932835    0.0212208   -0.193      -0.00281476   0.034884     0.0233489     0.0960386   -0.0598274   -0.0605821     0.00915713    0.142012     0.0356387    0.0902063    0.00503779   0.0257707    0.0839773   0.0129462   -0.141646     -0.000482811  -0.0132164     0.0327785   -0.13624      0.0672377   -0.0227605
  0.00703156   0.0462411  -0.069476     0.0604006    0.0281506   0.148116     0.0407725   -0.0183306     0.127569    -0.153239     0.0534202     0.121065      0.104049    -0.0491704    0.107336    -0.0299816   -0.0665824    0.137034   -0.121481     0.0290301    -0.105723     -0.021833      0.0356822   -0.0831337   -0.030039     0.178445[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     16
│     19
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.037706
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      4
│     13
│     16
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.995199
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      8
│     13
│      ⋮
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.002066
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      4
│     13
│     16
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.000210
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     13
│     16
│     19
│     22
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.013925
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│     13
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.988106
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      8
│     13
│      ⋮
│     22
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.014425
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     13
│     16
│     17
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.002737
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      8
│     13
│      ⋮
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.004794
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│     13
│     16
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.992827
┌ Info: EM with 100000 data points 10 iterations avll -0.992827
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0710321    0.012802    -0.0169718   -0.0916206    0.0193372   -0.160917     0.149715     0.124483     0.0438413    0.201257      0.0766095   -0.0583246   -0.113646     -0.0299376    0.0684115   -0.00505992  -0.208924      0.0425721    0.0567866     0.161851     0.0217785    0.0108653   -0.0999932     0.0350488   -0.148724   -0.199746
  0.0882809    0.0516691   -0.037904     0.100013    -0.0482958    0.00843689   0.190442     0.0177584   -0.0576059   -0.0237722     0.0227871   -0.0674203   -0.0469222     0.00373684   0.00904176   0.204364    -0.0127017     0.0625857    0.099916      0.0517487    0.0488796   -0.11341     -0.0575718     0.129713     0.025038   -0.0517916
  0.116965     0.0381066    0.0430483    0.276163     0.079093    -0.030245     0.0392797   -0.0735216   -0.0137434   -0.0578039     0.0643113   -0.00250476   0.0700844    -0.105801     0.0956618    0.0341259   -0.0176265    -0.0486675   -0.0323038     0.0176864   -0.284653    -0.170866     0.0382886     0.101647    -0.0651574   0.169387
  0.132275    -0.0528745   -0.00192168   0.166827    -0.058497     0.0396001    0.166478     0.00540652  -0.0509127   -0.0496379     0.0720936    0.114134     0.115775      0.0661043    0.0892657   -0.0419901    0.0447499    -0.0924481   -0.0676708     0.00278201   0.131056    -0.105301     0.0216101    -0.0318985   -0.0332864   0.0249745
  0.067285    -0.165999    -0.109301     0.0476782   -0.0494362    0.0131381   -0.0380718   -0.0954885   -0.0995037   -0.0359314    -0.0828075   -0.128821     0.00447558    0.133522    -0.116247     0.0488679    0.0502051     0.185819    -0.164483      0.117998     0.223166     0.188935     0.00464052    0.0926682    0.0170194  -0.0827976
  0.0158224    0.138671     0.0184914   -0.0149297   -0.124684     0.00998781  -0.0509177   -0.0405842   -0.120004    -0.000782201  -0.156655    -0.00440661   0.0853205     0.0250231    0.116506     0.0798527   -0.209601     -0.189572     0.000376564  -0.170322    -0.0503124    0.0447522    0.111297      0.0656972   -0.051674   -0.00665273
  0.130796    -0.172957    -0.0163828    0.136007    -0.00521508   0.00689696  -0.210424    -0.107436     0.0993844   -0.0401409    -0.0725013    0.018832     0.0591274    -0.188827     0.0340719   -0.200749     0.0621813     0.148086    -0.0107215    -0.0050034    0.0432499    0.0708642    0.00206226    0.107422     0.067521   -0.0317223
  0.0571079   -0.226498     0.0869087    0.0992739    0.0297782   -0.0289601    0.119859    -0.019146    -0.0712703    0.0708325     0.0922391    0.192564     0.0486554     0.0306682    0.0330471   -0.020721    -0.10961       0.143844     0.088338     -0.00839105   0.0565971   -0.00497255   0.0238189    -0.0248807    0.125952    0.0778778
 -0.18409     -0.00301439  -0.0523003   -0.00768172   0.041079     0.0474393   -0.093576    -0.0156912    0.0750901   -0.0596577     0.00962735   0.030845    -0.112479      0.0612635    0.129858     0.103857    -0.0275662    -0.0213056   -0.160971      0.032773     0.178435     0.0293508   -0.0931229     0.0300362   -0.149542    0.0884654
  0.111713    -0.133785     0.0823055   -0.0765566   -0.0501262   -0.0768143    0.00480723  -0.0798363   -0.137107    -0.06463       0.0573912   -0.0127829    0.0842152     0.0164335    0.104795     0.103416    -0.0866463     0.0668777   -0.0108676    -0.185206     0.0824686    0.11868     -0.0742968     0.0881281    0.0284754   0.102534
  0.0380528   -0.0240469    0.00611722   0.0270881    0.0720262    0.0204016   -0.0338888   -0.0398275    0.0146563    0.256913      0.0576967   -0.0351138    0.0418988    -0.00860511   0.0553467    0.0291904    0.0360744    -0.167377    -0.243619      0.156549    -0.041519    -0.105634     0.0312493     0.0726856    0.0435555  -0.0268839
 -0.079683     0.0933609   -0.144504    -0.0280863    0.00347641  -0.00604272   0.0805203   -0.119664     0.0836989    0.13941       0.106119     0.0303988   -0.0117135    -0.0332478    0.059044    -0.0712056    0.0173921     0.0389704    0.276663     -0.0172748    0.0301061   -0.115908     0.0189437    -0.0281224   -0.0752616   0.0259175
  0.139566    -0.0638965    0.12622      0.0792227    0.00147349   0.0740057    0.0162464    0.0242742   -0.184889    -0.0415781     0.0492287    0.316636    -0.049071     -0.0169773   -0.21188      0.0922934   -0.091368      0.126559     0.0965434     0.124127    -0.174004     0.0196908    0.0534852     0.106886     0.0215362   0.0433616
 -0.0702226    0.0295127   -0.171177     0.241213     0.0200258   -0.05951      0.0255711   -0.192751    -0.0146648   -0.0457076    -0.255663     0.0857299   -0.184998      0.0354964   -0.0859912   -0.128841    -0.0688354     0.0251847    0.021403      0.0373742   -0.106293     0.0425477   -0.0764311    -0.0984296    0.0186472  -0.0611942
  0.0603953    0.0652773   -0.208394    -0.128834    -0.0739333   -0.0915871    0.0321373    0.186993    -0.0997234    0.0105658     0.109201     0.0628707    0.0214613     0.130905    -0.0710499   -0.182214    -0.0567522    -0.0548997    0.0122415     0.0996751    0.0399823    0.167278    -0.0312511     0.00229304  -0.129533    0.103033
  0.185123    -0.0172849   -0.0247161    0.0776902    0.0362032    0.060351    -0.112438     0.0619386    0.102411    -0.0830389    -0.0962943    0.173507    -0.10878      -0.0870352    0.0630748    0.0711059    0.317986     -0.0373225    0.0168951     0.00391939  -0.00555416   0.0250986   -0.096228     -0.0702565   -0.0789873  -0.0656562
  0.0355263   -0.0183124    0.105422     0.0842386   -0.350363    -0.061798    -0.184559    -0.0157224   -0.00569351  -0.178466     -0.0310033   -0.15357     -0.15673       0.146756     0.0444267   -0.126586    -0.146521      0.209187     0.0653606     0.00492422  -0.0410527   -0.00515643  -0.0713355    -0.0550207   -0.115423    0.11106
  0.00273484   0.117477     0.0106096    0.0496594   -0.088056    -0.0619472   -0.0469604   -0.0866357    0.226381    -0.0288812    -0.196978    -0.0745778   -0.0149009     0.0186376   -0.0644102   -0.0820557    0.0611832    -0.227291    -0.0719956    -0.00229807   0.0325592    0.0261733   -0.0639366    -0.0466023    0.204591    0.0104001
 -0.0320803    0.153499    -0.0574443    0.074448    -0.0524688    0.0790255    0.068947     0.0352676   -0.0792076    0.153622      0.0212744   -0.120941     0.0253029    -0.014281    -0.179785     0.0170792   -0.0455313    -0.210708    -0.1728        0.1486      -0.105148     0.281052    -0.0821638     0.245278     0.017046    0.111619
 -0.142847     0.146613     0.0494832    0.111658     0.0279155    0.0971908   -0.0950226   -0.0783472   -0.00562925   0.0758802     0.0403274    0.111022     0.00862024   -0.0494494    0.0652445   -0.0653336    0.0518341     0.117801    -0.00696328   -0.0844535   -0.0604895    0.0246529   -0.0231373     0.179123    -0.0164172   0.00324288
  0.171152     0.0045809   -0.00153543   0.165325     0.0591555   -0.0257916   -0.0766894    0.0233736   -0.0770165    0.0484587    -0.230525     0.255122    -0.107081     -0.258272    -0.20118      0.104039     0.0835612     0.0669914   -0.0273394    -0.115868     0.0515688   -0.103792     0.113238      0.086303    -0.063872   -0.218825
  0.0769192   -0.0927437   -0.0475478    0.00084086   0.110117    -0.0133673    0.0620979    0.177313    -0.125355    -0.158471      0.116837     0.154221    -0.0174842    -0.0289298    0.0370146   -0.141719    -0.0259376     0.198776     0.0745399     0.128659    -0.0452494    0.0480778   -0.0674714    -0.106075     0.0496144  -0.0441429
  0.0178027    0.104942     0.124201    -0.0361548   -0.0844123   -0.00941972   0.0964581    0.100317    -0.031875    -0.173674     -0.183636     0.137487    -0.0969171     0.186995     0.0235623   -0.0731817    0.0695765     0.0560062    0.157379     -0.119118    -0.0981157   -0.0403013    0.0451066     0.068389     0.0520853   0.0537845
 -0.0736024   -0.162545    -0.0220249    0.00555078  -0.00244946   0.0139613   -0.00212916   0.0569902   -0.0597086   -0.0641825    -0.106112    -0.0746132    0.087405     -0.141607     0.198254    -0.0279262    0.128747     -0.0253838   -0.028442     -0.0214761   -0.205489    -0.023093     0.0751786     0.105158     0.0136197  -0.0172465
  0.00653753   0.0464552    0.060634     0.0270932   -0.0337224   -0.0738451   -0.0131355    0.0688258   -0.127622    -0.112625      0.189944    -0.0651768   -0.00596       0.00186065  -0.129162     0.138243     0.369662     -0.100202     0.0277687    -0.143849     0.00133627  -0.119607    -0.0748643     0.00631461  -0.112006   -0.0146264
  0.183547    -0.00394403  -0.0456782   -0.00743179   0.0117986   -0.0057333    0.0211223    0.0785955   -0.0773417   -0.025155      0.0867964   -0.0409415    0.0453495    -0.00820017   0.0168429   -0.0538968    0.000676658  -0.055462    -0.132763      0.0731072    0.0967773   -0.239606    -0.0690449     0.00357865   0.110211    0.0763425
  0.0754717    0.0724032   -0.305923     0.178308     0.047973    -0.167056    -0.288271    -0.00205371   0.159814     0.133033     -0.0296998   -0.092591    -0.0685118    -0.00841307  -0.0881506   -0.0925386   -0.0446488     0.218118     0.0659404    -0.203968    -0.0837747    0.0763628   -0.038877     -0.124432    -0.0874891   0.0953372
 -0.0240474   -0.0453717   -0.038349     0.0284561    0.0488844   -0.0734046   -0.01974      0.0882749    0.169016     0.086105     -0.0578485   -0.0504123   -0.000907062   0.0121585   -0.00826909  -0.291116    -0.0585964     0.00928672  -0.0597983    -0.0448241    0.0435939   -0.0307029   -0.0475157     0.0240797   -0.0468768  -0.0146963
 -0.0226225   -0.0312607   -0.135964     0.0607457    0.106499    -0.110847    -0.211247    -0.0673888   -0.0615741   -0.162023     -0.0287895   -0.119024     0.158809     -0.0296934    0.0815948   -0.0289624   -0.0355646     0.021745    -0.140783     -0.00949338   0.294991    -0.10287      0.134776     -0.0571416   -0.146291   -0.0221468
 -0.0638566    0.0690963   -0.131357    -0.0341104    0.0230243    0.027703    -0.0244466   -0.0115558    0.103831     0.00527778   -0.00526588  -0.134941    -0.0932445     0.226366    -0.0372688   -0.150259     0.165324      0.133964     0.0168324    -0.1673       0.0116335    0.0545733   -0.000296457   0.0477485   -0.0125911  -0.0175105
  0.0830736    0.140558     0.250726     0.0693658   -0.0288501   -0.163305    -0.0157358   -0.0272485   -0.0342755   -0.0191187    -0.032903    -0.128354     0.0159357     0.0138192    0.0217193   -0.0892884    0.0627612    -0.0293071   -0.0244706     0.0847591    0.0126649   -0.0296674   -0.0294332    -0.0741526   -0.136089   -0.0529755
  0.0884727    0.00435968  -0.282231    -0.147136    -0.0349018   -0.0255975   -0.157277     0.130226     0.222421     0.0447413    -0.03833      0.209738     0.117494     -0.0289916    0.0833009    0.102367    -0.0694201    -0.0510828   -0.0980636     0.0350794   -0.00451225  -0.0791655   -0.115119     -0.0225155    0.0418388  -0.0894468kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4240248166389546
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424044
[ Info: iteration 2, average log likelihood -1.423965
[ Info: iteration 3, average log likelihood -1.423890
[ Info: iteration 4, average log likelihood -1.423791
[ Info: iteration 5, average log likelihood -1.423659
[ Info: iteration 6, average log likelihood -1.423493
[ Info: iteration 7, average log likelihood -1.423296
[ Info: iteration 8, average log likelihood -1.423058
[ Info: iteration 9, average log likelihood -1.422741
[ Info: iteration 10, average log likelihood -1.422268
[ Info: iteration 11, average log likelihood -1.421571
[ Info: iteration 12, average log likelihood -1.420688
[ Info: iteration 13, average log likelihood -1.419828
[ Info: iteration 14, average log likelihood -1.419210
[ Info: iteration 15, average log likelihood -1.418866
[ Info: iteration 16, average log likelihood -1.418701
[ Info: iteration 17, average log likelihood -1.418627
[ Info: iteration 18, average log likelihood -1.418594
[ Info: iteration 19, average log likelihood -1.418579
[ Info: iteration 20, average log likelihood -1.418573
[ Info: iteration 21, average log likelihood -1.418570
[ Info: iteration 22, average log likelihood -1.418569
[ Info: iteration 23, average log likelihood -1.418568
[ Info: iteration 24, average log likelihood -1.418567
[ Info: iteration 25, average log likelihood -1.418567
[ Info: iteration 26, average log likelihood -1.418567
[ Info: iteration 27, average log likelihood -1.418567
[ Info: iteration 28, average log likelihood -1.418567
[ Info: iteration 29, average log likelihood -1.418566
[ Info: iteration 30, average log likelihood -1.418566
[ Info: iteration 31, average log likelihood -1.418566
[ Info: iteration 32, average log likelihood -1.418566
[ Info: iteration 33, average log likelihood -1.418566
[ Info: iteration 34, average log likelihood -1.418566
[ Info: iteration 35, average log likelihood -1.418566
[ Info: iteration 36, average log likelihood -1.418566
[ Info: iteration 37, average log likelihood -1.418566
[ Info: iteration 38, average log likelihood -1.418566
[ Info: iteration 39, average log likelihood -1.418566
[ Info: iteration 40, average log likelihood -1.418566
[ Info: iteration 41, average log likelihood -1.418566
[ Info: iteration 42, average log likelihood -1.418566
[ Info: iteration 43, average log likelihood -1.418566
[ Info: iteration 44, average log likelihood -1.418566
[ Info: iteration 45, average log likelihood -1.418566
[ Info: iteration 46, average log likelihood -1.418566
[ Info: iteration 47, average log likelihood -1.418566
[ Info: iteration 48, average log likelihood -1.418566
[ Info: iteration 49, average log likelihood -1.418566
[ Info: iteration 50, average log likelihood -1.418566
┌ Info: EM with 100000 data points 50 iterations avll -1.418566
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4240439686360822
│     -1.4239645207700007
│      ⋮
└     -1.4185656292201567
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418581
[ Info: iteration 2, average log likelihood -1.418509
[ Info: iteration 3, average log likelihood -1.418439
[ Info: iteration 4, average log likelihood -1.418345
[ Info: iteration 5, average log likelihood -1.418224
[ Info: iteration 6, average log likelihood -1.418084
[ Info: iteration 7, average log likelihood -1.417943
[ Info: iteration 8, average log likelihood -1.417823
[ Info: iteration 9, average log likelihood -1.417731
[ Info: iteration 10, average log likelihood -1.417663
[ Info: iteration 11, average log likelihood -1.417611
[ Info: iteration 12, average log likelihood -1.417570
[ Info: iteration 13, average log likelihood -1.417536
[ Info: iteration 14, average log likelihood -1.417509
[ Info: iteration 15, average log likelihood -1.417487
[ Info: iteration 16, average log likelihood -1.417470
[ Info: iteration 17, average log likelihood -1.417456
[ Info: iteration 18, average log likelihood -1.417445
[ Info: iteration 19, average log likelihood -1.417436
[ Info: iteration 20, average log likelihood -1.417429
[ Info: iteration 21, average log likelihood -1.417422
[ Info: iteration 22, average log likelihood -1.417416
[ Info: iteration 23, average log likelihood -1.417411
[ Info: iteration 24, average log likelihood -1.417406
[ Info: iteration 25, average log likelihood -1.417401
[ Info: iteration 26, average log likelihood -1.417397
[ Info: iteration 27, average log likelihood -1.417392
[ Info: iteration 28, average log likelihood -1.417388
[ Info: iteration 29, average log likelihood -1.417385
[ Info: iteration 30, average log likelihood -1.417381
[ Info: iteration 31, average log likelihood -1.417377
[ Info: iteration 32, average log likelihood -1.417374
[ Info: iteration 33, average log likelihood -1.417370
[ Info: iteration 34, average log likelihood -1.417367
[ Info: iteration 35, average log likelihood -1.417363
[ Info: iteration 36, average log likelihood -1.417360
[ Info: iteration 37, average log likelihood -1.417356
[ Info: iteration 38, average log likelihood -1.417352
[ Info: iteration 39, average log likelihood -1.417349
[ Info: iteration 40, average log likelihood -1.417345
[ Info: iteration 41, average log likelihood -1.417342
[ Info: iteration 42, average log likelihood -1.417338
[ Info: iteration 43, average log likelihood -1.417334
[ Info: iteration 44, average log likelihood -1.417331
[ Info: iteration 45, average log likelihood -1.417327
[ Info: iteration 46, average log likelihood -1.417323
[ Info: iteration 47, average log likelihood -1.417319
[ Info: iteration 48, average log likelihood -1.417315
[ Info: iteration 49, average log likelihood -1.417312
[ Info: iteration 50, average log likelihood -1.417308
┌ Info: EM with 100000 data points 50 iterations avll -1.417308
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4185807499733638
│     -1.4185092727973976
│      ⋮
└     -1.4173078857114005
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417315
[ Info: iteration 2, average log likelihood -1.417257
[ Info: iteration 3, average log likelihood -1.417206
[ Info: iteration 4, average log likelihood -1.417151
[ Info: iteration 5, average log likelihood -1.417085
[ Info: iteration 6, average log likelihood -1.417010
[ Info: iteration 7, average log likelihood -1.416926
[ Info: iteration 8, average log likelihood -1.416834
[ Info: iteration 9, average log likelihood -1.416739
[ Info: iteration 10, average log likelihood -1.416645
[ Info: iteration 11, average log likelihood -1.416553
[ Info: iteration 12, average log likelihood -1.416468
[ Info: iteration 13, average log likelihood -1.416391
[ Info: iteration 14, average log likelihood -1.416323
[ Info: iteration 15, average log likelihood -1.416265
[ Info: iteration 16, average log likelihood -1.416217
[ Info: iteration 17, average log likelihood -1.416177
[ Info: iteration 18, average log likelihood -1.416143
[ Info: iteration 19, average log likelihood -1.416116
[ Info: iteration 20, average log likelihood -1.416092
[ Info: iteration 21, average log likelihood -1.416073
[ Info: iteration 22, average log likelihood -1.416055
[ Info: iteration 23, average log likelihood -1.416040
[ Info: iteration 24, average log likelihood -1.416027
[ Info: iteration 25, average log likelihood -1.416015
[ Info: iteration 26, average log likelihood -1.416004
[ Info: iteration 27, average log likelihood -1.415994
[ Info: iteration 28, average log likelihood -1.415985
[ Info: iteration 29, average log likelihood -1.415976
[ Info: iteration 30, average log likelihood -1.415968
[ Info: iteration 31, average log likelihood -1.415960
[ Info: iteration 32, average log likelihood -1.415953
[ Info: iteration 33, average log likelihood -1.415946
[ Info: iteration 34, average log likelihood -1.415939
[ Info: iteration 35, average log likelihood -1.415933
[ Info: iteration 36, average log likelihood -1.415926
[ Info: iteration 37, average log likelihood -1.415920
[ Info: iteration 38, average log likelihood -1.415914
[ Info: iteration 39, average log likelihood -1.415908
[ Info: iteration 40, average log likelihood -1.415902
[ Info: iteration 41, average log likelihood -1.415896
[ Info: iteration 42, average log likelihood -1.415891
[ Info: iteration 43, average log likelihood -1.415885
[ Info: iteration 44, average log likelihood -1.415880
[ Info: iteration 45, average log likelihood -1.415874
[ Info: iteration 46, average log likelihood -1.415869
[ Info: iteration 47, average log likelihood -1.415864
[ Info: iteration 48, average log likelihood -1.415859
[ Info: iteration 49, average log likelihood -1.415854
[ Info: iteration 50, average log likelihood -1.415849
┌ Info: EM with 100000 data points 50 iterations avll -1.415849
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4173145411640182
│     -1.4172569209143304
│      ⋮
└     -1.415848699932202
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415853
[ Info: iteration 2, average log likelihood -1.415801
[ Info: iteration 3, average log likelihood -1.415755
[ Info: iteration 4, average log likelihood -1.415705
[ Info: iteration 5, average log likelihood -1.415645
[ Info: iteration 6, average log likelihood -1.415573
[ Info: iteration 7, average log likelihood -1.415489
[ Info: iteration 8, average log likelihood -1.415395
[ Info: iteration 9, average log likelihood -1.415294
[ Info: iteration 10, average log likelihood -1.415191
[ Info: iteration 11, average log likelihood -1.415092
[ Info: iteration 12, average log likelihood -1.415001
[ Info: iteration 13, average log likelihood -1.414918
[ Info: iteration 14, average log likelihood -1.414846
[ Info: iteration 15, average log likelihood -1.414784
[ Info: iteration 16, average log likelihood -1.414732
[ Info: iteration 17, average log likelihood -1.414687
[ Info: iteration 18, average log likelihood -1.414650
[ Info: iteration 19, average log likelihood -1.414618
[ Info: iteration 20, average log likelihood -1.414590
[ Info: iteration 21, average log likelihood -1.414565
[ Info: iteration 22, average log likelihood -1.414544
[ Info: iteration 23, average log likelihood -1.414524
[ Info: iteration 24, average log likelihood -1.414506
[ Info: iteration 25, average log likelihood -1.414489
[ Info: iteration 26, average log likelihood -1.414473
[ Info: iteration 27, average log likelihood -1.414458
[ Info: iteration 28, average log likelihood -1.414443
[ Info: iteration 29, average log likelihood -1.414429
[ Info: iteration 30, average log likelihood -1.414416
[ Info: iteration 31, average log likelihood -1.414403
[ Info: iteration 32, average log likelihood -1.414390
[ Info: iteration 33, average log likelihood -1.414377
[ Info: iteration 34, average log likelihood -1.414364
[ Info: iteration 35, average log likelihood -1.414352
[ Info: iteration 36, average log likelihood -1.414339
[ Info: iteration 37, average log likelihood -1.414327
[ Info: iteration 38, average log likelihood -1.414315
[ Info: iteration 39, average log likelihood -1.414303
[ Info: iteration 40, average log likelihood -1.414291
[ Info: iteration 41, average log likelihood -1.414279
[ Info: iteration 42, average log likelihood -1.414267
[ Info: iteration 43, average log likelihood -1.414255
[ Info: iteration 44, average log likelihood -1.414243
[ Info: iteration 45, average log likelihood -1.414232
[ Info: iteration 46, average log likelihood -1.414221
[ Info: iteration 47, average log likelihood -1.414209
[ Info: iteration 48, average log likelihood -1.414198
[ Info: iteration 49, average log likelihood -1.414188
[ Info: iteration 50, average log likelihood -1.414177
┌ Info: EM with 100000 data points 50 iterations avll -1.414177
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4158526962609168
│     -1.4158008691037998
│      ⋮
└     -1.41417711520028
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414175
[ Info: iteration 2, average log likelihood -1.414115
[ Info: iteration 3, average log likelihood -1.414059
[ Info: iteration 4, average log likelihood -1.413997
[ Info: iteration 5, average log likelihood -1.413921
[ Info: iteration 6, average log likelihood -1.413829
[ Info: iteration 7, average log likelihood -1.413718
[ Info: iteration 8, average log likelihood -1.413588
[ Info: iteration 9, average log likelihood -1.413443
[ Info: iteration 10, average log likelihood -1.413290
[ Info: iteration 11, average log likelihood -1.413135
[ Info: iteration 12, average log likelihood -1.412987
[ Info: iteration 13, average log likelihood -1.412848
[ Info: iteration 14, average log likelihood -1.412721
[ Info: iteration 15, average log likelihood -1.412608
[ Info: iteration 16, average log likelihood -1.412506
[ Info: iteration 17, average log likelihood -1.412416
[ Info: iteration 18, average log likelihood -1.412335
[ Info: iteration 19, average log likelihood -1.412263
[ Info: iteration 20, average log likelihood -1.412198
[ Info: iteration 21, average log likelihood -1.412139
[ Info: iteration 22, average log likelihood -1.412086
[ Info: iteration 23, average log likelihood -1.412037
[ Info: iteration 24, average log likelihood -1.411993
[ Info: iteration 25, average log likelihood -1.411951
[ Info: iteration 26, average log likelihood -1.411912
[ Info: iteration 27, average log likelihood -1.411875
[ Info: iteration 28, average log likelihood -1.411841
[ Info: iteration 29, average log likelihood -1.411808
[ Info: iteration 30, average log likelihood -1.411776
[ Info: iteration 31, average log likelihood -1.411747
[ Info: iteration 32, average log likelihood -1.411718
[ Info: iteration 33, average log likelihood -1.411691
[ Info: iteration 34, average log likelihood -1.411665
[ Info: iteration 35, average log likelihood -1.411640
[ Info: iteration 36, average log likelihood -1.411616
[ Info: iteration 37, average log likelihood -1.411593
[ Info: iteration 38, average log likelihood -1.411571
[ Info: iteration 39, average log likelihood -1.411550
[ Info: iteration 40, average log likelihood -1.411530
[ Info: iteration 41, average log likelihood -1.411511
[ Info: iteration 42, average log likelihood -1.411493
[ Info: iteration 43, average log likelihood -1.411475
[ Info: iteration 44, average log likelihood -1.411458
[ Info: iteration 45, average log likelihood -1.411442
[ Info: iteration 46, average log likelihood -1.411426
[ Info: iteration 47, average log likelihood -1.411411
[ Info: iteration 48, average log likelihood -1.411396
[ Info: iteration 49, average log likelihood -1.411382
[ Info: iteration 50, average log likelihood -1.411367
┌ Info: EM with 100000 data points 50 iterations avll -1.411367
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4141754352775067
│     -1.4141151010664674
│      ⋮
└     -1.411367498847251
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4240248166389546
│     -1.4240439686360822
│     -1.4239645207700007
│     -1.4238900283186264
│      ⋮
│     -1.4113959952909736
│     -1.4113815490117885
└     -1.411367498847251
32×26 Array{Float64,2}:
 -0.614314    -0.0729431  -0.437369    0.289529    -0.452074    0.0698052   -0.227163    -0.291639   -0.296395   -0.811985    -0.216184    0.277466    0.400712    -0.264305    -0.124667    0.320654    0.337322   -0.266865   -0.459123      0.0809791  -0.215083    -0.272218   -0.477111   -0.0163224  -0.54608      0.350182
  0.0161677   -0.582647   -0.46009    -0.284864     0.222062   -0.389825     0.283962    -0.0250034  -0.550601   -0.44034     -0.153809    0.48474     0.240734    -0.230979     0.488867   -0.154224   -0.23472     0.486081    0.00185274    0.210876   -0.60058      0.426947   -0.58552    -0.0798778  -0.187128    -0.172367
  0.736628     0.110505    0.170212   -0.135753    -0.308894   -0.967848    -0.00874862  -0.396734   -0.956241   -0.504436    -0.0506147  -0.0808986  -0.0346386    0.417157     0.381771    0.364471   -0.0141924   0.0774922   0.759202     -0.504435    0.442998    -0.482246    0.0727839  -0.025146   -0.290951     0.685126
  0.534074     0.212586    0.914323    0.183838    -0.316249   -0.0927932   -0.542567     0.0926867  -0.1173     -0.186547     0.762116    0.158793    0.127151    -0.00982608  -0.312636   -0.192673    0.308585   -0.338153    0.241521      0.116852    0.387349    -0.276527    0.285083   -0.421542   -0.356034     0.285997
 -0.0124841    0.240024    0.171126    0.407084     0.773749   -0.302324     0.219467    -0.18318     0.0737233   0.270783    -0.0632404  -0.0773908  -0.433271     0.106107     1.01206    -0.117814   -0.441486    0.0556704  -0.543906     -0.429763   -0.164867    -0.172854   -0.0974992  -0.0476276  -0.230636    -0.475835
 -0.109605     0.0939065  -0.188515   -0.0730069    0.0474116  -0.484932     0.223676    -0.895762   -0.197784    0.869832    -0.0798303  -0.161219    0.473458     0.274335     0.487889   -0.0989353   0.111761   -0.410149   -0.140714      0.339875    0.191523    -0.0425525  -0.130747   -0.151161   -0.616484     0.199357
 -0.250452     0.0160271  -0.129729   -0.584977     0.229115   -0.0727871    0.368523     0.199575    0.151612   -0.393894    -0.0751604  -0.293276   -0.285072    -0.107767     0.262897    0.156665    0.895229   -0.800298    0.536617     -0.705547    0.170461     0.351757   -0.395445   -0.445727   -0.472118    -0.0230426
  0.66548     -0.282233   -0.197683   -0.392568     0.209884   -0.655676    -0.660923    -0.68858    -0.0279884   0.0398027   -0.0933706   0.0404245  -0.662036    -0.713927     0.178939    0.308286    0.419934   -0.354533   -0.0157715     0.0896741  -0.200495     0.0709221   0.264724   -0.184343   -0.3969      -0.252315
  0.194095    -0.11825    -0.136805   -0.183809     0.118623   -0.209836     0.155763     0.0911177   0.131389   -0.00563855   0.106234   -0.143302   -0.0843742    0.00963081   0.131159    0.124755   -0.0380278  -0.246641    0.0905474    -0.373108   -0.0508576    0.11642    -0.0742876   0.0450295  -0.172731    -0.167047
 -0.248397     0.0775588   0.326137   -0.00464996  -0.375558    0.272394    -0.366052    -0.0961204  -0.0481757   0.0475582   -0.215573    0.323799    0.174357     0.114259    -0.147012   -0.213081   -0.062387    0.431681   -0.0176773     0.560776    0.0737959    0.243649    0.0521122  -0.0442271   0.458112     0.15864
  0.175147     0.113968   -0.634807   -0.906571     0.296597    0.0958861    0.210395     0.39861     0.638567    0.354129    -0.354652   -0.186733   -0.361526     0.199293    -0.306918   -0.356333   -0.167172   -0.261508   -0.0280149     0.244648    0.577664     0.390297    0.132487    0.573755    0.141662    -0.363415
  0.754655    -0.0537757  -0.454307   -0.0707806   -0.218812   -0.173666    -0.297236     0.321651    0.178507   -0.422621    -0.579401   -0.143721    0.487384    -0.826744    -0.257288   -0.428198    0.109017    0.225331   -0.296077      0.0303954   0.0597788    0.0132958  -0.258507    0.152174    0.228471     0.618032
 -0.455342     0.131923   -0.150456    0.231274     0.665614   -0.00149447  -0.0684724   -0.564812   -0.204842    0.670322     0.449257   -0.296069   -0.535969    -0.493412    -0.631575   -0.020171   -0.259175    1.10912    -0.0856421     0.239208    0.19406      0.256159    0.655703    0.107599    0.0531791    0.129924
 -0.891229     0.0541557   0.460264    0.0200267    0.212372    0.0335803   -0.0512396   -0.807853   -0.0581629   0.450372    -0.379488    0.0710708  -0.653342     0.851384    -0.100612    0.0802112  -0.375967   -0.149146    0.349767     -0.110297   -0.137595     0.0866981   0.244937   -0.329644    0.203535    -0.368515
  0.252479     0.445865   -0.255979    0.807228     0.153241    0.0731159    0.128684     0.881571    0.109911   -0.186126     0.443993   -0.0762141  -0.180471     0.290781    -0.526021    0.287683   -0.431099    0.437973    0.0940026    -0.299723    0.0198841   -0.318583    0.139586    0.0757401   0.256343    -0.289103
  0.287629    -0.183228   -0.275785    0.793093     0.0547231  -0.342851     1.10723      0.0797031  -0.265392    0.42787      0.169971   -0.212758   -0.104244    -0.358323    -0.0455972   0.0432085   0.349222    0.229257   -0.0154168    -0.218703    0.0565313   -0.416916    0.402343    0.613314   -0.0292762   -0.0998013
  0.0860714    0.0160282   0.147334    0.323394    -0.0951249  -0.553219     0.10691     -0.296249   -0.3754      0.171809     0.431904   -0.0385376   0.105836     0.105643     0.285029    0.163838    0.244771   -0.105454    0.20964       0.128189   -0.122472    -0.134277   -0.104942   -0.274144   -0.366083     0.0147423
 -0.0274061    0.16215     0.218332    0.290138     0.166125    0.186805     0.113062     0.153018    0.295894    0.33521      0.275274   -0.369396   -0.633334    -0.14251     -0.163766   -0.201577    0.330426   -0.307003    0.0713383     0.0578586   0.109453    -0.170082    0.356327   -0.183865    0.436765    -0.176612
  0.357056    -0.46544     0.0904759   0.494599     0.771999    0.217057    -0.487668     0.206644   -0.224819   -0.25479      0.207626    0.652453   -0.16         0.0233401   -0.274452    0.499968    0.0394659   0.0971731   0.178515      0.14556    -0.0269819   -0.116933    0.425004    0.30951    -0.414583    -0.817438
 -0.213202    -0.201999    0.210165    0.120593     0.221117    0.226737    -0.116824    -0.200809    0.0583017   0.103571     0.222542    1.05788    -0.21458     -0.368672     0.477326   -0.131306   -0.145352   -0.758866   -0.172375     -0.545447    0.150289    -0.602935    0.266893    0.10554     0.274861     0.347075
 -0.320059    -0.241123   -0.0279029  -0.190877     0.0156011   0.355766    -0.0268126    0.246426   -0.240669   -0.477659    -0.456029    0.479575   -0.551161    -0.229895    -0.410747   -0.195432   -0.0910375   0.184242    0.078725     -0.0847509   0.00461146  -0.048292    0.149483    0.613412    0.700627    -0.116423
 -0.459831    -0.0752213   0.466325    0.0771673   -0.33996     0.499491    -0.0826802    0.20271    -0.309981   -0.111755    -0.201223    0.555056    0.418249     0.401367    -0.028361   -0.0404393  -0.10135     0.208146    0.117854      0.326754    0.0981972   -0.327586   -0.109195    0.0727699   0.403965     0.123983
  0.327876    -0.213174    0.41454     0.166455    -0.25468     0.0492594   -0.204374     0.26972     0.139106    0.083378     0.0375652  -0.305816   -0.00978878   0.0720198   -0.178863   -0.322554   -0.2791      0.482559    0.162588      0.252803   -0.553292     0.245621    0.0552976  -0.0705843   0.584177    -0.0224962
  0.377992     0.054933    0.423464    0.111228     0.0999124   0.0262754    0.360138     0.386634    0.156028    0.33088     -0.0378793   0.114487   -0.0520876    0.16562     -0.0622133   0.0316591  -0.484036    0.147765    0.185674     -0.162532    0.630325     0.265347    0.410534    0.189464    0.29698      0.0271146
 -0.00856109   0.106981   -0.408517    0.0363926   -0.144738    0.482416    -0.144575    -0.0782912   0.425372   -0.039549    -0.423311   -0.71712     0.195635     0.497689    -0.178142   -0.183282   -0.335993    0.592188   -0.533884     -0.175261   -0.371303     0.0560026  -0.101413    0.0961492  -0.0739827    0.404593
 -0.125974     0.108026    0.148969    0.494706    -0.348523   -0.0677236   -0.239577    -0.393324   -0.0371917  -0.293715     0.478871   -0.478223    0.0658037    0.173571     0.173389   -0.243295    0.480219    0.470882    0.000238905  -0.240415   -0.593166    -0.0898426  -0.203171   -0.527656    0.0135412    0.335335
 -0.472223     0.385606   -0.17252     0.0361041   -0.238313    0.393547     0.0353801    0.413693    0.701506    0.222508     0.0686888  -0.5082      0.0284105   -0.209511    -0.0484855  -0.239577    0.101204    0.148161   -0.222759      0.431861   -0.36927      0.599696   -0.712463   -0.164595    0.304288    -0.411666
  0.635187     0.24173     0.106289   -0.0848003   -0.661946   -0.013354     0.153331     0.676782    0.115758   -0.274705    -0.0551647   0.0695525   0.646144     0.565242     0.539582   -0.112912    0.0120478  -0.649078    0.00286294    0.137645   -0.0906329   -0.165864   -0.824624    0.197559   -0.344703    -0.260555
 -0.273105     0.119573   -0.220033    0.1881      -0.0467402   0.160932    -0.0505966    0.0179068  -0.0106925  -0.186408    -0.0983515   0.0390164   0.0194571    0.0185279   -0.0514723  -0.0481162  -0.0259479   0.14892    -0.228459      0.0116126  -0.125074     0.0307981  -0.17185     0.0195762   0.00560937[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
   0.00353418
  0.403947    -0.152897   -0.266701    0.0843885    0.0402668  -0.194957     0.184282     0.171052   -0.295152   -0.159455    -0.141322    0.186629    0.0897706   -0.0461387   -0.0578535  -0.0345612  -0.0234175  -0.187499    0.0372953    -0.0615488   0.0734576   -0.293582    0.112843    0.469493   -0.323528     0.0654755
  0.0923622   -0.120454   -0.225824   -0.865904    -0.610904    0.0134359   -0.397452    -0.27577    -0.0983549  -0.00286515  -0.169704    0.175812    0.438786    -0.0514878   -0.235495    0.253121    0.132811   -0.247335    0.202325      0.219498    0.293575     0.51345    -0.0732989  -0.0440493  -0.208382     0.173387
  0.185383     0.0654818  -0.181718   -0.32435      0.197064   -0.0519875   -0.264955    -0.140239    0.534054    0.203966    -0.048026   -0.112274    0.0751725   -0.216564     0.163038    0.180572    0.0430988  -0.180037   -0.196375     -0.208869    0.245222     0.153828   -0.0560373  -0.170562   -0.351269     0.00316083[ Info: iteration 1, average log likelihood -1.411354
[ Info: iteration 2, average log likelihood -1.411340
[ Info: iteration 3, average log likelihood -1.411327
[ Info: iteration 4, average log likelihood -1.411315
[ Info: iteration 5, average log likelihood -1.411302
[ Info: iteration 6, average log likelihood -1.411290
[ Info: iteration 7, average log likelihood -1.411278
[ Info: iteration 8, average log likelihood -1.411266
[ Info: iteration 9, average log likelihood -1.411254
kind full, method kmeans
[ Info: iteration 10, average log likelihood -1.411243
┌ Info: EM with 100000 data points 10 iterations avll -1.411243
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.775431e+05
      1       7.069941e+05      -1.705490e+05 |       32
      2       6.936144e+05      -1.337973e+04 |       32
      3       6.883155e+05      -5.298839e+03 |       32
      4       6.855237e+05      -2.791805e+03 |       32
      5       6.837812e+05      -1.742554e+03 |       32
      6       6.824848e+05      -1.296376e+03 |       32
      7       6.813582e+05      -1.126647e+03 |       32
      8       6.804193e+05      -9.388195e+02 |       32
      9       6.796574e+05      -7.619279e+02 |       32
     10       6.790267e+05      -6.306783e+02 |       32
     11       6.784793e+05      -5.474717e+02 |       32
     12       6.779827e+05      -4.965743e+02 |       32
     13       6.775491e+05      -4.335334e+02 |       32
     14       6.772022e+05      -3.469564e+02 |       32
     15       6.768711e+05      -3.310599e+02 |       32
     16       6.765520e+05      -3.191801e+02 |       32
     17       6.762572e+05      -2.947338e+02 |       32
     18       6.759789e+05      -2.783068e+02 |       32
     19       6.757415e+05      -2.373874e+02 |       32
     20       6.755423e+05      -1.991992e+02 |       32
     21       6.753626e+05      -1.797566e+02 |       32
     22       6.751947e+05      -1.679110e+02 |       32
     23       6.750304e+05      -1.642481e+02 |       32
     24       6.748884e+05      -1.419921e+02 |       32
     25       6.747499e+05      -1.384871e+02 |       32
     26       6.746291e+05      -1.208146e+02 |       32
     27       6.745208e+05      -1.082912e+02 |       32
     28       6.744246e+05      -9.620231e+01 |       32
     29       6.743326e+05      -9.202970e+01 |       32
     30       6.742474e+05      -8.515478e+01 |       32
     31       6.741673e+05      -8.013513e+01 |       32
     32       6.740918e+05      -7.552177e+01 |       32
     33       6.740265e+05      -6.528004e+01 |       32
     34       6.739671e+05      -5.935369e+01 |       32
     35       6.739132e+05      -5.391033e+01 |       32
     36       6.738638e+05      -4.942235e+01 |       32
     37       6.738158e+05      -4.804876e+01 |       32
     38       6.737675e+05      -4.823127e+01 |       32
     39       6.737220e+05      -4.550294e+01 |       32
     40       6.736821e+05      -3.997404e+01 |       32
     41       6.736463e+05      -3.578217e+01 |       32
     42       6.736092e+05      -3.711792e+01 |       32
     43       6.735765e+05      -3.262659e+01 |       32
     44       6.735484e+05      -2.811054e+01 |       32
     45       6.735151e+05      -3.335223e+01 |       32
     46       6.734863e+05      -2.881313e+01 |       32
     47       6.734581e+05      -2.820450e+01 |       32
     48       6.734320e+05      -2.602806e+01 |       32
     49       6.734047e+05      -2.729278e+01 |       32
     50       6.733795e+05      -2.525982e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 673379.4704948317)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423509
[ Info: iteration 2, average log likelihood -1.418305
[ Info: iteration 3, average log likelihood -1.416921
[ Info: iteration 4, average log likelihood -1.415907
[ Info: iteration 5, average log likelihood -1.414837
[ Info: iteration 6, average log likelihood -1.413837
[ Info: iteration 7, average log likelihood -1.413133
[ Info: iteration 8, average log likelihood -1.412731
[ Info: iteration 9, average log likelihood -1.412505
[ Info: iteration 10, average log likelihood -1.412363
[ Info: iteration 11, average log likelihood -1.412260
[ Info: iteration 12, average log likelihood -1.412178
[ Info: iteration 13, average log likelihood -1.412109
[ Info: iteration 14, average log likelihood -1.412048
[ Info: iteration 15, average log likelihood -1.411994
[ Info: iteration 16, average log likelihood -1.411944
[ Info: iteration 17, average log likelihood -1.411898
[ Info: iteration 18, average log likelihood -1.411856
[ Info: iteration 19, average log likelihood -1.411816
[ Info: iteration 20, average log likelihood -1.411779
[ Info: iteration 21, average log likelihood -1.411744
[ Info: iteration 22, average log likelihood -1.411711
[ Info: iteration 23, average log likelihood -1.411680
[ Info: iteration 24, average log likelihood -1.411650
[ Info: iteration 25, average log likelihood -1.411622
[ Info: iteration 26, average log likelihood -1.411594
[ Info: iteration 27, average log likelihood -1.411568
[ Info: iteration 28, average log likelihood -1.411543
[ Info: iteration 29, average log likelihood -1.411519
[ Info: iteration 30, average log likelihood -1.411497
[ Info: iteration 31, average log likelihood -1.411474
[ Info: iteration 32, average log likelihood -1.411453
[ Info: iteration 33, average log likelihood -1.411433
[ Info: iteration 34, average log likelihood -1.411414
[ Info: iteration 35, average log likelihood -1.411395
[ Info: iteration 36, average log likelihood -1.411377
[ Info: iteration 37, average log likelihood -1.411360
[ Info: iteration 38, average log likelihood -1.411344
[ Info: iteration 39, average log likelihood -1.411328
[ Info: iteration 40, average log likelihood -1.411313
[ Info: iteration 41, average log likelihood -1.411299
[ Info: iteration 42, average log likelihood -1.411286
[ Info: iteration 43, average log likelihood -1.411273
[ Info: iteration 44, average log likelihood -1.411260
[ Info: iteration 45, average log likelihood -1.411249
[ Info: iteration 46, average log likelihood -1.411237
[ Info: iteration 47, average log likelihood -1.411226
[ Info: iteration 48, average log likelihood -1.411216
[ Info: iteration 49, average log likelihood -1.411206
32×26 Array{Float64,2}:
  0.375248    0.27695     0.689293     0.440001     -0.533496    -0.123549   -0.271189     0.147219    -0.208169    -0.327035     0.859151    0.124402    0.215191    0.127634   -0.289507   -0.289678     0.35442    -0.163852     [ Info: iteration 50, average log likelihood -1.411196
┌ Info: EM with 100000 data points 50 iterations avll -1.411196
└ 59.0 data points per parameter
 0.328662     0.163983    0.121922    -0.194535     0.199282   -0.434337   -0.35673     0.239331
  0.155484   -0.130486   -0.192802    -0.029243      0.31999     -0.238467    0.16657     -0.0780111   -0.362471    -0.226482    -0.17038     0.522895    0.0879868   0.0194268   0.38233    -0.0837653   -0.139817   -0.452079     -0.108772    -0.233561   -0.0510666   -0.517156     0.0427915   0.32587    -0.550186    0.193937
 -0.0838255  -0.282581   -0.970167    -0.317816      0.135329    -0.462618    0.47714      0.273678    -0.201679    -0.0681896   -0.342521    0.152005    0.289836   -0.400584    0.434451   -0.0716543   -0.153134    0.525754     -0.258889     0.314165   -0.673775     0.554379    -0.516342    0.214563    0.212935   -0.312467
  0.166336    0.293051   -0.0433494   -0.329113     -0.0814437   -0.113471   -0.0221297    0.0506403    0.477363     0.152507    -0.238047   -0.338177    0.162123    0.262463    0.68685    -0.316548     0.0259004  -0.365226     -0.213297    -0.0864793  -0.24992      0.0512971   -0.569247   -0.282456   -0.318083   -0.0463792
  0.187296    0.450307    0.160174    -0.285334     -0.591433     0.0656835   0.0286278    0.500778     0.076946    -0.143292     0.121096    0.108812    0.608864    0.411209    0.323188    0.0684181    0.071926   -0.290053      0.0756577    0.335842    0.182506     0.11879     -0.924936    0.110327   -0.265171   -0.238175
 -0.165937   -0.0213203  -0.22577     -0.189969     -0.473771     0.893186   -0.641344     0.299201     0.454233    -0.674539    -0.402319    0.120769    0.289245   -0.118091   -0.681464    0.209772     0.168236    0.0698206    -0.215139     0.156114   -0.061021     0.43295     -0.27456    -0.115363    0.161665   -0.0169135
  0.226341   -0.276884   -0.131955     0.793927      0.485414    -0.0323757  -0.238174     0.256011    -0.399685    -0.314789     0.368493    0.53162    -0.132613   -0.070664   -0.45343     0.567596     0.0132769   0.218038      0.171195     0.0700876   0.0375411   -0.152346     0.389665    0.346954   -0.291916   -0.593265
 -0.103309   -0.0599694  -0.138104     0.399679     -0.291564    -0.349357   -0.216234    -0.627156    -0.33535     -0.150529     0.253901   -0.186792    0.470819   -0.0332787   0.284855    0.254472     0.316771   -0.0749808    -0.234629     0.196525   -0.596511    -0.171184    -0.496872   -0.323907   -0.815804    0.199005
  0.32105    -0.0507753  -0.479837    -0.380861      0.300911    -0.179721    0.00307038  -0.0672473    0.628953     0.41735      0.0221092   0.0397126   0.0135832  -0.401264    0.325362    0.361248     0.0907268  -0.414707     -0.261694    -0.238467    0.505316     0.0755232    0.0141703   0.198971   -0.549109   -0.377831
 -0.355178    0.041398    0.496457     0.0604871    -0.548116     0.114371   -0.225665    -0.166607     0.0115934    0.0955608   -0.0384069  -0.22461     0.201328    0.227238    0.0741771  -0.524959    -0.0742213   0.591948      0.0859127    0.378647   -0.555031     0.112355    -0.17633    -0.384804    0.742724    0.384009
  0.39023    -0.100661   -0.0534551   -0.322905     -0.267106    -0.202237   -0.0359856    0.012841     0.253394     0.115963    -0.325359   -0.154506    0.188167    0.175784   -0.065467    0.12212     -0.503858    0.15805       0.0703523   -0.103691    0.232556     0.483197     0.269764   -0.0285354  -0.153836    0.316966
 -0.110217   -0.182306    0.308311     0.247518     -0.180005     0.142585    0.412542    -0.174586    -0.226665     0.737491    -0.0413723   0.295997   -0.168375    0.339817    0.0608963  -0.0568567    0.112493   -0.0268845     0.0357853    0.257916    0.438546    -0.408174     0.52705     0.360869    0.193222    0.0763239
 -0.0161166   0.0864412  -0.336138     0.00146807   -0.659024    -0.524632   -0.146696    -0.110419    -0.687032    -0.71611     -0.457814    0.313736   -0.0103266  -0.236174   -0.176012    0.30015     -0.0839691   0.227252      0.0956382   -0.160889    0.764443    -0.0774243    0.0118872  -0.0358855   0.430534    0.57618
 -0.302107   -0.521622    0.265287     0.255062     -0.217682    -0.163303    0.140356    -0.0701863   -0.500085    -0.40245     -0.114113    1.0315      0.296247   -0.075088    0.340253    0.0761744    0.0334754  -0.364086      0.131273     0.0438006  -0.0476211   -0.349053    -0.175377    0.107192   -0.0992532   0.169439
  0.0516142   0.529999   -0.29667      0.0333649     0.780929     0.185761   -0.435434    -0.61402     -3.76689e-5   0.674232     0.0894672  -0.478567   -0.0205229  -0.279471   -0.325766   -0.795812     0.193759    0.395249     -0.780239     0.386602    0.512303     0.0818402    0.530953   -0.070241   -0.181696    0.532019
  0.390572   -0.24424     0.197546    -0.544445      0.115832    -0.731512   -0.633424    -0.519412    -0.129669    -0.00882153   0.0387455   0.314487   -0.612949   -0.590948    0.147819    0.146994     0.404041   -0.426174      0.227833     0.196845    0.0294       0.094096     0.195758   -0.50763    -0.10626    -0.087602
  0.0789603   0.122525   -0.458502    -0.668017      0.214933     0.147956    0.325701     0.568162     0.552551     0.244239    -0.476834   -0.0894434  -0.495369    0.131229   -0.445777   -0.693422    -0.140367   -0.329891      0.105646     0.234157    0.629708     0.285454     0.139532    0.50054     0.461032   -0.287099
  0.696834    0.356568   -0.209451     1.59141       0.108546    -0.22226     0.551403     0.358398    -0.01277      0.112666    -0.249175   -0.326947   -0.0338006   0.322252    0.118003   -0.531402    -0.208457    0.18587      -0.475477    -0.323506   -0.181359    -0.607889     0.441143    0.20688     0.285378   -0.338857
  0.823892   -0.18573    -0.373951    -0.0468579    -0.352755    -0.0649145  -0.320857     0.254472     0.127843    -0.420597    -0.545809   -0.138712    0.595112   -0.734151   -0.320609   -0.503554     0.0886011   0.219145     -0.257892     0.0784252  -0.142956    -0.18272     -0.289766    0.333023    0.118145    0.644269
 -0.699379    0.430588   -0.472018     0.518008     -0.00881471   1.03701     0.0451478   -0.107182     0.310559    -0.0925345   -0.164196   -0.311847    0.169148    0.447564   -0.045968   -0.345328    -0.0849688   0.372739     -0.674036     0.0655867  -0.349183    -0.218983    -0.337513    0.239698   -0.161497    0.0439176
 -0.0286508  -0.0587349   0.00211182   0.333955      0.177198     0.0429158   0.258676     0.193754     0.0430036    0.405924     0.311846   -0.0563493  -0.302994   -0.16023    -0.522485    0.199546    -0.267525    0.438129      0.106748     0.0933294   0.136927     0.109101     0.44717     0.318601    0.296627   -0.168177
  0.135639    0.291665   -0.550153     0.110359     -0.127516    -0.3245      0.0548306    0.00655629   0.275869     0.0457932    0.195194   -0.997321   -0.205101    0.265595   -0.611118   -0.00786753  -0.0806673   0.750329      0.238518    -0.105586   -0.330133     0.28942     -0.205502    0.116466   -0.131655   -0.141839
 -0.223396   -0.0717637  -0.150391     0.0607533     0.170649     0.0511604   0.314861     0.228342     0.173658    -0.528419     0.188509   -0.517016   -0.23167    -0.427539    0.241044   -0.149939     0.67462    -0.255435      0.0524109   -0.713545   -0.210912     0.0657601   -0.388009   -0.532583   -0.070096    0.184835
  0.0273131   0.0759641  -0.0885465    0.128243     -0.0339044   -0.136789   -0.0259616   -0.0845967   -0.0122117    0.0077548    0.0806483  -0.0847963  -0.0328789  -0.0424807   0.0253307   0.00708454   0.141885    0.000960816  -0.0444303   -0.0225284  -0.0317736    0.00726872  -0.0510781  -0.0881761  -0.0787558   0.0374975
 -0.730553    0.243367    0.216809     0.298401      0.530722    -0.056753    0.00671243  -0.704445    -0.259384     0.277884    -0.137125    0.242804   -0.895909   -0.0464663   0.588432   -0.0483732   -0.309237    0.259226     -0.46842     -0.549173   -0.110964     0.00409643   0.166332    0.111964    0.313891   -0.243378
  0.297334   -0.882603    0.187074    -0.388446      0.834509     0.41741    -0.580043    -0.10147     -0.138401    -0.366739    -0.675981    0.209329   -0.487405    0.189159   -0.0777759   0.0229675   -0.115155    0.391562      0.0674854    0.175873   -0.523129    -0.0130472    0.246805    0.387613   -0.14342    -0.584831
 -0.306282    0.177236    0.00693049   0.0341506     0.246762    -0.660699    0.519443    -0.565272    -0.123851     0.868532     0.170863   -0.211286   -0.0685257   0.575546    0.461683    0.0499712    0.0589026  -0.463014      0.435512     0.109508    0.237401     0.0821408    0.134241   -0.389411   -0.342038   -0.226653
  0.150062    0.0464446   0.501624     0.212898      0.307784     0.203393    0.022629    -0.00251705   0.425318     0.680865     0.305395   -0.422585   -0.389174   -0.167329   -0.0523519  -0.171993    -0.0453122   0.0513142     0.0915001    0.167122   -0.390152     0.302934     0.0746012  -0.121279    0.319474   -0.543272
  0.939936    0.12208     0.0884091   -0.0530154     0.0790776   -0.951135    0.181642    -0.316465    -0.785757    -0.249394     0.210603   -0.317165    0.142503    0.332948    0.357393    0.29188      0.286351   -0.0272898     0.526312    -0.699077    0.265951    -0.519217     0.0332925   0.208285   -0.659905    0.382618
  0.107957    0.181262    0.579887     0.397553      0.337989     0.500738   -0.0586291    0.463071     0.252243     0.119644     0.444719    0.333327   -0.304705    0.028133    0.0627272   0.285016    -0.327796   -0.0323694     0.0853482   -0.43565     0.387313    -0.141904     0.397515   -0.0848304   0.517253   -0.045624
 -0.432221   -0.55159    -0.153207    -1.60622      -0.567259     0.560073   -0.294135    -0.605481    -0.32245      0.292832     0.218527    0.209152    0.236274    0.0204161  -0.351565    0.911625    -0.0601409  -0.793256      0.547804    -0.242055    0.0924916    0.837275     0.0378375   0.283082   -0.0808125   0.543047
 -0.206018   -0.116526    0.0673026    0.000143958  -0.0551762    0.400695   -0.0778605    0.326142    -0.125469    -0.306721    -0.239386    0.268227   -0.0112807   0.0106688  -0.278737   -0.114043    -0.144853    0.149411      0.00178604   0.0997841  -0.00228593  -0.0882166   -0.0282098   0.236512    0.3744     -0.0246614[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411186
[ Info: iteration 2, average log likelihood -1.411177
[ Info: iteration 3, average log likelihood -1.411169
[ Info: iteration 4, average log likelihood -1.411160
[ Info: iteration 5, average log likelihood -1.411152
[ Info: iteration 6, average log likelihood -1.411144
[ Info: iteration 7, average log likelihood -1.411136
[ Info: iteration 8, average log likelihood -1.411128
[ Info: iteration 9, average log likelihood -1.411121
[ Info: iteration 10, average log likelihood -1.411114
┌ Info: EM with 100000 data points 10 iterations avll -1.411114
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
