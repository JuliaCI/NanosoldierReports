   Cloning default registries into `~/.julia`
   Cloning registry from "https://github.com/JuliaRegistries/General.git"
[?25l    Fetching: [>                                        ]  0.0 %    Fetching: [============>                            ]  29.4 %    Fetching: [=========================>               ]  60.7 %[2K[?25h     Added registry `General` to `~/.julia/registries/General`
 Resolving package versions...
 Installed StrTables â”€â”€â”€â”€â”€â”€ v1.0.1
 Installed WordTokenizers â”€ v0.5.3
 Installed HTML_Entities â”€â”€ v1.0.0
  Updating `~/.julia/environments/v1.3/Project.toml`
  [796a5d58] + WordTokenizers v0.5.3
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7693890a] + HTML_Entities v1.0.0
  [9700d1a9] + StrTables v1.0.1
  [796a5d58] + WordTokenizers v0.5.3
  [ade2ca70] + Dates 
  [de0858da] + Printf 
  [4ec0a83e] + Unicode 
  Building HTML_Entities â†’ `~/.julia/packages/HTML_Entities/g4t7p/deps/build.log`
   Testing WordTokenizers
 Resolving package versions...
    Status `/tmp/jl_tXEpVX/Manifest.toml`
  [7693890a] HTML_Entities v1.0.0
  [9700d1a9] StrTables v1.0.1
  [796a5d58] WordTokenizers v0.5.3
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [8dfed614] Test  [`@stdlib/Test`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
Test Summary: | Pass  Total
simple        |    6      6
Test Summary: | Pass  Total
sedbased      |   35     35
Test Summary:      | Pass  Broken  Total
sentence_splitting |   11       1     12
Test Summary:  | Pass  Total
set_method_api |    5      5
Test Summary:  | Pass  Total
tweet_tokenize |   24     24
Test Summary:  | Pass  Total
reversible_tok |    7      7
Test Summary: | Pass  Total
toktok        |   24     24
   Testing WordTokenizers tests passed 
