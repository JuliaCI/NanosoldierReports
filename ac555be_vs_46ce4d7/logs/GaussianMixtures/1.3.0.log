Running tests with Julia v1.3.0
   Cloning default registries into `~/.julia`
   Cloning registry from "https://github.com/JuliaRegistries/General.git"
[?25l    Fetching: [>                                        ]  0.0 %    Fetching: [==============>                          ]  33.9 %    Fetching: [====================================>    ]  88.7 %[2K[?25h     Added registry `General` to `~/.julia/registries/General`
 Resolving package versions...
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.6
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.2
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.21.10
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+1
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed OrderedCollections â”€ v1.1.0
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed SpecialFunctions â”€â”€â”€ v0.8.0
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.0
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed Polynomials â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.10
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [f27b6e38] + Polynomials v0.6.0
  [1fd47b50] + QuadGK v2.2.0
  [3cdcf5f2] + RecipesBase v0.7.0
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.8.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building SpecialFunctions â†’ `~/.julia/packages/SpecialFunctions/ne2iw/deps/build.log`
  Building CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_ch4qNk/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.10
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [f27b6e38] Polynomials v0.6.0
  [1fd47b50] QuadGK v2.2.0
  [3cdcf5f2] RecipesBase v0.7.0
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.8.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -1.0942104898316269e6, [17376.061774390582, 82623.93822560944], [-4483.028253118232 -37.072677429131545 612.0788507880433; 3896.458328132596 -255.73432732175962 -227.3102897117193], Array{Float64,2}[[5306.504344174119 6130.5810472885605 3597.4740019578558; 6130.581047288559 13825.133560776454 -1073.8499964631321; 3597.4740019578558 -1073.8499964631324 17239.066245783564], [95337.83423130598 -6155.997095275163 -3565.5967408178785; -6155.997095275163 86746.28600945474 542.9957622759309; -3565.596740817878 542.9957622759309 82188.92521566877]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.771593e+02
      1       8.574713e+02      -1.196880e+02 |        5
      2       8.473691e+02      -1.010222e+01 |        0
      3       8.473691e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 847.3691244197025)
â”Œ Info: K-means with 272 data points using 3 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.082976
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.876054
[ Info: iteration 2, lowerbound -3.798202
[ Info: iteration 3, lowerbound -3.723300
[ Info: iteration 4, lowerbound -3.630189
[ Info: iteration 5, lowerbound -3.517443
[ Info: iteration 6, lowerbound -3.387715
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.249236
[ Info: iteration 8, lowerbound -3.123519
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -3.029207
[ Info: iteration 10, lowerbound -2.963431
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.905739
[ Info: iteration 12, lowerbound -2.854360
[ Info: iteration 13, lowerbound -2.823214
[ Info: iteration 14, lowerbound -2.807653
[ Info: dropping number of Gaussions to 3
[ Info: iteration 15, lowerbound -2.798527
[ Info: iteration 16, lowerbound -2.787206
[ Info: iteration 17, lowerbound -2.776441
[ Info: iteration 18, lowerbound -2.761146
[ Info: iteration 19, lowerbound -2.739832
[ Info: iteration 20, lowerbound -2.711200
[ Info: iteration 21, lowerbound -2.674656
[ Info: iteration 22, lowerbound -2.630879
[ Info: iteration 23, lowerbound -2.582091
[ Info: iteration 24, lowerbound -2.531752
[ Info: iteration 25, lowerbound -2.483560
[ Info: iteration 26, lowerbound -2.440094
[ Info: iteration 27, lowerbound -2.402006
[ Info: iteration 28, lowerbound -2.368503
[ Info: iteration 29, lowerbound -2.339374
[ Info: iteration 30, lowerbound -2.317448
[ Info: iteration 31, lowerbound -2.307663
[ Info: dropping number of Gaussions to 2
[ Info: iteration 32, lowerbound -2.303000
[ Info: iteration 33, lowerbound -2.299262
[ Info: iteration 34, lowerbound -2.299257
[ Info: iteration 35, lowerbound -2.299255
[ Info: iteration 36, lowerbound -2.299254
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Dec  5 23:26:09 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Dec  5 23:26:17 2019: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Thu Dec  5 23:26:18 2019: EM with 272 data points 0 iterations avll -2.082976
5.8 data points per parameter
, Thu Dec  5 23:26:20 2019: GMM converted to Variational GMM
, Thu Dec  5 23:26:29 2019: iteration 1, lowerbound -3.876054
, Thu Dec  5 23:26:29 2019: iteration 2, lowerbound -3.798202
, Thu Dec  5 23:26:29 2019: iteration 3, lowerbound -3.723300
, Thu Dec  5 23:26:29 2019: iteration 4, lowerbound -3.630189
, Thu Dec  5 23:26:29 2019: iteration 5, lowerbound -3.517443
, Thu Dec  5 23:26:29 2019: iteration 6, lowerbound -3.387715
, Thu Dec  5 23:26:30 2019: dropping number of Gaussions to 7
, Thu Dec  5 23:26:30 2019: iteration 7, lowerbound -3.249236
, Thu Dec  5 23:26:30 2019: iteration 8, lowerbound -3.123519
, Thu Dec  5 23:26:30 2019: dropping number of Gaussions to 6
, Thu Dec  5 23:26:30 2019: iteration 9, lowerbound -3.029207
, Thu Dec  5 23:26:30 2019: iteration 10, lowerbound -2.963431
, Thu Dec  5 23:26:30 2019: dropping number of Gaussions to 4
, Thu Dec  5 23:26:30 2019: iteration 11, lowerbound -2.905739
, Thu Dec  5 23:26:30 2019: iteration 12, lowerbound -2.854360
, Thu Dec  5 23:26:30 2019: iteration 13, lowerbound -2.823214
, Thu Dec  5 23:26:30 2019: iteration 14, lowerbound -2.807653
, Thu Dec  5 23:26:30 2019: dropping number of Gaussions to 3
, Thu Dec  5 23:26:30 2019: iteration 15, lowerbound -2.798527
, Thu Dec  5 23:26:30 2019: iteration 16, lowerbound -2.787206
, Thu Dec  5 23:26:30 2019: iteration 17, lowerbound -2.776441
, Thu Dec  5 23:26:30 2019: iteration 18, lowerbound -2.761146
, Thu Dec  5 23:26:30 2019: iteration 19, lowerbound -2.739832
, Thu Dec  5 23:26:30 2019: iteration 20, lowerbound -2.711200
, Thu Dec  5 23:26:30 2019: iteration 21, lowerbound -2.674656
, Thu Dec  5 23:26:30 2019: iteration 22, lowerbound -2.630879
, Thu Dec  5 23:26:30 2019: iteration 23, lowerbound -2.582091
, Thu Dec  5 23:26:30 2019: iteration 24, lowerbound -2.531752
, Thu Dec  5 23:26:30 2019: iteration 25, lowerbound -2.483560
, Thu Dec  5 23:26:30 2019: iteration 26, lowerbound -2.440094
, Thu Dec  5 23:26:30 2019: iteration 27, lowerbound -2.402006
, Thu Dec  5 23:26:30 2019: iteration 28, lowerbound -2.368503
, Thu Dec  5 23:26:30 2019: iteration 29, lowerbound -2.339374
, Thu Dec  5 23:26:30 2019: iteration 30, lowerbound -2.317448
, Thu Dec  5 23:26:30 2019: iteration 31, lowerbound -2.307663
, Thu Dec  5 23:26:30 2019: dropping number of Gaussions to 2
, Thu Dec  5 23:26:30 2019: iteration 32, lowerbound -2.303000
, Thu Dec  5 23:26:30 2019: iteration 33, lowerbound -2.299262
, Thu Dec  5 23:26:30 2019: iteration 34, lowerbound -2.299257
, Thu Dec  5 23:26:30 2019: iteration 35, lowerbound -2.299255
, Thu Dec  5 23:26:30 2019: iteration 36, lowerbound -2.299254
, Thu Dec  5 23:26:30 2019: iteration 37, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 38, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 39, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 40, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 41, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 42, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 43, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 44, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 45, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 46, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 47, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 48, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 49, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: iteration 50, lowerbound -2.299253
, Thu Dec  5 23:26:30 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509223725123, 95.9549077627489]
Î² = [178.04509223725123, 95.9549077627489]
m = [4.250300733178765 79.28686694302141; 2.0002292576809797 53.85198717196972]
Î½ = [180.04509223725123, 97.9549077627489]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554622801 -0.007644049043524773; 0.0 0.008581705164648535], [0.3758763613517427 -0.008953123829208988; 0.0 0.012748664777886822]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0031507990085877
avll from llpg:  -1.0031507990085888
avll direct:     -1.0031507990085888
sum posterior: 100000.00000000001
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -1.0001086750965082
avll from llpg:  -1.000108675096508
avll direct:     -1.000108675096508
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
  0.06332      0.0157594    0.153805     0.0337308    0.0435446   -0.0138324   -0.0211454    0.11596      0.00905334   0.097125     -0.176665     0.0392753   -0.000359321   0.0473178   0.0174685     0.138552    -0.0476763    0.0697788   -0.0341194   -0.0360203    0.0187599   -0.0592693   -0.15842     -0.180981    -0.149324    -0.0599316  
 -0.114321    -0.0521708   -0.052169     0.0777481    0.0095625   -0.0532445   -0.139064    -0.0393942    0.0802828    0.0210356    -0.163386     0.0449201    0.202638      0.0226762   0.235128      0.00138347  -0.111267     0.055959     0.156563    -0.0154436    0.0268123   -0.00355819   0.227537     0.0870358   -0.0871162   -0.0114773  
  0.210471    -0.201853     0.0500531    0.104412    -0.155315    -0.0992107    0.151318    -0.133517     0.00971053  -0.0131816    -0.181713    -0.0533551    0.077458     -0.0605276   0.0434562    -0.0286427    0.192374     0.179821     0.189412     0.0225118   -0.189261     0.0810984   -0.057387     0.0639293   -0.132879    -0.109971   
 -0.0476997   -0.0944695    0.150719     0.135154    -0.0393382    0.0532148   -0.106784     0.0375965    0.084439     0.148972      0.0223576   -0.183974     0.0548723    -0.0721304   0.139257     -0.0511918    0.0556933   -0.0798729   -0.102411    -0.0248313    0.0180816   -0.127497     0.0255028   -0.0295004   -0.0444536    0.123422   
 -0.163909     0.055531    -0.0646994    0.0597448   -0.129913     0.153875     0.0922081   -0.254979    -0.0639657   -0.105368      0.138928     0.0240341    0.0153284     0.0610497  -0.0343294    -0.325929     0.175461    -0.0500856   -0.0195328   -0.0456177    0.225055    -0.0614564   -0.108022    -0.0186665    0.00152821   0.0367081  
 -0.0448859   -0.107027    -0.118677     0.0747353   -0.0691155   -0.0933876    0.183875     0.0467969    0.147946     0.122367     -0.10852     -0.0583957    0.0156765    -0.0797402   0.0288304     0.152912    -0.0274159    0.0375119   -0.220106     0.113218    -0.21013      0.13268     -0.0611816   -0.0885252   -0.0512553    0.137244   
 -0.0362982    0.182491    -0.34495      0.0458702   -0.118885    -0.0644391   -0.0989984   -0.0709375   -0.0435983    0.0944628     0.0912063   -0.21806      0.0867154    -0.202037    0.0399846     0.047959    -0.0190962   -0.0245562    0.0938742   -0.0785004    0.0220482    0.0997532   -0.0950237    0.170253     0.0638622    0.0686256  
 -0.0405918    0.00219551   0.0615112    0.00403863   0.0117208    0.0458159   -0.102958    -0.177877     0.121782    -0.111983      0.0326835    0.165376     0.0198105     0.0920826   0.0836158     0.0829042   -0.0465679    0.191529     0.0891589   -0.0847847    0.120179    -0.0973861    0.0730014   -0.0638743    0.0387195    0.0093838  
 -0.0601589    0.141881    -0.0314887    0.0932502   -0.0420713    0.044724    -0.0355891    0.124068     0.0315292   -0.0948923     0.0111678    0.00894044  -0.00498167    0.0437532   0.0135736     0.169611    -0.0324111   -0.0181361    0.00746006  -0.110628    -0.126426     0.0484933   -0.0777414   -0.0143159   -0.03887      0.011102   
  0.219119     0.00677753   0.108359    -0.0312445    0.0254406   -0.0874011    0.0261505   -0.00690224  -0.0729732    0.0461183     0.0306805   -0.050795     0.136339     -0.06161     0.00624743    0.116695    -0.0876503   -0.143444     0.139179     0.130619    -0.10631      0.17557      0.0115556   -0.102674     0.205933    -0.0230159  
 -0.310871    -0.0686639    0.0785278   -0.115706    -0.112691    -0.162603     0.0701399   -0.0949184   -0.0965934   -0.122312      0.0684699   -0.0604097   -0.0467246     0.0319681  -0.0812734    -0.0523006    0.122995    -0.220338     0.107038    -0.0213984    0.0181668    0.0574134   -0.232881    -0.00471298   0.0102139    0.194195   
 -0.10192      0.0878766    0.00640912   0.124085    -0.0660016    0.215835    -0.0216461   -0.121419    -0.124682     0.0108874     0.169828    -0.159848     0.100037      0.190636   -0.0995438    -0.0721129   -0.0381561    0.0620569    0.0264863    0.175867    -0.172833     0.0614002   -0.0336656   -0.0261417    0.0485383    0.000462325
 -0.00116605  -0.0780199    0.0727895    0.0341787   -0.0546395    0.117736     0.00405498  -0.107261    -0.116915     0.00199827    0.0927666   -0.29538     -0.0709163    -0.0604903  -0.0424663     0.175953     0.0572795    0.00817431  -0.123078     0.00248269  -0.131578    -0.106145     0.0385487   -0.104176     0.053171    -0.00433814 
 -0.0517284   -0.0219542   -0.0484047    0.00781096   0.042876     0.0795341    0.0240721    0.0136285    0.22747      0.0534683    -0.0132156   -0.0801346   -0.10959       0.0401759  -0.0265691     0.0218776   -0.159508    -0.00407964  -0.029773     0.0777432   -0.0463718   -0.227693    -0.0591023   -0.186993     0.0511697    0.0512486  
  0.104288     0.0792707   -0.033264    -0.0755627    0.0847749   -0.00318904  -0.100458    -0.00422562   0.121226    -0.267722      0.0840069    0.0921982   -0.122337      0.127568    0.0692805    -0.0184711    0.0377053   -0.125011    -0.0710507    0.218149    -0.0586726   -0.138047    -0.0536191   -0.14508     -0.0127539   -0.0830263  
  0.121855     0.149387    -0.0433416   -0.142637     0.226216    -0.00686608   0.0207405    0.0723281   -0.0295375   -0.00776218    0.00457572   0.0662611   -0.0821408     0.0428435   0.144872      0.0657088    0.0124658    0.221358     0.0510272    0.0461586   -0.0223677   -0.0084443    0.0569087   -0.275551     0.066004    -0.14785    
  0.0155234   -0.139973     0.0793501   -0.216664     0.0716645   -0.0270193    0.0397047    0.0307733    0.0903937    0.0491973     0.0571183   -0.0179687   -0.0192253     0.0586356   0.00415385   -0.0838171   -0.105032    -0.115525    -0.0675959    0.107575    -0.0648932    0.165492    -0.117856    -0.096054     0.0479782   -0.123449   
 -0.170262    -0.0433893    0.0376232    0.175287     0.183044     0.17126      0.144907     0.104989    -0.14214     -0.0886247    -0.0277545    0.00888913   0.104573      0.115169   -0.0342279     0.0135046    0.0976878    0.0573814    0.0808472    0.0868017   -0.0801184   -0.0680956    0.08136      0.131937    -0.0283568   -0.270339   
  0.139903    -0.146188     0.0062527    0.00349717  -0.141281     0.164167     0.0624612   -0.0656405    0.0659133   -0.0139011    -0.0686796   -0.0419285    0.0450861     0.115232    0.120018     -0.132683     0.143429    -0.228111    -0.104398     0.104861     0.0680361    0.0352538   -0.0303533   -0.126763    -0.0679293    0.0231508  
  0.0723076    0.0151034    0.140049     0.0664356    0.035835    -0.00752694   0.125025    -0.198163    -0.169075    -0.0950946     0.036145    -0.00183823   0.0461676    -0.0472399   0.0878102    -0.0896906    0.126061     0.00476061   0.0899408    0.0718434   -0.0351013    0.101166    -0.169165     0.096034     0.0658231   -0.0400106  
 -0.0939361   -0.133807     0.00830502   0.0563046   -0.00972915   0.167695    -0.0639173    0.158413     0.0196684   -0.0686175     0.0999748   -0.095269     0.0141079    -0.141477   -0.00708637   -0.0572776   -0.0825518   -0.0258017    0.0481561   -0.110324    -0.017051     0.0687436   -0.00108451   0.0288107    0.0422479   -0.019036   
 -0.0369596   -0.10551      0.0749671    0.0655236    0.0884111   -0.11496     -0.0629597   -0.0541414    0.122115    -0.000408806  -0.284133     0.0171265    0.105297      0.147274    0.0956142     0.218315     0.178155    -0.103024     0.133326    -0.00503792   0.115631     0.149947    -0.0207366   -0.0258973    0.0929422   -0.240812   
 -0.0692915    0.0729404    0.21272     -0.088483    -0.108041    -0.00864965  -0.133889    -0.0518481   -0.148031    -0.148485      0.104402     0.120745    -0.0019865    -0.0262983   0.000707845  -0.030581     0.0240873   -0.0319856    0.0671225    0.0510944    0.0895203    0.152171    -0.0151789    0.0631821    0.0297336   -0.108552   
  0.00441959  -0.0918842   -0.0609953   -0.0394125   -0.0787265   -0.0362945    0.219046    -0.147914    -0.0154592   -0.0483039    -0.0634254   -0.0135353   -0.217183     -0.146956    0.0458945    -0.0560134   -0.0231586   -0.0376671    0.18485     -0.0242718   -0.19596      0.152718    -0.0926917    0.156496    -0.0878432    0.000123703
  0.108012     0.0773938   -0.103299    -0.0826102    0.0638817   -0.0756669    0.00851321  -0.034356     0.00529866   0.0696052     0.00828412   0.0115259   -0.0792494    -0.0395568  -0.0252848    -0.162084     0.0741077   -0.0294123    0.0536729    0.0682521   -0.210653     0.0363284   -0.207125     0.0709051    0.139822     0.045604   
 -0.0577078    0.148181     0.054154     0.174604    -0.0937123   -0.272384     0.103015    -0.0883182   -0.0742581   -0.0507251    -0.0943852    0.180637    -0.116147     -0.108783    0.0850841    -0.0566758    0.0272577    0.0336383    0.168249     0.115834     0.0073748   -0.0573293   -0.0397774   -0.0468779    0.114649    -0.0288495  
 -0.155568    -0.0642753   -0.0261233   -0.0462302   -0.0814898    0.161994     0.14042     -0.106795    -0.0593967   -0.0726198     0.127281    -0.0527974   -0.0472506    -0.13357    -0.117584     -0.0472559    0.00836933   0.175228    -0.162711     0.13583     -0.00958432  -0.049131     0.0900414   -0.0946125   -0.131696    -0.067165   
  0.0290321   -0.106373    -0.0910443   -0.0281987    0.0306858    0.00763883   0.098409     0.0603608    0.0566596    0.00498222   -0.101816    -0.0236083    0.125137     -0.0445643   0.121001      0.149411     0.00973831   0.0054463   -0.0693233    0.0637237    0.010238    -0.112074    -0.0626162    0.0584084    0.124981    -0.150171   
  0.0454637   -0.0355684    0.0296897   -0.0973377   -0.10888      0.0407281   -0.185299    -0.0136033   -0.0877835    0.0190673    -0.158598     0.172134    -0.0577359     0.060914   -0.147785      0.0859043   -0.0919663   -0.0673761    0.0322696    0.139623    -0.0258612   -0.0175454   -0.16055      0.237912    -0.0625191    0.079459   
 -0.100438     0.0785714    0.0999266    0.122335     0.0798317   -0.0933854    0.192911    -0.196981    -0.132391    -0.125275      0.0126896   -0.227806     0.0160116    -0.0651043  -0.0661255    -0.237917    -0.111351    -0.199185     0.0748674    0.215659    -0.0720851    0.0721461    0.119278    -0.0384919   -0.0207227    0.085585   
 -0.0185559    0.0789223   -0.00321872   0.0156487   -0.0590227    0.0732569   -0.25052     -0.0493401    0.101112    -0.096832      0.174348    -0.0136014   -0.0991762     0.180509    0.0342977    -0.111661     0.0926407   -0.0470111    0.0740245   -0.00999549  -0.15998     -0.0348806    0.166025    -0.114091     0.0460875   -0.0503536  
 -0.0466296   -0.0191418   -0.0416189    0.119869    -0.013316     0.19952     -0.129105     0.0105348    0.0347584   -0.0130908    -0.120775     0.0105827   -0.059545      0.0919776  -0.00262586    0.00755042  -0.0182387   -0.0112406   -0.173802     0.00757976   0.0568472    0.0102933    0.0393274   -0.00252811   0.00834454  -0.136158   kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4194186485379876
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419481
[ Info: iteration 2, average log likelihood -1.419411
[ Info: iteration 3, average log likelihood -1.418832
[ Info: iteration 4, average log likelihood -1.411051
[ Info: iteration 5, average log likelihood -1.389818
[ Info: iteration 6, average log likelihood -1.382136
[ Info: iteration 7, average log likelihood -1.380249
[ Info: iteration 8, average log likelihood -1.378961
[ Info: iteration 9, average log likelihood -1.377961
[ Info: iteration 10, average log likelihood -1.377171
[ Info: iteration 11, average log likelihood -1.376523
[ Info: iteration 12, average log likelihood -1.376035
[ Info: iteration 13, average log likelihood -1.375711
[ Info: iteration 14, average log likelihood -1.375493
[ Info: iteration 15, average log likelihood -1.375343
[ Info: iteration 16, average log likelihood -1.375243
[ Info: iteration 17, average log likelihood -1.375181
[ Info: iteration 18, average log likelihood -1.375142
[ Info: iteration 19, average log likelihood -1.375118
[ Info: iteration 20, average log likelihood -1.375102
[ Info: iteration 21, average log likelihood -1.375092
[ Info: iteration 22, average log likelihood -1.375085
[ Info: iteration 23, average log likelihood -1.375080
[ Info: iteration 24, average log likelihood -1.375077
[ Info: iteration 25, average log likelihood -1.375075
[ Info: iteration 26, average log likelihood -1.375073
[ Info: iteration 27, average log likelihood -1.375072
[ Info: iteration 28, average log likelihood -1.375071
[ Info: iteration 29, average log likelihood -1.375071
[ Info: iteration 30, average log likelihood -1.375071
[ Info: iteration 31, average log likelihood -1.375070
[ Info: iteration 32, average log likelihood -1.375070
[ Info: iteration 33, average log likelihood -1.375070
[ Info: iteration 34, average log likelihood -1.375070
[ Info: iteration 35, average log likelihood -1.375070
[ Info: iteration 36, average log likelihood -1.375070
[ Info: iteration 37, average log likelihood -1.375070
[ Info: iteration 38, average log likelihood -1.375070
[ Info: iteration 39, average log likelihood -1.375070
[ Info: iteration 40, average log likelihood -1.375070
[ Info: iteration 41, average log likelihood -1.375070
[ Info: iteration 42, average log likelihood -1.375070
[ Info: iteration 43, average log likelihood -1.375070
[ Info: iteration 44, average log likelihood -1.375070
[ Info: iteration 45, average log likelihood -1.375070
[ Info: iteration 46, average log likelihood -1.375070
[ Info: iteration 47, average log likelihood -1.375070
[ Info: iteration 48, average log likelihood -1.375070
[ Info: iteration 49, average log likelihood -1.375070
[ Info: iteration 50, average log likelihood -1.375070
â”Œ Info: EM with 100000 data points 50 iterations avll -1.375070
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4194812612115204
â”‚     -1.4194107206841151
â”‚      â‹®                 
â””     -1.3750697813159511
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.375194
[ Info: iteration 2, average log likelihood -1.375077
[ Info: iteration 3, average log likelihood -1.374588
[ Info: iteration 4, average log likelihood -1.369324
[ Info: iteration 5, average log likelihood -1.350508
[ Info: iteration 6, average log likelihood -1.336646
[ Info: iteration 7, average log likelihood -1.332260
[ Info: iteration 8, average log likelihood -1.330450
[ Info: iteration 9, average log likelihood -1.329454
[ Info: iteration 10, average log likelihood -1.328824
[ Info: iteration 11, average log likelihood -1.328376
[ Info: iteration 12, average log likelihood -1.328012
[ Info: iteration 13, average log likelihood -1.327686
[ Info: iteration 14, average log likelihood -1.327357
[ Info: iteration 15, average log likelihood -1.327004
[ Info: iteration 16, average log likelihood -1.326647
[ Info: iteration 17, average log likelihood -1.326249
[ Info: iteration 18, average log likelihood -1.325791
[ Info: iteration 19, average log likelihood -1.325233
[ Info: iteration 20, average log likelihood -1.324547
[ Info: iteration 21, average log likelihood -1.323801
[ Info: iteration 22, average log likelihood -1.323104
[ Info: iteration 23, average log likelihood -1.322566
[ Info: iteration 24, average log likelihood -1.322200
[ Info: iteration 25, average log likelihood -1.321962
[ Info: iteration 26, average log likelihood -1.321805
[ Info: iteration 27, average log likelihood -1.321698
[ Info: iteration 28, average log likelihood -1.321620
[ Info: iteration 29, average log likelihood -1.321558
[ Info: iteration 30, average log likelihood -1.321504
[ Info: iteration 31, average log likelihood -1.321451
[ Info: iteration 32, average log likelihood -1.321395
[ Info: iteration 33, average log likelihood -1.321333
[ Info: iteration 34, average log likelihood -1.321266
[ Info: iteration 35, average log likelihood -1.321197
[ Info: iteration 36, average log likelihood -1.321129
[ Info: iteration 37, average log likelihood -1.321064
[ Info: iteration 38, average log likelihood -1.321004
[ Info: iteration 39, average log likelihood -1.320950
[ Info: iteration 40, average log likelihood -1.320903
[ Info: iteration 41, average log likelihood -1.320866
[ Info: iteration 42, average log likelihood -1.320838
[ Info: iteration 43, average log likelihood -1.320820
[ Info: iteration 44, average log likelihood -1.320808
[ Info: iteration 45, average log likelihood -1.320801
[ Info: iteration 46, average log likelihood -1.320796
[ Info: iteration 47, average log likelihood -1.320794
[ Info: iteration 48, average log likelihood -1.320792
[ Info: iteration 49, average log likelihood -1.320791
[ Info: iteration 50, average log likelihood -1.320791
â”Œ Info: EM with 100000 data points 50 iterations avll -1.320791
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3751939363328618
â”‚     -1.375076750892092 
â”‚      â‹®                 
â””     -1.3207908525667655
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.321000
[ Info: iteration 2, average log likelihood -1.320768
[ Info: iteration 3, average log likelihood -1.319793
[ Info: iteration 4, average log likelihood -1.310327
[ Info: iteration 5, average log likelihood -1.286069
[ Info: iteration 6, average log likelihood -1.272072
[ Info: iteration 7, average log likelihood -1.265626
[ Info: iteration 8, average log likelihood -1.261330
[ Info: iteration 9, average log likelihood -1.258361
[ Info: iteration 10, average log likelihood -1.256214
[ Info: iteration 11, average log likelihood -1.254897
[ Info: iteration 12, average log likelihood -1.254086
[ Info: iteration 13, average log likelihood -1.253545
[ Info: iteration 14, average log likelihood -1.253192
[ Info: iteration 15, average log likelihood -1.252976
[ Info: iteration 16, average log likelihood -1.252790
[ Info: iteration 17, average log likelihood -1.252588
[ Info: iteration 18, average log likelihood -1.252381
[ Info: iteration 19, average log likelihood -1.252183
[ Info: iteration 20, average log likelihood -1.252020
[ Info: iteration 21, average log likelihood -1.251896
[ Info: iteration 22, average log likelihood -1.251800
[ Info: iteration 23, average log likelihood -1.251725
[ Info: iteration 24, average log likelihood -1.251665
[ Info: iteration 25, average log likelihood -1.251617
[ Info: iteration 26, average log likelihood -1.251580
[ Info: iteration 27, average log likelihood -1.251552
[ Info: iteration 28, average log likelihood -1.251532
[ Info: iteration 29, average log likelihood -1.251519
[ Info: iteration 30, average log likelihood -1.251509
[ Info: iteration 31, average log likelihood -1.251502
[ Info: iteration 32, average log likelihood -1.251497
[ Info: iteration 33, average log likelihood -1.251494
[ Info: iteration 34, average log likelihood -1.251491
[ Info: iteration 35, average log likelihood -1.251490
[ Info: iteration 36, average log likelihood -1.251488
[ Info: iteration 37, average log likelihood -1.251487
[ Info: iteration 38, average log likelihood -1.251487
[ Info: iteration 39, average log likelihood -1.251486
[ Info: iteration 40, average log likelihood -1.251486
[ Info: iteration 41, average log likelihood -1.251486
[ Info: iteration 42, average log likelihood -1.251486
[ Info: iteration 43, average log likelihood -1.251486
[ Info: iteration 44, average log likelihood -1.251485
[ Info: iteration 45, average log likelihood -1.251485
[ Info: iteration 46, average log likelihood -1.251485
[ Info: iteration 47, average log likelihood -1.251485
[ Info: iteration 48, average log likelihood -1.251485
[ Info: iteration 49, average log likelihood -1.251485
[ Info: iteration 50, average log likelihood -1.251485
â”Œ Info: EM with 100000 data points 50 iterations avll -1.251485
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3210001199207082
â”‚     -1.3207677004308924
â”‚      â‹®                 
â””     -1.2514852302463781
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.251729
[ Info: iteration 2, average log likelihood -1.251420
[ Info: iteration 3, average log likelihood -1.249654
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.230373
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.187860
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.187419
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.164965
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.176055
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.160251
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.174463
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.159248
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.173848
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.166326
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.166382
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.166255
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.173635
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.158919
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.173629
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.166213
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.173603
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.158974
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.173589
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.166172
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.173555
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.158930
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.173544
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.166138
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.173516
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.158902
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.173506
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.166106
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.173468
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.158854
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.173437
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.166035
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.173378
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.158747
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.173333
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.165937
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.173280
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.165902
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.173255
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.165886
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.173244
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.165879
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.173238
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.165875
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.173233
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.165872
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.173230
â”Œ Info: EM with 100000 data points 50 iterations avll -1.173230
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2517291751250814
â”‚     -1.2514197055026117
â”‚      â‹®                 
â””     -1.1732295771349441
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.166163
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.165778
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.163603
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     25
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.140848
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.089848
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.054210
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚     11
â”‚     14
â”‚     20
â”‚     21
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.057646
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     25
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.068740
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.052688
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     14
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.058523
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     11
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.055317
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      5
â”‚     20
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.045273
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     11
â”‚     14
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.064359
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     25
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.059763
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.049140
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     14
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.054982
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     11
â”‚     20
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.051642
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.058031
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     11
â”‚     14
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.057830
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     25
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.057680
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     20
â”‚     21
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.046170
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     14
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.065192
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     11
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.058821
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.050457
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     11
â”‚     14
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.054985
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     20
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.053481
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.057013
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     14
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.058954
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     11
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.056859
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.047455
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚     11
â”‚     14
â”‚     20
â”‚     21
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.050830
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     25
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.065866
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.050762
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     14
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.057106
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     11
â”‚     20
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.054116
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.057838
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     11
â”‚     14
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.057853
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     25
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.058205
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.047457
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚     14
â”‚     20
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.052631
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     11
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.064831
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.051685
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     11
â”‚     14
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.056091
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     25
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.055375
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     20
â”‚     21
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.043683
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚     14
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.065228
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     11
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.058692
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     21
â”‚     22
â”‚     23
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.049846
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚     11
â”‚     14
â”‚     20
â”‚     21
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.053533
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     23
â”‚     24
â”‚     25
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.065696
â”Œ Info: EM with 100000 data points 50 iterations avll -1.065696
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.1661631263868812
â”‚     -1.165777665165498 
â”‚      â‹®                 
â””     -1.0656963985855732
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4194186485379876
â”‚     -1.4194812612115204
â”‚     -1.4194107206841151
â”‚     -1.4188322842146417
â”‚      â‹®                 
â”‚     -1.049846147518114 
â”‚     -1.0535325426177995
â””     -1.0656963985855732
32Ã—26 Array{Float64,2}:
 -0.234943     0.000179826  -0.00647044  -0.00387952   -0.116703    -0.0142024    0.0760343   -0.151413   -0.0743019   -0.140814     0.0885613   -0.0241582   -0.00968501   0.0507763   -0.0549608   -0.164942     0.179359    -0.138406     0.046566    -0.0277557    0.115791   -0.00202022  -0.172051   -0.00196967   0.0045429    0.11013    
  0.0838554   -0.0793668     0.00849197  -0.0574552    -0.136885     0.0915612   -0.0792216   -0.0403746  -0.0185906    0.00746381  -0.105906     0.0861627   -0.0283615    0.0994657   -0.0408007   -0.0200499    0.0204104   -0.151654    -0.0513101    0.132965     0.0163766   0.016362    -0.11344     0.0739023   -0.0567598    0.0598676  
 -0.0919247   -0.132472     -0.0289894    0.0717844    -0.00437736   0.192621    -0.0608871    0.147721    0.0180606   -0.103481     0.107743    -0.12892      0.00594427  -0.142187    -0.00950317  -0.0507666   -0.0831594   -0.0293943    0.0536896   -0.125792    -0.0149122   0.0670156   -0.046884    0.0261655    0.0410264   -0.0185521  
  0.201003    -0.199499      0.0523629    0.101009     -0.137899    -0.0995084    0.165337    -0.155006   -0.00398356  -0.00976775  -0.166763    -0.0702763    0.0756743   -0.0547549    0.0586513   -0.0503817    0.198686     0.149748     0.14951      0.0152581   -0.16386     0.0757095   -0.0196491   0.0388015   -0.128372    -0.116495   
  0.0440162   -0.00389181    0.118272     0.0913173     0.0279857   -0.00623656   0.125919    -0.19193    -0.153492    -0.0945929    0.0870845   -0.00703394   0.0505936   -0.046101     0.063996    -0.0814885    0.112248     0.00764397   0.119286     0.0683008   -0.035534    0.0731243   -0.180732    0.0963175    0.0595771   -0.0441417  
 -0.0897866    0.0947497     0.00485371   0.128876     -0.0311421    0.199372    -0.0125804   -0.129628   -0.127017     0.0123258    0.172638    -0.15712      0.101646     0.176696    -0.093747    -0.104109    -0.00718016   0.0633401    0.0233136    0.177251    -0.167254    0.0735872   -0.0404948  -0.030597     0.0292727    0.000669164
 -0.181272    -0.327378      0.0442852    0.142313     -0.0725041   -0.266721     0.118713    -0.1057     -0.0595209   -0.0498479   -0.089697     0.189325    -0.0661576   -0.106081     0.121342     0.00945732   0.0333413   -0.0191978    0.314969     0.111715     0.036556   -0.0717954   -0.0290157  -0.0502269    0.133375    -0.179032   
  0.00105625   0.659294      0.0821921    0.268039     -0.13815     -0.275606     0.148222    -0.0488606  -0.0940242   -0.0484734   -0.0535273    0.187248    -0.0727768   -0.106594     0.0533093   -0.158418    -0.0416494    0.0967344   -0.00291202   0.119944    -0.0133123  -0.0448504   -0.0511832  -0.0513173    0.09684      0.0250693  
 -0.0393096    0.18703      -0.345282     0.0453294    -0.11533     -0.0640459   -0.0956678   -0.070449   -0.0407807    0.0072981    0.0898196   -0.205912     0.114179    -0.227656     0.0310267    0.0563581   -0.0393516   -0.041863     0.0889313   -0.0733986    0.0604276   0.113984    -0.0945253   0.205831     0.0491713    0.0663538  
 -0.097968     0.087154      0.221515    -0.0755393    -0.104101    -0.0079864   -0.127275    -0.046703   -0.149761    -0.153801     0.100188     0.112909    -0.00315889  -0.0398661   -0.0292005   -0.0330371    0.0412645    0.00396541   0.0756323    0.0904644    0.0808088   0.152657    -0.0300076   0.0630815    0.0271071   -0.110049   
  0.126546     0.14611      -0.0312213   -0.149835      0.216747    -0.00529202   0.0229965    0.0622837  -0.0330182   -0.0399137    0.00494624   0.0580306   -0.0712367    0.057379     0.146794     0.0652785    0.0135122    0.216277     0.0493965    0.068981    -0.0694557  -0.011743     0.0662617  -0.273464     0.0416354   -0.123485   
  0.0495124   -0.143527      0.0707093   -0.210207      0.0811699   -0.0257483    0.0386149    0.037758    0.092335     0.0594234    0.101987    -0.031016    -0.011603     0.0722958    0.012869    -0.0531841   -0.128247    -0.112846    -0.0551049    0.133464    -0.0773687   0.162303    -0.129571   -0.105641     0.0362264   -0.129366   
 -0.0386253    0.0409279     0.050387     0.004235     -0.030938     0.0784153   -0.233144    -0.110803    0.110423    -0.10459      0.128137     0.0941048   -0.0484115    0.161753     0.0633494   -0.0262189    0.0292078    0.0572065    0.0813947   -0.045517    -0.0257448  -0.0693169    0.120031   -0.086603     0.0389715   -0.0230371  
 -0.0309675   -0.0851912     0.115222     0.0623392     0.0763038   -0.0891104   -0.0754183   -0.0558732   0.116936     0.0128865   -0.258088     0.00208441   0.0966456    0.14352      0.0820513    0.176517     0.15918     -0.0910101    0.141241    -0.0303939    0.146669    0.111443    -0.0106485  -0.0351645    0.109084    -0.238975   
 -0.0586923   -0.0802764    -0.0603606    0.0128075    -0.0319657   -0.0416076    0.0462966   -0.0869852   0.0298031   -0.0236321   -0.11186      0.0199342    0.00572942  -0.0570195    0.141389    -0.0419291   -0.0278115    0.0133367    0.171011    -0.0204471   -0.0855965   0.08418      0.0656205   0.114774    -0.0800947   -0.0198566  
  0.0280851   -0.00990253   -0.0695948   -0.000921513   0.0110297   -0.0428749    0.0319613    0.0395048   0.148844    -0.0803676   -0.0186793    0.0219463   -0.0612337    0.0101614    0.0462239    0.0792316   -0.0198057   -0.0457263   -0.150116     0.161108    -0.129355    0.00408815  -0.060547   -0.115707    -0.0398028    0.00476062 
 -0.0500272    0.143406     -0.0387178    0.0719914    -0.0403528    0.0456273   -0.0472958    0.107546    0.0453936   -0.634537     0.0130187    0.0199151    0.0044072   -0.00365815  -0.00436108   0.118052    -0.0074151   -0.0949217    0.0185673   -0.114042    -0.0879067   0.194521     0.012759   -0.055213    -0.00998728   0.0100352  
 -0.0623543    0.144887     -0.0281694    0.133448     -0.0486162    0.045252    -0.0277711    0.143115   -0.0487128    0.414089     0.0110739    0.00322816   0.0809097    0.0723457    0.035117     0.210496    -0.0225987    0.0507086    0.0085849   -0.086802    -0.152478   -0.0789949   -0.11553     0.00353277  -0.0537904    0.00677068 
 -0.0636893   -0.0488248     0.0869015    0.113259     -0.0365038    0.102282    -0.133655     0.0459296   0.0477164    0.109646    -0.0626981   -0.119398     0.016259     0.00638907   0.112473    -0.029037     0.030199    -0.092914    -0.125311    -0.0812385    0.0325353  -0.0464375    0.022463   -0.00945025  -0.0322596    0.0260031  
 -0.127946    -0.043337     -0.0542767   -0.0218376    -0.0492239    0.191488     0.0814475   -0.0615815  -0.043437    -0.0811824    0.0823      -0.0234343   -0.0563956   -0.0889193   -0.0937399   -0.0113483    0.00699395   0.176249    -0.17963      0.153045     0.0121419  -0.0228852    0.0461629  -0.0723685   -0.117819    -0.0866316  
  0.216886    -0.00945499    0.116113    -0.0332249     0.0193145   -0.0852416    0.0318136   -0.196263   -0.076345    -0.222176     0.875005    -0.0578758    0.144859    -0.0267392    0.0439505    0.130814    -0.0871571   -0.254758     0.0856325    0.0933132   -0.112933    0.172332     0.0204012  -0.0844033    0.217172    -0.00915679 
  0.226177     0.0702728     0.105777    -0.0330811     0.0247095   -0.0871063    0.0290031    0.232445   -0.0744946    0.301278    -0.881734    -0.0396026    0.150644    -0.139833    -0.0747959    0.127849    -0.0854974   -0.0760789    0.101133     0.202998    -0.147108    0.174642     0.0110326  -0.159052     0.201669    -0.0341082  
 -0.154968     0.0814424     0.28274      0.105896      0.163122    -0.0972853    0.186958    -0.208318    0.873607    -0.125439     0.0209598   -0.233855     0.0268945   -0.06436     -0.0519905   -0.0191645   -0.109487    -0.204328     0.0836905    0.230015    -0.0691032   0.0743682    0.135089   -0.0404878   -0.0220931    0.0663591  
 -0.0735345    0.0469093    -0.144918     0.137223      0.0127057   -0.0909833    0.185629    -0.203604   -1.06099     -0.126128     0.0160342   -0.234353     0.0109967   -0.0436361   -0.0317016   -0.478568    -0.112838    -0.182208     0.0702779    0.23167     -0.0678353   0.0739363    0.119037   -0.0165173   -0.0233961    0.0898008  
  0.00589504  -0.0730642     0.11024      0.0347502    -0.0663589    0.112698    -0.024882    -0.103161   -0.142099     0.0373932    0.0931076   -0.297871    -0.0493286   -0.0554443   -0.0433893    0.17536      0.0506543    0.0079772   -0.108494     0.00491989  -0.135597   -0.0905972    0.0506424  -0.0938697    0.0562592    0.0188305  
  0.0309305   -0.106265     -0.0793438   -0.0193757     0.0576151    0.00951759   0.0973969    0.144264    0.0419157    0.0134134   -0.0969174   -0.0128645    0.114871    -0.0413986    0.11976      0.149313     0.0105467    0.00642233  -0.0776605    0.0620696    0.0144023  -0.0944893   -0.062933    0.0581913    0.145386    -0.158594   
  0.107853     0.0757401    -0.109682    -0.0806284     0.0675032   -0.0738337   -0.00129671  -0.0580344   0.0230246    0.0591159    0.0136117   -0.0612859   -0.0775867   -0.0386468   -0.0178934   -0.159948     0.0725809   -0.0276225    0.0430161    0.0503235   -0.21864     0.0338981   -0.19247     0.0515739    0.1549       0.0705015  
 -0.169474    -0.051973      0.023442     0.169051      0.169453     0.169561     0.143527     0.09837    -0.100722    -0.0693215   -0.0316316   -0.00454969   0.105461     0.117871    -0.0340126    0.0086753    0.0981743    0.0597516    0.0701964    0.0890093   -0.132142   -0.0658989    0.0850644   0.131168    -0.0145307   -0.225674   
 -0.12091     -0.0718133    -0.09887     -0.00210202    0.0495614    0.101435    -0.00818434   0.18086     0.226434     0.0636625    0.00559721   0.104273    -0.114735    -0.089225    -0.0118103    0.0311702   -0.154576    -0.500592    -0.0422855    0.0881362   -0.0360761   0.0361553   -0.0204301  -0.187396     0.0805754    0.0501161  
 -0.0551362    0.00380139    0.0264452    0.0364409     0.0267708    0.0746108    0.0613614   -0.116696    0.233695     0.0499538   -0.0280336   -0.163477    -0.09264      0.168579    -0.0186175    0.0151722   -0.165886     0.353209    -0.00913317   0.0669832   -0.0333519  -0.52952     -0.110046   -0.18786      0.0427184    0.0490121  
  0.013132    -0.0503907     0.155101    -0.0806698     0.051626    -0.177627    -0.0184205    0.136193    0.011716     0.0977604   -0.175056     0.0247901    0.262086     0.00214937   0.0222782    0.109856    -0.0473659    0.00595815   0.112168    -0.0369497    0.0130119  -0.0922904   -0.414003   -0.269504    -0.146097    -0.097799   
  0.133214     0.00941852    0.152368     0.102796      0.0010712    0.15394     -0.020085     0.127268    0.0123263    0.110526    -0.169754     0.078325    -0.25549      0.101259     0.0238594    0.17019     -0.0465443    0.136637    -0.176725    -0.0398094    0.0215265  -0.0617844    0.0139622  -0.0815896   -0.148539    -0.0190381  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.050834
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     14
â”‚     21
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.034285
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.048100
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     14
â”‚     20
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.029251
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.051092
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     14
â”‚     21
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.031580
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     20
â”‚     21
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.044222
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     14
â”‚     21
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.035353
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     21
â”‚     22
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.047223
kind diag, method kmeans
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     14
â”‚     20
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.028424
â”Œ Info: EM with 100000 data points 10 iterations avll -1.028424
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.668305e+05
      1       6.881109e+05      -1.787195e+05 |       32
      2       6.597228e+05      -2.838810e+04 |       32
      3       6.380458e+05      -2.167698e+04 |       32
      4       6.235381e+05      -1.450778e+04 |       32
      5       6.169246e+05      -6.613425e+03 |       32
      6       6.144864e+05      -2.438195e+03 |       32
      7       6.130649e+05      -1.421580e+03 |       32
      8       6.120418e+05      -1.023069e+03 |       32
      9       6.112584e+05      -7.834304e+02 |       32
     10       6.106359e+05      -6.224393e+02 |       32
     11       6.101055e+05      -5.304634e+02 |       32
     12       6.095691e+05      -5.363804e+02 |       32
     13       6.091257e+05      -4.434111e+02 |       32
     14       6.087022e+05      -4.234512e+02 |       32
     15       6.083888e+05      -3.133944e+02 |       32
     16       6.082539e+05      -1.348768e+02 |       31
     17       6.082093e+05      -4.467520e+01 |       32
     18       6.081790e+05      -3.028989e+01 |       32
     19       6.081526e+05      -2.639289e+01 |       29
     20       6.081270e+05      -2.558322e+01 |       31
     21       6.081016e+05      -2.540035e+01 |       31
     22       6.080715e+05      -3.014553e+01 |       30
     23       6.080085e+05      -6.294671e+01 |       30
     24       6.079110e+05      -9.755175e+01 |       32
     25       6.077508e+05      -1.601109e+02 |       32
     26       6.075570e+05      -1.938081e+02 |       32
     27       6.074008e+05      -1.562452e+02 |       32
     28       6.072400e+05      -1.607784e+02 |       32
     29       6.070801e+05      -1.599483e+02 |       32
     30       6.069252e+05      -1.548804e+02 |       32
     31       6.068254e+05      -9.977069e+01 |       32
     32       6.067684e+05      -5.696479e+01 |       31
     33       6.067297e+05      -3.875647e+01 |       30
     34       6.067043e+05      -2.537775e+01 |       31
     35       6.066871e+05      -1.724626e+01 |       29
     36       6.066805e+05      -6.533425e+00 |       29
     37       6.066770e+05      -3.568071e+00 |       25
     38       6.066749e+05      -2.042288e+00 |       21
     39       6.066733e+05      -1.597491e+00 |       14
     40       6.066728e+05      -4.870671e-01 |       11
     41       6.066725e+05      -3.493287e-01 |       11
     42       6.066722e+05      -3.383576e-01 |        8
     43       6.066719e+05      -2.289506e-01 |        5
     44       6.066718e+05      -9.569621e-02 |        5
     45       6.066717e+05      -1.019055e-01 |        4
     46       6.066717e+05      -4.826167e-02 |        2
     47       6.066716e+05      -6.817632e-02 |        3
     48       6.066715e+05      -6.729634e-02 |        2
     49       6.066715e+05      -6.400936e-02 |        2
     50       6.066715e+05      -2.165926e-02 |        0
K-means terminated without convergence after 50 iterations (objv = 606671.4557638583)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.325435
[ Info: iteration 2, average log likelihood -1.286378
[ Info: iteration 3, average log likelihood -1.250203
[ Info: iteration 4, average log likelihood -1.212294
[ Info: iteration 5, average log likelihood -1.163406
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.100764
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      6
â”‚     24
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.051111
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     21
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.050484
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.044400
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      9
â”‚     17
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.024801
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      6
â”‚     21
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.032765
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.041186
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      9
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.027268
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚     17
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.032037
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      6
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.043867
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     16
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.030371
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      9
â”‚     21
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.020259
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      6
â”‚     17
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.024987
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.035373
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.045897
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      6
â”‚      9
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.028080
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     16
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.030647
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚     17
â”‚     21
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.001659
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     2
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.054839
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      6
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.042457
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     21
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.023914
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      9
â”‚     17
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -0.999794
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.043712
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      6
â”‚     16
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.045157
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.034722
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚     17
â”‚     24
â”‚     25
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -0.999838
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.049925
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     3
â”‚     6
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.036641
[ Info: iteration 34, average log likelihood -1.041296
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚     16
â”‚     17
â”‚     21
â”‚     24
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -0.991095
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.076967
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      6
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.051776
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.028813
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚      9
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.027231
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      6
â”‚     16
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.042671
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     17
â”‚     21
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.034489
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      9
â”‚     24
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.020642
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.060915
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      6
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.041728
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      9
â”‚     17
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.017739
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     13
â”‚     24
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.024668
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.048384
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.050357
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      6
â”‚     16
â”‚     17
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.014196
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     21
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.030232
â”Œ Info: EM with 100000 data points 50 iterations avll -1.030232
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.0829555    -0.0611929   -0.0407399    0.0752566     0.0166941   -0.0620882   -0.132938   -0.0169682   0.0780966    0.036519    -0.165854     0.0423075    0.189316     0.0302121    0.236468    -0.00881383  -0.113415     0.0543045    0.156969   -0.00739149   0.0238953   -0.000303101   0.19145     0.0921126   -0.0752962    -0.0312227  
 -0.165914     -0.0531768    0.0173801    0.160824      0.158155     0.163993     0.138295    0.0948288  -0.112541    -0.069421    -0.0301223   -0.00687409   0.100163     0.114935    -0.0323069    0.00825654   0.0952306    0.0589414    0.0717771   0.0880237   -0.1289      -0.0645827     0.0813634   0.128451    -0.0158997    -0.215932   
 -0.0811995    -0.083754     0.145584     0.105452     -0.0473977    0.055223    -0.112184    0.0314489   0.0677295    0.148326     0.0141939   -0.180895     0.0506819   -0.034205     0.147271    -0.0487116    0.062746    -0.0751846   -0.102663   -0.0203852    0.014322    -0.113678      0.0140687  -0.0204692   -0.0513742     0.11412    
 -0.0397711     0.191792    -0.341171     0.0473576    -0.114993    -0.0581338   -0.0882334  -0.0731782  -0.0381445    0.0104295    0.0896533   -0.206417     0.114832    -0.230492     0.0282327    0.0568258   -0.0363021   -0.0410502    0.0815782  -0.0746625    0.0753666    0.111187     -0.0949446   0.205878     0.0566116     0.0621431  
 -0.0803829    -0.0320154   -0.0295159    0.0203071     0.0373107    0.0867421    0.0321948   0.0206746   0.230901     0.0560049   -0.0130217   -0.0423138   -0.102301     0.0485997   -0.0164433    0.0227842   -0.160291    -0.0348142   -0.0246809   0.0763044   -0.0325298   -0.272597     -0.0697414  -0.187776     0.0601236     0.0497315  
 -0.0188472    -0.133066     0.132627     0.0406148     0.0817013   -0.0851593   -0.0800077  -0.0353712   0.204797    -0.014309    -0.247505     0.00714123   0.0906912    0.128265     0.0826308    0.246822     0.215065    -0.110549     0.185758   -0.0718115    0.289573     0.185072     -0.0324412  -0.0429937    0.13287      -0.346673   
 -0.0460824    -0.105789    -0.11088      0.075929     -0.0673928   -0.0867538    0.172743    0.0648065   0.161213     0.119726    -0.107864    -0.0512665    0.012015    -0.0992586    0.0227506    0.178428    -0.0541254    0.0380661   -0.216728    0.120387    -0.20611      0.141344     -0.0624711  -0.0874      -0.0641984     0.116485   
 -0.094279      0.137454     0.0631973    0.207174     -0.0980893   -0.27103      0.132573   -0.0848133  -0.0803341   -0.0506167   -0.0597249    0.181956    -0.0646116   -0.103344     0.0874286   -0.0765069   -0.00196334   0.0346972    0.162347    0.114933     0.0109213   -0.0566729    -0.0440288  -0.045994     0.110594     -0.0787594  
  0.0679129    -0.0162934    0.155285     0.0105917     0.0250951   -0.0147975   -0.0216474   0.135855    0.0107082    0.105015    -0.17272      0.0531701    0.00516114   0.0489877    0.0199418    0.140736    -0.046755     0.0694322   -0.0328632  -0.0375671    0.0172587   -0.0752827    -0.20368    -0.181546    -0.147231     -0.0613396  
 -0.0563571     0.144931    -0.0330838    0.102533     -0.0437795    0.0447755   -0.0380067   0.128815   -0.00392377  -0.0770191    0.0121495    0.0110491    0.0458987    0.036755     0.0162602    0.17185     -0.0148634   -0.0182198    0.0144153  -0.0980159   -0.121647     0.0477688    -0.060326   -0.0250033   -0.0333562     0.00873336 
  0.133853     -0.143071     0.00512722   0.00078962   -0.160162     0.158403     0.06017    -0.0656863   0.0652166   -0.0107015   -0.0679678   -0.0509339    0.0434669    0.107638     0.11224     -0.131539     0.171883    -0.25124     -0.105634    0.106704     0.0325254    0.0471168    -0.0353546  -0.104274    -0.0693984     0.0217908  
 -0.0905338     0.0974094    0.00324936   0.132745     -0.0355876    0.20193     -0.0140205  -0.129288   -0.127464     0.0128308    0.173803    -0.158961     0.101725     0.177066    -0.0932818   -0.100097    -0.00755421   0.0633556    0.0239707   0.17999     -0.165192     0.0755177    -0.0398383  -0.030795     0.0305409     0.000461233
  0.0928566     0.0734365    0.158188     0.014591      0.0317671   -0.0198611    0.114895   -0.161135   -0.164154    -0.0905499    0.123753    -0.0312115    0.0554618   -0.0462251    0.0317511   -0.0469538    0.0496863    0.00710217   0.0988633   0.0612053   -0.0273771    0.0618799    -0.1971      0.096516     0.0719008    -0.0397509  
 -0.0916675    -0.132964    -0.0276044    0.0730424    -0.00497439   0.193807    -0.0616785   0.148836    0.0178911   -0.101864     0.106406    -0.131612     0.00601748  -0.144672    -0.00825081  -0.0517326   -0.0845399   -0.03038      0.0536499  -0.12593     -0.0139202    0.0671251    -0.0458756   0.0269734    0.0415367    -0.0174419  
  0.0946353     0.0214471    0.0375696    0.0405782     0.00771751   0.0520214   -0.0427519   0.0208495  -0.0354171    0.0102312   -0.0573227   -0.0180196    0.03941     -0.00616572  -0.00565715   0.0658364   -0.0593038   -0.110585    -0.0372261   0.049067    -0.0364563    0.12193       0.0280776  -0.0625378    0.106332     -0.0777795  
 -0.288555     -0.11363      0.0147894    0.0256558     0.0112515    0.041649    -0.0695153   0.167338   -0.105065     0.0234563   -0.0236399   -0.101006     0.00376688   0.0577973    0.00406785   0.179455     0.0884508   -0.0429701    0.376366    0.0948633   -0.124544     0.013759     -0.020816   -0.119668    -0.22385      -0.135601   
  0.000681777  -0.0846937    0.170649     0.0122947    -0.0351504    0.083748    -0.0434143  -0.0944743  -0.251084     0.0563794    0.0569785   -0.230227    -0.0663525   -0.00447847  -0.0105272    0.159367     0.0465044    0.0119011   -0.208232    0.0146409   -0.184055    -0.120721      0.0640067  -0.0907207    0.0471041     0.0533952  
 -0.00302976    0.0749299    0.0136014    0.0167864    -0.0581996    0.0847078   -0.246126   -0.0468551   0.101468    -0.0854743    0.183476    -0.00124365  -0.0913801    0.204194     0.0385923   -0.124544     0.0999469   -0.0658161    0.074815   -0.0110486   -0.179569    -0.0302586     0.16646    -0.113945     0.048109     -0.0567396  
  0.0758224    -0.0183775   -0.0924542   -0.041221      0.0451136   -0.0235475    0.0416654   0.0302445   0.0032931    0.0437224   -0.0252338   -0.068902     0.0112237   -0.0424758    0.040777     0.0132184    0.0431466   -0.0103323   -0.0195965   0.0515672   -0.115317    -0.0392344    -0.108072    0.0373865    0.150626     -0.0345033  
 -0.0278142    -0.0898713   -0.0838154   -0.044759     -0.0701859   -0.0167024    0.190475   -0.140058   -0.0209647   -0.0888646   -0.0504218   -0.0292143   -0.184454    -0.128335     0.0355698   -0.0441829    0.0453147   -0.0343199    0.183606   -0.0364697   -0.207953     0.151493     -0.0556276   0.133286    -0.0733991    -0.00770462 
  0.122953      0.152743    -0.0272431   -0.15072       0.225856    -0.00529383   0.0130768   0.0619242  -0.0321489   -0.0493739    0.00348643   0.0568775   -0.0760606    0.0508312    0.145825     0.0510602    0.0133638    0.200618     0.0498688   0.0720458   -0.0598086   -0.00989279    0.0594786  -0.275252     0.0485746    -0.131237   
 -0.158306      0.0792793   -0.0791221    0.1304       -0.127853     0.132076     0.0745869  -0.229714   -0.0607198   -0.101815     0.136528     0.0219079    0.031367     0.0679768   -0.0334017   -0.315812     0.20653     -0.0464722   -0.0217804  -0.0547348    0.227005    -0.0531501    -0.0717759  -0.00626318   0.000414589   0.0363388  
  0.0412967    -0.141607     0.0708602   -0.209234      0.0841154   -0.0253973    0.0386207   0.0386839   0.0913739    0.05986      0.103191    -0.0252507   -0.0130856    0.0767338    0.0113628   -0.0562135   -0.122922    -0.113308    -0.0485048   0.132726    -0.0785179    0.162659     -0.126642   -0.106884     0.0365574    -0.132483   
  0.0421857    -0.0308805    0.1098       0.13927       0.0367721    0.0163151    0.0939233  -0.221898   -0.160182    -0.0966811    0.0375044    0.0160881    0.0447414   -0.0148636    0.0916091   -0.162787     0.170212    -0.00368698   0.14911     0.0852568   -0.0573956    0.105614     -0.16628     0.0653351    0.0643586    -0.0509045  
  0.12319       0.100068    -0.0841765   -0.0337966     0.0607647    0.0189619   -0.0894146   0.0371466   0.261837    -0.329864     0.0421725    0.0516353   -0.113129     0.0795767    0.0512005   -0.0359755   -0.0180964   -0.132476    -0.153654    0.253846    -0.120375    -0.183048     -0.0726918  -0.121219    -0.051355     -0.0934643  
  0.210256     -0.203194     0.0552614    0.10583      -0.135219    -0.117045     0.165122   -0.174225   -0.0122703   -0.00799011  -0.180691    -0.0682909    0.0738163   -0.0586946    0.0587085   -0.04559      0.194308     0.176762     0.181819    0.00289446  -0.176541     0.0772394    -0.020911    0.0727151   -0.132464     -0.119586   
 -0.0976776     0.0859933    0.219322    -0.0767408    -0.103897    -0.00890733  -0.128263   -0.0486624  -0.149849    -0.153398     0.101556     0.111848    -0.00134176  -0.0420896   -0.0292992   -0.0330038    0.0431127    0.0053545    0.0758228   0.0924619    0.0786489    0.1527       -0.0311748   0.0653703    0.0282117    -0.10972    
 -0.0969965    -0.00585008   0.107572    -0.000135726   0.00922334   0.0525147   -0.196619   -0.184922    0.119315    -0.0927869    0.025        0.159025     0.0222436    0.115031     0.0857271    0.0837553   -0.0386913    0.178914     0.12012    -0.0814762    0.138302    -0.106127      0.0667815  -0.0502852    0.0384101    -0.000907603
 -0.10765       0.0593573    0.0581423    0.119743      0.0841063   -0.0955758    0.191486   -0.19806    -0.131415    -0.125271     0.0194382   -0.2314       0.0252003   -0.0534065   -0.0420136   -0.253738    -0.111322    -0.197385     0.0806399   0.227563    -0.0681049    0.0723427     0.126153   -0.0288551   -0.0220308     0.080359   
  0.0548795    -0.00590478   0.0148562   -0.096325     -0.0788726    0.0230567   -0.164457   -0.0203782  -0.0810962   -0.0214135   -0.119214     0.184542    -0.06982      0.0855173   -0.116987     0.0726627   -0.0783974   -0.0683153   -0.0364351   0.16805     -0.0179149   -0.0412094    -0.160499    0.16555     -0.0454578     0.0834099  
 -0.155883     -0.0601166   -0.0423512   -0.0565496    -0.0665402    0.167325     0.139707   -0.0951942  -0.050898    -0.0773181    0.126969    -0.0561194   -0.0388173   -0.140754    -0.109547    -0.0167301    0.00966514   0.185735    -0.176713    0.160271    -0.0155399   -0.0479895     0.046227   -0.095092    -0.142815     -0.0669858  
 -0.305502     -0.0709196    0.0635461   -0.132445     -0.105789    -0.158182     0.0754107  -0.0884596  -0.0925032   -0.177096     0.0581921   -0.0600338   -0.0630067    0.0351973   -0.0801135   -0.033761     0.155027    -0.214003     0.115713   -0.00966198   0.00818382   0.058414     -0.267435    0.00510588   0.0110853     0.1789     [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚      9
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.037574
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      6
â”‚      9
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.000954
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      9
â”‚     13
â”‚      â‹®
â”‚     25
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.971917
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      6
â”‚      9
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.031509
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      9
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.004384
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      6
â”‚      9
â”‚      â‹®
â”‚     25
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.967143
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      9
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.036356
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      6
â”‚      9
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.001373
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      9
â”‚     13
â”‚      â‹®
â”‚     25
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.971458
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      6
â”‚      9
â”‚     13
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.030828
â”Œ Info: EM with 100000 data points 10 iterations avll -1.030828
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.0417455    0.00086488   0.0123203   -0.12181     -0.10528     -0.0421187  -0.083026      0.0329129    -0.0641938    -0.0243147    0.0144477    0.0294807   -0.00297399  -0.223947    -0.0739827   -0.0507747   -0.175927    0.149514     0.0380248     0.0122488    0.135772    -0.170519     -0.0905397    0.191949    -0.147848     0.207928   
  0.0335056    0.0427342   -0.113219    -0.0163822    0.115583     0.184811   -0.0255638     0.0457593    -0.0655521    -0.0213785    0.0340661   -0.144194     0.00542346   0.00714036  -0.0730277   -0.0239171    0.10728     0.0349405    0.134155     -0.190214     0.0531432    0.0885142    -0.0439335    0.0710474    0.0777513   -0.0107845  
 -0.0137315    0.162716    -0.0885309    0.0412066   -0.0114523   -0.0844936   0.00209946   -0.111629     -0.0981134    -0.0289185    0.0582332    0.0465483    0.0844987   -0.0293727    0.165614    -0.0138582   -0.117613   -0.0418003    0.108696     -0.0757075   -0.0785025   -0.123691      0.174187     0.00116626   0.206581    -0.057484   
  0.150073     0.0429811   -0.0718611    0.151758     0.108438    -0.063622    0.0827896    -0.115636     -0.00365124   -0.115435     0.0533817   -0.142303    -0.0670763    0.0220729   -0.122272    -0.0209043    0.110514   -0.0716046    0.0375004     0.195235    -0.080698     0.143896     -0.0347809   -0.0571257    0.0392352    0.00594425 
  0.0442898   -0.0226653    0.186407     0.00494806  -0.14633     -0.0138528   0.0216713     0.0753119    -0.000299626  -0.023505    -0.124412    -0.0163731   -0.177037    -0.0814171   -0.050329    -0.0275252    0.0453154  -0.0522466    0.0903453    -0.0450537    0.015159     0.0103424     0.054933    -0.0380442   -0.0939259    0.229513   
  0.00613837  -0.106612     0.0103518   -0.0316902    0.0989747    0.0561987  -0.0437966    -0.0116504    -0.0705366     0.178398    -0.0999233    0.10139     -0.0478786   -0.132169    -0.0469884   -0.00705098  -0.0933488  -0.106379     0.100481      0.0177356    0.205332    -0.000948943   0.11655     -0.101759    -0.0828358   -0.0889708  
 -0.0464056   -0.0143925   -0.0175857    0.133489     0.0301451    0.0863884   0.0491052    -0.00795218   -0.0455435    -0.0832509   -0.0477753    0.011914    -0.119931     0.132437    -0.113608    -0.154861    -0.050556    0.0190522   -0.0827108     0.109836     0.0615126    0.0489717     0.0342642    0.0605948    0.102145     0.0970465  
  0.117328    -0.0762785   -0.084799    -0.0434558    0.040256    -0.0611081   0.0175024     0.0266535     0.0292806     0.0499029    0.0412369    0.0513059   -0.0608653    0.0369812    0.0281464   -0.0459442    0.0643981  -0.00114279   0.0121113     0.0505007   -0.0489235   -0.050572     -0.0280613    0.0135569    0.0161945   -0.0364239  
 -0.0325646   -0.0693679    0.0126712    0.123409    -0.0387604   -0.111911   -0.0694882    -0.1116       -0.0259105    -0.0535006   -0.00631657   0.00212181  -0.106651    -0.00136401  -0.140677     0.0485937    0.0623904  -0.0712085    0.0214196     0.0223319    0.0745605    0.136766      0.0676266    0.0960878    0.166952     0.0246867  
  0.0446852   -0.0202127    0.0716049    0.0673989    0.0457391    0.0347752   0.0716717     0.0841894     0.0636313     0.00718407  -0.0587234   -0.0583433   -0.08365     -0.260066    -0.0859685   -0.00257522   0.04876     0.0174688    0.0851876     0.113685    -0.124846     0.13775      -0.100366    -0.0229109   -0.0673417    0.0897575  
 -0.0515565    0.0344162   -0.0265092   -0.0339374    0.122806    -0.116435   -0.00475911    0.161052     -0.0429802     0.0797668    0.163491     0.0517869   -0.173325     0.0139764   -0.00301186  -0.175543    -0.0216471   0.176807     0.154439     -0.0692605   -0.0357196   -0.121299      0.0576212   -0.127748    -0.31048      0.00634509 
  0.0890764   -0.097781     0.0623978   -0.00947067   0.148454     0.151015    0.0212051     0.0956459     0.00631667   -0.10418     -0.0379562    0.0541792    0.0504801    0.0326239    0.0758425    0.0360891   -0.121205   -0.0261693    0.0308401     0.0767428   -0.00342038   0.0451729     0.0358342    0.183659    -0.11693     -0.0543496  
 -0.0809612    0.101899     0.10155      0.114004    -0.052107    -0.0864557  -0.0813345     0.0144052    -0.0985138    -0.0584368    0.0512018   -0.0580662   -0.0102404   -0.0879781    0.0388255   -0.048021     0.252327    0.104553     0.0859561    -0.0431212   -0.0178087   -0.0405342     0.202172    -0.0669317    0.139837     0.0657982  
 -0.0538908   -0.174024    -0.104778    -0.0844465   -0.00692957  -0.072065    0.0511898    -0.0203078    -0.0953695     0.00347994  -0.0623165    0.0552875   -0.0833249   -0.114554     0.0323079    0.0474179    0.0542228   0.217687    -0.0160467     0.200632     0.0225264    0.0733158    -0.0205879    0.165128    -0.0610105   -0.0513746  
  0.206448     0.133593     0.00412154  -0.105527    -0.0262328   -0.173473   -0.0541117     0.0320125    -0.0595653     0.0472142   -0.0650511    0.132618     0.0327912   -0.0186528   -0.1266       0.0565917    0.0467544  -0.0646115    0.156066     -0.142497     0.0779302   -0.041523     -0.0687019    0.0292003    0.0492935   -0.0137819  
 -0.0756742    0.0464285    0.12616     -0.0092846   -0.00484122  -0.097509    0.0671514     0.373498      0.162733     -0.0592341    0.0818921    0.0165236   -0.010742     0.0168565    0.0776408    0.100352     0.076098    0.0194748   -0.132101      0.145864     0.0792729    0.10686       0.0106049   -0.0440735    0.0420352    0.131412   
  0.0407403   -0.0740301    0.0616096    0.0358909    0.082228     0.0833398   0.111386     -0.0675746    -0.085032     -0.0200347    0.078733    -0.0497202    0.176628     8.47965e-5  -0.0246295   -0.005833    -0.0356844   0.257065    -0.119889      0.0609931    0.0461189   -0.0615625    -0.205232     0.0825333    0.138666    -0.0537344  
  0.17268     -0.182557    -0.0504498    0.0703087   -0.0735962    0.0523188  -0.000411383  -0.000444589  -0.158492     -0.0847309   -0.00388298  -0.12211      0.0155226   -0.0485662    0.119674     0.0989864   -0.034479   -0.136961    -0.0295068    -0.14755     -0.0305143   -0.0361754    -0.0554392   -0.0358481    0.0690196    0.00119975 
  0.142063    -0.00127317   0.1361       0.0223908    0.0321468   -0.0332458  -0.0704268     0.0839166    -0.128512     -0.0220704    0.177895    -0.0503318   -0.0423367    0.0918597   -0.0017494   -0.0460085   -0.109026    0.132753     0.0468468     0.0130455   -0.192909     0.0889791    -0.0495815   -0.0837012    0.139631    -0.0574539  
 -0.00685618   0.171777     0.0442378   -0.00286914   0.177802    -0.0614859   0.0473069     0.0654479    -0.0926452     0.0933999    0.0578756   -0.0219036    0.111792    -0.157215     0.0564712   -0.0852613    0.0325727   0.110109    -0.201241     -0.020037    -0.0983349   -0.111964      0.0480703   -0.029373    -0.0189127   -0.0811727  
  0.0276557   -0.00900289   0.0640994    0.0109071   -0.0250156   -0.0685356  -0.0625317     0.0406808    -0.0509722     0.15804     -0.0870138   -0.17536     -0.125398     0.159068    -0.0462374    0.161269    -0.0418351   0.0662378   -0.0012216     0.152757    -0.0902639   -0.099548      0.00996092   0.0264176   -0.0802294   -0.0105036  
  0.160144    -0.0266383    0.143755     0.0810781   -0.0492594   -0.0346052   0.180885     -0.169602      0.182914     -0.0125311   -0.0811657   -0.113729     0.123516     0.105037     0.018691    -0.0788196    0.106999   -0.0097551   -0.0201923     0.0016552   -0.0367962    0.0490806    -0.0293363    0.0461465    0.00213535  -0.0924513  
  0.229283     0.00465542   0.13212      0.132148    -0.0246749    0.0388517   0.131659     -0.0995379    -0.0688763     0.18631      0.0772512    0.0610136    0.00979031   0.0410883   -0.115286     0.16654      0.118483    0.0273741    0.0215408     0.0960563    0.0664142   -0.156932     -0.109073    -0.0552971   -0.0582769    0.0892264  
 -0.287944     0.123327    -0.111955     0.109262    -0.0494955   -0.161478   -0.0715494     0.0910148     0.130683      0.215427    -0.0362208    0.0259177    0.132148     0.26069      0.0457542   -0.149676    -0.0823685   0.0297552   -0.0528214    -0.00327412  -0.164319     0.113794      0.0198133    0.161648    -0.107659    -0.0158987  
  0.118519     0.0614768    0.0492021   -0.00929107  -0.13484      0.0756292   0.0282459     0.03054       0.0207903    -0.0488804   -0.00579823   0.16086     -0.0389856    0.00551601   0.0757118    0.0391026   -0.0453247   0.0291747    0.000711731   0.0393317    0.0165732   -0.152473     -0.0175392   -0.0457841   -0.0238339   -0.236215   
 -0.13649     -0.0903876    0.0937872    0.0204347    0.063523     0.0998586   0.227504     -0.0446046    -0.229179      0.038146     0.0842945   -0.0258796   -0.0639462   -0.181761    -0.204505     0.0708673   -0.0467214  -0.113182     0.0350746    -0.108619    -0.00238679   0.0788152    -0.0755765    0.075254     0.0120294    0.0250968  
  0.00349735  -0.0850325   -0.0189251    0.0550114   -0.0355324   -0.0797289  -0.132881      0.0196061     0.0268262    -0.0978907   -0.078052    -0.1362      -0.128256    -0.130488     0.0606334    0.202814    -0.0260316   0.0535981   -0.0643455    -0.250323     0.015141    -0.244697      0.0686708   -0.182973    -0.0117703   -0.0725901  
  0.0205583   -0.110642    -0.0856242   -0.0683751   -0.169964    -0.149834   -0.232547     -0.0416346     0.0330868     0.172295    -0.108672    -0.0210347    0.144481     0.0564442   -0.0845529    0.115497     0.125845    0.038377     0.301785      0.0623531   -0.00654987  -0.0367616    -0.0427031   -0.0836225    0.125146    -0.0177964  
 -0.179998     0.0476821   -0.0862165   -0.0848366   -0.0649288    0.0328962   0.14436       0.0495589     0.012975     -0.0284015   -0.0333049    0.0151039    0.224547     0.110239    -0.057902    -0.154169     0.107398    0.254262     0.0246938    -0.0570036    0.236921    -0.0148367     0.0706561    0.0108576   -0.0789061   -0.000368322
  0.0462476   -0.0404989   -0.0716896    0.170297    -0.0132461   -0.0116873   0.184127     -0.130429      0.0218055     0.0866773   -0.0602513   -0.0569556   -0.14651     -0.0380017    0.039135    -0.0430345   -0.0559447  -0.0908815    0.179329     -0.0332813   -0.166721     0.181541     -0.0492319   -0.035189     0.0446121   -0.0597947  
 -0.067261     0.0670317   -0.0977636    0.049795    -0.0260698   -0.221842    0.198709     -0.13243      -0.0789315    -0.104625     0.0555698    0.0181689   -0.0867583    0.00857793  -0.0719407    0.120347     0.0783701  -0.1048      -0.0414449    -0.0217791   -0.0504642    0.0227888     0.028666     0.0127685   -0.0982537   -0.0472273  
 -0.130051     0.0320681   -0.0285314    0.0582793   -0.154297     0.0362449  -0.0635107     0.142038      0.186982      0.131644    -0.0407831   -0.0758304    0.163261    -0.121924     0.0754919    0.0349475    0.0263533  -0.0176286   -0.181607     -0.0357358    0.0904722   -0.0925312     0.0676632    0.0523721    0.035143     0.126573   kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.423321790345662
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423342
[ Info: iteration 2, average log likelihood -1.423275
[ Info: iteration 3, average log likelihood -1.423219
[ Info: iteration 4, average log likelihood -1.423141
[ Info: iteration 5, average log likelihood -1.423019
[ Info: iteration 6, average log likelihood -1.422798
[ Info: iteration 7, average log likelihood -1.422360
[ Info: iteration 8, average log likelihood -1.421543
[ Info: iteration 9, average log likelihood -1.420352
[ Info: iteration 10, average log likelihood -1.419187
[ Info: iteration 11, average log likelihood -1.418447
[ Info: iteration 12, average log likelihood -1.418104
[ Info: iteration 13, average log likelihood -1.417965
[ Info: iteration 14, average log likelihood -1.417910
[ Info: iteration 15, average log likelihood -1.417888
[ Info: iteration 16, average log likelihood -1.417878
[ Info: iteration 17, average log likelihood -1.417875
[ Info: iteration 18, average log likelihood -1.417873
[ Info: iteration 19, average log likelihood -1.417872
[ Info: iteration 20, average log likelihood -1.417872
[ Info: iteration 21, average log likelihood -1.417872
[ Info: iteration 22, average log likelihood -1.417872
[ Info: iteration 23, average log likelihood -1.417871
[ Info: iteration 24, average log likelihood -1.417871
[ Info: iteration 25, average log likelihood -1.417871
[ Info: iteration 26, average log likelihood -1.417871
[ Info: iteration 27, average log likelihood -1.417871
[ Info: iteration 28, average log likelihood -1.417871
[ Info: iteration 29, average log likelihood -1.417871
[ Info: iteration 30, average log likelihood -1.417871
[ Info: iteration 31, average log likelihood -1.417871
[ Info: iteration 32, average log likelihood -1.417871
[ Info: iteration 33, average log likelihood -1.417871
[ Info: iteration 34, average log likelihood -1.417871
[ Info: iteration 35, average log likelihood -1.417871
[ Info: iteration 36, average log likelihood -1.417871
[ Info: iteration 37, average log likelihood -1.417871
[ Info: iteration 38, average log likelihood -1.417871
[ Info: iteration 39, average log likelihood -1.417871
[ Info: iteration 40, average log likelihood -1.417871
[ Info: iteration 41, average log likelihood -1.417871
[ Info: iteration 42, average log likelihood -1.417871
[ Info: iteration 43, average log likelihood -1.417871
[ Info: iteration 44, average log likelihood -1.417871
[ Info: iteration 45, average log likelihood -1.417871
[ Info: iteration 46, average log likelihood -1.417871
[ Info: iteration 47, average log likelihood -1.417871
[ Info: iteration 48, average log likelihood -1.417871
[ Info: iteration 49, average log likelihood -1.417871
[ Info: iteration 50, average log likelihood -1.417871
â”Œ Info: EM with 100000 data points 50 iterations avll -1.417871
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4233421731951328
â”‚     -1.4232752975125669
â”‚      â‹®                 
â””     -1.4178707245190683
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417891
[ Info: iteration 2, average log likelihood -1.417822
[ Info: iteration 3, average log likelihood -1.417766
[ Info: iteration 4, average log likelihood -1.417697
[ Info: iteration 5, average log likelihood -1.417613
[ Info: iteration 6, average log likelihood -1.417517
[ Info: iteration 7, average log likelihood -1.417418
[ Info: iteration 8, average log likelihood -1.417328
[ Info: iteration 9, average log likelihood -1.417254
[ Info: iteration 10, average log likelihood -1.417197
[ Info: iteration 11, average log likelihood -1.417155
[ Info: iteration 12, average log likelihood -1.417124
[ Info: iteration 13, average log likelihood -1.417099
[ Info: iteration 14, average log likelihood -1.417079
[ Info: iteration 15, average log likelihood -1.417061
[ Info: iteration 16, average log likelihood -1.417046
[ Info: iteration 17, average log likelihood -1.417031
[ Info: iteration 18, average log likelihood -1.417017
[ Info: iteration 19, average log likelihood -1.417003
[ Info: iteration 20, average log likelihood -1.416989
[ Info: iteration 21, average log likelihood -1.416974
[ Info: iteration 22, average log likelihood -1.416960
[ Info: iteration 23, average log likelihood -1.416945
[ Info: iteration 24, average log likelihood -1.416930
[ Info: iteration 25, average log likelihood -1.416915
[ Info: iteration 26, average log likelihood -1.416899
[ Info: iteration 27, average log likelihood -1.416883
[ Info: iteration 28, average log likelihood -1.416867
[ Info: iteration 29, average log likelihood -1.416851
[ Info: iteration 30, average log likelihood -1.416835
[ Info: iteration 31, average log likelihood -1.416819
[ Info: iteration 32, average log likelihood -1.416804
[ Info: iteration 33, average log likelihood -1.416791
[ Info: iteration 34, average log likelihood -1.416778
[ Info: iteration 35, average log likelihood -1.416766
[ Info: iteration 36, average log likelihood -1.416755
[ Info: iteration 37, average log likelihood -1.416745
[ Info: iteration 38, average log likelihood -1.416736
[ Info: iteration 39, average log likelihood -1.416729
[ Info: iteration 40, average log likelihood -1.416722
[ Info: iteration 41, average log likelihood -1.416716
[ Info: iteration 42, average log likelihood -1.416712
[ Info: iteration 43, average log likelihood -1.416707
[ Info: iteration 44, average log likelihood -1.416704
[ Info: iteration 45, average log likelihood -1.416700
[ Info: iteration 46, average log likelihood -1.416698
[ Info: iteration 47, average log likelihood -1.416695
[ Info: iteration 48, average log likelihood -1.416693
[ Info: iteration 49, average log likelihood -1.416692
[ Info: iteration 50, average log likelihood -1.416690
â”Œ Info: EM with 100000 data points 50 iterations avll -1.416690
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4178908038727227
â”‚     -1.4178221781472378
â”‚      â‹®                 
â””     -1.4166900697186873
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416700
[ Info: iteration 2, average log likelihood -1.416646
[ Info: iteration 3, average log likelihood -1.416601
[ Info: iteration 4, average log likelihood -1.416551
[ Info: iteration 5, average log likelihood -1.416491
[ Info: iteration 6, average log likelihood -1.416421
[ Info: iteration 7, average log likelihood -1.416340
[ Info: iteration 8, average log likelihood -1.416252
[ Info: iteration 9, average log likelihood -1.416162
[ Info: iteration 10, average log likelihood -1.416074
[ Info: iteration 11, average log likelihood -1.415995
[ Info: iteration 12, average log likelihood -1.415925
[ Info: iteration 13, average log likelihood -1.415866
[ Info: iteration 14, average log likelihood -1.415817
[ Info: iteration 15, average log likelihood -1.415778
[ Info: iteration 16, average log likelihood -1.415745
[ Info: iteration 17, average log likelihood -1.415718
[ Info: iteration 18, average log likelihood -1.415696
[ Info: iteration 19, average log likelihood -1.415677
[ Info: iteration 20, average log likelihood -1.415661
[ Info: iteration 21, average log likelihood -1.415646
[ Info: iteration 22, average log likelihood -1.415633
[ Info: iteration 23, average log likelihood -1.415620
[ Info: iteration 24, average log likelihood -1.415609
[ Info: iteration 25, average log likelihood -1.415598
[ Info: iteration 26, average log likelihood -1.415587
[ Info: iteration 27, average log likelihood -1.415577
[ Info: iteration 28, average log likelihood -1.415566
[ Info: iteration 29, average log likelihood -1.415556
[ Info: iteration 30, average log likelihood -1.415546
[ Info: iteration 31, average log likelihood -1.415537
[ Info: iteration 32, average log likelihood -1.415527
[ Info: iteration 33, average log likelihood -1.415517
[ Info: iteration 34, average log likelihood -1.415508
[ Info: iteration 35, average log likelihood -1.415498
[ Info: iteration 36, average log likelihood -1.415489
[ Info: iteration 37, average log likelihood -1.415480
[ Info: iteration 38, average log likelihood -1.415471
[ Info: iteration 39, average log likelihood -1.415462
[ Info: iteration 40, average log likelihood -1.415453
[ Info: iteration 41, average log likelihood -1.415444
[ Info: iteration 42, average log likelihood -1.415435
[ Info: iteration 43, average log likelihood -1.415427
[ Info: iteration 44, average log likelihood -1.415419
[ Info: iteration 45, average log likelihood -1.415410
[ Info: iteration 46, average log likelihood -1.415402
[ Info: iteration 47, average log likelihood -1.415394
[ Info: iteration 48, average log likelihood -1.415386
[ Info: iteration 49, average log likelihood -1.415378
[ Info: iteration 50, average log likelihood -1.415371
â”Œ Info: EM with 100000 data points 50 iterations avll -1.415371
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.416700172073793 
â”‚     -1.4166456651484856
â”‚      â‹®                 
â””     -1.4153705218142374
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415374
[ Info: iteration 2, average log likelihood -1.415319
[ Info: iteration 3, average log likelihood -1.415270
[ Info: iteration 4, average log likelihood -1.415216
[ Info: iteration 5, average log likelihood -1.415152
[ Info: iteration 6, average log likelihood -1.415076
[ Info: iteration 7, average log likelihood -1.414988
[ Info: iteration 8, average log likelihood -1.414890
[ Info: iteration 9, average log likelihood -1.414786
[ Info: iteration 10, average log likelihood -1.414681
[ Info: iteration 11, average log likelihood -1.414580
[ Info: iteration 12, average log likelihood -1.414484
[ Info: iteration 13, average log likelihood -1.414394
[ Info: iteration 14, average log likelihood -1.414310
[ Info: iteration 15, average log likelihood -1.414234
[ Info: iteration 16, average log likelihood -1.414164
[ Info: iteration 17, average log likelihood -1.414101
[ Info: iteration 18, average log likelihood -1.414045
[ Info: iteration 19, average log likelihood -1.413997
[ Info: iteration 20, average log likelihood -1.413955
[ Info: iteration 21, average log likelihood -1.413918
[ Info: iteration 22, average log likelihood -1.413886
[ Info: iteration 23, average log likelihood -1.413858
[ Info: iteration 24, average log likelihood -1.413832
[ Info: iteration 25, average log likelihood -1.413809
[ Info: iteration 26, average log likelihood -1.413788
[ Info: iteration 27, average log likelihood -1.413768
[ Info: iteration 28, average log likelihood -1.413749
[ Info: iteration 29, average log likelihood -1.413731
[ Info: iteration 30, average log likelihood -1.413714
[ Info: iteration 31, average log likelihood -1.413697
[ Info: iteration 32, average log likelihood -1.413681
[ Info: iteration 33, average log likelihood -1.413665
[ Info: iteration 34, average log likelihood -1.413650
[ Info: iteration 35, average log likelihood -1.413635
[ Info: iteration 36, average log likelihood -1.413621
[ Info: iteration 37, average log likelihood -1.413606
[ Info: iteration 38, average log likelihood -1.413592
[ Info: iteration 39, average log likelihood -1.413579
[ Info: iteration 40, average log likelihood -1.413565
[ Info: iteration 41, average log likelihood -1.413552
[ Info: iteration 42, average log likelihood -1.413540
[ Info: iteration 43, average log likelihood -1.413527
[ Info: iteration 44, average log likelihood -1.413515
[ Info: iteration 45, average log likelihood -1.413503
[ Info: iteration 46, average log likelihood -1.413492
[ Info: iteration 47, average log likelihood -1.413481
[ Info: iteration 48, average log likelihood -1.413471
[ Info: iteration 49, average log likelihood -1.413461
[ Info: iteration 50, average log likelihood -1.413451
â”Œ Info: EM with 100000 data points 50 iterations avll -1.413451
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4153738626078678
â”‚     -1.4153185755999207
â”‚      â‹®                 
â””     -1.4134508322127723
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413450
[ Info: iteration 2, average log likelihood -1.413386
[ Info: iteration 3, average log likelihood -1.413326
[ Info: iteration 4, average log likelihood -1.413256
[ Info: iteration 5, average log likelihood -1.413171
[ Info: iteration 6, average log likelihood -1.413066
[ Info: iteration 7, average log likelihood -1.412942
[ Info: iteration 8, average log likelihood -1.412802
[ Info: iteration 9, average log likelihood -1.412655
[ Info: iteration 10, average log likelihood -1.412507
[ Info: iteration 11, average log likelihood -1.412366
[ Info: iteration 12, average log likelihood -1.412235
[ Info: iteration 13, average log likelihood -1.412118
[ Info: iteration 14, average log likelihood -1.412014
[ Info: iteration 15, average log likelihood -1.411922
[ Info: iteration 16, average log likelihood -1.411840
[ Info: iteration 17, average log likelihood -1.411768
[ Info: iteration 18, average log likelihood -1.411702
[ Info: iteration 19, average log likelihood -1.411643
[ Info: iteration 20, average log likelihood -1.411588
[ Info: iteration 21, average log likelihood -1.411538
[ Info: iteration 22, average log likelihood -1.411492
[ Info: iteration 23, average log likelihood -1.411449
[ Info: iteration 24, average log likelihood -1.411409
[ Info: iteration 25, average log likelihood -1.411371
[ Info: iteration 26, average log likelihood -1.411336
[ Info: iteration 27, average log likelihood -1.411302
[ Info: iteration 28, average log likelihood -1.411271
[ Info: iteration 29, average log likelihood -1.411241
[ Info: iteration 30, average log likelihood -1.411212
[ Info: iteration 31, average log likelihood -1.411185
[ Info: iteration 32, average log likelihood -1.411160
[ Info: iteration 33, average log likelihood -1.411135
[ Info: iteration 34, average log likelihood -1.411112
[ Info: iteration 35, average log likelihood -1.411089
[ Info: iteration 36, average log likelihood -1.411068
[ Info: iteration 37, average log likelihood -1.411047
[ Info: iteration 38, average log likelihood -1.411027
[ Info: iteration 39, average log likelihood -1.411007
[ Info: iteration 40, average log likelihood -1.410988
[ Info: iteration 41, average log likelihood -1.410970
[ Info: iteration 42, average log likelihood -1.410952
[ Info: iteration 43, average log likelihood -1.410934
[ Info: iteration 44, average log likelihood -1.410917
[ Info: iteration 45, average log likelihood -1.410900
[ Info: iteration 46, average log likelihood -1.410883
[ Info: iteration 47, average log likelihood -1.410866
[ Info: iteration 48, average log likelihood -1.410850
[ Info: iteration 49, average log likelihood -1.410833
[ Info: iteration 50, average log likelihood -1.410817
â”Œ Info: EM with 100000 data points 50 iterations avll -1.410817
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4134498119986563
â”‚     -1.4133860785454144
â”‚      â‹®                 
â””     -1.410817164711043 
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.423321790345662 
â”‚     -1.4233421731951328
â”‚     -1.4232752975125669
â”‚     -1.4232186245503067
â”‚      â‹®                 
â”‚     -1.4108496317710981
â”‚     -1.4108332739706024
â””     -1.410817164711043 
32Ã—26 Array{Float64,2}:
  0.190714   -0.352096    0.0751331    0.0648731   0.00651411  -0.216964    -0.289624    -0.341386     0.310065   -0.15688     0.0210687    0.361312     0.0383779    0.0557173    0.280782    -0.125684     0.646566    0.265777   -0.98193     -0.0575491    -0.237777   -0.238147    0.195455    -0.00476389   0.0938915   -0.134388  
  0.488027    0.0111036   0.518251     0.366953   -0.819352    -0.310802    -0.646993    -0.121982     0.077455   -0.0807033   0.00696826  -0.549588    -0.206063    -0.430495    -0.289412    -0.107808     0.824133    0.338363    0.650085    -0.114727     -0.295942    0.112015    0.142484    -0.438637     0.213002     0.172042  
  0.659252    0.604166    0.182552    -0.425356    0.0205592    0.051854    -0.170571     0.190285     0.307415    0.300309    0.1026       0.240631    -0.114316    -0.605771    -0.216076    -0.23777      0.445971    0.613372    0.016345    -0.253573      0.117148    0.11568    -0.56835      0.259698    -0.5578      -0.493198  
  0.560381   -0.735781    0.00402457  -0.592366    0.138608    -0.0560246   -0.0210265   -0.476928     0.196124    0.108231    0.572321     0.147521    -0.244627    -0.804584     0.0854928    0.721362    -0.0806235   0.23089    -0.61258     -0.0847444     0.0885961   0.0749971  -0.156384    -0.105586     0.261874    -0.937624  
 -0.182977   -0.405756   -0.575292    -0.266725    0.832821    -0.25829     -0.00616622   0.019624    -0.353739   -0.329954    0.16806      0.418207     0.124769     0.574675    -0.259767     0.589831    -0.247384    0.0685799  -0.645968     0.525821     -0.0513703  -0.0117009  -0.0601517    0.387235    -0.217725    -0.0970542 
 -0.338069    0.215951   -0.363764     0.0177756   0.635368    -0.241873    -0.104321     0.433196    -0.0711238   1.08518    -0.0230451    0.541869     0.175012     0.2869      -0.0852216    0.455117     0.0435873   0.0707592  -0.124034    -0.17781      -0.29266    -0.34698     0.578353    -0.024789    -0.354447    -0.331196  
  0.389074    0.175613   -0.494326     0.646068    0.575845    -0.65715     -0.12162     -0.519128     0.45854    -0.210104    0.4084       0.0668549   -0.204857    -0.162684    -0.106977    -0.170794    -0.0010011  -0.514284   -0.184117     0.0344686    -0.028101    0.102703   -0.259014    -0.435538    -0.447501     0.480115  
  0.605105   -0.170775   -0.623021     0.356144    0.811102     0.224732    -0.227824    -0.618874     0.640077   -0.0181358   0.00492033  -0.791558    -0.140454     0.800764     0.0883385    0.247021     0.0451423  -0.366709    0.20398      0.616487     -0.0238848  -0.0822667   0.166951    -0.100133    -0.00817894  -0.50629   
  0.09462    -0.130831   -0.0116902   -0.512476   -0.44652     -0.456457     0.565954    -0.327008    -0.292848   -0.30864     0.377345     0.0496039   -0.294027     0.342857    -0.108983     0.258441     0.449604   -0.283563    0.0278636    0.625411      0.0675077   0.162863    0.375434     0.114517     0.413362    -0.135115  
 -0.320501   -0.157633   -0.0452869    0.398921   -0.1114      -0.159366     0.35205     -0.00490936   0.295447    0.0722722   0.310651     0.331796    -0.232991     2.18371e-5   0.741304     0.00974839  -0.803908   -0.429838    0.225202     0.000882836   0.395486   -0.671646    1.15541     -0.345871     0.745357     0.362638  
 -0.361327   -0.205492   -0.0637414    0.766863    0.060787     0.604122    -0.403722     0.642185     0.349306    0.187567   -0.777555     0.154702    -0.617013     0.0264452    0.24318     -0.500159    -0.316244    0.346391    0.213346    -0.28711       0.388398    0.200688    0.362889     0.0415055   -0.0560094    0.00321074
 -0.289788    0.569704    0.234969     0.379203   -0.00564628  -0.144367     0.124156     0.731584    -0.165405   -0.0740995  -0.423312     0.363152    -0.0960229    0.0851084   -0.285192    -0.462364    -0.171865   -0.375204    0.712236    -0.13466       0.112567   -0.212422    0.244246     0.130634    -0.26231      0.76364   
 -0.221756    0.233833   -0.069193     0.0194603   0.169088     0.0883053    0.259664     0.206421    -0.469837   -0.0683581  -0.13275      0.0347618    0.114991    -0.0591567   -0.0498085    0.0470136   -0.291094   -0.162645    0.340069     0.0169612     0.0842985   0.0248363  -0.127817     0.0885803   -0.171431    -0.00116484
 -0.384631   -0.228231    0.225062     0.0494368  -0.518758     0.109031    -0.102527    -0.397125    -0.0134521  -0.667136   -0.127879    -0.538976    -0.0890668   -0.562255     0.00782506  -0.419111    -0.649111    0.0403623  -0.0254058   -0.212139      0.0711617   0.25024    -0.790617     0.387846     0.501744     0.238105  
 -0.114977    0.176599   -0.0665253   -0.637523   -0.171213     0.134287    -0.351022    -0.00834211   0.282045    0.923416   -0.13738     -0.992961     0.625593     0.0505897   -0.279395     0.782515    -0.165688    0.75816    -0.012213    -0.0172972     0.422371    0.0769029  -0.253559     0.169685     0.177622     0.113757  
 -0.271241    0.0393585   0.0214326    0.435193   -0.0551871    0.0256841    0.232567     0.335789     0.527159    0.693973    0.443877    -0.912409     0.651919    -0.0664339    0.0519691   -0.138797    -0.36802    -0.271962    0.316289    -0.675794      0.114122    0.161782   -0.051056     0.0570505   -0.449728     0.523149  
 -0.208387   -0.245461   -0.275909    -0.0891236  -0.0162855    0.222296    -0.353777    -0.387534    -0.302128    0.137423   -0.0539582   -0.459472    -0.00449875   0.0893549   -0.227655     0.363551     0.170255    0.234888    0.0450835   -0.367484     -0.628315    0.255243   -0.671949    -0.420776    -0.215113    -0.539827  
 -0.0788398  -0.0549066  -0.276603     0.143667   -0.176952     0.156631    -0.156838    -0.42157     -0.160489   -0.433332   -0.386775     0.0401219   -0.308197     0.293669     0.64616      0.472028     0.179938    0.304464    0.0508999    0.0137713     0.0411234  -0.355004    0.207356    -0.527499     0.312276    -0.310643  
  0.0995482   0.380689   -0.427734    -0.217348    0.0167657   -0.221876     0.198177    -0.133953     0.268249   -0.0916182  -0.17241     -0.246157     0.0544535    0.539913     0.510076    -0.400329     0.193635    0.321728   -0.573371     0.581017     -0.250227   -0.179112   -0.234047     0.0652131    0.561254     0.268248  
 -0.443067   -0.107136   -0.504371    -0.103434   -0.32988      0.94893      0.0142571   -0.642939     0.147593    0.236075    0.225238    -0.401597    -0.0508834   -0.161279     0.523252    -0.0448418    0.253662    0.369708   -0.559517     0.425347      0.0273303  -0.236822   -0.144166     0.194094     0.0350458   -0.0890953 
  0.0961903   0.276217    0.305417     0.126794   -0.40181      0.0650017    0.317841    -0.367529    -0.80868    -0.297579   -0.025231    -0.210652    -0.0450095   -0.288206    -0.592321     0.0466297    0.0639449   0.434322    0.205107     0.269209      0.0858238   0.0639378  -0.769679     0.54346     -0.137371     0.0289326 
 -0.0383024   0.0884995  -0.0422421   -0.143881    0.230866     0.51599      0.305964     0.154001     0.141773    0.0235048   0.0894227   -0.278725     0.0151717    0.0272354   -0.570719    -0.118202    -0.378887   -0.224845    0.75137      0.280257      0.246521    0.558312   -0.173066     0.400695    -0.183828    -0.27538   
 -0.0895503   0.297625    0.490068    -0.213714   -0.888973     0.0249258    0.657877     0.0104591   -0.134287    0.104177   -0.31764     -0.503739    -0.251581    -0.297194     0.143867    -0.133128    -0.278098    0.142633    0.453966    -0.539112      0.11815     0.152409   -0.0135339   -0.0617892    0.796126    -0.104706  
 -0.207594    0.0602822   0.443172    -0.030608   -0.369919     0.0791821    0.0915532    0.289786     0.0846026   0.348679   -0.249317    -0.359461     0.165158     0.105475     0.1256       0.134455     0.321144    0.186711    0.384099     0.662364      0.366135   -0.239215    0.617084     0.439771     0.0578012    0.218991  
 -0.0348932  -0.0451186  -0.0185814    0.49169     0.227443    -0.1935       0.451155     0.163173    -0.351132   -0.474398    0.0293611    0.83636     -0.570061     0.0855939   -0.0819521   -0.423015     0.0112579  -0.317133   -0.1233      -0.371524     -0.513135   -0.148239    0.166614    -0.14776     -0.227481    -0.282112  
  0.6114     -0.676872    0.55269      0.176699    0.1284      -0.202308    -0.33829      0.0360032   -0.187755   -0.31814     0.365337     0.655462    -0.445906     0.0432486   -0.482321     0.0850186    0.242505   -0.125607   -0.0599807    0.301166     -0.0164316  -0.20181     0.689625     0.00912953  -0.0889277    0.0389414 
  0.285926    0.143934    0.130131    -0.0253668  -0.0720381    0.0983893    0.232126     0.0559993   -0.302107   -0.365618    0.222546     0.359597     0.544982    -0.054895     0.261968    -0.0784797   -0.289912   -0.182889   -0.15325     -0.32255       0.0714626  -0.0774891  -0.520207    -0.178334    -0.380837    -0.22334   
 -0.060282   -0.458199    0.391169    -0.420038   -0.145467     0.0687106    0.165547     0.970875    -0.360132    0.18615     0.122774     0.722547     0.103485    -0.508846     0.0778425   -0.227652    -0.127599    0.123343   -0.398503    -0.383193     -0.147525    0.104268   -0.0421034   -0.15263      0.0703359    0.213128  
  0.0121469  -0.124942    0.0516306   -0.138972   -0.161415    -0.00830712   0.103566    -0.00598226  -0.13312    -0.0804578  -0.0289664   -0.00438984  -0.123872    -0.0263986   -0.0525616   -0.0307683    0.108089    0.102498    0.0414771    0.133311     -0.105604    0.0429952   0.00103628   0.0148123    0.150637    -0.0439228 
  0.0579141   0.129466   -0.107109     0.10247     0.265611     0.0240077    0.0702413    0.101134     0.245546    0.271532    0.070167     0.0146794    0.0561444    0.0258418   -0.0125774    0.0571564   -0.241728    0.0507327  -0.00272417  -0.148467      0.188871   -0.166503    0.0434196    0.110047    -0.132547    -0.0103027 
  0.158856   -0.0649035   0.0364007   -0.0681371   0.123479    -0.572264    -0.199511    -0.0627975    0.133063   -0.186688   -0.0553646   -0.255224     0.280798    -0.203231     0.0173691   -0.0971096    0.0329005  -0.401859    0.147234    -0.114595      0.203206    0.646003    0.0656119   -0.265272     0.408133     0.483949  
  0.0803126   0.0506932   0.041865     0.602011    0.0679337   -0.321082    -0.532732    -0.0469732    0.141998    0.280893   -0.0190922   -0.178566     0.2935       0.0122307    0.100606    -0.112512     0.467252   -0.188513   -0.173901    -0.157545     -0.102425   -0.244196    0.192795    -0.184976    -0.358387     0.450175  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410801
[ Info: iteration 2, average log likelihood -1.410786
[ Info: iteration 3, average log likelihood -1.410771
[ Info: iteration 4, average log likelihood -1.410756
[ Info: iteration 5, average log likelihood -1.410742
[ Info: iteration 6, average log likelihood -1.410728
[ Info: iteration 7, average log likelihood -1.410715
[ Info: iteration 8, average log likelihood -1.410702
[ Info: iteration 9, average log likelihood -1.410690
[ Info: iteration 10, average log likelihood -1.410678
â”Œ Info: EM with 100000 data points 10 iterations avll -1.410678
â”” 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.017325e+05
      1       7.047396e+05      -1.969929e+05 |       32
      2       6.922136e+05      -1.252601e+04 |       32
      3       6.872539e+05      -4.959685e+03 |       32
      4       6.846312e+05      -2.622734e+03 |       32
      5       6.828906e+05      -1.740626e+03 |       32
      6       6.816646e+05      -1.226014e+03 |       32
      7       6.807148e+05      -9.497380e+02 |       32
      8       6.799701e+05      -7.447174e+02 |       32
      9       6.793619e+05      -6.081928e+02 |       32
     10       6.788651e+05      -4.968213e+02 |       32
     11       6.784539e+05      -4.111572e+02 |       32
     12       6.781142e+05      -3.397361e+02 |       32
     13       6.778284e+05      -2.857468e+02 |       32
     14       6.775797e+05      -2.487302e+02 |       32
     15       6.773684e+05      -2.112825e+02 |       32
     16       6.771620e+05      -2.063994e+02 |       32
     17       6.769732e+05      -1.888726e+02 |       32
     18       6.768091e+05      -1.640388e+02 |       32
     19       6.766533e+05      -1.557784e+02 |       32
     20       6.765116e+05      -1.417323e+02 |       32
     21       6.763715e+05      -1.401118e+02 |       32
     22       6.762552e+05      -1.162934e+02 |       32
     23       6.761387e+05      -1.165073e+02 |       32
     24       6.760228e+05      -1.158580e+02 |       32
     25       6.759153e+05      -1.075001e+02 |       32
     26       6.758135e+05      -1.018791e+02 |       32
     27       6.757112e+05      -1.022836e+02 |       32
     28       6.756224e+05      -8.882076e+01 |       32
     29       6.755409e+05      -8.147254e+01 |       32
     30       6.754658e+05      -7.505096e+01 |       32
     31       6.753952e+05      -7.058567e+01 |       32
     32       6.753263e+05      -6.897021e+01 |       32
     33       6.752651e+05      -6.115813e+01 |       32
     34       6.752033e+05      -6.180993e+01 |       32
     35       6.751477e+05      -5.556104e+01 |       32
     36       6.750938e+05      -5.397699e+01 |       32
     37       6.750421e+05      -5.163092e+01 |       32
     38       6.749938e+05      -4.830621e+01 |       32
     39       6.749474e+05      -4.642662e+01 |       32
     40       6.749072e+05      -4.021305e+01 |       32
     41       6.748666e+05      -4.057983e+01 |       32
     42       6.748298e+05      -3.681797e+01 |       32
     43       6.747978e+05      -3.197764e+01 |       32
     44       6.747651e+05      -3.268876e+01 |       32
     45       6.747335e+05      -3.163535e+01 |       32
     46       6.747044e+05      -2.906189e+01 |       32
     47       6.746787e+05      -2.570277e+01 |       32
     48       6.746561e+05      -2.258068e+01 |       32
     49       6.746354e+05      -2.077092e+01 |       32
     50       6.746181e+05      -1.730354e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 674618.0719433824)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422960
[ Info: iteration 2, average log likelihood -1.417916
[ Info: iteration 3, average log likelihood -1.416547
[ Info: iteration 4, average log likelihood -1.415505
[ Info: iteration 5, average log likelihood -1.414365
[ Info: iteration 6, average log likelihood -1.413285
[ Info: iteration 7, average log likelihood -1.412539
[ Info: iteration 8, average log likelihood -1.412125
[ Info: iteration 9, average log likelihood -1.411893
[ Info: iteration 10, average log likelihood -1.411742
[ Info: iteration 11, average log likelihood -1.411628
[ Info: iteration 12, average log likelihood -1.411534
[ Info: iteration 13, average log likelihood -1.411452
[ Info: iteration 14, average log likelihood -1.411380
[ Info: iteration 15, average log likelihood -1.411314
[ Info: iteration 16, average log likelihood -1.411254
[ Info: iteration 17, average log likelihood -1.411199
[ Info: iteration 18, average log likelihood -1.411148
[ Info: iteration 19, average log likelihood -1.411101
[ Info: iteration 20, average log likelihood -1.411058
[ Info: iteration 21, average log likelihood -1.411018
[ Info: iteration 22, average log likelihood -1.410981
[ Info: iteration 23, average log likelihood -1.410946
[ Info: iteration 24, average log likelihood -1.410913
[ Info: iteration 25, average log likelihood -1.410883
[ Info: iteration 26, average log likelihood -1.410854
[ Info: iteration 27, average log likelihood -1.410827
[ Info: iteration 28, average log likelihood -1.410801
[ Info: iteration 29, average log likelihood -1.410777
[ Info: iteration 30, average log likelihood -1.410753
[ Info: iteration 31, average log likelihood -1.410731
[ Info: iteration 32, average log likelihood -1.410709
[ Info: iteration 33, average log likelihood -1.410688
[ Info: iteration 34, average log likelihood -1.410668
[ Info: iteration 35, average log likelihood -1.410649
[ Info: iteration 36, average log likelihood -1.410630
[ Info: iteration 37, average log likelihood -1.410612
[ Info: iteration 38, average log likelihood -1.410594
[ Info: iteration 39, average log likelihood -1.410577
[ Info: iteration 40, average log likelihood -1.410561
[ Info: iteration 41, average log likelihood -1.410545
[ Info: iteration 42, average log likelihood -1.410529
[ Info: iteration 43, average log likelihood -1.410514
[ Info: iteration 44, average log likelihood -1.410500
[ Info: iteration 45, average log likelihood -1.410486
[ Info: iteration 46, average log likelihood -1.410472
[ Info: iteration 47, average log likelihood -1.410459
[ Info: iteration 48, average log likelihood -1.410447
[ Info: iteration 49, average log likelihood -1.410435
[ Info: iteration 50, average log likelihood -1.410423
â”Œ Info: EM with 100000 data points 50 iterations avll -1.410423
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.156759    0.00632052   0.00701528   0.109625    0.0658638  -0.132606     0.323843     0.11631    -0.195956    -0.475166    0.0880782    0.790055    -0.565094    -0.274616    -0.0752612    -0.607097     0.171779      0.0990623  -0.58583    -0.449834   -0.577446     0.200057   -0.483108   -0.280555   -0.271039    -0.135101  
  0.0656051   0.0578274   -0.618615    -0.376097    0.290136    0.057238     0.0970973    0.2383      0.0490793    0.675628    0.133358     0.373326    -0.436728    -0.194505    -0.123396      0.530902    -0.480596      0.754216   -0.559555   -0.362315    0.121329    -0.689697   -0.202606   -0.0231217  -0.380699    -0.399225  
 -0.0354032  -0.275116     0.543403     0.0745758  -0.452918    0.0436114   -0.237813    -0.816602   -0.00918229  -0.392228    0.0503277   -0.467512    -0.212402    -0.90544     -0.423775     -0.265639    -0.493956      0.235067    0.195518   -0.145152    0.15095      0.1265     -0.819455    0.344337    0.299592     0.273747  
 -0.0585002   0.0446727   -0.39006     -0.0294397  -0.0488793   0.230296    -0.173821    -0.627484   -0.403608    -0.103777   -0.201279    -0.161465    -0.107295     0.375562     0.175795      0.478063     0.221923      0.0072049   0.348501   -0.0738481  -0.448466    -0.218927   -0.262874   -0.622512   -0.136948    -0.43558   
  0.156444   -0.642073     0.239809     0.249052    0.542466   -0.329718    -0.450176     0.349808    0.485614     0.457041    0.109785     0.573546     0.529904     0.0139189    0.374533     -0.0949472    0.371757     -0.235451   -0.829671   -0.363439   -0.256116    -0.253234    0.626177   -0.294462   -0.246498    -0.00214012
  1.18523    -0.153129     0.358682    -0.54263     0.0815544  -0.48401      0.267225    -0.309231   -0.308499     0.508908    0.574101    -0.176582     0.502194    -0.247193    -0.113446      0.349306     0.439651     -0.429933   -0.32148     0.38289     0.0189879   -0.243063   -0.453961    0.108441   -0.430817    -0.107267  
  0.424761   -0.766303     0.471093     0.0230584   0.0488006  -0.164717    -0.432733    -0.209636   -0.236721    -0.567183    0.344498     0.614495    -0.542059     0.335242    -0.660969      0.321615     0.382609      0.19351    -0.352292    0.68371     0.00319402  -0.134436    0.688795    0.156864   -0.167844     0.0333252 
  0.126894    0.149501    -0.781438     0.0527675   0.240827    0.282644    -0.310627    -0.603108    0.547439     0.0780682   0.0437305   -0.630291    -0.11018      0.585067     0.489004     -0.235966     0.452626      0.352013   -0.583371    0.723429   -0.222149    -0.366499   -0.177371   -0.0221824   0.273744     0.0246076 
  0.166624    0.242533    -0.417989     0.767615    0.472795   -0.717685    -0.517338    -0.350165    0.144305    -0.0147381   0.0625633   -0.0753284    0.152697    -0.0660874   -0.112035     -0.0367934    0.179073     -0.532859   -0.114047   -0.0288808  -0.196797    -0.0081726  -0.221421   -0.338178   -0.447463     0.497546  
  0.236583    0.302748     0.101328    -0.113359    0.0339297  -0.0039468   -0.733583     0.0863711   0.220162     0.395926    0.00969099  -0.628577     0.407488    -0.133123    -0.31516       0.246028     0.320791      0.605363    0.123359   -0.38554    -0.0506495    0.519499   -0.610764    0.0318017  -0.256237    -0.222635  
  0.262941   -0.189535     0.387762     0.393015   -0.369767   -0.212345    -0.0630905   -0.596998    0.42382     -0.433384   -0.353854    -0.123269     0.197082    -0.0584675    0.971689      0.395039     0.281888      0.868015   -0.918277   -0.234558    0.203917    -0.788687    0.398264   -0.388087    0.589449    -0.0615124 
 -0.651993   -1.18738      0.0655825   -0.0409555  -0.333555    0.638051    -0.345085     0.478506   -0.544461    -0.251271   -0.0622904   -0.0565277    0.204044    -0.430282     0.317962     -0.0726352   -0.458195     -0.178403   -0.461781   -0.272965   -0.503439     0.18343    -0.481552   -0.0569019  -0.103264     0.0820113 
  0.136752    0.368189    -0.301972    -0.0864388  -0.284621    0.119577     0.504347     0.174419    0.16273     -0.567009   -0.0527764    2.62895e-5   0.681932     0.138481     0.714107     -0.174197    -0.347673      0.192167   -0.280286    0.0441662   0.474893     0.328936   -0.837417   -0.224722    0.133493     0.0521506 
  0.0704087  -0.0158405    0.161071    -0.140979   -0.143035    0.0908699    0.100398     0.0584012  -0.0056944    0.0325295  -0.0148917    0.0111937   -0.0590247   -0.169656    -0.125178     -0.0361727    0.028818      0.268855   -0.020154    0.0686683   0.0151309    0.0256548  -0.135838    0.107324   -0.00785008  -0.0439179 
  0.0844634  -0.680928    -0.323691    -0.513613    0.0460857   0.00853416   0.00236644  -0.712257    0.0170382   -0.383417    0.358431    -0.13074     -0.283963    -0.29417      0.190694      0.6318       0.138655      0.270862   -0.72722     0.206673   -0.127262     0.306553   -0.213146   -0.0821013   0.309888    -1.10351   
 -0.222946    0.201654     0.672294     0.111215    0.0577299  -0.261528     0.265835     1.0082     -0.278581    -0.0144495  -0.0971562    0.532791     0.138003    -0.452002    -0.534128     -0.0827176   -0.29303      -0.357256    0.522289   -0.566584    0.232957     0.19527     0.224334    0.141301   -0.201945     0.637569  
  0.225405    0.14321      0.227188     0.156071    0.51041     0.112158     0.251732     0.184392   -0.101263     0.380402    0.265526     0.62565     -0.166238    -0.33502     -0.506516     -0.170769    -0.125011     -0.169294    0.40467    -0.0759888  -0.0930727   -0.168559    0.093356    0.0326391  -0.727486    -0.151745  
 -0.0252348   0.538603    -0.0409288    0.111162   -0.405284    0.360487     0.651786    -0.0842502  -0.57186     -0.401862   -0.208364    -0.442446    -0.128564    -0.0157522   -0.593682     -0.276655    -0.221477      0.194806    0.692594    0.31334     0.119135     0.258734   -0.673749    0.511673   -0.299906    -0.0205689 
  0.594646   -0.201916     0.44001      0.228257   -0.696743   -0.499392    -0.537353     0.0394277   0.0293245   -0.227128   -0.158766    -0.194524    -0.605347    -0.463621    -0.295573      0.0559377    0.585414      0.158944    0.728753   -0.099605   -0.256719     0.124096    0.390478   -0.466816    0.208616    -0.102449  
  0.249798   -0.193447    -0.31891      0.0651394   0.809403    0.324776     0.0979706    0.0245506   0.276496     0.015223    0.122302    -0.239283     0.200044     0.408554    -0.204931     -0.0133663   -0.547246     -0.608325    0.32764     0.269821    0.177568     0.358319   -0.0304956   0.347813   -0.152034    -0.352099  
 -0.581546    0.241196    -0.0636313    0.699854   -0.124297    0.613656    -0.363193     0.429371    0.140416    -0.135114   -0.922002     0.332709    -0.462085     0.214659     0.100164     -0.613735    -0.16386       0.461325    0.370273   -0.205371    0.34107     -0.0263172   0.219285    0.135039   -0.043097     0.0408079 
  0.0387333  -0.100771    -0.0406282    0.162069    0.211527   -0.149075     0.16741      0.238101   -0.290937    -0.1808      0.105889     0.421575    -0.00624177   0.260049     0.151343     -0.115913    -0.0195496    -0.32985    -0.188026   -0.0994589  -0.195633    -0.199184    0.197968   -0.0327532  -0.00573531  -0.0817167 
  0.15197     0.441604     0.478569    -0.709512   -0.539081   -0.0714915    0.197232     0.259515   -0.632701     0.0440627  -0.15595      0.501046     0.087419    -0.256369     0.196425     -0.0555124    0.338446      0.586646   -0.221626    0.196433    0.249798    -0.0106275  -0.219913    0.407353    0.455164    -0.101597  
 -0.14182     0.091941    -0.0854983    0.0127531   0.0592355   0.0241383    0.0051392   -0.0819989  -0.0830262    0.0182405   0.0353795   -0.0739528    0.103256     0.0316625   -0.000848747   0.0343812    0.000202324  -0.0761428   0.0452839   0.0470881   0.0411774   -0.0123596   0.023019    0.10314    -0.0214118    0.0109512 
 -0.604165   -0.0598624   -0.467771    -0.125564    0.49301    -0.314605    -0.0448462    0.621019   -0.500559     0.606114   -0.29958      0.193152     0.238447     0.693589    -0.231569      0.65983      0.230783      0.41361     0.194677    0.578584   -0.19995     -0.0473602   0.555038    0.119651    0.11636     -0.0804375 
 -0.495578    0.0462055   -0.108324     0.41794     0.240603    0.154138     0.419547     0.392921    0.683268     0.742523    0.0760541   -0.674469     0.482617    -0.202356     0.250357      0.0446306   -0.817922     -0.0721598   0.132083   -0.750123    0.115543    -0.303823    0.185282   -0.153842   -0.484229     0.532575  
 -0.114496   -0.0350877   -0.19797     -0.0993547  -0.142585   -0.974528     0.59348     -0.327894   -0.206289    -0.213719    0.222916    -0.245546    -0.183068     0.335497    -0.194523     -0.011114     0.034173     -0.411921   -0.226957    0.202136   -0.115395     0.238062    0.247171    0.16372     0.641712     0.455064  
  0.0273968  -0.0671988   -0.159318     0.331408    0.0247797  -0.183194     0.237288     0.0341677   0.0722958   -0.233677    0.0873986    0.632945    -0.535217     0.152056     0.547762     -0.0857921   -0.323522     -0.504575    0.259616    0.126398    0.243851    -0.463627    0.976078   -0.264308    0.347817     0.153052  
  0.0652978   0.0910769   -0.219854     0.114814    0.131359   -0.265728    -0.235356    -0.0632064   0.246701     0.068551   -0.0952398   -0.265373     0.0952239    0.00511788   0.0362138    -0.00726432  -0.113122     -0.123434    0.242347   -0.104749    0.22897      0.16585     0.0378472  -0.0860788   0.141106     0.28779   
 -0.149968    0.263376     0.439473    -0.0602009  -0.748037   -0.0301488    0.584861     0.152663   -0.125699     0.197324   -0.233321    -0.673735    -0.233037    -0.414923     0.473286     -0.321955    -0.25994      -0.133598    0.784698   -0.588837   -0.0416811    0.282541   -0.119311   -0.395526    1.09166     -0.114792  
 -0.405982   -0.118667     0.10092     -0.349966   -0.379433    0.664689     0.458346    -0.232267    0.0489218    0.291407    0.251718    -0.409001     0.00313261  -0.0109815   -0.114702      0.453659    -0.0302988     0.244505    0.197954    0.102088    0.237389     0.0070085   0.172091    0.246921    0.174796    -0.371344  
 -0.0897195   0.188011     0.437443     0.195478   -0.477908[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
    0.0208215   -0.0771346    0.179447    0.322725     0.301381   -0.112529    -0.539399     0.257055    -0.0258799    0.138302     -0.281022     0.468388     -0.0798348   0.324244    0.363305    0.317006    -0.0775666   0.494031    0.22654    -0.0674785    0.573636  [ Info: iteration 1, average log likelihood -1.410412
[ Info: iteration 2, average log likelihood -1.410401
[ Info: iteration 3, average log likelihood -1.410391
[ Info: iteration 4, average log likelihood -1.410381
[ Info: iteration 5, average log likelihood -1.410371
[ Info: iteration 6, average log likelihood -1.410362
[ Info: iteration 7, average log likelihood -1.410353
[ Info: iteration 8, average log likelihood -1.410344
[ Info: iteration 9, average log likelihood -1.410336
[ Info: iteration 10, average log likelihood -1.410328
â”Œ Info: EM with 100000 data points 10 iterations avll -1.410328
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
