Julia Version 1.3.0
Commit 46ce4d7933 (2019-11-26 06:09 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)

   Cloning default registries into `~/.julia`
   Cloning registry from "https://github.com/JuliaRegistries/General.git"
[?25l    Fetching: [>                                        ]  0.0 %    Fetching: [============>                            ]  28.4 %    Fetching: [=========================>               ]  61.4 %[2K[?25h     Added registry `General` to `~/.julia/registries/General`
 Resolving package versions...
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.6
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.2
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.21.11
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed OrderedCollections â”€ v1.1.0
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+1
 Installed SpecialFunctions â”€â”€â”€ v0.9.0
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.0
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed Polynomials â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed OpenSpecFun_jll â”€â”€â”€â”€ v0.5.3+1
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [f27b6e38] + Polynomials v0.6.0
  [1fd47b50] + QuadGK v2.2.0
  [3cdcf5f2] + RecipesBase v0.7.0
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_20wxDJ/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [f27b6e38] Polynomials v0.6.0
  [1fd47b50] QuadGK v2.2.0
  [3cdcf5f2] RecipesBase v0.7.0
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -778131.0489612081, [3189.976068986278, 96810.02393101373], [875.9090679911614 -2992.686117386114 5470.507395808161; -907.4662093576718 3386.633172513042 -5440.732661514513], Array{Float64,2}[[1911.7214567373812 -526.5501019843615 2257.096982537634; -526.5501019843615 5555.436772916631 -3992.9316955172994; 2257.096982537634 -3992.9316955172994 10412.291088930642], [97302.47182201344 259.9062092397213 -2333.542086899293; 259.90620923972125 94392.47162481326 4122.289816881703; -2333.542086899293 4122.289816881702 89377.49985574013]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.564304e+03
      1       9.509350e+02      -6.133694e+02 |        8
      2       8.322579e+02      -1.186771e+02 |        4
      3       8.178037e+02      -1.445422e+01 |        2
      4       8.025069e+02      -1.529674e+01 |        0
      5       8.025069e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 802.5069447335131)
â”Œ Info: K-means with 272 data points using 5 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.060901
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.811275
[ Info: iteration 2, lowerbound -3.685934
[ Info: iteration 3, lowerbound -3.551023
[ Info: iteration 4, lowerbound -3.401056
[ Info: iteration 5, lowerbound -3.262369
[ Info: iteration 6, lowerbound -3.162437
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.109014
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -3.080539
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -3.063344
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -3.041350
[ Info: iteration 11, lowerbound -3.014895
[ Info: iteration 12, lowerbound -2.979306
[ Info: iteration 13, lowerbound -2.926694
[ Info: iteration 14, lowerbound -2.855083
[ Info: iteration 15, lowerbound -2.767891
[ Info: iteration 16, lowerbound -2.673426
[ Info: iteration 17, lowerbound -2.578987
[ Info: iteration 18, lowerbound -2.489160
[ Info: iteration 19, lowerbound -2.411559
[ Info: iteration 20, lowerbound -2.355588
[ Info: iteration 21, lowerbound -2.326233
[ Info: dropping number of Gaussions to 3
[ Info: iteration 22, lowerbound -2.311423
[ Info: dropping number of Gaussions to 2
[ Info: iteration 23, lowerbound -2.303001
[ Info: iteration 24, lowerbound -2.299265
[ Info: iteration 25, lowerbound -2.299258
[ Info: iteration 26, lowerbound -2.299255
[ Info: iteration 27, lowerbound -2.299254
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Dec  6 18:57:06 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Dec  6 18:57:13 2019: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Fri Dec  6 18:57:15 2019: EM with 272 data points 0 iterations avll -2.060901
5.8 data points per parameter
, Fri Dec  6 18:57:17 2019: GMM converted to Variational GMM
, Fri Dec  6 18:57:25 2019: iteration 1, lowerbound -3.811275
, Fri Dec  6 18:57:25 2019: iteration 2, lowerbound -3.685934
, Fri Dec  6 18:57:25 2019: iteration 3, lowerbound -3.551023
, Fri Dec  6 18:57:25 2019: iteration 4, lowerbound -3.401056
, Fri Dec  6 18:57:25 2019: iteration 5, lowerbound -3.262369
, Fri Dec  6 18:57:25 2019: iteration 6, lowerbound -3.162437
, Fri Dec  6 18:57:26 2019: dropping number of Gaussions to 7
, Fri Dec  6 18:57:26 2019: iteration 7, lowerbound -3.109014
, Fri Dec  6 18:57:26 2019: dropping number of Gaussions to 6
, Fri Dec  6 18:57:26 2019: iteration 8, lowerbound -3.080539
, Fri Dec  6 18:57:26 2019: dropping number of Gaussions to 5
, Fri Dec  6 18:57:26 2019: iteration 9, lowerbound -3.063344
, Fri Dec  6 18:57:26 2019: dropping number of Gaussions to 4
, Fri Dec  6 18:57:26 2019: iteration 10, lowerbound -3.041350
, Fri Dec  6 18:57:26 2019: iteration 11, lowerbound -3.014895
, Fri Dec  6 18:57:26 2019: iteration 12, lowerbound -2.979306
, Fri Dec  6 18:57:26 2019: iteration 13, lowerbound -2.926694
, Fri Dec  6 18:57:26 2019: iteration 14, lowerbound -2.855083
, Fri Dec  6 18:57:26 2019: iteration 15, lowerbound -2.767891
, Fri Dec  6 18:57:26 2019: iteration 16, lowerbound -2.673426
, Fri Dec  6 18:57:26 2019: iteration 17, lowerbound -2.578987
, Fri Dec  6 18:57:26 2019: iteration 18, lowerbound -2.489160
, Fri Dec  6 18:57:26 2019: iteration 19, lowerbound -2.411559
, Fri Dec  6 18:57:26 2019: iteration 20, lowerbound -2.355588
, Fri Dec  6 18:57:26 2019: iteration 21, lowerbound -2.326233
, Fri Dec  6 18:57:26 2019: dropping number of Gaussions to 3
, Fri Dec  6 18:57:26 2019: iteration 22, lowerbound -2.311423
, Fri Dec  6 18:57:26 2019: dropping number of Gaussions to 2
, Fri Dec  6 18:57:26 2019: iteration 23, lowerbound -2.303001
, Fri Dec  6 18:57:26 2019: iteration 24, lowerbound -2.299265
, Fri Dec  6 18:57:26 2019: iteration 25, lowerbound -2.299258
, Fri Dec  6 18:57:26 2019: iteration 26, lowerbound -2.299255
, Fri Dec  6 18:57:26 2019: iteration 27, lowerbound -2.299254
, Fri Dec  6 18:57:26 2019: iteration 28, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 29, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 30, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 31, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 32, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 33, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 34, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 35, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 36, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 37, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 38, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 39, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 40, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 41, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 42, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 43, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 44, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 45, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 46, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 47, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 48, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 49, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: iteration 50, lowerbound -2.299253
, Fri Dec  6 18:57:26 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509222602397, 95.95490777397599]
Î² = [178.04509222602397, 95.95490777397599]
m = [4.250300733269828 79.28686694436064; 2.0002292577752856 53.85198717246084]
Î½ = [180.04509222602397, 97.95490777397599]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547483383 -0.007644049042328323; 0.0 0.008581705166331964], [0.3758763611949786 -0.008953123827347384; 0.0 0.012748664777409697]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999994
avll from stats: -1.0004017527201619
avll from llpg:  -1.0004017527200912
avll direct:     -1.0004017527200912
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0348123182259263
avll from llpg:  -1.0348123182259263
avll direct:     -1.0348123182259263
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
  0.0148402   -0.175172    -0.100221    -0.057427     0.0122465    -0.0638818    0.109868     0.140034     0.205837     -0.0799616   -0.0265427   -0.0827536    0.072136    0.0429167   -0.103258    -0.0576179    0.0646221     0.0126873   -0.0255119    0.109656     0.0988497   -0.087078      0.100415     0.0538869    0.233419     0.0838777 
  0.149899    -0.0192507   -0.0591218    0.0279071   -0.000364014  -0.0802308   -0.0925294   -0.0338146    0.0856114    -0.0316645    0.0991882   -0.13418      0.0554543   0.027403    -0.0232935   -0.0862638   -0.0245928     0.0566163   -0.128749     0.00452455   0.0181085    0.0809921     0.0749324    0.0460456    0.134893     0.0728397 
  0.00439079   0.0499072   -0.245783    -0.0802888    0.0118465     0.178726    -0.0492318   -0.0423936    0.00843388    0.070373    -0.128598     0.125287     0.146353    0.0606127   -0.128543    -0.00333355   0.0526604     0.286458     0.133425    -0.0302879   -0.00520843   0.152747      0.0713973    0.142949     0.019417     0.00846125
  0.0747087   -0.0750516   -0.115269     0.0160302    0.0265087    -0.103294     0.0234645   -0.0752585    0.000415361  -0.00641886   0.00434228   0.0560827    0.148502    0.045767     0.175449     0.0536393    0.181467      0.135596    -0.0379889    0.0236191   -0.0844429   -0.140036     -0.139133    -0.00629042   0.0867755   -0.0809841 
  0.141154    -0.216466     0.139414     0.0479861    0.175971      0.0788283   -0.0370933    0.0270053   -0.00859679   -0.128267    -0.118985     0.0244266    0.0684809   0.287378    -0.0239207   -0.128242     0.127688      0.0755584   -0.0290381   -0.0402292   -0.114586    -0.176564      0.135469     0.156807     0.00938195   0.0400171 
  0.0277557    0.0273074   -0.190146    -0.103979     0.102824     -0.00645637  -0.301545     5.51035e-5  -0.0203844     0.0704183    0.0299997   -0.025203     0.0781037  -0.133154     0.0197401   -0.119794     0.00160567   -0.118        0.167534     0.160018    -0.047216    -0.014929     -0.0321311    0.0324802   -0.0606386    0.0687681 
  0.0722396    0.0445938   -0.0875972    0.196008    -0.120353     -0.0465967   -0.096368     0.155319    -0.0101036    -0.0308592    0.163746     0.0952843    0.0135606  -0.178662     0.102858     0.140356    -0.0837364     0.0436074    0.131139     0.198955    -0.0521764    0.0894711    -0.117021    -0.0268845   -0.166926     0.040054  
 -0.039311    -0.151116    -0.0535184    0.00819277  -0.273592      0.0507421    0.120255     0.0788219   -0.154931      0.132595     0.0584648    0.0738885   -0.128871   -0.0557068    0.0362351    0.0780276    0.127493     -0.0426391   -0.0245277   -0.0763111   -0.111805     0.0707216     0.20465      0.13722     -0.0300094    0.021932  
  0.0798739   -0.0328594    0.0732831   -0.10239     -0.137444      0.0264162    0.00685233  -0.113281    -0.13528       0.0745298   -0.160944    -0.0713132   -0.0523499  -0.0878055    0.0528649   -0.256324     0.0260923    -0.034858     0.0412866    0.0523182   -0.0387105   -0.055285     -0.00498945  -0.0817163    0.0642823   -0.0237665 
  0.0298312    0.100289    -0.0804076   -0.0286106   -0.181674     -0.0726715    0.0833581   -0.147715    -0.151997     -0.00726915  -0.027652     0.00802597   0.125888   -0.133782    -0.0841911   -0.00946951  -0.06885       0.299528    -0.0586068    0.0149728    0.00652057  -0.179303      0.0159012   -0.0583803   -0.0668236    0.105121  
 -0.0326223    0.167617     0.0872393   -0.00512851  -0.133879      0.0829387   -0.0429451   -0.0190796    0.00347067    0.00378978  -0.26239     -0.00554781   0.140556   -0.0772681   -0.0262585   -0.0268331   -0.0260003     0.190188    -0.0669307    0.0194565    0.217071    -0.00681565    0.0411564   -0.0349273   -0.00630378   0.250742  
 -0.0253008    0.162859     0.0265102   -0.158242     0.0110142     0.0472603   -0.124475     0.136136    -0.0610207     0.0475574   -0.00794387  -0.0113632   -0.0105547  -0.0324736   -0.0655293   -0.00641607  -0.000881589  -0.00552063  -0.005987    -0.112925     0.0798087    0.159261      0.236696    -0.0934663   -0.0294337    0.0449394 
 -0.123342    -0.171799    -0.0832846   -0.151629    -0.0496888    -0.0801779   -0.0182825    0.157951     0.184113     -0.0733814   -0.0362066   -0.00400871  -0.0140979   0.106063     0.0621815    0.00588498   0.148686     -0.138689    -0.1322      -0.155941    -0.206883     0.0402514    -0.0983846    0.0679942    0.165741    -0.0475596 
 -0.074915    -0.0247901    0.193052    -0.00323656   0.0058784     0.0324807    0.0441754    0.0254849   -0.101323      0.00674347   0.0149135    0.0765153   -0.128227    0.117186     0.0206041    0.0320164    0.0607227    -0.00315945   0.0157029   -0.0635431    0.0597157    0.271918     -0.0919531    0.0914994   -0.0733944   -0.157291  
 -0.0888672    0.128219     0.110867    -0.0118283    0.100045      0.0525016    0.0252305   -0.133061    -0.0746517    -0.0922218   -0.061217    -0.100346     0.127451   -0.0406463    0.0319289   -0.027814    -0.0540534    -0.0689361    0.0754372    0.119836     0.233849     0.0050028    -0.023426     0.179327     0.125493    -0.12403   
 -0.186614    -0.020288     0.104773    -0.0398426   -0.13247      -0.0526594   -0.0442289   -0.0283849   -0.0316483     0.107271    -0.0487397    0.0754479    0.0575123   0.0148546    0.0805114    0.00969632   0.0431809    -0.0594256   -0.0177109    0.182023    -0.0244305   -0.0403193     0.0800865    0.0623888    0.0492346   -0.148623  
  0.0374079    0.222145    -0.0232522   -0.0668671   -0.158928     -0.0983366    0.115054    -0.00186901   0.0864248     0.070596    -0.0228992   -0.106104     0.0586972   0.00913002  -0.0450065    0.00565618   0.0454961     0.0588118    0.0480273   -0.0370401    0.114003     0.0193089     0.0487518   -0.0106569    0.00268183  -0.101426  
  0.133321     0.0590924   -0.0100106    0.048899     0.149691     -0.154686     0.0481784    0.127324     0.161843     -0.0875888    0.0509362   -0.00354739  -0.206843    0.0417007   -0.0880127    0.0632704    0.166462     -0.0710819    0.157562    -0.0457789    0.0196255    0.000584087  -0.0406392   -0.111871    -0.0923704    0.095031  
  0.0435506    0.00214479  -0.0308458    0.0885738    0.166744      0.0280718   -0.0812658   -0.0460592    0.171539      0.0104237   -0.0243962   -0.0867281    0.147209    0.101878    -0.0267235    0.0329698    0.121693      0.029044    -0.0628927    0.0763028    0.127198    -0.0838901     0.0299241    0.0528408   -0.10698      0.166162  
 -0.0880847   -0.0335516    0.0813784   -0.0592701    0.0420367    -0.0198563   -0.0183142    0.0213417   -0.0368008    -0.0242159   -0.0318099   -0.0203976   -0.141639    0.0466621   -0.0905716   -0.126332     0.111681     -0.00764781   0.041905    -0.0147024   -0.0486177   -0.125662     -0.00390522   0.0372138   -0.12937     -0.0198488 
 -0.196277    -0.144937    -0.0315134    0.0965677    0.00874397   -0.146833    -0.0302003    0.0877126    0.0600097    -0.00852318  -0.0779954    0.0243069    0.0606524  -0.0419194    0.122475    -0.0397035   -0.0449514     0.0683243   -0.115836     0.11859      0.0639638    0.103142     -0.0817048   -0.0514839    0.0181433    0.00466148
  0.0356532   -0.0301504   -0.00256226   0.0838125    0.00395331   -0.132127     0.121035     0.0149371   -0.192191      0.00425642   0.00963858  -0.0887195    0.240352    0.0375027    0.239516     0.0410259   -0.0378424    -0.0566573   -0.00892951  -0.182218    -0.102574     0.166664     -0.158146     0.0381341   -0.124734    -0.00325504
 -0.111065     0.0304925    0.0499997    0.0754025    0.142547     -0.135932     0.082077    -0.0938947    0.0925053    -0.20249     -0.150323    -0.119542     0.139838    0.0484015   -0.0197421   -0.00741184   0.0781413     0.0519165   -0.0141619    0.204104     0.0558529    0.0378743     0.177402    -0.127653     0.184854    -0.0523113 
 -0.0465935   -0.0235631   -0.0437728   -0.158827     0.0361264     0.0648211   -0.0465668    0.0243982    0.0694355    -0.0692696   -0.0619789   -0.0352613   -0.0043558  -0.0316826    0.0261433   -0.0645197    0.0113473    -0.00700878  -0.2026      -0.02285     -0.112157     0.031378      0.0365956   -0.154225     0.085416    -0.00327131
 -0.00178997   0.0723678    0.0746684    0.0868633    0.0143933    -0.069693    -0.0810867    0.102639     0.0441636    -0.0187059   -0.0737729   -0.0142956    0.142179    0.11774     -0.00490063   0.113085    -0.0528532    -0.0823432   -0.0580289    0.0109312   -0.00302424   0.0702277    -0.0201497    0.026588     0.0972408    0.159466  
  0.0424702    0.0667388   -0.0915605   -0.116084     0.113245      0.129955     0.252873    -0.0100037    0.0962681    -0.0615433    0.137061     0.0340154    0.0532165   0.128767     0.0112115    0.117622    -0.110146     -0.175169    -0.0307329   -0.110268     0.012416    -0.122893      0.026831     0.0455179   -0.0296207    0.0442772 
  0.072859    -0.0060064    0.0370625    0.0371542    0.00716843   -0.0587467    0.0572731   -0.207253    -0.032073      0.0672575   -0.0692185   -0.0310451    0.020119    0.0263934   -0.042198    -0.00926707   0.193003      0.00142975  -0.135954    -0.0625489   -0.117375    -0.235435     -0.196098    -0.0954898   -0.00683096  -0.0451897 
 -0.0464082   -0.0183023    0.0253701    0.110597     0.00151461   -0.136766     0.195266     0.14001      0.20153      -0.0711291   -0.0124499    0.0599088    0.108932    0.0644757    0.0276289   -0.0592336   -0.0494668    -0.0687879   -0.102893     0.108244    -0.0974831   -0.0742971    -0.0771042    0.0494653   -0.143467    -0.119854  
  0.116451     0.196761    -0.00252529   0.0111687    0.051389      0.0691266    0.0543755    0.0153564    0.0303523     0.0368243    0.08438      0.0945943   -0.0336243  -0.157286    -0.063722    -0.125691     0.140066      0.246612    -0.0373627   -0.0322593    0.0953075    0.0601112     0.0228532   -0.0353759    0.0256406   -0.149886  
 -0.0308025    0.167449    -0.0210946    0.00470797  -0.0515024     0.0536487    0.160401    -0.0447938   -0.0111524    -0.021995    -0.185081     0.0387004   -0.0558554   0.0698007   -0.115519    -0.0524078   -0.0445258     0.078143     0.0459975   -0.0586916    0.00927179   0.0274091     0.103425     0.0757928    0.0594765   -0.127695  
  0.0194971    0.0599773    0.00253892   0.0193479   -0.0155109     0.239294     0.0727036   -0.0781008   -0.0845704     0.051423    -0.159742     0.0839622   -0.0508225  -0.16182      0.0291769    0.118513    -0.149368      0.0037909   -0.0873475   -0.131981    -0.0528465    0.0830926     0.00647537   0.1151       0.156643     0.0199627 
  0.118069    -0.012675    -0.0924383   -0.0654344    0.0472068    -0.0560334   -0.0975586    0.141761    -0.0575214     0.0296032    0.00401406   0.119736     0.086264   -0.00530624   0.103938     0.0555944    0.0885683    -0.0486711   -0.060967    -0.0258132    0.0851266   -0.104874     -0.238386    -0.0559871   -0.14873     -0.0525534 kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4112712774290943
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411360
[ Info: iteration 2, average log likelihood -1.411268
[ Info: iteration 3, average log likelihood -1.410614
[ Info: iteration 4, average log likelihood -1.403371
[ Info: iteration 5, average log likelihood -1.385553
[ Info: iteration 6, average log likelihood -1.376630
[ Info: iteration 7, average log likelihood -1.373540
[ Info: iteration 8, average log likelihood -1.371889
[ Info: iteration 9, average log likelihood -1.370697
[ Info: iteration 10, average log likelihood -1.369712
[ Info: iteration 11, average log likelihood -1.368908
[ Info: iteration 12, average log likelihood -1.368276
[ Info: iteration 13, average log likelihood -1.367763
[ Info: iteration 14, average log likelihood -1.367349
[ Info: iteration 15, average log likelihood -1.367036
[ Info: iteration 16, average log likelihood -1.366816
[ Info: iteration 17, average log likelihood -1.366676
[ Info: iteration 18, average log likelihood -1.366593
[ Info: iteration 19, average log likelihood -1.366545
[ Info: iteration 20, average log likelihood -1.366518
[ Info: iteration 21, average log likelihood -1.366500
[ Info: iteration 22, average log likelihood -1.366489
[ Info: iteration 23, average log likelihood -1.366481
[ Info: iteration 24, average log likelihood -1.366476
[ Info: iteration 25, average log likelihood -1.366472
[ Info: iteration 26, average log likelihood -1.366469
[ Info: iteration 27, average log likelihood -1.366466
[ Info: iteration 28, average log likelihood -1.366464
[ Info: iteration 29, average log likelihood -1.366463
[ Info: iteration 30, average log likelihood -1.366461
[ Info: iteration 31, average log likelihood -1.366460
[ Info: iteration 32, average log likelihood -1.366460
[ Info: iteration 33, average log likelihood -1.366459
[ Info: iteration 34, average log likelihood -1.366458
[ Info: iteration 35, average log likelihood -1.366458
[ Info: iteration 36, average log likelihood -1.366458
[ Info: iteration 37, average log likelihood -1.366457
[ Info: iteration 38, average log likelihood -1.366457
[ Info: iteration 39, average log likelihood -1.366457
[ Info: iteration 40, average log likelihood -1.366457
[ Info: iteration 41, average log likelihood -1.366456
[ Info: iteration 42, average log likelihood -1.366456
[ Info: iteration 43, average log likelihood -1.366456
[ Info: iteration 44, average log likelihood -1.366456
[ Info: iteration 45, average log likelihood -1.366456
[ Info: iteration 46, average log likelihood -1.366456
[ Info: iteration 47, average log likelihood -1.366456
[ Info: iteration 48, average log likelihood -1.366456
[ Info: iteration 49, average log likelihood -1.366456
[ Info: iteration 50, average log likelihood -1.366456
â”Œ Info: EM with 100000 data points 50 iterations avll -1.366456
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4113596352640743
â”‚     -1.4112678554469325
â”‚      â‹®                 
â””     -1.3664557446918701
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.366592
[ Info: iteration 2, average log likelihood -1.366489
[ Info: iteration 3, average log likelihood -1.366286
[ Info: iteration 4, average log likelihood -1.364212
[ Info: iteration 5, average log likelihood -1.352997
[ Info: iteration 6, average log likelihood -1.337807
[ Info: iteration 7, average log likelihood -1.332188
[ Info: iteration 8, average log likelihood -1.329889
[ Info: iteration 9, average log likelihood -1.328341
[ Info: iteration 10, average log likelihood -1.327234
[ Info: iteration 11, average log likelihood -1.326392
[ Info: iteration 12, average log likelihood -1.325707
[ Info: iteration 13, average log likelihood -1.325134
[ Info: iteration 14, average log likelihood -1.324656
[ Info: iteration 15, average log likelihood -1.324258
[ Info: iteration 16, average log likelihood -1.323927
[ Info: iteration 17, average log likelihood -1.323641
[ Info: iteration 18, average log likelihood -1.323379
[ Info: iteration 19, average log likelihood -1.323129
[ Info: iteration 20, average log likelihood -1.322900
[ Info: iteration 21, average log likelihood -1.322707
[ Info: iteration 22, average log likelihood -1.322549
[ Info: iteration 23, average log likelihood -1.322420
[ Info: iteration 24, average log likelihood -1.322311
[ Info: iteration 25, average log likelihood -1.322211
[ Info: iteration 26, average log likelihood -1.322109
[ Info: iteration 27, average log likelihood -1.321990
[ Info: iteration 28, average log likelihood -1.321845
[ Info: iteration 29, average log likelihood -1.321678
[ Info: iteration 30, average log likelihood -1.321488
[ Info: iteration 31, average log likelihood -1.321284
[ Info: iteration 32, average log likelihood -1.321064
[ Info: iteration 33, average log likelihood -1.320849
[ Info: iteration 34, average log likelihood -1.320661
[ Info: iteration 35, average log likelihood -1.320512
[ Info: iteration 36, average log likelihood -1.320401
[ Info: iteration 37, average log likelihood -1.320331
[ Info: iteration 38, average log likelihood -1.320291
[ Info: iteration 39, average log likelihood -1.320267
[ Info: iteration 40, average log likelihood -1.320252
[ Info: iteration 41, average log likelihood -1.320241
[ Info: iteration 42, average log likelihood -1.320234
[ Info: iteration 43, average log likelihood -1.320228
[ Info: iteration 44, average log likelihood -1.320224
[ Info: iteration 45, average log likelihood -1.320220
[ Info: iteration 46, average log likelihood -1.320218
[ Info: iteration 47, average log likelihood -1.320215
[ Info: iteration 48, average log likelihood -1.320214
[ Info: iteration 49, average log likelihood -1.320212
[ Info: iteration 50, average log likelihood -1.320211
â”Œ Info: EM with 100000 data points 50 iterations avll -1.320211
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.366592025015806 
â”‚     -1.3664888058659517
â”‚      â‹®                 
â””     -1.3202108833729451
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.320386
[ Info: iteration 2, average log likelihood -1.320232
[ Info: iteration 3, average log likelihood -1.319718
[ Info: iteration 4, average log likelihood -1.315660
[ Info: iteration 5, average log likelihood -1.303155
[ Info: iteration 6, average log likelihood -1.286329
[ Info: iteration 7, average log likelihood -1.274786
[ Info: iteration 8, average log likelihood -1.269647
[ Info: iteration 9, average log likelihood -1.267394
[ Info: iteration 10, average log likelihood -1.265985
[ Info: iteration 11, average log likelihood -1.264851
[ Info: iteration 12, average log likelihood -1.263899
[ Info: iteration 13, average log likelihood -1.263076
[ Info: iteration 14, average log likelihood -1.262283
[ Info: iteration 15, average log likelihood -1.261472
[ Info: iteration 16, average log likelihood -1.260705
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.260067
[ Info: iteration 18, average log likelihood -1.269742
[ Info: iteration 19, average log likelihood -1.264468
[ Info: iteration 20, average log likelihood -1.262554
[ Info: iteration 21, average log likelihood -1.261267
[ Info: iteration 22, average log likelihood -1.260294
[ Info: iteration 23, average log likelihood -1.259560
[ Info: iteration 24, average log likelihood -1.259048
[ Info: iteration 25, average log likelihood -1.258681
[ Info: iteration 26, average log likelihood -1.258391
[ Info: iteration 27, average log likelihood -1.258121
[ Info: iteration 28, average log likelihood -1.257850
[ Info: iteration 29, average log likelihood -1.257578
[ Info: iteration 30, average log likelihood -1.257306
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.257047
[ Info: iteration 32, average log likelihood -1.266914
[ Info: iteration 33, average log likelihood -1.261713
[ Info: iteration 34, average log likelihood -1.259791
[ Info: iteration 35, average log likelihood -1.258671
[ Info: iteration 36, average log likelihood -1.257953
[ Info: iteration 37, average log likelihood -1.257500
[ Info: iteration 38, average log likelihood -1.257261
[ Info: iteration 39, average log likelihood -1.257099
[ Info: iteration 40, average log likelihood -1.256933
[ Info: iteration 41, average log likelihood -1.256700
[ Info: iteration 42, average log likelihood -1.256360
[ Info: iteration 43, average log likelihood -1.255931
[ Info: iteration 44, average log likelihood -1.255501
[ Info: iteration 45, average log likelihood -1.255185
[ Info: iteration 46, average log likelihood -1.254998
[ Info: iteration 47, average log likelihood -1.254898
[ Info: iteration 48, average log likelihood -1.254843
[ Info: iteration 49, average log likelihood -1.254811
[ Info: iteration 50, average log likelihood -1.254792
â”Œ Info: EM with 100000 data points 50 iterations avll -1.254792
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3203857907187193
â”‚     -1.3202318168965088
â”‚      â‹®                 
â””     -1.2547915933941463
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.255016
[ Info: iteration 2, average log likelihood -1.254737
[ Info: iteration 3, average log likelihood -1.253303
[ Info: iteration 4, average log likelihood -1.236967
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     5
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.200281
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.179573
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      8
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.179390
[ Info: iteration 8, average log likelihood -1.192745
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     5
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.170433
[ Info: iteration 10, average log likelihood -1.182756
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      8
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.170403
[ Info: iteration 12, average log likelihood -1.183482
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.162855
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.185882
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     5
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.179613
[ Info: iteration 16, average log likelihood -1.167018
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚      8
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.154240
[ Info: iteration 18, average log likelihood -1.189507
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.169320
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.167830
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     5
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.173999
[ Info: iteration 22, average log likelihood -1.180628
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     5
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.170461
[ Info: iteration 24, average log likelihood -1.171164
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     14
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.155725
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.192070
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     5
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.181101
[ Info: iteration 28, average log likelihood -1.167782
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     5
â”‚     6
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.155410
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.177533
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.175357
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.172106
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     5
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.164722
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.174920
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     5
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.177628
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.173040
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.172961
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.172936
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.162578
[ Info: iteration 40, average log likelihood -1.186255
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     5
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.171421
[ Info: iteration 42, average log likelihood -1.171715
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.157142
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.181559
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     5
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.175590
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.163134
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     5
â”‚     6
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.160882
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.178086
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.177476
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.172947
â”Œ Info: EM with 100000 data points 50 iterations avll -1.172947
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2550157265157365
â”‚     -1.254736613754259 
â”‚      â‹®                 
â””     -1.1729467973316046
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.166179
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.158820
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     15
â”‚     16
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.153839
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     27
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.141797
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     14
â”‚     25
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.089842
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      8
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     16
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.080704
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.074888
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.057164
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚      9
â”‚     10
â”‚      â‹®
â”‚     13
â”‚     14
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.074546
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.076206
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.060459
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      8
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.052459
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.065848
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     25
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.051264
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚      9
â”‚     10
â”‚      â‹®
â”‚     13
â”‚     14
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.057321
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.058859
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      9
â”‚     10
â”‚      â‹®
â”‚     13
â”‚     14
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.058955
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      8
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     16
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.058921
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     14
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.055719
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.053104
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.062581
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.057860
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.057126
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      8
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.049130
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.071044
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     25
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.053950
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      8
â”‚      9
â”‚      â‹®
â”‚     13
â”‚     14
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.052390
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.063535
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     14
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.059456
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      8
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     16
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.060548
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.058121
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.046871
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.066682
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.058171
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.058155
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      8
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.050866
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.062455
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     25
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.044519
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚      9
â”‚     10
â”‚      â‹®
â”‚     24
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.047075
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.068990
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.061212
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      8
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     16
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.048972
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      9
â”‚     10
â”‚      â‹®
â”‚     14
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.046308
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.051516
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.055487
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.048566
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     14
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.041074
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     16
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.048962
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚      9
â”‚     10
â”‚      â‹®
â”‚     13
â”‚     14
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.042535
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     25
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.050653
â”Œ Info: EM with 100000 data points 50 iterations avll -1.050653
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.1661788654583598
â”‚     -1.1588204664330788
â”‚      â‹®                 
â””     -1.0506526067326591
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4112712774290943
â”‚     -1.4113596352640743
â”‚     -1.4112678554469325
â”‚     -1.4106135535448971
â”‚      â‹®                 
â”‚     -1.048962210623856 
â”‚     -1.0425351364792679
â””     -1.0506526067326591
32Ã—26 Array{Float64,2}:
 -0.00292207   0.1548       0.062672     0.0540536   -0.156131      0.056956    -0.0335434   -0.00675586  -0.0248084   -0.0010218   -0.185562    -0.0104657     0.127964    -0.108589     0.0275913   -0.00878336   -0.0389642    0.164089    -0.059516     0.0191389    0.176311     0.0122975    0.027656    -0.0713985   -0.0341576    0.212795  
  0.122852    -0.00850686  -0.0912076   -0.086486     0.00551106   -0.0662745   -0.0981512    0.148259    -0.0222489    0.0322746    0.0281543    0.11469       0.100756    -0.00701213   0.116086     0.0626663     0.0789274   -0.0333099   -0.087695    -0.0151306    0.0835607   -0.156571    -0.232917    -0.0582489   -0.164513    -0.0525015 
 -0.0973754    0.0309004    0.0338075    0.0640783    0.13919      -0.135517     0.0683811   -0.0930814    0.0889545   -0.212472    -0.135353    -0.128389      0.119596     0.0520496   -0.0236189   -0.0254276     0.0760321    0.0898957   -0.0122542    0.208909     0.0543428    0.0105633    0.161181    -0.124611     0.184259    -0.0541899 
 -0.193323    -0.144682    -0.034766     0.097362     0.0154349    -0.145589    -0.0207797    0.0879206    0.0569293   -0.00174557  -0.110918     0.00716052    0.0133781   -0.0506045    0.119542    -0.0386329    -0.0447993    0.0774903   -0.112027     0.125096     0.0605206    0.0696035   -0.0703385   -0.0410082    0.0338566    0.00335249
  0.0752914   -0.0843473   -0.142605     0.0380367    0.0380473    -0.100677     0.0329362   -0.0893931   -0.00605003  -0.0311387   -0.0178667    0.0566925     0.152835     0.0431471    0.187692     0.0534292     0.178862     0.135192    -0.0493642    0.0206433   -0.0831736   -0.159927    -0.12635     -0.00566479   0.0839292   -0.0809423 
  0.0286879    0.0118852    0.0178144    0.032018     0.0248127    -0.0479966    0.0206685   -0.0347497   -0.0522758   -0.0386763    0.0387588   -0.102329      0.113057    -0.0260475    0.07565     -0.0249987    -0.0469722   -0.0356419   -0.0158568    0.0191136    0.0480931    0.0744149   -0.0758337    0.0856964    0.0483193   -0.0280975 
 -0.112239    -0.178653    -0.0908501   -0.193433    -0.0589428    -0.0655621   -0.00925436   0.167206     0.17535     -0.0743644   -0.0215011   -0.00463719    0.00707427   0.130396     0.055797     0.0318249     0.13712     -0.138088    -0.189321    -0.152657    -0.214798     0.0682222   -0.12011      0.0752806    0.169059    -0.0609146 
 -0.0640192   -0.00181745   0.150231     0.0582557    0.0172015     0.0199311    0.0178273    0.0367351   -0.126743    -0.018197     0.0452134    0.074835     -0.0989503    0.0810731    0.0448744    0.0658701     0.0408898   -0.0108089    0.0450878   -0.0755548    0.0436185    0.236808    -0.095485     0.0847446   -0.0833404   -0.152862  
 -0.588909    -0.0607011    0.0439714   -0.256245     0.0378031     0.0644007   -0.00303176  -0.026604     0.376076    -0.11823     -0.120727    -0.0192805     0.012219    -0.0648624    0.018437    -0.0503196    -0.032789    -0.0655646   -0.274557     0.0429094   -0.0776726   -0.304809     0.0243067   -0.152635     0.0802332    0.00822128
  0.365288    -0.141787    -0.117213    -0.0756688    0.0405379     0.0649456   -0.0454351    0.0642153   -0.179704    -0.0521653    0.0305078   -0.0124033    -0.100964    -0.00575232   0.0779808   -0.080829      0.0722674    0.106513    -0.132685    -0.041536    -0.128101     0.346563     0.0298474   -0.153338     0.0967906   -0.0376926 
 -0.0221731    0.0361744   -0.2096      -0.0963967    0.0746089    -0.0066396   -0.29877      0.00621147  -0.0459642    0.0752813    0.0379476   -0.418155      0.0780963   -0.135375     0.154776    -0.170472     -0.00847979  -0.445176     0.141699    -0.411011     0.0103091   -0.00562036   0.0323268    0.0330597   -0.0566909    0.0902252 
  0.0801378    0.0220616   -0.182234    -0.118604     0.140019     -0.00633589  -0.3018       0.0243566    0.0264149    0.0651186    0.0229982    0.351657      0.0779054   -0.14308     -0.0387811   -0.0558932    -0.00789634   0.291982     0.19014      0.795183    -0.0761434   -0.0186652   -0.0284906    0.0388299   -0.109032     0.0663484 
  0.0770673   -0.0342909    0.0706774   -0.141178    -0.176268      0.03172      0.00587218  -0.11584     -0.109996     0.0831144   -0.159822    -0.0743711    -0.0802357   -0.0900808    0.113138    -0.254752      0.0284413   -0.0326774    0.0427971    0.069739    -0.0606353   -0.0693429   -0.00597135  -0.0726463    0.0602997   -0.0633066 
  0.0933656    0.0600875   -0.00906621   0.0563467    0.161608     -0.163483     0.0688938    0.134115     0.1411      -0.090921     0.0548336   -0.00136781   -0.198972     0.0638807   -0.0640573    0.0746506     0.166628    -0.0686099    0.172337    -0.0583704    0.0112468    0.00892367  -0.0295316   -0.131042    -0.12228      0.0615138 
 -0.123682    -0.0213069    0.17003     -0.0239717   -0.137061     -0.0641068    0.00372566  -0.00472188  -1.52101      0.166804    -0.0437886    0.129195      0.0629353    0.0377282    0.024611    -0.0187579     0.0426646   -0.0768216   -0.0298903    0.175541    -0.0857621   -0.0680309    0.071519     0.0613999    0.0661962   -0.107222  
 -0.202314    -0.0224686    0.119514    -0.0601384   -0.12971      -0.0417817   -0.0272468   -0.0341528    1.51168      0.0481682   -0.0524479    0.00119686    0.0494909   -0.0907423    0.234248    -0.00544894    0.0426978   -0.0466322   -0.025054     0.178511    -0.0139133   -0.0529915    0.0683691    0.0433867    0.0356907   -0.200684  
 -0.215584     0.0753508   -0.069184    -0.0762558   -0.218957     -0.0948213    0.0764892   -0.202511    -0.142802    -0.0157656   -0.025617     0.000579262   0.171006    -0.197786    -0.104926    -0.0372374    -0.091875     0.296706    -0.0664378    0.0309468    0.0257237   -0.183413     0.0157165   -0.161501    -0.0383663    0.114659  
  0.438345     0.208337    -0.0927891    0.0578744   -0.159462     -0.0637804    0.0363869   -0.0298136   -0.0924301   -0.0220247   -0.0307885   -0.0838394     0.0601032   -0.105135    -0.0488076    0.0290994    -0.132995     0.301916    -0.019424    -0.0840566   -5.79704e-5  -0.160302     0.0249919    0.00710512  -0.134615     0.0999311 
 -0.0105342    0.0792564    0.0698869    0.0820551    0.0141984    -0.069838    -0.0906461    0.102084     0.0432549   -0.0196174   -0.0575553   -0.0198495     0.131392     0.147523    -0.00637156   0.110112     -0.0278836   -0.0515748   -0.0623451    0.0136255   -0.00639171   0.0704547   -0.025061     0.0191423    0.0852447    0.165093  
  0.0242922    0.0664526    0.00492296   0.0396804   -0.0152681     0.227249     0.0721815   -0.0885383   -0.0879392    0.0538557   -0.163175     0.0858051    -0.0592426   -0.162939     0.0163051    0.122815     -0.147453     0.0114014   -0.0859348   -0.14245     -0.0571806    0.0825004    0.0065886    0.131237     0.144807     0.0194253 
  0.126411     0.189245     0.0213594   -0.00877724   0.0453479     0.032219     0.0365507    0.00883235   0.0315642    0.0305335    0.101396     0.0764828    -0.0124491   -0.155108    -0.0583515   -0.134377      0.16517      0.240252    -0.022671    -0.0179628    0.10483      0.0724912    0.0220668    0.00573608   0.0260859   -0.104707  
  0.01413     -0.172229    -0.0832277   -0.0446748    0.000849452  -0.0631196    0.0358222    0.117641     0.214205    -0.0786251   -0.02785     -0.0754512     0.0692732    0.0392374   -0.105455    -0.0812422     0.058479     0.0180418   -0.0453032    0.105787     0.101874    -0.0862355    0.0930981    0.055077     0.234498     0.0771518 
  0.0327004    0.0364691   -0.0659495   -0.0145809    0.143545      0.0719637    0.0805153   -0.0302565    0.13731     -0.0265802    0.0474331   -0.047895      0.105693     0.109709    -0.015099     0.0535779     0.0430478   -0.0624081   -0.0248685   -0.0159908    0.0827924   -0.0997332    0.0379089    0.0714205   -0.0734047    0.114423  
  0.00842792   0.0744846   -0.307143    -0.08079      0.0188107     0.172833    -0.0553539   -0.0419865    0.00917834   0.0593956   -0.117093     0.140839      0.135848     0.0749976   -0.106904    -0.000808196   0.0282564    0.285171     0.125658    -0.0281422    0.00383793   0.142057     0.0408396    0.123683     0.0106185    0.0111015 
 -0.0468773    0.00516254   0.0252229    0.114029    -0.0502225    -0.134048     0.1945       0.126576     0.208745    -0.0721116   -0.0290681    0.0707923     0.108412     0.0613724    0.022978    -0.0583929    -0.0576238   -0.0765072   -0.0919805    0.13191     -0.102988    -0.110331    -0.0803793    0.0507324   -0.141904    -0.121587  
 -0.0896693   -0.029253     0.0133848   -0.0501238    0.0288359    -0.0202994   -0.0175695    0.0326668   -0.0241585   -0.0215901   -0.00332325  -0.0607636    -0.141342     0.0461159   -0.0714715   -0.117489      0.096397     0.0173384    0.0410118    0.00259367  -0.0537769   -0.107661     0.0174269    0.0197286   -0.144283    -0.0228728 
  0.0749833   -0.0384865    0.0510993    0.0345628    0.0053002    -0.0583708    0.0530897   -0.219529    -0.0374668    0.0578204   -0.0825564   -0.0209379     0.00947485   0.0331644   -0.0239047   -0.0033769     0.194303    -0.00200697  -0.14414     -0.0634628   -0.0932365   -0.223874    -0.199318    -0.0952579   -0.00523978  -0.0451227 
 -0.0301175    0.169619    -0.00703785   0.00465304  -0.0494173     0.0483088    0.156167    -0.0406854   -0.0142708   -0.0338649   -0.185714     0.0466737    -0.00688815   0.084561    -0.12159     -0.0540463    -0.0918489    0.08141      0.0556595   -0.0586858   -0.0206341    0.027497     0.104101     0.0803225    0.0566733   -0.127565  
 -0.0423739   -0.149213    -0.0323951   -0.00398531  -0.263148      0.0625658    0.115027     0.082585    -0.170971     0.136675     0.0512904    0.0898072    -0.116767    -0.0525606    0.0381301    0.081881      0.13742     -0.042313    -0.0250689   -0.0862571   -0.113054     0.0796234    0.210044     0.148221    -0.0355656    0.00683298
  0.0627775    0.240626    -0.0283632   -0.0685207   -0.169635     -0.0883665    0.118596    -0.0298705    0.100601     0.0458032   -0.0273164   -0.114041      0.0652056    0.00730625  -0.0354344    0.0159983     0.0615113    0.0754038    0.0399731   -0.0280575    0.118759     0.0301745    0.0129599   -0.0172438   -0.083761    -0.0530845 
 -0.0320175    0.175011     0.0185499   -0.161394     0.0119371     0.0476603   -0.1136       0.132906    -0.0913331   -0.00890852  -0.0176296   -0.0100817    -0.00289548  -0.020628    -0.0636609   -0.00136627    0.0270063   -0.0392505   -0.00667616  -0.114588     0.0813952    0.159029     0.229503    -0.0702429   -0.112728     0.00909878
  0.131749    -0.178766     0.104848     0.0570501    0.150821      0.0618533   -0.0446314    0.0531096   -0.00385773  -0.111167    -0.0732495    0.0426996     0.0588448    0.231111    -0.00555755  -0.0807408     0.0828719    0.0652868   -0.00538562  -0.0186028   -0.109366    -0.151956     0.103136     0.113291    -0.0493532    0.0533581 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     24
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.052933
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.028952
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      8
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     24
â”‚     25
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.034951
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    15-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      9
â”‚     10
â”‚      â‹®
â”‚     28
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.025623
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      8
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     14
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.043568
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.019347
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      8
â”‚      9
â”‚      â‹®
â”‚     28
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.038808
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.029834
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚      9
â”‚     10
â”‚      â‹®
â”‚     25
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.024649
kind diag, method kmeans
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.023545
â”Œ Info: EM with 100000 data points 10 iterations avll -1.023545
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.892433e+05
      1       6.915060e+05      -1.977373e+05 |       32
      2       6.470225e+05      -4.448354e+04 |       32
      3       6.328305e+05      -1.419196e+04 |       32
      4       6.252155e+05      -7.615036e+03 |       32
      5       6.198696e+05      -5.345906e+03 |       32
      6       6.165100e+05      -3.359563e+03 |       32
      7       6.144259e+05      -2.084126e+03 |       32
      8       6.130112e+05      -1.414710e+03 |       32
      9       6.119509e+05      -1.060244e+03 |       32
     10       6.111074e+05      -8.435796e+02 |       32
     11       6.103273e+05      -7.800244e+02 |       32
     12       6.095268e+05      -8.005623e+02 |       32
     13       6.088255e+05      -7.012920e+02 |       32
     14       6.084003e+05      -4.251675e+02 |       32
     15       6.081000e+05      -3.002643e+02 |       31
     16       6.077596e+05      -3.404280e+02 |       31
     17       6.074116e+05      -3.479918e+02 |       30
     18       6.071242e+05      -2.874370e+02 |       32
     19       6.069460e+05      -1.782184e+02 |       32
     20       6.068110e+05      -1.349572e+02 |       31
     21       6.067040e+05      -1.070467e+02 |       32
     22       6.065896e+05      -1.143535e+02 |       31
     23       6.064897e+05      -9.993901e+01 |       32
     24       6.063623e+05      -1.273960e+02 |       31
     25       6.060951e+05      -2.671986e+02 |       32
     26       6.054611e+05      -6.339626e+02 |       32
     27       6.047842e+05      -6.768626e+02 |       31
     28       6.044316e+05      -3.526514e+02 |       32
     29       6.043389e+05      -9.274123e+01 |       32
     30       6.043091e+05      -2.977458e+01 |       31
     31       6.042943e+05      -1.476852e+01 |       31
     32       6.042849e+05      -9.429534e+00 |       29
     33       6.042782e+05      -6.720975e+00 |       25
     34       6.042720e+05      -6.117926e+00 |       28
     35       6.042679e+05      -4.114550e+00 |       24
     36       6.042656e+05      -2.295069e+00 |       23
     37       6.042636e+05      -2.043561e+00 |       22
     38       6.042620e+05      -1.550600e+00 |       18
     39       6.042603e+05      -1.730072e+00 |       13
     40       6.042593e+05      -1.056190e+00 |       14
     41       6.042587e+05      -5.452659e-01 |        7
     42       6.042580e+05      -6.789959e-01 |       12
     43       6.042565e+05      -1.520546e+00 |       12
     44       6.042555e+05      -9.916528e-01 |       14
     45       6.042547e+05      -7.756196e-01 |       18
     46       6.042540e+05      -7.914983e-01 |       12
     47       6.042531e+05      -8.691411e-01 |       12
     48       6.042524e+05      -6.419201e-01 |       10
     49       6.042521e+05      -3.368705e-01 |       12
     50       6.042518e+05      -3.395591e-01 |        8
K-means terminated without convergence after 50 iterations (objv = 604251.7643512285)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.314123
[ Info: iteration 2, average log likelihood -1.280867
[ Info: iteration 3, average log likelihood -1.248084
[ Info: iteration 4, average log likelihood -1.211680
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.165511
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.134478
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚     15
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.099793
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.107349
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚     11
â”‚     13
â”‚     18
â”‚     21
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.057433
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     25
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.108326
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     27
â”‚     28
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.118003
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.100971
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚     20
â”‚     21
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.042152
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     15
â”‚     18
â”‚     28
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.060340
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     13
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.117245
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚     20
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.076305
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.081035
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      8
â”‚     18
â”‚     24
â”‚     28
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.033648
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚     11
â”‚     25
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.067509
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     13
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.115872
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     24
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.071853
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      8
â”‚     15
â”‚     18
â”‚     20
â”‚     27
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.053364
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     13
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.093977
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚     11
â”‚     21
â”‚     24
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.071669
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      8
â”‚     18
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.105338
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     20
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.077851
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚     24
â”‚     25
â”‚     27
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.042147
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      8
â”‚     13
â”‚     21
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.097345
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     18
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.100429
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     15
â”‚     20
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.076176
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     28
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.052045
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚     13
â”‚     18
â”‚     21
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.083157
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.096825
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     11
â”‚     20
â”‚     27
â”‚     28
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.049061
[ Info: iteration 35, average log likelihood -1.136670
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     13
â”‚     18
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.049864
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚     15
â”‚     21
â”‚     25
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.043145
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.106319
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.101407
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     18
â”‚     24
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.057930
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     13
â”‚     28
â”‚     29
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.039012
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚     11
â”‚     20
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.094134
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.106793
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     15
â”‚     18
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.049167
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚     13
â”‚     20
â”‚     21
â”‚     25
â”‚     27
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.072242
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.101001
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.085104
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      8
â”‚     18
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.080522
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     21
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.072173
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚     13
â”‚     18
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.047509
â”Œ Info: EM with 100000 data points 50 iterations avll -1.047509
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0271137    0.0292649   -0.19627     -0.106893     0.106411     -0.00651539  -0.300138     0.0149186   -0.0115738    0.0702439     0.0306801   -0.0465537    0.0779658    -0.138937     0.0620875   -0.115182     -0.00834885  -0.089129      0.165029     0.171537    -0.031193     -0.0120093     0.00316385   0.035964    -0.0816534    0.0785992 
  0.079555    -0.0328376    0.0737803   -0.148161    -0.178852      0.0278949    0.00163236  -0.124302    -0.135366     0.0773701    -0.162945    -0.0786487   -0.0967338    -0.0587616    0.132786    -0.267277      0.0245635   -0.0355659     0.0473968    0.0657597   -0.0549678    -0.0518725    -0.00854987  -0.061442     0.060178    -0.0633198 
  0.0265207   -0.0704436   -0.00190045   0.0885083   -0.000282433  -0.125119     0.12013      0.0306665   -0.192048    -0.0147474    -0.00119567  -0.0849808    0.21016      -0.00426001   0.238969     0.0335131    -0.0427551   -0.0641175    -0.00464875  -0.179402    -0.0968683     0.165958     -0.179305     0.0462401   -0.113305    -0.0214903 
 -0.102638     0.115482     0.112011    -0.00950957   0.0824458     0.0564652    0.0295139   -0.12474     -0.0899051   -0.0646895    -0.0484457   -0.0978316    0.123215     -0.0566106    0.0249618   -0.0273066    -0.048959    -0.0726284     0.0514456    0.106981     0.263816     -0.014422     -0.0209276    0.164821     0.130288    -0.104165  
 -0.114578    -0.177817    -0.0902665   -0.196668    -0.0599236    -0.0665457   -0.00476051   0.167593     0.176465    -0.0740616    -0.025801    -0.00424889   0.000321595   0.129864     0.0544455    0.0307584     0.136067    -0.1375       -0.194355    -0.153256    -0.213716      0.0633503    -0.122414     0.0753772    0.168797    -0.0612871 
 -0.027501     0.170888     0.0220168   -0.160644     0.0122613     0.0475282   -0.115916     0.131595    -0.090169    -0.00502087   -0.0219103   -0.00909214  -0.00302552   -0.0189283   -0.0641279   -0.000875056   0.0315149   -0.0373796    -0.00694427  -0.114698     0.0817805     0.161049      0.233773    -0.0690551   -0.111743     0.0135199 
  0.0246559    0.0656275    0.00495825   0.0389049   -0.0142391     0.233904     0.0676174   -0.0927439   -0.0874006    0.0550566    -0.173377     0.0852467   -0.0621236    -0.168502     0.01605      0.12195      -0.148865     0.0188315    -0.0860246   -0.143311    -0.0555145     0.0820267     0.00640535   0.13554      0.14985      0.0194832 
  0.141846    -0.20526      0.170489     0.0513305    0.172078      0.0770423   -0.0475764    0.0276894   -0.00876484  -0.127306     -0.121068     0.0357835    0.0714155     0.284977    -0.0281866   -0.132703      0.109833     0.0698298    -0.0213212   -0.0326658   -0.114801     -0.19625       0.136382     0.147321     0.00142285   0.0501966 
  0.0833023    0.0512261   -0.0871889    0.185135    -0.11979      -0.0469949   -0.0972039    0.152793    -0.00622488  -0.0211415     0.159831     0.0749741    0.0198073    -0.184999     0.10543      0.134422     -0.062739     0.0375896     0.129359     0.217239    -0.0538638     0.0872656    -0.132533    -0.0584378   -0.180674     0.0412602 
 -0.0129293    0.0777493    0.0711638    0.0823984    0.0171474    -0.0698326   -0.0911409    0.102749     0.0442224   -0.0187808    -0.0595601   -0.0200217    0.133264      0.143924    -0.00542387   0.111017     -0.0310579   -0.0528346    -0.0645499    0.0162691   -0.00391742    0.069689     -0.0248235    0.0218324    0.0861874    0.162807  
 -0.0478215    0.00548064   0.0246277    0.115134    -0.0656049    -0.132168     0.195029     0.124648     0.204303    -0.0716831    -0.0319808    0.0717416    0.107535      0.0616833    0.0236961   -0.0582891    -0.0558301   -0.0732147    -0.0925452    0.130685    -0.098621     -0.113355     -0.0816579    0.0507429   -0.141043    -0.11926   
  0.0539468    0.130394    -0.0786477   -0.0271762   -0.197176     -0.0858766    0.0597788   -0.15216     -0.12366     -0.014342     -0.0332227   -0.0268561    0.127905     -0.157289    -0.0858224   -0.0221441    -0.106983     0.299065     -0.0534249   -0.0262434    0.0211278    -0.183203      0.0196023   -0.0933644   -0.0754215    0.11001   
  0.00524714   0.0717645   -0.315328    -0.0806683    0.0132854     0.175362    -0.0594046   -0.0422764    0.0110731    0.0607649    -0.123463     0.145788     0.131103      0.0733827   -0.110581    -0.00174182    0.0370277    0.28651       0.124024    -0.025559     0.00573309    0.144263      0.0440289    0.12872      0.0119371    0.0111721 
  0.137043    -0.0389776   -0.0216384    0.0223978    0.00636993   -0.0807599   -0.0623082   -0.0329786    0.0944691   -0.0306438     0.10718     -0.135953     0.0624505     0.0530567   -0.019416    -0.0791521    -0.0239423    0.0470533    -0.126254     0.0308679    0.00298545    0.0839232     0.0217235    0.0430144    0.119393     0.0683371 
  0.0561462   -0.0114393    0.0572888    0.0301892   -0.00304018   -0.0629743    0.0679131   -0.190157    -0.034352     0.0583766    -0.095536    -0.0147768    0.00497215    0.0298202   -0.0330322   -0.0127334     0.168144     0.010814     -0.128869    -0.0585434   -0.0809995    -0.180292     -0.147797    -0.08136      0.00612377  -0.0570166 
  0.126006     0.189484     0.0225637   -0.00781314   0.0436241     0.0294839    0.0369572    0.00668626   0.0314053    0.0302583     0.10186      0.0736363   -0.0125684    -0.155631    -0.0576268   -0.133853      0.165039     0.239724     -0.02242     -0.0187941    0.10518       0.0730075     0.022041     0.00856692   0.0261877   -0.101533  
  0.0354115    0.0689759   -0.0942557   -0.11152      0.113396      0.131411     0.252217    -0.00809607   0.096556    -0.0711554     0.128331    -0.0164187    0.0491281     0.128302     0.0144119    0.0921036    -0.102876    -0.178187     -0.0426265   -0.105688     0.0164797    -0.132257      0.0287669    0.0771238   -0.0324829    0.0445274 
 -0.165247    -0.0224667    0.143916    -0.0444398   -0.133764     -0.0527394   -0.0137023   -0.0196637    0.0137549    0.10764      -0.0466492    0.066958     0.0548492    -0.023978     0.131936    -0.0112541     0.0426264   -0.0602079    -0.0272484    0.176538    -0.0467395    -0.0597985     0.0697009    0.0524006    0.0524321   -0.153624  
  0.0745181   -0.0848919   -0.140594     0.0370811    0.0381219    -0.0999424    0.0335722   -0.0899168   -0.00308626  -0.0300602    -0.0191823    0.0566345    0.152441      0.0434001    0.188601     0.053367      0.177269     0.136157     -0.0514377    0.021534    -0.0843189    -0.162972     -0.12443     -0.0049149    0.0845318   -0.0809685 
  0.0248971   -0.018049     0.0311452   -0.133551     0.00263293   -0.0276634    0.00474583   0.0468967   -0.0478155    0.0377243    -0.119972    -0.0272785   -0.0267142    -0.187334    -0.00790543  -0.132862      0.0755906   -0.0261296    -0.00156473   0.0539609    0.0263327    -0.0389492    -0.0254803   -0.101091     0.0156787    0.00600874
 -0.179783    -0.146859    -0.0136295    0.137046    -0.00404675   -0.0936749   -0.0285191    0.0681277    0.0705737    0.000682957  -0.13491      0.0120832    0.0296344    -0.0809603    0.163168    -0.0385293    -0.0546772    0.0887104    -0.0999207    0.128645     0.0872439     0.103788     -0.0581102   -0.0663807    0.0240949    0.023893  
  0.122053    -0.0115216   -0.0904831   -0.0978899    0.00600006   -0.0661047   -0.0990369    0.14336     -0.0225585    0.032806      0.0269492    0.114387     0.102218      0.00418368   0.11166      0.0595676     0.0774356   -0.0284988    -0.099247    -0.0173864    0.0841429    -0.163257     -0.225439    -0.0566424   -0.155488    -0.0535112 
 -0.100705     0.0191033    0.0285292    0.0653247    0.135147     -0.13528      0.0653529   -0.0828498    0.0877838   -0.201779     -0.139248    -0.123933     0.113176      0.0469905   -0.016079    -0.0279056     0.0709007    0.0922316    -0.0153313    0.211256     0.053688      0.000997384   0.150792    -0.118546     0.180989    -0.0508956 
 -0.0720053    0.0128772    0.217105    -0.00144869   0.10722       0.0368596    0.0558318    0.0195807   -0.179452    -0.0374036     0.00223876   0.103174    -0.145597      0.105813     0.0436803    0.0354462     0.0963718    0.000980684   0.00557321  -0.19519      0.00797278    0.303136     -0.0924603    0.322886    -0.0517093   -0.347168  
 -0.0310609    0.221063     0.0820883   -0.0256157   -0.214023      0.0729455   -0.058614    -0.00747393   0.00285618  -0.000665069  -0.216672    -0.0560146    0.106664     -0.0557609   -0.0741562   -0.0212971    -0.0501075    0.19295      -0.064506     0.01352      0.271076     -0.0241147     0.0544812   -0.257947    -0.0239638    0.392529  
 -0.0916565   -0.0298758    0.0164903   -0.055863     0.0344965    -0.0196842   -0.0176293    0.034818    -0.0208816   -0.0222196    -0.00877385  -0.0643205   -0.146721      0.046497    -0.0762557   -0.1203        0.0982219    0.0221959     0.0374016    0.00228827  -0.0476794    -0.116927      0.0214053    0.0196401   -0.141491    -0.0231653 
 -0.0445807   -0.150927    -0.0330607   -0.00226117  -0.250419      0.0578607    0.114045     0.0825221   -0.169529     0.134809      0.0489731    0.0898188   -0.110781     -0.0535013    0.0381238    0.0803887     0.134736    -0.0423857    -0.0261164   -0.0795137   -0.114003      0.0764993     0.2074       0.14417     -0.0318497    0.00764211
  0.0588333    0.258711    -0.0213098   -0.0795408   -0.182039     -0.0979895    0.146397    -0.0378617    0.0995023    0.0607218    -0.0363101   -0.120995     0.0666644     0.0115873   -0.0441139    0.00603448    0.0638412    0.0778049     0.0369841   -0.0485592    0.131422      0.0248813     0.0154482   -0.0125197   -0.0788056   -0.0709899 
 -0.022767     0.155304    -0.0528397    0.00654762  -0.041026      0.0669125    0.150846    -0.028647    -0.00916585  -0.0586808    -0.177604     0.0508755   -0.00719773    0.110231    -0.123947    -0.055498     -0.118915     0.0831349     0.0812393   -0.0573927   -0.0320597     0.0359138     0.100999     0.101918     0.0588625   -0.123351  
  0.0974476    0.0595744   -0.0100732    0.0632479    0.166069     -0.154905     0.0707409    0.128199     0.163331    -0.0802639     0.0588289   -0.0015321   -0.190146      0.0486841   -0.0732875    0.0754724     0.166267    -0.0670798     0.163731    -0.049598     0.000565441  -0.00233987   -0.0323177   -0.131225    -0.120977     0.0569133 
  0.0221788   -0.0832665   -0.0638834    0.0125268    0.0863513    -0.0185145   -0.014078     0.0378834    0.190904    -0.0338031    -0.0265319   -0.0788672    0.112175      0.0720068   -0.0755336   -0.0306816     0.114003     0.024493     -0.030405     0.082239     0.117015     -0.0839789     0.0661248    0.060346     0.0599228    0.123566  
 -0.109713    -0.115161    -0.0406748   -0.165993     0.041195      0.0642965   -0.0270055    0.0134824    0.0796468   -0.08159      -0.0448026   -0.0193742   -0.0435124    -0.0319327    0.0479185   -0.0676134     0.0243216    0.0192281    -0.20819     -0.00672282  -0.107154      0.0329846     0.0262987   -0.152491     0.0899383   -0.0240342 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     15
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.085122
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     15
â”‚     20
â”‚     24
â”‚     27
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.035046
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     11
â”‚     15
â”‚      â‹®
â”‚     29
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.002415
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     11
â”‚     13
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.049800
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      8
â”‚     11
â”‚     15
â”‚     20
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.035854
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     11
â”‚     15
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.011547
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     11
â”‚     15
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.045462
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     13
â”‚     15
â”‚     24
â”‚     28
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.024353
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.013385
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     15
â”‚     24
â”‚     25
â”‚     27
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.047522
â”Œ Info: EM with 100000 data points 10 iterations avll -1.047522
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.028892     0.0182239    -0.130533     0.0558134   -0.00368296   -0.121133      0.0134944   -0.101466     -0.041538    -0.187564     -0.138894    -0.0703685  -0.0564252    0.0424056    -0.0577471   -0.0695974   -0.102676   -0.163767    -0.0934434  -0.0461309   -0.0696378   -0.0507987    -0.0492228    -0.188892    -0.155574     0.0230767 
  0.0755266   -0.0229406     0.0613333   -0.0222859    0.103801     -0.0922132    -0.0558603    0.136437      0.00331572  -0.0419287    -0.0410238    0.127144   -0.245973     0.0016344     0.0178308    0.0354092    0.107554   -0.106986    -0.119892    0.167381    -0.0492263    0.00525528    0.0869278     0.0799072    0.160078     0.103373  
  0.0556448   -0.271274      0.0970277    0.147143    -0.00452687    0.0557235     0.0043873   -0.121132      0.0276933   -0.0196575     0.207256    -0.038733    0.0185774    0.0948214     0.0255342   -0.0942088    0.157117    0.0284674    0.0166395  -0.0548058   -0.0516113   -0.0724099    -0.0996146    -0.0612527    0.0815141   -0.0543941 
 -0.0192409   -0.0261549    -0.100186     0.078689     0.0512472     0.104577     -0.0250544    0.121589     -0.181776    -0.110908      0.110908     0.21481    -0.0369484    0.0569472     0.00986947  -0.0516073   -0.036086   -0.0104459    0.0621665   0.0174305   -0.025042     0.0775065     0.0759844    -0.0397841    0.0942693    0.0164866 
 -0.0216518   -0.000747222   0.0916701   -0.00324818  -0.0931868     0.116491     -0.0317499    0.0957677     0.0137995   -0.00790272   -0.0402111   -0.0257619   0.00595056   0.194665      0.0797241   -0.0557477    0.0532599  -0.0619678   -0.140483    0.148066     0.0805866   -0.0465808    -0.0309231     0.0434966    0.0697985   -0.200774  
  0.0342383    0.0406114    -0.091379     0.0798001    0.268484     -0.0354853     0.030469     0.0187463    -0.0597973   -0.0348775     0.013258     0.144138    0.0521701   -0.00820863    0.0865062   -0.0659701   -0.0728963  -0.074455     0.172398    0.173844     0.0366646   -0.00948865   -0.000183956   0.0565708   -0.192201     0.00940447
  0.0291097    0.0946376     0.0234122   -0.218045    -0.0551476    -0.0917253     0.116386    -0.0021053     0.0377965    0.064728     -0.0852888   -0.0556713  -0.123806    -0.0957487     0.0956107    0.0347556   -0.163424    0.0480137   -0.162304   -0.0280202   -0.00879431   0.0331892     0.000918325   0.00885194   0.0082415    0.0806405 
 -0.0191496    0.0231639    -0.107962    -0.222943     0.0176362    -0.0697497     0.00653148   0.217198      0.0720809    0.0356282    -0.0568124   -0.155906   -0.17719     -0.155712      0.09056     -0.0197438   -0.0895428   0.0230527    0.063545   -0.0435655    0.0335239    0.101194      0.157728      0.109026     0.00371831   0.0832324 
  0.126406    -0.0802188    -0.0254849    0.0148826   -0.00727457   -0.230551      0.00722743  -0.12527      -0.105687    -0.0454856     0.041368    -0.0343812  -0.0168968    0.013891     -0.168774     0.0881528    0.0181038  -0.0065242   -0.0619129  -0.0574785    0.125808     0.0293775    -0.145877     -0.00518256   0.0264462   -0.00828715
  0.0850125    0.221191     -0.0679071   -0.0839206   -0.0406644    -0.148656      0.101852     0.067104      0.0137808   -0.0464047    -0.097061     0.0178181  -0.00963856  -0.0587776    -0.0416562    0.156699     0.112605   -0.0798109    0.12273    -0.0984767    0.0390621   -0.025377      0.0228574    -0.0146402    0.0181947   -0.120299  
 -0.0657454   -0.00847115    0.0416257   -0.0478069    0.0561927    -0.129881      0.0646971   -0.0398955    -0.138678     0.103875      0.11305     -0.0777367  -0.14004     -0.0556293    -0.0414523    0.219424     0.0152475  -0.108562     0.0188159  -0.073071    -0.0905986    0.00823144    0.114704      0.00616596   0.0810755   -0.0832365 
  0.104098    -0.00827013   -0.100195     0.0429146   -0.015537     -0.0008659     0.0153163   -0.0115493     0.0403191    0.173449     -0.0315288   -0.028655   -0.0314137   -0.0488466     0.055495    -0.133232     0.0546349  -0.113307     0.267082   -0.0386968   -0.0765638    0.000133917  -0.0113741    -0.0994118   -0.194563    -0.139692  
 -0.01635      0.176183      0.184316     0.0662609   -0.0934338     0.085295     -0.0718189   -0.268725     -0.0351393   -0.088505     -0.0787761    0.0945339  -0.0931448    0.0829573    -0.227993    -0.0994374    0.0780188  -0.0716878   -0.0347541  -0.0735977    0.206762     0.132799     -0.0380624    -0.100203     0.0536496    0.123412  
 -0.209971     0.0295424    -0.0643845   -0.131999     0.0628804    -0.100245      0.0326598   -0.0380435    -0.0766559    0.146144     -0.0174213    0.0645138   0.0350773    0.0071404     0.0354551    0.0816819    0.0852444  -0.0906006   -0.138885   -0.251339     0.124926    -0.0595547    -0.0493504    -0.12254     -0.0665058   -0.125184  
 -0.0277503    0.0618066    -0.0558362   -0.107306    -0.051435     -0.00598863    0.0509583   -0.00147231    0.103684    -0.0476975     0.0692713   -0.152357    0.00217908  -0.164498     -0.0687217   -0.0920437    0.0861209   0.19077      0.116648   -0.280449    -0.102113     0.0542848     0.0499823     0.188291    -0.113112     0.0659054 
 -0.00277628   0.141261      0.0441018   -0.073011    -0.0786138     0.0350262     0.0309933   -0.0300112    -0.0415774   -0.0146929     0.00128517  -0.134652    0.0519833    0.0413377     0.160694     0.139145    -0.130934    0.0327874   -0.130024   -0.100914     0.0662134   -0.248719     -0.0719063    -0.24134     -0.0637214   -0.137841  
  0.0917618   -0.115896      0.0159231    0.0322026    0.0650749    -0.0301537     0.0651113    0.152889      0.187047     0.126312      0.0903985   -0.0852557  -0.0104757    0.059617     -0.139444    -0.0626575   -0.0320858   0.0262937   -0.135794    0.100044    -0.0257872   -0.145352      0.0143215    -0.0329091    0.120702     0.040868  
 -0.0023182   -0.0160253     0.0576378    0.0432414   -0.0453429    -0.174954      0.0497578    0.0139609    -0.146791    -0.0383044    -0.0298564   -0.203159   -0.145408     0.0127816    -0.0210549   -0.0548975   -0.0843852  -0.0909282    0.032005    0.0129809   -0.0558319   -0.0839821     0.0227666     0.0627794    0.0790217   -0.323605  
 -0.121026     0.02142      -0.201808    -0.11579     -0.12146       0.143795     -0.0108365    0.0170032     0.0790152    0.0706094    -0.0180692    0.154617   -0.0863063    0.102825      0.0972513    0.0258626   -0.105039   -0.0124821   -0.115889    0.11396      0.0934733    0.0487036     0.0422965     0.0457062    0.0790798    0.0879723 
  0.239899    -0.11287      -0.0627129   -0.0298226   -0.0719159    -0.13068       0.0614611    0.117528     -0.0757201    0.00914096    0.00115014   0.0290135  -0.213015    -0.076158     -0.199046    -0.00374544   0.115483   -0.0687831    0.0558128  -0.205782    -0.0971591    0.0787634     0.0120561     0.0543186    0.114361     0.102196  
  0.0174787   -0.307849      0.0200246   -0.140945     0.192011     -0.030115      0.0329559   -0.0750969     0.0579215    0.0757006     0.00304477   0.0196319  -0.252324     0.0129986    -0.0974168   -0.0776665    0.0546603  -0.103538     0.0703048   0.0460434   -0.0301194   -0.151431      0.113672      0.0981715    0.0129399   -0.0912817 
  0.0809329    0.000379939  -0.0532658   -0.0426021   -0.227492     -0.0138415    -0.0612699   -0.0126186     0.0777957    0.139716     -0.015982     0.0486274   0.0050012    0.158534     -0.0539843    0.115042    -0.0148049  -0.0137405    0.105844    0.117223     0.0101656    0.108847     -0.14082       0.111934     0.00132735   0.306687  
 -0.0571031   -0.000392192   0.0113254   -0.0724903   -0.0581008    -0.0941939     0.00616422  -0.0473953     0.0686371   -0.123788      0.0249673   -0.0963853  -0.193191     0.0341309    -0.10437      0.0655024   -0.085636   -0.0524118    0.0227575  -0.141201    -0.0563374    0.0553153    -0.0293732    -0.0783429    0.142149    -0.039529  
 -0.0762707   -0.0612819    -0.0887755    0.120596    -0.0400055    -0.0352349    -0.0945925    0.0343682    -0.0504344   -0.162675     -0.102461    -0.119676   -0.0594197    0.149443     -0.0373293    0.119437     0.0435562   0.060109    -0.0259174  -0.0280014    0.00847179   0.0602228     0.0151115     0.0989561    0.119805     0.180411  
 -0.101435    -0.141002     -0.00115383   0.0531567   -0.12265       0.000231399  -0.00152864   0.00570165    0.0690692   -0.0460317    -0.113666    -0.0307036  -0.0526746   -0.0898122    -0.0821104   -0.0458004    0.0330427  -0.080469     0.0614194   0.0538686   -0.106081    -0.0298998    -0.0997554     0.01352      0.0463415    0.0591942 
  0.159402     0.147685     -0.0689759    0.0438808    0.0728204     0.149942      0.0447671    0.174841     -0.0463345    0.035697      0.225079    -0.126526    0.015786    -0.0450605     0.0277011   -0.029205    -0.0331739   0.0473595    0.0988742   0.00698044   0.0180294   -0.0146218     0.0469193    -0.0245799   -0.0668235    0.139498  
 -0.125982     0.249525      0.00755781   0.19259      0.131973     -0.042854     -0.0993961    0.120617      0.152307     0.291218      0.089224    -0.259639    0.123665     0.132929     -0.00422084   0.0344929    0.0975193  -0.0963458    0.127688   -6.54631e-5  -0.170151     0.159747      0.171588     -0.0501089    0.0187305   -0.13541   
 -0.0217388    0.136681      0.00695167  -0.125703     0.0450934     0.144381      0.0575189    0.014625      0.0419341    0.139288     -0.05778     -0.0192056   0.011603     0.000351529  -0.173182     0.0157171   -0.109568   -0.282974     0.047158   -0.00691535  -0.107084     0.0595813    -0.093553     -0.00345216   0.0821062   -0.165687  
  0.106664     0.0318473    -0.0110505    0.0157324    0.00614401    0.041212      0.214858    -0.0524414    -0.0750949    0.00784439   -0.0994122   -0.0453841   0.0109733    0.0594779     0.0157444   -0.0358013    0.0120396  -0.00639755  -0.0633656  -0.0959773   -0.00660655  -0.118366     -0.0835188     0.0303666    0.0715071   -0.0771386 
 -0.0495586   -0.09142       0.0804364   -0.032266     0.0155766     0.0291363    -0.101264     0.000520232  -0.0865899    0.06114       0.00330558  -0.0667942  -0.0963539    0.246172     -0.133633    -0.0571206    0.0390312  -0.114318     0.0400364  -0.0340297    0.0162567    0.0338187    -0.0225405     0.0433017   -0.00107052   0.0508797 
  0.236968     0.0379564    -0.0246296    0.0740792    0.0856615    -0.206881      0.00323603  -0.119624     -0.0951213    0.000801548   0.0232478    0.134192    0.0064336   -0.0177632     0.0687838   -0.110148    -0.0559301  -0.258892     0.143027   -0.0708241   -0.056807    -0.0382769     0.0579494     0.138777    -0.0869476   -0.0981385 
  0.0544596    0.0280329    -0.0629268    0.15644      0.000411508   0.0162551     0.060688     0.191703      0.0963381   -0.0906421     0.0254956   -0.259535    0.0237924   -0.047371      0.00560211   0.100501    -0.153377    0.0476827    0.0932647   0.178049    -0.0110368   -0.0573482    -0.205505     -0.0425408   -0.0791491   -0.109599  kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.419947572992476
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419966
[ Info: iteration 2, average log likelihood -1.419872
[ Info: iteration 3, average log likelihood -1.419789
[ Info: iteration 4, average log likelihood -1.419686
[ Info: iteration 5, average log likelihood -1.419558
[ Info: iteration 6, average log likelihood -1.419411
[ Info: iteration 7, average log likelihood -1.419256
[ Info: iteration 8, average log likelihood -1.419098
[ Info: iteration 9, average log likelihood -1.418928
[ Info: iteration 10, average log likelihood -1.418711
[ Info: iteration 11, average log likelihood -1.418393
[ Info: iteration 12, average log likelihood -1.417915
[ Info: iteration 13, average log likelihood -1.417256
[ Info: iteration 14, average log likelihood -1.416496
[ Info: iteration 15, average log likelihood -1.415817
[ Info: iteration 16, average log likelihood -1.415352
[ Info: iteration 17, average log likelihood -1.415092
[ Info: iteration 18, average log likelihood -1.414963
[ Info: iteration 19, average log likelihood -1.414903
[ Info: iteration 20, average log likelihood -1.414876
[ Info: iteration 21, average log likelihood -1.414863
[ Info: iteration 22, average log likelihood -1.414857
[ Info: iteration 23, average log likelihood -1.414854
[ Info: iteration 24, average log likelihood -1.414852
[ Info: iteration 25, average log likelihood -1.414852
[ Info: iteration 26, average log likelihood -1.414851
[ Info: iteration 27, average log likelihood -1.414851
[ Info: iteration 28, average log likelihood -1.414850
[ Info: iteration 29, average log likelihood -1.414850
[ Info: iteration 30, average log likelihood -1.414850
[ Info: iteration 31, average log likelihood -1.414850
[ Info: iteration 32, average log likelihood -1.414850
[ Info: iteration 33, average log likelihood -1.414849
[ Info: iteration 34, average log likelihood -1.414849
[ Info: iteration 35, average log likelihood -1.414849
[ Info: iteration 36, average log likelihood -1.414849
[ Info: iteration 37, average log likelihood -1.414849
[ Info: iteration 38, average log likelihood -1.414849
[ Info: iteration 39, average log likelihood -1.414849
[ Info: iteration 40, average log likelihood -1.414849
[ Info: iteration 41, average log likelihood -1.414849
[ Info: iteration 42, average log likelihood -1.414849
[ Info: iteration 43, average log likelihood -1.414849
[ Info: iteration 44, average log likelihood -1.414848
[ Info: iteration 45, average log likelihood -1.414848
[ Info: iteration 46, average log likelihood -1.414848
[ Info: iteration 47, average log likelihood -1.414848
[ Info: iteration 48, average log likelihood -1.414848
[ Info: iteration 49, average log likelihood -1.414848
[ Info: iteration 50, average log likelihood -1.414848
â”Œ Info: EM with 100000 data points 50 iterations avll -1.414848
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.419966209390258 
â”‚     -1.4198724838809622
â”‚      â‹®                 
â””     -1.4148482473031503
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414867
[ Info: iteration 2, average log likelihood -1.414770
[ Info: iteration 3, average log likelihood -1.414684
[ Info: iteration 4, average log likelihood -1.414576
[ Info: iteration 5, average log likelihood -1.414445
[ Info: iteration 6, average log likelihood -1.414300
[ Info: iteration 7, average log likelihood -1.414161
[ Info: iteration 8, average log likelihood -1.414046
[ Info: iteration 9, average log likelihood -1.413962
[ Info: iteration 10, average log likelihood -1.413905
[ Info: iteration 11, average log likelihood -1.413867
[ Info: iteration 12, average log likelihood -1.413840
[ Info: iteration 13, average log likelihood -1.413820
[ Info: iteration 14, average log likelihood -1.413803
[ Info: iteration 15, average log likelihood -1.413789
[ Info: iteration 16, average log likelihood -1.413775
[ Info: iteration 17, average log likelihood -1.413760
[ Info: iteration 18, average log likelihood -1.413745
[ Info: iteration 19, average log likelihood -1.413729
[ Info: iteration 20, average log likelihood -1.413712
[ Info: iteration 21, average log likelihood -1.413693
[ Info: iteration 22, average log likelihood -1.413674
[ Info: iteration 23, average log likelihood -1.413653
[ Info: iteration 24, average log likelihood -1.413632
[ Info: iteration 25, average log likelihood -1.413612
[ Info: iteration 26, average log likelihood -1.413592
[ Info: iteration 27, average log likelihood -1.413574
[ Info: iteration 28, average log likelihood -1.413557
[ Info: iteration 29, average log likelihood -1.413542
[ Info: iteration 30, average log likelihood -1.413529
[ Info: iteration 31, average log likelihood -1.413518
[ Info: iteration 32, average log likelihood -1.413509
[ Info: iteration 33, average log likelihood -1.413501
[ Info: iteration 34, average log likelihood -1.413495
[ Info: iteration 35, average log likelihood -1.413490
[ Info: iteration 36, average log likelihood -1.413486
[ Info: iteration 37, average log likelihood -1.413482
[ Info: iteration 38, average log likelihood -1.413480
[ Info: iteration 39, average log likelihood -1.413478
[ Info: iteration 40, average log likelihood -1.413476
[ Info: iteration 41, average log likelihood -1.413474
[ Info: iteration 42, average log likelihood -1.413473
[ Info: iteration 43, average log likelihood -1.413472
[ Info: iteration 44, average log likelihood -1.413471
[ Info: iteration 45, average log likelihood -1.413470
[ Info: iteration 46, average log likelihood -1.413469
[ Info: iteration 47, average log likelihood -1.413469
[ Info: iteration 48, average log likelihood -1.413468
[ Info: iteration 49, average log likelihood -1.413468
[ Info: iteration 50, average log likelihood -1.413467
â”Œ Info: EM with 100000 data points 50 iterations avll -1.413467
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4148666447689586
â”‚     -1.4147703840640233
â”‚      â‹®                 
â””     -1.4134672938410826
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413478
[ Info: iteration 2, average log likelihood -1.413428
[ Info: iteration 3, average log likelihood -1.413384
[ Info: iteration 4, average log likelihood -1.413333
[ Info: iteration 5, average log likelihood -1.413270
[ Info: iteration 6, average log likelihood -1.413193
[ Info: iteration 7, average log likelihood -1.413102
[ Info: iteration 8, average log likelihood -1.413001
[ Info: iteration 9, average log likelihood -1.412898
[ Info: iteration 10, average log likelihood -1.412798
[ Info: iteration 11, average log likelihood -1.412708
[ Info: iteration 12, average log likelihood -1.412629
[ Info: iteration 13, average log likelihood -1.412562
[ Info: iteration 14, average log likelihood -1.412505
[ Info: iteration 15, average log likelihood -1.412456
[ Info: iteration 16, average log likelihood -1.412412
[ Info: iteration 17, average log likelihood -1.412373
[ Info: iteration 18, average log likelihood -1.412337
[ Info: iteration 19, average log likelihood -1.412305
[ Info: iteration 20, average log likelihood -1.412276
[ Info: iteration 21, average log likelihood -1.412249
[ Info: iteration 22, average log likelihood -1.412224
[ Info: iteration 23, average log likelihood -1.412201
[ Info: iteration 24, average log likelihood -1.412180
[ Info: iteration 25, average log likelihood -1.412160
[ Info: iteration 26, average log likelihood -1.412142
[ Info: iteration 27, average log likelihood -1.412125
[ Info: iteration 28, average log likelihood -1.412109
[ Info: iteration 29, average log likelihood -1.412095
[ Info: iteration 30, average log likelihood -1.412081
[ Info: iteration 31, average log likelihood -1.412068
[ Info: iteration 32, average log likelihood -1.412057
[ Info: iteration 33, average log likelihood -1.412046
[ Info: iteration 34, average log likelihood -1.412036
[ Info: iteration 35, average log likelihood -1.412027
[ Info: iteration 36, average log likelihood -1.412018
[ Info: iteration 37, average log likelihood -1.412010
[ Info: iteration 38, average log likelihood -1.412002
[ Info: iteration 39, average log likelihood -1.411995
[ Info: iteration 40, average log likelihood -1.411988
[ Info: iteration 41, average log likelihood -1.411981
[ Info: iteration 42, average log likelihood -1.411975
[ Info: iteration 43, average log likelihood -1.411969
[ Info: iteration 44, average log likelihood -1.411963
[ Info: iteration 45, average log likelihood -1.411957
[ Info: iteration 46, average log likelihood -1.411952
[ Info: iteration 47, average log likelihood -1.411946
[ Info: iteration 48, average log likelihood -1.411941
[ Info: iteration 49, average log likelihood -1.411936
[ Info: iteration 50, average log likelihood -1.411931
â”Œ Info: EM with 100000 data points 50 iterations avll -1.411931
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4134776796393624
â”‚     -1.413427900814367 
â”‚      â‹®                 
â””     -1.4119310859159808
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411935
[ Info: iteration 2, average log likelihood -1.411885
[ Info: iteration 3, average log likelihood -1.411842
[ Info: iteration 4, average log likelihood -1.411793
[ Info: iteration 5, average log likelihood -1.411736
[ Info: iteration 6, average log likelihood -1.411668
[ Info: iteration 7, average log likelihood -1.411588
[ Info: iteration 8, average log likelihood -1.411496
[ Info: iteration 9, average log likelihood -1.411397
[ Info: iteration 10, average log likelihood -1.411292
[ Info: iteration 11, average log likelihood -1.411186
[ Info: iteration 12, average log likelihood -1.411083
[ Info: iteration 13, average log likelihood -1.410984
[ Info: iteration 14, average log likelihood -1.410891
[ Info: iteration 15, average log likelihood -1.410806
[ Info: iteration 16, average log likelihood -1.410730
[ Info: iteration 17, average log likelihood -1.410662
[ Info: iteration 18, average log likelihood -1.410602
[ Info: iteration 19, average log likelihood -1.410549
[ Info: iteration 20, average log likelihood -1.410503
[ Info: iteration 21, average log likelihood -1.410463
[ Info: iteration 22, average log likelihood -1.410428
[ Info: iteration 23, average log likelihood -1.410397
[ Info: iteration 24, average log likelihood -1.410370
[ Info: iteration 25, average log likelihood -1.410345
[ Info: iteration 26, average log likelihood -1.410322
[ Info: iteration 27, average log likelihood -1.410302
[ Info: iteration 28, average log likelihood -1.410283
[ Info: iteration 29, average log likelihood -1.410265
[ Info: iteration 30, average log likelihood -1.410249
[ Info: iteration 31, average log likelihood -1.410233
[ Info: iteration 32, average log likelihood -1.410219
[ Info: iteration 33, average log likelihood -1.410205
[ Info: iteration 34, average log likelihood -1.410192
[ Info: iteration 35, average log likelihood -1.410180
[ Info: iteration 36, average log likelihood -1.410168
[ Info: iteration 37, average log likelihood -1.410157
[ Info: iteration 38, average log likelihood -1.410146
[ Info: iteration 39, average log likelihood -1.410136
[ Info: iteration 40, average log likelihood -1.410126
[ Info: iteration 41, average log likelihood -1.410116
[ Info: iteration 42, average log likelihood -1.410106
[ Info: iteration 43, average log likelihood -1.410097
[ Info: iteration 44, average log likelihood -1.410088
[ Info: iteration 45, average log likelihood -1.410079
[ Info: iteration 46, average log likelihood -1.410070
[ Info: iteration 47, average log likelihood -1.410061
[ Info: iteration 48, average log likelihood -1.410053
[ Info: iteration 49, average log likelihood -1.410044
[ Info: iteration 50, average log likelihood -1.410036
â”Œ Info: EM with 100000 data points 50 iterations avll -1.410036
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.411934507512222 
â”‚     -1.4118852757168034
â”‚      â‹®                 
â””     -1.4100361461258573
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410035
[ Info: iteration 2, average log likelihood -1.409973
[ Info: iteration 3, average log likelihood -1.409912
[ Info: iteration 4, average log likelihood -1.409840
[ Info: iteration 5, average log likelihood -1.409750
[ Info: iteration 6, average log likelihood -1.409637
[ Info: iteration 7, average log likelihood -1.409500
[ Info: iteration 8, average log likelihood -1.409345
[ Info: iteration 9, average log likelihood -1.409179
[ Info: iteration 10, average log likelihood -1.409012
[ Info: iteration 11, average log likelihood -1.408855
[ Info: iteration 12, average log likelihood -1.408711
[ Info: iteration 13, average log likelihood -1.408585
[ Info: iteration 14, average log likelihood -1.408477
[ Info: iteration 15, average log likelihood -1.408384
[ Info: iteration 16, average log likelihood -1.408304
[ Info: iteration 17, average log likelihood -1.408236
[ Info: iteration 18, average log likelihood -1.408177
[ Info: iteration 19, average log likelihood -1.408125
[ Info: iteration 20, average log likelihood -1.408079
[ Info: iteration 21, average log likelihood -1.408037
[ Info: iteration 22, average log likelihood -1.407999
[ Info: iteration 23, average log likelihood -1.407964
[ Info: iteration 24, average log likelihood -1.407931
[ Info: iteration 25, average log likelihood -1.407901
[ Info: iteration 26, average log likelihood -1.407872
[ Info: iteration 27, average log likelihood -1.407844
[ Info: iteration 28, average log likelihood -1.407817
[ Info: iteration 29, average log likelihood -1.407792
[ Info: iteration 30, average log likelihood -1.407767
[ Info: iteration 31, average log likelihood -1.407744
[ Info: iteration 32, average log likelihood -1.407721
[ Info: iteration 33, average log likelihood -1.407699
[ Info: iteration 34, average log likelihood -1.407677
[ Info: iteration 35, average log likelihood -1.407656
[ Info: iteration 36, average log likelihood -1.407636
[ Info: iteration 37, average log likelihood -1.407617
[ Info: iteration 38, average log likelihood -1.407598
[ Info: iteration 39, average log likelihood -1.407580
[ Info: iteration 40, average log likelihood -1.407562
[ Info: iteration 41, average log likelihood -1.407545
[ Info: iteration 42, average log likelihood -1.407528
[ Info: iteration 43, average log likelihood -1.407512
[ Info: iteration 44, average log likelihood -1.407497
[ Info: iteration 45, average log likelihood -1.407482
[ Info: iteration 46, average log likelihood -1.407467
[ Info: iteration 47, average log likelihood -1.407453
[ Info: iteration 48, average log likelihood -1.407439
[ Info: iteration 49, average log likelihood -1.407425
[ Info: iteration 50, average log likelihood -1.407412
â”Œ Info: EM with 100000 data points 50 iterations avll -1.407412
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4100353517752584
â”‚     -1.4099732068195392
â”‚      â‹®                 
â””     -1.4074120104732446
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.419947572992476 
â”‚     -1.419966209390258 
â”‚     -1.4198724838809622
â”‚     -1.419788796727965 
â”‚      â‹®                 
â”‚     -1.4074387628021878
â”‚     -1.4074252179511182
â””     -1.4074120104732446
32Ã—26 Array{Float64,2}:
 -0.0120661  -0.13748      0.0809578    0.242586   -0.2901      -0.243094    -0.554671    -0.553767    -0.50837    -0.21371     0.0388551  -0.466375     0.139137     0.608323   -0.642484     -0.565019    0.654022    0.10013       0.0837047   0.274857    -0.106306     0.340372    -0.566732    -0.526362    0.343658   -0.135796 
 -0.0434776   0.395671    -0.369209     0.328005    0.196537     0.528579    -0.184126    -0.156068    -0.853357    0.201711   -0.142893   -0.348649     0.218005     0.215526   -0.157976      0.40522    -0.0678476   0.0737418     0.807911    0.30717     -0.287375     0.273395     0.0802258   -0.467442   -0.083525    0.0926733
  0.0909434   0.261702     0.220798    -0.188825   -0.044519    -0.0569303    0.464036    -0.497035    -0.25946    -0.151883    0.218387    0.0445755    1.00808      0.476452   -0.17586      -0.0492684   0.892256   -0.366439      0.445926    0.182662    -0.105613    -0.137323     0.0845706    0.560842    0.550512    0.150398 
 -0.314882   -0.0624298   -0.253272    -0.106048    0.173313    -0.642548    -0.431243    -0.273602    -0.302213    0.015291    0.522101    0.144418     0.315842    -0.136923   -0.223987      0.340812   -0.167893   -0.250466      0.163945   -0.029984    -0.00483002   0.348429    -0.547503     0.863249    0.712521    0.349823 
  0.214044   -0.286167     0.340065     0.131492    0.395602    -0.735949    -0.171362     0.0712488   -0.632707   -0.311606    0.155024   -0.194638     0.247085    -0.61043     0.00711579   -0.350748   -0.569798   -0.386842      0.101614    0.162167    -0.111111    -0.524927    -0.690334     0.0734189  -0.450264    0.392282 
  0.262133   -0.00862193  -0.12854      0.590778   -0.593139    -0.687688     0.410515     0.286753    -0.471351    0.124474    0.152901    0.0367014   -0.171679    -0.415418    0.359888     -0.353727    0.380272   -0.210564     -0.0953018  -0.58386     -0.184962     0.239481     0.0674348   -0.0317862  -0.0325667   0.483361 
  0.186159   -0.0250055   -0.251335     0.37709     0.684722    -0.155023     0.318239     0.768878     0.51744     0.271541   -0.377915    0.348406    -0.196778    -0.331883    0.322176      0.637766   -0.456625   -0.122795      0.0271011  -0.0114337   -0.152932    -0.446634     0.273728     0.195228   -0.166965   -0.229596 
  0.282766   -0.0786664    0.151871    -0.0471412   0.00933786  -0.225838     0.153363     0.655099    -0.421355   -0.90802     0.132018    0.131098    -0.0419239    0.473465   -0.203535      0.595251    0.225141   -0.28789       0.411686   -0.643901     0.749602     0.372089     0.00682979   0.63538    -0.160884    0.155524 
 -0.288369    0.222697    -0.0680077    0.201311   -0.172801     0.0554404   -0.2491       0.48699     -0.016981    0.218543   -0.94152    -0.350819    -0.89825     -0.261096   -0.186108      0.0930203  -0.26021     0.0995047    -0.0536318   0.0255664    0.0516493    0.334598     0.276656    -0.621476    0.0609032  -0.273782 
 -0.0656785  -0.412553    -0.482299     0.145849   -0.030207     0.194218    -0.43481      0.236928     0.0212969   0.187346    0.296479    0.009175    -0.749776    -0.0887497   0.143304     -0.0204757  -0.453145    0.749208     -0.235905   -0.165143    -0.372954    -0.0173964    0.398362    -0.57464    -0.228219   -0.306593 
  0.217931   -0.373559     0.298313     0.371168   -0.756934     0.452278     0.1437      -0.459827     0.469637    0.0279471  -0.879993   -0.541865     0.0870133    0.1397      0.706343      0.470941    0.366009   -0.176099     -0.0667582   0.113029    -0.490631     0.543245     0.012953    -0.538848   -0.327459    0.39365  
  0.329334   -0.0545109    0.821042     0.613362   -0.531745    -0.117496    -0.230865    -0.17979      0.395327    0.289725   -0.411311    0.808036    -0.308781     0.0306505   0.07065      -0.202592    0.237677    0.0786496     0.0778011  -0.150186    -0.516956    -0.39569      0.166252    -0.619868    0.0807463  -0.205601 
 -0.0425396   0.237912    -0.00267014   0.17505     0.0883589    0.840628     0.850565     0.0225584    0.55103    -0.175121   -0.102698   -0.590897     0.11967      0.468516   -0.0592008    -0.401215   -0.0350033  -0.209765     -0.297338   -0.109684     0.150865     0.0227163   -0.247721    -0.164017    0.0177543  -0.515027 
  0.047438   -0.594051    -0.471057    -0.718292    0.0537355    0.39683      0.123318    -0.362799     0.499705   -0.0749134   0.736082   -0.761824     0.0277281    0.249641    0.000879912  -0.0175705  -0.451616   -0.394765     -0.0825189  -0.00366286   0.0457828    0.668016    -0.120779     0.23951    -0.260943    0.0435044
 -1.01294     0.303422    -0.274222    -0.51163    -0.0684172    0.354408    -0.278366    -0.523556     0.0462321   0.154245    0.0599744  -0.00686793  -0.328995    -0.201683   -0.472568     -0.915451   -0.168638   -0.165285     -0.293783    0.0735913   -0.189847    -0.201074     0.337909    -0.491833   -0.0988074  -0.332502 
 -0.0278288  -0.00762363   0.175049    -0.602487    0.0655674    0.208147    -0.25078     -0.14284      0.587051    0.128094    0.0363159   0.20169     -0.547674     0.389338   -0.15218       0.108202    0.0582515   0.360641     -0.238635    0.0321591    0.252336    -0.0799891    0.247332    -0.0946272   0.15298    -0.433053 
  0.180511    0.312685     0.268663     0.301389   -0.256155     0.0799776    0.137742     0.031028    -0.419611   -0.150517    0.111826   -0.0762579    0.210826    -0.035666   -0.102505     -0.203019    0.283775   -0.0858862     0.367259   -0.144113    -0.161501     0.14267     -0.134317    -0.262434   -0.0872537   0.249086 
  0.668358   -0.0541135    0.31452      0.309733   -0.406185    -0.252157    -0.1114       0.00223483  -0.049984   -0.165597   -0.138498    0.0813216    0.362693     0.43993     0.165289      0.676178    0.092219    0.147737      0.238167   -0.0283761    0.085117     0.19599     -0.433099     0.419184   -0.0145698   0.661492 
 -0.254547    0.463413     0.0616883   -0.147216   -0.182926    -0.460701    -0.0921823    0.459058    -0.192399   -0.258616    0.0284071   0.374394    -0.33702      0.0991671  -0.301507     -0.0662341   0.192451   -0.108835     -0.0201324  -0.628737     0.270653     0.00623733   0.101102     0.318225    0.275891   -0.548562 
  0.0509085   0.433008    -0.229311    -0.0629726  -0.644833     0.167855    -0.343922    -0.235133    -0.214811   -0.315736   -0.14583     0.306525     0.081346     0.191412   -0.320135      0.0796882   0.0611081  -0.0262949    -0.0521653  -0.953156     0.242488     0.410135     0.210483    -0.121255   -0.654482    0.301955 
 -0.174257   -0.0226873    0.0479408   -0.34075    -0.058464     0.145641    -0.217194    -0.617847    -0.0202537   0.143774    0.0117568  -0.0775488   -0.0494286    0.159733   -0.147932     -0.141739    0.0812549   0.175563     -0.316847    0.350182     0.0795164   -0.0118763   -0.0389203   -0.0532767   0.142799   -0.0760271
  0.0582101  -0.0219119   -0.0632169    0.0257748   0.0412372    0.00238539  -0.00114516   0.151194     0.159509    0.0323016  -0.082238    0.059447    -0.111069     0.0565428   0.05274       0.0558571  -0.0615781  -0.0828755    -0.012971   -0.133611    -0.023833     0.0578809    0.104401    -0.0692262  -0.0461189  -0.131536 
 -0.0546185  -0.242675    -0.0810055   -0.360301    0.431421     0.0536686   -0.423921     0.184263    -0.295808   -0.0178494   0.181928    0.156666    -0.320574     0.197664   -0.682043     -0.178922    0.0062196   0.000855162   0.35351     0.12051      0.19864     -0.398068     0.0414759   -0.0618501   0.455708   -0.53694  
 -0.290003   -0.671907     0.125027     0.254652    0.025986     0.00156084   0.117707     0.129143    -0.446466    0.0751442   0.57939    -0.0209403   -0.0686808   -0.0695799   0.433923     -0.17743     0.502732    0.00182718    0.513089    0.276861    -0.322026    -0.146608    -0.0521682   -0.328548    0.92999    -0.114525 
  0.152293   -0.332485    -0.45255      0.307797    0.185311    -0.336502     0.188404     0.167762    -0.0628205   0.213738   -0.0419543  -0.204944     0.00476613  -0.229697    0.408488      0.0533369  -0.533584   -0.181584      0.111153    0.367114    -0.220708    -0.275419    -0.162419     0.0901197  -0.157429    0.2382   
 -0.0612304   0.379373    -0.239357    -0.235297    0.400705    -0.149936     0.434471     0.145612    -0.232201   -0.0532622  -0.0819196  -0.324892     0.157217    -0.171191   -0.0323408     0.482946    0.146004   -0.519563      0.333549    0.126034     0.120952    -0.0601015   -0.0511379    0.55309     0.0621997   0.259744 
 -0.2138     -0.0910049   -0.0820349   -0.15319    -0.180887    -0.0189847   -0.05714      0.0171579    0.186955    0.2372      0.203188   -0.0424758    0.0657612   -0.759815    1.05588       0.0386992  -0.621838   -0.0895558     0.374587   -0.144585    -0.82564      0.456492     0.664663     0.781162    0.168258   -0.194409 
 -0.467964    0.212589    -0.575547    -0.0312353   0.159067     0.0999044    0.180658     0.318768     0.348748    0.345157    0.0591967  -0.152737    -0.24373     -0.274124    0.307712      0.53881     0.110806   -0.32149      -0.2225     -0.132591    -0.10469      0.413823     0.987455    -0.0390572  -0.116918   -0.248074 
  0.279543    0.53612      0.195962     0.298839    0.29091     -0.0628839    0.280932     0.122785     0.22901    -0.295074   -0.270763    0.0343921    0.0560586    0.0899341  -0.749861      0.070061   -0.213605    0.491844     -0.990804    0.294464     0.546714    -0.525731    -0.615444     0.0384049  -0.46618     0.39878  
  0.571786    0.527256     0.191971    -0.289737    0.0293555    0.785964     0.221935    -0.21784      0.196291    0.226084   -0.244048    0.150841     0.372456    -0.0435815   0.0764752    -0.596547   -0.507901    0.153012      0.204142   -0.154037     0.648184    -0.156517    -0.563326     0.138117   -0.460688    0.630918 
  0.235632   -0.111598     0.217702    -0.476941   -0.116979    -0.566067     0.318999     0.213518     0.565347   -0.0950934   0.213835    0.289148    -0.0932712   -0.244516    0.152102     -0.298563   -0.191172   -0.242433     -0.51481    -0.474315     0.190603    -0.472397    -0.0330377    0.378371   -0.362266   -0.0467147
  0.0245535  -0.694171     0.337946    -0.196454    0.438347    -0.378754     0.182737     0.071447     0.835336    0.134902   -0.0294811  -0.242362    -0.379988     0.145808    0.102629     -0.018915    0.0756526  -0.0643568    -0.551847    0.683239     0.0084803   -0.395206    -0.184524     0.282377    0.402129   -0.217054 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407399
[ Info: iteration 2, average log likelihood -1.407387
[ Info: iteration 3, average log likelihood -1.407374
[ Info: iteration 4, average log likelihood -1.407362
[ Info: iteration 5, average log likelihood -1.407350
[ Info: iteration 6, average log likelihood -1.407338
[ Info: iteration 7, average log likelihood -1.407327
[ Info: iteration 8, average log likelihood -1.407315
[ Info: iteration 9, average log likelihood -1.407304
[ Info: iteration 10, average log likelihood -1.407292
â”Œ Info: EM with 100000 data points 10 iterations avll -1.407292
â”” 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.665497e+05
      1       6.982085e+05      -2.683412e+05 |       32
      2       6.866681e+05      -1.154033e+04 |       32
      3       6.817989e+05      -4.869188e+03 |       32
      4       6.790722e+05      -2.726702e+03 |       32
      5       6.771772e+05      -1.895056e+03 |       32
      6       6.758323e+05      -1.344926e+03 |       32
      7       6.748590e+05      -9.732406e+02 |       32
      8       6.741293e+05      -7.296871e+02 |       32
      9       6.735831e+05      -5.462173e+02 |       32
     10       6.731545e+05      -4.286506e+02 |       32
     11       6.727883e+05      -3.661239e+02 |       32
     12       6.724697e+05      -3.186049e+02 |       32
     13       6.721931e+05      -2.766328e+02 |       32
     14       6.719553e+05      -2.378476e+02 |       32
     15       6.717279e+05      -2.273720e+02 |       32
     16       6.715235e+05      -2.043571e+02 |       32
     17       6.713332e+05      -1.903741e+02 |       32
     18       6.711639e+05      -1.692086e+02 |       32
     19       6.710239e+05      -1.400667e+02 |       32
     20       6.709048e+05      -1.190959e+02 |       32
     21       6.707983e+05      -1.065178e+02 |       32
     22       6.706963e+05      -1.020091e+02 |       32
     23       6.706044e+05      -9.185057e+01 |       32
     24       6.705215e+05      -8.287346e+01 |       32
     25       6.704323e+05      -8.919844e+01 |       32
     26       6.703578e+05      -7.453067e+01 |       32
     27       6.702875e+05      -7.033073e+01 |       32
     28       6.702239e+05      -6.360768e+01 |       32
     29       6.701643e+05      -5.960895e+01 |       32
     30       6.701091e+05      -5.517533e+01 |       32
     31       6.700580e+05      -5.108048e+01 |       32
     32       6.700162e+05      -4.180254e+01 |       32
     33       6.699792e+05      -3.695722e+01 |       32
     34       6.699409e+05      -3.838267e+01 |       32
     35       6.699076e+05      -3.324842e+01 |       32
     36       6.698735e+05      -3.412411e+01 |       32
     37       6.698376e+05      -3.583752e+01 |       32
     38       6.697968e+05      -4.081558e+01 |       32
     39       6.697540e+05      -4.282905e+01 |       32
     40       6.697101e+05      -4.391650e+01 |       32
     41       6.696732e+05      -3.683828e+01 |       32
     42       6.696375e+05      -3.571067e+01 |       32
     43       6.696057e+05      -3.183029e+01 |       32
     44       6.695788e+05      -2.690726e+01 |       32
     45       6.695477e+05      -3.108567e+01 |       32
     46       6.695226e+05      -2.513073e+01 |       32
     47       6.694984e+05      -2.416205e+01 |       32
     48       6.694751e+05      -2.328797e+01 |       32
     49       6.694486e+05      -2.649712e+01 |       32
     50       6.694215e+05      -2.710469e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 669421.528875456)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419017
[ Info: iteration 2, average log likelihood -1.414004
[ Info: iteration 3, average log likelihood -1.412677
[ Info: iteration 4, average log likelihood -1.411717
[ Info: iteration 5, average log likelihood -1.410706
[ Info: iteration 6, average log likelihood -1.409750
[ Info: iteration 7, average log likelihood -1.409070
[ Info: iteration 8, average log likelihood -1.408682
[ Info: iteration 9, average log likelihood -1.408464
[ Info: iteration 10, average log likelihood -1.408324
[ Info: iteration 11, average log likelihood -1.408221
[ Info: iteration 12, average log likelihood -1.408136
[ Info: iteration 13, average log likelihood -1.408064
[ Info: iteration 14, average log likelihood -1.407999
[ Info: iteration 15, average log likelihood -1.407941
[ Info: iteration 16, average log likelihood -1.407887
[ Info: iteration 17, average log likelihood -1.407838
[ Info: iteration 18, average log likelihood -1.407792
[ Info: iteration 19, average log likelihood -1.407749
[ Info: iteration 20, average log likelihood -1.407708
[ Info: iteration 21, average log likelihood -1.407671
[ Info: iteration 22, average log likelihood -1.407635
[ Info: iteration 23, average log likelihood -1.407602
[ Info: iteration 24, average log likelihood -1.407570
[ Info: iteration 25, average log likelihood -1.407540
[ Info: iteration 26, average log likelihood -1.407511
[ Info: iteration 27, average log likelihood -1.407484
[ Info: iteration 28, average log likelihood -1.407458
[ Info: iteration 29, average log likelihood -1.407434
[ Info: iteration 30, average log likelihood -1.407410
[ Info: iteration 31, average log likelihood -1.407388
[ Info: iteration 32, average log likelihood -1.407367
[ Info: iteration 33, average log likelihood -1.407346
[ Info: iteration 34, average log likelihood -1.407326
[ Info: iteration 35, average log likelihood -1.407307
[ Info: iteration 36, average log likelihood -1.407289
[ Info: iteration 37, average log likelihood -1.407271
[ Info: iteration 38, average log likelihood -1.407254
[ Info: iteration 39, average log likelihood -1.407238
[ Info: iteration 40, average log likelihood -1.407222
[ Info: iteration 41, average log likelihood -1.407207
[ Info: iteration 42, average log likelihood -1.407192
[ Info: iteration 43, average log likelihood -1.407177
[ Info: iteration 44, average log likelihood -1.407164
[ Info: iteration 45, average log likelihood -1.407150
[ Info: iteration 46, average log likelihood -1.407137
[ Info: iteration 47, average log likelihood -1.407125
[ Info: iteration 48, average log likelihood -1.407112
[ Info: iteration 49, average log likelihood -1.407101
[ Info: iteration 50, average log likelihood -1.407089
â”Œ Info: EM with 100000 data points 50 iterations avll -1.407089
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.447676     -0.338138     0.7104       0.240273   -0.530503    -0.188534    0.127133   -0.174564    0.654092   -0.0410419   -0.0538652   0.227918    -0.15162      0.0712755   0.174032    -0.36592     0.362676     0.147683    -0.111683    -0.0766525   -0.354931    -0.548319    0.10799     -0.227288    -0.108495   -0.150441  
 -0.351089     -0.124486     0.374897    -0.0157473  -0.600112    -0.555234   -0.931612   -1.23092     0.0296859  -0.183874     0.115522    0.0162373    0.650996     0.78764    -0.432567    -0.407096    0.986099    -0.685107    -0.633171    -0.224465     0.0916101    0.879444   -0.373837    -0.608639     0.289025   -0.551994  
 -0.238703      0.455648    -0.117544     0.0953915   0.244934     0.572342    0.484175   -0.616363   -0.705495   -0.128529     0.189995   -0.871764     0.238254     0.243701   -0.473237    -0.348691    0.245705    -0.0835467    0.198045     0.282757    -0.202314    -0.267323   -0.237119    -0.907954    -0.521612   -0.0195757 
 -0.307722     -0.707529     0.356922     0.131835    0.725806    -0.132699    0.24118     0.320365    0.396852    0.30347      0.19151    -0.334668    -0.265831    -0.0846367  -0.0454799   -0.260946    0.00328644  -0.490646    -0.0266584    0.801201    -0.127782    -0.485528   -0.238169    -0.141614     0.910347   -0.258105  
  0.454508     -0.0967522   -0.250793     0.897718   -0.397893    -0.797748    0.813867    0.325338   -0.625208    0.239327     0.201173   -0.119538    -0.337349    -0.378837    0.288499    -0.38064     0.33893     -0.098385    -0.139058    -0.560373    -0.102664     0.243129    0.0124116   -0.120609     0.0611751   0.595389  
  0.186918     -0.326969     0.0702505   -0.17209     0.241414    -0.547394    0.190029    0.155382   -0.291579   -0.355866     0.63941    -0.0149143    0.308092    -0.59325     0.227538    -0.279964   -0.491221    -0.489421    -0.0162721   -0.297022    -0.0916568   -0.613458   -0.227454     0.476128    -0.755911    0.0351158 
 -0.398451     -0.0105732    0.506479     0.169547   -0.0943288   -0.467598    0.0716561   0.524262   -0.263788   -1.13683      0.197227   -0.298054    -0.636254     0.415391   -0.381276     0.164966    0.616038    -0.188331     0.146387    -0.359587     0.0471242    0.443222    0.165713     0.356297     0.174375   -0.426736  
  0.701047      0.170733    -0.681089    -0.381301   -0.348601     0.0385728  -0.0857389  -0.286256    0.0219257  -0.240182     0.150557    0.110463    -0.17485      0.75668    -0.0699203    0.321148   -0.408189     0.00669101  -0.0972164   -0.51991      0.435042     0.945889   -0.020159     0.301861    -0.948195    0.0444914 
  0.201658     -0.0472389   -0.351582     0.379544    0.450038    -0.022172    0.145776    0.265903   -0.278712    0.0866759   -0.181302   -0.138483     0.125605     0.0226116   0.141224     0.364069   -0.280057    -0.150399     0.505047     0.528025    -0.261304    -0.222403   -0.102919    -0.0254084   -0.0864418   0.178086  
  0.326129     -0.014903     0.19438      0.148171   -0.0590641   -0.137764   -0.0738348  -0.204831   -0.411225   -0.279666     0.036598   -0.102679     0.411918     0.243453   -0.10376     -0.049109    0.0817903   -0.198551     0.469588     0.153834     0.00528931   0.086573   -0.448652     0.127361     0.0991625   0.469379  
  0.000541717  -0.200373     0.276462    -0.0267471  -0.161729    -0.0897849   0.312221   -0.0596155  -0.680238   -0.121181     0.171953    0.241637     0.406424     0.276382   -0.0650103   -0.15299     0.845665    -0.032747     0.645075     0.0811845   -0.117063    -0.429599   -0.0561158   -0.00337529   0.838318   -0.114487  
  0.4201        0.269153     0.193353    -0.051424    0.328544     1.28943     0.654979    0.0713308   0.478004   -0.291152    -0.299864   -0.225372    -0.0977237    0.488607   -0.0451712   -0.0255086  -0.259013     0.404917     0.0401825   -0.00706024   0.392078    -0.278952   -0.00902487  -0.141526    -0.163951   -0.156571  
 -0.634942      0.0318337   -0.441741    -0.0269395  -0.11939      0.496296    0.370276    0.165631    0.931979    0.153397     0.0241247   0.00812007  -0.00442525   0.182498    0.0511275   -0.193782   -0.0140702   -0.433967    -0.567759    -0.337854     0.119454     0.304414    0.383588    -0.0351066    0.0480548  -0.580342  
  0.441814      0.388313    -0.088191    -0.072233   -0.149348     0.626416    0.0655726  -0.290619    0.209085    0.40306     -0.144267    0.183335     0.509373    -0.272959    0.116427    -0.373042   -0.620965     0.108644    -0.057225    -0.0661801    0.284901    -0.0906192  -0.310786    -0.0733115   -0.495054    0.552407  
 -0.111983      0.220478    -0.230961    -0.488625    0.431272    -0.309875    0.482917    0.0563358   0.015753    0.0198811    0.0739887  -0.268976     0.14949     -0.295201    0.121227     0.56689     0.107417    -0.80919      0.207519    -0.0272704    0.239025     0.0257917   0.0792631    0.722835     0.0677528   0.255108  
 -0.049148     -0.241928     0.0135863   -0.614631    0.0686805   -0.402132   -0.325116    0.0825194   0.413064    0.162564     0.0527515   0.346134    -0.45264      0.145018    0.0501013    0.042509   -0.0622399    0.0687703   -0.341194    -0.093309     0.164078    -0.174316    0.182498     0.284883     0.181391   -0.328024  
  0.0509371     0.00850989  -0.0396517   -0.0164988   0.00404816  -0.0402058   0.117438    0.0378769   0.0734884   0.00181114   0.0183239  -0.0483067   -0.01648     -0.0141277   0.0386517   -0.0311047  -0.0280588   -0.149385    -0.00901581  -0.0823042   -0.0121277    0.0207049   0.0209194    0.0203762   -0.0570468  -0.0382844 
  0.0723166     0.069574     0.0468236   -0.303282    0.326627    -0.553895    0.147862    0.480062    0.485804    0.0770124    0.0146118   0.37293     -0.276475    -0.112443   -0.136912     0.157424    0.0846647    0.131814    -0.499753    -0.266705     0.323673    -0.537421    0.0862204    0.387553     0.0692593  -0.240083  
  0.493675     -0.101213     0.0639085    0.636247    0.228158    -0.456872   -0.158054    0.830107    0.532664    0.197467    -0.560808    0.574455    -0.362525    -0.208204    0.245422     0.523364   -0.323107    -0.120213    -0.0239249   -0.242859    -0.133465    -0.117431    0.118193    -0.0943001   -0.246049   -0.392582  
 -0.274564     -0.0600285   -0.558311     0.047163    0.205892     0.031653   -0.0109758   0.485288    0.0548181   0.233892    -0.115336   -0.360324    -0.912378    -0.550436    0.201176     0.199051   -0.496626     0.40495     -0.182463    -0.105141    -0.136525    -0.0323141   0.486198    -0.311895    -0.297928   -0.235525  
 -0.179519     -0.167001    -0.307649     0.0174599  -0.00456032  -0.12879     0.0935947   0.0403158   0.272312    0.42379      0.313158    0.0680634    0.0982604   -0.653737    0.865383     0.142616   -0.449658    -0.173773     0.170404     0.00250891  -0.830025     0.304889    0.561181     0.554491     0.248727   -0.199854  
 -0.416221     -0.0277601   -0.00221497  -0.296646   -0.24059      0.243641   -0.621603   -0.17051     0.0890177   0.262331    -0.188545    0.161766    -0.909966     0.0782135  -0.202479    -0.273001   -0.125274     0.275826    -0.0808586    0.0307949   -0.164985    -0.010201    0.380424    -0.731615     0.0424048  -0.384433  
 -0.370072     -0.457263    -0.0949091    0.0224249  -0.736741     0.381004   -0.192542   -0.250965    0.0194702  -0.16868     -0.0984679  -0.907514    -0.17902     -0.0873425   0.436744    -0.0579293  -0.135099    -0.42912      0.327689     0.253465    -0.281484     0.81631     0.11212     -0.316122     0.0642088   0.374506  
  0.223854      0.330598     0.505071    -0.037647   -0.0186535   -0.619232    0.38465     0.196137    0.355813   -0.0908383   -0.403611   -0.0305325   -0.0608853   -0.0470504  -0.238403    -0.332842   -0.325461    -0.106273    -0.818662     0.0571815    0.567747    -0.446118   -0.714339     0.253331    -0.375153    0.393663  
 -0.106155     -0.0629495    0.0842321    0.163733   -0.0349516    0.172592   -0.463769   -0.171176   -0.274929    0.243173    -0.0514583  -0.00704161  -0.297094     0.25738    -0.16342     -0.0979141   0.087127     0.344492     0.00624947   0.299577    -0.213084     0.138369    0.00753566  -0.618275     0.336576   -0.192576  
  0.0105729    -0.334792     0.0234062   -0.309873    0.325364     0.207832    0.0656384  -0.801258    0.48614    -0.0671576    0.208861   -0.497262     0.147541     0.108227   -0.23555     -0.073702    0.335032     0.461968    -0.761752     0.794357    -0.0593269   -0.197865   -0.313627     0.31426      0.16623     0.0760233 
 -0.0282677     0.580174     0.166599     0.11366    -0.508602     0.184594   -0.0645259   0.0559046  -0.357802   -0.24127     -0.197088    0.318167     0.0172698   -0.0591887  -0.254345    -0.0669304   0.303373    -0.0393488    0.140368    -0.696595     0.104973     0.169729    0.222825    -0.270923    -0.338864    0.124695  
 -0.370212      0.658764    -0.420201     0.289872    0.123135     0.481971    0.245744   -0.0840305  -0.302049    0.69559     -0.0906429  -0.230641     0.335776     0.567902   -0.359621     0.480991    0.386154    -0.225857     0.465958     0.228863    -0.219835     0.662492    0.554753     0.325061     0.444064   -0.136141  
 -0.297664      0.027384    -0.676723     0.16728     0.0690105   -0.285911   -0.930936   -0.0713295  -1.01045     0.029363     0.191217    0.0641221    0.382457    -0.172362   -0.204838     0.094284    0.0369179   -0.0458557    0.515289    -0.256473    -0.180719     0.305777   -0.151922    -0.286626     0.222195    0.00549266
  0.398779      0.0660266    0.30358      0.0852926  -0.286099    -0.209138   -0.172277   -0.0584828  -0.196377   -0.326697     0.117425    0.0470984    0.424909     0.286181   -0.00875026   0.392092    0.0229217    0.11199      0.370896    -0.103474     0.119944     0.203614   -0.560992     0.647978     0.222977    0.598405  
  0.687057     -0.0689061    0.433305     0.632251   -0.623037     0.163123    0.344943   -0.241566    0.340994    0.163926    -0.582227   -0.252402     0.414437     0.296163    0.57126      0.805801    0.420284    -0.201298    -0.118319    -0.185852    -0.45689      0.688098   -0.12656     -0.363311    -0.491594    0.446614  
 -0.322201      0.137895    -0.347577    -0.770108    0.220615     0.0860839  -0.349985   -0.131542   -0.352618   -0.184964     0.372008   -0.00902081  -0.100694     0.0324958  -0.875967    -0.554051   -0.252965     0.0355019    0.0932137   -0.109401     0.517474    -0.339929   -0.137955     0.292553     0.273972   -0.278381  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407078
[ Info: iteration 2, average log likelihood -1.407067
[ Info: iteration 3, average log likelihood -1.407057
[ Info: iteration 4, average log likelihood -1.407047
[ Info: iteration 5, average log likelihood -1.407037
[ Info: iteration 6, average log likelihood -1.407028
[ Info: iteration 7, average log likelihood -1.407018
[ Info: iteration 8, average log likelihood -1.407010
[ Info: iteration 9, average log likelihood -1.407001
[ Info: iteration 10, average log likelihood -1.406993
â”Œ Info: EM with 100000 data points 10 iterations avll -1.406993
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
