Running tests with Julia v1.3.1-pre.12
   Cloning default registries into `~/.julia`
   Cloning registry from "https://github.com/JuliaRegistries/General.git"
[?25l    Fetching: [>                                        ]  0.0 %    Fetching: [=============>                           ]  31.0 %    Fetching: [================================>        ]  78.4 %[2K[?25h     Added registry `General` to `~/.julia/registries/General`
 Resolving package versions...
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.10
 Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.1.1
 Installed SpecialFunctions â”€â”€â”€ v0.8.0
 Installed OrderedCollections â”€ v1.1.0
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+1
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.2
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.6
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.21.10
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v0.8.10
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.10
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.1.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.8.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Building SpecialFunctions â†’ `~/.julia/packages/SpecialFunctions/ne2iw/deps/build.log`
  Building Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_in1dfA/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v0.8.10
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.10
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.1.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.8.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -1.4886279531207748e6, [98462.90964091316, 1537.0903590868472], [-2028.3704301405996 1862.2553689040142 1098.18047917259; 1781.9049263857912 -1642.537999564155 -1236.466346645485], Array{Float64,2}[[97072.42739078612 593.1577689323941 846.97953150716; 593.1577689323941 98076.17028703801 -596.7494151181606; 846.97953150716 -596.7494151181609 98189.54805198543], [3096.347657525832 -1336.019512457036 -1103.9450795619234; -1336.0195124570355 2585.890918031372 809.9080532057698; -1103.9450795619234 809.9080532057698 2049.281756672192]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /workspace/srcdir/julia/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.232353e+03
      1       9.226469e+02      -3.097058e+02 |        8
      2       8.594688e+02      -6.317804e+01 |        2
      3       8.578110e+02      -1.657776e+00 |        0
      4       8.578110e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 857.8110389721705)
â”Œ Info: K-means with 272 data points using 4 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.066459
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.769772
[ Info: iteration 2, lowerbound -3.617232
[ Info: iteration 3, lowerbound -3.452726
[ Info: iteration 4, lowerbound -3.275702
[ Info: iteration 5, lowerbound -3.111628
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.978269
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.875333
[ Info: iteration 8, lowerbound -2.814433
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.783446
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.762057
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.732105
[ Info: iteration 12, lowerbound -2.696634
[ Info: iteration 13, lowerbound -2.650809
[ Info: iteration 14, lowerbound -2.590878
[ Info: iteration 15, lowerbound -2.522616
[ Info: iteration 16, lowerbound -2.456856
[ Info: iteration 17, lowerbound -2.402506
[ Info: iteration 18, lowerbound -2.361327
[ Info: iteration 19, lowerbound -2.331277
[ Info: iteration 20, lowerbound -2.312545
[ Info: iteration 21, lowerbound -2.307530
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.302923
[ Info: iteration 23, lowerbound -2.299260
[ Info: iteration 24, lowerbound -2.299256
[ Info: iteration 25, lowerbound -2.299254
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Dec  5 13:16:24 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Dec  5 13:16:32 2019: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Thu Dec  5 13:16:33 2019: EM with 272 data points 0 iterations avll -2.066459
5.8 data points per parameter
, Thu Dec  5 13:16:35 2019: GMM converted to Variational GMM
, Thu Dec  5 13:16:45 2019: iteration 1, lowerbound -3.769772
, Thu Dec  5 13:16:45 2019: iteration 2, lowerbound -3.617232
, Thu Dec  5 13:16:45 2019: iteration 3, lowerbound -3.452726
, Thu Dec  5 13:16:45 2019: iteration 4, lowerbound -3.275702
, Thu Dec  5 13:16:45 2019: iteration 5, lowerbound -3.111628
, Thu Dec  5 13:16:45 2019: dropping number of Gaussions to 7
, Thu Dec  5 13:16:45 2019: iteration 6, lowerbound -2.978269
, Thu Dec  5 13:16:45 2019: dropping number of Gaussions to 6
, Thu Dec  5 13:16:45 2019: iteration 7, lowerbound -2.875333
, Thu Dec  5 13:16:45 2019: iteration 8, lowerbound -2.814433
, Thu Dec  5 13:16:45 2019: dropping number of Gaussions to 5
, Thu Dec  5 13:16:45 2019: iteration 9, lowerbound -2.783446
, Thu Dec  5 13:16:45 2019: dropping number of Gaussions to 4
, Thu Dec  5 13:16:45 2019: iteration 10, lowerbound -2.762057
, Thu Dec  5 13:16:45 2019: dropping number of Gaussions to 3
, Thu Dec  5 13:16:45 2019: iteration 11, lowerbound -2.732105
, Thu Dec  5 13:16:45 2019: iteration 12, lowerbound -2.696634
, Thu Dec  5 13:16:45 2019: iteration 13, lowerbound -2.650809
, Thu Dec  5 13:16:45 2019: iteration 14, lowerbound -2.590878
, Thu Dec  5 13:16:45 2019: iteration 15, lowerbound -2.522616
, Thu Dec  5 13:16:45 2019: iteration 16, lowerbound -2.456856
, Thu Dec  5 13:16:45 2019: iteration 17, lowerbound -2.402506
, Thu Dec  5 13:16:45 2019: iteration 18, lowerbound -2.361327
, Thu Dec  5 13:16:45 2019: iteration 19, lowerbound -2.331277
, Thu Dec  5 13:16:45 2019: iteration 20, lowerbound -2.312545
, Thu Dec  5 13:16:45 2019: iteration 21, lowerbound -2.307530
, Thu Dec  5 13:16:45 2019: dropping number of Gaussions to 2
, Thu Dec  5 13:16:45 2019: iteration 22, lowerbound -2.302923
, Thu Dec  5 13:16:45 2019: iteration 23, lowerbound -2.299260
, Thu Dec  5 13:16:45 2019: iteration 24, lowerbound -2.299256
, Thu Dec  5 13:16:45 2019: iteration 25, lowerbound -2.299254
, Thu Dec  5 13:16:45 2019: iteration 26, lowerbound -2.299254
, Thu Dec  5 13:16:45 2019: iteration 27, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 28, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 29, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 30, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 31, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 32, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 33, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 34, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 35, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 36, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 37, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 38, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 39, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 40, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 41, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 42, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 43, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 44, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 45, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 46, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 47, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 48, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 49, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: iteration 50, lowerbound -2.299253
, Thu Dec  5 13:16:45 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509222601658, 95.95490777398342]
Î² = [178.04509222601658, 95.95490777398342]
m = [4.250300733269889 79.28686694436152; 2.0002292577753473 53.85198717246118]
Î½ = [180.04509222601658, 97.95490777398342]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484394 -0.007644049042327456; 0.0 0.008581705166333083], [0.3758763611948765 -0.008953123827346634; 0.0 0.012748664777409715]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.978141910244044
avll from llpg:  -0.9781419102440437
avll direct:     -0.9781419102440438
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0130049537879502
avll from llpg:  -1.0130049537879502
avll direct:     -1.0130049537879502
sum posterior: 100000.00000000001
32Ã—26 Array{Float64,2}:
  0.200499     0.168493    -0.031788      0.0252051   -0.226087    -0.110512    -0.10621      0.158227      0.0895237    0.211492     0.186589    -0.0964956    0.0244278    0.261528      0.0211356    0.0247698   -0.162068    -0.0428921  -0.0146031   -0.0109292    0.0657354   -0.0978407   -0.0539283   -0.0732823    -0.142653     -0.0484122 
  0.0804487    0.0425094   -0.126466      0.0597134   -0.115132    -0.131885     0.0808856   -0.00795103   -0.031134     0.0454427    0.00107591   0.112269     0.0713493    0.101133     -0.0195972   -0.042272     0.0338588   -0.0166027  -0.0450988    0.0736323   -0.00425478  -0.0407369    0.0632947   -0.0126497     0.0217439    -0.0491887 
 -0.0361094    0.0916501    0.0415759     0.0981609    0.0541359    0.0828652    0.104962    -0.113464     -0.12857     -0.0272716    0.178347    -0.0690592    0.0313909    0.0729313     0.0188904    0.0011897   -0.148197    -0.227042    0.0891359   -0.0236834   -0.0279788   -0.193557    -0.056656     0.16304      -0.085483      0.00658237
  0.0992355   -0.023516     0.0526409     0.0902045    0.0357252   -0.110608     0.0146241    0.00671939   -0.0390913    0.137805     0.0136734   -0.0503155   -0.0667203    0.042484      0.144552    -0.0302452   -0.00760891  -0.0272138  -0.174015    -0.00805395  -0.120945    -0.248635     0.213817     0.0679209     0.00401852    0.111538  
 -0.111601    -0.0242072   -0.0407817    -0.0134234    0.111952    -0.0779659   -0.0116187   -0.207678     -0.0255077   -0.106194    -0.207137     0.0528332    0.00208088  -0.204976      0.0373966   -0.102149    -0.077429     0.052341    0.0460517   -0.073024     0.0374513    0.173609     0.0432623   -0.000557989   0.0236445    -0.0186996 
  0.0103486   -0.216569     0.17972       0.0277441   -0.0764329   -0.103733    -0.10271      0.063298      0.075549     0.0493845   -0.097411     0.0509602    0.00602351   0.0909846     0.112338    -0.126003    -0.00111529  -0.0236466  -0.110384    -0.131273     0.161849     0.0537778   -0.0296988   -0.00522721    0.0616664    -0.0577069 
 -0.0991515    0.109653     0.143608      0.139609    -0.111829    -0.0574732   -0.00252007   0.000876364  -0.0391515    0.0519749    0.142253     0.125321    -0.022426     0.0694437    -0.140752    -0.147927     0.00379233  -0.0115958  -0.190677     0.0271659   -0.0658337   -0.0296695    0.0147329    0.0134722    -0.0199051     0.0560518 
 -0.0133753   -0.0243645    0.0346231     0.038451    -0.00852416   0.136289     0.0233625   -0.061138     -0.102706     0.0842389    0.118008    -0.0584448   -0.0780068   -0.0781789    -0.0847462    0.0688513    0.010976    -0.0169299  -0.0320391   -0.0215526    0.0886273    0.051682     0.0405006   -0.0478741    -0.0971579    -0.00470483
 -0.0384166   -0.0367387    0.0699776    -0.10225     -0.114322    -0.122396     0.087696     0.0337116    -0.223527     0.100198    -0.0122924    0.0357495   -0.038559     0.0724354    -0.0289721    0.129117    -0.135585     0.12635    -0.19098     -0.0537332    0.0764082    0.00415246  -0.00715078   0.0549502     0.0200263     0.0799905 
 -0.0362923    0.00106385  -0.108131     -0.0727877    0.0511103    0.133875    -0.0279445    0.0361437     0.0349645    0.106949     0.069876     0.0352931   -0.196854    -0.144114      0.040765    -0.0736686   -0.0355142    0.010459   -0.110417    -0.0463091    0.162529     0.0226661   -0.00210769  -0.0235511    -0.0492785     0.18669   
 -0.124507     0.100137    -0.0675863    -0.0557478    0.153169     0.0396834    0.0740492    0.086986      0.0194748    0.0783852   -0.052219     0.01074     -0.089853     0.0481048     0.0835972   -0.111788    -0.0115251   -0.0988106  -0.30234      0.0941121   -0.117853    -0.0442058   -0.0701033    0.129578      0.164014      0.153457  
 -0.0281864   -0.0597379    0.125425      0.114263    -0.0332226    0.083324    -0.193849    -0.0455212    -0.136125     0.0760545    0.0134343   -0.0878476   -0.0953006    0.0109285     0.0148192    0.0177064   -0.0477409    0.018986   -0.0943163    0.119402    -0.116184    -0.0813468   -0.0675644   -0.0611298     0.124507     -0.00942337
  0.0315895    0.037726     0.0990032    -0.0447826    0.0623495   -0.0372992   -0.0737445    0.138861      0.123775    -0.00500871  -0.0590088   -0.00671596   0.106062    -0.0944144     0.184246     0.134832     0.0196424   -0.0455867  -0.0389869   -0.00260601  -0.0366402    0.132982     0.0541817    0.08222       0.0132095     0.209653  
 -0.0329399    0.0679578   -0.035451      0.0136166    0.0173986    0.168587     0.0261284   -0.0398482    -0.0547897    0.0634145   -0.093496    -0.0274561   -0.0972746    0.00689162    0.0234861   -0.0753085    0.00849871  -0.139588    0.21657     -0.0706587    0.204999     0.179613    -0.158265    -0.073035     -0.021943      0.0657561 
 -0.0308591   -0.11489     -0.0759001    -0.0639501   -0.0128234   -0.0216461   -0.022074    -0.0592933     0.0328023    0.020455    -0.0829796    0.0315511    0.176658     0.166574     -0.072607    -0.0505533    0.170623     0.0441269   0.0301037    0.196098     0.201168     0.0653241    0.0811306   -0.0402487     0.00903603    0.0139852 
 -0.0891669   -0.181185     0.0625525     0.0483418   -0.172428    -0.163272    -0.0294917   -0.065503      0.0982918    0.121654    -0.114022    -0.0333658   -0.00390611  -0.124558     -0.118483    -0.033454     0.00188737   0.0701331  -0.00961115  -0.074215    -0.11882     -0.167159    -0.00873658  -0.0450266    -0.222741      0.0625205 
  0.0108493   -0.0530324   -0.0265549     0.0178656    0.0942595   -0.0956943   -0.0606628   -0.077705     -0.0995527   -0.059668     0.0144516   -0.0219166   -0.0347145    0.108187      0.100703    -0.0569326   -0.124677     0.0629871  -0.163914    -0.0616467    0.00336155   0.117533     0.0156974   -0.0243178    -0.166777     -0.0922501 
 -0.186648     0.0873373    0.143876      0.00939994  -0.165719    -0.125031    -0.0558155    0.0365242     0.106626     0.113901    -0.0615162   -0.00447462  -0.0590435   -0.0106207    -0.0170702   -0.008807     0.126294     0.0133442   0.155408     0.0540662   -0.154114    -0.0761792    0.266353     0.00594324    0.00335367   -0.124184  
  0.00230981  -0.00798594  -0.00765816   -0.0622637    0.0959917   -0.175788     0.133593    -0.0999189     0.0142534    0.0515682   -0.0868958    0.102746     0.00272559  -0.0156338    -0.134356     0.0100483    0.046116    -0.0878674   0.180745     0.0167434    0.173477     0.0851721   -0.0397414   -0.117198      0.269468     -0.183586  
 -0.0141672   -0.0543298   -0.01344      -0.0801223   -0.130354    -0.0185843   -0.141806     0.0522285     0.0787482   -0.024234     0.209253    -0.036103     0.08424     -0.196198     -0.0218706   -0.00875219  -0.0872181   -0.119235    0.118386    -0.108491    -0.162678    -0.00912837   0.0174804    0.00668819   -0.0857071    -0.0481561 
 -0.0208775    0.0130399   -0.0683002    -0.192589     0.0619895    0.00564439  -0.0178862    0.0959792    -0.0654049   -0.00739716  -0.0741601   -0.043206    -0.128002    -0.190656     -0.00926171  -0.109533     0.0348521   -0.0776919   0.109452     0.0503933    0.0237897    0.0709456    0.0511759    0.076472      0.000925434   0.190193  
  0.0222914   -0.262246    -0.137349     -0.0691521    0.0140058    0.123438    -0.0409638   -0.183122      0.0764176   -0.0146837   -0.0936006   -0.0770621   -0.0202473   -0.00368124    0.00825779  -0.210472    -0.0218809   -0.0756251  -0.0652203    0.0305928    0.00386828  -0.107618    -0.0380324   -0.00541248    0.0426847     0.19964   
  0.109779    -0.0549695    0.0236371    -0.0433307    0.0442336   -0.0396083    0.0713251    0.0071355     0.0560258   -0.106252    -0.152995    -0.0156073   -0.134777     0.0889852     0.132284     0.0546123    0.0484988   -0.0919506  -0.112872    -0.120819     0.0915195    0.289071     0.135815    -0.0363025     0.0808063    -0.0452459 
  0.0510233    0.0452404    0.0417932    -0.0202626   -0.0330014   -0.0952535   -0.0458003   -0.227965     -0.111112     0.105923     0.0114164   -0.00896194   0.139452    -0.0956764    -0.110203    -0.0893394    0.073091    -0.142578   -0.0573455   -0.154492    -0.092528    -0.159238    -0.0815701   -0.0403028    -0.0174216     0.0141774 
 -0.0535218   -0.0881519    0.232917     -0.0375158   -0.0758713   -0.0110683   -0.204503     0.0847839    -0.109474     0.144597    -0.0807123    0.0500916    0.0144026    0.0641082    -0.17218     -0.206102    -0.00646998   0.0975793  -0.116835     0.056784     0.0560738   -0.143782     0.102655     0.0568599    -0.0177626     0.0288308 
  0.0129605   -0.0261905    0.196356      0.0935663   -0.00410117  -0.223422     0.1216      -0.0665686     0.00841485  -0.00762839  -0.0274242   -0.0303608   -0.0913547   -0.000745607  -0.00158421   0.139376     0.119269    -0.0366269  -0.158129    -0.156257     0.0609236   -0.11458     -0.0414112   -0.0842022     0.145853     -0.0124011 
 -0.078897     0.0458057   -0.0376106     0.0339414   -0.0147914    0.0368805    0.0360414   -0.102947     -0.05753     -0.0465558   -0.0757288    0.0613097    0.119095     0.0186338     0.128125     0.109674     0.232793     0.0891268  -0.183379    -0.00457182  -0.199304    -0.101247     0.0944774    0.036609     -0.0541203    -0.0233691 
  0.053696    -0.0383625    0.000674768  -0.036314    -0.0396342    0.0375321   -0.09296     -0.0838406     0.0764602   -0.0790298   -0.0206435   -0.0339906   -0.0553152    0.034003     -0.00010411  -0.00162835  -0.0144382    0.0785227  -0.00691619   0.0210579   -0.0203422    0.00944198  -0.143226     0.0823647     0.0932081    -0.139358  
  0.106949    -0.161675     0.0378956    -0.102375     0.120581     0.0475869   -0.109889    -0.042671      0.117254    -0.0888674    0.0673153   -0.0726827    0.107549     0.133291     -0.0556099   -0.0871234   -0.0851591   -0.11961    -0.0527466   -0.163251    -0.100408    -0.0165197   -0.0960828   -0.0679701    -0.236055     -0.0652652 
  0.00313007  -0.0772356   -0.109232     -0.0259332   -0.0301097    0.107073    -0.0997465    0.0406862    -0.0275934    0.120849    -0.0413652   -0.101911    -0.0181332   -0.128231      0.0192308    0.0124354   -0.131854     0.0722081   0.117236    -0.130496     0.0746057   -0.0354231   -0.10538     -0.0817099    -0.0231498    -0.0725736 
 -0.23727     -0.112219     0.0563424     0.163716     0.0145484   -0.0106412    0.0100859   -0.0339775     0.0346024    0.0516506   -0.0617576    0.263904    -0.0138506    0.0738346    -0.129317     0.0497435    0.032745    -0.0185647   0.0804674   -0.0662069    0.0192972   -0.00140309  -0.262402     0.104212     -0.0282644     0.164886  
 -0.105629     0.167455    -0.00567732   -0.0222404    0.0286548    0.144853     0.00526283  -0.0283748     0.0565464    0.0278688    0.09763     -0.159058    -0.00497956   0.0881529    -0.0727149   -0.139675     4.06356e-5   0.0133373   0.00440055   0.0118462   -0.0106432   -0.100825     0.0559531    0.0916677    -0.014065      0.0308669 kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4185291272862828
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418595
[ Info: iteration 2, average log likelihood -1.418534
[ Info: iteration 3, average log likelihood -1.418202
[ Info: iteration 4, average log likelihood -1.414120
[ Info: iteration 5, average log likelihood -1.399232
[ Info: iteration 6, average log likelihood -1.390135
[ Info: iteration 7, average log likelihood -1.388347
[ Info: iteration 8, average log likelihood -1.387598
[ Info: iteration 9, average log likelihood -1.386991
[ Info: iteration 10, average log likelihood -1.386443
[ Info: iteration 11, average log likelihood -1.386027
[ Info: iteration 12, average log likelihood -1.385740
[ Info: iteration 13, average log likelihood -1.385521
[ Info: iteration 14, average log likelihood -1.385254
[ Info: iteration 15, average log likelihood -1.384732
[ Info: iteration 16, average log likelihood -1.384058
[ Info: iteration 17, average log likelihood -1.383490
[ Info: iteration 18, average log likelihood -1.383063
[ Info: iteration 19, average log likelihood -1.382725
[ Info: iteration 20, average log likelihood -1.382483
[ Info: iteration 21, average log likelihood -1.382329
[ Info: iteration 22, average log likelihood -1.382234
[ Info: iteration 23, average log likelihood -1.382174
[ Info: iteration 24, average log likelihood -1.382135
[ Info: iteration 25, average log likelihood -1.382109
[ Info: iteration 26, average log likelihood -1.382090
[ Info: iteration 27, average log likelihood -1.382077
[ Info: iteration 28, average log likelihood -1.382066
[ Info: iteration 29, average log likelihood -1.382058
[ Info: iteration 30, average log likelihood -1.382052
[ Info: iteration 31, average log likelihood -1.382047
[ Info: iteration 32, average log likelihood -1.382044
[ Info: iteration 33, average log likelihood -1.382041
[ Info: iteration 34, average log likelihood -1.382039
[ Info: iteration 35, average log likelihood -1.382037
[ Info: iteration 36, average log likelihood -1.382036
[ Info: iteration 37, average log likelihood -1.382035
[ Info: iteration 38, average log likelihood -1.382034
[ Info: iteration 39, average log likelihood -1.382034
[ Info: iteration 40, average log likelihood -1.382034
[ Info: iteration 41, average log likelihood -1.382033
[ Info: iteration 42, average log likelihood -1.382033
[ Info: iteration 43, average log likelihood -1.382033
[ Info: iteration 44, average log likelihood -1.382033
[ Info: iteration 45, average log likelihood -1.382033
[ Info: iteration 46, average log likelihood -1.382033
[ Info: iteration 47, average log likelihood -1.382033
[ Info: iteration 48, average log likelihood -1.382033
[ Info: iteration 49, average log likelihood -1.382033
[ Info: iteration 50, average log likelihood -1.382033
â”Œ Info: EM with 100000 data points 50 iterations avll -1.382033
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4185945412737715
â”‚     -1.418534212101455 
â”‚      â‹®                 
â””     -1.382032584296369 
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.382183
[ Info: iteration 2, average log likelihood -1.382056
[ Info: iteration 3, average log likelihood -1.381631
[ Info: iteration 4, average log likelihood -1.377541
[ Info: iteration 5, average log likelihood -1.361625
[ Info: iteration 6, average log likelihood -1.348042
[ Info: iteration 7, average log likelihood -1.343609
[ Info: iteration 8, average log likelihood -1.341766
[ Info: iteration 9, average log likelihood -1.340697
[ Info: iteration 10, average log likelihood -1.339942
[ Info: iteration 11, average log likelihood -1.339309
[ Info: iteration 12, average log likelihood -1.338698
[ Info: iteration 13, average log likelihood -1.338055
[ Info: iteration 14, average log likelihood -1.337339
[ Info: iteration 15, average log likelihood -1.336514
[ Info: iteration 16, average log likelihood -1.335551
[ Info: iteration 17, average log likelihood -1.334520
[ Info: iteration 18, average log likelihood -1.333596
[ Info: iteration 19, average log likelihood -1.332982
[ Info: iteration 20, average log likelihood -1.332584
[ Info: iteration 21, average log likelihood -1.332312
[ Info: iteration 22, average log likelihood -1.332134
[ Info: iteration 23, average log likelihood -1.332033
[ Info: iteration 24, average log likelihood -1.331975
[ Info: iteration 25, average log likelihood -1.331937
[ Info: iteration 26, average log likelihood -1.331911
[ Info: iteration 27, average log likelihood -1.331891
[ Info: iteration 28, average log likelihood -1.331876
[ Info: iteration 29, average log likelihood -1.331864
[ Info: iteration 30, average log likelihood -1.331855
[ Info: iteration 31, average log likelihood -1.331847
[ Info: iteration 32, average log likelihood -1.331841
[ Info: iteration 33, average log likelihood -1.331836
[ Info: iteration 34, average log likelihood -1.331832
[ Info: iteration 35, average log likelihood -1.331829
[ Info: iteration 36, average log likelihood -1.331827
[ Info: iteration 37, average log likelihood -1.331825
[ Info: iteration 38, average log likelihood -1.331823
[ Info: iteration 39, average log likelihood -1.331821
[ Info: iteration 40, average log likelihood -1.331820
[ Info: iteration 41, average log likelihood -1.331819
[ Info: iteration 42, average log likelihood -1.331818
[ Info: iteration 43, average log likelihood -1.331817
[ Info: iteration 44, average log likelihood -1.331816
[ Info: iteration 45, average log likelihood -1.331815
[ Info: iteration 46, average log likelihood -1.331815
[ Info: iteration 47, average log likelihood -1.331814
[ Info: iteration 48, average log likelihood -1.331813
[ Info: iteration 49, average log likelihood -1.331813
[ Info: iteration 50, average log likelihood -1.331812
â”Œ Info: EM with 100000 data points 50 iterations avll -1.331812
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3821826210988952
â”‚     -1.3820561772469264
â”‚      â‹®                 
â””     -1.3318122311297622
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.332015
[ Info: iteration 2, average log likelihood -1.331830
[ Info: iteration 3, average log likelihood -1.331224
[ Info: iteration 4, average log likelihood -1.325161
[ Info: iteration 5, average log likelihood -1.303429
[ Info: iteration 6, average log likelihood -1.283945
[ Info: iteration 7, average log likelihood -1.277607
[ Info: iteration 8, average log likelihood -1.274966
[ Info: iteration 9, average log likelihood -1.272882
[ Info: iteration 10, average log likelihood -1.270786
[ Info: iteration 11, average log likelihood -1.269271
[ Info: iteration 12, average log likelihood -1.268465
[ Info: iteration 13, average log likelihood -1.268131
[ Info: iteration 14, average log likelihood -1.268020
[ Info: iteration 15, average log likelihood -1.267975
[ Info: iteration 16, average log likelihood -1.267950
[ Info: iteration 17, average log likelihood -1.267934
[ Info: iteration 18, average log likelihood -1.267923
[ Info: iteration 19, average log likelihood -1.267916
[ Info: iteration 20, average log likelihood -1.267910
[ Info: iteration 21, average log likelihood -1.267905
[ Info: iteration 22, average log likelihood -1.267902
[ Info: iteration 23, average log likelihood -1.267899
[ Info: iteration 24, average log likelihood -1.267896
[ Info: iteration 25, average log likelihood -1.267893
[ Info: iteration 26, average log likelihood -1.267891
[ Info: iteration 27, average log likelihood -1.267888
[ Info: iteration 28, average log likelihood -1.267886
[ Info: iteration 29, average log likelihood -1.267883
[ Info: iteration 30, average log likelihood -1.267880
[ Info: iteration 31, average log likelihood -1.267876
[ Info: iteration 32, average log likelihood -1.267872
[ Info: iteration 33, average log likelihood -1.267868
[ Info: iteration 34, average log likelihood -1.267864
[ Info: iteration 35, average log likelihood -1.267860
[ Info: iteration 36, average log likelihood -1.267855
[ Info: iteration 37, average log likelihood -1.267851
[ Info: iteration 38, average log likelihood -1.267846
[ Info: iteration 39, average log likelihood -1.267842
[ Info: iteration 40, average log likelihood -1.267837
[ Info: iteration 41, average log likelihood -1.267833
[ Info: iteration 42, average log likelihood -1.267828
[ Info: iteration 43, average log likelihood -1.267823
[ Info: iteration 44, average log likelihood -1.267817
[ Info: iteration 45, average log likelihood -1.267811
[ Info: iteration 46, average log likelihood -1.267805
[ Info: iteration 47, average log likelihood -1.267799
[ Info: iteration 48, average log likelihood -1.267793
[ Info: iteration 49, average log likelihood -1.267787
[ Info: iteration 50, average log likelihood -1.267781
â”Œ Info: EM with 100000 data points 50 iterations avll -1.267781
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3320147299366694
â”‚     -1.3318300035269033
â”‚      â‹®                 
â””     -1.267781208132388 
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.268047
[ Info: iteration 2, average log likelihood -1.267771
[ Info: iteration 3, average log likelihood -1.267157
[ Info: iteration 4, average log likelihood -1.259647
[ Info: iteration 5, average log likelihood -1.230607
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.203354
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.202886
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.200681
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.199654
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.194074
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     2
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.192951
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.205389
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.201366
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.195697
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.193945
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     4
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.191705
[ Info: iteration 17, average log likelihood -1.206278
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     4
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.187610
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.199201
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.194323
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.194235
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.194277
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     2
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.192583
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.201251
[ Info: iteration 25, average log likelihood -1.198187
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     4
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.183424
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.200317
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.196814
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.194321
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.189587
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.186559
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚      7
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.184232
[ Info: iteration 33, average log likelihood -1.215768
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.194209
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.191871
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.201021
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.195709
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      4
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.194144
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.199521
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     4
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.190119
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.197978
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      4
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.190988
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.201529
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      4
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.193330
[ Info: iteration 45, average log likelihood -1.205430
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.185070
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     10
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.182390
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.210325
[ Info: iteration 49, average log likelihood -1.201119
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      4
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.182701
â”Œ Info: EM with 100000 data points 50 iterations avll -1.182701
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2680466618870825
â”‚     -1.2677707338486544
â”‚      â‹®                 
â””     -1.182701209422406 
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     3
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.196736
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      7
â”‚      8
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.178666
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.182932
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      7
â”‚      8
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.162310
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     17
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.108252
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      7
â”‚      8
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.068683
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     19
â”‚     20
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.088287
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      7
â”‚      8
â”‚     12
â”‚     17
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.070454
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     13
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.073483
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      7
â”‚      8
â”‚     12
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.079593
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     17
â”‚      â‹®
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.068517
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      7
â”‚      8
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.069623
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     19
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.086949
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     17
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.061142
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     13
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.064670
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      7
â”‚      8
â”‚     12
â”‚     17
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.070562
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      5
â”‚     19
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.061429
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      7
â”‚      8
â”‚      â‹®
â”‚     24
â”‚     27
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.054505
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     21
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.086584
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.057674
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     13
â”‚     17
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.067241
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.057634
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.088618
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     21
â”‚     27
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.036377
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.109796
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.045432
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     13
â”‚     24
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.069917
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      7
â”‚      â‹®
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.057249
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     21
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.084879
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     13
â”‚     27
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.054530
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     17
â”‚     19
â”‚     20
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.078559
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      8
â”‚     12
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.059264
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.055542
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      7
â”‚      8
â”‚     12
â”‚     21
â”‚     24
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.080365
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.082147
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.044939
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.094478
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.034182
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     13
â”‚     21
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.086361
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      8
â”‚     12
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.075618
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     17
â”‚     19
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.071582
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.055414
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     17
â”‚     19
â”‚     20
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.073217
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     21
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.052066
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     13
â”‚     19
â”‚     20
â”‚     27
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.079861
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      8
â”‚     12
â”‚     17
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.067596
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     19
â”‚     20
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.074512
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.049769
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚     19
â”‚     20
â”‚     21
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.078421
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      8
â”‚     12
â”‚     24
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.067326
â”Œ Info: EM with 100000 data points 50 iterations avll -1.067326
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.1967357526820215
â”‚     -1.1786659718634651
â”‚      â‹®                 
â””     -1.0673257318071296
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4185291272862828
â”‚     -1.4185945412737715
â”‚     -1.418534212101455 
â”‚     -1.4182019557846481
â”‚      â‹®                 
â”‚     -1.0497685225788713
â”‚     -1.0784214345322676
â””     -1.0673257318071296
32Ã—26 Array{Float64,2}:
 -0.059266     0.109988     0.112597     0.163747    -0.108679    -0.080248    -0.0215959   -0.026052    -0.0607676     0.0343004    0.13208      0.112828   -0.0106133    0.0252999   -0.128743     -0.065785      0.0231382   -0.051058    -0.177485     0.00162043  -0.0817375   -0.0551182   -0.00969978  -0.00826204  -0.0316697    0.0571443 
  0.0796401    0.0587891    0.0183676   -0.0441878   -0.0183739   -0.0952442   -0.0187846   -0.254456    -0.122303      0.0989459   -0.0171138   -0.0303676   0.171956    -0.115579    -0.113233     -0.059912      0.00911335  -0.155397    -0.0207006   -0.201079    -0.0998962   -0.146997    -0.0939864   -0.0547624   -0.0341852    0.0141682 
 -0.0332018   -0.26441     -0.124556    -0.0688409    0.0420665    0.122628     0.205634    -0.183374     0.105451     -0.0182576   -0.0934111   -0.0924839  -0.0600753   -0.0744437    0.0392643    -0.209662     -0.0157939   -0.0802739   -0.0544174    0.192672     0.0188454   -0.76754     -0.0307959    0.0384974   -0.0684353    0.202022  
  0.0697572   -0.265062    -0.163419    -0.0692343   -0.012788     0.124016    -0.305922    -0.200055     0.072768     -0.010301    -0.101971    -0.0748003   0.022627     0.0706939   -0.00813405   -0.210551     -0.0387226   -0.0433005   -0.0736055   -0.143169    -0.0190788    0.760648    -0.0354055   -0.0888071    0.216828     0.213938  
  0.0173174   -0.076991    -0.115669    -0.00529066  -0.00907816   0.106702    -0.134279     0.0425195   -0.0380093     0.0990929   -0.0795688   -0.102689   -0.0181576   -0.125404     0.0242189    -0.0327513    -0.144494     0.113327     0.118893    -0.103496     0.0747463   -0.0571955   -0.0539388   -0.0748763   -0.0160941   -0.0791593 
 -0.0377659   -0.0429737    0.0717411   -0.144591    -0.117493    -0.1227       0.123931     0.0683477   -0.227824      0.131662    -0.0206753    0.0365786  -0.0396189    0.0731243   -0.0290157     0.148511     -0.133499     0.0595729   -0.18947     -0.0544733    0.0836542    0.00189035   0.0174932    0.0549379    0.0187006    0.0883647 
 -0.030931    -0.0711661   -0.0733181   -0.0870122   -0.0311336   -0.0250552   -0.0154074   -0.0490199   -1.09344       0.0378048   -0.0911658    0.0340666   0.175908     0.165123    -0.0858541    -0.115257      0.177818     0.0341627    0.0193548    0.191457     0.200691     0.0613927    0.0839922   -0.012408     0.0121682    0.0149751 
 -0.0307706   -0.127612    -0.0816233   -0.0537458   -0.0159175   -0.0179289   -0.0283082   -0.0914115    0.987719      0.00706056  -0.0861663    0.0317693   0.17814      0.169463    -0.0842479     0.0507826     0.17852      0.0523993    0.0539286    0.189699     0.200148     0.0303241    0.0834243   -0.0367498    0.00839051   0.0131244 
 -0.0240049    0.0481965   -0.106301    -0.190106     0.0376528    0.00747204  -0.0278336    0.131588    -0.0684194    -0.00386168  -0.0503251   -0.0382012  -0.134199    -0.183988    -0.00726958   -0.0975372     0.0385434   -0.0837737    0.110337     0.0413988    0.0232555    0.089227     0.0511276    0.0951379   -0.00347892   0.186515  
  0.123832    -0.0546995    0.0373831   -0.038158     0.0613649   -0.0222447    0.0599531   -0.00444201   0.0471403    -0.102578    -0.140628    -0.0391939  -0.131852     0.0971915    0.113875      0.0641059     0.0286974   -0.0861229   -0.0739614   -0.123671     0.0991533    0.297223     0.109124    -0.0176347    0.0748098   -0.0404337 
 -0.106907     0.167739    -0.0117824   -0.0255547    0.0210587    0.152105     0.00185357  -0.0390091    0.05139       0.0293899    0.0900139   -0.160037   -0.0174156    0.106607    -0.070437     -0.183694     -0.0116801   -0.00261629   0.00751928   0.00891856  -0.0137928   -0.0959368    0.048559     0.0610231   -0.0178909    0.0625962 
  0.0972777   -0.0772576    0.0467826    0.0901801    0.0136962   -0.106689     0.0157836    0.0058261   -0.0590837     0.15189      0.0489302   -0.0729654  -0.146713     0.044199     0.148329     -0.0274532    -0.00926623   0.0118103   -0.173824    -0.0139477   -0.120362    -0.239723     0.212784     0.0633247    0.00271186   0.123093  
  0.0158196   -0.0545022    0.0398905    0.015932     0.105661    -0.100798    -0.0806282   -0.0767758   -0.112535     -0.0560897    0.00851678  -0.0217187  -0.0376665    0.118977     0.0924344     0.0101626    -0.115581     0.0572531   -0.152336    -0.0608205    0.00309062   0.145489     0.0143627   -0.0316243   -0.165059    -0.0855617 
  0.00762527  -0.204491     0.169992     0.00900341  -0.0787945   -0.104949    -0.106618     0.0453591    0.0529088     0.048501    -0.098979     0.0568988   0.00596358   0.0709523    0.107248     -0.111047     -0.0405718   -0.029594    -0.146201    -0.169791     0.154061     0.087433    -0.0346581    0.0452595    0.0629749   -0.0575907 
 -0.0317946   -0.00179535  -0.106923    -0.0896263    0.0354068    0.101448    -0.0496698    0.0463144    0.0306119     0.0721186    0.086014     0.0379441  -0.193129    -0.142269     0.0583357    -0.0908445    -0.0502499    0.00254756  -0.100342    -0.0456026    0.165343     0.017073    -0.00555778  -0.0198293   -0.0435159    0.2057    
 -0.0164774   -0.0564146    0.0706495   -0.0580261   -0.120835    -0.0255894   -0.147908     0.0252693    0.0751891    -0.0172026    0.170033    -0.0575453   0.0809784   -0.194042     0.000354176   0.0185419    -0.0942678   -0.0939393    0.116898    -0.111042    -0.171293    -0.00397635   0.0189907   -0.00571547  -0.086433    -0.0299317 
 -0.0308771   -0.0878529    0.129342     0.140199    -0.0340445    0.0852085   -0.194699    -0.0599738   -0.135853      0.102641     0.00858995  -0.0975155  -0.117591     0.00810332  -0.00706916    0.0165717    -0.0480009    0.0199301   -0.0954774    0.131902    -0.130116    -0.077292    -0.0650955   -0.0451615    0.118691     0.00902327
 -0.051252    -0.0957225    0.227457    -0.054446    -0.0854193   -0.0101448   -0.196555     0.0835977   -0.109773      0.137762    -0.080852     0.0942998   0.0203517    0.0681832   -0.158171     -0.239958      0.0156747    0.0982701   -0.116403     0.0607279    0.0547131   -0.145477     0.0940894    0.0563267   -0.00175287   0.0320945 
  0.0828196   -0.18971      0.060814    -0.0882423    0.142147     0.0239854   -0.0985589   -0.0372635    0.119781     -0.0610848    0.0727711   -2.12982     0.152817     0.127381    -0.0410232    -0.0897348    -0.078369    -0.15238     -0.0754186   -0.299489    -0.100068    -0.0178179   -0.0318608   -0.0606921   -0.222998    -0.0254142 
  0.0949834   -0.095808     0.00638062  -0.0671047    0.112125     0.0144122   -0.122667    -0.0299725    0.119421     -0.0667271    0.0715486    2.22065     0.0803535    0.127132    -0.0776326    -0.0971673    -0.0801406   -0.0403337   -0.112956     0.0545033   -0.104937    -0.0209171   -0.168472    -0.063091    -0.222559    -0.0633709 
 -0.0759337   -0.139249     0.0705079    0.0468311   -0.110773    -0.151372    -0.00998559  -0.0411976    0.124991      0.124791    -0.0982379   -0.0305251  -0.00334694  -0.107122    -0.0728474    -0.0223263     0.0031589    0.0539567   -0.0282835   -0.0867969   -0.121071    -0.159437    -0.00531659   0.00195894  -0.185375     0.0807354 
 -0.0556589    0.0264587    0.0250028   -0.0235352    0.116591    -0.0487609   -0.0604408   -0.0393415    0.0604253    -0.0524664   -0.131302     0.0256822   0.0559601   -0.142123     0.116197      0.0446342    -0.0414497    0.00381587   0.0162873   -0.0453804    0.00504038   0.191247     0.05448      0.0292654    0.0343277    0.0710477 
 -0.187081     0.0760842    0.12963     -0.0237469   -0.16076     -0.12789     -0.0311166    0.0594689    0.103288      0.126698    -0.0622801    0.0308945  -0.0523648   -0.0149519   -0.0218838    -0.0348708     0.120232     0.00781118   0.169653     0.0261851   -0.158994    -0.0725042    0.243857     0.0262822    0.00224736  -0.115856  
 -0.0440754    0.0889528    0.0429174    0.09865      0.056676     0.0908348    0.0885594   -0.0985623   -0.0937208    -0.099305     0.170821    -0.0551035   0.0251364    0.0803672    0.0251415     0.000596397  -0.154997    -0.218341     0.0860858   -0.0160692   -0.0309238   -0.186363    -0.0763968    0.152003    -0.0737089    0.0130512 
 -0.116541     0.0492268   -0.0026701    0.0391371   -0.0273295    0.0553918    0.0328854   -0.0788392   -0.053088     -0.0499492   -0.0630946    0.0336473   0.138277    -0.0146361    0.114716      0.110477      0.236606     0.0632698   -0.173933    -0.00598718  -0.213088    -0.0796951    0.0467735    0.0491149   -0.0360435   -0.0273551 
 -0.0581646   -0.0721903    0.022087     0.0479717   -0.017428     0.0165009   -0.0595157   -0.0560732    0.0551559     0.00755113  -0.0305008    0.0936132  -0.0730825    0.0404327   -0.0646097     0.0168356     0.0231998    0.0132148    0.0378045   -0.0118747   -0.00729206   0.00274628  -0.208005     0.0824192   -0.0266356    0.00508626
 -0.120811     0.118962    -0.0749869   -0.0638583    0.119519     0.0443274    0.0644279    0.0752849    0.0212493     0.0828259   -0.0429555    0.0191519  -0.0811672    0.0620779    0.0775273    -0.136895      0.0135618   -0.0953189   -0.305895     0.0928727   -0.0897226   -0.0439089   -0.0748295    0.118263     0.128383     0.137182  
 -0.0319303    0.0543372   -0.0399568    0.0146933    0.0266336    0.159637     0.0236661   -0.0547221   -0.0574698     0.0636258   -0.0832807   -0.0359329  -0.0866455   -0.0067369    0.032831     -0.070054      0.0331807   -0.137638     0.266027    -0.0683676    0.223371     0.161444    -0.157674    -0.0823762   -0.0241613    0.064662  
  0.012271    -0.0178942    0.104767     0.0666      -0.00789142  -0.03587      0.0441368   -0.0239523   -0.0557129     0.0303899    0.0225842   -0.0579018  -0.0974156   -0.0392872   -0.0500054     0.0723604     0.0613808   -0.0292142   -0.0945291   -0.0951949    0.0699813   -0.0302574    0.00761744  -0.0637084    0.00224862  -0.0165083 
  0.125139     0.118357    -0.0649539    0.0625586   -0.188133    -0.118079    -0.00751524   0.0682033   -0.00527576    0.102919     0.0930053    0.020465    0.00881528   0.168226    -0.039114     -0.0415709    -0.0673792   -0.0330297   -0.0118574    0.0348483    0.0175056   -0.0626968   -0.010919    -0.0325407   -0.0464753   -0.0517899 
  0.483369    -2.08743      0.964626    -1.57166      0.153707    -0.307427    -0.16142     -0.774592     0.000432604   0.0520193   -0.297214     0.12732     0.416463    -0.920076    -0.202333      0.00077773   -0.73192     -1.41988      0.255464     0.018505     0.178276     0.0934086   -0.0380257   -0.224642     0.287653     0.683722  
  0.0252625    0.0412811    0.0276224   -0.0369869    0.0901262   -0.170161     0.127117    -0.074934     0.0156889     0.0514628   -0.102205     0.0985693   0.0158139   -0.00127145  -0.124787      0.0146048     0.0699222   -0.0466246    0.172103     0.0160685    0.174684     0.0809607   -0.0384686   -0.131934     0.247449    -0.210154  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     13
â”‚     17
â”‚     27
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.068068
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.028920
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     13
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.050191
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    15-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.019974
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     13
â”‚     17
â”‚     19
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.066766
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.029629
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     13
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.048121
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    15-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.020382
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     13
â”‚     17
â”‚     19
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.066465
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     27
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.030095
â”Œ Info: EM with 100000 data points 10 iterations avll -1.030095
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind diag, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.466040e+05
      1       6.927342e+05      -1.538699e+05 |       32
      2       6.544637e+05      -3.827043e+04 |       32
      3       6.351275e+05      -1.933621e+04 |       32
      4       6.248648e+05      -1.026273e+04 |       32
      5       6.187505e+05      -6.114309e+03 |       32
      6       6.149573e+05      -3.793190e+03 |       32
      7       6.123519e+05      -2.605445e+03 |       32
      8       6.103297e+05      -2.022118e+03 |       32
      9       6.090311e+05      -1.298647e+03 |       32
     10       6.082621e+05      -7.689866e+02 |       32
     11       6.078907e+05      -3.714483e+02 |       32
     12       6.077086e+05      -1.820420e+02 |       32
     13       6.076042e+05      -1.044410e+02 |       32
     14       6.075440e+05      -6.012999e+01 |       32
     15       6.074912e+05      -5.287716e+01 |       32
     16       6.074351e+05      -5.603275e+01 |       32
     17       6.073538e+05      -8.133095e+01 |       32
     18       6.071955e+05      -1.582940e+02 |       32
     19       6.068972e+05      -2.982905e+02 |       32
     20       6.064217e+05      -4.755072e+02 |       32
     21       6.058756e+05      -5.460867e+02 |       32
     22       6.055110e+05      -3.645792e+02 |       32
     23       6.053282e+05      -1.828698e+02 |       32
     24       6.051843e+05      -1.439226e+02 |       32
     25       6.050469e+05      -1.373956e+02 |       32
     26       6.049250e+05      -1.218750e+02 |       32
     27       6.048099e+05      -1.151292e+02 |       32
     28       6.046767e+05      -1.331899e+02 |       32
     29       6.045786e+05      -9.809040e+01 |       32
     30       6.045290e+05      -4.952859e+01 |       32
     31       6.045013e+05      -2.772869e+01 |       30
     32       6.044897e+05      -1.164872e+01 |       30
     33       6.044820e+05      -7.659691e+00 |       28
     34       6.044754e+05      -6.611181e+00 |       22
     35       6.044690e+05      -6.397497e+00 |       28
     36       6.044628e+05      -6.214465e+00 |       27
     37       6.044539e+05      -8.931642e+00 |       30
     38       6.044400e+05      -1.383494e+01 |       31
     39       6.044261e+05      -1.391420e+01 |       31
     40       6.044102e+05      -1.589044e+01 |       31
     41       6.043895e+05      -2.073723e+01 |       30
     42       6.043689e+05      -2.058932e+01 |       30
     43       6.043396e+05      -2.931958e+01 |       30
     44       6.043055e+05      -3.409999e+01 |       29
     45       6.042566e+05      -4.882304e+01 |       30
     46       6.042071e+05      -4.954875e+01 |       31
     47       6.041731e+05      -3.399225e+01 |       30
     48       6.041569e+05      -1.616976e+01 |       31
     49       6.041490e+05      -7.939956e+00 |       26
     50       6.041439e+05      -5.091785e+00 |       23
K-means terminated without convergence after 50 iterations (objv = 604143.9004995727)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.325836
[ Info: iteration 2, average log likelihood -1.293450
[ Info: iteration 3, average log likelihood -1.262432
[ Info: iteration 4, average log likelihood -1.234801
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.201758
[ Info: iteration 6, average log likelihood -1.172422
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚      5
â”‚      6
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.111041
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.113358
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      7
â”‚     14
â”‚     23
â”‚     27
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.093631
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      6
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.130722
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚     26
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.088447
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.090905
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      4
â”‚      5
â”‚      6
â”‚     14
â”‚     23
â”‚     27
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.058828
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚     18
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.130592
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.114251
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     1
â”‚     6
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.076874
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     23
â”‚     27
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.056654
[ Info: iteration 18, average log likelihood -1.150825
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      6
â”‚      8
â”‚     18
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.072691
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.104314
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     14
â”‚     22
â”‚     23
â”‚     27
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.047475
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      6
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.133217
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.100667
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     18
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.076225
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     14
â”‚     22
â”‚     23
â”‚     27
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.063768
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.135616
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     28
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.092127
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      4
â”‚      5
â”‚      6
â”‚      7
â”‚     18
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.068615
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚     14
â”‚     22
â”‚     23
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.104208
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      8
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.115904
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.087604
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚     18
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.073378
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      8
â”‚     14
â”‚     22
â”‚     23
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.079369
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.119291
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.124378
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     3
â”‚     4
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.051131
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      6
â”‚      8
â”‚     14
â”‚      â‹®
â”‚     23
â”‚     27
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.039554
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚     28
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.134589
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.138419
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     4
â”‚     6
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.095429
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      8
â”‚     14
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.080350
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      5
â”‚     18
â”‚     22
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.072831
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      6
â”‚      7
â”‚     27
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.083247
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.131710
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     14
â”‚     23
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.088460
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      5
â”‚      6
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.092206
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.092075
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚     14
â”‚     22
â”‚     26
â”‚     27
â”‚     28
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.064374
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      5
â”‚      6
â”‚      7
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.112606
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.146574
â”Œ Info: EM with 100000 data points 50 iterations avll -1.146574
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.0427903   -0.109946     0.0804804   -0.0446207    0.0458013   -0.110682    -0.0342146    0.0552763    0.162637     0.108097    -0.0894064   -0.022769    0.036894   -0.105463      0.065322     0.0284491     0.0117742     0.0233743   -0.0279436   -0.00715168  -0.101535     0.0990085    0.0208777    0.0449312   -0.128298     0.157294  
 -0.0142012   -0.0588827    0.0805585   -0.0661876   -0.10786     -0.0193588   -0.146913     0.0134228    0.0749359   -0.0184481    0.173668    -0.0783188   0.0824666  -0.188661     -0.00847095   0.019346     -0.0943245    -0.100245     0.123753    -0.111046    -0.164425    -0.00336189   0.0193698   -0.0125791   -0.0886563   -0.0315981 
  0.101157    -0.160933     0.0385638   -0.095744     0.126932     0.0330935   -0.113045    -0.0296859    0.108016    -0.0813963    0.0655102   -0.0163492   0.194786    0.126078     -0.0451965   -0.0855144    -0.0787674    -0.121149    -0.0968664   -0.136093    -0.10485     -0.0174015   -0.116189    -0.056343    -0.225567    -0.0464045 
 -0.0288897   -0.0928308    0.128101     0.130862    -0.0327413    0.085872    -0.194498    -0.0592911   -0.12758      0.0992255    0.010607    -0.0926716  -0.111349    0.010511     -0.00973234   0.0132558    -0.0489304     0.0191912   -0.0936032    0.12889     -0.12621     -0.075091    -0.0639341   -0.0453134    0.10757      0.0088587 
  0.0325225   -0.0164539    0.0879495   -0.108437     0.0997362   -0.198399     0.117946    -0.100477     0.0151517    0.039614    -0.190762     0.0987964   0.0411821  -0.0445567    -0.186589     0.00459986    0.0618242    -0.0895038    0.152496     0.0237258    0.13956      0.0736666   -0.0286098   -0.149072     0.358506    -0.291283  
  0.0875743   -0.078938     0.0453247    0.0908684    0.0174483   -0.135411     0.0147912    0.00368091  -0.0731232    0.144703     0.0644142   -0.0628192  -0.199784    0.04505       0.165295    -0.0265867    -0.0024418     0.0314144   -0.167851     0.00377062  -0.113584    -0.232422     0.200619     0.0641601    0.0105069    0.132953  
  0.102351     0.0786617   -0.155594     0.119541    -0.112389    -0.138257     0.0965686   -0.00405978  -0.0742499    0.00562035   0.00624082   0.0970734   0.0205917   0.103222     -0.134255    -0.0504675     0.0183914    -0.0148522   -0.0276083    0.0603686    0.0102031   -0.0152419    0.040931    -0.0151578    0.0685605   -0.0618115 
 -0.0310366   -0.0985533   -0.0778052   -0.0698036   -0.0225355   -0.0180142   -0.0214059   -0.0683542   -0.0199274    0.0229574   -0.0878454    0.030013    0.171305    0.162217     -0.0841243   -0.0296583     0.168692      0.0396424    0.0395707    0.189734     0.197748     0.0468268    0.0837498   -0.0257755    0.00798322   0.0138065 
 -0.186161     0.0837419    0.120886    -0.0359051   -0.158823    -0.125002    -0.0300821    0.0617533    0.100632     0.124378    -0.0689897    0.0276494  -0.0555769  -0.0162439    -0.0144184   -0.0305213     0.120044      0.00931381   0.182295     0.0164958   -0.16376     -0.0725291    0.248653     0.0287872    0.00369022  -0.12007   
  0.163825     0.161919    -0.0461099    0.0261918   -0.248524    -0.107954    -0.0936299    0.158914     0.0793847    0.212264     0.183859    -0.102102    0.0198744   0.254264      0.0191206    0.0225532    -0.148979     -0.0510591    0.0428308   -0.00371961   0.0549699   -0.0955521   -0.0822093   -0.0592746   -0.152812    -0.05866   
 -0.100153     0.159922    -0.0131475   -0.0229498    0.0169207    0.149351     0.00229653  -0.035749     0.0459158    0.0308967    0.0878455   -0.158497   -0.015127    0.101292     -0.0649232   -0.183852     -0.0131183    -0.00999487   0.00506085   0.00297147  -0.0152165   -0.0985067    0.0522392    0.060127    -0.0185593    0.0678606 
 -0.0306011   -0.0032952   -0.111634    -0.0930946    0.0333078    0.102365    -0.0447756    0.0471298    0.0311714    0.0707846    0.0839604    0.0345751  -0.192043   -0.144152      0.0573326   -0.0871775    -0.0495877     0.00327438  -0.097496    -0.0395603    0.16481      0.0177658   -0.00569868  -0.0201678   -0.0424276    0.207826  
 -0.10713      0.00401148  -0.0174332   -0.0152671    0.1263      -0.0712411   -0.0399428   -0.139911    -0.00920126  -0.0881945   -0.182537     0.0279357   0.0110508  -0.174427      0.0732379   -0.0134127    -0.0600391     0.0336207    0.0429143   -0.0666499    0.021691     0.171563     0.0487556    0.00529735   0.0218705   -0.00532953
  0.0165113   -0.0538843    0.0160696    0.0130363    0.138849    -0.0721688   -0.144974    -0.0828506   -0.0991805   -0.0350926    0.0231638   -0.0320914  -0.0337831   0.0910177     0.0874722    0.0626752    -0.112617      0.0511589   -0.163572    -0.0603829    0.0187098    0.142906    -0.0224009   -0.0276767   -0.156079    -0.0741676 
  0.0550449    0.0253174    0.00352504  -0.0131158   -0.0253562   -0.0480274   -0.0244053   -0.196982    -0.081394     0.0884749    0.00198695  -0.018562    0.118754   -0.0847457    -0.103021    -0.0839878     0.0113613    -0.142711    -0.048544    -0.127031    -0.0731755   -0.17314     -0.0751358   -0.0445927   -0.0285378    0.0262917 
  0.0185661   -0.0436927    0.171877     0.0820826    0.0067776   -0.196417     0.0960501   -0.0638279    0.0125958   -0.0103099   -0.0588347   -0.0661546  -0.101444   -0.000877407  -0.00238629   0.111471      0.106813     -0.0343809   -0.152026    -0.153775     0.0610132   -0.0787141   -0.0362611   -0.0926312    0.117559    -0.0221129 
 -0.0717683    0.00996536   0.0236445   -0.0569318   -0.0681082   -0.0402213    0.0946998   -0.00168132  -0.131524     0.045021    -0.051545     0.0403234   0.0416867   0.0378622     0.0378576    0.120307      0.0592556     0.0481983   -0.157993    -0.0241935   -0.0389024   -0.0277987    0.0284236    0.0393929   -0.00372548   0.0250713 
 -0.0367572    0.0928523    0.043154     0.0977052    0.0632601    0.0966994    0.0865465   -0.0942861   -0.0949498   -0.0971587    0.171087    -0.0553507   0.0228534   0.0816246     0.0344964    0.000973621  -0.153519     -0.22833      0.0763225   -0.010996    -0.0421902   -0.19739     -0.0616826    0.154298    -0.071165     0.0131927 
  0.125034    -0.0430605    0.00140262  -0.0736688   -0.0452852    0.0363186   -0.116512    -0.0759265    0.0740927   -0.0594467   -0.0215248   -0.0411113  -0.127606    0.0168112    -0.00199454  -0.00356207    0.000822059   0.0923635    0.00435976   0.035532    -0.0480549    0.00902922  -0.133874     0.0811163   -0.0132426   -0.142612  
 -0.0201977    0.0425031   -0.104828    -0.179789     0.0373456    0.00587998  -0.0233522    0.131004    -0.0663514   -0.00381988  -0.0438972   -0.0384775  -0.145342   -0.177436      0.00157914  -0.0940746     0.0355631    -0.0884783    0.0998439    0.0400264    0.0199077    0.0853479    0.0563857    0.0939816   -0.00412103   0.189268  
 -0.0328246    0.0530163   -0.0406152    0.0143871    0.0249888    0.158843     0.0242263   -0.0552866   -0.0563772    0.0637451   -0.0824109   -0.037221   -0.0888154  -0.00617472    0.0324001   -0.0721065     0.0351746    -0.13609      0.262876    -0.0679845    0.226532     0.161208    -0.157608    -0.0804104   -0.0189612    0.0654447 
 -0.12014      0.0651793   -0.0854395   -0.0175628    0.0584975    0.0835263    0.072714     0.0876301   -0.0452439    0.0916761   -0.0136629   -0.0271997  -0.082384   -0.0382736     0.0177691   -0.153812     -0.0207967    -0.0584384   -0.236219     0.0500031   -0.00378465  -0.0466849   -0.0451712    0.0237874    0.0759622    0.0437156 
  0.00714021  -0.245466    -0.141647    -0.0625586    0.00998311   0.0988858   -0.0315255   -0.177404     0.101748    -0.0114186   -0.088599    -0.0742653  -0.0265743   0.00669913    0.0232276   -0.200388     -0.0288373    -0.0512694   -0.0736217    0.0644856    7.73679e-5   0.0204693   -0.0209756   -0.0192164    0.0655914    0.199297  
  0.123599    -0.0566374    0.0221814   -0.0385513    0.0648613   -0.0148445    0.060793    -0.0146477    0.0354582   -0.102916    -0.144011    -0.0363361  -0.132883    0.0971279     0.122863     0.060295      0.025227     -0.0857318   -0.0884466   -0.12377      0.0916643    0.304042     0.124034    -0.0151854    0.0646336   -0.0484703 
 -0.0470842   -0.0946378    0.220458    -0.0514189   -0.0742222   -0.0064843   -0.19201      0.0834029   -0.104458     0.133302    -0.0820214    0.0941062   0.0221304   0.0662342    -0.154213    -0.245349      0.0166124     0.0974676   -0.119757     0.0601597    0.0679484   -0.14259      0.0879084    0.0550096   -0.00548563   0.0333087 
  0.296054     0.0235701   -0.0970871   -0.1535      -0.0774134   -0.0951396    0.112345    -0.0108615   -0.0312486   -0.0146763    0.0272086    0.088156    0.0503457   0.00376857   -0.0476995    0.0435727    -0.0250782    -0.0263589    0.0661638    0.0612032    0.0463655   -0.0226143    0.0447441   -0.012079     0.100008    -0.0257406 
 -0.0796974    0.120126     0.194839     0.221363    -0.109551    -0.0678346   -0.0356217    0.0519959    0.0324859    0.0795236    0.0865587    0.122412    0.0012817   0.0294754    -0.0385633   -0.0840529     0.00201267   -0.0229006   -0.20525     -0.0145363   -0.0789194   -0.0086968    0.0318786    0.0275981   -0.0419858    0.122187  
 -0.0716754   -0.137806     0.0665425    0.107547    -0.228003    -0.163366    -0.0158793   -0.171814     0.033718     0.089545    -0.0679111   -0.0329294  -0.0291231  -0.0541639    -0.203875    -0.081083     -0.0306632     0.0660212   -0.0419586   -0.148308    -0.115841    -0.351938    -0.0330034   -0.0407875   -0.215891    -0.0529272 
  0.0697825    0.00522419   0.0255033    0.0379835    0.00170909   0.160525    -0.0370284   -0.0355593   -0.0559199    0.0357151    0.117709    -0.0345934  -0.127539   -0.0513957    -0.0468442    0.0838284     0.00183945   -0.0137389    0.0678746   -0.0355098    0.0698697    0.0549666    0.0947746   -0.0289205   -0.122326     0.0120279 
 -0.235121    -0.101191     0.0349899    0.147884     0.0172931   -0.00154889   0.00458964  -0.0156241    0.026404     0.0651579   -0.0654949    0.217466   -0.0179028   0.0627655    -0.110395     0.0170096     0.0335854    -0.0603737    0.0492141   -0.044466     0.00335571  -0.00864144  -0.27388      0.0917263   -0.0146582    0.161236  
  0.00870996  -0.0635641   -0.0902632    0.00448665  -0.00986246   0.0748942   -0.23463      0.0709649   -0.0370976    0.119304    -0.0920799   -0.082349   -0.0188688  -0.0969645     0.0413832    0.0379559    -0.155705      0.243739     0.238877    -0.209485     0.0576681   -0.0407942   -0.0134832   -0.0687444   -0.0437701   -0.0557631 
  0.00985058  -0.205126     0.164942     0.00643143  -0.0789749   -0.102678    -0.107069     0.0493134    0.0561641    0.0491187   -0.0962243    0.0540765   0.0047255   0.0715837     0.108365    -0.108595     -0.0385455    -0.0304156   -0.141465    -0.173452     0.15109      0.0855972   -0.0358755    0.0474788    0.0625554   -0.0572617 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     4
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.086411
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      6
â”‚      â‹®
â”‚     14
â”‚     23
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.025110
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚     28
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.047307
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     27
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.996072
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.073060
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      6
â”‚      â‹®
â”‚     26
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.015270
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      8
â”‚     18
â”‚     22
â”‚     27
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.045434
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      6
â”‚      â‹®
â”‚     14
â”‚     23
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.028465
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚     22
â”‚     26
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.052966
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      6
â”‚      â‹®
â”‚     18
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.015430
â”Œ Info: EM with 100000 data points 10 iterations avll -1.015430
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0396002    0.0987149    0.0963384    -0.0734138    0.0580653    0.0283123    0.00056839  -0.091368    -0.0258951    0.150368     -0.083438    -0.160297    -0.164972     0.0462448   0.0529722  -0.00623104  -0.038513      0.101026    -0.0561555    -0.0673534   -0.0709551    0.0808767   -0.0736519    0.0579664   0.0506795    0.0348927 
  0.00553983  -0.144742     0.0275748     0.0966733    0.0242156   -0.0989712   -0.15603      0.188102     0.0420821   -0.0564194     0.0463001    0.152767    -0.0132801    0.0975474   0.286298   -0.0426283    0.0924067    -0.0905863   -0.140087      0.230391    -0.0109826    0.0491473   -0.227204     0.151862    0.0694577    0.0355741 
  0.0205923    0.0320589   -0.0747523    -0.10066     -0.00827509  -0.0994555   -0.0402932   -0.018291     0.0230482    0.0661419    -0.0279421    0.141592     0.222084     0.215537    0.0696187   0.0573863   -0.0274634    -0.182591     0.038987     -0.0559834   -0.041829     0.0280778    0.0273991   -0.101654   -0.11581     -0.134917  
 -0.04448      0.0678358   -0.0749772    -0.0486206   -0.0113262   -0.203952     0.0302704    0.126022    -0.0682556    0.0252        0.10035     -0.0483991   -0.00392865   0.0930443  -0.163005    0.0901999    0.0167771    -0.131237     0.0319296    -0.0299892   -0.0169316   -0.0446103   -0.108858     0.154935    0.083902    -0.018478  
  0.135563     0.0466394    0.0954451    -0.261343    -0.0256192    0.0531526   -0.0500568   -0.034508     0.0531034   -0.0640613     0.136988    -0.0163044    0.187175    -0.103203    0.0942102  -0.0862175   -0.129579      0.0812739    0.0452991     0.126045     0.210326    -0.0622051   -0.107254    -0.130327   -0.0126249   -0.123846  
 -0.0651467    0.0877366   -0.0159949     0.0568564    0.133443     0.159968    -0.0495748    0.16455     -0.0632954    0.115012     -0.010982     0.0399538   -0.00106226  -0.0896084  -0.0232503  -0.00402042  -0.00923208    0.058465    -0.0133051     0.0339486   -0.0892233    0.153802     0.0945169    0.175704    0.0779719    0.0870112 
  0.0424471    0.04108     -0.0941292     0.307414    -0.134532     0.219905     0.0562641   -0.148813     0.107631     0.0995782     0.0857551   -0.00692636  -0.0521269    0.0845377   0.120212    0.159692    -0.107425     -0.0129826    0.134431      0.103967     0.243112     0.0808952   -0.0998831   -0.0243535   0.133389    -0.160303  
 -0.0270777   -0.0767054   -0.00679348    0.0599078    0.0817804    0.0541302   -0.109056    -0.0833128    0.00670035   0.00893581   -0.0974997    0.101814     0.00976149  -0.0364968   0.018945    0.0750909   -0.063895     -0.134249    -0.0844375    -0.117549    -0.0619095    0.125138     0.103948     0.0436448   0.00409917  -0.131828  
 -0.0321184   -0.00180927  -0.10038       0.105943    -0.0221158    0.110107    -0.00734575   0.108907    -0.0453197   -0.0304023    -0.134401     0.0227608    0.0242541   -0.15478    -0.0716186   0.0604589    0.000694985   0.0747979   -0.0627867     0.0186768    0.0832803    0.0200713    0.159222     0.0276576   0.045428     0.127722  
 -0.0340396   -0.0258172    0.0280651    -0.0274927    0.0658616   -0.103349     0.162921     0.0234758    0.0332186    0.0631881    -0.0881932   -0.156631     0.0994179   -0.119524   -0.0779912  -0.160295     0.0523612    -0.0221187    0.154819      0.0188917   -0.135473     0.0722302    0.00278186   0.123598   -0.0390527   -0.214409  
  0.104722     0.0125753   -0.00328869    0.110456     0.0239335   -0.0690628   -0.0484711   -0.200542    -0.114374     0.0539281    -0.0664849    0.00796507   0.0201248    0.0237043   0.13726    -0.0308454    0.180938      0.111503    -0.0127433    -0.10981     -0.111158    -0.0706333    0.152619     0.115772    0.011805    -0.111538  
  0.12428      0.0347719    0.177127      0.103307     0.0528831   -0.0419829   -0.0124613   -0.0487219    0.0242028    0.00368418    0.00898466  -0.130453     0.0155401    0.0244875   0.0518152  -0.0972942   -0.171789     -0.103958     0.2558        0.0524013    0.0213882    0.00560797  -0.109578     0.132689   -0.00788034  -0.0259793 
  0.00268617   0.0659934   -0.0250611    -0.0611713   -0.0410911   -0.141115     0.050107    -0.077582     0.121645    -0.145477     -0.00852776   0.0926045    0.16599      0.0366678  -0.0010447  -0.219138    -0.00425007   -0.0468536   -0.15148       0.0600203   -0.110041    -0.130576    -0.134869    -0.10955    -0.0792253    0.0129917 
  0.0571608    0.162107     0.11008      -0.0811099    0.138036     0.0704734    0.0419017   -0.145356    -0.139918     0.0153622     0.150702    -0.0094083    0.010575     0.142824    0.0880446  -0.0764723    0.0403201     0.0319285    0.205719      0.172986    -0.0857324    0.126062    -0.0156272    0.0421508  -0.0469923    0.0379116 
  0.158204    -0.00965947   0.0679348     0.0551241    0.157976    -0.0400141   -0.0412454   -0.112425     0.0481621    0.0961115     0.0791919    0.0290978    0.173879    -0.0681872   0.0192154   0.172762     0.0956213     0.118877    -0.0225667     0.00724476  -0.0607819    0.0763375    0.179075    -0.123117   -0.134911    -0.0509665 
  0.0513988    0.105945     0.132611      0.04718     -0.0575397    0.11295     -0.0769768   -0.00176354  -0.0638989    0.0307155    -0.105162    -0.166548    -0.0755999   -0.0067857  -0.0467862   0.104992     0.0989144    -0.0539058   -0.0720935     0.0359307   -0.0100011    0.0327778    0.204472    -0.042467    0.0440198   -0.0723297 
 -0.156411     0.0229682   -0.0633574     0.111395    -0.192531    -0.21776     -0.0122898   -0.0433457   -0.0139298   -0.0214714    -0.00595798  -0.193718    -0.0528146    0.0726037  -0.0298459  -0.044281    -0.00724517   -0.115886     0.186822      0.0438893    0.0204339   -0.112076    -0.269758    -0.108239    0.00402732  -0.00902738
  0.0086759   -0.0497126   -0.0161597     0.0319408   -0.112245    -0.0334313    0.00482454  -0.0387736   -0.177363    -0.0713336     0.210018     0.0167253    0.0669593   -0.0623805   0.0818778  -0.0924416   -0.105853     -0.102909     0.0355829     0.00287337   0.0457281    0.0577543    0.123505    -0.0824554  -0.0250004   -0.0379957 
  0.00714448   0.225424     0.138253     -0.00402854  -0.137059    -0.113201    -0.0933767   -0.082361     0.0438023    0.0095914    -0.0541525    0.081826     0.14406     -0.110448    0.0147015  -0.109944     0.120892      0.1742       0.0391153    -0.0337079   -0.0677084   -0.0261832   -0.145043     0.0296393  -0.157593     0.102077  
  0.0071933    0.119777    -0.0164251    -0.00387978   0.0982582   -0.175447    -0.054232     0.0452781    0.140795     0.0680807    -0.019207     0.0983706    0.0191458    0.0125911   0.0651506   0.199527     0.204329     -0.0163858   -0.159553      0.160861    -0.220426    -0.11302      0.0323689   -0.0111785  -0.13181     -0.0764557 
 -0.0433301   -0.143861     0.0111921     0.160321     0.0269449    0.106895     0.0320311    0.0528715   -0.184376    -0.108953      0.16143     -0.108242     0.0188639   -0.161152   -0.0211832  -0.0135137    0.033237      0.114432     0.121678      0.0996723   -0.123611    -0.0261188    0.0999802   -0.134329    0.147811    -0.106083  
 -0.110123    -0.00652397   0.000111886   0.0599713    0.0552267    0.00216572   0.0272723    0.192132    -0.0407665   -0.105382     -0.0637429    0.149747    -0.0680177   -0.0262152   0.0551545  -0.0256188   -0.176611      0.0600526    0.141024      0.0111806   -0.147055     0.0442391   -0.0960501    0.022631    0.0802327    0.0789661 
 -0.13489      0.234388    -0.0268887     0.0119002   -0.00547985  -0.0947185    0.0912826   -0.16975     -0.264231     0.0062053    -0.0203091    0.0126396    0.0556682    0.089397   -0.0600462   0.047717     0.0623101    -0.0331804    0.0151604     0.241118    -0.0258472    0.0287154   -0.242828     0.174512    0.114163    -0.0231957 
 -0.26539      0.107168    -0.010557     -0.121988     0.0640866   -0.111229     0.153203    -0.0935986   -0.0527706    0.0383076    -0.0132172    0.0689953    0.0795643    0.0138859  -0.119373   -0.122338     0.136625     -0.0287368    0.0497273    -0.0502489    0.0120372   -0.012816    -0.077165     0.042586    0.0680913    0.0722743 
  0.00548522   0.00100745  -0.00344944   -0.0500922   -0.0404555    0.14906     -0.135562    -0.00584285  -0.156152    -0.000282195  -0.132286     0.0117829   -0.00744482  -0.0867962   0.111373    0.031241    -0.0619331     0.0171808    0.0247853     0.0456241   -0.0725706    0.046565    -0.0669154    0.0808632  -0.012397    -0.0635104 
  0.0964863    0.0145907    0.0346424     0.0265443    0.0330777    0.0414688    0.0187599   -0.11753      0.065668    -0.294186      0.0199023    0.156154     0.112414    -0.0455677   0.195696   -0.11645      0.127923     -0.011026     0.0399252    -0.115093     0.0470818   -0.0101417    0.0784558    0.0850497  -0.0876926    0.083936  
 -0.0769422    0.0652422   -0.00707413    0.0416159    0.00903424  -0.0693639   -0.0404761    0.0076881    0.0722077   -0.104804     -0.0667625   -0.0231214   -0.00431646   0.0467272   0.12387    -0.200305     0.035813     -0.240512    -0.0438873    -0.108797     0.23328      0.254238     0.183273     0.0135859  -0.0181656   -0.198981  
 -0.128027    -0.108889     0.0266387     0.0512942   -0.106441     0.0149927    0.0479935    0.0947873    0.0945883    0.00169086    0.0879631    0.00582455  -0.116709     0.0697476   0.0677494  -0.081441     0.191696     -0.0429526   -0.0573201     0.226602    -0.00479543   0.0837266    0.0445843    0.0896993   0.0623579   -0.144887  
  0.152183    -0.0083578    0.0547466    -0.0286386    0.0687858    0.0822936   -0.0292788   -0.0602543    0.141155     0.0567886     0.143524    -0.00847564  -0.00478225   0.0172817   0.0507145   0.0105456    0.0525444     0.206836    -0.000690832   0.0208897   -0.0189907   -0.0684646   -0.0911981   -0.0745908  -0.215425    -0.171851  
 -0.11065      0.00575379  -0.0171764    -0.053977    -0.172393     0.0914578   -0.0112371    0.0318707    0.184815    -0.0227192     0.0249003   -0.130387     0.0627996   -0.0343752   0.0795977   0.0967393   -0.0389386     0.0811022   -0.0652097    -0.130961    -0.116003     0.013299    -0.146087    -0.113645   -0.0192206    0.0960544 
 -0.0858863   -0.122728    -0.00437816    0.147098    -0.0272431    0.0467106   -0.162913    -0.0813241    0.240848     0.0358719     0.0121663    0.0133096    0.0339366   -0.0321697  -0.0877413   0.0576179   -0.0611103     0.00491563  -0.112281      0.00223411  -0.199395    -0.0868527   -0.0799906   -0.0463189  -0.048333     0.0146868 
 -0.0382171   -0.0150484    0.0714385    -0.0392115    0.174771     0.0767462   -0.140533    -0.139178     0.0508998    0.0923646     0.0130712    0.0981542   -0.0428702    0.0248426  -0.0703765  -0.0122328   -0.139773     -0.0206537    0.0863056     0.0653515   -0.0425411    0.0509111   -0.0652684   -0.178512    0.0460072   -0.0208136 kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.42389643685228
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423916
[ Info: iteration 2, average log likelihood -1.423840
[ Info: iteration 3, average log likelihood -1.423773
[ Info: iteration 4, average log likelihood -1.423683
[ Info: iteration 5, average log likelihood -1.423565
[ Info: iteration 6, average log likelihood -1.423418
[ Info: iteration 7, average log likelihood -1.423245
[ Info: iteration 8, average log likelihood -1.423038
[ Info: iteration 9, average log likelihood -1.422761
[ Info: iteration 10, average log likelihood -1.422339
[ Info: iteration 11, average log likelihood -1.421681
[ Info: iteration 12, average log likelihood -1.420791
[ Info: iteration 13, average log likelihood -1.419868
[ Info: iteration 14, average log likelihood -1.419174
[ Info: iteration 15, average log likelihood -1.418779
[ Info: iteration 16, average log likelihood -1.418590
[ Info: iteration 17, average log likelihood -1.418507
[ Info: iteration 18, average log likelihood -1.418470
[ Info: iteration 19, average log likelihood -1.418455
[ Info: iteration 20, average log likelihood -1.418448
[ Info: iteration 21, average log likelihood -1.418445
[ Info: iteration 22, average log likelihood -1.418444
[ Info: iteration 23, average log likelihood -1.418443
[ Info: iteration 24, average log likelihood -1.418443
[ Info: iteration 25, average log likelihood -1.418442
[ Info: iteration 26, average log likelihood -1.418442
[ Info: iteration 27, average log likelihood -1.418442
[ Info: iteration 28, average log likelihood -1.418442
[ Info: iteration 29, average log likelihood -1.418442
[ Info: iteration 30, average log likelihood -1.418442
[ Info: iteration 31, average log likelihood -1.418442
[ Info: iteration 32, average log likelihood -1.418442
[ Info: iteration 33, average log likelihood -1.418442
[ Info: iteration 34, average log likelihood -1.418442
[ Info: iteration 35, average log likelihood -1.418442
[ Info: iteration 36, average log likelihood -1.418442
[ Info: iteration 37, average log likelihood -1.418442
[ Info: iteration 38, average log likelihood -1.418442
[ Info: iteration 39, average log likelihood -1.418442
[ Info: iteration 40, average log likelihood -1.418442
[ Info: iteration 41, average log likelihood -1.418442
[ Info: iteration 42, average log likelihood -1.418442
[ Info: iteration 43, average log likelihood -1.418442
[ Info: iteration 44, average log likelihood -1.418441
[ Info: iteration 45, average log likelihood -1.418441
[ Info: iteration 46, average log likelihood -1.418441
[ Info: iteration 47, average log likelihood -1.418441
[ Info: iteration 48, average log likelihood -1.418441
[ Info: iteration 49, average log likelihood -1.418441
[ Info: iteration 50, average log likelihood -1.418441
â”Œ Info: EM with 100000 data points 50 iterations avll -1.418441
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4239159336827831
â”‚     -1.4238404693630682
â”‚      â‹®                 
â””     -1.4184414398058005
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418461
[ Info: iteration 2, average log likelihood -1.418383
[ Info: iteration 3, average log likelihood -1.418313
[ Info: iteration 4, average log likelihood -1.418220
[ Info: iteration 5, average log likelihood -1.418101
[ Info: iteration 6, average log likelihood -1.417965
[ Info: iteration 7, average log likelihood -1.417831
[ Info: iteration 8, average log likelihood -1.417719
[ Info: iteration 9, average log likelihood -1.417638
[ Info: iteration 10, average log likelihood -1.417585
[ Info: iteration 11, average log likelihood -1.417550
[ Info: iteration 12, average log likelihood -1.417525
[ Info: iteration 13, average log likelihood -1.417507
[ Info: iteration 14, average log likelihood -1.417492
[ Info: iteration 15, average log likelihood -1.417479
[ Info: iteration 16, average log likelihood -1.417467
[ Info: iteration 17, average log likelihood -1.417456
[ Info: iteration 18, average log likelihood -1.417445
[ Info: iteration 19, average log likelihood -1.417434
[ Info: iteration 20, average log likelihood -1.417423
[ Info: iteration 21, average log likelihood -1.417411
[ Info: iteration 22, average log likelihood -1.417400
[ Info: iteration 23, average log likelihood -1.417387
[ Info: iteration 24, average log likelihood -1.417375
[ Info: iteration 25, average log likelihood -1.417362
[ Info: iteration 26, average log likelihood -1.417349
[ Info: iteration 27, average log likelihood -1.417337
[ Info: iteration 28, average log likelihood -1.417325
[ Info: iteration 29, average log likelihood -1.417314
[ Info: iteration 30, average log likelihood -1.417303
[ Info: iteration 31, average log likelihood -1.417293
[ Info: iteration 32, average log likelihood -1.417283
[ Info: iteration 33, average log likelihood -1.417275
[ Info: iteration 34, average log likelihood -1.417267
[ Info: iteration 35, average log likelihood -1.417260
[ Info: iteration 36, average log likelihood -1.417254
[ Info: iteration 37, average log likelihood -1.417248
[ Info: iteration 38, average log likelihood -1.417242
[ Info: iteration 39, average log likelihood -1.417237
[ Info: iteration 40, average log likelihood -1.417233
[ Info: iteration 41, average log likelihood -1.417229
[ Info: iteration 42, average log likelihood -1.417225
[ Info: iteration 43, average log likelihood -1.417221
[ Info: iteration 44, average log likelihood -1.417218
[ Info: iteration 45, average log likelihood -1.417214
[ Info: iteration 46, average log likelihood -1.417211
[ Info: iteration 47, average log likelihood -1.417208
[ Info: iteration 48, average log likelihood -1.417206
[ Info: iteration 49, average log likelihood -1.417203
[ Info: iteration 50, average log likelihood -1.417201
â”Œ Info: EM with 100000 data points 50 iterations avll -1.417201
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4184606603091714
â”‚     -1.4183829018438507
â”‚      â‹®                 
â””     -1.4172009252605429
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417210
[ Info: iteration 2, average log likelihood -1.417156
[ Info: iteration 3, average log likelihood -1.417108
[ Info: iteration 4, average log likelihood -1.417051
[ Info: iteration 5, average log likelihood -1.416982
[ Info: iteration 6, average log likelihood -1.416895
[ Info: iteration 7, average log likelihood -1.416794
[ Info: iteration 8, average log likelihood -1.416681
[ Info: iteration 9, average log likelihood -1.416563
[ Info: iteration 10, average log likelihood -1.416448
[ Info: iteration 11, average log likelihood -1.416340
[ Info: iteration 12, average log likelihood -1.416243
[ Info: iteration 13, average log likelihood -1.416158
[ Info: iteration 14, average log likelihood -1.416084
[ Info: iteration 15, average log likelihood -1.416022
[ Info: iteration 16, average log likelihood -1.415968
[ Info: iteration 17, average log likelihood -1.415924
[ Info: iteration 18, average log likelihood -1.415885
[ Info: iteration 19, average log likelihood -1.415853
[ Info: iteration 20, average log likelihood -1.415825
[ Info: iteration 21, average log likelihood -1.415801
[ Info: iteration 22, average log likelihood -1.415780
[ Info: iteration 23, average log likelihood -1.415762
[ Info: iteration 24, average log likelihood -1.415746
[ Info: iteration 25, average log likelihood -1.415731
[ Info: iteration 26, average log likelihood -1.415719
[ Info: iteration 27, average log likelihood -1.415707
[ Info: iteration 28, average log likelihood -1.415697
[ Info: iteration 29, average log likelihood -1.415688
[ Info: iteration 30, average log likelihood -1.415680
[ Info: iteration 31, average log likelihood -1.415672
[ Info: iteration 32, average log likelihood -1.415666
[ Info: iteration 33, average log likelihood -1.415659
[ Info: iteration 34, average log likelihood -1.415654
[ Info: iteration 35, average log likelihood -1.415648
[ Info: iteration 36, average log likelihood -1.415643
[ Info: iteration 37, average log likelihood -1.415639
[ Info: iteration 38, average log likelihood -1.415635
[ Info: iteration 39, average log likelihood -1.415631
[ Info: iteration 40, average log likelihood -1.415627
[ Info: iteration 41, average log likelihood -1.415623
[ Info: iteration 42, average log likelihood -1.415620
[ Info: iteration 43, average log likelihood -1.415617
[ Info: iteration 44, average log likelihood -1.415614
[ Info: iteration 45, average log likelihood -1.415611
[ Info: iteration 46, average log likelihood -1.415608
[ Info: iteration 47, average log likelihood -1.415606
[ Info: iteration 48, average log likelihood -1.415603
[ Info: iteration 49, average log likelihood -1.415601
[ Info: iteration 50, average log likelihood -1.415598
â”Œ Info: EM with 100000 data points 50 iterations avll -1.415598
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4172096538920218
â”‚     -1.4171556140937887
â”‚      â‹®                 
â””     -1.4155983422102456
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415605
[ Info: iteration 2, average log likelihood -1.415551
[ Info: iteration 3, average log likelihood -1.415503
[ Info: iteration 4, average log likelihood -1.415448
[ Info: iteration 5, average log likelihood -1.415381
[ Info: iteration 6, average log likelihood -1.415298
[ Info: iteration 7, average log likelihood -1.415198
[ Info: iteration 8, average log likelihood -1.415085
[ Info: iteration 9, average log likelihood -1.414962
[ Info: iteration 10, average log likelihood -1.414837
[ Info: iteration 11, average log likelihood -1.414716
[ Info: iteration 12, average log likelihood -1.414602
[ Info: iteration 13, average log likelihood -1.414498
[ Info: iteration 14, average log likelihood -1.414405
[ Info: iteration 15, average log likelihood -1.414323
[ Info: iteration 16, average log likelihood -1.414252
[ Info: iteration 17, average log likelihood -1.414190
[ Info: iteration 18, average log likelihood -1.414137
[ Info: iteration 19, average log likelihood -1.414092
[ Info: iteration 20, average log likelihood -1.414052
[ Info: iteration 21, average log likelihood -1.414018
[ Info: iteration 22, average log likelihood -1.413988
[ Info: iteration 23, average log likelihood -1.413962
[ Info: iteration 24, average log likelihood -1.413939
[ Info: iteration 25, average log likelihood -1.413917
[ Info: iteration 26, average log likelihood -1.413898
[ Info: iteration 27, average log likelihood -1.413880
[ Info: iteration 28, average log likelihood -1.413864
[ Info: iteration 29, average log likelihood -1.413848
[ Info: iteration 30, average log likelihood -1.413834
[ Info: iteration 31, average log likelihood -1.413820
[ Info: iteration 32, average log likelihood -1.413807
[ Info: iteration 33, average log likelihood -1.413795
[ Info: iteration 34, average log likelihood -1.413783
[ Info: iteration 35, average log likelihood -1.413772
[ Info: iteration 36, average log likelihood -1.413760
[ Info: iteration 37, average log likelihood -1.413750
[ Info: iteration 38, average log likelihood -1.413739
[ Info: iteration 39, average log likelihood -1.413729
[ Info: iteration 40, average log likelihood -1.413719
[ Info: iteration 41, average log likelihood -1.413709
[ Info: iteration 42, average log likelihood -1.413699
[ Info: iteration 43, average log likelihood -1.413690
[ Info: iteration 44, average log likelihood -1.413681
[ Info: iteration 45, average log likelihood -1.413672
[ Info: iteration 46, average log likelihood -1.413663
[ Info: iteration 47, average log likelihood -1.413654
[ Info: iteration 48, average log likelihood -1.413645
[ Info: iteration 49, average log likelihood -1.413636
[ Info: iteration 50, average log likelihood -1.413627
â”Œ Info: EM with 100000 data points 50 iterations avll -1.413627
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4156046995838496
â”‚     -1.4155514169922436
â”‚      â‹®                 
â””     -1.4136274377785556
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413627
[ Info: iteration 2, average log likelihood -1.413567
[ Info: iteration 3, average log likelihood -1.413510
[ Info: iteration 4, average log likelihood -1.413445
[ Info: iteration 5, average log likelihood -1.413365
[ Info: iteration 6, average log likelihood -1.413267
[ Info: iteration 7, average log likelihood -1.413151
[ Info: iteration 8, average log likelihood -1.413018
[ Info: iteration 9, average log likelihood -1.412875
[ Info: iteration 10, average log likelihood -1.412728
[ Info: iteration 11, average log likelihood -1.412582
[ Info: iteration 12, average log likelihood -1.412443
[ Info: iteration 13, average log likelihood -1.412314
[ Info: iteration 14, average log likelihood -1.412197
[ Info: iteration 15, average log likelihood -1.412091
[ Info: iteration 16, average log likelihood -1.411996
[ Info: iteration 17, average log likelihood -1.411911
[ Info: iteration 18, average log likelihood -1.411834
[ Info: iteration 19, average log likelihood -1.411764
[ Info: iteration 20, average log likelihood -1.411700
[ Info: iteration 21, average log likelihood -1.411641
[ Info: iteration 22, average log likelihood -1.411586
[ Info: iteration 23, average log likelihood -1.411534
[ Info: iteration 24, average log likelihood -1.411485
[ Info: iteration 25, average log likelihood -1.411439
[ Info: iteration 26, average log likelihood -1.411396
[ Info: iteration 27, average log likelihood -1.411354
[ Info: iteration 28, average log likelihood -1.411314
[ Info: iteration 29, average log likelihood -1.411276
[ Info: iteration 30, average log likelihood -1.411240
[ Info: iteration 31, average log likelihood -1.411204
[ Info: iteration 32, average log likelihood -1.411170
[ Info: iteration 33, average log likelihood -1.411137
[ Info: iteration 34, average log likelihood -1.411105
[ Info: iteration 35, average log likelihood -1.411074
[ Info: iteration 36, average log likelihood -1.411044
[ Info: iteration 37, average log likelihood -1.411015
[ Info: iteration 38, average log likelihood -1.410987
[ Info: iteration 39, average log likelihood -1.410959
[ Info: iteration 40, average log likelihood -1.410933
[ Info: iteration 41, average log likelihood -1.410907
[ Info: iteration 42, average log likelihood -1.410882
[ Info: iteration 43, average log likelihood -1.410858
[ Info: iteration 44, average log likelihood -1.410835
[ Info: iteration 45, average log likelihood -1.410812
[ Info: iteration 46, average log likelihood -1.410790
[ Info: iteration 47, average log likelihood -1.410769
[ Info: iteration 48, average log likelihood -1.410748
[ Info: iteration 49, average log likelihood -1.410729
[ Info: iteration 50, average log likelihood -1.410710
â”Œ Info: EM with 100000 data points 50 iterations avll -1.410710
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4136268111636665
â”‚     -1.4135668383819833
â”‚      â‹®                 
â””     -1.4107095648020729
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.42389643685228  
â”‚     -1.4239159336827831
â”‚     -1.4238404693630682
â”‚     -1.4237725376044708
â”‚      â‹®                 
â”‚     -1.4107484409157582
â”‚     -1.410728666507293 
â””     -1.4107095648020729
32Ã—26 Array{Float64,2}:
 -0.257199    -0.522887    0.263776      0.0908888   -0.126335    -0.66716      0.392053     0.391646    -0.00718894  -0.197182    0.105026    -0.594369    -0.101824     0.283687     0.116219    0.483913   -0.525208     0.180548     0.160824   -0.637704   -0.651731    0.214623   -0.218537    -0.529828     0.0210537   -0.496421  
 -0.258754     0.0448232   0.341063      0.0739551    0.15862     -0.173435    -0.233706     0.450561    -0.329821    -0.657268   -0.00265215   0.232366    -0.793794     0.00640953   0.169678    0.0105676   0.093816     0.577281    -0.197761   -0.404047   -0.178925   -0.274119   -0.109626    -0.127853    -0.0459231   -0.393945  
 -0.0502329    0.213764   -0.0251648    -0.0696785   -0.170652     0.591492    -0.173855     0.0443956    0.28688     -0.336696   -0.254128    -0.108756     0.0879114   -0.544687    -0.34572     0.405434    0.152902     0.247261     0.024333   -0.15248    -0.169878   -0.582275   -0.0970966   -0.208997     0.229198    -0.402227  
 -0.27203      0.137569    0.186666     -0.445537    -0.18622      0.671632    -0.00626466   0.0708896    0.206331    -0.0769673   0.0632977    0.353816    -0.0585807    0.299215    -0.406317    0.184014    0.20213      0.0402491    0.249337   -0.034843   -0.685879   -0.124723    0.297456    -0.109812     0.178806     0.377741  
 -0.649008    -0.277959   -0.257697      0.585716    -0.0446975    0.267922     0.0135822    0.0803038    0.14102      0.977658   -0.264791     0.222947     0.0621941   -0.299439    -0.0119021   0.0466863  -0.0280111   -0.53984     -0.377764   -0.209469    0.0874284  -0.303715   -0.443458     0.209775    -0.208406    -0.23128   
  0.20953     -0.633108    0.000948305  -0.0786507   -0.0673596    0.219621    -0.521771     0.103276     0.305615     0.622288    0.259897     0.286239     0.0181564   -0.273859     0.326852    0.410873   -0.0949426    0.146585    -0.318325   -0.0298913   0.359056    0.0200888   0.108541    -0.150884    -0.245472    -0.134698  
 -0.238536     0.149652   -0.0114434     0.130377     0.206886    -0.401431     0.400475    -0.148337    -0.0392187    0.174386   -0.131868     0.00338614   0.0538683    0.0547095   -0.135183   -0.138618   -0.176241    -0.0391493   -0.38474    -0.0615778  -0.011659    0.233699   -0.163015     0.0492549   -0.016396     0.0168894 
  0.043915     0.0159301  -0.0214019     0.0146372    0.00658862   0.0265576   -0.0160527    0.00259832  -0.057695     0.0131273   0.109459    -0.00535436   0.00271325  -0.0170638    0.0867017  -0.0126089   0.136502    -0.0825907    0.104238    0.0641173  -0.0074533   0.0652432   0.105106    -0.0626959    0.00664027  -0.0336022 
 -0.542902     0.415096   -0.0179604    -0.507719     0.477411    -0.165923     0.0739411    0.104292    -0.268743     0.0197561   0.0349343    0.131257    -0.147331     0.0872901    0.206225    0.522527   -0.316772    -0.258375     0.560769    0.239963    0.285136   -0.443897   -0.00506833   0.372761    -0.0668067    0.472706  
 -0.0849504   -0.115756   -0.0466248    -0.916886    -0.0172192    0.283542     0.24489     -0.511503     0.368625     0.439585    0.313493     0.298338     0.488621     0.119557     0.263673   -0.0495745  -0.517304    -0.653628     0.425261   -0.120612    0.0946729   0.529775    0.517634    -0.263211    -0.371339     0.371802  
 -0.237123    -0.150516   -0.624178      0.585323    -0.189724     0.35223      0.0864241   -0.129859     0.189915    -0.40297     1.10597     -0.253737     0.229826    -0.108506     0.0882997  -0.0247023  -0.217317     0.493737     0.31357    -0.107436   -0.241843    0.0178436   0.368639    -0.422825    -0.0402251    0.857542  
  0.492797    -0.230777    0.421347      0.350529    -0.102357    -0.0457212    0.197017    -0.301353     0.771865     0.0202433   0.183778    -0.244463     0.12725      0.397214     0.176377   -0.443049    0.126203     0.130492     0.283278    0.0562751  -0.235954   -0.0747693  -0.467602    -0.139912     0.0788882    0.280042  
  0.317935    -0.267621   -0.26864       0.246666    -0.0841396   -0.108249    -0.385484    -0.0725345   -0.159086    -0.086434   -0.179712    -0.347915     0.47366     -0.0799518    0.316047   -0.323532   -0.00261107  -0.00933699   0.147461    0.500062    0.254431    0.109259   -0.419913     0.462783     0.16679     -0.108221  
  0.287342     0.413061   -0.142659     -0.419428    -0.617347    -0.0909365   -0.598976     0.317426    -0.00767379  -0.212073   -0.209823     0.68401      0.424515    -0.0972891    0.391054   -0.555203    0.0639667   -0.235392     0.10826     0.157186   -0.161919    0.190912   -0.149272    -0.017072     0.144951    -0.282306  
  0.144681     0.274798    0.133128      0.0170525   -0.291722     0.161623     0.144883    -0.21103     -0.452704    -0.536342    0.0182668   -0.420461    -0.228566     0.600796     0.116881   -0.384037    0.250664    -0.00141828   0.475303    0.061218   -0.14742     0.191821    0.670009     0.305812    -0.279389    -0.0940069 
  0.824476     0.405313    0.258613     -0.386967     0.162493    -0.148999    -0.284271    -0.19227     -0.241448    -1.00767     0.489133    -0.142583    -0.242539     0.141461     0.0959039   0.222974    0.0999331    0.595934     0.622192    0.0636395   0.268093    0.272311    0.634279    -0.100516     0.514934    -0.207863  
  0.40673     -0.289109   -0.19342       0.382706    -0.445918     0.410057    -0.0322764   -0.562279     0.059343     0.0227212  -0.325055    -0.218888     0.386088    -0.455514    -0.160321   -0.802735    0.338487    -0.0973679    0.0821931   0.0292456  -0.701305    0.622908    0.295215    -0.633272    -0.418946    -0.386121  
 -0.234147    -0.264462    0.438121      0.488826    -0.339191     0.156078    -0.215088    -0.195769     0.604154    -0.341926    0.454097     1.13369      0.232037    -0.526559    -0.46204     0.141965   -0.11681     -0.0908455   -0.175395   -0.0116822  -0.506807    0.563688   -0.556893    -0.979401     0.449962    -0.00237761
  0.370005    -0.24405     0.441053     -0.0435025    0.140719    -0.188781    -0.372321    -0.663402     0.469267    -0.434324    0.151236     0.404651    -0.310415     0.12857      0.992805   -0.464972   -0.313449    -0.154499     0.0978128   0.0379057  -0.483833    0.270045   -0.562988     0.203778    -1.22138     -0.0634675 
 -0.018982     0.196104    0.186219     -0.00678836  -0.218053     0.0213859    0.0715615   -0.0554528    0.00431622   0.010638    0.0171022    0.0426368    0.157684     0.253735    -0.0331914  -0.154991    0.125399    -0.107299     0.167028   -0.0323719  -0.0884577   0.134145   -0.028314     0.1904       0.101299     0.088719  
  0.0770021   -0.135035   -0.402234      0.151697    -0.144699     0.127182    -0.270037     0.733529     0.0242492   -0.332679   -0.545067    -0.114875    -0.0213152   -0.716216     0.266591   -0.125854    0.153388     0.456117     0.396654    0.468684   -0.054297   -0.471783   -0.104107    -0.505411     0.32044      0.0465772 
 -0.0687926   -0.169074   -0.567469     -0.176594    -0.0328795    0.994353    -0.448521     0.243238     0.456503    -0.120134    0.293719    -0.0800866   -0.384476    -0.324271     0.285767    0.94489    -0.486753     0.275731     0.0399688  -0.248826   -0.0233001  -0.659951    0.130118    -0.259022    -0.187265    -0.0183721 
  0.224853     0.544015   -0.427837     -0.0677204   -0.189371     0.804675    -0.427067    -0.309346    -0.148083     0.287512   -0.150302     0.28906      0.299746    -0.360477     0.0457386  -0.282947    0.300929    -0.15906     -0.053282    0.377781    0.450891   -0.141501    0.319447     0.70269     -0.140327     0.61278   
  0.00113724   0.327547   -0.258695     -0.089827    -0.302566     0.290812     0.225532     0.20402     -0.160399     0.573635   -0.0515941   -0.183847     0.362669    -0.0518287   -0.6949      0.445293    0.468849     0.11955     -0.0900482   0.0509579   0.592376   -0.201876    0.395708    -0.00194389   1.02485      0.129688  
  0.301204    -0.160514   -0.487985      0.216772     0.233447    -0.71746      0.00149905   0.312406    -0.218397     0.254188   -0.188092    -0.0988001    0.0600721   -0.153324     0.741763   -0.39083     0.0137243   -0.408494    -0.438687    0.161305    0.412628    0.101863   -0.409312     0.0360103    0.131505    -0.393415  
 -0.0346822    0.36755     0.69971      -0.00642001   0.358346    -0.731828    -0.00124995  -0.275235    -0.652113     0.0690014  -0.251096     0.0285817    0.154337    -0.0267654    0.165578    0.184605    0.125731    -0.37341     -0.269096   -0.11901     0.35282     0.0371401   0.0671911    0.6099      -0.541321    -0.64797   
  0.0732465   -0.148109   -0.107086      0.242649     0.540693    -0.625528    -0.825315     0.319994    -0.246951     0.227162   -0.0133838    0.268562    -0.0369346   -0.12081      0.0934542   0.0742746   0.204242     0.571412    -0.242576    0.579066   -1.05532     0.334277   -0.468766    -0.325889    -0.198901    -0.17682   
  0.36531     -0.0360471   0.299666      0.348665     0.88238     -0.426853    -0.10104      0.622624     0.0667523   -0.178134    0.423887    -0.333393    -0.0488435    0.00612203  -0.145007    0.537343    0.20449      0.648537    -0.860659    0.332261    0.355195   -0.318215   -0.952793     0.608934     0.268719    -0.0899668 
 -0.899329     0.316289    0.167131      0.151366     0.315926    -0.00451315   0.754383    -0.213116    -0.140967    -0.0572613  -0.0168456   -0.306       -0.537499    -0.0422981   -0.430681    0.0995641  -0.10633      0.469103    -0.4152     -0.438059   -0.564795    0.0726183   0.0890531    0.146791    -0.420523    -0.251553  
 -0.051117    -0.140428   -0.0645163    -0.284254     0.577485    -0.058929     0.337919    -0.633579     0.203211     0.397855   -0.113792    -0.410739    -0.228906     0.379798    -0.291445    0.737826   -0.836394    -0.350672    -0.201746   -0.0620784   0.585654   -0.286061    0.289861    -0.283679    -0.227968    -0.27031   
 -0.176728    -0.400914    0.489132      0.478539     0.436101    -0.625774     0.520093     0.0288598   -0.380057     0.338186    0.491681    -0.0573778   -0.0783656    0.508777    -0.119006   -0.434961    0.488729    -0.441485     0.198653    0.326302    0.370956    0.515026    0.0268536   -0.239581     0.334053     0.32666   
 -0.291196     0.556221    0.286752     -0.131905    -0.0585362   -0.476983     0.422642    -0.438013    -0.241362    -0.16743    -0.42033      0.143509     0.165955     0.641943    -0.656233   -0.452533    0.135025    -0.256933    -0.061672    0.215744    0.0049814   0.623836   -0.432092     0.773837     0.262477     0.0875487 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410691
[ Info: iteration 2, average log likelihood -1.410673
[ Info: iteration 3, average log likelihood -1.410656
[ Info: iteration 4, average log likelihood -1.410639
[ Info: iteration 5, average log likelihood -1.410623
[ Info: iteration 6, average log likelihood -1.410608
[ Info: iteration 7, average log likelihood -1.410593
[ Info: iteration 8, average log likelihood -1.410578
[ Info: iteration 9, average log likelihood -1.410564
[ Info: iteration 10, average log likelihood -1.410551
â”Œ Info: EM with 100000 data points 10 iterations avll -1.410551
â”” 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.218930e+05
      1       7.161629e+05      -2.057301e+05 |       32
      2       6.959214e+05      -2.024150e+04 |       32
      3       6.892430e+05      -6.678344e+03 |       32
      4       6.862497e+05      -2.993361e+03 |       32
      5       6.844893e+05      -1.760354e+03 |       32
      6       6.832705e+05      -1.218870e+03 |       32
      7       6.823675e+05      -9.029447e+02 |       32
      8       6.816630e+05      -7.045587e+02 |       32
      9       6.811031e+05      -5.598662e+02 |       32
     10       6.806140e+05      -4.890673e+02 |       32
     11       6.801846e+05      -4.294076e+02 |       32
     12       6.797870e+05      -3.976149e+02 |       32
     13       6.794495e+05      -3.374970e+02 |       32
     14       6.791580e+05      -2.915240e+02 |       32
     15       6.789110e+05      -2.469423e+02 |       32
     16       6.786883e+05      -2.227232e+02 |       32
     17       6.785053e+05      -1.830483e+02 |       32
     18       6.783460e+05      -1.593023e+02 |       32
     19       6.782090e+05      -1.369574e+02 |       32
     20       6.780811e+05      -1.278852e+02 |       32
     21       6.779490e+05      -1.321378e+02 |       32
     22       6.778332e+05      -1.157831e+02 |       32
     23       6.777174e+05      -1.158393e+02 |       32
     24       6.776057e+05      -1.116568e+02 |       32
     25       6.774909e+05      -1.148243e+02 |       32
     26       6.773824e+05      -1.085050e+02 |       32
     27       6.772707e+05      -1.116538e+02 |       32
     28       6.771452e+05      -1.255620e+02 |       32
     29       6.770189e+05      -1.262837e+02 |       32
     30       6.768957e+05      -1.232047e+02 |       32
     31       6.767787e+05      -1.169783e+02 |       32
     32       6.766723e+05      -1.063697e+02 |       32
     33       6.765729e+05      -9.944322e+01 |       32
     34       6.764844e+05      -8.846081e+01 |       32
     35       6.763966e+05      -8.782878e+01 |       32
     36       6.763157e+05      -8.088445e+01 |       32
     37       6.762370e+05      -7.867815e+01 |       32
     38       6.761576e+05      -7.945754e+01 |       32
     39       6.760767e+05      -8.091104e+01 |       32
     40       6.760103e+05      -6.639538e+01 |       32
     41       6.759481e+05      -6.216332e+01 |       32
     42       6.758924e+05      -5.567641e+01 |       32
     43       6.758360e+05      -5.643982e+01 |       32
     44       6.757722e+05      -6.382865e+01 |       32
     45       6.757097e+05      -6.246838e+01 |       32
     46       6.756563e+05      -5.338157e+01 |       32
     47       6.756123e+05      -4.402064e+01 |       32
     48       6.755748e+05      -3.747205e+01 |       32
     49       6.755386e+05      -3.623522e+01 |       32
     50       6.755000e+05      -3.858023e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 675499.9933860739)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422502
[ Info: iteration 2, average log likelihood -1.417505
[ Info: iteration 3, average log likelihood -1.416133
[ Info: iteration 4, average log likelihood -1.415131
[ Info: iteration 5, average log likelihood -1.414129
[ Info: iteration 6, average log likelihood -1.413227
[ Info: iteration 7, average log likelihood -1.412593
[ Info: iteration 8, average log likelihood -1.412221
[ Info: iteration 9, average log likelihood -1.412005
[ Info: iteration 10, average log likelihood -1.411866
[ Info: iteration 11, average log likelihood -1.411764
[ Info: iteration 12, average log likelihood -1.411682
[ Info: iteration 13, average log likelihood -1.411612
[ Info: iteration 14, average log likelihood -1.411550
[ Info: iteration 15, average log likelihood -1.411494
[ Info: iteration 16, average log likelihood -1.411442
[ Info: iteration 17, average log likelihood -1.411394
[ Info: iteration 18, average log likelihood -1.411350
[ Info: iteration 19, average log likelihood -1.411308
[ Info: iteration 20, average log likelihood -1.411268
[ Info: iteration 21, average log likelihood -1.411231
[ Info: iteration 22, average log likelihood -1.411195
[ Info: iteration 23, average log likelihood -1.411161
[ Info: iteration 24, average log likelihood -1.411129
[ Info: iteration 25, average log likelihood -1.411098
[ Info: iteration 26, average log likelihood -1.411067
[ Info: iteration 27, average log likelihood -1.411038
[ Info: iteration 28, average log likelihood -1.411010
[ Info: iteration 29, average log likelihood -1.410983
[ Info: iteration 30, average log likelihood -1.410957
[ Info: iteration 31, average log likelihood -1.410932
[ Info: iteration 32, average log likelihood -1.410907
[ Info: iteration 33, average log likelihood -1.410884
[ Info: iteration 34, average log likelihood -1.410861
[ Info: iteration 35, average log likelihood -1.410839
[ Info: iteration 36, average log likelihood -1.410817
[ Info: iteration 37, average log likelihood -1.410797
[ Info: iteration 38, average log likelihood -1.410777
[ Info: iteration 39, average log likelihood -1.410758
[ Info: iteration 40, average log likelihood -1.410740
[ Info: iteration 41, average log likelihood -1.410722
[ Info: iteration 42, average log likelihood -1.410705
[ Info: iteration 43, average log likelihood -1.410688
[ Info: iteration 44, average log likelihood -1.410672
[ Info: iteration 45, average log likelihood -1.410656
[ Info: iteration 46, average log likelihood -1.410641
[ Info: iteration 47, average log likelihood -1.410626
[ Info: iteration 48, average log likelihood -1.410612
[ Info: iteration 49, average log likelihood -1.410598
[ Info: iteration 50, average log likelihood -1.410584
â”Œ Info: EM with 100000 data points 50 iterations avll -1.410584
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.0244326    0.0526407  -0.025779    0.0662361   -0.0213838   -0.0197927   0.089998   -0.0517725     0.0143225    0.0388571    0.0433779  -0.0434273   0.0660314  -0.0298857    -0.0042959    -0.0216929    0.0837533  -0.0646751   0.0126245   0.0712198    0.0466676   0.00848448  -0.0245451     0.00334821   0.123313    -0.0213851 
 -0.440944     0.0848388  -0.369635   -0.111772    -0.0983688    0.0293477  -0.0082842   0.7126       -0.394308    -0.168344    -0.930376   -0.137563   -0.155698   -0.800043      0.388443      0.0193872   -0.30485     0.603043    0.443246    0.570446     0.0643769  -0.164275     0.150851     -0.251188    -0.120503     0.270872  
  0.145223     0.344494   -0.140964   -0.103365    -0.320578     0.292868    0.235568   -0.0877332    -0.265279     0.636107    -0.0385804  -0.336704    0.205156   -0.012541     -0.637995      0.624518     0.39133     0.170429   -0.166317   -0.0700314    0.742051   -0.210163     0.732658      0.170868     0.546836     0.0278783 
  0.216719    -0.543554   -0.780793    0.229262    -0.351897     0.755343   -0.607285    0.517534      0.545206     0.00720638   0.510323   -0.0946702  -0.143789   -0.154182      0.688108      0.59407     -0.172808    0.220161   -0.0796218  -0.131641     0.102443   -0.524184     0.197002     -0.47776      0.00223599   0.00273467
  0.0699452    0.019249   -0.256497   -0.0154229    0.0499229    0.095533   -0.289784   -0.000964012  -0.475272     0.47417     -0.0940364  -0.126708    0.0746431  -0.0905713     0.514161     -0.108443     0.160824   -0.305373   -0.0717031   0.190659     0.394404    0.112653     0.18953       0.558459    -0.401516     0.0107148 
  0.357116     0.698563   -0.26737    -0.459712    -0.773374    -0.523723   -0.686475    0.556453      0.0229917   -0.262272    -0.408543    0.373589    0.48659     0.104533      0.738884     -0.608605    -0.230201   -0.424473    0.227965    0.297918    -0.0982432   0.0448558   -0.128773     -0.209957     0.31937     -0.544558  
 -0.0874046   -0.18529    -0.10327    -0.679474     0.582523     0.141404    0.179445   -0.532863      0.280884     0.314081     0.0415886  -0.131576   -0.155144    0.279433      0.0107897     0.610709    -0.953884   -0.454972    0.24616    -0.0760231    0.417274   -0.106147     0.426532     -0.33698     -0.443035    -0.0646928 
 -0.242454     0.166053    0.209922   -0.238519    -0.197929     0.397716    0.215698   -0.23779       0.0317581   -0.129631     0.0703455   0.132359   -0.117791    0.399288     -0.419773      0.0810333    0.0649396   0.0164737   0.136546   -0.346353    -0.301044    0.0346351    0.494393      0.0747333   -0.177764     0.0443062 
 -0.277593    -0.055506   -0.411678    0.405014    -0.109835     0.337056    0.123495   -0.137059      0.133931    -0.562253     1.05097    -0.254537    0.102639   -0.196251      0.000243385   0.116848    -0.255014    0.493607    0.442349   -0.289006    -0.351906   -0.0894532    0.405843     -0.51323      0.0270494    0.660788  
  0.0629151   -0.369783    0.0280865  -0.0245925    0.322731    -0.284527   -0.267678   -0.000874796   0.1851       0.197166     0.167291    0.16128     0.0515144   0.0830147     0.254927      0.0994564   -0.268266    0.166972    0.01924     0.189583    -0.322309    0.216011    -0.18576      -0.158273    -0.267473     0.225931  
 -0.20762      0.0194996   0.322913    0.00805919   0.0582193   -0.095736   -0.204246    0.606778     -0.43731     -0.467112     0.0143541   0.162651   -0.719631    0.0087211     0.222441      0.100221     0.195727    0.426016   -0.0718103  -0.476891    -0.286462   -0.209113    -0.00522656   -0.231269    -0.0109259   -0.357024  
  0.0484579    0.0615393  -0.224978   -0.264147    -0.540193     0.418783    0.359121   -0.518205      0.327861     0.494782     0.13189     0.120219    0.706544    0.0519249     0.118872     -0.526681    -0.0633739  -0.636743    0.370532    0.271174    -0.19219     0.520597     0.35548      -0.213602    -0.00616653   0.469965  
  0.712718    -0.184197    0.336873    0.176987    -0.521881     0.16764    -0.407705   -0.157938      0.20835      0.085244     0.0959771   0.255761    0.205179   -0.316134     -0.0140389    -0.58         0.389875    0.37963    -0.158412   -0.200467    -0.252624    0.546902    -0.000935496  -0.366606    -0.131088    -0.160851  
  0.811737     0.372531    0.184789   -0.394474     0.178481    -0.177278   -0.384794   -0.249472     -0.29973     -1.22641      0.364262   -0.17899    -0.266665    0.0488604     0.0978684     0.219379     0.0432691   0.566848    0.618767    0.195831     0.318305    0.252633     0.607039     -0.0056328    0.47975     -0.327244  
  0.521744    -0.493093   -0.101996    0.439882     0.459165    -0.604178   -0.472807    0.659502     -0.0703715   -0.18921      0.0117075  -0.60399     0.18916     0.0764184     0.206354      0.0694542   -0.0389166   0.326162   -0.439154    0.538287     0.485652    0.0392499   -1.03063       0.541661     0.38735     -0.215489  
  0.163423    -0.159634   -0.203026    0.418627     0.113994    -0.136143   -0.226657   -0.0130398     6.33005e-5   0.220051    -0.236416    0.103585    0.362209   -0.660602      0.148527     -0.463936     0.468575   -0.196707   -0.0010421   0.178321    -0.318526    0.197998    -0.276593     -0.296587    -0.0881984   -0.368012  
 -0.0258491    0.283878    0.366516   -0.0528269   -0.24052     -0.45803     0.101311   -0.475052     -0.40678     -0.0315716   -0.428965    0.20091     0.378301    0.730459     -0.248395     -0.29385      0.488505   -0.583774   -0.0495214   0.396233     0.415838    0.620153    -0.699439      1.25632      0.0988634   -0.102284  
 -0.417412     0.150879    0.0609605   0.295105     0.566321     0.172601    0.0658132  -0.0777549     0.267502    -0.173073    -0.034193   -0.402863   -0.532085   -0.403363     -0.528607      0.644622     0.0650889   0.678799   -0.768475   -0.00472123  -0.275319   -0.406385    -0.412983      0.19987     -0.265315    -0.505985  
  0.0988312   -0.171247   -0.18167     0.281582    -0.0272984   -0.516582    0.0178982   0.0823225    -0.044173    -0.212685    -0.144094    0.131307    0.123366   -0.287546      0.430979     -0.28095     -0.101948   -0.23097    -0.126292    0.0339325    0.116576    0.121284    -0.339825     -0.151783     0.091411    -0.763182  
 -0.548817     0.219297   -0.0640841   0.381166    -0.00821186  -0.361476    0.668962   -0.00881751    0.0825908    0.657607    -0.125875   -0.025848   -0.0302437   0.406451     -0.138215     -0.367346    -0.424165    0.0108729  -0.755898   -0.315991    -0.141432    0.327969    -0.540388      0.0312326   -0.00839717   0.291922  
 -0.362034    -0.633243   -0.10469     0.222368     0.049398     0.158797   -0.278677   -0.0409757     0.374423     0.951499    -0.0905058   0.401773    0.11647    -0.599957      0.00517598    0.465408    -0.214079   -0.392707   -0.689188   -0.022019     0.429462   -0.21331     -0.368266     -0.085244    -0.126862    -0.465359  
 -0.0890095    0.584824    0.400039   -0.498387     0.611859    -0.574997    0.198209    0.27351      -0.108348     0.279051     0.541801    0.403467    0.0263969   0.295388      0.282036      0.717636     0.0575829  -0.267318   -0.0669188   0.158212     0.377536   -0.325719    -0.214483      0.28542      0.466418     0.430189  
  0.332858     0.0459648  -0.497833    0.573838    -0.0408658    0.228296    0.12785     0.0345436     0.352147    -0.197326    -0.253425   -0.199188    0.437055   -0.403653     -0.180899     -0.485392     0.332489    0.187407    0.0800725   0.276366     0.289805   -0.499592    -0.263748      0.133311     0.685852     0.334821  
 -0.51204      0.774084    0.103218   -0.0119134    0.430573    -0.544637    0.417789   -0.17844      -0.603268    -0.144489    -0.285033   -0.134377   -0.0021088   0.0300105    -0.476459     -0.160373     0.0794898  -0.260081    0.12574     0.236845    -0.117613    0.145381     0.117608      0.119433     0.151241    -0.0446802 
  0.32529      0.0217362   0.320915    0.16291     -0.200701    -0.0338106   0.186093   -0.194254     -0.111991    -0.477446     0.0182077  -0.53418     0.0136046   0.779755      0.235781     -0.643876     0.221227    0.077124    0.642851    0.321949    -0.307448    0.115248     0.160333      0.185141    -0.0929959    0.164978  
 -0.319153    -0.36527     0.54726     0.195042    -0.232179    -0.0860548   0.168357    0.0948886     0.488145    -0.458297    -0.0602033  -0.0252563   0.154747   -0.0731681    -0.553082      0.401473    -0.249667    0.0955154   0.0428149  -0.474498    -0.703688   -0.079134    -0.50784      -0.663881     0.541641    -0.398524  
 -0.236974     0.0108109   0.545975    0.101703     0.519426    -0.882513    0.30905    -0.331119     -0.474216    -0.229082    -0.171747   -0.208948    0.0634204   0.000975274   0.0955021    -0.0300575   -0.209198   -0.176125   -0.361466   -0.628455    -0.0044742   0.133936     0.320761      0.487163    -0.973609    -0.876724  
 -0.271348     0.346044    0.244246   -0.059891    -0.131679     0.0930147   0.347473   -0.00792912   -0.197568    -0.258252     0.133418   -0.163733   -0.298137    0.538337     -0.140879     -0.00748482  -0.0273311   0.165501    0.243651   -0.18495     -0.201525    0.00528201   0.129855      0.245225     0.068361     0.172892  
 -0.0479605    0.538582   -0.297511   -0.40245     -0.185629     0.830518   -1.05102    -0.120807      0.0309051    0.0335546   -0.055486    0.879139   -0.0313258  -0.319971     -0.279904     -0.0582712    0.229206    0.0988681  -0.0244432   0.644333    -0.147065   -0.216556    -0.100078      0.260774     0.165118     0.523493  
  0.00400757   0.132622   -0.0985143  -0.414217    -0.192831     0.759468   -0.284361    0.198553      0.254823    -0.140465    -0.216421    0.0951274   0.187785   -0.374457     -0.145048      0.520056     [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
0.164206    0.0958967   0.303632    0.0152163   -0.151492   -0.466173    -0.0371749    -0.0965003    0.212461    -0.104798  
  0.35663     -0.228229    0.408835   -0.0205641    0.0789692   -0.150753   -0.3198     -0.641678      0.483675    -0.387133     0.197272    0.341871   -0.307347    0.177005      0.984021     -0.412657    -0.28527    -0.17341     0.166638    0.0650947   -0.429381    0.226366    -0.52088       0.125527    -1.0801       0.00871711
 -0.113704    -0.813931    0.49191     0.555757     0.539723    -0.324927    0.569178    0.0641022    -0.0500384    0.377407     0.60171     0.0868502  -0.248094    0.539272     -0.271717     -0.273206     0.600249   -0.424494    0.134821    0.260863     0.478456    0.549552    -0.11791      -0.357259     0.483412     0.299953  [ Info: iteration 1, average log likelihood -1.410571
[ Info: iteration 2, average log likelihood -1.410558
[ Info: iteration 3, average log likelihood -1.410546
[ Info: iteration 4, average log likelihood -1.410534
[ Info: iteration 5, average log likelihood -1.410522
[ Info: iteration 6, average log likelihood -1.410511
[ Info: iteration 7, average log likelihood -1.410500
[ Info: iteration 8, average log likelihood -1.410489
[ Info: iteration 9, average log likelihood -1.410479
[ Info: iteration 10, average log likelihood -1.410469
â”Œ Info: EM with 100000 data points 10 iterations avll -1.410469
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
