Running tests with Julia v1.3.1-pre.12
   Cloning default registries into `~/.julia`
   Cloning registry from "https://github.com/JuliaRegistries/General.git"
[?25l    Fetching: [>                                        ]  0.0 %    Fetching: [=============>                           ]  31.0 %    Fetching: [================================>        ]  79.5 %[2K[?25h     Added registry `General` to `~/.julia/registries/General`
 Resolving package versions...
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed OrderedCollections â”€ v1.1.0
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed SpecialFunctions â”€â”€â”€ v0.8.0
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.6
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.1.1
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.2
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.21.10
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+1
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.10
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.1.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.8.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building SpecialFunctions â†’ `~/.julia/packages/SpecialFunctions/ne2iw/deps/build.log`
  Building Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_ELpEBe/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.10
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.1.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.8.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -3.335865045440511e6, [75908.17251791318, 24091.827482086836], [-5099.585165343652 21852.375796454548 21654.172423647735; 4794.056023246578 -21631.058892934787 -21827.98509917332], Array{Float64,2}[[76629.16969842219 2689.8178638275663 1510.4108914899264; 2689.8178638275663 64560.06431562558 -9909.227994590512; 1510.4108914899264 -9909.227994590512 64338.56285300444], [23488.377123110884 -2979.0737225048333 -2154.560156566968; -2979.073722504833 35165.995991550815 9877.401541217814; -2154.5601565669685 9877.401541217814 35621.70964637909]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /workspace/srcdir/julia/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.333789e+03
      1       9.501320e+02      -3.836569e+02 |        6
      2       8.742507e+02      -7.588133e+01 |        4
      3       8.580688e+02      -1.618181e+01 |        0
      4       8.580688e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 858.0688483947179)
â”Œ Info: K-means with 272 data points using 4 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.069849
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.851288
[ Info: iteration 2, lowerbound -3.751128
[ Info: iteration 3, lowerbound -3.637671
[ Info: iteration 4, lowerbound -3.489199
[ Info: iteration 5, lowerbound -3.308596
[ Info: iteration 6, lowerbound -3.108729
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.907574
[ Info: iteration 8, lowerbound -2.732938
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -2.607889
[ Info: iteration 10, lowerbound -2.534492
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.476133
[ Info: iteration 12, lowerbound -2.423602
[ Info: iteration 13, lowerbound -2.387384
[ Info: iteration 14, lowerbound -2.355569
[ Info: iteration 15, lowerbound -2.328924
[ Info: iteration 16, lowerbound -2.311594
[ Info: iteration 17, lowerbound -2.307751
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302918
[ Info: iteration 19, lowerbound -2.299259
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Dec  5 17:31:27 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Dec  5 17:31:36 2019: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Thu Dec  5 17:31:37 2019: EM with 272 data points 0 iterations avll -2.069849
5.8 data points per parameter
, Thu Dec  5 17:31:39 2019: GMM converted to Variational GMM
, Thu Dec  5 17:31:49 2019: iteration 1, lowerbound -3.851288
, Thu Dec  5 17:31:49 2019: iteration 2, lowerbound -3.751128
, Thu Dec  5 17:31:49 2019: iteration 3, lowerbound -3.637671
, Thu Dec  5 17:31:49 2019: iteration 4, lowerbound -3.489199
, Thu Dec  5 17:31:49 2019: iteration 5, lowerbound -3.308596
, Thu Dec  5 17:31:49 2019: iteration 6, lowerbound -3.108729
, Thu Dec  5 17:31:49 2019: dropping number of Gaussions to 7
, Thu Dec  5 17:31:49 2019: iteration 7, lowerbound -2.907574
, Thu Dec  5 17:31:49 2019: iteration 8, lowerbound -2.732938
, Thu Dec  5 17:31:49 2019: dropping number of Gaussions to 6
, Thu Dec  5 17:31:49 2019: iteration 9, lowerbound -2.607889
, Thu Dec  5 17:31:49 2019: iteration 10, lowerbound -2.534492
, Thu Dec  5 17:31:49 2019: dropping number of Gaussions to 3
, Thu Dec  5 17:31:49 2019: iteration 11, lowerbound -2.476133
, Thu Dec  5 17:31:49 2019: iteration 12, lowerbound -2.423602
, Thu Dec  5 17:31:49 2019: iteration 13, lowerbound -2.387384
, Thu Dec  5 17:31:50 2019: iteration 14, lowerbound -2.355569
, Thu Dec  5 17:31:50 2019: iteration 15, lowerbound -2.328924
, Thu Dec  5 17:31:50 2019: iteration 16, lowerbound -2.311594
, Thu Dec  5 17:31:50 2019: iteration 17, lowerbound -2.307751
, Thu Dec  5 17:31:50 2019: dropping number of Gaussions to 2
, Thu Dec  5 17:31:50 2019: iteration 18, lowerbound -2.302918
, Thu Dec  5 17:31:50 2019: iteration 19, lowerbound -2.299259
, Thu Dec  5 17:31:50 2019: iteration 20, lowerbound -2.299256
, Thu Dec  5 17:31:50 2019: iteration 21, lowerbound -2.299254
, Thu Dec  5 17:31:50 2019: iteration 22, lowerbound -2.299254
, Thu Dec  5 17:31:50 2019: iteration 23, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 24, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 25, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 26, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 27, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 28, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 29, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 30, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 31, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 32, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 33, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 34, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 35, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 36, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 37, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 38, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 39, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 40, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 41, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 42, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 43, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 44, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 45, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 46, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 47, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 48, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 49, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: iteration 50, lowerbound -2.299253
, Thu Dec  5 17:31:50 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509222601402, 95.95490777398595]
Î² = [178.04509222601402, 95.95490777398595]
m = [4.250300733269909 79.28686694436182; 2.000229257775369 53.85198717246128]
Î½ = [180.04509222601402, 97.95490777398595]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.184041555474851 -0.007644049042327771; 0.0 0.008581705166333558], [0.3758763611948455 -0.008953123827346036; 0.0 0.012748664777409303]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.995168354880985
avll from llpg:  -0.9951683548809835
avll direct:     -0.9951683548809835
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9853801974989154
avll from llpg:  -0.9853801974989155
avll direct:     -0.9853801974989155
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
  0.0469582   -0.0903115   -0.0558206     0.020221    -0.0978762    0.0567095    0.0508109    -0.009527     0.0160367    0.0574195    0.0715484    0.038085    -0.0113483   -0.144635    -0.0452963   -0.0812379   0.135015     -0.0496645   -0.0126915    0.0387712    0.079368     0.138004     0.223966    -0.0627512     0.0446911   -0.0143404 
  0.0942735   -0.0785794    0.0861713     0.154333     0.0260401    0.0570921   -0.0923639    -0.140499    -0.066731    -0.080881    -0.0792037    0.0158075   -0.059541    -0.00408874  -0.102664    -0.0302592   0.116937     -0.13037      0.0426597    0.0709365    0.158387     0.235404     0.196309    -0.114236     -0.217295     0.0823472 
  0.185999     0.0912608    0.0996946     0.144243    -0.0379003   -0.156568    -0.059778      0.229472    -0.114031    -0.0970979    0.00994092  -0.0347198    0.0821516   -0.133569    -0.0687523   -0.10453    -0.0168762    -0.130201     0.0395093    0.0514695    0.155412    -0.0397614   -0.0771257   -0.111075     -0.0479593    0.0117299 
  0.125945     0.0958562   -0.027401     -0.0311899   -0.155123    -0.200254     0.15804       0.0133478   -0.188026    -0.0571003   -0.0950664   -0.0797723    0.0589754    0.16315     -0.0541441   -0.129362   -0.034398     -0.155168    -0.185845    -0.0431176    0.0850105    0.143688     0.0923906    0.226826     -0.0646423    0.0201966 
  0.0354942    0.00512751  -0.095342      0.00903864   0.165773     0.126053     0.195352     -0.0481102    0.159739     0.142021    -0.033172    -0.0212596    0.0572829    0.00622     -0.0341994   -0.113621   -0.0626058    -0.146674     0.0755903   -0.0941218   -0.0250387    0.167436     0.0214275    0.10837      -0.174267     0.0408511 
  0.0225964   -0.0783984   -0.0848957     0.0751082    0.0611241    0.00209229   0.0329888    -0.0204087    0.0110344   -0.100269     0.0117253    0.110072     0.0179464    0.0353735   -0.0159705    0.140956   -0.090941      0.0707055    0.0468189    0.00961819  -0.150214    -0.0659266   -0.0939707    0.000501962   0.112743     0.0358194 
 -0.0738967    0.161436     0.0577954     0.0663353    0.0386887    0.10473     -0.016097      0.0826701   -0.0575338   -0.0725027    0.0434728    0.0798733    0.0825954   -0.0859318   -0.0460472   -0.113128    0.000840932  -0.069433     0.00162294  -0.0708926   -0.235301    -0.0660797    0.0976649    0.166796      0.0288921    0.0619367 
 -0.0155453   -0.0134293    0.0394004    -0.0231917    0.0418301    0.0486216    0.00479633    0.043694    -0.114472    -0.0765018   -0.147413     0.143128    -0.0214887   -0.043389    -0.0196693    0.099291   -0.153902      0.0269768   -0.0389458    0.0736032   -0.228096    -0.0407002   -0.0111254   -0.205925      0.0855802   -0.16263   
  0.120902    -0.0860937    0.0461422     0.114445    -0.0256176    0.0472496   -0.145945      0.0436809   -0.156189    -0.0264351    0.00160122   0.0920072   -0.0949004   -0.0115785   -0.116719    -0.106639   -0.0116055    -0.0521342    0.114106    -0.0825739   -0.0137225   -0.0688774    0.0282602    0.100639     -0.128001    -0.0712808 
  0.0365509   -0.0960261    0.0557478     0.064364     0.0326749    0.0927943    0.00263204   -0.0676745   -0.00860148   0.107476     0.086612    -0.0555135    0.243874     0.136919     0.110166    -0.041484    0.00219998   -0.141825    -0.0482891    0.294519     0.0907101   -0.170854    -0.0985544    0.0770591    -0.0675152    0.131123  
  0.0485674   -0.0639189   -0.117945      0.0156492   -0.0364467   -0.0954619    0.141482      0.0742936    0.0674779   -0.167353    -0.200532     0.0052626    0.0895529    0.13448      0.0611513    0.0600668   0.0194725     0.031654    -0.0485449    0.13187      0.316317     0.14244     -0.144889    -0.0216976    -0.200722     0.0485684 
  0.108607    -0.0902117    0.000381651   0.0406095   -0.00514788   0.0835384    0.145888      0.0118686    0.0924754   -0.0561398    0.119807     0.0533018   -0.165482     0.0699105   -0.00828827   0.101377    0.0971825    -0.0758325   -0.0561917   -0.0746582    0.0841558    0.0803745    0.0137275   -0.0353946    -0.127274     0.0275068 
  0.10793      0.0944096   -0.0628441     0.148027     0.0547129    0.0722106   -0.00473383    0.0821256   -0.132043     0.0231259    0.181538    -0.0627028   -0.0574331   -0.0901571    0.113478    -0.0177465   0.0802939    -0.114467    -0.018303     0.00600963   0.0225231   -0.0266623    0.0620076   -0.0457839    -0.0798432    0.118869  
  0.182743    -0.00151723  -0.0181906     0.078605     0.0969036   -0.0533373    0.0393994     0.107208     0.070629     0.00324318  -0.0105458   -0.102108    -0.0197881    0.0374128    0.0659259    0.160436    0.0403095    -0.00237796  -0.00175869  -0.0993786    0.0614458    0.0407777   -0.0154968   -0.0219529    -0.00113064   0.0583444 
 -0.0179216    0.0593662    0.05031       0.030334    -0.102902    -0.131687    -0.0134968    -0.0672177    0.00716752  -0.0790523    0.0403563   -0.0335018   -0.0691162    0.1199      -0.0968808   -0.0128734   0.0308461     0.0841066    0.0349753    0.153867    -0.00839996  -0.00972146  -0.0494742    0.122931     -0.0473487    0.0956606 
 -0.0580353    0.138061    -0.0234046    -0.225827     0.00736378   0.0853888   -0.0549354     0.0088052    0.0388278   -0.108514    -0.0406938    0.185575     0.0509495    0.00495753  -0.0273046   -0.0308758  -0.0485124     0.113354    -0.180881     0.148354    -0.0407486   -0.049451    -0.0628671   -0.0369728     0.198781     0.143552  
  0.0982847   -0.145144    -0.0609847    -0.132104    -0.0227086    0.00237505  -0.232778     -0.023366    -0.114073    -0.193829    -0.249794     0.0240615    0.0786936    0.0665412   -0.146518    -0.013469   -0.0465912     0.158458    -0.0177867   -0.056611    -0.00282526  -0.132683    -0.0815629    0.150938      0.19796     -0.00111727
 -0.0179283   -0.0716649   -0.133398     -0.156007     0.0104203   -0.176601     0.0288374     0.0941625    0.117203    -0.139917     0.0126867    0.0978946   -0.0253545    0.108779     0.0846951   -0.0624297   0.0201131    -0.184301     0.0812751   -0.0525959   -0.199791     0.181433     0.00505461   0.0995857     0.145593     0.161156  
  0.119229    -0.00994925   0.0264383     0.0140424   -0.113259    -0.089407    -0.249481     -0.121613     0.144487    -0.00157974  -0.0993876    0.116113    -0.0807027    0.0660351   -0.0808791   -0.0494495   0.0844602     0.0616368   -0.0983426    0.00613745   0.0299227    0.0397138    0.00137512   0.00285196   -0.241162    -0.0220092 
  0.0198428    0.0801741    0.00710175    0.139919    -0.022241    -0.0494672   -0.0891389     0.158795     0.0736986   -0.139511    -0.018313    -0.149621    -0.0960155   -0.0025135   -0.00828366   0.0240162  -0.0437795     0.0334817    0.0740622    0.0249472   -0.155334     0.0920955    0.110752     0.0512676    -0.117339    -0.052443  
  0.151791    -0.056194    -0.0690919    -0.0865631    0.00277517   0.10166      0.177472     -0.00936249   0.00438823  -0.12185     -0.126941    -0.0716731   -0.0500726   -0.00302259  -0.055727     0.119291   -0.0783645     0.091905    -0.116154     0.0987069   -0.0526614    0.0969864    0.0106691   -0.0232467    -0.0174197    0.138511  
  0.0538249   -0.0737739    0.0122848     0.0943257   -0.00138029  -0.124294    -0.0706931    -0.168368    -0.12883     -0.0813971    0.0370895   -0.109115     0.00691137   0.123684    -0.0327787    0.130939    0.138059      0.116815    -0.0780773   -0.0723136    0.0718768   -0.0199208   -0.0975436    0.088449      0.00108113  -0.0100895 
  0.145648    -0.208453     0.215458      0.279277    -0.184341    -0.0926481    0.0723294    -0.110102     0.105534     0.0662808    0.0806031    0.0197681   -0.0420846   -0.0954587    0.092273     0.146991   -0.09357       0.0395699    0.0889792    0.0847453    0.0492656   -0.0705214    0.0238823   -0.201524      0.0660142   -0.187291  
  0.0659458    0.117872    -0.0816258     0.131666    -0.0877654   -0.0736839   -0.0368564    -0.00238461   0.0303292    0.0514021   -0.179944     0.200345    -0.00880045  -0.139208    -0.042203    -0.0048047  -0.0448852    -0.147545    -0.0218344    0.0365631   -0.113565     0.123863    -0.0571943   -0.104329      0.107975    -0.0475493 
  0.0513071   -0.0392712    0.0404028    -0.0753695    0.125802     0.0577534    0.01041       0.0136228   -0.00614465   0.13375      0.00572744  -0.149328    -0.0782082   -0.259541     0.0544895   -0.0039677  -0.0683996     0.0323246    0.0694175   -0.19436     -0.0329853    0.0815066   -0.0628243    0.0717178     0.0802244    0.0949944 
  0.0617446    0.00664337   0.0637669    -0.139405    -0.229756     0.137011    -0.000768466   0.0122275    0.0702357    0.040191    -0.00986688  -0.0468498    0.103278     0.0695624   -0.0454386   -0.031465   -0.117777     -0.16349     -0.11062      0.00300345  -0.23406     -0.0772843   -0.163626    -0.209658      0.176625    -0.108915  
 -0.00774421  -0.0967676   -0.134249      0.106854    -0.0781773    0.108294     0.177455     -0.00700167  -0.0994009    0.0898105   -0.123778     0.0819401    0.0857296   -0.0115671    0.0982461    0.0124754   0.152826      0.0312522   -0.0203319    0.0625844   -0.121974    -0.0987716   -0.212654    -0.0152138    -0.267069    -0.0482226 
 -0.0413366    0.294298     0.132184     -0.213529     0.00594527   0.0267426    0.0420634    -0.155698    -0.0125555    0.0541997   -0.204127    -0.098657    -0.136221     0.0495024   -0.130907     0.125957   -0.0498038     0.00245914  -0.15023      0.0689928   -0.0496018   -0.00956332  -0.06088     -0.14795       0.0617972   -0.180128  
  0.0689865   -0.0712311    0.0186009     0.0973876    0.059301    -0.0191373    0.0795465     0.095628     0.0670859   -0.0113317   -0.0920819   -0.0563275   -0.107895    -0.0654914   -0.0326214   -0.105602    0.0512683    -0.0872207    0.180496    -0.165358    -0.0332478    0.117757    -0.0202546   -0.0190933    -0.140412     0.112713  
  0.00552262   0.243821     0.0305808     0.0270879   -0.0430195    0.0473899    0.00782544    0.0138459    0.0468133   -0.0158152   -0.0746589   -0.0134544   -0.199866     0.0623211    0.016712    -0.171692    0.0466954    -0.0628989    0.023605     0.139567    -0.108542     0.0310695    0.00924464  -0.0190696     0.0282852    0.0125081 
  0.0717403   -0.00804613   0.016608      0.063964    -0.0452849   -0.0165151   -0.0820473     0.0619501   -0.0704459   -0.0492687   -0.0441441    0.119881    -0.0997806    0.0415285    0.181796    -0.0522978   0.127729      0.0123325    0.156247     0.1489       0.161976     0.0351576    0.0477762    0.0795223    -0.109386    -0.0138941 
  0.102851     0.0682432   -0.13824       0.118284    -0.0480729    0.0739416   -0.0132774     0.0247875    0.0225164    0.0500271   -0.0490572   -0.00132281  -0.0128727   -0.155497     0.109842     0.0648844  -0.0269308    -0.0713707   -0.0482568   -0.129761     0.157116     0.0273158   -0.0709784   -0.0504733     0.0380777   -0.0022584 kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4056786722114614
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405766
[ Info: iteration 2, average log likelihood -1.405700
[ Info: iteration 3, average log likelihood -1.405305
[ Info: iteration 4, average log likelihood -1.398858
[ Info: iteration 5, average log likelihood -1.378253
[ Info: iteration 6, average log likelihood -1.368893
[ Info: iteration 7, average log likelihood -1.367029
[ Info: iteration 8, average log likelihood -1.366220
[ Info: iteration 9, average log likelihood -1.365680
[ Info: iteration 10, average log likelihood -1.365201
[ Info: iteration 11, average log likelihood -1.364776
[ Info: iteration 12, average log likelihood -1.364438
[ Info: iteration 13, average log likelihood -1.364184
[ Info: iteration 14, average log likelihood -1.364000
[ Info: iteration 15, average log likelihood -1.363870
[ Info: iteration 16, average log likelihood -1.363779
[ Info: iteration 17, average log likelihood -1.363715
[ Info: iteration 18, average log likelihood -1.363669
[ Info: iteration 19, average log likelihood -1.363636
[ Info: iteration 20, average log likelihood -1.363613
[ Info: iteration 21, average log likelihood -1.363597
[ Info: iteration 22, average log likelihood -1.363586
[ Info: iteration 23, average log likelihood -1.363579
[ Info: iteration 24, average log likelihood -1.363574
[ Info: iteration 25, average log likelihood -1.363571
[ Info: iteration 26, average log likelihood -1.363569
[ Info: iteration 27, average log likelihood -1.363568
[ Info: iteration 28, average log likelihood -1.363567
[ Info: iteration 29, average log likelihood -1.363566
[ Info: iteration 30, average log likelihood -1.363565
[ Info: iteration 31, average log likelihood -1.363565
[ Info: iteration 32, average log likelihood -1.363565
[ Info: iteration 33, average log likelihood -1.363565
[ Info: iteration 34, average log likelihood -1.363565
[ Info: iteration 35, average log likelihood -1.363565
[ Info: iteration 36, average log likelihood -1.363565
[ Info: iteration 37, average log likelihood -1.363565
[ Info: iteration 38, average log likelihood -1.363565
[ Info: iteration 39, average log likelihood -1.363565
[ Info: iteration 40, average log likelihood -1.363564
[ Info: iteration 41, average log likelihood -1.363564
[ Info: iteration 42, average log likelihood -1.363564
[ Info: iteration 43, average log likelihood -1.363564
[ Info: iteration 44, average log likelihood -1.363564
[ Info: iteration 45, average log likelihood -1.363564
[ Info: iteration 46, average log likelihood -1.363564
[ Info: iteration 47, average log likelihood -1.363564
[ Info: iteration 48, average log likelihood -1.363564
[ Info: iteration 49, average log likelihood -1.363564
[ Info: iteration 50, average log likelihood -1.363564
â”Œ Info: EM with 100000 data points 50 iterations avll -1.363564
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4057656113371053
â”‚     -1.405699690358631 
â”‚      â‹®                 
â””     -1.3635644724627307
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.363713
[ Info: iteration 2, average log likelihood -1.363597
[ Info: iteration 3, average log likelihood -1.363224
[ Info: iteration 4, average log likelihood -1.359089
[ Info: iteration 5, average log likelihood -1.345174
[ Info: iteration 6, average log likelihood -1.335007
[ Info: iteration 7, average log likelihood -1.332053
[ Info: iteration 8, average log likelihood -1.330550
[ Info: iteration 9, average log likelihood -1.329417
[ Info: iteration 10, average log likelihood -1.328457
[ Info: iteration 11, average log likelihood -1.327598
[ Info: iteration 12, average log likelihood -1.326743
[ Info: iteration 13, average log likelihood -1.325786
[ Info: iteration 14, average log likelihood -1.324626
[ Info: iteration 15, average log likelihood -1.323266
[ Info: iteration 16, average log likelihood -1.321876
[ Info: iteration 17, average log likelihood -1.320664
[ Info: iteration 18, average log likelihood -1.319845
[ Info: iteration 19, average log likelihood -1.319374
[ Info: iteration 20, average log likelihood -1.319112
[ Info: iteration 21, average log likelihood -1.318963
[ Info: iteration 22, average log likelihood -1.318876
[ Info: iteration 23, average log likelihood -1.318823
[ Info: iteration 24, average log likelihood -1.318790
[ Info: iteration 25, average log likelihood -1.318769
[ Info: iteration 26, average log likelihood -1.318754
[ Info: iteration 27, average log likelihood -1.318744
[ Info: iteration 28, average log likelihood -1.318736
[ Info: iteration 29, average log likelihood -1.318729
[ Info: iteration 30, average log likelihood -1.318723
[ Info: iteration 31, average log likelihood -1.318717
[ Info: iteration 32, average log likelihood -1.318710
[ Info: iteration 33, average log likelihood -1.318704
[ Info: iteration 34, average log likelihood -1.318696
[ Info: iteration 35, average log likelihood -1.318688
[ Info: iteration 36, average log likelihood -1.318679
[ Info: iteration 37, average log likelihood -1.318669
[ Info: iteration 38, average log likelihood -1.318660
[ Info: iteration 39, average log likelihood -1.318650
[ Info: iteration 40, average log likelihood -1.318640
[ Info: iteration 41, average log likelihood -1.318630
[ Info: iteration 42, average log likelihood -1.318621
[ Info: iteration 43, average log likelihood -1.318611
[ Info: iteration 44, average log likelihood -1.318603
[ Info: iteration 45, average log likelihood -1.318594
[ Info: iteration 46, average log likelihood -1.318587
[ Info: iteration 47, average log likelihood -1.318579
[ Info: iteration 48, average log likelihood -1.318572
[ Info: iteration 49, average log likelihood -1.318564
[ Info: iteration 50, average log likelihood -1.318556
â”Œ Info: EM with 100000 data points 50 iterations avll -1.318556
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3637133833437567
â”‚     -1.363597463347831 
â”‚      â‹®                 
â””     -1.3185558540271363
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.318701
[ Info: iteration 2, average log likelihood -1.318504
[ Info: iteration 3, average log likelihood -1.317095
[ Info: iteration 4, average log likelihood -1.305703
[ Info: iteration 5, average log likelihood -1.281681
[ Info: iteration 6, average log likelihood -1.266407
[ Info: iteration 7, average log likelihood -1.259976
[ Info: iteration 8, average log likelihood -1.256000
[ Info: iteration 9, average log likelihood -1.253885
[ Info: iteration 10, average log likelihood -1.252925
[ Info: iteration 11, average log likelihood -1.252443
[ Info: iteration 12, average log likelihood -1.252168
[ Info: iteration 13, average log likelihood -1.251984
[ Info: iteration 14, average log likelihood -1.251840
[ Info: iteration 15, average log likelihood -1.251713
[ Info: iteration 16, average log likelihood -1.251598
[ Info: iteration 17, average log likelihood -1.251491
[ Info: iteration 18, average log likelihood -1.251395
[ Info: iteration 19, average log likelihood -1.251312
[ Info: iteration 20, average log likelihood -1.251244
[ Info: iteration 21, average log likelihood -1.251190
[ Info: iteration 22, average log likelihood -1.251146
[ Info: iteration 23, average log likelihood -1.251111
[ Info: iteration 24, average log likelihood -1.251084
[ Info: iteration 25, average log likelihood -1.251063
[ Info: iteration 26, average log likelihood -1.251047
[ Info: iteration 27, average log likelihood -1.251035
[ Info: iteration 28, average log likelihood -1.251027
[ Info: iteration 29, average log likelihood -1.251020
[ Info: iteration 30, average log likelihood -1.251015
[ Info: iteration 31, average log likelihood -1.251009
[ Info: iteration 32, average log likelihood -1.251004
[ Info: iteration 33, average log likelihood -1.250999
[ Info: iteration 34, average log likelihood -1.250993
[ Info: iteration 35, average log likelihood -1.250986
[ Info: iteration 36, average log likelihood -1.250978
[ Info: iteration 37, average log likelihood -1.250968
[ Info: iteration 38, average log likelihood -1.250955
[ Info: iteration 39, average log likelihood -1.250938
[ Info: iteration 40, average log likelihood -1.250914
[ Info: iteration 41, average log likelihood -1.250878
[ Info: iteration 42, average log likelihood -1.250819
[ Info: iteration 43, average log likelihood -1.250707
[ Info: iteration 44, average log likelihood -1.250510
[ Info: iteration 45, average log likelihood -1.250116
[ Info: iteration 46, average log likelihood -1.249479
[ Info: iteration 47, average log likelihood -1.248972
[ Info: iteration 48, average log likelihood -1.248866
[ Info: iteration 49, average log likelihood -1.248848
[ Info: iteration 50, average log likelihood -1.248844
â”Œ Info: EM with 100000 data points 50 iterations avll -1.248844
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3187010924622713
â”‚     -1.3185036719290268
â”‚      â‹®                 
â””     -1.2488438248702765
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.249069
[ Info: iteration 2, average log likelihood -1.248803
[ Info: iteration 3, average log likelihood -1.247405
[ Info: iteration 4, average log likelihood -1.234786
[ Info: iteration 5, average log likelihood -1.203377
[ Info: iteration 6, average log likelihood -1.171040
[ Info: iteration 7, average log likelihood -1.154816
[ Info: iteration 8, average log likelihood -1.147083
[ Info: iteration 9, average log likelihood -1.141186
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.135522
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.153429
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.148865
[ Info: iteration 13, average log likelihood -1.148278
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.139022
[ Info: iteration 15, average log likelihood -1.148125
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     5
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.140285
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.144761
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.144195
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.146777
[ Info: iteration 20, average log likelihood -1.148804
[ Info: iteration 21, average log likelihood -1.139970
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.135533
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.154789
[ Info: iteration 24, average log likelihood -1.151060
[ Info: iteration 25, average log likelihood -1.139777
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.133965
[ Info: iteration 27, average log likelihood -1.153978
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     5
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.141743
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.146095
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.146445
[ Info: iteration 31, average log likelihood -1.150148
[ Info: iteration 32, average log likelihood -1.140726
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.135282
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.141351
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.156144
[ Info: iteration 36, average log likelihood -1.152105
[ Info: iteration 37, average log likelihood -1.141552
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.136409
[ Info: iteration 39, average log likelihood -1.145793
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.137000
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.151978
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.147732
[ Info: iteration 43, average log likelihood -1.151192
[ Info: iteration 44, average log likelihood -1.142517
[ Info: iteration 45, average log likelihood -1.137771
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.133040
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     11
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.151174
[ Info: iteration 48, average log likelihood -1.157855
[ Info: iteration 49, average log likelihood -1.142914
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.137311
â”Œ Info: EM with 100000 data points 50 iterations avll -1.137311
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2490692200789366
â”‚     -1.2488025372607696
â”‚      â‹®                 
â””     -1.1373109850813354
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.147468
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      9
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.138382
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     21
â”‚     22
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.130403
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      9
â”‚     10
â”‚     19
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.112272
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     10
â”‚     18
â”‚     21
â”‚     22
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.104264
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      9
â”‚     13
â”‚     18
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.074474
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     10
â”‚     14
â”‚      â‹®
â”‚     23
â”‚     28
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.042205
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      9
â”‚     18
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.051932
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.044617
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      9
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.026775
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.055418
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      9
â”‚     18
â”‚      â‹®
â”‚     29
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.028712
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     10
â”‚     14
â”‚      â‹®
â”‚     22
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.035491
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      9
â”‚     18
â”‚     23
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.052199
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.045943
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      9
â”‚     14
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.025532
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      5
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.047213
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚      9
â”‚     18
â”‚     23
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.038264
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     10
â”‚     14
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.033118
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      5
â”‚      9
â”‚     18
â”‚     23
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.040715
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.037968
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      6
â”‚      9
â”‚     14
â”‚     18
â”‚      â‹®
â”‚     23
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.033950
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      5
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.044883
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      9
â”‚     18
â”‚     23
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.035699
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     10
â”‚     14
â”‚      â‹®
â”‚     22
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.029984
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.024880
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.062945
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      9
â”‚     14
â”‚      â‹®
â”‚     23
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.033120
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.045366
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      9
â”‚     18
â”‚     23
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.027754
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.031255
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     18
â”‚     23
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.050159
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.026521
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      9
â”‚     14
â”‚     18
â”‚     19
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.037098
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.041312
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      9
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.030393
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     10
â”‚     14
â”‚      â‹®
â”‚     23
â”‚     28
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.035837
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     18
â”‚     23
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.043564
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      6
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.034776
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      9
â”‚     14
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.032247
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.051192
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      9
â”‚     18
â”‚     23
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.041594
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     10
â”‚      â‹®
â”‚     22
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.022288
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      6
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.038750
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.034907
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      5
â”‚      9
â”‚     14
â”‚     18
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.013365
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.039876
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚      9
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.015289
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     10
â”‚      â‹®
â”‚     23
â”‚     28
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.013366
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     18
â”‚     23
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.041604
â”Œ Info: EM with 100000 data points 50 iterations avll -1.041604
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.1474680542791653
â”‚     -1.1383817905138889
â”‚      â‹®                 
â””     -1.0416044677660432
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4056786722114614
â”‚     -1.4057656113371053
â”‚     -1.405699690358631 
â”‚     -1.4053050133235159
â”‚      â‹®                 
â”‚     -1.0152888554581108
â”‚     -1.013365561703695 
â””     -1.0416044677660432
32Ã—26 Array{Float64,2}:
 -0.0119454   -0.0676617   -0.156028    -0.151126     0.0130369   -0.176241     0.0214392    0.107985     0.119143    -0.140223     0.012469     0.0965753   -0.0257851    0.136318     0.0634788   -0.00181861   0.0113492    -0.18512      0.0806931    -0.0334904   -0.214825     0.169699     0.0381855     0.106316    0.145826    0.16158   
  0.0889492    0.0722141   -0.142181     0.138181     0.00911961   0.0540708    0.013426     0.0541294   -0.0687437    0.0446378    0.0637787   -0.0132113   -0.0371525   -0.111376     0.114553     0.0191947    0.0274044    -0.0841358   -0.03581      -0.056229     0.0901994   -0.00217231  -0.000446452  -0.0530451  -0.0215058   0.0720153 
  0.115417     0.0709193   -0.0147594   -0.0403235   -0.161809    -0.202248     0.196521     0.0200743   -0.244696    -0.0588021   -0.0779832   -0.0842145    0.061144     0.169269    -0.052691    -0.0882794   -0.0322775    -0.13877     -0.180589     -0.0250461    0.0781989    0.14014      0.053587      0.263594   -0.0590032   0.017958  
  0.0710296    0.104355    -0.0569052    0.141683    -0.0500008   -0.0681509   -0.0495121    0.00551598   0.0493445    0.0455898   -0.177885     0.224097    -0.00405005  -0.116941    -0.022994    -0.0542366   -0.0592044    -0.124424    -0.00285079    0.0309701   -0.134873     0.100887    -0.03741      -0.143115    0.11122    -0.106282  
  0.186999     0.0835217    0.0260307    0.140718    -0.041531    -0.153279    -0.0476626    0.23902     -0.110512    -0.0855481    0.00971696  -0.0524075    0.0773661   -0.12939     -0.095269    -0.0835299   -0.0240845    -0.11673      0.0173334     0.0471451    0.151216    -0.0212044   -0.0669545    -0.109605   -0.0505374   0.00966362
  0.0174957   -0.0601265   -0.0754086    0.0810284    0.0629599    0.0183138    0.0370248   -0.0391703    0.0311212   -0.0890204   -0.0120394    0.125136     0.0275145    0.0349896    0.0172595    0.123413    -0.0073723     0.0710951    0.0742179     0.00549766  -0.144787    -0.0637653   -0.0658361    -0.035751    0.124292    0.0895147 
  0.0937658   -0.103963     0.0868173    0.151375     0.0175369    0.0436794   -0.056806    -0.151621    -0.0566267   -0.0735537   -0.0857571    0.045491    -0.0456366   -0.030211    -0.103504    -0.0215241    0.082375     -0.129903     0.00520017    0.0491089    0.161312     0.217205     0.194146     -0.092996   -0.218558    0.0691376 
 -0.0752162    0.174455     0.0370908    0.0647079    0.0679732    0.105179    -0.0301789    0.0794894   -0.0435825   -0.0755874    0.0709246    0.0487186    0.102051    -0.0852568   -0.0456284   -0.130864    -0.0105593    -0.0685623   -0.00561387   -0.0629811   -0.253118    -0.0547399    0.073175      0.129136    0.0289804   0.0521019 
  0.076636    -0.442836    -0.151798    -0.112922     0.0715627   -0.00061085  -0.23757     -0.0405586   -0.042187    -0.195482    -0.260938    -0.00216517   0.133095     0.0660763   -0.0257713    0.0139822    0.0115623     0.148619    -0.114838     -0.0594008   -0.0773392   -0.148566     0.144343      0.295517    0.211898    0.0253065 
  0.111221     0.218875     0.1017      -0.134623    -0.132748    -0.0206915   -0.247124    -0.00176113  -0.207269    -0.191468    -0.255182     0.0587256    0.0465329    0.0650701   -0.272421    -0.0312716   -0.0981115     0.168617     0.116567     -0.0957025    0.0314365   -0.0714676   -0.280986      0.0496484   0.181593   -0.0367885 
  0.0506789   -0.0722284    0.00167815   0.0944871   -0.00278326  -0.218251    -0.0709286   -0.167563    -0.11912     -0.07944      0.0307291   -0.108901     0.00716269   0.164071    -0.0483401    0.111897     0.144839      0.134096    -0.0784049    -0.07094      0.0502028   -0.016816    -0.100655     -0.007999    0.0224957   0.0027695 
 -0.00377396   0.239038     0.0309581    0.0353479   -0.0484157    0.0492931   -0.0093956    0.00121595   0.0474645   -0.0115952   -0.0798526    0.00905681  -0.186034     0.0679643    0.0370481   -0.162372     0.0488085    -0.0627933    0.020714      0.151876    -0.101409    -0.00878526  -0.000764298  -0.007301    0.0150377   0.00120218
  0.0360345   -0.0573784   -0.118572     0.0171905   -0.0467028   -0.118582     0.125928     0.0742792    0.0549832   -0.129059    -0.194894    -0.00878494   0.085317     0.130375     0.0573393    0.0864325    0.0248695     0.0424045   -0.0514033     0.131737     0.315284     0.125857    -0.176568     -0.0215582  -0.211438    0.0499952 
 -0.0663867    0.142563    -0.0147869   -0.21563      0.0196809    0.0858432   -0.0457478    0.0100239   -0.0216812   -0.0444363   -0.0537256    0.183876     0.050349    -0.0785657   -0.0286538   -0.0302173   -0.0516732     0.116172    -0.173673      0.183777    -0.0414637   -0.0428756   -0.0348096    -0.0488028   0.187799    0.128612  
  0.148788    -0.202992     0.207417     0.280612    -0.173426    -0.10902      0.0918108   -0.110454     0.110298     0.0676765    0.0772145    0.0264974   -0.0446199   -0.155457     0.0906851    0.145873    -0.101609      0.0411256    0.0799972     0.0839874    0.115494    -0.0728453    0.0311746    -0.1876      0.0875783  -0.145453  
  0.0464521    0.0837946    0.0340083   -0.0725665   -0.0224126    0.0596538    0.0559991   -0.0327749   -0.0550626   -0.0441082   -0.110267    -0.00100749  -0.0946529    0.0368667   -0.00687648   0.0728794    0.000956253   0.0344326   -0.0337579     0.108438     0.013262     0.0231393   -0.00546094   -0.0330378  -0.0165069  -0.0456097 
  0.0572915    0.00208691   0.0649705   -0.154287    -0.213572     0.130579    -0.00107597   0.0016099    0.0624724    0.0485635   -0.00445429  -0.0472012    0.102299     0.0781177   -0.0624997   -0.0308963   -0.110347     -0.165526    -0.11275       0.00242951  -0.221387    -0.076359    -0.163341     -0.21414     0.177954   -0.114811  
  0.065561    -0.0641294   -0.0617236    0.0243931   -0.104463     0.0561667    0.0506372    0.00161729  -0.00311588   0.0499777    0.0815915    0.0415311   -0.00913907  -0.129764    -0.0444958   -0.0794922    0.126798     -0.0490962   -0.0279575     0.0537425    0.0729265    0.137036     0.219234     -0.0642604   0.0129399  -0.00363273
  0.0767758   -0.00846395   0.0317134    0.0982545    0.0560325   -0.00996287   0.0878376    0.0896351    0.0369872   -0.00573348  -0.0755425   -0.0535605   -0.0576445   -0.0658335   -0.00742896  -0.476668     0.0798235    -0.109796     0.180351     -0.14724     -0.0373119    0.112751    -0.0229994    -0.0236139  -0.148338    0.0951823 
  0.0240822    0.0381689    0.0226735    0.119696     0.0564786   -0.0125505    0.115508     0.0836287    0.0917597   -0.0169687   -0.0909735   -0.0473627   -0.011676    -0.0557308   -0.039587     0.446212     0.0356063    -0.063175     0.154098     -0.219105    -0.0836715    0.107773    -0.0199314    -0.0251433  -0.136399    0.11647   
  0.0361689   -0.901967     0.00308108   0.141276    -0.0927496   -0.0509782   -0.0825979    0.242586     0.0945354   -0.126263     0.0198129   -0.104697    -0.115611    -0.0192073    0.0237744    0.0145493    0.0175143     0.0631455    0.0360754     0.0244811   -0.151088     0.103902     0.118746      0.051501   -0.141727   -0.0232978 
  0.0351927    0.936806     0.0110347    0.146077     0.0695153   -0.0520867   -0.0579038    0.0486317    0.0759738   -0.119851    -0.042949    -0.144309    -0.0148491    0.0072742   -0.0202448    0.0164815   -0.140812      0.0156486    0.0749539     0.0174925   -0.147684     0.0963355    0.0954322     0.0512235  -0.131318   -0.0737015 
  0.0330145    0.0229239   -0.0921242   -0.00268063   0.159957     0.130903     0.226513    -0.0683141    0.159271     0.156881    -0.00628898  -0.0205385    0.0692532   -0.0060075   -0.065657    -0.119122    -0.0638496    -0.132324     0.0914367    -0.0970457   -0.0367668    0.17069      0.0203092     0.122803   -0.224371    0.0514125 
  0.190018    -0.00169564  -0.0196537    0.0777875    0.106784    -0.0297875    0.0379208    0.107579     0.0700332   -0.0290894    0.0167164   -0.106104    -0.0321738    0.0320657    0.0733746    0.0972475    0.0366086     0.00314869  -0.000774298  -0.100964     0.0618402    0.0421223   -0.0263643    -0.0286739  -0.0314546   0.0571229 
 -0.0231912   -0.117195    -0.137988     0.0957142   -0.0815655    0.104022     0.162797     0.00461484  -0.0879449    0.0830077   -0.11897      0.0828724    0.0884281   -0.0306689    0.0977002   -0.0388769    0.152585      0.0343323   -0.0297511     0.0383071   -0.141861    -0.104745    -0.230201     -0.0215893  -0.231189   -0.0499604 
  0.11268     -0.0315413    0.0222758    0.0221059   -0.112068    -0.0892818   -0.248118    -0.116198     0.14512      0.00105517  -0.0994262    0.117975    -0.0954679    0.0572505   -0.0810038   -0.0653803    0.0832206     0.0617642   -0.0954599     0.0124879    0.0437094    0.038033     0.00744691    0.0116746  -0.27577    -0.0567544 
  0.0570939   -0.09681      0.0566144    0.0625941    0.0325928    0.087593     0.00595856  -0.0648868   -0.0088021    0.0580773    0.0888894   -0.0218846    0.237927     0.140534     0.112689    -0.0440025    0.00208426   -0.138641    -0.0650409     0.300563     0.0895447   -0.215452    -0.102837      0.0572316  -0.0461732   0.130092  
  0.130701    -0.113292     0.0460461    0.114581    -0.0277175    0.0352997   -0.15699      0.0533226   -0.155737    -0.0285705    0.00316582   0.0764644   -0.0856905   -0.00756468  -0.0981258   -0.0991499   -0.0238952    -0.0651646    0.0979323    -0.17541      0.0091257   -0.0576788    0.0335091     0.0981096  -0.134471   -0.069034  
 -0.0216821    0.063159     0.0581399    0.030778    -0.0744702   -0.129271     0.0095443   -0.0548674    0.0132278   -0.0704434    0.0375249   -0.0327214   -0.0720356    0.115788    -0.104018    -0.00630408   0.0538333     0.0850274   -0.0151656     0.118741    -0.00233815  -0.00606196  -0.0485611     0.120953   -0.0448489   0.0990058 
  0.0438149   -0.0371547    0.0362044   -0.0767054    0.121335     0.0706805   -0.00770761   0.0619144    0.0133039    0.0891542   -0.00537075  -0.113976    -0.09445     -0.216049     0.0703978   -0.0109846   -0.073        -0.00830813   0.0721785    -0.163929    -0.029241     0.07477     -0.0389073     0.0464389   0.0795189   0.0912148 
 -0.0252593    0.00754632   0.0395422   -0.018848     0.0198267    0.0616022    0.0106922    0.0683418   -0.130397    -0.0847562   -0.130874     0.133513     0.0465674   -0.0235649   -0.0211117    0.10577     -0.13858       0.011172    -0.0398154     0.0880169   -0.180956    -0.0557286   -0.0279679    -0.203009    0.074349   -0.252462  
  0.107343    -0.0820001   -0.00220849   0.04235     -0.0053602    0.0894118    0.126027    -0.0337997    0.114489    -0.0880565    0.134296     0.0687209   -0.164748     0.0892839    0.0660339    0.113829     0.105482     -0.0817626   -0.0537557    -0.15818      0.0889888    0.0829186    0.0123104    -0.014283   -0.133549   -0.00347314[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.028300
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    16-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      6
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.992288
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      6
â”‚      â‹®
â”‚     23
â”‚     28
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.008646
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    15-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      9
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.005918
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.014404
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    18-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.987268
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     18
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.027778
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    16-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      6
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.993363
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      6
â”‚      â‹®
â”‚     23
â”‚     28
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.009061
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    15-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚      9
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
kind diag, method kmeans
[ Info: iteration 10, average log likelihood -1.005938
â”Œ Info: EM with 100000 data points 10 iterations avll -1.005938
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.659388e+05
      1       6.721769e+05      -1.937619e+05 |       32
      2       6.434457e+05      -2.873118e+04 |       32
      3       6.286070e+05      -1.483877e+04 |       32
      4       6.208780e+05      -7.728916e+03 |       32
      5       6.145347e+05      -6.343287e+03 |       32
      6       6.095952e+05      -4.939502e+03 |       32
      7       6.070867e+05      -2.508532e+03 |       32
      8       6.059907e+05      -1.096030e+03 |       32
      9       6.054190e+05      -5.716474e+02 |       32
     10       6.050130e+05      -4.060447e+02 |       32
     11       6.046487e+05      -3.642767e+02 |       32
     12       6.042512e+05      -3.975116e+02 |       32
     13       6.037409e+05      -5.103104e+02 |       32
     14       6.031056e+05      -6.353319e+02 |       32
     15       6.024268e+05      -6.787264e+02 |       32
     16       6.016643e+05      -7.625345e+02 |       32
     17       6.007420e+05      -9.223339e+02 |       32
     18       6.000048e+05      -7.371321e+02 |       32
     19       5.996576e+05      -3.472847e+02 |       32
     20       5.995056e+05      -1.519294e+02 |       32
     21       5.994228e+05      -8.277336e+01 |       32
     22       5.993571e+05      -6.571701e+01 |       32
     23       5.992928e+05      -6.436988e+01 |       31
     24       5.992318e+05      -6.100637e+01 |       32
     25       5.991758e+05      -5.598952e+01 |       32
     26       5.991295e+05      -4.621991e+01 |       32
     27       5.990983e+05      -3.125289e+01 |       31
     28       5.990674e+05      -3.088036e+01 |       31
     29       5.990476e+05      -1.980411e+01 |       30
     30       5.990354e+05      -1.221244e+01 |       29
     31       5.990263e+05      -9.095825e+00 |       27
     32       5.990192e+05      -7.119329e+00 |       25
     33       5.990138e+05      -5.423754e+00 |       27
     34       5.990090e+05      -4.780563e+00 |       30
     35       5.990052e+05      -3.825096e+00 |       27
     36       5.990029e+05      -2.256083e+00 |       20
     37       5.990014e+05      -1.452923e+00 |       18
     38       5.990001e+05      -1.363935e+00 |       20
     39       5.989990e+05      -1.066223e+00 |       18
     40       5.989984e+05      -6.089765e-01 |       10
     41       5.989977e+05      -6.685107e-01 |       13
     42       5.989972e+05      -5.433868e-01 |       13
     43       5.989967e+05      -5.217547e-01 |       11
     44       5.989962e+05      -4.563940e-01 |       12
     45       5.989958e+05      -4.299124e-01 |       10
     46       5.989955e+05      -2.438470e-01 |       12
     47       5.989952e+05      -2.892410e-01 |        8
     48       5.989950e+05      -2.529419e-01 |        7
     49       5.989947e+05      -2.894081e-01 |       12
     50       5.989943e+05      -4.173709e-01 |        5
K-means terminated without convergence after 50 iterations (objv = 598994.2899053271)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.311321
[ Info: iteration 2, average log likelihood -1.275452
[ Info: iteration 3, average log likelihood -1.239108
[ Info: iteration 4, average log likelihood -1.193802
[ Info: iteration 5, average log likelihood -1.125717
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      7
â”‚     12
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.053621
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      8
â”‚     16
â”‚     25
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.100499
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      6
â”‚      9
â”‚     13
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.074194
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      7
â”‚     14
â”‚     17
â”‚     20
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.035107
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      4
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.094934
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      8
â”‚     12
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.057132
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚      6
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.039504
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚      9
â”‚     13
â”‚     14
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.020727
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚     12
â”‚     16
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.049205
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.089962
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     15
â”‚     25
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.054304
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     14
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.059584
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      2
â”‚      8
â”‚     13
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.035761
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      6
â”‚      9
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.040922
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      4
â”‚      5
â”‚      7
â”‚     15
â”‚     18
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.032338
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     14
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.065604
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      8
â”‚     20
â”‚     25
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.066774
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      6
â”‚     12
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.053369
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      5
â”‚      7
â”‚      9
â”‚     14
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.016216
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     16
â”‚     19
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.085344
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      8
â”‚     18
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.072384
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     12
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.041235
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      5
â”‚      7
â”‚     13
â”‚     14
â”‚     15
â”‚     22
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.017491
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     6
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.083300
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      2
â”‚      8
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.056764
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     12
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.075201
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      4
â”‚      5
â”‚     14
â”‚     15
â”‚     25
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.011406
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      6
â”‚      7
â”‚      8
â”‚      9
â”‚     13
â”‚     16
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.038577
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     12
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.110225
[ Info: iteration 35, average log likelihood -1.089963
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      5
â”‚     14
â”‚     15
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.004133
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      6
â”‚      7
â”‚      8
â”‚     18
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.059502
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      9
â”‚     12
â”‚     13
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.077751
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.069699
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚      5
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.033904
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     14
â”‚     22
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.027929
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      2
â”‚     12
â”‚     20
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.068416
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.075242
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     15
â”‚     16
â”‚     18
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.001698
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      6
â”‚      8
â”‚     14
â”‚     22
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.032655
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     12
â”‚     13
â”‚     20
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.104104
[ Info: iteration 47, average log likelihood -1.078031
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      5
â”‚      7
â”‚      9
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -0.997048
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      8
â”‚     14
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.051470
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     12
â”‚     13
â”‚     16
â”‚     18
â”‚     20
â”‚     22
â”‚     25
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.048175
32Ã—26 Array{Float64,2}:
â”Œ Info: EM with 100000 data points 50 iterations avll -1.048175
â”” 59.0 data points per parameter
  0.150095     -0.204184     0.207786      0.281055   -0.174797    -0.109739     0.09139      -0.110661      0.111115     0.06748     0.0788227    0.0264828   -0.0443012   -0.157614     0.0911147     0.145878    -0.101195     0.0411109    0.080284      0.0838836    0.116088    -0.0718941    0.0309307    -0.189044     0.0872148   -0.148083   
  0.0608669    -0.103061     0.0550284     0.0738271   0.0253839    0.0897998   -0.00936022   -0.0664995    -0.0218586    0.0355263   0.0802069   -0.0090999    0.216328     0.135192     0.101855     -0.051939     0.0023729   -0.125278    -0.0421971     0.29283      0.088238    -0.204598    -0.0905393     0.0561872   -0.0495345    0.112535   
  0.189357     -0.00159693  -0.0198247     0.0777527   0.106195    -0.0291981    0.0379112     0.107584      0.0702067   -0.03031     0.017458    -0.10648     -0.0322112    0.0322886    0.0713269     0.097366     0.0365232    0.00321535  -0.000159741  -0.100829     0.0617714    0.0421924   -0.0266832    -0.0283623   -0.0300954    0.0569186  
  0.13693      -0.0942735    0.0354646     0.081551   -0.0309287   -0.00793479  -0.208614      0.0284265    -0.14275     -0.0357574  -0.00746451   0.0682242   -0.0510886   -0.0116437   -0.152122     -0.0811198   -0.011941    -0.0735278    0.0693162    -0.233945     0.0298304   -0.0585995    0.0166054     0.0384319   -0.10795     -0.0475857  
  0.241851      0.0867746    0.111646      0.187047   -0.0364954   -0.151139    -0.0188016     0.358604     -0.117569    -0.0784316   0.0377036   -0.0512018    0.0561195   -0.157448    -0.201321     -0.10842     -0.0466032   -0.123256     0.0226045     0.044206     0.17672     -0.0363193   -0.108456     -0.0685483   -0.0568194    0.000173669
  0.0325832     0.0239223   -0.0784848     0.0242496   0.139496     0.0789139    0.175944     -0.0549983     0.158109     0.08811     0.00538206  -0.0378588    0.0554495    0.00210198  -0.026441     -0.100012    -0.0641479   -0.115607     0.0811051    -0.0851269   -0.0524613    0.164274     0.0353782     0.106724    -0.188242     0.0548498  
 -0.000794051  -0.0115195   -0.150797     -0.09661     0.0225777   -0.123195    -0.00186832    0.092568      0.103739    -0.103403    0.0307463    0.0997657   -0.0109019    0.0568155    0.0631404     0.00012912   0.00593281  -0.1334       0.0113334    -0.0014236   -0.135686     0.11825      0.016799      0.0494353    0.124326     0.153568   
  0.125216      0.0836335   -0.0364507    -0.0238811  -0.167069    -0.175623     0.20509       0.0243785    -0.309399    -0.0412452  -0.0578466   -0.0627573    0.0672329    0.154491    -0.0355542    -0.102914    -0.0284835   -0.135887    -0.160003     -0.0278225    0.0850079    0.121667     0.0787525     0.244096    -0.0585218    0.0233024  
  0.0488707     0.060413     0.0240297     0.149226   -0.00304886  -0.0533921   -0.0994137     0.196271      0.0506833   -0.126139   -0.0203264   -0.134955    -0.0955793   -0.0240228   -0.000881732   0.0214435   -0.0480478    0.0641652    0.0414639     0.0396835   -0.144079     0.0860384    0.112552      0.0472832   -0.151174    -0.0607455  
  0.0013923     0.240411     0.0314253     0.0403443  -0.0549093    0.0452294   -0.0116643     0.00589952    0.0420699   -0.0108382  -0.0748962    0.00341918  -0.19051      0.0694923    0.0373375    -0.17026      0.0533664   -0.0657473    0.0219512     0.149367    -0.093686    -0.00333439   0.000248854   0.00667457   0.00937561   0.00558012 
  0.0536601    -0.0723762   -0.0028735     0.0962209  -0.00130161  -0.221463    -0.0711396    -0.166292     -0.11777     -0.078612    0.0371554   -0.114847     0.00972644   0.171044    -0.0424894     0.111754     0.14748      0.130159    -0.0789143    -0.0748605    0.0573394   -0.0168232   -0.103792     -0.00796822   0.0188247    0.00695485 
  0.0994788    -0.101752     0.000138157   0.0419485  -0.0056839    0.0706196    0.101646     -0.00212734    0.112911    -0.0875379   0.222656     0.0763714   -0.164422     0.0853903    0.0923575     0.11065      0.114844    -0.088187    -0.0601127    -0.25728      0.0858045    0.094123     0.00835226   -0.0159499   -0.127673    -0.0549219  
  0.115682     -0.0322103   -0.000896162   0.0359159  -0.00434411   0.134255     0.16429      -0.0869029     0.101315    -0.0965242  -0.11752      0.0607682   -0.163558     0.0755158   -0.0246659     0.107444     0.0539129   -0.0529926   -0.0415617     0.0927537    0.0635528    0.0244236    0.0183582    -0.0351135   -0.121081     0.105756   
  0.0679625     0.119836    -0.0663751     0.151883   -0.108316    -0.0790306   -0.0449756    -0.0504583     0.0566991    0.0546292  -0.191156     0.187955    -0.0181661   -0.154621    -0.018053     -0.114058    -0.0397386   -0.140584    -0.028941      0.0302038   -0.106727     0.121327    -0.0665052    -0.115196     0.100181    -0.0786517  
  0.132048      0.0855181   -0.0922071     0.232386    0.0706321    0.122605    -0.0266917     0.068638     -0.31288      0.0571694   0.149276    -0.0592352   -0.0687743   -0.139277     0.132561     -0.0276642    0.15265     -0.10706     -0.0222452    -0.00521444   0.02291     -0.0239482    0.0843242    -0.0445468   -0.13735      0.0962265  
  0.130937     -0.0352171   -0.0556968    -0.0870723  -0.00109525   0.0972015    0.178423     -0.0100839    -0.0173349   -0.127235   -0.104614    -0.0571999   -0.0487707   -0.00300997  -0.0573225     0.116831    -0.0872703    0.0912347   -0.0985605     0.0824073   -0.0494604    0.0822715    0.0122183    -0.034715    -0.00845931   0.128702   
  0.0801345     0.0648099   -0.163387      0.114707   -0.0475045    0.05424      0.0478275     0.0159957     0.0212065    0.0663468  -0.0479984    0.0204732   -0.0139165   -0.144935     0.104825      0.0535745   -0.0308649   -0.0569021   -0.0490225    -0.125661     0.160178     0.027517    -0.0657447    -0.0503754    0.0342971    0.0115302  
  0.0968959    -0.127311    -0.0266183    -0.124468   -0.0283761   -0.00988625  -0.246525     -0.0216164    -0.133006    -0.195168   -0.25589      0.0324227    0.0885289    0.066131    -0.146451     -0.0119917   -0.0403278    0.159726     0.00284353   -0.0739815   -0.0239623   -0.110109    -0.0688517     0.179723     0.200379    -0.00718979 
 -0.116456      0.261314    -0.00811886   -0.219441    0.0252305    0.131724    -0.0458783     0.0100057    -0.0348289    0.0140583  -0.0624773    0.174456     0.0356827   -0.131195    -0.0281859    -0.0389943   -0.0452834    0.122306    -0.158797      0.310926    -0.0216502   -0.0996506   -0.0189689    -0.0381451    0.198295     0.135353   
 -0.0119047    -0.0143526    0.0403544    -0.022662    0.0552169    0.0613687   -0.00289274    0.0580222    -0.0843885   -0.0734604  -0.147735     0.144389     0.00851005  -0.00841235  -0.00105046    0.085883    -0.152243     0.0237173   -0.0402715     0.0789813   -0.197159    -0.0412321   -0.0151721    -0.213125     0.085197    -0.212477   
  0.0364476    -0.0592888   -0.118854      0.0159144  -0.0471995   -0.120627     0.127128      0.0738073     0.0557623   -0.13283    -0.19511     -0.00685028   0.0853154    0.130963     0.0565947     0.0860097    0.024838     0.042598    -0.0519598     0.131652     0.316173     0.126846    -0.177363     -0.0215375   -0.212083     0.0509374  
  0.0660192    -0.0690662   -0.0599349     0.0291917  -0.106421     0.0550831    0.0507333     0.000420526  -0.00393668   0.0525084   0.0835877    0.0404307   -0.00666393  -0.131723    -0.0423004    -0.0802125    0.128552    -0.0490773   -0.0267938     0.0521797    0.0731879    0.137595     0.222058     -0.0628543    0.0105872   -0.00503395 
 -0.0718936     0.174325     0.0383001     0.0607355   0.059445     0.103792    -0.0277642     0.0790827    -0.0404648   -0.0669229   0.0652896    0.0546589    0.098744    -0.0864597   -0.0460218    -0.121198    -0.0108715   -0.0690254   -0.00824369   -0.0622544   -0.24642     -0.055997     0.071983      0.124614     0.0286399    0.0428866  
  0.0678235     0.00455766   0.0245332     0.0783004  -0.0710385    0.00823643  -0.0607362     0.0619187    -0.0745059   -0.0524617  -0.0255291    0.115352    -0.0871738    0.0604897    0.168061     -0.0488384    0.118053     0.0119024    0.142916      0.14978      0.153937    -0.0135547    0.0389722     0.0682964   -0.113786    -0.00740168 
  0.0565976     0.00969712   0.0245268     0.115505    0.0595216   -0.0164965    0.100612      0.0955348     0.0657368   -0.0100121  -0.0802254   -0.0560148   -0.0333818   -0.062873    -0.0305613    -0.104674     0.0714424   -0.0938418    0.189522     -0.182451    -0.0505666    0.11726     -0.0223622    -0.0191495   -0.152143     0.113631   
  0.0935884    -0.0980505    0.0914719     0.148459    0.0164349    0.0423463   -0.0554521    -0.149818     -0.0585344   -0.0682967  -0.0882464    0.0474584   -0.0448195   -0.035624    -0.104194     -0.030436     0.0802847   -0.130403     0.00395357    0.0467195    0.161072     0.213917     0.189608     -0.0934795   -0.212962     0.0689394  
 -0.0218998     0.0619102    0.0599886     0.0307852  -0.0809411   -0.129471     0.00987479   -0.053596      0.0141957   -0.0701113   0.0390033   -0.03479     -0.0727036    0.116649    -0.105313     -0.00729666   0.0557215    0.084878    -0.0187954     0.120603    -0.00528283  -0.00614606  -0.0485682     0.122774    -0.0446418    0.100005   
  0.0527429    -0.0361822    0.0367825    -0.0825039   0.128943     0.0638125   -0.0104612     0.0679509     0.0235097    0.0930418   0.0159686   -0.135112    -0.0941159   -0.221167     0.0759353    -0.02155     -0.0668592   -0.0140637    0.0777773    -0.189182    -0.017067     0.0803041   -0.0477518     0.0647715    0.0794691    0.0907955  
  0.0567803     6.77518e-5   0.0638189    -0.15205    -0.211646     0.128778    -0.000801683   0.00180538    0.0629531    0.0470651  -0.00316249  -0.0464669    0.101573     0.0764123   -0.0614617    -0.0316717   -0.110082    -0.164209    -0.110989      0.00309059  -0.218381    -0.074031    -0.163123     -0.213514     0.177514    -0.116298   
  0.0477884    -0.0775982   -0.0536892     0.0504148  -0.0948794    0.0045709   -0.0405084    -0.0560005     0.0316141    0.0456795  -0.111168     0.0962884   -0.00223227   0.0174016    0.00582443   -0.0489213    0.111955     0.0564245   -0.0649564     0.0268366   -0.0553039   -0.0330353   -0.106741     -0.00178995  -0.251896    -0.046621   
 -0.0707634     0.327091     0.13034      -0.214808    0.00100206   0.0627563    0.0290452    -0.156275     -0.0394893    0.0551665  -0.192609    -0.081573    -0.137739     0.0502249   -0.131913      0.136357    -0.01658      0.00178864  -0.157546      0.0711751   -0.0360335   -0.00366672  -0.0616816    -0.126609     0.0685849   -0.203122   
  0.0242897    -0.04915     -0.0838614     0.0930376   0.0379814   -0.0061172    0.0200121    -0.0207658     0.0324469   -0.0953925  -0.00619393   0.116069     0.0251802    0.0261285    0.00106837    0.123003    -0.00683788   0.0708167    0.0885867     0.0100948   -0.131943    -0.0616416   -0.0652032    -0.0253325    0.109002     0.103841   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     2
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.082717
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚      7
â”‚      9
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.013387
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      6
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.006355
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚      7
â”‚      â‹®
â”‚     15
â”‚     19
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.985254
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      6
â”‚     13
â”‚     14
â”‚     16
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.999760
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚      7
â”‚      â‹®
â”‚     12
â”‚     15
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.992516
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      6
â”‚     14
â”‚     18
â”‚     19
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.017923
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚      7
â”‚      8
â”‚      9
â”‚     15
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.001929
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      6
â”‚     12
â”‚     13
â”‚     14
â”‚     20
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.988472
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚      7
â”‚      9
â”‚     15
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.008057
â”Œ Info: EM with 100000 data points 10 iterations avll -1.008057
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.149399     -0.0687997    0.0177575   -0.0268374    0.204698      0.0575466    0.106483    -0.0261032   0.140884     0.119377    -0.00436536  -0.0980364    0.0140829  -0.204443     0.0221329    0.0799698   -0.0898713     0.086438    -0.115516     -0.0465774   -0.0354482   -0.0689668  -0.0344108    -0.00823547  -0.0902043     0.181812 
  0.010028      0.118964    -0.0267239    0.257562    -0.0306598    -0.130487    -0.0536159   -0.0275305   0.237373    -0.144835     0.0249354   -0.111323     0.15553     0.215585     0.131998    -0.0425578   -0.103258      0.0641425    0.0818994     0.0510624   -0.186717     0.10466     0.126883      0.109932    -0.0688624     0.0761298
 -0.270416     -0.0453649    0.233401     0.189123     0.013654      0.0722127   -0.120467     0.092729   -0.00529524  -0.100681     0.0188985    0.0706538    0.0307871   0.113388     0.0866556   -0.156748    -0.0850804    -0.0129608   -0.0812516    -0.0370557   -0.0257052   -0.0522458  -0.143578      0.0731442    0.0186525     0.0536842
 -0.157544     -0.024634    -0.0115215   -0.00471424   0.0526247     0.102069    -0.046342    -0.0811209  -0.12153      0.290145    -0.0670634   -0.0478204    0.0849693   0.173543    -0.0598902    0.150809     0.0209883     0.183984    -0.0786948    -0.0115718   -0.0990105   -0.0308564  -0.0223425     0.150753    -0.169213     -0.109108 
  0.0822398    -0.264508    -0.129663    -0.0526107   -0.227627      0.119823     0.106531     0.144028   -0.0946211   -0.0564761   -0.0404153   -0.0767451   -0.0681597  -0.134686     0.053437     0.123983    -0.0624933    -0.0395833   -0.0567811     0.0635267   -0.111018    -0.10647     0.0252481    -0.0149525   -0.115861      0.014424 
  0.15464      -0.0525372    0.0468458   -0.00915909   0.169064      0.10913     -0.0228864    0.15359    -0.0267607   -0.0614663   -0.0806555   -0.118868    -0.0389485   0.0801762    0.222803    -0.0401317    0.0188476     0.068457     0.0335162     0.0166577    0.0891412   -0.17876     0.0541701     0.0823415    0.0326482     0.161562 
 -0.178886     -0.0460722    0.0237924   -0.225979    -0.173251      0.0902008   -0.0638038   -0.0960031  -0.163833     0.142067     0.0318566    0.138955    -0.0680222  -0.12166     -0.111722     0.0799462    0.00197437    0.0367348    0.054204     -0.135218     0.0739504    0.108728   -0.138678      0.182578     0.0413688    -0.163856 
  0.0420824     0.0574729   -0.185236     0.12918     -0.0344468     0.0423566    0.027049     0.0259381  -0.0785364    0.00416414   0.0595908   -0.05016      0.0389437   0.0453527    0.0813718   -0.00323162   0.0805476    -0.0443481    0.0428145    -0.0114527    0.022493     0.0354762   0.0451905     0.0638742   -0.123267     -0.108861 
 -0.171635      0.0153596   -0.0159237   -0.0383276    0.085522     -0.118486    -0.0788116   -0.10485     0.131405    -0.0380891    8.13711e-6  -0.206506     0.0588319  -0.0174291   -0.01189      0.0183534    0.125619      0.0335014    0.0232428     0.162401    -0.0402218    0.142406   -0.0735147    -0.0114926    0.0328382     0.0435095
 -0.0303358     0.0470077   -0.0365879    0.130324     0.103944      0.0890493    0.120943    -0.121189   -0.13208      0.257815     0.0653163   -0.122203    -0.012252    0.032414     0.00673958  -0.187401    -0.0127559     0.13879     -0.14657      -0.0374361    0.0392007   -0.047094    0.000258969  -0.15832     -0.0988925     0.0145947
  0.274672      0.0697485    0.0194281   -0.122224    -0.143807     -0.00626012  -0.0574173   -0.083978   -0.118123     0.104938     0.0481483   -0.133112     0.0396754  -0.00488377  -0.0740376   -0.0417369    0.113233     -0.256017     0.137059     -0.0777505    0.0757974   -0.141456    0.0240885     0.115415    -0.0367373    -0.0691931
  0.0484724     0.0117225    0.0392703    0.0631017    0.11227       0.0910772   -0.127101     0.131974    0.0681886   -0.0460892   -0.047497    -0.0171902   -0.0422948  -0.0461778   -0.135184     0.0165309   -0.038611      0.0222968   -0.0193402    -0.0765487    0.105935    -0.0208786   0.158824      0.121337    -0.00208139   -0.18996  
  0.167506     -0.0455017   -0.189383     0.13927     -0.00479831    0.0141895   -0.0826385    0.0913537  -0.136509    -0.195987    -0.169291    -0.23934     -0.118349    0.125555    -0.0186125   -0.0171514   -0.0543014    -0.235367     0.0500363     0.0699523    0.201179     0.0712068   0.0752442     0.0399173    0.145766      0.107998 
  0.000823072   0.00859263  -0.0595685   -0.372362     0.151961     -0.0414022    0.0556164    0.0687871  -0.123295     0.00322855   0.153542    -0.0555109   -0.0696782   0.0128356    0.11171      0.0392076   -0.0189733    -0.0470489    0.0215828     0.00753306  -0.0831662    0.0281461   0.055245      0.0563782   -0.0718263     0.0415971
 -0.137899     -0.0641802    0.0755698   -0.0795199   -0.0589516     0.0985363   -0.143726    -0.025489    0.0517869    0.0631549   -0.0701373    0.0638412   -0.0187142  -0.0398865   -0.0397639   -0.0855059    0.0295404     0.00821746   0.0626905    -0.0444779   -0.0618449   -0.0147351  -0.0677682     0.0519886   -0.181666      0.025165 
  0.0016797     0.0227372   -0.170243     0.0246667   -0.138736      0.0695812   -0.0934616    0.0379168  -0.030743    -0.102895    -0.102483     0.0567312    0.0135245   0.101301     0.0100375    0.0596821    0.0402855    -0.158228    -0.000440167  -0.00601917  -0.118656    -0.120435    0.0601856    -0.00597826   0.10215       0.0789659
  0.026267      0.038165    -0.0590492   -0.132765     0.122679     -0.099357    -0.0112859    0.0309083   0.0446307   -0.0535931    0.02468     -0.100439    -0.161183    0.0992504   -0.0883752   -0.117862    -0.0434881    -0.0491031    0.028913     -0.0455517    0.111597     0.0875654   0.118156     -0.0296802    0.0370536    -0.101018 
  0.112212      0.00944234  -0.0949308   -0.0988137   -0.0524964     0.0406176    0.0193398   -0.0812965  -0.0311335    0.0440661    0.123648    -0.121271    -0.0255041   0.137144    -0.124875    -0.0980163    0.000186574   0.0154024   -0.00755071   -0.0120959    0.0499093    0.141376    0.0537148     0.264192    -0.00500382   -0.0339312
  0.134525     -0.149133     0.158643    -0.0231695   -0.0409196     0.184048     0.0472252    0.0761488  -0.0118051   -0.124381    -0.0641653   -0.00206063   0.0109334   0.113264    -0.00355091  -0.133512    -0.0698369    -0.0348345   -0.00947074   -0.0264657    0.00482261  -0.15366     0.0176921     0.0342663    0.000795612  -0.121301 
 -0.120111      0.0219604   -0.0600885    0.0849298   -0.0337293    -0.0299881   -0.106317    -0.082932   -0.0170112   -0.0162008    0.0870832    0.162772    -0.223867   -0.0879888    0.0691624   -0.00745094  -0.163382     -0.0303538    0.012447      0.150915    -0.0266686   -0.213106   -0.158996     -0.0967395   -0.00804117   -0.0435494
  0.0538129     0.00486366  -0.0669849   -0.138561    -0.0925028    -0.0498667   -0.0873576    0.0416493   0.189251    -0.00295621  -0.0559826    0.0791426    0.0130357  -0.156302    -0.0344988    0.0582902    0.0429744     0.0832439    0.070294     -0.0282952    0.16016      0.0605176  -0.00884526    0.0159672   -0.103137     -0.0613448
 -0.0205787    -0.0272981    0.13438      0.0326341   -0.124505      0.178678    -0.0473556   -0.273987    0.159809    -0.118025    -0.0868919   -0.101041     0.0673891  -0.30474     -0.0275296    0.0363937   -0.0398355     0.101884    -0.0109957     0.0477106   -0.0529726    0.039291    0.0950576     0.110744     0.0667225    -0.226015 
 -0.021649      0.137863    -0.0550568   -0.0603231    0.13118      -0.0704908    0.17146     -0.0468014  -0.0548486    0.0079859    0.0178355   -0.0353912    0.169183   -0.0261847    0.0819738   -0.0832975    0.16989       0.0307258   -0.0393202    -0.169832    -0.0972828   -0.0972475   0.11949       0.0249152    0.0331615    -0.0944022
 -0.0510969     0.0244337   -0.0901901    0.148894     0.108085     -0.152205    -0.15034     -0.226137   -0.0576952   -0.296868    -0.062781     0.0410543    0.136996    0.134131    -0.0947854    0.073769     0.0305689    -0.00835925   0.0312518     0.167368     0.00614939  -0.0768872  -0.116816     -0.0658332    0.0139262    -0.0570663
 -0.0960871     0.100143     0.127152    -0.00989745   0.0731218     0.132491     0.017911    -0.0723774   0.00255226  -0.0670823   -0.00864322   0.0490654    0.214582   -0.0239976    0.121486     0.0942211    0.0515603     0.0782217   -0.0179504     0.0980351   -0.0925474    0.171262   -0.0438781    -0.0456915   -0.00133429   -0.0546869
 -0.0663519     0.0265006    0.00833483  -0.127988     0.0731195     0.0932243   -0.117736    -0.0897764   0.0224       0.0763754    0.00428372   0.12138     -0.145404   -0.0228297   -0.126132     0.0210326    0.199496      0.221717    -0.0580564     0.0492876    0.0284957    0.0517155  -0.0926752    -0.054027    -0.0769421    -0.124369 
  0.156155     -0.0351177    0.0363904    0.02289     -0.0288123     0.194921    -0.0178911    0.0989316   0.207518    -0.0611591    0.141807    -0.0279218    0.222438   -0.124092     0.0414784    0.141116     0.0127938     0.109174     0.132012     -0.108612    -0.100241     0.102928    0.117952      0.0143389   -0.0459057     0.014066 
  0.0867218    -0.0280456   -0.0051113    0.00952651   0.0740988    -0.00980151   0.112853    -0.107696   -0.0578192    0.205807    -0.103135    -0.0348412   -0.0406497  -0.160817     0.0928754    0.0271058   -0.0310886     0.0615672    0.0150618    -0.112923     0.112866     0.079118   -0.113175     -0.0918278    0.0450269     0.100742 
  0.0594049    -0.0928254   -0.0529093   -0.0559811    0.192114      0.102808     0.00864515  -0.115237   -0.0720302    0.00681191   0.00274561   0.00323055   0.241111   -0.171282    -0.0379455    0.137473     0.114206     -0.0451994   -0.0630385    -0.0726611    0.128997     0.0386718   0.0111976     0.057714    -0.00827066   -0.0340977
  0.0252234     0.0930289   -0.0663258   -0.248355     0.0638361     0.0904837   -0.00589649  -0.0187464   0.146225    -0.130484     0.145501     0.164134     0.0662003  -0.0693718    0.20575     -0.112698     0.0266877    -0.0902603   -0.0622145    -0.0918128   -0.173187    -0.0132523   0.136056     -0.0672891    0.0388713     0.0221049
  0.131557     -0.0755559   -0.140566    -0.101092    -0.0483414     0.038218    -0.14474     -0.113798    0.0171925    0.0148166    0.0512825   -0.046793    -0.03093     0.0479845   -0.0211438   -0.0202684   -0.0408047    -0.010034     0.0891852    -0.133146    -0.0190416   -0.150629    0.187829      0.109476     0.0659141     0.0394599
  0.0441983    -0.0382996    0.0498135    0.105247    -0.000429134  -0.0204557   -0.0964568   -0.13069     0.0626545    0.157973     0.218956     0.15988      0.172724   -0.0856242   -6.91795e-5   0.130139    -0.108569     -0.047613    -0.00116805   -0.121384    -0.0628684    0.094656    0.182976     -0.226108     0.129674     -0.0556482kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4161187160101802
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416137
[ Info: iteration 2, average log likelihood -1.416067
[ Info: iteration 3, average log likelihood -1.416009
[ Info: iteration 4, average log likelihood -1.415934
[ Info: iteration 5, average log likelihood -1.415835
[ Info: iteration 6, average log likelihood -1.415707
[ Info: iteration 7, average log likelihood -1.415550
[ Info: iteration 8, average log likelihood -1.415363
[ Info: iteration 9, average log likelihood -1.415127
[ Info: iteration 10, average log likelihood -1.414793
[ Info: iteration 11, average log likelihood -1.414282
[ Info: iteration 12, average log likelihood -1.413539
[ Info: iteration 13, average log likelihood -1.412641
[ Info: iteration 14, average log likelihood -1.411816
[ Info: iteration 15, average log likelihood -1.411251
[ Info: iteration 16, average log likelihood -1.410942
[ Info: iteration 17, average log likelihood -1.410793
[ Info: iteration 18, average log likelihood -1.410724
[ Info: iteration 19, average log likelihood -1.410693
[ Info: iteration 20, average log likelihood -1.410678
[ Info: iteration 21, average log likelihood -1.410672
[ Info: iteration 22, average log likelihood -1.410668
[ Info: iteration 23, average log likelihood -1.410666
[ Info: iteration 24, average log likelihood -1.410665
[ Info: iteration 25, average log likelihood -1.410665
[ Info: iteration 26, average log likelihood -1.410664
[ Info: iteration 27, average log likelihood -1.410664
[ Info: iteration 28, average log likelihood -1.410663
[ Info: iteration 29, average log likelihood -1.410663
[ Info: iteration 30, average log likelihood -1.410663
[ Info: iteration 31, average log likelihood -1.410663
[ Info: iteration 32, average log likelihood -1.410662
[ Info: iteration 33, average log likelihood -1.410662
[ Info: iteration 34, average log likelihood -1.410662
[ Info: iteration 35, average log likelihood -1.410662
[ Info: iteration 36, average log likelihood -1.410662
[ Info: iteration 37, average log likelihood -1.410662
[ Info: iteration 38, average log likelihood -1.410662
[ Info: iteration 39, average log likelihood -1.410661
[ Info: iteration 40, average log likelihood -1.410661
[ Info: iteration 41, average log likelihood -1.410661
[ Info: iteration 42, average log likelihood -1.410661
[ Info: iteration 43, average log likelihood -1.410661
[ Info: iteration 44, average log likelihood -1.410661
[ Info: iteration 45, average log likelihood -1.410661
[ Info: iteration 46, average log likelihood -1.410661
[ Info: iteration 47, average log likelihood -1.410661
[ Info: iteration 48, average log likelihood -1.410661
[ Info: iteration 49, average log likelihood -1.410661
[ Info: iteration 50, average log likelihood -1.410661
â”Œ Info: EM with 100000 data points 50 iterations avll -1.410661
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4161368842803514
â”‚     -1.4160670509983977
â”‚      â‹®                 
â””     -1.4106608982028113
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410676
[ Info: iteration 2, average log likelihood -1.410615
[ Info: iteration 3, average log likelihood -1.410567
[ Info: iteration 4, average log likelihood -1.410513
[ Info: iteration 5, average log likelihood -1.410445
[ Info: iteration 6, average log likelihood -1.410362
[ Info: iteration 7, average log likelihood -1.410261
[ Info: iteration 8, average log likelihood -1.410145
[ Info: iteration 9, average log likelihood -1.410022
[ Info: iteration 10, average log likelihood -1.409901
[ Info: iteration 11, average log likelihood -1.409794
[ Info: iteration 12, average log likelihood -1.409708
[ Info: iteration 13, average log likelihood -1.409643
[ Info: iteration 14, average log likelihood -1.409597
[ Info: iteration 15, average log likelihood -1.409565
[ Info: iteration 16, average log likelihood -1.409541
[ Info: iteration 17, average log likelihood -1.409522
[ Info: iteration 18, average log likelihood -1.409507
[ Info: iteration 19, average log likelihood -1.409494
[ Info: iteration 20, average log likelihood -1.409483
[ Info: iteration 21, average log likelihood -1.409473
[ Info: iteration 22, average log likelihood -1.409465
[ Info: iteration 23, average log likelihood -1.409458
[ Info: iteration 24, average log likelihood -1.409451
[ Info: iteration 25, average log likelihood -1.409446
[ Info: iteration 26, average log likelihood -1.409441
[ Info: iteration 27, average log likelihood -1.409436
[ Info: iteration 28, average log likelihood -1.409432
[ Info: iteration 29, average log likelihood -1.409428
[ Info: iteration 30, average log likelihood -1.409425
[ Info: iteration 31, average log likelihood -1.409422
[ Info: iteration 32, average log likelihood -1.409419
[ Info: iteration 33, average log likelihood -1.409416
[ Info: iteration 34, average log likelihood -1.409413
[ Info: iteration 35, average log likelihood -1.409410
[ Info: iteration 36, average log likelihood -1.409408
[ Info: iteration 37, average log likelihood -1.409405
[ Info: iteration 38, average log likelihood -1.409403
[ Info: iteration 39, average log likelihood -1.409400
[ Info: iteration 40, average log likelihood -1.409397
[ Info: iteration 41, average log likelihood -1.409395
[ Info: iteration 42, average log likelihood -1.409392
[ Info: iteration 43, average log likelihood -1.409389
[ Info: iteration 44, average log likelihood -1.409386
[ Info: iteration 45, average log likelihood -1.409384
[ Info: iteration 46, average log likelihood -1.409381
[ Info: iteration 47, average log likelihood -1.409378
[ Info: iteration 48, average log likelihood -1.409375
[ Info: iteration 49, average log likelihood -1.409372
[ Info: iteration 50, average log likelihood -1.409369
â”Œ Info: EM with 100000 data points 50 iterations avll -1.409369
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4106759481645847
â”‚     -1.410614829191851 
â”‚      â‹®                 
â””     -1.4093685406924783
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409377
[ Info: iteration 2, average log likelihood -1.409314
[ Info: iteration 3, average log likelihood -1.409258
[ Info: iteration 4, average log likelihood -1.409192
[ Info: iteration 5, average log likelihood -1.409108
[ Info: iteration 6, average log likelihood -1.409005
[ Info: iteration 7, average log likelihood -1.408888
[ Info: iteration 8, average log likelihood -1.408765
[ Info: iteration 9, average log likelihood -1.408648
[ Info: iteration 10, average log likelihood -1.408545
[ Info: iteration 11, average log likelihood -1.408457
[ Info: iteration 12, average log likelihood -1.408383
[ Info: iteration 13, average log likelihood -1.408320
[ Info: iteration 14, average log likelihood -1.408266
[ Info: iteration 15, average log likelihood -1.408219
[ Info: iteration 16, average log likelihood -1.408179
[ Info: iteration 17, average log likelihood -1.408144
[ Info: iteration 18, average log likelihood -1.408114
[ Info: iteration 19, average log likelihood -1.408087
[ Info: iteration 20, average log likelihood -1.408063
[ Info: iteration 21, average log likelihood -1.408042
[ Info: iteration 22, average log likelihood -1.408023
[ Info: iteration 23, average log likelihood -1.408006
[ Info: iteration 24, average log likelihood -1.407990
[ Info: iteration 25, average log likelihood -1.407975
[ Info: iteration 26, average log likelihood -1.407960
[ Info: iteration 27, average log likelihood -1.407947
[ Info: iteration 28, average log likelihood -1.407935
[ Info: iteration 29, average log likelihood -1.407923
[ Info: iteration 30, average log likelihood -1.407912
[ Info: iteration 31, average log likelihood -1.407902
[ Info: iteration 32, average log likelihood -1.407892
[ Info: iteration 33, average log likelihood -1.407882
[ Info: iteration 34, average log likelihood -1.407873
[ Info: iteration 35, average log likelihood -1.407865
[ Info: iteration 36, average log likelihood -1.407857
[ Info: iteration 37, average log likelihood -1.407849
[ Info: iteration 38, average log likelihood -1.407842
[ Info: iteration 39, average log likelihood -1.407834
[ Info: iteration 40, average log likelihood -1.407828
[ Info: iteration 41, average log likelihood -1.407821
[ Info: iteration 42, average log likelihood -1.407815
[ Info: iteration 43, average log likelihood -1.407809
[ Info: iteration 44, average log likelihood -1.407803
[ Info: iteration 45, average log likelihood -1.407797
[ Info: iteration 46, average log likelihood -1.407792
[ Info: iteration 47, average log likelihood -1.407787
[ Info: iteration 48, average log likelihood -1.407781
[ Info: iteration 49, average log likelihood -1.407777
[ Info: iteration 50, average log likelihood -1.407772
â”Œ Info: EM with 100000 data points 50 iterations avll -1.407772
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4093770234212215
â”‚     -1.409314182249976 
â”‚      â‹®                 
â””     -1.4077717290727116
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407776
[ Info: iteration 2, average log likelihood -1.407716
[ Info: iteration 3, average log likelihood -1.407660
[ Info: iteration 4, average log likelihood -1.407594
[ Info: iteration 5, average log likelihood -1.407512
[ Info: iteration 6, average log likelihood -1.407413
[ Info: iteration 7, average log likelihood -1.407299
[ Info: iteration 8, average log likelihood -1.407174
[ Info: iteration 9, average log likelihood -1.407045
[ Info: iteration 10, average log likelihood -1.406918
[ Info: iteration 11, average log likelihood -1.406798
[ Info: iteration 12, average log likelihood -1.406687
[ Info: iteration 13, average log likelihood -1.406586
[ Info: iteration 14, average log likelihood -1.406496
[ Info: iteration 15, average log likelihood -1.406417
[ Info: iteration 16, average log likelihood -1.406346
[ Info: iteration 17, average log likelihood -1.406285
[ Info: iteration 18, average log likelihood -1.406231
[ Info: iteration 19, average log likelihood -1.406184
[ Info: iteration 20, average log likelihood -1.406141
[ Info: iteration 21, average log likelihood -1.406103
[ Info: iteration 22, average log likelihood -1.406068
[ Info: iteration 23, average log likelihood -1.406036
[ Info: iteration 24, average log likelihood -1.406006
[ Info: iteration 25, average log likelihood -1.405977
[ Info: iteration 26, average log likelihood -1.405951
[ Info: iteration 27, average log likelihood -1.405925
[ Info: iteration 28, average log likelihood -1.405901
[ Info: iteration 29, average log likelihood -1.405878
[ Info: iteration 30, average log likelihood -1.405855
[ Info: iteration 31, average log likelihood -1.405834
[ Info: iteration 32, average log likelihood -1.405813
[ Info: iteration 33, average log likelihood -1.405793
[ Info: iteration 34, average log likelihood -1.405773
[ Info: iteration 35, average log likelihood -1.405754
[ Info: iteration 36, average log likelihood -1.405736
[ Info: iteration 37, average log likelihood -1.405718
[ Info: iteration 38, average log likelihood -1.405701
[ Info: iteration 39, average log likelihood -1.405685
[ Info: iteration 40, average log likelihood -1.405669
[ Info: iteration 41, average log likelihood -1.405653
[ Info: iteration 42, average log likelihood -1.405638
[ Info: iteration 43, average log likelihood -1.405624
[ Info: iteration 44, average log likelihood -1.405610
[ Info: iteration 45, average log likelihood -1.405596
[ Info: iteration 46, average log likelihood -1.405583
[ Info: iteration 47, average log likelihood -1.405571
[ Info: iteration 48, average log likelihood -1.405559
[ Info: iteration 49, average log likelihood -1.405547
[ Info: iteration 50, average log likelihood -1.405535
â”Œ Info: EM with 100000 data points 50 iterations avll -1.405535
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4077761246831397
â”‚     -1.4077161440252826
â”‚      â‹®                 
â””     -1.4055354545334733
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405532
[ Info: iteration 2, average log likelihood -1.405462
[ Info: iteration 3, average log likelihood -1.405394
[ Info: iteration 4, average log likelihood -1.405312
[ Info: iteration 5, average log likelihood -1.405209
[ Info: iteration 6, average log likelihood -1.405078
[ Info: iteration 7, average log likelihood -1.404919
[ Info: iteration 8, average log likelihood -1.404739
[ Info: iteration 9, average log likelihood -1.404551
[ Info: iteration 10, average log likelihood -1.404366
[ Info: iteration 11, average log likelihood -1.404193
[ Info: iteration 12, average log likelihood -1.404037
[ Info: iteration 13, average log likelihood -1.403898
[ Info: iteration 14, average log likelihood -1.403778
[ Info: iteration 15, average log likelihood -1.403674
[ Info: iteration 16, average log likelihood -1.403583
[ Info: iteration 17, average log likelihood -1.403505
[ Info: iteration 18, average log likelihood -1.403436
[ Info: iteration 19, average log likelihood -1.403374
[ Info: iteration 20, average log likelihood -1.403319
[ Info: iteration 21, average log likelihood -1.403269
[ Info: iteration 22, average log likelihood -1.403223
[ Info: iteration 23, average log likelihood -1.403181
[ Info: iteration 24, average log likelihood -1.403142
[ Info: iteration 25, average log likelihood -1.403106
[ Info: iteration 26, average log likelihood -1.403072
[ Info: iteration 27, average log likelihood -1.403041
[ Info: iteration 28, average log likelihood -1.403012
[ Info: iteration 29, average log likelihood -1.402985
[ Info: iteration 30, average log likelihood -1.402960
[ Info: iteration 31, average log likelihood -1.402936
[ Info: iteration 32, average log likelihood -1.402915
[ Info: iteration 33, average log likelihood -1.402894
[ Info: iteration 34, average log likelihood -1.402875
[ Info: iteration 35, average log likelihood -1.402857
[ Info: iteration 36, average log likelihood -1.402840
[ Info: iteration 37, average log likelihood -1.402825
[ Info: iteration 38, average log likelihood -1.402810
[ Info: iteration 39, average log likelihood -1.402796
[ Info: iteration 40, average log likelihood -1.402783
[ Info: iteration 41, average log likelihood -1.402770
[ Info: iteration 42, average log likelihood -1.402758
[ Info: iteration 43, average log likelihood -1.402746
[ Info: iteration 44, average log likelihood -1.402736
[ Info: iteration 45, average log likelihood -1.402725
[ Info: iteration 46, average log likelihood -1.402715
[ Info: iteration 47, average log likelihood -1.402705
[ Info: iteration 48, average log likelihood -1.402696
[ Info: iteration 49, average log likelihood -1.402687
[ Info: iteration 50, average log likelihood -1.402679
â”Œ Info: EM with 100000 data points 50 iterations avll -1.402679
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4055319889674927
â”‚     -1.4054620698731715
â”‚      â‹®                 
â””     -1.4026788099461995
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4161187160101802
â”‚     -1.4161368842803514
â”‚     -1.4160670509983977
â”‚     -1.4160089032535785
â”‚      â‹®                 
â”‚     -1.4026961909739948
â”‚     -1.402687329193679 
â””     -1.4026788099461995
32Ã—26 Array{Float64,2}:
 -0.0178567   0.233673    -0.140752   -0.169919    -0.401468   -0.0699506   -0.000400939   0.159245   -0.00643715   0.319405    0.101024    -0.183042    -0.528674    -0.10045    -0.236965    -0.285564     0.276346    -0.128018     0.207545    0.0987833  -0.0218603  -0.0818854   0.128915   -0.52651     -0.209083    0.394061  
  0.181087   -0.160027     0.0497503   0.0753825   -0.0448828  -0.135058    -0.273855     -0.0775946  -0.0816213   -0.242155   -0.0748056   -0.145824     0.42187     -0.0385281  -0.387731    -0.213885     0.0528148    0.254713     0.10969     0.428664   -0.24975     0.0421548  -0.0331975  -0.0467398   -0.425007    0.0923322 
  0.2206     -0.0817637   -0.622517    0.0780766    0.149462   -0.406546     0.101535     -0.462216   -0.523526     0.19479    -0.0343602   -0.0472394   -0.00595537  -0.521568    0.356103    -0.287035     0.753608     0.471905     0.196375   -0.400418   -0.566459    0.103701    0.207314   -0.332858     0.145639   -0.631058  
  0.259791   -0.505519     0.571189    0.363527     0.043415   -0.0966335   -0.0809195    -0.339172    0.285585    -0.21159    -0.24013     -0.43572     -0.113373    -0.522003    0.452917    -0.303097     0.269943    -0.159875    -0.590203   -0.0594801  -0.20422    -0.183406    0.402669    0.0563626    0.0955668   0.0442164 
 -0.0747317  -0.0636662   -0.129947    0.0926323   -0.0353931  -0.0877794   -0.0469771    -0.0622248  -0.0486552    0.0511145   0.033905    -0.0224212   -0.0201379   -0.454185    0.135299    -0.129362     0.0354655   -0.110536     0.0362322   0.0393888   0.0928667   0.0601873  -0.0461809   0.158107     0.122368   -0.158823  
  0.0221586   0.0570965    0.049862   -0.0781096    0.0158231   0.212968    -0.00942496    0.0790396   0.0582311   -0.0423445   0.0354254    0.00192616  -0.0786795    0.458961   -0.038879     0.233792    -0.0324585   -0.0123813   -0.035814   -0.0628091   0.19256    -0.0137132   0.12444     0.0727153    0.0450038   0.00965576
  0.0864366  -0.136922    -0.429113    0.543593    -0.117948    0.0674954   -0.197148     -0.392485   -0.543714     0.549047   -0.102735     0.324914     0.429382    -0.104212    0.0917985   -0.105451    -0.122729     0.0128438   -0.440318    0.139006    0.0810798  -0.398988   -0.067506    0.77733      0.289747   -0.370487  
  0.525848   -0.0851797    0.866903    0.227754    -0.0607446   0.0715821    0.0188008    -0.470323   -0.689042    -0.17691     0.0314458    0.0780566    0.562095     0.23744    -0.264609     0.365454    -0.381115     0.0932361   -0.11372     0.108965    0.297924    0.252809    0.125567    0.733349     0.600141   -0.412885  
 -0.780461    0.271303    -0.0421139  -0.321777    -0.465413    0.474046    -0.190195      0.142795    0.459959    -0.1091     -0.0464361    0.195199    -0.0147781    0.0730015   0.225842     0.0254258   -0.0903841    0.0355146    0.455733   -0.436695   -0.170406   -0.271      -0.521062   -0.307406    -0.285919    0.0979226 
  0.158224    0.15598      0.142681   -0.328794     0.405374    0.357631     0.242538     -0.268173    0.273874     0.120995   -0.152692     0.404311     0.413875     0.245392    0.107596     0.108534    -0.178334     0.183707    -0.141522   -0.750414   -0.383919   -0.049024   -0.178168    0.0488171   -0.147445    0.0022678 
 -0.195414    0.114492     0.293566   -0.26083      0.620154   -0.224191    -0.106284      0.443723    0.490679    -0.760636    0.234062    -0.111528     0.0496716    0.208714   -0.183765     0.304227    -0.118825     0.0808397    0.24352    -0.446676   -0.152752    0.130318    0.588989    0.170556     0.233603   -0.677359  
  0.335754    0.952882     0.354309   -0.281676     0.560433    0.362193     0.135073      0.278303   -0.0642073    0.117755    0.281849     0.0526567   -0.117295     0.568926   -0.393715     0.00253663  -0.266002    -0.227192     0.0879722  -0.203313   -0.253248    0.0162469   0.510449   -0.43971     -0.054905    0.30194   
  0.35879     0.209898    -0.638463    0.507431    -0.234988    0.294206    -0.923969      0.114863    0.0271223   -0.190876    0.117356     0.249775    -0.15101     -0.0819672   0.0672544    0.428195    -0.0230859    0.188999     0.167903    0.0210274   0.0709696  -0.279224   -0.0135546  -0.246804     0.255125   -0.133545  
 -0.119632    0.487933    -0.639963   -0.167357     0.0359327   0.443585     0.439929      0.111985   -0.0262701    0.450172    0.0307329    0.202912    -0.232475     0.0154566   0.0873594    0.436354    -0.218215     0.0623603    0.222278   -0.0699504   0.326408    0.331493   -0.216554    0.0682855    0.499966   -0.107413  
  0.130699    0.00117993  -0.248718    0.186887     0.31621     0.880652     0.459723      0.671877   -0.660687     0.0998442   0.23062     -0.189418    -0.16231      0.558196    0.641002    -0.0130361   -0.00412115  -0.0212349    0.33397     0.104831    0.463212   -0.675419    0.793791   -0.327029    -0.17679    -0.12589   
  0.650238   -0.697739    -0.246788   -0.885398    -0.228596    0.775464     0.836204      0.73901    -0.0788749    0.122859    0.114377     0.179558     0.0116016    0.131142   -0.111113     0.94979      0.211167     0.259493    -0.0191946   0.0857951  -0.37729    -0.805546    0.129536   -0.166369    -0.472765   -0.241023  
 -0.516981   -0.155482     0.117649   -0.15525     -0.327972   -0.479044     0.292859      0.317506    0.37205      0.41544    -0.0867189    0.421013    -0.794341    -0.432317   -0.0283528    0.189997     0.734227    -0.850246    -0.0785009  -0.10215     0.435788    0.736176    0.476989    0.87495      0.227695   -0.112889  
 -0.451626   -0.332771     0.124036   -0.206901     0.469895    0.28112      0.384674     -0.165169    0.378195     0.097695    0.129886     0.616762    -0.62703     -0.0524117   0.591015     0.0691831    0.059726     0.174957    -0.624491   -0.528221    0.158766   -0.281393   -0.39653    -0.00248052   0.466483   -0.084743  
 -0.163749   -0.0410893    0.177557   -0.665085    -0.479983   -0.684844    -0.491459     -0.672841    0.428505    -0.0398536   0.259636     0.117606     0.0603478   -0.624604   -0.923445    -0.280529    -0.213257     0.00985998  -0.14267    -0.238594   -0.513374    0.471085   -0.679144    0.0625951    0.159532   -0.119358  
  0.0774061  -0.616438    -0.284716    0.260566    -0.393999   -0.657251    -0.537532     -0.583467    0.172643    -0.661453   -0.294408    -0.0276785    0.158181    -0.200557    0.389747     0.38766     -0.263686    -0.455176    -0.315907   -0.261074    0.156029    0.219634   -0.267345    0.405603     0.444168    0.0966731 
 -0.038701    0.1834       0.0650957  -0.171232     0.654267    0.301402     0.168414     -0.420425   -0.382132    -0.170835   -0.019388     0.0507587    0.13166     -0.385589    0.490725     0.325808     0.171267    -0.038412     0.0103044  -0.283615    0.21119     0.0973276  -0.175132   -0.0167289    0.316578   -0.200095  
  0.43401    -0.130668     0.0816033   0.269517     0.308099    0.200191    -0.251432     -0.153869    0.483478    -0.261415   -0.395883     0.056762     0.380168     0.514273   -0.00372155   0.184571     0.0615834    0.742029    -0.164936   -0.222194   -0.249395    0.321122    0.259619    0.262876     0.14043    -0.339018  
  0.282381   -0.200897    -0.108851    0.236822     0.535388    0.720165    -0.353879     -0.0788802  -0.318833    -0.565658    0.00584192  -0.596028     1.15802      0.402494    0.306015    -0.0630114   -0.760686     0.483461    -0.134215   -0.0279783  -0.351076   -0.695998   -0.66025    -0.591113    -0.188745    0.145018  
  0.652777   -0.0752658   -0.12539     0.689088     0.508283    0.04366      0.287353      0.0207053  -0.171377    -0.292266   -0.449726     0.249702     0.184049     0.240968    0.635558     0.0695883    0.124304     0.293874     0.268437    0.25159    -0.167958   -0.0541252   0.316778   -0.645818     0.020193    0.698886  
  0.103013   -0.150226     0.0598016   0.430801    -0.605972   -0.491915    -0.615434      0.263308   -0.536977    -0.448492    0.112388    -0.811766     0.236511    -0.204011   -0.369031    -0.268566     0.415999    -0.449989     0.357671    0.653653    0.195724    0.234067    0.330552    0.192383    -0.557077   -0.0420604 
 -0.624328   -0.517691     0.0559669  -0.107249    -0.57897     0.103398    -0.25832      -0.0151222  -0.0438518   -0.335476   -0.285782    -0.146132    -0.168828    -0.249054    0.0903026   -0.0995916    0.182677    -0.277161     0.0920892   0.367957    0.478717   -0.175463   -0.79964     0.421195    -0.365429   -0.441213  
  0.335149   -0.245634     0.645009   -0.00177951   0.36046    -0.344819     0.35142      -0.602526   -0.154836    -0.152263   -0.28345      0.159281     0.202074     0.0350997  -0.0797688   -0.444323     0.174684     0.0949162    0.0239538   0.532289    0.304564    0.526351   -0.573296    0.0226945   -0.665969    0.551833  
 -0.0172041  -0.189725     0.528259    0.217927     0.304002    0.0601825    0.165583      0.165901    0.148358    -0.115172   -0.206245    -0.011801     0.469377     0.113822   -0.292675     0.305369    -0.791221    -0.684284    -0.404918    0.844403    0.624631    0.0677266  -0.179723    0.248999    -0.0653804   0.877701  
 -0.228535   -0.0367635   -0.321969   -0.0405855   -0.580159   -0.118405    -0.336003      0.207095    0.0199679   -0.0109358   0.279734    -0.045308    -0.352743    -0.037392   -0.347238    -0.0189657   -0.239147    -0.376662    -0.0213815   0.0431881  -0.0157505  -0.594526    0.11297    -0.357976    -0.0069926   0.136278  
  0.0887279  -0.0324743   -0.506809   -0.111878    -0.651904   -0.0651679    0.0791754     0.284958    0.543138     1.01569     0.168944    -0.202924    -0.293844    -0.0485083  -0.2659      -0.43464     -0.00638074   0.418175     0.308979    0.173268   -0.255484    0.0916329  -0.0210224   0.12776     -0.655211    0.304852  
 -0.399936    0.294987  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
   0.47418    -0.536073     0.318248   -0.180088     0.602139      0.0934063   0.0157764    0.74006     0.463861    -0.271155     0.131073    -0.4544      0.0146752   -0.587232    -0.0133559   -0.132275     0.0726674  -0.221484   -0.394041   -0.147077    0.502464    0.0600895   -0.141415    0.0126761 
 -0.364771   -0.106444     0.22049    -0.638241     0.135458   -0.00915511   0.430893     -0.315898   -0.197715     0.524278    0.0152963   -0.811348    -0.0391125    0.5115     -0.0299603   -0.176982     0.116193    -0.026695    -0.523709    0.199388    0.146488    0.675564    0.121426    0.63849     -0.285398   -0.0625073 [ Info: iteration 1, average log likelihood -1.402671
[ Info: iteration 2, average log likelihood -1.402663
[ Info: iteration 3, average log likelihood -1.402655
[ Info: iteration 4, average log likelihood -1.402648
[ Info: iteration 5, average log likelihood -1.402641
[ Info: iteration 6, average log likelihood -1.402634
[ Info: iteration 7, average log likelihood -1.402627
[ Info: iteration 8, average log likelihood -1.402621
[ Info: iteration 9, average log likelihood -1.402615
[ Info: iteration 10, average log likelihood -1.402609
â”Œ Info: EM with 100000 data points 10 iterations avll -1.402609
â”” 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.237774e+05
      1       6.940572e+05      -2.297202e+05 |       32
      2       6.807175e+05      -1.333969e+04 |       32
      3       6.758432e+05      -4.874376e+03 |       32
      4       6.733159e+05      -2.527304e+03 |       32
      5       6.715466e+05      -1.769304e+03 |       32
      6       6.702677e+05      -1.278821e+03 |       32
      7       6.693121e+05      -9.556687e+02 |       32
      8       6.685761e+05      -7.360024e+02 |       32
      9       6.679570e+05      -6.190835e+02 |       32
     10       6.674337e+05      -5.233207e+02 |       32
     11       6.669775e+05      -4.561350e+02 |       32
     12       6.665926e+05      -3.849300e+02 |       32
     13       6.662330e+05      -3.596157e+02 |       32
     14       6.659052e+05      -3.278150e+02 |       32
     15       6.655795e+05      -3.256172e+02 |       32
     16       6.653049e+05      -2.746190e+02 |       32
     17       6.650693e+05      -2.356370e+02 |       32
     18       6.648209e+05      -2.483363e+02 |       32
     19       6.645867e+05      -2.342714e+02 |       32
     20       6.643772e+05      -2.094573e+02 |       32
     21       6.642048e+05      -1.724124e+02 |       32
     22       6.640410e+05      -1.638142e+02 |       32
     23       6.638898e+05      -1.512362e+02 |       32
     24       6.637606e+05      -1.291833e+02 |       32
     25       6.636371e+05      -1.234362e+02 |       32
     26       6.635134e+05      -1.237083e+02 |       32
     27       6.633894e+05      -1.240260e+02 |       32
     28       6.632587e+05      -1.307054e+02 |       32
     29       6.631355e+05      -1.231671e+02 |       32
     30       6.630296e+05      -1.059558e+02 |       32
     31       6.629346e+05      -9.502426e+01 |       32
     32       6.628420e+05      -9.255491e+01 |       32
     33       6.627648e+05      -7.724331e+01 |       32
     34       6.626993e+05      -6.545100e+01 |       32
     35       6.626368e+05      -6.254925e+01 |       32
     36       6.625802e+05      -5.659355e+01 |       32
     37       6.625228e+05      -5.732074e+01 |       32
     38       6.624679e+05      -5.497642e+01 |       32
     39       6.624172e+05      -5.063692e+01 |       32
     40       6.623571e+05      -6.016137e+01 |       32
     41       6.623003e+05      -5.676374e+01 |       32
     42       6.622504e+05      -4.987469e+01 |       32
     43       6.621971e+05      -5.329913e+01 |       32
     44       6.621512e+05      -4.593035e+01 |       32
     45       6.621010e+05      -5.018697e+01 |       32
     46       6.620516e+05      -4.945398e+01 |       32
     47       6.620034e+05      -4.820252e+01 |       32
     48       6.619473e+05      -5.608853e+01 |       32
     49       6.618938e+05      -5.348389e+01 |       32
     50       6.618469e+05      -4.687078e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 661846.9093350966)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414847
[ Info: iteration 2, average log likelihood -1.409763
[ Info: iteration 3, average log likelihood -1.408330
[ Info: iteration 4, average log likelihood -1.407205
[ Info: iteration 5, average log likelihood -1.406047
[ Info: iteration 6, average log likelihood -1.405073
[ Info: iteration 7, average log likelihood -1.404469
[ Info: iteration 8, average log likelihood -1.404146
[ Info: iteration 9, average log likelihood -1.403962
[ Info: iteration 10, average log likelihood -1.403838
[ Info: iteration 11, average log likelihood -1.403744
[ Info: iteration 12, average log likelihood -1.403666
[ Info: iteration 13, average log likelihood -1.403600
[ Info: iteration 14, average log likelihood -1.403542
[ Info: iteration 15, average log likelihood -1.403490
[ Info: iteration 16, average log likelihood -1.403443
[ Info: iteration 17, average log likelihood -1.403400
[ Info: iteration 18, average log likelihood -1.403361
[ Info: iteration 19, average log likelihood -1.403324
[ Info: iteration 20, average log likelihood -1.403290
[ Info: iteration 21, average log likelihood -1.403259
[ Info: iteration 22, average log likelihood -1.403229
[ Info: iteration 23, average log likelihood -1.403201
[ Info: iteration 24, average log likelihood -1.403174
[ Info: iteration 25, average log likelihood -1.403149
[ Info: iteration 26, average log likelihood -1.403125
[ Info: iteration 27, average log likelihood -1.403102
[ Info: iteration 28, average log likelihood -1.403079
[ Info: iteration 29, average log likelihood -1.403058
[ Info: iteration 30, average log likelihood -1.403037
[ Info: iteration 31, average log likelihood -1.403016
[ Info: iteration 32, average log likelihood -1.402997
[ Info: iteration 33, average log likelihood -1.402977
[ Info: iteration 34, average log likelihood -1.402959
[ Info: iteration 35, average log likelihood -1.402940
[ Info: iteration 36, average log likelihood -1.402922
[ Info: iteration 37, average log likelihood -1.402905
[ Info: iteration 38, average log likelihood -1.402888
[ Info: iteration 39, average log likelihood -1.402871
[ Info: iteration 40, average log likelihood -1.402854
[ Info: iteration 41, average log likelihood -1.402838
[ Info: iteration 42, average log likelihood -1.402823
[ Info: iteration 43, average log likelihood -1.402808
[ Info: iteration 44, average log likelihood -1.402793
[ Info: iteration 45, average log likelihood -1.402779
[ Info: iteration 46, average log likelihood -1.402765
[ Info: iteration 47, average log likelihood -1.402752
[ Info: iteration 48, average log likelihood -1.402739
[ Info: iteration 49, average log likelihood -1.402726
32Ã—26 Array{Float64,2}:
[ Info: iteration 50, average log likelihood -1.402714
â”Œ Info: EM with 100000 data points 50 iterations avll -1.402714
â”” 59.0 data points per parameter
 -0.483387     0.216023    0.245388    -0.604565    0.711624    -0.299522    0.0234779   0.328724     0.45536    -0.750032    0.239265    -0.226698    -0.0539125    0.193595     -0.208567    0.395457    -0.053306    0.160483     0.335619    -0.54599    -0.181898     0.338075    0.433803     0.231693     0.0569548   -0.827042 
  0.221557     0.222491   -0.540396     0.258492    0.504222     0.111619    0.827267   -0.432964    -0.609861    0.542701    0.0517163   -0.310634     0.314328    -0.483249      0.745649   -0.35129      0.121635    0.666094     0.414601    -0.79563    -0.563991     0.646168    0.0399711   -0.315776     0.506761     0.19587  
 -0.531859    -0.121381    0.507106    -0.399181   -0.113497    -0.427178    0.425764   -0.214974     0.208738    0.380021    0.0711917    0.0293445   -0.375859    -0.193022     -0.131845   -0.351282     0.122992   -0.461981    -0.0286481    0.204171    0.517799     0.309892   -0.0916391    0.347363    -0.286526     0.212508 
  0.00168865   0.160734   -0.422405    -0.480417    0.0130385   -0.0182247   0.220655   -0.411154    -0.63188     0.216624    0.179863    -0.414968     0.326346    -0.000476271  -0.322568   -0.412038    -0.293524    0.425363     0.746607     0.827648   -0.0160148   -0.156289    0.0329593   -0.243448    -0.106281    -0.579549 
  0.0387046   -0.0461203   0.0944495   -0.0886961   0.0237556   -0.0608502  -0.0257043  -0.0182895    0.0844942  -0.068564   -0.0256043   -0.0588641    0.0690863   -0.0552085    -0.0872369  -0.0616603    0.038856    0.00280414  -0.00950091  -0.0238212  -0.130385     0.0242086   0.0674161    0.00411332  -0.108185     0.0296367
  0.0138923   -0.227146   -0.00188198   0.30081    -0.121592    -0.211516   -0.139859   -0.308726    -0.556784    0.200186    0.24196     -0.201771    -0.0737136   -0.110617     -0.0186645  -0.282005    -0.0565961  -0.00988568  -0.44226      0.450073    0.475846     0.0912012  -0.0206234    0.367695     0.228732    -0.26703  
 -0.165449    -0.721911    0.119239     0.16555     0.105747    -0.180412    0.0530765  -0.120078     0.297266   -0.442007   -0.165392    -0.00737625  -0.0892963   -0.813662      0.497267   -0.301792     0.041389   -0.264905    -0.346       -0.0768465  -0.312931    -0.241893   -0.117131     0.198773     0.331556    -0.0264735
  0.302161    -0.481592    0.679568     0.650908    0.163492    -0.0420954  -0.181567   -0.314032    -0.191463   -0.288728   -0.228421    -0.00443568   0.644502     0.191251      0.001864    0.107382    -0.308298   -0.253199    -0.670334     0.298331    0.214919     0.142357    0.0400027    0.681801     0.115245     0.010619 
  0.0362558    0.362942   -0.315391    -0.141361   -0.630237     0.459624   -0.0179119  -0.369174    -0.242862    0.634033   -0.195132     0.172156    -0.131817    -0.175572     -0.131039   -0.0151681    0.0326305  -0.214528     0.152655     0.309345    0.196202    -0.0804346  -0.492853    -0.173012    -0.115588     0.781425 
 -0.893448    -0.174083    0.178122    -0.254617   -0.68579      0.479381   -0.304256   -0.00992176   0.441225   -0.284166   -0.117376     0.141146    -0.483441    -0.0600523     0.442113    0.0362557    0.165517    0.0067296    0.457762    -0.249182    0.335783    -0.200855   -0.731852    -0.0105868   -0.13811     -0.339007 
 -0.0727153    0.101246   -0.185673    -0.0194202   0.0201987    0.298514    0.108051    0.19882     -0.0238378   0.020636    0.0886447   -0.0134157   -0.335393     0.265116      0.168747    0.314643    -0.0353005  -0.143914     0.0811323   -0.0856309   0.547112    -0.0290588   0.115743     0.101933     0.274226    -0.170144 
 -0.142175     0.133928    0.0498786   -0.413298    0.604546     0.524986    0.435184   -0.199675     0.365292    0.273207    0.0125052    0.756744    -0.00403701   0.307958      0.225839    0.34599     -0.262765    0.281035    -0.366154    -0.710452   -0.107427    -0.130987   -0.257596     0.0236295    0.314806    -0.200807 
 -0.525642     0.208946   -0.987213     0.0706021  -0.641498     0.194675   -0.20451     0.793609    -0.358168    0.276624    0.155022    -0.0614108   -0.0528478   -0.257047     -0.0371966   0.350342    -0.25271    -0.336761     0.16191      0.153047    0.00105943  -0.694429    0.00134184   0.00311591   0.0174168   -0.359266 
  0.52909      0.0924298  -0.215568     0.479804    0.461301     0.227433    0.373267    0.275045    -0.333488   -0.156671   -0.294        0.197486    -0.109518     0.350741      0.513137   -0.0821488    0.0181675   0.0886398    0.209234     0.401998    0.10322     -0.276287    0.470138    -0.84227     -0.229335     0.620046 
 -0.233768    -0.0223012   0.211583    -0.711962   -0.513606    -0.680546   -0.45762    -0.567707     0.388786    0.0555373   0.371863     0.0203272    0.0565563   -0.65944      -0.912234   -0.473096    -0.244474   -0.0222523   -0.170398    -0.284405   -0.57116      0.364065   -0.627776     0.0399718    0.148532    -0.166394 
 -0.218175     0.301129   -0.0607536   -0.443862   -0.189896     0.0107733   0.0859026   0.191924     0.244622    0.509979    0.259303    -0.279682    -0.242161    -0.120522     -0.0257291  -0.495242     0.389286    0.137797     0.267847    -0.183317   -0.403368    -0.142107    0.184621    -0.473958    -0.522519     0.226998 
  0.278795     0.254429   -0.0820357    0.0431028   0.463114     0.558386    0.0238041  -0.132789    -0.205829   -0.234024   -0.1526       0.0962324    0.0905632    0.118443      0.411333    0.637486     0.0794446   0.156981     0.100526    -0.276108    0.265897     0.0242753   0.0242509    0.0376679    0.419875    -0.231343 
  0.348081     0.310049   -0.52455      0.205099   -0.104459    -0.193966   -0.490666    0.0399368    0.219726   -0.0953406   0.53487      0.204374    -0.445948    -0.237361     -0.361368    0.367905    -0.126709   -0.0321354    0.334839    -0.331434   -0.210325    -0.407747    0.548118    -0.765553     0.589224     0.170944 
 -0.0710126    0.386506    0.620594    -0.299589    0.579763     0.405067    0.564316    0.416982    -0.245625    0.534174    0.667241    -0.257501    -0.261574     0.189113      0.129026   -0.541281    -0.160142   -0.146708    -0.111733    -0.30737    -0.249891    -0.400546    0.798157    -0.132738    -0.00820397   0.063739 
  0.199328    -0.468964   -0.564515     0.0602295  -0.484931    -0.56023    -0.604182   -0.786363     0.154252   -0.67746    -0.371452     0.234177     0.344291    -0.199377      0.0553366   0.816946    -0.143223   -0.168059    -0.00956843  -0.105531    0.293436     0.284722   -0.560399     0.301042     0.159668    -0.180611 
  0.245113    -0.232544    0.119369     0.0402879   0.842385     0.715698   -0.229926   -0.192566    -0.341557   -0.598271   -0.0143472   -0.522871     1.22866      0.256698      0.392395    0.118124    -0.586683    0.310139    -0.099904    -0.121206   -0.130941    -0.619822   -0.626962    -0.529276    -0.201086     0.313598 
  0.152885    -0.124955   -0.772935     0.123929    0.00182225  -0.599856    0.015792   -0.860435    -0.739405    0.433634   -0.345332     0.178984    -0.312373    -0.380406      0.443835   -0.312465     0.78214     0.298832    -0.18366     -0.375481   -0.476309    -0.0997676   0.226151     0.00220502   0.274686    -0.930076 
  0.25518     -0.27638    -0.389907     0.136481   -0.432988    -0.065693   -0.243749    0.184832     0.264271    0.190713   -0.00600379  -0.190865     0.092707    -0.012158     -0.338172   -0.393821    -0.0215756   0.361671     0.114626     0.202804   -0.44061     -0.137086   -0.0647766   -0.0985294   -0.471055     0.169051 
  0.260503     0.460854    0.0756637    0.0800175   0.290397    -0.057505    0.0704552   0.0409159    0.0880135   0.270282   -0.0311347    0.268538     0.177467    -0.5591        0.047895    0.165229     0.221431   -0.28459      0.62521     -0.0686679   0.16694      0.471306    0.299919     0.51893      0.210058    -0.261751 
  0.452784     0.0398856  -0.0795443    0.605633    0.349285     0.113586   -0.693366    0.0601963    0.310535   -0.353386   -0.136726     0.106597     0.116098     0.292926      0.192479    0.0566828    0.264274    0.862791    -0.0810681   -0.178481   -0.26185      0.162829    0.375958     0.0128329    0.300043    -0.403564 
 -0.350248    -0.1864      0.170966    -0.620359    0.129143     0.130684    0.545932   -0.179717    -0.111812    0.440556   -0.0678338   -0.518527     0.251956     0.255794     -0.041668    0.0645385    0.0818193  -0.0779116   -0.592356     0.0166478  -0.100157     0.541178    0.0740497    0.783802    -0.28245     -0.113623 
  0.0112758   -0.306334    0.0128419    0.342921   -0.643681    -0.428951   -0.54875     0.250895    -0.34453    -0.409523   -0.0281186   -0.662464     0.0750628   -0.220091     -0.301777   -0.285049     0.475818   -0.357357     0.2612       0.543777    0.183193     0.115971    0.195568     0.147028    -0.545009    -0.0103691
  0.367548    -0.161081    0.626954    -0.0505085   0.455126    -0.412949    0.107824   -0.573223     0.0679651  -0.252341   -0.219435     0.0884245    0.224261    -0.0244923    -0.212499   -0.200237     0.105085    0.200498     0.0488548    0.37977    -0.00190331   0.411738   -0.338555    -0.21755     -0.458281     0.691269 
 -0.109117     0.186793   -0.285535     0.0743798  -0.386751    -0.109128   -0.104718    0.392434     0.491368    0.386215    0.0354024    0.189232    -0.907733     0.220902     -0.0341978   0.213866     0.0414456  -0.388244    -0.509691    -0.246164    0.400977     0.45695     0.177346     0.2615       0.354105     0.426201 
  0.685488    -0.574786   -0.192221    -0.675443   -0.0552345    0.728558    0.761328    0.742664    -0.055624   -0.0293445   0.0927606    0.191487     0.0234822    0.350687     -0.0453542   0.850557     0.149566    0.31452      0.141456     0.075462   -0.192463    -0.683012    0.269662    -0.205466    -0.41555     -0.156515 
  0.146615     0.823163    0.401682    -0.135219    0.264659     0.309013   -0.240796    0.24968      0.0559904  -0.370713    0.071529    -0.219269     0.378286     0.703462     -0.678034    0.260783    -0.404395   -0.362687     0.218728    -0.0220102  -0.276676     0.130247    0.405257    -0.244627    -0.177996     0.115501 
  0.0387255   -0.0660782  -0.196445     0.386545   -0.26984      0.292686   -0.426239   -0.0747815   -0.0403929  -0.1125     -0.112079     0.197962     0.355779     0.115476      0.121206   -0.00592925  -0.212443    0.232301    -0.0248549   -0.0738317  -0.14721     -0.354088   -0.389951    -0.0450564    0.0035032   -0.0792941[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.402702
[ Info: iteration 2, average log likelihood -1.402691
[ Info: iteration 3, average log likelihood -1.402680
[ Info: iteration 4, average log likelihood -1.402669
[ Info: iteration 5, average log likelihood -1.402658
[ Info: iteration 6, average log likelihood -1.402648
[ Info: iteration 7, average log likelihood -1.402639
[ Info: iteration 8, average log likelihood -1.402629
[ Info: iteration 9, average log likelihood -1.402620
[ Info: iteration 10, average log likelihood -1.402612
â”Œ Info: EM with 100000 data points 10 iterations avll -1.402612
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
