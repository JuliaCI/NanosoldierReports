Running tests with Julia v1.3.1-pre.12
 Resolving package versions...
 Installed URIParser ────────── v0.4.0
 Installed GaussianMixtures ─── v0.3.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed PDMats ───────────── v0.9.10
 Installed CMake ────────────── v1.1.2
 Installed Distances ────────── v0.8.2
 Installed Parameters ───────── v0.12.0
 Installed BinaryProvider ───── v0.5.8
 Installed NearestNeighbors ─── v0.4.4
 Installed Compat ───────────── v2.2.0
 Installed QuadGK ───────────── v2.1.1
 Installed FileIO ───────────── v1.1.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed ScikitLearnBase ──── v0.5.0
 Installed JLD ──────────────── v0.9.1
 Installed Clustering ───────── v0.13.3
 Installed Blosc ────────────── v0.5.1
 Installed OrderedCollections ─ v1.1.0
 Installed BinDeps ──────────── v0.8.10
 Installed SortingAlgorithms ── v0.3.1
 Installed StatsBase ────────── v0.32.0
 Installed Arpack ───────────── v0.4.0
 Installed StatsFuns ────────── v0.9.1
 Installed DataStructures ───── v0.17.6
 Installed LegacyStrings ────── v0.4.1
 Installed HDF5 ─────────────── v0.12.5
 Installed FillArrays ───────── v0.8.2
 Installed SpecialFunctions ─── v0.8.0
 Installed DataAPI ──────────── v1.1.0
 Installed Missings ─────────── v0.4.3
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed Rmath ────────────── v0.5.1
 Installed Distributions ────── v0.21.10
 Installed StaticArrays ─────── v0.12.1
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v0.8.10
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.10
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.1.1
  [79098fc4] + Rmath v0.5.1
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.8.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.1
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake ───────────→ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc ───────────→ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ────────────→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Building SpecialFunctions → `~/.julia/packages/SpecialFunctions/ne2iw/deps/build.log`
  Building Rmath ───────────→ `~/.julia/packages/Rmath/4wt82/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_PLMkJa/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v0.8.10
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.10
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.1.1
  [79098fc4] Rmath v0.5.1
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.8.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.1
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -1.426208695403709e6, [42753.00019489115, 57246.99980510885], [20999.391265589053 28446.837510899008 16065.063865629012; -20851.19822239021 -28322.49193741276 -16018.410082990702], Array{Float64,2}[[45675.52965865529 3385.1000332990343 -390.9582677365256; 3385.1000332990347 44506.37569810601 1947.0747200945618; -390.95826773652556 1947.0747200945618 46294.5116269689], [54709.73190460493 -3184.3316454188375 409.0977568047356; -3184.3316454188375 55217.18772238595 -1461.3495311282275; 409.0977568047357 -1461.3495311282275 54006.12940442905]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/julia/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.120631e+03
      1       9.124814e+02      -2.081494e+02 |        4
      2       9.034357e+02      -9.045721e+00 |        0
      3       9.034357e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 903.4356667115753)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.066003
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.856323
[ Info: iteration 2, lowerbound -3.772637
[ Info: iteration 3, lowerbound -3.685551
[ Info: iteration 4, lowerbound -3.574852
[ Info: iteration 5, lowerbound -3.436136
[ Info: iteration 6, lowerbound -3.270812
[ Info: iteration 7, lowerbound -3.089943
[ Info: dropping number of Gaussions to 7
[ Info: iteration 8, lowerbound -2.901023
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -2.709956
[ Info: iteration 10, lowerbound -2.548335
[ Info: iteration 11, lowerbound -2.431389
[ Info: dropping number of Gaussions to 5
[ Info: iteration 12, lowerbound -2.358324
[ Info: iteration 13, lowerbound -2.326054
[ Info: dropping number of Gaussions to 3
[ Info: iteration 14, lowerbound -2.315416
[ Info: dropping number of Gaussions to 2
[ Info: iteration 15, lowerbound -2.302927
[ Info: iteration 16, lowerbound -2.299264
[ Info: iteration 17, lowerbound -2.299258
[ Info: iteration 18, lowerbound -2.299255
[ Info: iteration 19, lowerbound -2.299254
[ Info: iteration 20, lowerbound -2.299253
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Dec  4 21:47:42 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Dec  4 21:47:51 2019: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Wed Dec  4 21:47:53 2019: EM with 272 data points 0 iterations avll -2.066003
5.8 data points per parameter
, Wed Dec  4 21:47:55 2019: GMM converted to Variational GMM
, Wed Dec  4 21:48:04 2019: iteration 1, lowerbound -3.856323
, Wed Dec  4 21:48:04 2019: iteration 2, lowerbound -3.772637
, Wed Dec  4 21:48:04 2019: iteration 3, lowerbound -3.685551
, Wed Dec  4 21:48:04 2019: iteration 4, lowerbound -3.574852
, Wed Dec  4 21:48:04 2019: iteration 5, lowerbound -3.436136
, Wed Dec  4 21:48:04 2019: iteration 6, lowerbound -3.270812
, Wed Dec  4 21:48:04 2019: iteration 7, lowerbound -3.089943
, Wed Dec  4 21:48:05 2019: dropping number of Gaussions to 7
, Wed Dec  4 21:48:05 2019: iteration 8, lowerbound -2.901023
, Wed Dec  4 21:48:05 2019: dropping number of Gaussions to 6
, Wed Dec  4 21:48:05 2019: iteration 9, lowerbound -2.709956
, Wed Dec  4 21:48:05 2019: iteration 10, lowerbound -2.548335
, Wed Dec  4 21:48:05 2019: iteration 11, lowerbound -2.431389
, Wed Dec  4 21:48:05 2019: dropping number of Gaussions to 5
, Wed Dec  4 21:48:05 2019: iteration 12, lowerbound -2.358324
, Wed Dec  4 21:48:05 2019: iteration 13, lowerbound -2.326054
, Wed Dec  4 21:48:05 2019: dropping number of Gaussions to 3
, Wed Dec  4 21:48:05 2019: iteration 14, lowerbound -2.315416
, Wed Dec  4 21:48:05 2019: dropping number of Gaussions to 2
, Wed Dec  4 21:48:05 2019: iteration 15, lowerbound -2.302927
, Wed Dec  4 21:48:05 2019: iteration 16, lowerbound -2.299264
, Wed Dec  4 21:48:05 2019: iteration 17, lowerbound -2.299258
, Wed Dec  4 21:48:05 2019: iteration 18, lowerbound -2.299255
, Wed Dec  4 21:48:05 2019: iteration 19, lowerbound -2.299254
, Wed Dec  4 21:48:05 2019: iteration 20, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 21, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 22, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 23, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 24, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 25, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 26, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 27, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 28, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 29, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 30, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 31, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 32, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 33, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 34, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 35, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 36, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 37, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 38, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 39, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 40, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 41, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 42, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 43, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 44, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 45, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 46, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 47, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 48, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 49, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: iteration 50, lowerbound -2.299253
, Wed Dec  4 21:48:05 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398615, 178.04509222601388]
β = [95.95490777398615, 178.04509222601388]
m = [2.000229257775371 53.8519871724613; 4.250300733269908 79.28686694436183]
ν = [97.95490777398615, 180.04509222601388]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948404 -0.008953123827345958; 0.0 0.012748664777409383], [0.18404155547484194 -0.007644049042327396; 0.0 0.008581705166333407]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -1.0115602565690744
avll from llpg:  -1.0115602565690742
avll direct:     -1.0115602565690742
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9916520872323423
avll from llpg:  -0.9916520872323421
avll direct:     -0.9916520872323422
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.112837     0.0269259    -0.0131084   -0.0177508     0.139647     -0.0515339   0.154283     0.0533346   -0.0178027   0.0795564    0.0960364    0.0625218   -0.00654977   0.000776484  -0.00951615   0.0751165   -0.176577    -0.0538084   -0.0154129   -0.085949     0.0297601    -0.235575    -0.0308749    0.066427    -0.0343071    0.148722   
  0.0298789    0.117514     -0.0433415    0.035137     -0.0250074     0.100205    0.0755775    0.0472536    0.126043   -0.0771654    0.00480511   0.053414    -0.0526542   -0.137478     -0.02944      0.13705     -0.0406568   -0.153089     0.0125193    0.0506837   -0.144413     -0.159518     0.209716    -0.0339227   -0.187881     0.071184   
  0.0588341    0.0662596    -0.0732388    0.135148     -0.0505938     0.0893163  -0.0490831    0.145539     0.0303283  -0.0722806   -0.0338665    0.031024    -0.0888512   -0.123542     -0.00274703   0.146407     0.101908    -0.0766767    0.00723728   0.063092    -0.202551     -0.0494722   -0.18315      0.0655439   -0.0676552    0.0665223  
 -0.256437     0.035767     -0.0527629    0.0616129     0.0247832    -0.0814267   0.0471338   -0.097635     0.0760541   0.264082    -0.00928534   0.15663      0.0200259    0.149978      0.0553743    0.0868539    0.170183     0.141024     0.0599833    0.023841     0.0214683    -0.0269317    0.0804344   -0.0476642    0.132513    -0.000154288
  0.198639     0.105174      0.118654     0.0408874    -0.108883      0.150725    0.00861494   0.0506856    0.066809   -0.238248     0.0806487   -0.0949415    0.138011     0.0668975    -0.0279379   -0.0546094    0.0200294    0.00545374   0.0620203    0.18738      0.162329      0.171763     0.151593     0.0475936   -0.0102167   -0.0490461  
  0.143021    -0.163598      0.0120528    0.134129      0.0164141     0.108611    0.0890803   -0.00940672  -0.0112981   0.128826     0.12939     -0.113023    -0.0674447    0.154223     -0.0270636    0.123434    -0.120322    -0.111055    -0.00122056   0.0094343    0.0165406    -0.0285427   -0.0953703   -0.117207     0.0654747    0.0671337  
 -0.133895     0.00255661   -0.00928909   0.0836052    -0.0304766     0.171718    0.0172514    0.0838717    0.141857   -0.103709     0.0355689    0.028089    -0.0911779    0.0585354     0.0550102    0.0471622    0.0888237   -0.111845    -0.00627093   0.12508     -0.0683826     0.277001    -0.0579951    0.338318    -0.101072     0.0902233  
  0.0508094   -0.13521       0.0370512   -0.0412239     0.0682993    -0.148129   -0.0585012    0.0191875   -0.0451968   0.0230221    0.02575     -0.140378     0.077167    -0.0662164     0.0435589   -0.108529     0.00601984  -0.0213753    0.0974667    0.0882555    0.128332      0.0555695    0.237809    -0.143587    -0.0620656   -0.140077   
  0.109571     0.0368757     0.0978357   -0.0894971    -0.157728     -0.10484     0.145103     0.05268      0.052795    0.120361    -0.0200275   -0.0369308   -0.023771     0.0796779     0.10858      0.0319015   -0.0723938    0.142835    -0.0341828   -0.117051    -0.0283982     0.029937     0.142891    -0.0194075   -0.151249     0.0907181  
 -0.0535758    0.0105628     0.110583    -0.15839      -0.000572855  -0.0754368  -0.0386268   -0.0152249    0.0306266  -0.191683     0.0405403   -0.141393     0.142048    -0.130484     -0.0819879    0.0456614   -0.0067856   -0.193065    -0.0284685   -0.0294858   -0.176199     -0.17629      0.0137227    0.0439546   -0.0281343    0.128503   
  0.125695    -0.135366      0.175422    -0.184949      0.0535295     0.0111422   0.0755437    0.0287801    0.0473576  -0.0127587    0.298794     0.12137      0.0915812    0.0875705     0.0737433    0.100596    -0.0699994   -0.0340389   -0.00206332  -0.0899509   -0.122603      0.146411     0.0932989    0.0938519    0.128923     0.0327234  
  0.0797631    0.0359446    -0.0522647   -0.0782699     0.1555       -0.0484251   0.249063     0.126361     0.0434366  -0.109389    -0.0242367   -0.134954    -0.0983476   -0.0931458    -0.0201231   -0.0917811    0.0818298   -0.0719462   -0.0389743    0.15199     -0.135967      0.233934    -0.00761467   0.0138008   -0.0378722    0.000301376
  0.013216     0.0225265     0.0179912   -0.00480124   -0.118488      0.0604116  -0.0470045    0.00040982   0.0178796  -0.00698042  -0.0264334    0.328036    -0.0493907   -0.0344864     0.0048929    0.00861203   0.116472    -0.132804     0.0108739   -0.0787977    0.0320919    -0.00514389  -0.00280482   0.066552    -0.121062     0.015522   
  0.169019    -0.034316      0.0809501    0.18123      -0.0589339     0.064212   -0.156556     0.130214    -0.0935192   0.0415273   -0.0150829   -0.131384     0.00144589   0.0681707     0.0953332   -0.137097    -0.1774       0.00964326  -0.0915587    0.0648268    0.0970316    -0.162071    -0.173985    -0.106464     0.0571273   -0.0292575  
  0.0594377   -0.0139119    -0.0490811   -0.0278305    -0.175897     -0.0272832   0.0476943   -0.308869    -0.0165818  -0.108003    -0.0857349    0.00226606  -0.102691     0.216285     -0.00827783  -0.0827506   -0.0164706   -0.0189431    0.0861434   -0.00618131  -0.000139888  -0.0216109   -0.129299    -0.0245201    0.0709022   -0.055669   
 -0.058094    -0.0377105    -0.0253455    0.0143675    -0.00587088   -0.0392289   0.0111516    0.066354     0.117224   -0.0745347    0.139982    -0.0570457    0.0461252   -0.0383077    -0.156818     0.210157     0.0480925    0.00119465  -0.139342    -0.0928375   -0.0148685     0.0155405   -0.25745      0.0631762   -0.163857     0.110766   
 -0.0199408    0.119766      0.260527     0.137184     -0.135951      0.151329   -0.0288023    0.0979476    0.0567482   0.113057    -0.0837882    0.026391    -0.07914      0.128204      0.048997    -0.215914    -0.292496    -0.0417936   -0.161685     0.152191    -0.0733581    -0.0416826   -0.00293112  -0.17353     -0.113074    -0.0911438  
 -0.0868141    0.158887      0.127854    -0.100783      0.135451     -0.0684222   0.0140393    0.12277     -0.250132    0.0788217    0.122515    -0.15631     -0.159831     0.0744164    -0.049806     0.146113     0.0709635    0.0992549   -0.0951119    0.263815    -0.0518263     0.111827     0.103116     0.0971708   -0.137384     0.00359225 
  0.152497     0.195143     -0.0185893   -0.109991      0.102075     -0.13369    -0.122356    -0.0542116   -0.119367   -0.0155484    0.0715404    0.0126952   -0.188942    -0.192575     -0.0681354    0.10055      0.044172    -0.0196284   -0.0223324    0.147646    -0.114077      0.0175039    0.241453     0.0351988   -0.115733     0.163134   
 -0.046042    -0.0325637    -0.00604978  -0.0670576    -0.00980555   -0.120126   -0.074474    -0.085785    -0.13733    -0.0621932    0.0189757    0.0995085   -0.0565553   -0.0322139     0.204189     0.0988914    0.0942147   -0.0643523    0.0196446   -0.00292975  -0.0691868     0.103346     0.0203685    0.0678989    0.0287854   -0.100512   
  0.127165    -0.0623658    -0.0116856    0.0900726    -0.142388     -0.0187171   0.0568455   -0.140909    -0.213324   -0.0820181   -0.0721161   -0.154921     0.0544662    0.0105244     0.129326    -0.0397699   -0.0568968    0.0785565    0.0763629    0.0835622   -0.161453      0.00943433   0.0263363   -0.0646056    0.166798     0.0383966  
 -0.0571868   -0.000565072   0.0774693    0.040744     -0.0671518    -0.0789748  -0.0867104   -0.0847449    0.0886366   0.21022      0.0158699   -0.0804684   -0.177516    -0.00323365    0.0234894   -0.193672    -0.0587309   -0.0749835    0.091566    -0.199281    -0.0326618    -0.0722828   -0.152124    -0.310597    -0.00144393  -0.128867   
 -0.309603     0.109086     -0.0379589    0.102827     -0.0840044     0.0223646  -0.0803308   -0.237458    -0.132706   -0.0544917    0.0407868    0.120064    -0.129321    -0.167459     -0.0363417   -0.0348436    0.0384487    0.0413611   -0.0215112   -0.0389848   -0.00497433   -0.0383311   -0.0864167   -0.0166268   -0.0854989   -0.0588557  
  0.0795552    0.0715953    -0.150283     0.000255336  -0.0831501    -0.0873974   0.0263345    0.0250308    0.0847631   0.0968723   -0.0248047   -0.0972631   -0.0501217    0.0588543     0.0163967   -0.0813871   -0.180324     0.00427062  -0.034174    -0.161841     0.00939862    0.00536182  -0.048612     0.00584206   0.0471093    0.0474738  
 -0.175139     0.0451775     0.0252654   -0.0302851     0.155738      0.0707882   0.00710345   0.112981     0.137564   -0.15467     -0.0218403    0.0695641   -0.0373801   -0.0169915     0.241683     0.0555314   -0.011493    -0.0503336   -0.00749542  -0.068321     0.0919701    -0.260286    -0.0421768   -0.164369     0.0261067    0.31881    
  0.00327198   0.00524814    0.0696847   -0.0823501     0.111568      0.0558276   0.0541704    0.0358473   -0.0237894  -0.0324345    0.113041     0.0296379    0.199786     0.0523947     0.202245    -0.0454318    0.0225148    0.0488384    0.00794604  -0.0922104   -0.0525502     0.00170459  -0.0305835   -0.0816415   -0.178453     0.0627842  
  0.0233079   -0.0804797     0.0887145    0.143784      0.0336656     0.0350578  -0.102183     0.0468789   -0.0289215   0.0462969   -0.0750584    0.107004    -0.0577433    0.073845      0.276179    -0.0359846    0.0746223   -0.0685968    0.0841       0.182388    -0.00502255   -0.108329    -0.0367555   -0.0588144   -0.0268925   -0.00567822 
  0.116731     0.0200444     0.0890469    0.0448317    -0.0103082     0.145602   -0.0438512    0.0907156    0.0544163   0.0363184   -0.06855      0.237863     0.0215255    0.0896607    -0.0908541    0.162076    -0.327463    -0.0164998   -0.0049385    0.0458423   -0.190349      0.136118    -0.0780421    0.0605564    0.0762731    0.0516605  
  0.0210606    0.0818299    -0.0551288    0.0281962    -0.0996653    -0.0114933  -0.0560473   -0.0829118   -0.161317    0.0561538    0.0475863    0.113394     0.0972832   -0.192513      0.159469     0.029404    -0.0387623    0.0386228    0.033351     0.0804393    0.0707554     0.0200588   -0.00726978   0.169089    -0.106772    -0.172033   
 -0.0999517    0.0526574    -0.12165      0.0287867     0.0635288     0.0998524   0.0900774    0.0102966   -0.0410032  -0.0161197    0.14917      0.181344     0.0683117   -0.0293805    -0.168852     0.00843922   0.0262033   -0.054665    -0.055899    -0.0899538    0.228277      0.108115     0.119027    -0.0189346    0.0227732   -0.249603   
 -0.00163669   0.113772      0.0193108   -0.203697      0.0985288     0.151424    0.0113276   -0.209664     0.0957154   0.0468464    0.0325072   -0.02131     -0.0812634    0.072408      0.0384731   -0.0368105    0.120099    -0.0722833   -0.135385     0.0532093    0.247042      0.015569    -0.0262796    0.15756     -0.0375586    0.0489441  
  0.063282    -0.150894     -0.0679218   -0.0168612     0.0117179    -0.0774565   0.142347    -0.092192     0.118541    0.16168      0.0607792    0.0877824   -0.112287     0.00417676    0.0646529    0.0908939   -0.113231     0.122574    -0.0468658    0.245621     0.0190301    -0.00306645   0.0366312    0.0555316    0.0900985    0.0621662  kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.376783607608716
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.376860
[ Info: iteration 2, average log likelihood -1.376782
[ Info: iteration 3, average log likelihood -1.375972
[ Info: iteration 4, average log likelihood -1.365394
[ Info: iteration 5, average log likelihood -1.342579
[ Info: iteration 6, average log likelihood -1.335938
[ Info: iteration 7, average log likelihood -1.334177
[ Info: iteration 8, average log likelihood -1.333339
[ Info: iteration 9, average log likelihood -1.332905
[ Info: iteration 10, average log likelihood -1.332672
[ Info: iteration 11, average log likelihood -1.332537
[ Info: iteration 12, average log likelihood -1.332455
[ Info: iteration 13, average log likelihood -1.332401
[ Info: iteration 14, average log likelihood -1.332363
[ Info: iteration 15, average log likelihood -1.332334
[ Info: iteration 16, average log likelihood -1.332311
[ Info: iteration 17, average log likelihood -1.332292
[ Info: iteration 18, average log likelihood -1.332276
[ Info: iteration 19, average log likelihood -1.332262
[ Info: iteration 20, average log likelihood -1.332249
[ Info: iteration 21, average log likelihood -1.332237
[ Info: iteration 22, average log likelihood -1.332225
[ Info: iteration 23, average log likelihood -1.332214
[ Info: iteration 24, average log likelihood -1.332203
[ Info: iteration 25, average log likelihood -1.332191
[ Info: iteration 26, average log likelihood -1.332178
[ Info: iteration 27, average log likelihood -1.332164
[ Info: iteration 28, average log likelihood -1.332147
[ Info: iteration 29, average log likelihood -1.332130
[ Info: iteration 30, average log likelihood -1.332111
[ Info: iteration 31, average log likelihood -1.332093
[ Info: iteration 32, average log likelihood -1.332077
[ Info: iteration 33, average log likelihood -1.332062
[ Info: iteration 34, average log likelihood -1.332049
[ Info: iteration 35, average log likelihood -1.332039
[ Info: iteration 36, average log likelihood -1.332030
[ Info: iteration 37, average log likelihood -1.332024
[ Info: iteration 38, average log likelihood -1.332018
[ Info: iteration 39, average log likelihood -1.332014
[ Info: iteration 40, average log likelihood -1.332011
[ Info: iteration 41, average log likelihood -1.332009
[ Info: iteration 42, average log likelihood -1.332007
[ Info: iteration 43, average log likelihood -1.332006
[ Info: iteration 44, average log likelihood -1.332005
[ Info: iteration 45, average log likelihood -1.332004
[ Info: iteration 46, average log likelihood -1.332003
[ Info: iteration 47, average log likelihood -1.332002
[ Info: iteration 48, average log likelihood -1.332002
[ Info: iteration 49, average log likelihood -1.332001
[ Info: iteration 50, average log likelihood -1.332000
┌ Info: EM with 100000 data points 50 iterations avll -1.332000
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3768604379309217
│     -1.376781518160497 
│      ⋮                 
└     -1.3320001284408474
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.332120
[ Info: iteration 2, average log likelihood -1.331968
[ Info: iteration 3, average log likelihood -1.331097
[ Info: iteration 4, average log likelihood -1.322581
[ Info: iteration 5, average log likelihood -1.302253
[ Info: iteration 6, average log likelihood -1.292085
[ Info: iteration 7, average log likelihood -1.288816
[ Info: iteration 8, average log likelihood -1.287348
[ Info: iteration 9, average log likelihood -1.286545
[ Info: iteration 10, average log likelihood -1.286005
[ Info: iteration 11, average log likelihood -1.285541
[ Info: iteration 12, average log likelihood -1.285047
[ Info: iteration 13, average log likelihood -1.284453
[ Info: iteration 14, average log likelihood -1.283734
[ Info: iteration 15, average log likelihood -1.282918
[ Info: iteration 16, average log likelihood -1.282061
[ Info: iteration 17, average log likelihood -1.281280
[ Info: iteration 18, average log likelihood -1.280651
[ Info: iteration 19, average log likelihood -1.280170
[ Info: iteration 20, average log likelihood -1.279787
[ Info: iteration 21, average log likelihood -1.279457
[ Info: iteration 22, average log likelihood -1.279161
[ Info: iteration 23, average log likelihood -1.278879
[ Info: iteration 24, average log likelihood -1.278595
[ Info: iteration 25, average log likelihood -1.278308
[ Info: iteration 26, average log likelihood -1.278009
[ Info: iteration 27, average log likelihood -1.277696
[ Info: iteration 28, average log likelihood -1.277381
[ Info: iteration 29, average log likelihood -1.277050
[ Info: iteration 30, average log likelihood -1.276685
[ Info: iteration 31, average log likelihood -1.276283
[ Info: iteration 32, average log likelihood -1.275802
[ Info: iteration 33, average log likelihood -1.275152
[ Info: iteration 34, average log likelihood -1.274423
[ Info: iteration 35, average log likelihood -1.274003
[ Info: iteration 36, average log likelihood -1.273837
[ Info: iteration 37, average log likelihood -1.273727
[ Info: iteration 38, average log likelihood -1.273601
[ Info: iteration 39, average log likelihood -1.273456
[ Info: iteration 40, average log likelihood -1.273335
[ Info: iteration 41, average log likelihood -1.273261
[ Info: iteration 42, average log likelihood -1.273220
[ Info: iteration 43, average log likelihood -1.273197
[ Info: iteration 44, average log likelihood -1.273181
[ Info: iteration 45, average log likelihood -1.273170
[ Info: iteration 46, average log likelihood -1.273161
[ Info: iteration 47, average log likelihood -1.273153
[ Info: iteration 48, average log likelihood -1.273146
[ Info: iteration 49, average log likelihood -1.273140
[ Info: iteration 50, average log likelihood -1.273135
┌ Info: EM with 100000 data points 50 iterations avll -1.273135
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3321196495115468
│     -1.331967891304504 
│      ⋮                 
└     -1.2731346594846746
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.273289
[ Info: iteration 2, average log likelihood -1.273064
[ Info: iteration 3, average log likelihood -1.271511
[ Info: iteration 4, average log likelihood -1.260162
[ Info: iteration 5, average log likelihood -1.239448
[ Info: iteration 6, average log likelihood -1.229243
[ Info: iteration 7, average log likelihood -1.224849
[ Info: iteration 8, average log likelihood -1.221475
[ Info: iteration 9, average log likelihood -1.218885
[ Info: iteration 10, average log likelihood -1.217610
[ Info: iteration 11, average log likelihood -1.217042
[ Info: iteration 12, average log likelihood -1.216716
[ Info: iteration 13, average log likelihood -1.216456
[ Info: iteration 14, average log likelihood -1.216167
[ Info: iteration 15, average log likelihood -1.215743
[ Info: iteration 16, average log likelihood -1.215075
[ Info: iteration 17, average log likelihood -1.214158
[ Info: iteration 18, average log likelihood -1.213346
[ Info: iteration 19, average log likelihood -1.213028
[ Info: iteration 20, average log likelihood -1.212929
[ Info: iteration 21, average log likelihood -1.212869
[ Info: iteration 22, average log likelihood -1.212816
[ Info: iteration 23, average log likelihood -1.212763
[ Info: iteration 24, average log likelihood -1.212706
[ Info: iteration 25, average log likelihood -1.212649
[ Info: iteration 26, average log likelihood -1.212601
[ Info: iteration 27, average log likelihood -1.212565
[ Info: iteration 28, average log likelihood -1.212537
[ Info: iteration 29, average log likelihood -1.212515
[ Info: iteration 30, average log likelihood -1.212496
[ Info: iteration 31, average log likelihood -1.212481
[ Info: iteration 32, average log likelihood -1.212467
[ Info: iteration 33, average log likelihood -1.212455
[ Info: iteration 34, average log likelihood -1.212444
[ Info: iteration 35, average log likelihood -1.212433
[ Info: iteration 36, average log likelihood -1.212423
[ Info: iteration 37, average log likelihood -1.212413
[ Info: iteration 38, average log likelihood -1.212404
[ Info: iteration 39, average log likelihood -1.212394
[ Info: iteration 40, average log likelihood -1.212386
[ Info: iteration 41, average log likelihood -1.212377
[ Info: iteration 42, average log likelihood -1.212369
[ Info: iteration 43, average log likelihood -1.212360
[ Info: iteration 44, average log likelihood -1.212353
[ Info: iteration 45, average log likelihood -1.212345
[ Info: iteration 46, average log likelihood -1.212338
[ Info: iteration 47, average log likelihood -1.212331
[ Info: iteration 48, average log likelihood -1.212324
[ Info: iteration 49, average log likelihood -1.212317
[ Info: iteration 50, average log likelihood -1.212310
┌ Info: EM with 100000 data points 50 iterations avll -1.212310
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2732891432972635
│     -1.273063585821125 
│      ⋮                 
└     -1.2123104748995677
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.212513
[ Info: iteration 2, average log likelihood -1.212254
[ Info: iteration 3, average log likelihood -1.210577
[ Info: iteration 4, average log likelihood -1.193675
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.158227
[ Info: iteration 6, average log likelihood -1.149699
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.124557
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.120847
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.129216
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.124130
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.118417
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.119192
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.114294
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.130687
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.129554
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.111750
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.112807
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.116435
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.130790
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.123465
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.122888
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.109680
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.111498
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.133582
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.123578
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.117068
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.120822
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.108299
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.128593
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.126687
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.117356
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.115053
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     11
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.119364
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.125254
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.121473
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.120191
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.115351
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.113651
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.131150
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.118960
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.114872
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.124171
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.109021
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.121963
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.135973
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.108920
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     11
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.111925
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.135096
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.113902
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.117739
┌ Info: EM with 100000 data points 50 iterations avll -1.117739
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2125132395845448
│     -1.2122535824610752
│      ⋮                 
└     -1.1177390415591295
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.127831
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     19
│     20
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.102353
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.102518
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     19
│     20
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.091599
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.043938
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      6
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.019227
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     14
│     21
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.046562
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     14
│     19
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.019181
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.999409
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     14
│     19
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.044468
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     14
│     21
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.031744
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.007772
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│     14
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.027427
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     14
│     22
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.019446
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -0.996730
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     14
│     22
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.033613
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     14
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.026439
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.015018
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     14
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.022905
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     14
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.006450
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     10
│     14
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.012237
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.022377
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│     14
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.028240
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     10
│     14
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.016817
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      7
│      8
│     14
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -0.999199
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     14
│     21
│     22
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.034975
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -0.987926
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     14
│     21
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.028726
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      7
│      8
│     14
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -0.996840
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     10
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.024906
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     14
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.024511
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      6
│     14
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.022172
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      7
│      8
│     10
│     14
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -0.982735
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.017298
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      7
│      8
│     14
│     16
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.013469
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     10
│     14
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.038311
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      7
│      8
│     14
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.011509
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     14
│     21
│     22
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.026705
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.976231
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     14
│     16
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.038575
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      7
│      8
│     14
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.004934
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     10
│     14
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.040651
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     14
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.003103
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│     14
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.005404
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      7
│      8
│     10
│     14
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -0.991717
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.039465
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     14
│     19
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.014312
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     10
│     14
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.016124
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      7
│      8
│     14
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.002204
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     14
│     16
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.020963
┌ Info: EM with 100000 data points 50 iterations avll -1.020963
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1278305663522477
│     -1.1023534656453986
│      ⋮                 
└     -1.020962737106431 
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.376783607608716 
│     -1.3768604379309217
│     -1.376781518160497 
│     -1.3759720962615172
│      ⋮                 
│     -1.0161235107061224
│     -1.0022040464186117
└     -1.020962737106431 
32×26 Array{Float64,2}:
 -0.0555294    0.0026665    0.0950421   -0.203399     0.00462113  -0.0750938  -0.0439943   -0.0349505   0.0321438   -0.18116      0.0335163   -0.13542      0.136681    -0.119629    -0.0973064    0.0562068    0.017783   -0.190498     -0.0194289    -0.0320125   -0.191666    -0.16931      0.00537785   0.0493285   -0.0354481    0.118191   
 -0.0641565   -0.04574     -0.0381996   -0.0675893    0.0038955   -0.114176   -0.0721302   -0.0824529  -0.144818    -0.126571     0.0181803    0.105562    -0.0651054   -0.0694475    0.19804      0.0815591    0.127962   -0.0647099     0.000869556   0.0162318   -0.0657315    0.104081     0.0292336    0.0742092    0.0403006   -0.103231   
  0.0342559    0.0534061    0.131534     0.162152     0.104599     0.0404208  -0.071088     0.139201    0.0143812   -0.284108    -0.0690062    0.0485782   -0.0657937    0.0819567    0.301909    -0.0378978    0.135981   -0.0730773     0.144134      0.242637     0.0111867   -0.103496    -0.128667    -0.0616328   -0.0124307    0.00518782 
 -0.0387375   -0.150237     0.105302     0.132716    -0.0930933    0.0295869  -0.13049     -0.0242113  -0.0783343    0.289065    -0.079061     0.155635    -0.0121491    0.0733373    0.278331    -0.0284703    0.0224498  -0.0693983    -0.139379      0.10959     -0.00678388  -0.116611    -0.00160609  -0.0459237   -0.0280645   -0.0249513  
 -0.0240222   -0.0721144    0.139702     0.0456292    1.14271     -0.0802373  -0.0680906   -0.0891556   0.100935     0.215813     0.0157787   -0.122975    -0.192281     0.0745922    0.0742238   -0.198291    -0.102848   -0.0747735     0.0913743    -0.202413     0.0431996   -0.0714236   -0.108597    -0.283062    -0.0296891   -0.117795   
 -0.109114     0.151367    -0.0132257    0.0363134   -1.21206     -0.0804672  -0.0582464   -0.0949465   0.0691638    0.243279     0.0158558   -0.0689227   -0.146411    -0.0113584   -0.00388826  -0.180558    -0.0167695  -0.0750284     0.0923184    -0.205947    -0.140673    -0.0713012   -0.161027    -0.314066     0.0667178   -0.100814   
  0.121788    -0.121186     0.0926388   -0.0440836   -0.124641    -0.0878887   0.152349    -0.738063    0.0523362    0.1334      -0.0288548   -0.0508319   -0.00250447   0.0629092    0.11621      0.0325239   -0.094599    0.139827     -0.0248929    -0.127054    -0.0224072   -0.010251     0.125252    -0.107657    -0.134017     0.12739    
  0.0985015    0.126052     0.0924971   -0.145926    -0.147683    -0.0769835   0.165532     0.760073    0.0325606    0.0872956   -0.00733926  -0.0341693   -0.0244315    0.0919959    0.13107      0.0341624   -0.0887263   0.138681     -0.0359356    -0.112577    -0.0244469    0.0371178    0.186031     0.00772465  -0.139152     0.174978   
  0.193981     0.0928892    0.115892    -0.0447217   -0.108429     0.144187    0.0108669    0.03499     0.0572455   -0.258924     0.0754643   -0.0941375    0.141355     0.0567728   -0.0304391   -0.0150121    0.0218633  -0.000262147   0.0589581     0.188476     0.160696     0.157293     0.173903     0.0424081   -0.0160414   -0.0478166  
 -0.132493     0.00361068  -0.0430811    0.0870953   -0.0325329    0.172823    0.0133229    0.0756483   0.140442    -0.0817776   -0.0094663    0.0300094   -0.0850634    0.0687774    0.0623614    0.0446657    0.0862017  -0.0911498    -0.00175558    0.123676    -0.0614969    0.26284     -0.0665224    0.318307    -0.09174      0.0982906  
  0.0207298   -0.0317674    0.0374711   -0.0662615    0.0667741    0.0648615   0.0774367    0.0377865   0.00142445  -0.0145551    0.18174      0.0937169    0.101768     0.0321946    0.0308305    0.0334301    0.0098419  -0.0186797    -0.0325217    -0.0704349   -0.00333596   0.0963216    0.0600796    0.00527523   0.00337794  -0.0368998  
  0.0924274   -0.0834879   -0.0219865    0.0471179   -0.069516     0.0225859   0.0639575   -0.133582   -0.00605876  -0.0041858    0.0378868   -0.0454535   -0.0704955    0.195332    -0.0278707    0.0380678   -0.0850308  -0.059614      0.028017      0.0056303    0.00832025  -0.0215328   -0.113117    -0.0719731    0.0859422    0.018199   
  0.180711    -0.034439     0.0917768    0.20326     -0.0641328    0.0284228  -0.157324     0.12812    -0.0939306    0.0409771   -0.0164003   -0.142195     0.0481205    0.0819527    0.0956145   -0.155232    -0.177014    0.0191867    -0.0976164     0.0839069    0.0971774   -0.172273    -0.172316    -0.0922395    0.0581344   -0.0265723  
  0.0819516    0.0351862   -0.05351     -0.0764437    0.155094    -0.0615913   0.248816     0.128233    0.0388518   -0.109499    -0.0197282   -0.104547    -0.0876293   -0.0936757   -0.0217168   -0.106084     0.0772962  -0.0935236    -0.0425997     0.123829    -0.141477     0.233691    -0.0405271    0.022597    -0.00485905  -0.00142856 
 -0.107577     0.0581425   -0.0715622   -0.0189865    0.0711276   -0.0185297   0.0180549    0.0783145   0.104059    -0.0398972   -0.0503561    0.0137938   -0.0411664    0.0149566    0.123095    -0.0126734   -0.0929636  -0.0227798    -0.0158925    -0.116001     0.0462846   -0.130551    -0.0551074   -0.0706805    0.0368077    0.178375   
  0.0619891   -0.122571     0.0371483   -0.0352541    0.0652077   -0.163189   -0.042293     0.0151994  -0.0681525    0.0135858    0.0350231   -0.145153     0.0781481   -0.072135     0.0389789   -0.152654     0.0053744  -0.0183225     0.107457      0.0824164    0.127391     0.0556298    0.232803    -0.127451    -0.0580169   -0.147152   
 -0.357608     0.114698    -0.038336     0.143089    -0.087738     0.0102705  -0.0859904   -0.25322    -0.130424    -0.0783206    0.041941     0.119271    -0.156711    -0.167061    -0.0496181   -0.00646934   0.0325397   0.0445636     0.0317803    -0.039437    -0.0272498   -0.0348538   -0.0878722   -0.00613153  -0.0850386   -0.0513686  
 -0.0466575    0.0980399    0.259251     0.137653    -0.122517     0.152838   -0.0276014    0.0972983   0.0577891    0.116196    -0.0847161    0.0344187   -0.0880895    0.115918     0.0553867   -0.256148    -0.289781   -0.0591752    -0.125407      0.1523      -0.0652329   -0.0344231   -0.0154044   -0.175342    -0.110841    -0.0947575  
 -0.0877955    0.168439     0.123419    -0.0796758    0.13032     -0.0587955  -0.00433033   0.122219   -0.2411       0.0787398    0.110604    -0.158019    -0.154455     0.0955664   -0.0312538    0.0987363    0.0798798   0.0696301    -0.0945114     0.262751    -0.0510692    0.106038     0.118832     0.0789262   -0.137059     0.0132333  
  0.0146214    0.117253    -0.0442528    0.034859    -0.0295972    0.09711     0.0535456    0.0418949   0.12502     -0.0764734    0.0148134    0.0680763   -0.0319625   -0.134329    -0.0655053    0.133072    -0.03451    -0.153401      0.021556      0.0503132   -0.145275    -0.156998     0.185282    -0.0406488   -0.185173     0.0688748  
 -1.011       -0.150122    -0.0797922    0.023133     0.0639509    0.210858    0.286689    -0.0924203   0.0180004    0.169235     0.0398585    0.11611     -0.113765     0.00351982   0.115872     0.00216793  -0.139394    0.189568      0.0385407     0.189082     0.0269394   -0.0163389    0.0354683    0.0544959    0.0104263    0.140232   
  0.267039    -0.149118    -0.0516738   -0.0284596   -0.0114555   -0.147853    0.140932    -0.088996    0.142416     0.157266     0.0606116    0.081082    -0.117694     0.00343144   0.0596889    0.125997    -0.0912771   0.111898     -0.0626135     0.291078    -0.00535753   0.00117956   0.0113741    0.0590136    0.101799     0.0383192  
  0.0296105    0.0230103    0.0170033   -0.00792558  -0.128082     0.060708   -0.051141    -0.0150957   0.00914872  -0.00515391  -0.0303691    0.318381    -0.0456769   -0.0527024    0.0102825    0.0123562    0.10847    -0.117763      0.00269292   -0.0681973    0.0301737    0.0101      -0.00417596   0.0800739   -0.110349    -0.000884142
  0.119079     0.027746    -0.00944389  -0.0130392    0.131012    -0.0517716   0.171452     0.0582976   0.0120583    0.0817557    0.0893825    0.0988916   -0.0299224    0.00832855   0.0134806    0.0539424   -0.172691   -0.0535572    -0.0042275    -0.0850758    0.0309104   -0.234649    -0.010706     0.0661277   -0.0346119    0.176319   
  0.1183       0.0305852    0.0129576    0.141625    -0.0450495    0.0819112  -0.0374892    0.117885   -0.0197459   -0.0626447   -0.0705352    0.0526568   -0.0768018   -0.133709     0.0106824    0.131159     0.108189   -0.0719966     0.00859042    0.0545761   -0.214196    -0.115475    -0.154023     0.0654337   -0.0793966    0.0908884  
  0.0214702    0.0825361   -0.0558958    0.0684799   -0.113536    -0.012715   -0.0514311   -0.0758962  -0.208239     0.0552465    0.0345291    0.10215      0.0941905   -0.19189      0.148899     0.0279382   -0.0419461   0.048704      0.0397159     0.062544     0.104457     0.0169759   -0.00144301   0.168558    -0.0889598   -0.18706    
  0.164544     0.246869    -0.195058    -0.263243     0.0887771   -0.129726   -0.124895    -0.147571   -0.088627     0.015586     0.1176       0.0968907   -0.192934    -0.091026    -0.0834868    0.0719592    0.0447351  -0.0276677     0.0913799    -0.0248072   -0.115489     0.112456    -0.530363     0.0349367    0.0305575    0.113259   
  0.154216     0.196872     0.102467    -0.0312994    0.132077    -0.136054   -0.12159     -0.125255   -0.161619    -0.0442757   -0.0157555   -0.0418499   -0.191496    -0.291691    -0.0919377    0.105177     0.0426173  -0.0225525    -0.143811      0.344453    -0.108319    -0.115634     0.911009     0.0353763   -0.340385     0.232622   
  0.131103    -0.0523894   -0.0514734    0.0901684   -0.155755    -0.0171789   0.0317938   -0.113033   -0.195411    -0.0869598   -0.0717246   -0.192539     0.0625698    0.0163435    0.130197    -0.0920933   -0.0522271   0.0795279     0.089583      0.0298328   -0.156725    -0.00985254   0.0363536   -0.0688355    0.176911     0.0391657  
 -0.00271289   0.139135    -0.0404318   -0.196406     0.0968037    0.154873    0.0114939   -0.232174    0.0913125    0.0513794    0.0308044   -0.00498332  -0.0749155    0.069184     0.0571861   -0.0220457    0.111535   -0.0592994    -0.163227      0.102801     0.25033      0.0315349   -0.0291375    0.146745    -0.0511677    0.041279   
  0.132218     0.0196916    0.122961     0.0475734   -0.0283465    0.143235   -0.0452433    0.179599    0.0659646    0.0411137   -0.0766569    0.232335     0.0231545    0.07862     -0.127367     0.142797    -0.320489   -0.0159886    -0.0450758     0.0496632   -0.191248     0.132461    -0.0747548    0.0828498    0.103311     0.0546553  
 -0.127081     0.00733223  -0.0473195    0.0458877    0.013066    -0.0348171  -0.0101592    0.035146    0.137332     0.0843184    0.0437226    0.0371014    0.0129109    0.0238848   -0.0461716    0.139429     0.137037    0.0426344    -0.0279945     0.00179354  -0.0339088   -0.0329718   -0.10614      0.0250909   -0.00772163   0.0559707  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.987431
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.968382
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.977300
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.963922
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.974809
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.974562
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.979840
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.965300
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.975473
kind diag, method kmeans
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.974561
┌ Info: EM with 100000 data points 10 iterations avll -0.974561
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.097779e+05
      1       6.346952e+05      -1.750827e+05 |       32
      2       6.042702e+05      -3.042503e+04 |       32
      3       5.892511e+05      -1.501905e+04 |       32
      4       5.811581e+05      -8.093010e+03 |       32
      5       5.759358e+05      -5.222292e+03 |       32
      6       5.730860e+05      -2.849811e+03 |       32
      7       5.715186e+05      -1.567435e+03 |       32
      8       5.700588e+05      -1.459760e+03 |       32
      9       5.684129e+05      -1.645965e+03 |       32
     10       5.673189e+05      -1.093970e+03 |       32
     11       5.666251e+05      -6.938215e+02 |       32
     12       5.662114e+05      -4.136233e+02 |       32
     13       5.660132e+05      -1.982083e+02 |       32
     14       5.659012e+05      -1.120542e+02 |       32
     15       5.658371e+05      -6.412873e+01 |       32
     16       5.657938e+05      -4.328824e+01 |       32
     17       5.657651e+05      -2.869291e+01 |       31
     18       5.657468e+05      -1.830130e+01 |       32
     19       5.657350e+05      -1.177329e+01 |       30
     20       5.657277e+05      -7.303488e+00 |       28
     21       5.657209e+05      -6.800269e+00 |       30
     22       5.657153e+05      -5.644841e+00 |       29
     23       5.657116e+05      -3.695082e+00 |       25
     24       5.657072e+05      -4.320849e+00 |       27
     25       5.657042e+05      -2.992588e+00 |       24
     26       5.657023e+05      -1.959773e+00 |       24
     27       5.657003e+05      -2.033942e+00 |       21
     28       5.656983e+05      -1.955519e+00 |       20
     29       5.656968e+05      -1.457337e+00 |       23
     30       5.656953e+05      -1.568279e+00 |       17
     31       5.656945e+05      -8.013005e-01 |       11
     32       5.656939e+05      -5.385440e-01 |       11
     33       5.656937e+05      -2.704073e-01 |        8
     34       5.656935e+05      -1.560503e-01 |        5
     35       5.656934e+05      -9.852316e-02 |        6
     36       5.656933e+05      -1.014291e-01 |        3
     37       5.656933e+05      -3.144905e-02 |        0
     38       5.656933e+05       0.000000e+00 |        0
K-means converged with 38 iterations (objv = 565693.2718264393)
┌ Info: K-means with 32000 data points using 38 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.278671
[ Info: iteration 2, average log likelihood -1.239753
[ Info: iteration 3, average log likelihood -1.200448
[ Info: iteration 4, average log likelihood -1.151877
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.087379
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│     15
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.051550
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     13
│     18
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.054228
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.065053
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      8
│     12
│     15
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.003463
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.075763
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     13
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.022697
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.031805
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      8
│     11
│     12
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -0.995739
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.043508
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     18
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.020657
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.022287
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│      6
│      8
│      ⋮
│     15
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -0.989215
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.065621
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     18
│     23
│     28
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.006326
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.032334
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      8
│      9
│     12
│     13
│     15
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -0.999497
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.057899
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     18
│     23
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.009319
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.037636
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     12
│     15
│     19
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -0.964547
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      6
│      8
│     13
│     23
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.014328
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.074011
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.028335
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      9
│     11
│     12
│     15
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -0.970515
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      8
│     13
│     16
│     22
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.030397
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.063662
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.019497
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      9
│     12
│     15
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -0.984499
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     13
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.039621
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     16
│     23
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.025810
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     18
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.018899
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     12
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.006559
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.029652
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     16
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.018782
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      9
│     11
│     18
│     22
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -0.992996
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     12
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.033035
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│     13
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.040469
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      8
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.047437
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     18
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.000687
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│     11
│     12
│      ⋮
│     22
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -0.986895
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.059942
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      8
│      9
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.045341
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.031908
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      4
│      6
│     12
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.008537
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.030935
┌ Info: EM with 100000 data points 50 iterations avll -1.030935
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.026319     0.0798157    -0.0494289    0.0989796   -0.144606     -0.009204    -0.0443793   -0.0833348   -0.246649     0.0438647    0.0228198     0.0962392     0.085078   -0.189111    0.204968     0.0134005   -0.0369337    0.0432742    0.0325063    0.0829341   0.157093     0.0148607   -0.0142276     0.170793    -0.0671199   -0.290514   
  0.0140023    0.114189     -0.0417793    0.0311102   -0.0248002     0.0950252    0.0599374    0.0485212    0.120176    -0.0693855    0.0164257     0.0724666    -0.0397733  -0.13396    -0.0644861    0.127959    -0.0393559   -0.150162     0.017761     0.0538664  -0.142197    -0.161942     0.184926     -0.0354873   -0.181947     0.0735502  
  0.0664013    0.296169     -0.0501329   -0.205696    -0.0470946    -0.0168581    0.00862808  -0.0948049   -0.195761    -0.00585677   0.0063771     0.239719      0.0300378  -0.133392   -0.130687     0.124313     0.00644756  -0.0201202    0.0155766    0.18572    -0.161746     0.143451     0.11513       0.0929962   -0.0724666    0.278704   
 -0.055734     0.143432      0.0978281   -0.0928416    0.167649     -0.070646     0.0456043    0.140035    -0.178583     0.0319618    0.0784229    -0.159483     -0.157623    0.0597892  -0.0283565    0.111829     0.0987537    0.0504135   -0.0797207    0.236038   -0.0659329    0.173912     0.120132      0.0790961   -0.12717      0.0111046  
 -0.0475568    0.0983635     0.259548     0.137786    -0.121954      0.152771    -0.0276151    0.0973347    0.0577213    0.116212    -0.0852819     0.0341183    -0.0870263   0.116384    0.0556582   -0.255952    -0.288618    -0.0596035   -0.125131     0.152325   -0.0656342   -0.0345558   -0.0145324    -0.175477    -0.110863    -0.094818   
  0.16537     -0.0119143     0.0957528   -0.084755    -0.233226     -0.116466     0.198717     0.054011     0.0554384    0.108233    -0.00867087   -0.0406556    -0.0447403   0.143712    0.127161    -0.0233554   -0.121091     0.0709771    0.011923    -0.143674   -0.0241423    0.00425645   0.177712      0.0415717   -0.152247     0.392042   
 -0.212264     0.0321296     0.0181783   -0.0479068    0.217474      0.0616679    0.00199918   0.127428     0.130445    -0.147534    -0.0167711     0.140216     -0.0297995  -0.0265386   0.232574     0.0567846   -0.00759189  -0.0502163   -0.00578685  -0.062336    0.10174     -0.262879    -0.0589689    -0.1621       0.025097     0.32166    
  0.0714382    0.057508     -0.028527     0.133769    -0.0533152     0.0781959   -0.0700994    0.122796     0.0167326   -0.0599832   -0.0448396     0.060667     -0.0732548  -0.134344    0.014418     0.131826     0.0982241   -0.0694739    0.0131513    0.0683592  -0.186942    -0.0489377   -0.156863      0.0719548   -0.0677922    0.0775744  
  0.015221     0.123062     -0.0382781   -0.179647     0.0836865     0.145614     0.00740963  -0.229914     0.0944048    0.040336     0.0218573     0.000603004  -0.0637932   0.0605893   0.0660569   -0.029581     0.101079    -0.0660534   -0.135975     0.0929445   0.218309     0.0121941   -0.0281898     0.128445    -0.0273464    0.0418509  
  0.180496    -0.0341176     0.0908264    0.202035    -0.0668432     0.0302021   -0.15625      0.128064    -0.0935558    0.0406419   -0.0164733    -0.143557      0.047098    0.081002    0.095208    -0.151764    -0.177005     0.0185178   -0.0974482    0.0844607   0.0970055   -0.173613    -0.172189     -0.092923     0.0575838   -0.0264296  
 -0.0862779    0.0278611    -0.153273     0.02648      0.0314462     0.0842573    0.103701     0.014398    -0.0530349   -0.0152981    0.134472      0.160604      0.0536846  -0.0149809  -0.158049     0.0119794    0.0158995   -0.0541526   -0.0748772   -0.0539167   0.220818     0.103751     0.132691     -0.015942     0.085179    -0.246735   
  0.0946104    0.0480088    -0.0300185   -0.0600448    0.347196     -0.0419525    0.258267     0.142985     0.0603221   -0.102478    -0.00968342   -0.126654     -0.108345   -0.156115   -0.0158764   -0.253948     0.0820626   -0.0906582   -0.0123228    0.0577539  -0.220206     0.191418    -0.0562075    -0.00708981   0.00961519  -0.00232456 
  0.131538     0.0203089     0.123494     0.0489839   -0.0319283     0.142144    -0.0455001    0.178068     0.0676102    0.0427394   -0.0746169     0.233894      0.0233689   0.0785971  -0.132042     0.144841    -0.320227    -0.0158211   -0.0446064    0.0501695  -0.192939     0.133297    -0.0745621     0.0830689    0.102746     0.0557924  
  0.192282     0.0935123     0.116233    -0.0438519   -0.107496      0.146313     0.0107601    0.0378046    0.0567813   -0.259272     0.079091     -0.0943201     0.141676    0.056995   -0.0301768   -0.0152736    0.0212829    0.00240208   0.0579191    0.192219    0.160253     0.161759     0.177555      0.0418215   -0.0181924   -0.0490419  
 -0.239574     0.0143       -0.0563017    0.0448229    0.0320615    -0.0868888    0.0475676   -0.0628577    0.129401     0.256602    -0.0252444     0.135507      0.0229724   0.129477    0.0485996    0.0873437    0.170414     0.125676     0.0477817    0.0420451   0.0383316   -0.036422     0.0506427    -0.0276298    0.143267     0.000214346
 -0.0194063   -0.136132     -0.0584675   -0.0140558    0.00594697   -0.0701125    0.173741    -0.0855542    0.115293     0.151761     0.05707       0.0915352    -0.113307   -0.0017111   0.0687318    0.105768    -0.0991416    0.128786    -0.0462491    0.266563    0.0032795    0.00435473   0.0241091     0.0593816    0.0685953    0.0510448  
  0.0139141    0.0036595     0.0677169   -0.083006     0.108145      0.0416907    0.049287     0.0420011   -0.0125826   -0.0354338    0.11223       0.0126282     0.193358    0.0581672   0.172969    -0.0541038    0.0491038    0.0476289    0.00467669  -0.0660481  -0.0499856    0.00363386  -0.0278328    -0.0876065   -0.179865     0.0378344  
  0.124013    -0.0471404    -0.0498076    0.0885464   -0.200163     -0.0298432    0.0693704   -0.119222    -0.206974    -0.0854083   -0.0747923    -0.237135      0.0525157   0.0234973   0.126469    -0.137707    -0.0535191    0.110849     0.076961     0.0311651  -0.148431     0.00430888   0.0353215    -0.0647069    0.171923     0.037661   
 -0.0906383    0.052123      0.0769117    0.00697549  -0.135809     -0.0954807   -0.0900073   -0.0878757    0.0755283    0.261074     0.000252182  -0.104843     -0.125458    0.0275889   0.0265194   -0.106967    -0.0745346    0.0236623    0.0291256   -0.178923   -0.0265297   -0.0347848   -0.120835     -0.428181     0.00128086  -0.315216   
  0.137368    -0.153567      0.020893     0.12986      0.0126689     0.0883854    0.0899107   -0.00838991  -0.00424961   0.122101     0.0976504    -0.104746     -0.0834251   0.171045   -0.0304892    0.132477    -0.135854    -0.0983338   -0.00827748   0.0207449   0.0145755   -0.0349192   -0.0952454    -0.126857     0.0943075    0.0817357  
 -0.356294     0.114948     -0.0382918    0.143319    -0.0871052     0.0104648   -0.0861684   -0.251387    -0.130715    -0.0784062    0.0424165     0.119193     -0.156553   -0.16685    -0.0471684   -0.00679073   0.0323484    0.0443221    0.0313474   -0.038678   -0.027963    -0.0348172   -0.0864958    -0.0044515   -0.0851622   -0.0513143  
  0.0917799   -0.0431078    -0.0418962   -0.0794279   -0.143416     -0.0478012    0.0617493   -0.210934    -0.0177239    0.0251999    9.55426e-5    0.0130844    -0.0700671   0.0373686  -0.0222727   -0.0475692   -0.0336012   -0.007946     0.0728389   -0.0168333  -0.00695981  -0.0339884   -0.0598235     0.0121531    0.147712    -0.0235529  
  0.146771     0.204639     -0.0372225   -0.120639     0.0980275    -0.11866     -0.124114    -0.124364    -0.12513     -0.0112907    0.0453378     0.029601     -0.174609   -0.191727   -0.0833644    0.0881427    0.0393629   -0.0231764   -0.021333     0.162337   -0.111744     0.0031881    0.196315      0.0391762   -0.163139     0.166179   
 -0.0716554   -0.0441191    -0.0345798   -0.0628213   -0.000901317  -0.113119    -0.075161    -0.085095    -0.131132    -0.105612     0.0159237     0.0971041    -0.0737299  -0.0437214   0.203686     0.0678928    0.12105     -0.0660277    0.00156204   0.0164048  -0.0686972    0.0945712    0.0290113     0.0597836    0.0439034   -0.101437   
  0.0833319    0.0268633     0.00472081  -0.00995554   0.00869643   -0.00554806   0.0683662    0.0306407    0.00549808   0.0411721    0.0291081     0.215002     -0.0330258  -0.0198363   0.00954866   0.0323307   -0.0361852   -0.0840786   -0.00421802  -0.0779589   0.0287357   -0.11689     -0.00270906    0.0737635   -0.069326     0.0899201  
  0.123016    -0.121191      0.160817    -0.180212     0.0377663     0.0339812    0.0793836    0.0164917    0.0549067   -0.0109505    0.28915       0.112412      0.0857367   0.0780392   0.0825112    0.0945359   -0.0646305   -0.0222575   -0.0247888   -0.0926751  -0.140319     0.142001     0.0827589     0.09482      0.10959      0.0537652  
 -0.0291205   -0.0282003     0.113087     0.13441     -0.020924      0.0331261   -0.103194     0.0403674   -0.0207145    0.0470351   -0.0622016     0.075925     -0.0628988   0.0664338   0.265798    -0.0420536    0.0613349   -0.0695752    0.0149199    0.12386    -0.019206    -0.105022    -0.0699587    -0.0783378   -0.0185599   -0.0185156  
 -0.0540702   -0.0254122    -0.0321483    0.00665131   0.014968     -0.0392427   -0.00979316   0.0753454    0.111066    -0.0494811    0.166141     -0.0948654     0.0441323  -0.0390077  -0.148167     0.205908     0.084193    -0.00286604  -0.126831    -0.0571058  -0.0311154    0.0128278   -0.24479       0.0726375   -0.160191     0.123237   
 -0.0646212    0.000844285  -0.0512582    0.0445169   -0.0836976     0.0955084    0.0247321   -0.0745685    0.0843972   -0.101858    -0.0463431     0.0191879    -0.096227    0.156881    0.0317692    0.00186474   0.0443308   -0.0743877    0.0307503    0.0776179  -0.0376671    0.151113    -0.0965869     0.193409    -0.0269096    0.0398895  
 -0.0567019    0.00574891    0.0915338   -0.188203     0.0152466    -0.0750773   -0.0396258   -0.029085     0.0371775   -0.189349     0.0314838    -0.139779      0.135756   -0.124286   -0.0935803    0.0491873    0.0217059   -0.188334    -0.0104391   -0.0359071  -0.191541    -0.17221     -0.000116093   0.0437565   -0.0292366    0.127738   
  0.00922091   0.0803289    -0.153213     0.00422802  -0.0648207    -0.0969915    0.0343978    0.0312523    0.0854828    0.0717337   -0.0948357    -0.108893     -0.0497376   0.0570307   0.0221606   -0.0831064   -0.177736     0.00445102  -0.0192333   -0.16187     0.00160457  -0.00803958  -0.0491223     0.00711214   0.0486251    0.0436954  
  0.0687752   -0.118892      0.034934    -0.0359035    0.0674885    -0.159724    -0.0386239    0.0158358   -0.0663276    0.0163578    0.0333522    -0.147786      0.0771912  -0.0593868   0.040494    -0.166368     0.00660358  -0.0218991    0.104286     0.0791767   0.123783     0.0587824    0.220976     -0.126279    -0.0612025   -0.144931   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│      9
│     11
│     13
│      ⋮
│     25
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.998880
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.923148
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      6
│      8
│      9
│     11
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.964046
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.931600
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      6
│      8
│      9
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.963580
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.941683
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      6
│      8
│      9
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.967200
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      4
│      8
│      9
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.939125
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      6
│      8
│      9
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.958331
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      4
│      8
│      9
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.950260
┌ Info: EM with 100000 data points 10 iterations avll -0.950260
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0504473   -0.113611      0.0445136     0.0384906    0.0740953    0.0677225    0.081295     0.0595488    0.003664    -0.0525225    0.261684    -0.00372904   0.103239    -0.0955035    -0.0834314    0.0231872    0.270093      0.0275004   -0.115158    -0.0672415   0.0517154   -0.137651     0.0387264    0.0190089   -0.160407     0.0132997
 -0.175338    -0.0127658     0.00157624    0.059332    -0.111295    -0.0151954    0.108963    -0.0807527   -0.107717    -0.034986    -0.182485    -0.0467383   -0.0670729    0.0764305    -0.00738485   0.112041     0.0547055    -0.0968069   -0.157333    -0.0949975  -0.0298474   -0.0530189   -0.0864824   -0.0344278    0.0720246   -0.0617591
 -0.0770953    0.0319116    -0.0979659    -0.00619392  -0.0360969   -0.0964886    0.203217     0.131698     0.0898375   -0.110219    -0.0869892   -0.13292     -0.0233063    0.0333942     0.101261     0.163401    -0.172628     -0.0902743    0.100009     0.165366   -0.0721984   -0.0438153   -0.0401458   -0.0426477   -0.012779    -0.0911707
  0.0257302   -0.196014     -0.130934     -0.0163817   -0.252321    -0.143285     0.00495462   0.0086859   -0.0767012   -0.120255     0.0635317    0.0447651   -0.00928899  -0.100082     -0.022055    -0.0208622   -0.0178948    -0.139903    -0.0314962   -0.052079   -0.149131     0.0568003   -0.0714675   -0.00463406   0.0679492   -0.0894323
  0.0401251   -0.000199773  -0.0373402    -0.0324174   -0.0822535    0.0970505   -0.019814    -0.124968    -0.115776    -0.0817804   -0.0973445   -0.0522008   -0.0595949   -0.015995     -0.0393354   -0.0874135   -0.08701       0.0687456    0.111134    -0.0397704   0.061174     0.0339337   -0.122004    -0.0954058   -0.00571666  -0.0800471
  0.0579573    0.121834      0.0200166    -0.0321716   -0.0902983   -0.0214289    0.105034     0.0903011   -0.16152      0.0460791    0.118773     0.0348145    0.0900963   -0.0213691     0.00345404   0.130621    -0.0664974    -0.0664473   -0.0499167   -0.143412   -0.00654902   0.0829332   -0.0137906   -0.0357891    0.138547    -0.0295637
  0.0647751   -0.149414     -0.152735      0.0810858   -0.150452     0.307565    -0.016003    -0.111866    -0.0392435   -0.0792485    0.114703     0.10773      0.0285909    0.0905509     0.00805052  -0.0264726    0.0498764     0.118051    -0.0356538    0.094783    0.0896982    0.205189    -0.00882572   0.0668015   -0.0360304   -0.05039  
  0.036308     0.0202039     0.000920395  -0.160182    -0.0826859    0.0977178    0.0713558    0.00540308  -0.0348782    0.0481645   -0.0373226    0.162363    -0.00112544  -0.0851389     0.0405891   -0.0750425    0.00432483    0.0982605   -0.105558    -0.165842   -0.0124834   -0.0728774    0.108129    -0.0600784    0.113461    -0.0233821
  0.156024    -0.139567     -0.0961566    -0.199705     0.083727     0.134364     0.101599     0.104884    -0.0203588   -0.0331294   -0.0780775   -0.0479821    0.0810446   -0.132493     -0.0312161   -0.138771     0.145621     -0.00107885  -0.054903    -0.0479773  -0.00244145  -0.0625813   -0.0930373   -0.0615767    0.212116    -0.0528668
 -0.0511664    0.221477     -0.0354684    -0.0035289   -0.0202253   -0.0692585    0.104621    -0.142612     0.0590758   -0.0428012    0.0928508   -0.250129     0.0514081    0.0312685    -0.144862     0.186279    -0.152356      0.0168556    0.096052    -0.139675    0.103012     0.134436    -0.16777      0.224807    -0.0363657    0.154699 
  0.272662    -0.171396      0.0701035     0.112531    -0.010528     0.229225     0.163053    -0.131219     0.0126437   -0.124532     0.0100044   -0.0836926   -0.0717675   -0.0973806     0.0572148   -0.0313489    0.0073161     0.275043     0.0724022    0.283235   -0.0887547    0.00455748  -0.0161396   -0.144377    -0.0236658   -0.0516433
 -0.0751004    0.0292642    -0.0841907     0.0418837   -0.00973346   0.114212     0.1991       0.126432    -0.147952     0.0483016    0.0149893    0.173185    -0.0777227   -0.115196      0.00834339   0.0154436    0.0540631     0.219814     0.037046     0.115599   -0.0706064   -0.0589505   -0.00427903  -0.126923    -0.158363     0.149409 
  0.0198156   -0.00315989    0.111255      0.042833     0.202399    -0.0489815    0.113052    -0.0512751   -0.0113036   -0.0202795   -0.150146    -0.0764934   -0.0473029    0.151628      0.0587918   -0.0989577    0.216707      0.0657942   -0.0623792    0.0677564   0.106538    -0.080166    -0.101057     0.0616899    0.00557479   0.178058 
  0.0341871   -0.14529      -0.0687079     0.100568    -0.113493    -0.0698293   -0.15732     -0.00135392  -0.0213473    0.0352429    0.0966      -0.0620144   -0.081191     0.173407     -0.0203383    0.0147968   -0.0212814    -0.0102563    0.121405     0.0720403  -0.0687125    0.0170492   -0.146493    -0.135443     0.0302932   -0.0291466
  0.0172216    0.0911637     0.0780554    -0.0681411    0.0185353    0.238757    -0.0701658    0.0498122    0.199399     0.119367     0.138219     0.162233    -0.0086795    0.0210942    -0.200858    -0.119875    -0.0481559    -0.144341     0.121099    -0.0953227   0.118201    -0.0861065   -0.0985246    0.0399838   -0.0529132    0.0357436
 -0.0644262   -0.0600416     0.132785     -0.0454323   -0.182548    -0.20366     -0.139332     0.0322945   -0.0438996   -0.11269      0.170148    -0.118738     0.0584846   -0.193816     -0.0290896    0.0786758    0.0380039     0.0606945   -0.150488     0.0751767   0.113512    -0.078674    -0.0199584    0.103235     0.0364191    0.0638249
 -0.0642927   -0.0223316    -0.0837963     0.100338    -0.00211095  -0.0631268   -0.0535026   -0.0350482    0.0893135   -0.045489     0.104631    -0.0811415   -0.193891     0.0468829    -0.00743921  -0.0332242   -0.000334638   0.0986307    0.0343846    0.0940807   0.0493089    0.19826     -0.182803    -0.251916     0.0461362   -0.132223 
 -0.057372    -0.189626      0.0208295     0.0388596   -0.110289     0.224573     0.060847     0.0956577   -0.0479846   -0.0221352   -0.039723    -0.0401371    0.0437396   -0.00978652   -0.010781    -0.0539992   -0.0873098     0.0404337    0.041589    -0.0964976  -0.0188548   -0.121        0.150514    -0.167795    -0.0872576   -0.0798717
  0.00124709  -0.113974      0.0652282    -0.197863    -0.0406685   -0.181203    -0.158411    -0.267984     0.0809069    0.0485287    0.143341     0.048093    -0.0502037    0.211823     -0.0130835    0.0241007    0.0947352     0.0727926    0.0401209    0.110221    0.084885    -0.0290829   -0.211662    -0.0288697   -0.0230424   -0.248086 
 -0.169338     0.0746505    -0.0111027     0.189423    -0.0780532   -0.230489    -0.0259711   -0.00353492  -0.176944    -0.0212147   -0.151241     0.0427282   -0.0169172   -0.167242      0.0492775   -0.0415331    0.0555167     0.240458    -0.101546    -0.011294    0.13503     -0.00790412  -0.202449    -0.0188937   -0.152219     0.0174011
  0.00398195   0.000539011  -0.25859      -0.160815     0.215664     0.115934    -0.0638881   -0.0457738    0.120249     0.115816    -0.0798457   -0.100367    -0.0863311    0.065534     -0.115671     0.0576707   -0.0537744     0.0940236   -0.164346     0.0699696   0.00556505   0.124195    -0.0955318   -0.11033     -0.0870831   -0.0678627
 -0.0518746    0.0262266    -0.0139815    -0.016181     0.0291087    0.00477804  -0.283951     0.0617476    0.0972604    0.11139     -0.179567     0.103743    -0.0429808   -0.0276566    -0.200598    -0.0721728    0.0160701     0.0111149    0.0837327    0.125503   -0.118542     0.110017     0.165237    -0.0385751    0.0407906    0.27591  
 -0.0493402    0.0617198    -0.0656694    -0.127721    -0.190408     0.0254018    0.219833    -0.148619     0.0434815    0.0373175   -0.118725    -0.0379496    0.0613979    0.185216     -0.113567     0.0246365    0.0240789     0.0908624   -0.0213363   -0.198877    0.0602667    0.0225643   -0.00748985  -0.147347     0.116293     0.07564  
 -0.194689     0.124782     -0.0120574     0.0451493   -0.144876     0.133981    -0.0701102    0.0327188    0.129211    -0.134794     0.0467885    0.0596125    0.134928    -0.061112      0.126856    -0.0999647    0.0683294     0.0901921    0.0288344    0.0601992  -0.131437    -0.0104459    0.145548     0.165612     0.0912232   -0.0858007
  0.0431219    0.0286988     0.154413      0.0516936    0.103919    -0.135377     0.199512    -0.041885    -0.224141     0.0567027   -0.122357    -0.178448     0.00992385   0.0860841     0.119622     0.0928307    0.0442626     0.00862772   0.0526913    0.0557748  -0.201265    -0.0673722   -0.0111885    0.0291079   -0.0855287   -0.0345006
  0.173468     0.0986201    -0.0981417     0.173129    -0.159338    -0.0292066    0.102424     0.0649597   -0.16173     -0.0118033    0.083953    -0.111751     0.124358    -0.0128579     0.0230982   -0.0208873   -0.0697712    -0.0941797    0.00402216   0.205324   -0.112092     0.0843656    0.0798075    0.0555519   -0.105206     0.164788 
  0.138863    -0.0372574    -0.0830299     0.010957    -0.0250003   -0.174206    -0.0561833   -0.0618542   -0.126652     0.0679687   -0.0367202    0.127658    -0.0502718    0.0528644    -0.0466748   -0.0723931   -0.0773993    -0.012311    -0.111556    -0.106451    0.145815     0.175726     0.0451465   -0.00315047  -0.103885     0.053384 
  0.0108461   -0.0374107     0.0227811     0.0652115   -0.0187026    0.187491    -0.0123607    0.0159747   -0.00889443   0.0818563   -0.00687276  -0.0510421   -0.11564      0.175426      0.083582     0.0110792    0.145811      0.0590927   -0.182354    -0.0221712   0.0534269    0.0545791    0.104188    -0.0977334   -0.0234246    0.0929754
  0.185015    -0.0624215     0.0750337     0.0766988    0.0861164    0.0168362   -0.0489213    0.0686058    0.0320165    0.0132516   -0.0393702    0.00649223   0.200185     0.000526186  -0.011032    -0.189542     0.0176679    -0.0124968   -0.139052     0.0709709   0.0459128    0.0593166   -0.1072      -0.00321135  -0.00229096   0.0168789
 -0.0522893    0.118958      0.0999956    -0.0378081   -0.0211307   -0.0824621   -0.15679     -0.127044     0.00170415  -0.00549256  -0.0110391   -0.0244994   -0.00775013   0.0500526    -0.0968619   -0.0862383   -0.0470076    -0.1537      -0.030187    -0.112959    0.150812     0.191524    -0.219884    -0.0515629    0.0766935   -0.0129041
  0.10931      0.0453506    -0.237181     -0.115514    -0.117065    -0.0134958   -0.0362881   -0.0303137   -0.0987952   -0.197533    -0.0921729   -0.0153274   -0.0373003    0.202359     -0.198786    -0.00347659  -0.129788      0.0414226    0.0118659    0.151636   -0.0838912    0.0496826   -0.0912277   -0.0748956    0.0490658   -0.0225488
  0.0140884   -0.00739111    0.0977109     0.0203525    0.0701749   -0.11697      0.0321784   -0.112437    -0.0896616   -0.112977    -0.0765671    0.115367     0.219107     0.0636334    -0.113639    -0.0613411   -0.0478255    -0.14325     -0.310078    -0.0420806   0.0564182    0.135034    -0.141653    -0.060456     0.226281     0.102681 kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4288854363880277
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428905
[ Info: iteration 2, average log likelihood -1.428828
[ Info: iteration 3, average log likelihood -1.428764
[ Info: iteration 4, average log likelihood -1.428687
[ Info: iteration 5, average log likelihood -1.428591
[ Info: iteration 6, average log likelihood -1.428476
[ Info: iteration 7, average log likelihood -1.428345
[ Info: iteration 8, average log likelihood -1.428195
[ Info: iteration 9, average log likelihood -1.427999
[ Info: iteration 10, average log likelihood -1.427690
[ Info: iteration 11, average log likelihood -1.427161
[ Info: iteration 12, average log likelihood -1.426324
[ Info: iteration 13, average log likelihood -1.425261
[ Info: iteration 14, average log likelihood -1.424301
[ Info: iteration 15, average log likelihood -1.423700
[ Info: iteration 16, average log likelihood -1.423413
[ Info: iteration 17, average log likelihood -1.423294
[ Info: iteration 18, average log likelihood -1.423246
[ Info: iteration 19, average log likelihood -1.423227
[ Info: iteration 20, average log likelihood -1.423218
[ Info: iteration 21, average log likelihood -1.423215
[ Info: iteration 22, average log likelihood -1.423213
[ Info: iteration 23, average log likelihood -1.423211
[ Info: iteration 24, average log likelihood -1.423211
[ Info: iteration 25, average log likelihood -1.423210
[ Info: iteration 26, average log likelihood -1.423209
[ Info: iteration 27, average log likelihood -1.423209
[ Info: iteration 28, average log likelihood -1.423209
[ Info: iteration 29, average log likelihood -1.423208
[ Info: iteration 30, average log likelihood -1.423208
[ Info: iteration 31, average log likelihood -1.423208
[ Info: iteration 32, average log likelihood -1.423207
[ Info: iteration 33, average log likelihood -1.423207
[ Info: iteration 34, average log likelihood -1.423207
[ Info: iteration 35, average log likelihood -1.423207
[ Info: iteration 36, average log likelihood -1.423207
[ Info: iteration 37, average log likelihood -1.423207
[ Info: iteration 38, average log likelihood -1.423206
[ Info: iteration 39, average log likelihood -1.423206
[ Info: iteration 40, average log likelihood -1.423206
[ Info: iteration 41, average log likelihood -1.423206
[ Info: iteration 42, average log likelihood -1.423206
[ Info: iteration 43, average log likelihood -1.423206
[ Info: iteration 44, average log likelihood -1.423206
[ Info: iteration 45, average log likelihood -1.423206
[ Info: iteration 46, average log likelihood -1.423206
[ Info: iteration 47, average log likelihood -1.423206
[ Info: iteration 48, average log likelihood -1.423206
[ Info: iteration 49, average log likelihood -1.423206
[ Info: iteration 50, average log likelihood -1.423206
┌ Info: EM with 100000 data points 50 iterations avll -1.423206
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4289046368637226
│     -1.4288278855550534
│      ⋮                 
└     -1.423205642280679 
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423221
[ Info: iteration 2, average log likelihood -1.423147
[ Info: iteration 3, average log likelihood -1.423082
[ Info: iteration 4, average log likelihood -1.423002
[ Info: iteration 5, average log likelihood -1.422903
[ Info: iteration 6, average log likelihood -1.422785
[ Info: iteration 7, average log likelihood -1.422660
[ Info: iteration 8, average log likelihood -1.422539
[ Info: iteration 9, average log likelihood -1.422434
[ Info: iteration 10, average log likelihood -1.422346
[ Info: iteration 11, average log likelihood -1.422274
[ Info: iteration 12, average log likelihood -1.422216
[ Info: iteration 13, average log likelihood -1.422170
[ Info: iteration 14, average log likelihood -1.422134
[ Info: iteration 15, average log likelihood -1.422106
[ Info: iteration 16, average log likelihood -1.422083
[ Info: iteration 17, average log likelihood -1.422063
[ Info: iteration 18, average log likelihood -1.422045
[ Info: iteration 19, average log likelihood -1.422029
[ Info: iteration 20, average log likelihood -1.422014
[ Info: iteration 21, average log likelihood -1.422000
[ Info: iteration 22, average log likelihood -1.421986
[ Info: iteration 23, average log likelihood -1.421974
[ Info: iteration 24, average log likelihood -1.421962
[ Info: iteration 25, average log likelihood -1.421952
[ Info: iteration 26, average log likelihood -1.421943
[ Info: iteration 27, average log likelihood -1.421934
[ Info: iteration 28, average log likelihood -1.421927
[ Info: iteration 29, average log likelihood -1.421920
[ Info: iteration 30, average log likelihood -1.421914
[ Info: iteration 31, average log likelihood -1.421909
[ Info: iteration 32, average log likelihood -1.421905
[ Info: iteration 33, average log likelihood -1.421901
[ Info: iteration 34, average log likelihood -1.421898
[ Info: iteration 35, average log likelihood -1.421895
[ Info: iteration 36, average log likelihood -1.421892
[ Info: iteration 37, average log likelihood -1.421890
[ Info: iteration 38, average log likelihood -1.421888
[ Info: iteration 39, average log likelihood -1.421886
[ Info: iteration 40, average log likelihood -1.421885
[ Info: iteration 41, average log likelihood -1.421884
[ Info: iteration 42, average log likelihood -1.421882
[ Info: iteration 43, average log likelihood -1.421881
[ Info: iteration 44, average log likelihood -1.421880
[ Info: iteration 45, average log likelihood -1.421879
[ Info: iteration 46, average log likelihood -1.421878
[ Info: iteration 47, average log likelihood -1.421878
[ Info: iteration 48, average log likelihood -1.421877
[ Info: iteration 49, average log likelihood -1.421876
[ Info: iteration 50, average log likelihood -1.421876
┌ Info: EM with 100000 data points 50 iterations avll -1.421876
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4232211656739817
│     -1.4231474622353635
│      ⋮                 
└     -1.4218757961823159
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421886
[ Info: iteration 2, average log likelihood -1.421830
[ Info: iteration 3, average log likelihood -1.421781
[ Info: iteration 4, average log likelihood -1.421725
[ Info: iteration 5, average log likelihood -1.421657
[ Info: iteration 6, average log likelihood -1.421575
[ Info: iteration 7, average log likelihood -1.421484
[ Info: iteration 8, average log likelihood -1.421387
[ Info: iteration 9, average log likelihood -1.421291
[ Info: iteration 10, average log likelihood -1.421201
[ Info: iteration 11, average log likelihood -1.421119
[ Info: iteration 12, average log likelihood -1.421046
[ Info: iteration 13, average log likelihood -1.420983
[ Info: iteration 14, average log likelihood -1.420928
[ Info: iteration 15, average log likelihood -1.420882
[ Info: iteration 16, average log likelihood -1.420844
[ Info: iteration 17, average log likelihood -1.420812
[ Info: iteration 18, average log likelihood -1.420786
[ Info: iteration 19, average log likelihood -1.420764
[ Info: iteration 20, average log likelihood -1.420746
[ Info: iteration 21, average log likelihood -1.420731
[ Info: iteration 22, average log likelihood -1.420718
[ Info: iteration 23, average log likelihood -1.420707
[ Info: iteration 24, average log likelihood -1.420697
[ Info: iteration 25, average log likelihood -1.420687
[ Info: iteration 26, average log likelihood -1.420679
[ Info: iteration 27, average log likelihood -1.420671
[ Info: iteration 28, average log likelihood -1.420664
[ Info: iteration 29, average log likelihood -1.420657
[ Info: iteration 30, average log likelihood -1.420651
[ Info: iteration 31, average log likelihood -1.420644
[ Info: iteration 32, average log likelihood -1.420638
[ Info: iteration 33, average log likelihood -1.420632
[ Info: iteration 34, average log likelihood -1.420626
[ Info: iteration 35, average log likelihood -1.420621
[ Info: iteration 36, average log likelihood -1.420615
[ Info: iteration 37, average log likelihood -1.420609
[ Info: iteration 38, average log likelihood -1.420604
[ Info: iteration 39, average log likelihood -1.420599
[ Info: iteration 40, average log likelihood -1.420594
[ Info: iteration 41, average log likelihood -1.420589
[ Info: iteration 42, average log likelihood -1.420584
[ Info: iteration 43, average log likelihood -1.420579
[ Info: iteration 44, average log likelihood -1.420575
[ Info: iteration 45, average log likelihood -1.420570
[ Info: iteration 46, average log likelihood -1.420566
[ Info: iteration 47, average log likelihood -1.420562
[ Info: iteration 48, average log likelihood -1.420557
[ Info: iteration 49, average log likelihood -1.420553
[ Info: iteration 50, average log likelihood -1.420549
┌ Info: EM with 100000 data points 50 iterations avll -1.420549
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4218857471210757
│     -1.4218296576644849
│      ⋮                 
└     -1.4205493710818375
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420555
[ Info: iteration 2, average log likelihood -1.420497
[ Info: iteration 3, average log likelihood -1.420443
[ Info: iteration 4, average log likelihood -1.420378
[ Info: iteration 5, average log likelihood -1.420295
[ Info: iteration 6, average log likelihood -1.420190
[ Info: iteration 7, average log likelihood -1.420066
[ Info: iteration 8, average log likelihood -1.419930
[ Info: iteration 9, average log likelihood -1.419789
[ Info: iteration 10, average log likelihood -1.419653
[ Info: iteration 11, average log likelihood -1.419525
[ Info: iteration 12, average log likelihood -1.419408
[ Info: iteration 13, average log likelihood -1.419304
[ Info: iteration 14, average log likelihood -1.419213
[ Info: iteration 15, average log likelihood -1.419133
[ Info: iteration 16, average log likelihood -1.419063
[ Info: iteration 17, average log likelihood -1.419004
[ Info: iteration 18, average log likelihood -1.418952
[ Info: iteration 19, average log likelihood -1.418908
[ Info: iteration 20, average log likelihood -1.418869
[ Info: iteration 21, average log likelihood -1.418835
[ Info: iteration 22, average log likelihood -1.418805
[ Info: iteration 23, average log likelihood -1.418777
[ Info: iteration 24, average log likelihood -1.418753
[ Info: iteration 25, average log likelihood -1.418730
[ Info: iteration 26, average log likelihood -1.418709
[ Info: iteration 27, average log likelihood -1.418690
[ Info: iteration 28, average log likelihood -1.418672
[ Info: iteration 29, average log likelihood -1.418655
[ Info: iteration 30, average log likelihood -1.418639
[ Info: iteration 31, average log likelihood -1.418624
[ Info: iteration 32, average log likelihood -1.418609
[ Info: iteration 33, average log likelihood -1.418594
[ Info: iteration 34, average log likelihood -1.418580
[ Info: iteration 35, average log likelihood -1.418567
[ Info: iteration 36, average log likelihood -1.418553
[ Info: iteration 37, average log likelihood -1.418540
[ Info: iteration 38, average log likelihood -1.418526
[ Info: iteration 39, average log likelihood -1.418513
[ Info: iteration 40, average log likelihood -1.418500
[ Info: iteration 41, average log likelihood -1.418487
[ Info: iteration 42, average log likelihood -1.418473
[ Info: iteration 43, average log likelihood -1.418460
[ Info: iteration 44, average log likelihood -1.418447
[ Info: iteration 45, average log likelihood -1.418433
[ Info: iteration 46, average log likelihood -1.418420
[ Info: iteration 47, average log likelihood -1.418406
[ Info: iteration 48, average log likelihood -1.418393
[ Info: iteration 49, average log likelihood -1.418380
[ Info: iteration 50, average log likelihood -1.418367
┌ Info: EM with 100000 data points 50 iterations avll -1.418367
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4205550326304293
│     -1.4204974968588657
│      ⋮                 
└     -1.4183671661106334
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418363
[ Info: iteration 2, average log likelihood -1.418300
[ Info: iteration 3, average log likelihood -1.418241
[ Info: iteration 4, average log likelihood -1.418173
[ Info: iteration 5, average log likelihood -1.418090
[ Info: iteration 6, average log likelihood -1.417990
[ Info: iteration 7, average log likelihood -1.417872
[ Info: iteration 8, average log likelihood -1.417738
[ Info: iteration 9, average log likelihood -1.417595
[ Info: iteration 10, average log likelihood -1.417447
[ Info: iteration 11, average log likelihood -1.417303
[ Info: iteration 12, average log likelihood -1.417165
[ Info: iteration 13, average log likelihood -1.417037
[ Info: iteration 14, average log likelihood -1.416921
[ Info: iteration 15, average log likelihood -1.416816
[ Info: iteration 16, average log likelihood -1.416723
[ Info: iteration 17, average log likelihood -1.416640
[ Info: iteration 18, average log likelihood -1.416565
[ Info: iteration 19, average log likelihood -1.416497
[ Info: iteration 20, average log likelihood -1.416434
[ Info: iteration 21, average log likelihood -1.416376
[ Info: iteration 22, average log likelihood -1.416322
[ Info: iteration 23, average log likelihood -1.416271
[ Info: iteration 24, average log likelihood -1.416223
[ Info: iteration 25, average log likelihood -1.416177
[ Info: iteration 26, average log likelihood -1.416134
[ Info: iteration 27, average log likelihood -1.416093
[ Info: iteration 28, average log likelihood -1.416054
[ Info: iteration 29, average log likelihood -1.416017
[ Info: iteration 30, average log likelihood -1.415982
[ Info: iteration 31, average log likelihood -1.415948
[ Info: iteration 32, average log likelihood -1.415915
[ Info: iteration 33, average log likelihood -1.415884
[ Info: iteration 34, average log likelihood -1.415854
[ Info: iteration 35, average log likelihood -1.415825
[ Info: iteration 36, average log likelihood -1.415797
[ Info: iteration 37, average log likelihood -1.415771
[ Info: iteration 38, average log likelihood -1.415745
[ Info: iteration 39, average log likelihood -1.415720
[ Info: iteration 40, average log likelihood -1.415696
[ Info: iteration 41, average log likelihood -1.415673
[ Info: iteration 42, average log likelihood -1.415651
[ Info: iteration 43, average log likelihood -1.415630
[ Info: iteration 44, average log likelihood -1.415609
[ Info: iteration 45, average log likelihood -1.415590
[ Info: iteration 46, average log likelihood -1.415571
[ Info: iteration 47, average log likelihood -1.415552
[ Info: iteration 48, average log likelihood -1.415535
[ Info: iteration 49, average log likelihood -1.415518
[ Info: iteration 50, average log likelihood -1.415502
┌ Info: EM with 100000 data points 50 iterations avll -1.415502
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4183626251619597
│     -1.4182998363915025
│      ⋮                 
└     -1.4155018501720116
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4288854363880277
│     -1.4289046368637226
│     -1.4288278855550534
│     -1.428764351483093 
│      ⋮                 
│     -1.415534921520667 
│     -1.4155180634909792
└     -1.4155018501720116
32×26 Array{Float64,2}:
  0.172433    -0.584323    -0.0127691  -0.384625   -0.239727    0.169553     -0.300778   -0.034783    0.432586    0.0100802    0.0597675   -0.181465    0.164646    0.248455     -0.661266   -0.102722     0.0016903   0.59644      0.433264    0.552981     0.00234585  -0.139271   -0.432359    -0.639286    0.0691011   -0.3916     
 -0.313726     0.255799     0.0594622  -0.0942078  -0.0486804  -0.0214772     0.282773    0.109455    0.0507839  -0.201734    -0.0985777   -0.306193    0.196361    0.110843     -0.278929    0.0486417   -0.03435     0.107024     0.411129   -0.762476    -0.272114     0.0562461  -0.634706    -0.548562   -0.132103     0.0173483  
 -0.273441     0.399759    -0.0635732   0.605332    0.405371    0.177686     -0.176157   -0.410315    0.151337   -0.23331     -0.52376     -0.300665    0.440918   -0.252974     -0.095736   -0.0759978   -0.0379156  -0.170327     0.468758   -0.0954408    0.253766     0.379823   -0.355419     0.122237   -0.00632516  -0.0467745  
 -0.0949367    0.141359    -0.104753    0.251927    0.257096    0.218991     -0.459025   -0.261056    0.328409   -0.120831     0.482515    -0.0184681   0.206881    0.0988912     0.101384    0.197087    -0.213583   -0.249898     0.455209    0.143447     0.020432     0.333118   -0.755911     0.463095    0.100577    -0.130103   
  0.709035    -0.491008    -0.454944   -0.103596   -0.197128    0.118186      0.157405    0.240406   -0.0785949  -0.117698    -0.0853746    0.462164    0.0105361   0.276343      0.0762289  -0.00181244   0.314697   -0.497325    -0.558985    0.138575    -0.172039    -0.461597    0.560567    -0.264168    0.0741617   -0.0978105  
  0.315664     0.257075    -0.337913   -0.384175    0.699385    0.0826914    -0.44099    -0.0292743  -0.0168383  -0.0453812    0.0899901    0.586736    0.251157   -0.127909     -0.237424   -0.489853     0.164846   -0.438646     0.225739   -0.275164    -0.0245614    0.143913    0.505034    -0.405076    0.297119    -0.367897   
  0.00702842   0.105863    -0.121059   -0.042407   -0.025225   -0.0157635    -0.139888    0.0903647  -0.0629379  -0.0607582   -0.235572    -0.044786    0.043565    0.115065     -0.011524   -0.105476    -0.0772539  -0.0415006   -0.0873564   0.0838208    0.0226237    0.0191028  -0.0300764   -0.112764    0.0204687    0.170252   
  0.0806143   -0.250762    -0.032857    0.196676   -0.0596895   0.0130114     0.342859   -0.147295    0.0654855  -0.0765726    0.252884    -0.0988767   0.0661332   0.000148862   0.0892038   0.0987502   -0.0281643   0.152009    -0.167943   -0.00732323  -0.0855153    0.0982767   0.10362     -0.0316021  -0.144448    -0.133501   
  0.0021507   -0.644718     0.730837   -0.254283   -0.371832   -0.518473      0.657321    0.251061   -0.215089    0.163491     0.320237    -0.152131   -0.064198   -0.116931     -0.247335   -0.13056      0.174928    0.434891    -0.112997   -0.566467    -0.321111    -0.641185    0.130403    -0.272333    0.128539     0.318168   
 -0.0483817   -0.190959     0.39312     0.0476154   0.184575    0.582478      0.676364   -0.396962   -0.525201    0.118216     0.224926     0.485638   -0.394374   -0.0167909    -0.340001    0.405874     0.307772   -0.122803    -0.14879    -0.0371252   -0.242784    -0.373169    0.140009    -0.355143   -0.576152    -0.0650471  
 -0.0167999   -0.114716     0.125389   -0.181591   -0.64837     0.0443817     0.0827231   0.176614   -0.269561    0.196321     0.020973    -0.0142601  -0.477738    0.268825     -0.0366769   0.411776    -0.0187102   0.223619    -0.529974    0.409719     0.00932517  -0.408665   -0.0463794    0.449531   -0.0917385    0.48283    
  0.0777001    0.119016    -0.156576   -0.505867    0.34315     0.171559      0.0591437   0.0242501  -0.345223    0.464825    -0.0807588   -0.195776   -0.817428   -0.144624      0.12991    -0.132822     0.184764   -0.0948523    0.0964954   0.521838    -0.0804876   -0.133929   -0.336381    -0.149095   -0.325574     0.243779   
 -0.400182    -0.008371     0.50177     0.0605369  -0.0231985   0.0378967     0.199353    0.0573967  -0.39384     0.104393     0.30368      0.378161   -0.208994   -0.436229     -0.17429     0.303692     0.213169   -0.146269    -0.0401927  -0.424084    -0.066906    -0.0866348  -0.00999318   0.275114    0.502736    -0.138091   
 -0.11726      0.287487     0.388341    0.0337415  -0.308071    0.409612      0.217512    0.120431    0.658018    0.0182827    0.0139655    0.522781   -0.0355041   0.664617     -0.0394893  -0.353583     0.517228   -0.00534815  -0.340987    0.0744       0.417504     0.326409    0.0717278    0.749199    0.0170878   -0.447237   
 -0.63694      0.0755637   -0.0877547   0.168667   -0.118517   -0.359507     -0.279775   -0.0610884   0.050801    0.22372      0.00794349  -0.0377075  -0.421961   -0.739222      0.186006   -0.647094     0.293185    1.00072      0.21162    -0.0581464    0.373918     0.31863    -0.0809109    0.178027   -0.0456075   -0.439717   
 -0.0909124    0.160052     0.701749   -0.486552    0.0952419  -0.677128      0.0559107   0.0281894  -0.165443    0.915739    -0.16131      0.574364   -0.361538    0.124916     -0.318927   -0.432102    -0.0289388   0.36176      0.191196   -0.0291694   -0.0635789    0.0939661  -0.105131     0.24059     0.0974151    0.17801    
 -0.383533    -0.580116    -0.192736    0.26258    -0.333369    0.57335       0.464874   -0.463317   -0.276985    0.171292    -0.232791    -0.50186    -0.0503797  -0.085137     -0.115324    0.846801     0.405127    0.389128     0.282841    0.0685648    0.649738    -0.170139   -0.40894     -0.0389814  -0.515896     0.329468   
 -0.201626     0.104806     0.441311    0.713055   -0.0466571   0.0703926     0.102146   -0.318065   -0.419057    0.106733    -0.2224      -0.261333   -0.107023   -0.059135      0.022189    0.489371    -0.579696    0.107972     0.15325     0.0636553    0.163706     0.122878   -0.568174     0.808187    0.00709693   0.427724   
 -0.429533     0.127472    -0.321669    0.142728    0.175039   -0.269005     -0.499197   -0.164598   -1.10645    -0.424847    -0.113207    -0.0856184  -0.206735   -0.418089      0.0909739   0.450045    -0.254023   -0.383259     0.379703   -0.0946341   -0.503009    -0.362317   -0.14984     -0.641329    0.173007     0.537562   
 -0.0470309    0.896143    -0.302022    0.293982    0.0519194  -0.521124      0.0963838  -0.124525   -0.524455   -0.321438    -0.0774608   -0.0430892  -0.336335   -0.184417      0.513958   -0.224872    -0.261202   -0.61734     -0.493117   -0.556767     0.0369774    0.505218    0.131471     0.322728    0.0752037    0.312454   
 -0.102556     0.298703    -0.808327    0.561288    0.045338   -0.0180501     0.136766   -0.0245364   0.493074   -0.269718     0.0698835   -0.0541963   0.694327    0.101931      0.255394    0.417191     0.0837209  -0.288461     0.493268   -0.662301    -0.477489     0.321876   -0.314204    -0.429329   -0.251509    -0.508936   
 -0.557652    -0.00073582   0.865225   -0.476567    0.0792628  -0.21148      -0.0823777   0.124258    0.300297    0.0450534   -0.0278029    0.248234    0.323963    0.136024     -0.658295   -0.0759696    0.25357    -0.0955115    0.604845   -0.607446    -0.125719     0.226389   -0.827421    -0.246778    0.629468    -0.360487   
  0.0781392   -0.242354    -0.0471332   0.250633   -0.468044    0.168778     -0.435908   -0.233542    0.744927    0.00606303  -0.035199     0.23589     0.989313    0.0888129    -0.150362   -0.0134246    0.241709    0.302421    -0.0760874  -0.0213571   -0.140397     0.0683193   0.848505    -0.576678   -0.326631    -0.018258   
  0.0973116   -0.37695     -0.0910053   0.0987493  -0.371167    0.000404431   0.268557    0.59071     0.220329    0.00683306  -0.306948     0.275356    1.22359     0.408649      0.103407    0.157107    -0.311787    0.626963    -0.232428   -0.381465     0.0724886    0.351534    0.481878     0.459322    0.496232    -0.162385   
  0.299722     0.302269    -0.506436    0.0388126  -0.354118   -0.622454     -0.54581    -0.487141    0.353013   -0.442116    -0.113627    -0.389409    0.316669   -0.18756      -0.324632    0.00550214   0.0587636  -0.486585    -0.651464    0.427012     0.0256344   -0.0947928  -0.267324    -0.239095   -0.0377422    0.0169969  
  0.2232       0.163258    -0.629743   -0.2018     -0.255196    0.0634775    -0.500146    0.219962    0.328164   -0.0245331   -0.584186    -0.632623    0.412284    0.586673      0.198561   -0.159743    -0.27833     0.157924    -0.0319097   0.239901     0.226012     0.354423   -0.167286    -0.381296    0.0306759    0.539645   
  0.296812    -0.241469     0.354122   -0.0730649   0.25699    -0.183944      0.186435    0.520296   -0.282201   -0.0930191    0.018607    -0.556581   -0.717785    0.0603758     0.0951444  -0.750376    -0.700523    0.0263411   -0.0338475   0.243896     0.109548     0.26329    -0.145144     0.38733     0.553394     0.0219042  
  0.181767    -0.203856     0.572082   -0.148324    0.17399    -0.443496     -0.241873   -0.133885    0.122061   -0.220588     0.374709     0.427127    0.0998392  -0.168261      0.285985   -0.0455146   -0.465471   -0.107386    -0.471769    0.438753     0.301937    -0.41548     0.90022      0.796257    0.796599    -0.000620072
  0.481755    -0.0681569   -1.17293     0.469683    0.154765    0.351947      0.245269   -0.185922   -0.194374   -0.433956    -0.51037     -0.259305    0.0244841  -0.363542      0.158011   -0.0610767   -0.306223    0.22935     -0.122386    0.427473     0.145966     0.317641    0.291403    -0.439143   -0.34235     -0.404606   
  0.266986    -0.239649    -0.339592    0.320913   -0.0163006   0.100775      0.101096   -0.178687    0.176241   -0.433307     0.958089    -0.607915   -0.273745    0.0157048     0.700973   -0.293031    -0.230041   -0.187922    -0.43601     0.437401    -0.361331     0.28536     0.215163    -0.212751   -0.629114    -0.284185   
  0.295338    -0.436996    -0.0400009  -0.31794    -0.264744    0.00817335   -0.198449   -0.125216    0.24354     0.0560228    0.139847     0.119959   -0.0307025  -0.173345      0.0341043  -0.272976     0.390114    0.0811516   -0.101891    0.453661     0.036859    -0.105011    0.310256    -0.0922981  -0.0499882   -0.213282   
  0.163003     0.709115     0.205334   -0.580119    0.106374    0.106616      0.0626305   0.389147   -0.28565     0.222919    -0.0514004    0.542578   -0.160324    0.393014     -0.264192   -0.194628     0.342036   -0.227721    -0.431237   -0.185637     0.246005    -0.38063     0.04993     -0.238073    0.0667654    0.320666   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415486
[ Info: iteration 2, average log likelihood -1.415471
[ Info: iteration 3, average log likelihood -1.415457
[ Info: iteration 4, average log likelihood -1.415443
[ Info: iteration 5, average log likelihood -1.415429
[ Info: iteration 6, average log likelihood -1.415416
[ Info: iteration 7, average log likelihood -1.415403
[ Info: iteration 8, average log likelihood -1.415391
[ Info: iteration 9, average log likelihood -1.415379
[ Info: iteration 10, average log likelihood -1.415368
┌ Info: EM with 100000 data points 10 iterations avll -1.415368
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.254099e+05
      1       7.124842e+05      -2.129256e+05 |       32
      2       6.985287e+05      -1.395554e+04 |       32
      3       6.927311e+05      -5.797531e+03 |       32
      4       6.897736e+05      -2.957513e+03 |       32
      5       6.879177e+05      -1.855923e+03 |       32
      6       6.865563e+05      -1.361458e+03 |       32
      7       6.855348e+05      -1.021414e+03 |       32
      8       6.847808e+05      -7.540218e+02 |       32
      9       6.841480e+05      -6.328206e+02 |       32
     10       6.836374e+05      -5.105548e+02 |       32
     11       6.832262e+05      -4.112501e+02 |       32
     12       6.828921e+05      -3.341252e+02 |       32
     13       6.826094e+05      -2.826393e+02 |       32
     14       6.823822e+05      -2.271837e+02 |       32
     15       6.821793e+05      -2.029015e+02 |       32
     16       6.820035e+05      -1.758763e+02 |       32
     17       6.818491e+05      -1.544006e+02 |       32
     18       6.817187e+05      -1.303732e+02 |       32
     19       6.816103e+05      -1.083439e+02 |       32
     20       6.815061e+05      -1.042747e+02 |       32
     21       6.814136e+05      -9.251152e+01 |       32
     22       6.813301e+05      -8.343110e+01 |       32
     23       6.812448e+05      -8.537554e+01 |       32
     24       6.811653e+05      -7.944328e+01 |       32
     25       6.811027e+05      -6.261262e+01 |       32
     26       6.810439e+05      -5.878901e+01 |       32
     27       6.809889e+05      -5.505270e+01 |       32
     28       6.809356e+05      -5.322266e+01 |       32
     29       6.808803e+05      -5.536291e+01 |       32
     30       6.808246e+05      -5.563694e+01 |       32
     31       6.807689e+05      -5.571715e+01 |       32
     32       6.807173e+05      -5.165274e+01 |       32
     33       6.806697e+05      -4.756964e+01 |       32
     34       6.806174e+05      -5.227458e+01 |       32
     35       6.805594e+05      -5.801875e+01 |       32
     36       6.805098e+05      -4.956882e+01 |       32
     37       6.804633e+05      -4.652353e+01 |       32
     38       6.804195e+05      -4.384749e+01 |       32
     39       6.803846e+05      -3.487771e+01 |       32
     40       6.803541e+05      -3.048013e+01 |       32
     41       6.803277e+05      -2.637812e+01 |       32
     42       6.803038e+05      -2.393641e+01 |       32
     43       6.802821e+05      -2.169223e+01 |       32
     44       6.802596e+05      -2.245222e+01 |       32
     45       6.802376e+05      -2.204713e+01 |       32
     46       6.802138e+05      -2.375520e+01 |       32
     47       6.801894e+05      -2.440482e+01 |       32
     48       6.801650e+05      -2.447177e+01 |       32
     49       6.801363e+05      -2.868692e+01 |       32
     50       6.801091e+05      -2.718088e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 680109.098266433)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427688
[ Info: iteration 2, average log likelihood -1.422543
[ Info: iteration 3, average log likelihood -1.420989
[ Info: iteration 4, average log likelihood -1.419713
[ Info: iteration 5, average log likelihood -1.418470
[ Info: iteration 6, average log likelihood -1.417530
[ Info: iteration 7, average log likelihood -1.416996
[ Info: iteration 8, average log likelihood -1.416719
[ Info: iteration 9, average log likelihood -1.416558
[ Info: iteration 10, average log likelihood -1.416446
[ Info: iteration 11, average log likelihood -1.416360
[ Info: iteration 12, average log likelihood -1.416288
[ Info: iteration 13, average log likelihood -1.416226
[ Info: iteration 14, average log likelihood -1.416171
[ Info: iteration 15, average log likelihood -1.416122
[ Info: iteration 16, average log likelihood -1.416077
[ Info: iteration 17, average log likelihood -1.416036
[ Info: iteration 18, average log likelihood -1.415998
[ Info: iteration 19, average log likelihood -1.415962
[ Info: iteration 20, average log likelihood -1.415930
[ Info: iteration 21, average log likelihood -1.415899
[ Info: iteration 22, average log likelihood -1.415870
[ Info: iteration 23, average log likelihood -1.415843
[ Info: iteration 24, average log likelihood -1.415818
[ Info: iteration 25, average log likelihood -1.415793
[ Info: iteration 26, average log likelihood -1.415770
[ Info: iteration 27, average log likelihood -1.415748
[ Info: iteration 28, average log likelihood -1.415727
[ Info: iteration 29, average log likelihood -1.415707
[ Info: iteration 30, average log likelihood -1.415687
[ Info: iteration 31, average log likelihood -1.415669
[ Info: iteration 32, average log likelihood -1.415650
[ Info: iteration 33, average log likelihood -1.415633
[ Info: iteration 34, average log likelihood -1.415615
[ Info: iteration 35, average log likelihood -1.415599
[ Info: iteration 36, average log likelihood -1.415582
[ Info: iteration 37, average log likelihood -1.415566
[ Info: iteration 38, average log likelihood -1.415550
[ Info: iteration 39, average log likelihood -1.415534
[ Info: iteration 40, average log likelihood -1.415519
[ Info: iteration 41, average log likelihood -1.415503
[ Info: iteration 42, average log likelihood -1.415488
[ Info: iteration 43, average log likelihood -1.415473
[ Info: iteration 44, average log likelihood -1.415458
[ Info: iteration 45, average log likelihood -1.415443
[ Info: iteration 46, average log likelihood -1.415428
[ Info: iteration 47, average log likelihood -1.415414
[ Info: iteration 48, average log likelihood -1.415400
[ Info: iteration 49, average log likelihood -1.415386
[ Info: iteration 50, average log likelihood -1.415373
┌ Info: EM with 100000 data points 50 iterations avll -1.415373
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0644858   -0.212383    -0.0212336  -0.371976    -0.235317   -0.0175102   0.0243378    0.185452     -0.251624     0.344191   -0.0130258    0.0463862  -0.564836     0.202166     0.128564    0.121919    -0.0279655   0.142384   -0.387177    0.490758    -0.0902438    -0.307512    0.0132885     0.243629    -0.0795524    0.306218   
 -0.0346142    0.334136     0.374875    0.240737    -0.605379   -0.113342    0.603628     0.370415      0.0691074   -0.239869    0.273498    -0.860592   -0.632722    -0.17388      0.0182437   0.00810178  -0.02877     0.25982    -0.789815   -0.180592    -0.34043      -0.340706   -0.122543      0.101726    -0.176518     0.580346   
 -0.122989     0.407173    -0.574152   -0.15867      0.122912   -0.514755   -1.07147      0.292605     -0.486871    -0.375789   -0.356667    -0.489078    0.298665     0.00543561   0.141543    0.0281      -0.624652   -0.0701998   0.133021    0.100269     0.000346978   0.685047   -0.165297     -0.476416     0.3022       0.582488   
  0.131843    -0.22414     -0.0760213  -0.229924    -0.586696   -0.298067   -0.855961    -0.299108      0.500005    -0.143196    0.0451985   -0.164478    0.172059    -0.706321    -0.562446   -0.135427     0.718631   -0.0290684  -0.389642    0.285259     0.23096      -0.297988   -0.0981355    -0.567238    -0.319207    -0.197267   
 -0.263695    -0.254637    -0.573896    0.133864    -0.487036    0.689593    0.405316    -0.457269     -0.198658     0.11357    -0.437979    -0.187598    0.197482     0.27108     -0.0638221   0.849352     0.396396    0.335477    0.123415   -0.00841085   0.492783     -0.100597   -0.264756     -0.260997    -0.636907     0.302776   
  0.309118    -0.389522    -0.198444   -0.0436428    0.0705874  -0.567332    0.343386    -0.195938      0.221898    -0.358761    0.712636    -0.609194   -0.00602056   0.277878     0.0742442  -0.280369    -0.646888    0.0118234  -0.302893    0.272771    -0.359981      0.484677   -0.317424     -0.0674781   -0.562153    -0.517238   
 -0.175779     0.252386     0.345882   -0.754514     0.147475   -0.22331     0.319184     0.325911     -0.624009     0.515998   -0.3683       0.566592   -0.150509    -0.231484    -0.814909   -0.181444     0.330149    0.242826    0.119837   -0.360984     0.0823728    -0.114142   -0.106067     -0.228165     0.271018     0.000547709
  0.0155479   -0.289024     0.18526     0.192695     0.0766688  -0.127347   -0.0214071   -0.122289     -0.55659      0.0729536  -0.429797    -0.429565   -0.364805    -0.0273284    0.219511   -0.0314051   -0.712843    0.0894528   0.168633    0.474193     0.34108       0.111362   -0.246708      0.731666     0.368743     0.471817   
  0.258772     0.0330574   -0.430847    0.00592841  -0.137397    0.07927    -0.207071     0.0237947     0.314395    -0.126038   -0.368937    -0.507437    0.316859     0.321237    -0.0523321  -0.105227    -0.205642    0.154943   -0.0596145   0.194469     0.122694      0.0598308  -0.0857336    -0.464837    -0.16356      0.227483   
 -0.0335231    0.367064    -0.13682     0.473344     0.390474    0.170293    0.417257     0.350199     -0.520057    -0.466056   -0.152745    -0.0120585  -0.135916     0.229295     0.269281   -0.0739329   -0.486245   -0.293665    0.0469908  -0.279731     0.101704      0.439715   -0.232702      0.373237     0.27498     -0.321669   
  0.599141     0.534609     0.395051   -0.504271     0.462974    0.133934    0.40095      0.276862     -0.0792642    0.2505     -0.212254     0.104301   -0.464816     0.604123    -0.393909   -0.687635    -0.42346    -0.0618514  -0.660702    0.153882     0.599074     -0.340859    0.187485     -0.258853     0.206955     0.18198    
  0.261682     0.221657     0.084421   -0.0760253   -0.250752    0.354012    0.114707    -0.16797       1.13782      0.239507    0.113984     0.136937    0.329209     0.704596     0.201609   -0.366688     0.344248    0.334364   -0.440763    0.298082     0.420716      0.664925    0.258399      0.390985    -0.389223    -0.144972   
 -0.162288     0.113273     0.0088063   0.117142     0.249961    0.0041194  -0.153553    -0.17417       0.359095    -0.0261121   0.0053855    0.0573035   0.271864    -0.22479     -0.106958   -0.208523     0.204597    0.0855043   0.401532   -0.217502     0.0813813     0.197901   -0.133477     -0.101665     0.0439525   -0.237063   
 -0.154143    -0.333027     1.09009     0.173876    -0.116825    0.194456    0.289276    -0.00698109   -0.370247     0.447976    0.300401     0.0166357  -0.272534     0.141695    -0.524837    0.55468     -0.0361779   0.159885    0.177613   -0.231582     0.108436     -0.481161   -0.360338      0.457293    -0.180203     0.742446   
 -0.262664    -0.30789     -0.120378    0.265247     0.213502   -0.222349    0.166363    -0.164724     -0.425673    -0.285576   -0.086694    -0.351105    0.0832178   -0.266553    -0.0351515   0.272697    -0.212787   -0.0857857   0.63391    -0.431691    -0.745386     -0.494048   -0.329056     -0.855401    -0.0434335    0.268021   
  0.603762     0.00175336  -0.53107    -0.549605     0.0868064   0.253699   -0.412212     0.445243      0.00977704  -0.215249   -0.197671     0.459897    0.183929     0.565726     0.128398   -0.245105     0.380174   -0.705033    0.0157309   0.00821429  -0.149573     -0.40892     0.194235     -0.433914     0.143171     0.139088   
  0.00976244  -0.55187      0.150429   -0.36056     -0.360872    0.146368   -0.425098     0.0843775     0.532849     0.0988557   0.103994    -0.178197    0.191392     0.364838    -0.665369   -0.114771    -0.0106162   0.65215     0.565111    0.397876    -0.0795512     0.0302077  -0.634988     -0.453033     0.401383    -0.445859   
 -0.104594     0.17384     -0.105736    0.0161763    0.415464    0.388416    0.267347    -0.325271     -0.97729      0.244476    0.505213     0.331731   -1.06603     -0.299736     0.0233436   0.20606      0.50546    -0.517547   -0.0708705   0.0882129   -0.370197     -0.280303   -0.0235912    -0.480915    -0.399723    -0.0583366  
 -0.398594    -0.0953632    0.880387   -0.473747    -0.231647   -0.287065    0.0349357    0.327574     -0.026384     0.183239    0.432032     0.627957    0.0171475    0.260474     0.0607194  -0.185564     0.458642   -0.139124   -0.0712237  -0.375264    -0.126818     -0.0809861  -0.0113701     0.332087     0.479705    -0.0881146  
 -0.207334    -0.261496     0.212922    0.0464447    0.220015    0.218621    0.399636    -0.161976     -0.368617     0.195598    0.119331    -0.405818   -0.441903    -0.687586     0.196894   -0.106715     0.270538    0.760208    0.495815    0.328661     0.326965      0.304471   -0.446482      0.112872    -0.262658    -0.185959   
 -0.083615     0.0506114    0.0146212   0.0326204   -0.0542423   0.0626159   0.079375     0.00383983   -0.248606    -0.0814686   0.00452636  -0.0164732  -0.0593514   -0.0114812    0.0162464   0.0749556   -0.0512991  -0.0969863  -0.118465   -0.00818618  -0.0605503     0.0343748  -0.0637944    -0.00873185   0.0226762    0.157106   
  0.10936     -0.33822      0.136133    0.0806431   -0.16813     0.116643    0.528493    -0.0441681     0.0087037   -0.0467358   0.3035       0.463334   -0.0311321    0.00294713  -0.121975    0.125767     0.398053   -0.0444403  -0.435871   -0.228643    -0.0761073    -0.202828    0.379935     -0.0884877    0.0379968   -0.403024   
 -0.076452     0.584189    -0.121801    0.462116     0.416738    0.623592   -0.680863    -0.455861      0.381204    -0.084246    0.0577597   -0.116634    0.0452464    0.23216     -0.213678    0.277708    -0.0906201  -0.778201    0.378362    0.309906     0.196229      0.281644   -0.720389      0.483242    -0.284634    -0.0302456  
  0.564919    -0.120516    -1.1566      0.260774    -0.0559548   0.242318    0.00701743  -0.113923      0.0780159   -0.492838    0.00305978  -0.321067    0.0973152   -0.277463     0.516593   -0.32611     -0.100557   -0.0270929  -0.367178    0.470202    -0.142789      0.199938    0.532443     -0.400094    -0.303529    -0.337643   
  0.141165     0.725655    -0.290755   -0.0523519   -0.0290909  -0.652555   -0.0339159   -0.507684     -0.255607    -0.0303591  -0.0942879    0.185548    0.147382    -0.0138439    0.237131    0.0605693    0.22435    -0.877813   -0.649999   -0.096907    -0.208177      0.0854006   0.000301503  -0.158928    -0.101629     0.543285   
 -1.05703      0.533611     0.194528    0.349926    -0.19727    -0.239314   -0.18273     -0.697766     -0.57429     -0.297545   -0.333758    -0.393649    0.221641    -0.552237    -0.356512    0.204583    -0.368652    0.202438   -0.0654371  -0.309893     0.196853      0.160538   -0.359211      0.27059      0.0839733   -0.00832547 
 -0.473434     0.158495    -0.124613    0.102424    -0.185945   -0.53488    -0.418012    -0.0445459     0.126787     0.43926    -0.0879598    0.240027   -0.616783    -0.328506     0.479261   -0.746627     0.0196063   0.660918    0.196545   -0.0510979    0.316553      0.332692    0.150239      0.437523     0.128846     0.0292193  
  0.0804824   -0.370795    -0.0498793   0.0848619   -0.439959   -0.129451    0.0717391    0.610577      0.36354     -0.0723423  -0.402344     0.343369    1.16123      0.48621     -0.0308538   0.0650381   -0.257008    0.634106   -0.229673   -0.387685    -0.0100867     0.158974    0.533497      0.342536     0.537638    -0.149403   
  0.258584    -1.04771      0.421024    0.00585681  -0.187764    0.39167     0.211732    -0.433636      0.194082     0.013013    0.088062     0.503777    0.194041    -0.1669      -0.287353    0.0653769    0.161355    0.240503    0.0574777   0.739631    -0.0987344    -0.478314    0.930174     -0.165483    -0.366252    -0.262333   
 -0.268047     0.348524    -0.203128    0.287052     0.206977   -0.0150017   0.144866     0.000879541   0.554337    -0.24905    -0.0504921   -0.0745516   0.621447    -0.00820943  -0.136298    0.0716846    0.035958   -0.0654505   0.580639   -0.771128    -0.224164      0.360873   -0.456902     -0.496527     0.00937456  -0.42959    
  0.368709    -0.108235    -0.154769    0.96497     -0.649787    0.0652985  -0.0406445   -0.201452     -0.00865262  -0.0124615   0.171291    -0.17696     0.254575    -0.275888     0.453541    0.900388    -0.39894    -0.237367    0.0476576  -0.179005    -0.281969      0.289872    0.158063      0.579691     0.347164     0.128169   
  0.280346     0.0850984    0.436138   -0.16148      0.24405    -0.536642   -0.399118     0.0950391     0.0456071   -0.220716    0.450061     0.395878    0.027281    -0.25114      0.208033   -0.347147    -0.402708   -0.31983    -0.445201    0.170589     0.0945113    -0.0738544   0.552666      0.645715     0.762773    -0.231652   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415360
[ Info: iteration 2, average log likelihood -1.415347
[ Info: iteration 3, average log likelihood -1.415334
[ Info: iteration 4, average log likelihood -1.415322
[ Info: iteration 5, average log likelihood -1.415311
[ Info: iteration 6, average log likelihood -1.415300
[ Info: iteration 7, average log likelihood -1.415289
[ Info: iteration 8, average log likelihood -1.415279
[ Info: iteration 9, average log likelihood -1.415269
[ Info: iteration 10, average log likelihood -1.415260
┌ Info: EM with 100000 data points 10 iterations avll -1.415260
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
