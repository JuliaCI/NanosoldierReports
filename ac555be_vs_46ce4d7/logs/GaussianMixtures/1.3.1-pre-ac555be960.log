Julia Version 1.3.1-pre.12
Commit ac555be960 (2019-12-04 10:45 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)

   Cloning default registries into `~/.julia`
   Cloning registry from "https://github.com/JuliaRegistries/General.git"
[?25l    Fetching: [>                                        ]  0.0 %    Fetching: [============>                            ]  29.9 %    Fetching: [=========================>               ]  61.9 %[2K[?25h     Added registry `General` to `~/.julia/registries/General`
 Resolving package versions...
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed SpecialFunctions â”€â”€â”€ v0.9.0
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.2
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.6
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.0
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+1
 Installed Polynomials â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed OrderedCollections â”€ v1.1.0
 Installed OpenSpecFun_jll â”€â”€â”€â”€ v0.5.3+1
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.21.11
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [f27b6e38] + Polynomials v0.6.0
  [1fd47b50] + QuadGK v2.2.0
  [3cdcf5f2] + RecipesBase v0.7.0
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Building Rmath â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_xQLK84/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [f27b6e38] Polynomials v0.6.0
  [1fd47b50] QuadGK v2.2.0
  [3cdcf5f2] RecipesBase v0.7.0
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -1.3283141216546223e6, [21119.391746705005, 78880.60825329501], [15469.208928884262 7534.198607836893 6076.5093849814; -15098.409471618994 -7690.356085802646 -5926.827415723187], Array{Float64,2}[[19898.40142900865 942.1009244084162 11057.243127042797; 942.100924408416 25429.64595387228 -4087.3443394368414; 11057.243127042797 -4087.3443394368414 10961.347786919408], [79971.35454050804 -999.0707409234604 -11115.036480944484; -999.0707409234603 74601.6139489833 4035.506857634984; -11115.036480944485 4035.506857634984 89214.23379524799]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /workspace/srcdir/julia/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.227946e+03
      1       8.604550e+02      -3.674907e+02 |        6
      2       8.349259e+02      -2.552904e+01 |        2
      3       8.103691e+02      -2.455683e+01 |        2
      4       8.065897e+02      -3.779375e+00 |        0
      5       8.065897e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 806.5897107667411)
â”Œ Info: K-means with 272 data points using 5 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.058432
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.765080
[ Info: iteration 2, lowerbound -3.622619
[ Info: iteration 3, lowerbound -3.477987
[ Info: iteration 4, lowerbound -3.330461
[ Info: iteration 5, lowerbound -3.204179
[ Info: iteration 6, lowerbound -3.121762
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.086530
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -3.071250
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -3.052053
[ Info: iteration 10, lowerbound -3.037556
[ Info: iteration 11, lowerbound -3.021793
[ Info: iteration 12, lowerbound -2.999417
[ Info: iteration 13, lowerbound -2.968421
[ Info: iteration 14, lowerbound -2.926589
[ Info: iteration 15, lowerbound -2.871640
[ Info: iteration 16, lowerbound -2.801719
[ Info: iteration 17, lowerbound -2.716956
[ Info: iteration 18, lowerbound -2.622586
[ Info: iteration 19, lowerbound -2.530897
[ Info: iteration 20, lowerbound -2.454787
[ Info: iteration 21, lowerbound -2.398687
[ Info: iteration 22, lowerbound -2.361992
[ Info: dropping number of Gaussions to 3
[ Info: iteration 23, lowerbound -2.331832
[ Info: iteration 24, lowerbound -2.311239
[ Info: iteration 25, lowerbound -2.307862
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.302917
[ Info: iteration 27, lowerbound -2.299260
[ Info: iteration 28, lowerbound -2.299256
[ Info: iteration 29, lowerbound -2.299254
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Dec  6 11:55:33 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Dec  6 11:55:40 2019: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Fri Dec  6 11:55:42 2019: EM with 272 data points 0 iterations avll -2.058432
5.8 data points per parameter
, Fri Dec  6 11:55:44 2019: GMM converted to Variational GMM
, Fri Dec  6 11:55:53 2019: iteration 1, lowerbound -3.765080
, Fri Dec  6 11:55:53 2019: iteration 2, lowerbound -3.622619
, Fri Dec  6 11:55:53 2019: iteration 3, lowerbound -3.477987
, Fri Dec  6 11:55:53 2019: iteration 4, lowerbound -3.330461
, Fri Dec  6 11:55:53 2019: iteration 5, lowerbound -3.204179
, Fri Dec  6 11:55:53 2019: iteration 6, lowerbound -3.121762
, Fri Dec  6 11:55:54 2019: dropping number of Gaussions to 7
, Fri Dec  6 11:55:54 2019: iteration 7, lowerbound -3.086530
, Fri Dec  6 11:55:54 2019: dropping number of Gaussions to 5
, Fri Dec  6 11:55:54 2019: iteration 8, lowerbound -3.071250
, Fri Dec  6 11:55:54 2019: dropping number of Gaussions to 4
, Fri Dec  6 11:55:54 2019: iteration 9, lowerbound -3.052053
, Fri Dec  6 11:55:54 2019: iteration 10, lowerbound -3.037556
, Fri Dec  6 11:55:54 2019: iteration 11, lowerbound -3.021793
, Fri Dec  6 11:55:54 2019: iteration 12, lowerbound -2.999417
, Fri Dec  6 11:55:54 2019: iteration 13, lowerbound -2.968421
, Fri Dec  6 11:55:54 2019: iteration 14, lowerbound -2.926589
, Fri Dec  6 11:55:54 2019: iteration 15, lowerbound -2.871640
, Fri Dec  6 11:55:54 2019: iteration 16, lowerbound -2.801719
, Fri Dec  6 11:55:54 2019: iteration 17, lowerbound -2.716956
, Fri Dec  6 11:55:54 2019: iteration 18, lowerbound -2.622586
, Fri Dec  6 11:55:54 2019: iteration 19, lowerbound -2.530897
, Fri Dec  6 11:55:54 2019: iteration 20, lowerbound -2.454787
, Fri Dec  6 11:55:54 2019: iteration 21, lowerbound -2.398687
, Fri Dec  6 11:55:54 2019: iteration 22, lowerbound -2.361992
, Fri Dec  6 11:55:54 2019: dropping number of Gaussions to 3
, Fri Dec  6 11:55:54 2019: iteration 23, lowerbound -2.331832
, Fri Dec  6 11:55:54 2019: iteration 24, lowerbound -2.311239
, Fri Dec  6 11:55:54 2019: iteration 25, lowerbound -2.307862
, Fri Dec  6 11:55:54 2019: dropping number of Gaussions to 2
, Fri Dec  6 11:55:54 2019: iteration 26, lowerbound -2.302917
, Fri Dec  6 11:55:54 2019: iteration 27, lowerbound -2.299260
, Fri Dec  6 11:55:54 2019: iteration 28, lowerbound -2.299256
, Fri Dec  6 11:55:54 2019: iteration 29, lowerbound -2.299254
, Fri Dec  6 11:55:54 2019: iteration 30, lowerbound -2.299254
, Fri Dec  6 11:55:54 2019: iteration 31, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 32, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 33, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 34, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 35, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 36, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 37, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 38, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 39, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 40, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 41, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 42, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 43, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 44, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 45, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 46, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 47, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 48, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 49, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: iteration 50, lowerbound -2.299253
, Fri Dec  6 11:55:54 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509222607933, 95.95490777392084]
Î² = [178.04509222607933, 95.95490777392084]
m = [4.250300733269377 79.28686694435397; 2.0002292577748206 53.85198717245841]
Î½ = [180.04509222607933, 97.95490777392084]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547477605 -0.007644049042334374; 0.0 0.008581705166323344], [0.3758763611957543 -0.00895312382735706; 0.0 0.01274866477741189]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999991
avll from stats: -1.000102867271955
avll from llpg:  -1.0001028672719574
avll direct:     -1.0001028672719572
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9873180352479053
avll from llpg:  -0.9873180352479051
avll direct:     -0.9873180352479051
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
  0.0443822    0.151521      0.148049     0.0419047   -0.12281     -0.082936     0.00528314  -0.0540233    0.0323966   -0.0756252    0.026941      0.0431177    0.0430241    0.225815     0.0384548  -0.0814888    0.148048     0.0838932    0.0236254    0.071973    -0.066172     -0.0341621    0.105853     0.0109381   0.0620841     0.166618   
  0.0647773   -0.00414749   -0.1545       0.112778    -0.0638484   -0.0159124   -0.0590014    0.0206796    0.038861     0.165958    -0.111169      0.00755992   0.238503     0.071694     0.0877367   0.13317      0.0286122    0.0296114   -0.0331139   -0.105687    -0.120165     -0.00479379   0.250508    -0.100337    0.0301665     0.152507   
  0.106345     0.123447     -0.117586    -0.138125    -0.00702786  -0.0156603    0.0423108   -0.0533643   -0.038382     0.0993463    0.059914     -0.0144596    0.192453     0.112123    -0.0749929  -0.0233829   -0.0249014   -0.0680783    0.203033     0.0479567    0.144192      0.0845297    0.0555652   -0.0493473   0.1332       -0.132533   
 -0.044955     0.00735971    0.0618533   -0.0566638   -0.0832279    0.0368334   -0.0216576    0.00164277  -0.0559933   -0.0237131   -0.000930547   0.171488     0.0159375   -0.143629     0.0532533   0.0551726    0.0808159   -0.182224     0.00100796   0.00432082   0.055498     -0.102213    -0.147198    -0.0815643   0.200668      0.0563526  
  0.0464265    0.0885177    -0.042536     0.17953      0.0619185   -0.0139967    0.0447659   -0.0410406    0.00129602  -0.133099     0.125843     -0.22995     -0.20466      0.20978      0.0968284   0.0713963    0.0849682    0.0622533    0.0216642   -0.120766    -0.0125728    -0.441981     0.077076    -0.0109286  -0.0488975     0.0281014  
  0.187055     0.173511     -0.102743     0.124551    -0.0720824   -0.0206628    0.0908102    0.0459258   -0.0612466   -0.0735853   -0.0446755    -0.0198152   -0.0325988    0.11933     -0.0883055  -0.0843172    0.11676     -0.00266901  -0.0608475    0.127307     0.0784383     0.0873285    0.0774133   -0.0389642   0.165313      0.02193    
  0.030393     0.0329505    -0.0907267   -0.0736962    0.0240729    0.0408327    0.0210339   -0.0231273   -0.0569537   -0.133715     0.0331542     0.102199     0.084038    -0.0337343   -0.0161872  -0.00631665   0.0222453    0.0496177   -0.105661     0.0806185   -0.0374469    -0.00707738   0.0160964    0.0739211   0.0268586    -0.0119799  
  0.116694    -0.142229     -0.0702863    0.0451733   -0.0229594    0.210308    -0.0840709   -0.0568738    0.010661    -0.00298064   0.0440517     0.0995609   -0.159639     0.0509165   -0.0684931  -0.0403449    0.0437812    0.148617    -0.13407      0.0183605    0.108172      0.0863455   -0.0555357    0.0574467  -0.0934966     0.032691   
  0.00262173   0.13625      -0.111495    -0.231619    -0.0388859   -0.00406873  -0.0782381    0.0651856   -0.192092     0.156797    -0.0965738     0.0720269    0.0467707   -0.0298846    0.0617825   0.00719078   0.109748    -0.022266    -0.125613    -0.0438879   -0.0601389     0.0063082   -0.0792728   -0.246673    0.0871438     0.0622096  
  0.0243839   -0.000235666   0.0454838    0.296607    -0.00280795   0.0100698   -0.00368874  -0.00484414  -0.00336254  -0.0413441   -0.0234315    -0.00555866  -0.12194     -0.156508    -0.0180725  -0.0906026   -0.0943982   -0.0934229   -0.0972731    0.120136     0.253521      0.100902     0.0567196   -0.0383071  -0.120679      0.0364095  
  0.0240428   -0.0701867     0.0343606    0.0618166    0.053282    -0.0601941    0.02553     -0.082017    -0.00158566  -0.230484     0.029191     -0.163533    -0.0807648   -0.169227     0.157974    0.137843    -0.125029    -0.168048     0.103448    -0.213398     0.177958     -0.0189508   -0.0553214   -0.0251178   0.270745     -0.108277   
  0.0574694    0.0631832    -0.117243     0.117973    -0.128064    -0.107586    -0.0501242   -0.161693     0.0896871    0.020856     0.0606704    -0.0529016    0.0407687   -0.185861    -0.0627883   0.0668319   -0.126742     0.106678     0.178106     0.0912617    0.0679712    -0.171745    -0.0312469    0.055032    0.127208      0.0605756  
  0.121008    -0.0506041     0.0805196    0.120017    -0.142454     0.0696693   -0.233262     0.0573516   -0.115443    -0.104052    -0.0129844    -0.089017     0.128545     0.031838     0.0124895   0.0339272    0.175123    -0.0988726    0.221908    -0.141882     0.0629576    -0.138566     0.089112    -0.0559912  -0.00223292   -0.0315693  
  0.0810101   -0.0493773     0.0665211   -0.0481379   -0.201694     0.0501284    0.0185385    0.113818    -0.145722    -0.0338327    0.137455     -0.0675635   -0.0588424    0.0791196   -0.264235    0.0668493   -0.0699165   -0.105138    -0.143854     0.165465     0.0129018     0.0951023    0.0825257   -0.14526     0.0162599     0.212412   
  0.117303     0.0245847    -0.0106532   -0.00648549   0.203621     0.0105218   -0.0298011    0.0251957   -0.0206883    0.0197833   -0.126862      0.136249     0.153217    -0.00934202  -0.196339   -0.111801    -0.0788763   -0.0226823   -0.0172323   -0.14484      0.00234241   -0.0694618    0.169906     0.223347   -0.0413305    -0.0196536  
  0.203803     0.120147      0.0192687    0.0400337   -0.0495331   -0.0536916    0.139364     0.0476968    0.0493955   -0.147552    -0.0512978     0.0628743   -0.0841041    0.0506596    0.109284   -0.0203932   -0.085987     0.030685     0.159758     0.0437891    0.140012     -0.0105667    0.090654     0.115424   -0.0384572     0.0535955  
 -0.0797462    0.113289     -0.129697     0.110789     0.151528     0.0129185   -0.014171     0.0372184   -0.00791936   0.0384227   -0.0850421    -0.0275536    0.0980386   -0.147072    -0.0642207  -0.101329     0.0528987   -0.0833836    0.139428     0.00232341   0.000288993  -0.0633378   -0.0778052   -0.0956592   0.0287276     0.131038   
  0.0467119    0.109685      0.0843148    0.219764     0.115471     0.0675304   -0.064818     0.0471634   -0.06823      0.103507     0.107536     -0.0644021    0.0139819   -0.0808613   -0.0665881   0.128663     0.0331954   -0.0321144    0.0512652    0.118602    -0.0202099    -0.0288595   -0.105867     0.0253843   0.144121     -0.00998897 
 -0.0643206    0.0991642     0.0839069   -0.111998     0.0915179    0.0120692    0.0405162   -0.0363556   -0.269651    -0.091839     0.0720525    -0.24751      0.00582761   0.0993671   -0.108501    0.0146172   -0.146215    -0.0273269    0.0946964   -0.171309    -0.11837      -0.087308    -0.119115     0.213902    0.000594266  -0.0867084  
  0.0430618    0.0301154    -0.0612942   -0.0255007    0.018445     0.0720252    0.00966178  -0.136446    -0.0718856   -0.0560892   -0.00933571   -0.0949187   -0.0516219   -0.123815     0.0493943  -0.0928112    0.0462468   -0.0815182    0.0906266    0.280336     0.203558     -0.0881987   -0.0374926    0.0639598   0.103675     -0.133142   
  0.0028851   -0.199556     -0.0335661   -0.233889     0.0353828    0.178143     0.0171411    0.0315081   -0.228021     0.0386766    0.0943825     0.0735765    0.0830217   -0.0457801    0.0409002   0.156472     0.129344     0.0857986   -0.118122     0.0079168   -0.0670308     0.0772287    0.0192978   -0.0233492   0.039282      0.0717593  
 -0.261007     0.0346915     0.222326     0.12432     -0.114679    -0.177991     0.065323     0.0154763    0.0639223   -0.0228808   -0.0700303    -0.143835     0.011806    -0.0270621    0.0287129   0.0290563   -0.196401     0.179783     0.0247129   -0.109038    -0.048306      0.0636497    0.086584     0.104596   -0.051161     -0.000202642
  0.0117348   -0.0521917     0.165943    -0.00838011   0.0518305    0.116423    -0.0298613    0.0306175    0.211532     0.0893448   -0.0962575     0.0435613    0.0755015    0.0711781    0.0851238   0.0196079    0.00126447  -0.180063     0.0408591   -0.0788832   -0.00259044   -0.156604    -0.0862249   -0.033755    0.120525      0.0373828  
  0.0256737   -0.0553039     0.0968184    0.128335    -0.0543726   -0.0496159    0.00447006  -0.0259575   -0.0798174   -0.116643    -0.107461     -0.0265295   -0.00926115   0.0148186    0.0426661   0.0495572   -0.00342423  -0.00631887   0.118213    -0.243868    -0.130592      0.0789789   -0.124499     0.0976924   0.0749623     0.0586218  
 -0.013735    -0.0198782    -0.0777338    0.0457719    0.0759958    0.203803    -0.0682045   -0.00899468   0.111901    -0.0621351   -0.0534013    -0.0758943    0.0639228    0.228335     0.108294   -0.184014     0.049248     0.0291655   -0.0269505   -0.189179    -0.114372      0.0316568    0.0853719    0.0862779   0.0539926    -0.0508496  
  0.065476    -0.287441     -0.00638017  -0.00865058  -0.0202929   -0.144871    -0.0851927    0.165289    -0.086343     0.0854018   -0.0222672     0.0488556   -0.0609283    0.0728282    0.198712   -0.0196291   -0.0913859    0.0839536   -0.100608    -0.0484963    0.00860051   -0.0190803    0.085872     0.124465    0.0177849     0.0354264  
  0.0505187    0.103957     -0.0993276    0.110269    -0.124973     0.0793258   -0.00861844  -0.0117281   -0.156876    -0.0745045    0.0460734    -0.0311696    0.00930994  -0.0680852    0.039552   -0.161966    -0.158077     0.104191     0.0284388    0.0478781    0.0514424     0.220757    -0.125795     0.1819      0.0189821     0.00197555 
  0.0310061    0.107632     -0.0380174   -0.0753938   -0.168254     0.0415577   -0.031928     0.126353     0.109819    -0.0617607    0.0557112     0.0282618   -0.0945022    0.0208092    0.0998282   0.143882     0.0698618   -0.0194622    0.163804     0.0252857    0.16351      -0.153796    -0.0368473   -0.0960679   0.148524      0.0404164  
  0.00510284  -0.0953204    -0.0193076   -0.0778559   -0.164217    -0.00343244  -0.134402     0.095366    -0.185676    -0.00699166  -0.0336679    -0.109805     0.22675      0.0265617   -0.178973    0.106669     0.0690412   -0.125197     0.138676    -0.0916786    0.0634636     0.0126327   -0.315022     0.0361957   0.122795     -0.0717482  
  0.0493708    0.123422     -0.163774    -0.00813423   0.0730642   -0.00862344   0.0496114   -0.0618312    0.064018     0.234964     0.0395551     0.0475896   -0.0527487    0.259016    -0.0935603   0.0299093    0.143561    -0.0437527   -0.0512989   -0.0932669   -0.123442      0.0535066    0.0266198   -0.0361926   0.0162278    -0.0228759  
 -0.00890497  -0.00772568   -0.061544     0.205509    -0.0564116   -0.0511492   -0.0734059    0.0887253   -0.0548593    0.00648605  -0.0639697    -0.053296     0.0603259   -0.00475826  -0.0591264   0.0600497    0.00201739  -0.0734747   -0.0792432    0.0426088    0.0453934    -0.110247    -0.00474137   0.0817319   0.0374034    -0.128815   
 -0.181926    -0.148047      0.00747432   0.0347758    0.217688     0.171345     0.135495     0.114703     0.0311828   -0.0102161    0.244088      0.0739156   -0.0150516    0.0417793    0.0818564   0.134989    -0.0502226   -0.174752    -0.22403      0.142005     0.120415     -0.118306     0.0817507   -0.0387387   0.0191475    -0.00421346 kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.3780115953582093
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.378066
[ Info: iteration 2, average log likelihood -1.378010
[ Info: iteration 3, average log likelihood -1.377716
[ Info: iteration 4, average log likelihood -1.374254
[ Info: iteration 5, average log likelihood -1.360216
[ Info: iteration 6, average log likelihood -1.350686
[ Info: iteration 7, average log likelihood -1.349076
[ Info: iteration 8, average log likelihood -1.348563
[ Info: iteration 9, average log likelihood -1.348256
[ Info: iteration 10, average log likelihood -1.348044
[ Info: iteration 11, average log likelihood -1.347892
[ Info: iteration 12, average log likelihood -1.347779
[ Info: iteration 13, average log likelihood -1.347693
[ Info: iteration 14, average log likelihood -1.347627
[ Info: iteration 15, average log likelihood -1.347573
[ Info: iteration 16, average log likelihood -1.347529
[ Info: iteration 17, average log likelihood -1.347491
[ Info: iteration 18, average log likelihood -1.347458
[ Info: iteration 19, average log likelihood -1.347425
[ Info: iteration 20, average log likelihood -1.347391
[ Info: iteration 21, average log likelihood -1.347353
[ Info: iteration 22, average log likelihood -1.347304
[ Info: iteration 23, average log likelihood -1.347237
[ Info: iteration 24, average log likelihood -1.347138
[ Info: iteration 25, average log likelihood -1.346987
[ Info: iteration 26, average log likelihood -1.346754
[ Info: iteration 27, average log likelihood -1.346414
[ Info: iteration 28, average log likelihood -1.345978
[ Info: iteration 29, average log likelihood -1.345483
[ Info: iteration 30, average log likelihood -1.345005
[ Info: iteration 31, average log likelihood -1.344615
[ Info: iteration 32, average log likelihood -1.344356
[ Info: iteration 33, average log likelihood -1.344201
[ Info: iteration 34, average log likelihood -1.344109
[ Info: iteration 35, average log likelihood -1.344050
[ Info: iteration 36, average log likelihood -1.344011
[ Info: iteration 37, average log likelihood -1.343981
[ Info: iteration 38, average log likelihood -1.343957
[ Info: iteration 39, average log likelihood -1.343937
[ Info: iteration 40, average log likelihood -1.343920
[ Info: iteration 41, average log likelihood -1.343905
[ Info: iteration 42, average log likelihood -1.343892
[ Info: iteration 43, average log likelihood -1.343881
[ Info: iteration 44, average log likelihood -1.343872
[ Info: iteration 45, average log likelihood -1.343863
[ Info: iteration 46, average log likelihood -1.343856
[ Info: iteration 47, average log likelihood -1.343850
[ Info: iteration 48, average log likelihood -1.343845
[ Info: iteration 49, average log likelihood -1.343841
[ Info: iteration 50, average log likelihood -1.343837
â”Œ Info: EM with 100000 data points 50 iterations avll -1.343837
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3780658084730197
â”‚     -1.3780103055856474
â”‚      â‹®                 
â””     -1.343836880878086 
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.343927
[ Info: iteration 2, average log likelihood -1.343834
[ Info: iteration 3, average log likelihood -1.343537
[ Info: iteration 4, average log likelihood -1.340848
[ Info: iteration 5, average log likelihood -1.329765
[ Info: iteration 6, average log likelihood -1.318612
[ Info: iteration 7, average log likelihood -1.314560
[ Info: iteration 8, average log likelihood -1.312689
[ Info: iteration 9, average log likelihood -1.311408
[ Info: iteration 10, average log likelihood -1.310396
[ Info: iteration 11, average log likelihood -1.309556
[ Info: iteration 12, average log likelihood -1.308836
[ Info: iteration 13, average log likelihood -1.308203
[ Info: iteration 14, average log likelihood -1.307686
[ Info: iteration 15, average log likelihood -1.307291
[ Info: iteration 16, average log likelihood -1.306994
[ Info: iteration 17, average log likelihood -1.306763
[ Info: iteration 18, average log likelihood -1.306587
[ Info: iteration 19, average log likelihood -1.306457
[ Info: iteration 20, average log likelihood -1.306361
[ Info: iteration 21, average log likelihood -1.306285
[ Info: iteration 22, average log likelihood -1.306221
[ Info: iteration 23, average log likelihood -1.306164
[ Info: iteration 24, average log likelihood -1.306111
[ Info: iteration 25, average log likelihood -1.306060
[ Info: iteration 26, average log likelihood -1.306011
[ Info: iteration 27, average log likelihood -1.305961
[ Info: iteration 28, average log likelihood -1.305911
[ Info: iteration 29, average log likelihood -1.305859
[ Info: iteration 30, average log likelihood -1.305803
[ Info: iteration 31, average log likelihood -1.305743
[ Info: iteration 32, average log likelihood -1.305678
[ Info: iteration 33, average log likelihood -1.305605
[ Info: iteration 34, average log likelihood -1.305524
[ Info: iteration 35, average log likelihood -1.305436
[ Info: iteration 36, average log likelihood -1.305343
[ Info: iteration 37, average log likelihood -1.305246
[ Info: iteration 38, average log likelihood -1.305145
[ Info: iteration 39, average log likelihood -1.305039
[ Info: iteration 40, average log likelihood -1.304932
[ Info: iteration 41, average log likelihood -1.304824
[ Info: iteration 42, average log likelihood -1.304713
[ Info: iteration 43, average log likelihood -1.304599
[ Info: iteration 44, average log likelihood -1.304478
[ Info: iteration 45, average log likelihood -1.304349
[ Info: iteration 46, average log likelihood -1.304211
[ Info: iteration 47, average log likelihood -1.304061
[ Info: iteration 48, average log likelihood -1.303897
[ Info: iteration 49, average log likelihood -1.303723
[ Info: iteration 50, average log likelihood -1.303533
â”Œ Info: EM with 100000 data points 50 iterations avll -1.303533
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3439265475271585
â”‚     -1.343833938723641 
â”‚      â‹®                 
â””     -1.3035329752965035
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.303468
[ Info: iteration 2, average log likelihood -1.303099
[ Info: iteration 3, average log likelihood -1.302396
[ Info: iteration 4, average log likelihood -1.298476
[ Info: iteration 5, average log likelihood -1.286180
[ Info: iteration 6, average log likelihood -1.270042
[ Info: iteration 7, average log likelihood -1.262185
[ Info: iteration 8, average log likelihood -1.258908
[ Info: iteration 9, average log likelihood -1.256573
[ Info: iteration 10, average log likelihood -1.254406
[ Info: iteration 11, average log likelihood -1.252153
[ Info: iteration 12, average log likelihood -1.249666
[ Info: iteration 13, average log likelihood -1.247285
[ Info: iteration 14, average log likelihood -1.245729
[ Info: iteration 15, average log likelihood -1.244874
[ Info: iteration 16, average log likelihood -1.244167
[ Info: iteration 17, average log likelihood -1.243408
[ Info: iteration 18, average log likelihood -1.242614
[ Info: iteration 19, average log likelihood -1.241920
[ Info: iteration 20, average log likelihood -1.241396
[ Info: iteration 21, average log likelihood -1.241001
[ Info: iteration 22, average log likelihood -1.240696
[ Info: iteration 23, average log likelihood -1.240457
[ Info: iteration 24, average log likelihood -1.240268
[ Info: iteration 25, average log likelihood -1.240114
[ Info: iteration 26, average log likelihood -1.239982
[ Info: iteration 27, average log likelihood -1.239864
[ Info: iteration 28, average log likelihood -1.239758
[ Info: iteration 29, average log likelihood -1.239662
[ Info: iteration 30, average log likelihood -1.239571
[ Info: iteration 31, average log likelihood -1.239485
[ Info: iteration 32, average log likelihood -1.239406
[ Info: iteration 33, average log likelihood -1.239335
[ Info: iteration 34, average log likelihood -1.239273
[ Info: iteration 35, average log likelihood -1.239219
[ Info: iteration 36, average log likelihood -1.239171
[ Info: iteration 37, average log likelihood -1.239128
[ Info: iteration 38, average log likelihood -1.239091
[ Info: iteration 39, average log likelihood -1.239057
[ Info: iteration 40, average log likelihood -1.239026
[ Info: iteration 41, average log likelihood -1.238997
[ Info: iteration 42, average log likelihood -1.238968
[ Info: iteration 43, average log likelihood -1.238940
[ Info: iteration 44, average log likelihood -1.238911
[ Info: iteration 45, average log likelihood -1.238879
[ Info: iteration 46, average log likelihood -1.238841
[ Info: iteration 47, average log likelihood -1.238798
[ Info: iteration 48, average log likelihood -1.238748
[ Info: iteration 49, average log likelihood -1.238691
[ Info: iteration 50, average log likelihood -1.238622
â”Œ Info: EM with 100000 data points 50 iterations avll -1.238622
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3034678553788652
â”‚     -1.3030985061473979
â”‚      â‹®                 
â””     -1.2386216398283194
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.238701
[ Info: iteration 2, average log likelihood -1.238382
[ Info: iteration 3, average log likelihood -1.237273
[ Info: iteration 4, average log likelihood -1.228381
[ Info: iteration 5, average log likelihood -1.203400
[ Info: iteration 6, average log likelihood -1.182125
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      4
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.168950
[ Info: iteration 8, average log likelihood -1.181040
[ Info: iteration 9, average log likelihood -1.166463
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.157412
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.185036
[ Info: iteration 12, average log likelihood -1.182677
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.163998
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     4
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.163729
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.168863
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.177352
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.174548
[ Info: iteration 18, average log likelihood -1.170289
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.157587
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.159374
[ Info: iteration 21, average log likelihood -1.182939
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.165407
[ Info: iteration 23, average log likelihood -1.164844
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     4
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.153860
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.163228
[ Info: iteration 26, average log likelihood -1.182382
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.170347
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.166162
[ Info: iteration 29, average log likelihood -1.164684
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.153607
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.179391
[ Info: iteration 32, average log likelihood -1.174047
[ Info: iteration 33, average log likelihood -1.159747
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚      6
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.150587
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.171067
[ Info: iteration 36, average log likelihood -1.177880
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      4
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.163652
[ Info: iteration 38, average log likelihood -1.173509
[ Info: iteration 39, average log likelihood -1.159603
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.150600
[ Info: iteration 41, average log likelihood -1.186934
[ Info: iteration 42, average log likelihood -1.172330
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.158200
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.159908
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      6
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.158951
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.178400
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.173590
[ Info: iteration 48, average log likelihood -1.168636
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.156295
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.158692
â”Œ Info: EM with 100000 data points 50 iterations avll -1.158692
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.238700717096097 
â”‚     -1.2383821364037748
â”‚      â‹®                 
â””     -1.1586915500885704
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.182837
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.165838
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.159985
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.139254
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     20
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.121951
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.096853
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     11
â”‚     19
â”‚     20
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.084942
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      2
â”‚      8
â”‚     25
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.065451
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚     20
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.077023
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     19
â”‚     20
â”‚     25
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.056772
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.074254
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      8
â”‚     11
â”‚     20
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.048806
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     19
â”‚     20
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.083970
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.061878
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      8
â”‚     11
â”‚     20
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.052634
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚     19
â”‚     20
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.059155
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.078911
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚     20
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.062246
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     11
â”‚     19
â”‚     20
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.056129
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.081148
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     20
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.054054
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     19
â”‚     20
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.046734
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.072149
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     20
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.064874
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     11
â”‚     19
â”‚     20
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.047485
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.074218
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     20
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.054791
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.041701
[ Info: iteration 29, average log likelihood -1.090099
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      8
â”‚     20
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.049351
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚     11
â”‚     19
â”‚     20
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.048375
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.078861
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     20
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.065798
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.037064
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.085460
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     20
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.055246
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     19
â”‚     20
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.059730
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.068917
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚     20
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.055771
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     11
â”‚     19
â”‚     20
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.046997
[ Info: iteration 41, average log likelihood -1.085885
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     20
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.046109
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     19
â”‚     20
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.053472
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.074882
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚     20
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.062445
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     11
â”‚     19
â”‚     20
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.041792
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.081125
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     20
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.051969
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     19
â”‚     20
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.058721
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.068902
â”Œ Info: EM with 100000 data points 50 iterations avll -1.068902
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.1828370289240182
â”‚     -1.1658380501285597
â”‚      â‹®                 
â””     -1.0689019572679774
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.3780115953582093
â”‚     -1.3780658084730197
â”‚     -1.3780103055856474
â”‚     -1.37771629569573  
â”‚      â‹®                 
â”‚     -1.0519694245643387
â”‚     -1.058721311343788 
â””     -1.0689019572679774
32Ã—26 Array{Float64,2}:
  0.0879597    0.112431     -0.131442     0.0965592   -0.113896     -0.126817    -0.0415416   -0.146204     0.0830203    0.0609071   0.0634001   -0.0521543    0.0388736  -0.228276     -0.0688872    0.0657835    -0.109995     0.134442     0.165947     0.0869881    0.0712016    -0.15361     -0.0275252    0.0563094    0.115826    -0.00180194
  0.0435414   -0.000845159  -0.112699    -0.0706288    0.0223378     0.02925      0.0303774   -0.0237241   -0.0521887   -0.123614    0.0400809    0.0965951    0.0770113  -0.0339032    -0.0138127   -0.00613709    0.0149664    0.0428674   -0.0978387    0.056521    -0.0274753    -0.00782049   0.0168138    0.0785255    0.0304083    0.0151937 
  0.0718535   -0.00947025   -0.158027     0.11082     -0.0647646     0.00321067  -0.0639764    0.0177223    0.0308278    0.147696   -0.120853     0.0117479    0.231419    0.0769969     0.0857976    0.121427     -0.0132616    0.0372015   -0.0403754   -0.103835    -0.127095     -0.0202476    0.257609    -0.103112     0.0383954    0.150771  
  0.0281373    0.134403      0.146275     0.026917    -0.127271     -0.0801047    0.00442149  -0.0551215    0.0339689   -0.0839768   0.0313249    0.0547335    0.0454255   0.233811      0.0374988   -0.0574666     0.174501     0.068508     0.0380469    0.0820562   -0.0433833    -0.0112819    0.0952129   -0.0108252    0.0620748    0.15511   
  0.0439928    0.00797489   -0.0537805    0.234226     0.0611491    -0.822182    -0.0153931    0.0644342    0.00579711  -0.196355    0.11473     -0.232827    -0.160977    0.178323      0.066794     0.0741411     0.0803981   -0.0764082    0.0116405   -0.0828305   -0.0185507    -0.501602     0.00796801  -0.0866336   -0.07068      0.108644  
  0.0470235    0.1236        0.00297429   0.190644     0.0622659     0.622605     0.126756    -0.15363     -0.00621978  -0.12212     0.120512    -0.229168    -0.222469    0.229104      0.146074     0.0714464     0.0889752    0.210828     0.023888    -0.149281    -0.00636053   -0.399572     0.129749    -0.0165969   -0.0902011   -0.0532971 
  0.0601916    0.103241     -0.0584028   -0.0845461   -0.161845      0.0583864   -0.03048      0.108146     0.103465    -0.0270617   0.0564505    0.0214135   -0.114036    0.000778653   0.103201     0.136235      0.0680031    0.0183897    0.153255     0.0397764    0.165166     -0.135796    -0.0573405   -0.0760176    0.133522     0.0387167 
  0.129643     0.0290805     0.00603478  -0.00894895   0.200177      0.0352016   -0.0355423    0.0149755   -0.0254956    0.022631   -0.131114     0.135904     0.162707   -0.00887233   -0.18532     -0.112708     -0.0791843   -0.0376988   -0.0104093   -0.140368     0.0168414    -0.0840228    0.171054     0.192691    -0.0436443   -0.0330354 
  0.0679223   -0.140696      0.0395239    0.0558997    0.0422199    -0.0336793    0.0279756   -0.00116182   0.149243    -0.512879    0.00344955  -0.183411    -0.125465   -0.196437      0.158489     0.117174     -0.688326    -0.165734     0.264906    -0.202662     0.122316      0.0193661   -0.0542863   -0.0253294    0.309366    -0.0687533 
 -0.0305274   -0.0204147     0.0416302    0.0683919    0.0702071    -0.0809467    0.0256191   -0.0802311   -0.0780317    0.0340222   0.0477206   -0.145619    -0.0515542  -0.119066      0.167404     0.173117      0.527341    -0.163747    -0.00643153  -0.224783     0.221504     -0.0769192   -0.0539465   -0.0166147    0.227855    -0.057691  
 -0.00268926  -0.195321     -0.0289815   -0.227537     0.0175501     0.171065     0.0169547    0.0293767   -0.214734     0.0442341   0.0522543    0.0569081    0.0755786  -0.0313609     0.0406242    0.141174      0.129765     0.0859845   -0.117812    -0.0118348   -0.0563687     0.0534027    0.0124249   -0.0211558    0.0527982    0.020144  
 -0.256581     0.0396244     0.227675     0.111874    -0.110056     -0.177474     0.0692142    0.0252709    0.0499691   -0.0289085  -0.0675859   -0.139505     0.0032569  -0.0264103     0.0513618    0.0159118    -0.187438     0.180552     0.0208315   -0.109011    -0.0496146     0.0631174    0.0910438    0.135733    -0.0369489    0.0103088 
  0.028792     0.032108     -0.0237025    0.0740796   -0.0058324    -0.0410428    0.0142753   -0.0423456    0.035408     0.0423445  -0.03712      0.00624048  -0.0170044   0.103853     -0.0148063    0.0472765     0.0661976    0.022332     0.0535645   -0.177218    -0.154923      0.0591401   -0.0555041    0.0409496    0.0411064    0.0174059 
  0.0897202   -0.0596857     0.0800238   -0.0444911   -0.202467      0.0509244   -0.0358843    0.112509    -0.148517    -0.0303688   0.174828    -0.0672765   -0.0721016   0.0341       -0.269021     0.0658274    -0.0687578   -0.109988    -0.153336     0.171506    -0.000923008   0.0555677    0.116269    -0.142595     0.0564149    0.213758  
  0.0190153   -0.0516863    -0.00704      0.00239234  -0.0595251     0.112499    -0.0303193   -0.0272389   -0.0190896   -0.0138332   0.0251901    0.113911    -0.0764219  -0.0435276    -0.0117975    0.0064101     0.0574748   -0.0195699   -0.0774628   -0.0301798    0.110558      0.00468191  -0.0888084   -0.00262628   0.0709164    0.0450955 
  0.0500293   -0.148076      0.0207812    0.128094     0.0056121    -0.0666272   -0.050482     0.0760907   -0.0156072    0.0191354  -0.0266146    0.00760888  -0.0875818  -0.0450742     0.0845568   -0.0637211    -0.0912286   -0.0194615   -0.0920321    0.0648009    0.148693      0.0393679    0.0696578    0.0538022   -0.058414     0.0441696 
  0.0089973   -0.0406621     0.189065     0.00194683   0.0479012     0.113096    -0.0507298    0.0215642    0.214827     0.0910772  -0.0935984    0.0850085    0.0400373   0.0710233     0.0767846    0.0464213    -0.00433457  -0.182467     0.0230266   -0.0615114   -0.000960674  -0.196174    -0.0800529   -0.109824     0.123985     0.0299219 
 -0.0236016    0.0127554     0.0187567   -0.0885002   -0.0338867    -0.00131933  -0.0233029    0.03138     -0.231134    -0.0582068   0.0189403   -0.163692     0.096102    0.0743167    -0.134829     0.0265856    -0.0379002   -0.0962552    0.11684     -0.140167    -0.0545025    -0.0210472   -0.211354     0.114753     0.081112    -0.0776186 
  0.0572091    0.129784     -0.0997307    0.128031    -0.150054      0.0827788   -0.0402844    0.00588819  -0.155409    -0.108462    0.0533899    0.013058    -0.0534967  -0.0911097     0.0489298   -0.167733     -0.162072     0.117255     0.11092      0.0625077    0.0660917     0.216094    -0.130512     0.208383     0.0170052    0.00152747
 -0.00261129   0.136988     -0.103198    -0.230409    -0.0557137    -0.00480637  -0.0831143    0.071872    -0.202132     0.153668   -0.0906662    0.0523305   -0.0499344  -0.012896      0.0634509    0.00935415    0.0669632   -0.0255759   -0.12735     -0.0555112   -0.0691888     0.0395278   -0.0720942   -0.255946     0.0952332    0.051557  
 -0.118808     0.0827968    -0.12579      0.116457     0.153623     -0.00824782  -0.0144121    0.0590619   -0.0647796    0.0612642  -0.0851322   -0.0390435    0.0974747  -0.14583      -0.045679    -0.0929276     0.0433024   -0.0528436    0.157289    -0.0178453    0.00444526   -0.0625013   -0.0552574   -0.0980662    0.0428977    0.138852  
  0.170863     0.106977      0.0304163    0.0373602   -0.0548981    -0.0408448    0.133349     0.0425743    0.0511599   -0.150075   -0.077719     0.0524837   -0.0793746   0.0762775     0.105424    -0.00285344   -0.102021     0.0367489    0.156628     0.0789601    0.136121     -0.0120172    0.0886612    0.100969    -0.0422109    0.0525221 
  0.0272312   -0.0122708    -0.0604193    0.099605    -0.0196272     0.0130795   -0.0421334   -0.0213961   -0.0714675   -0.0364672  -0.0593362   -0.078101     0.0195183  -0.0617435    -0.00628143  -0.00836289    0.0160066   -0.0786486   -0.00416499   0.177645     0.10325      -0.0992941   -0.0322843    0.0828564    0.0774776   -0.126967  
 -0.0992938   -0.0902857    -0.0446527    0.0705031    0.129863      0.138872     0.0309406    0.0450834    0.0676162   -0.0497779   0.0867345   -0.00263233   0.0334418   0.10865       0.0834384    0.000689394  -0.0105897   -0.0648101   -0.112694     0.00875693   0.0145578    -0.0558791    0.0696802    0.0287962    0.0486496   -0.0227781 
 -0.0137507    0.518908      0.119698    -0.23223     -0.137095      0.0220923   -0.47697      0.0475991   -0.120985     0.206812    0.0176943    0.067638     0.147338    0.0357296    -0.799383     0.0449761     0.142424    -0.0799342    0.164919    -0.13399      0.974034      0.150504     0.0734367   -0.0731575   -0.00293025  -0.0392155 
  0.183989    -0.248052      0.0583814    0.172439    -0.138598      0.0671603   -0.181275     0.0475913   -0.128922    -0.162451   -0.0240937   -0.104619     0.118126    0.0142347     0.276343     0.030621      0.159258    -0.0792982    0.234051    -0.129841    -0.134062     -0.248329     0.067176    -0.0406529   -0.0030554   -0.0427806 
  0.0444281    0.107962      0.0792401    0.244144     0.117095      0.0679015   -0.0725901    0.042736    -0.0903288    0.105006    0.108988    -0.046406     0.014643   -0.0855344    -0.0521001    0.129311      0.0252132   -0.0147908    0.0528436    0.129462    -0.0088392    -0.0102867   -0.144384     0.0196958    0.14399     -0.00445395
  0.187814     0.171249     -0.107491     0.102151    -0.0617085    -0.015829     0.0807761    0.040061     0.0259012   -0.0830649  -0.0963827   -0.012663    -0.033408    0.144088     -0.0753845   -0.0799592     0.116978    -0.00511586  -0.0606195    0.128723     0.0976784     0.0817577    0.106638    -0.0573653    0.165848     0.0206464 
  0.140229     0.116423      0.266665    -0.258012    -0.0178444     0.138708    -1.39148      0.0400511   -0.02305      0.352814   -0.00158663  -0.112082     0.174208    0.136939      0.00321129  -0.0185314    -0.0411759   -0.0630925    0.128429     0.190576     0.127294      0.0860493    0.0422514    0.0216646    0.133088    -0.207729  
  0.0598077    0.103545     -0.212674    -0.076884    -0.000744099   0.0900562    0.703329    -0.105512    -0.0917698    0.236647    0.0730446   -0.0295033    0.203146   -0.0507651     0.0181774   -0.024574     -0.013786    -0.0707609    0.190234     0.223004    -0.0468271     0.061144    -0.0342537   -0.166978     0.128922    -0.0612455 
  0.111062     0.131997     -0.589523    -0.0091552   -0.0088516    -0.207903    -0.780656    -0.0996679    0.0339357   -0.201687    0.13532     -0.0206383    0.228726    0.119303     -0.142205    -0.022427     -0.0128527   -0.0701894    0.302047     0.0248153    0.240837      0.0607585    0.0649285   -0.0585003    0.138429    -0.076012  
  0.136907     0.133344     -0.147451    -0.0971134   -0.00406221   -0.133625     2.00824     -0.0247987   -0.0308066   -0.0628757   0.00863216   0.0690745    0.163315    0.186994     -0.194178    -0.0263387    -0.0246023   -0.0741106    0.16598     -0.174412     0.168834      0.178535     0.126128     0.00966048   0.133696    -0.0634082 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚     20
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.055747
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.025712
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚     20
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.055193
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.026026
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚     20
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.055189
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.026021
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚     20
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.055186
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.026017
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚     20
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.055182
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.026013
â”Œ Info: EM with 100000 data points 10 iterations avll -1.026013
â”” 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.318567e+05
      1       6.434554e+05      -1.884013e+05 |       32
      2       6.142911e+05      -2.916433e+04 |       32
      3       6.007670e+05      -1.352402e+04 |       32
      4       5.924457e+05      -8.321329e+03 |       32
      5       5.863513e+05      -6.094446e+03 |       32
      6       5.819383e+05      -4.412943e+03 |       32
      7       5.792419e+05      -2.696415e+03 |       32
      8       5.777320e+05      -1.509958e+03 |       32
      9       5.769205e+05      -8.114503e+02 |       32
     10       5.764897e+05      -4.307896e+02 |       32
     11       5.762638e+05      -2.259100e+02 |       32
     12       5.761118e+05      -1.520354e+02 |       32
     13       5.760032e+05      -1.085460e+02 |       32
     14       5.759309e+05      -7.231384e+01 |       32
     15       5.758702e+05      -6.068538e+01 |       32
     16       5.758131e+05      -5.713642e+01 |       32
     17       5.757554e+05      -5.773266e+01 |       32
     18       5.756919e+05      -6.344885e+01 |       32
     19       5.756287e+05      -6.317250e+01 |       32
     20       5.755668e+05      -6.190024e+01 |       32
     21       5.754821e+05      -8.473024e+01 |       32
     22       5.753644e+05      -1.177106e+02 |       32
     23       5.751990e+05      -1.654188e+02 |       32
     24       5.749451e+05      -2.538872e+02 |       32
     25       5.745758e+05      -3.692661e+02 |       32
     26       5.739973e+05      -5.785657e+02 |       32
     27       5.731716e+05      -8.256780e+02 |       32
     28       5.720478e+05      -1.123789e+03 |       32
     29       5.709919e+05      -1.055938e+03 |       32
     30       5.702264e+05      -7.654681e+02 |       32
     31       5.696121e+05      -6.143180e+02 |       32
     32       5.691082e+05      -5.038564e+02 |       32
     33       5.687231e+05      -3.850608e+02 |       32
     34       5.684797e+05      -2.434332e+02 |       32
     35       5.683183e+05      -1.614183e+02 |       32
     36       5.682016e+05      -1.167051e+02 |       32
     37       5.680904e+05      -1.111911e+02 |       32
     38       5.679528e+05      -1.375524e+02 |       32
     39       5.677785e+05      -1.743468e+02 |       32
     40       5.676151e+05      -1.633926e+02 |       32
     41       5.675048e+05      -1.103076e+02 |       31
     42       5.674001e+05      -1.047091e+02 |       32
     43       5.673369e+05      -6.318490e+01 |       32
     44       5.673058e+05      -3.114141e+01 |       32
     45       5.672818e+05      -2.393626e+01 |       32
     46       5.672647e+05      -1.708240e+01 |       30
     47       5.672546e+05      -1.018082e+01 |       30
     48       5.672468e+05      -7.741299e+00 |       27
     49       5.672414e+05      -5.394166e+00 |       26
     50       5.672382e+05      -3.206112e+00 |       25
K-means terminated without convergence after 50 iterations (objv = 567238.2264120979)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.301559
[ Info: iteration 2, average log likelihood -1.272429
[ Info: iteration 3, average log likelihood -1.245864
[ Info: iteration 4, average log likelihood -1.216927
[ Info: iteration 5, average log likelihood -1.176295
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.122152
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     15
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.085170
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     22
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.067648
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚     18
â”‚     19
â”‚     23
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.053532
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.086964
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      7
â”‚     15
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.046159
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      9
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.073744
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚     16
â”‚     21
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.051489
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     12
â”‚     18
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.061400
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      4
â”‚     11
â”‚     15
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.041256
[ Info: iteration 16, average log likelihood -1.099755
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      7
â”‚     19
â”‚     21
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.051865
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      9
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.058956
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚     15
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.028773
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚     16
â”‚     18
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.046566
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     11
â”‚     14
â”‚     19
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.046255
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      7
â”‚      9
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.059447
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚     15
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.046946
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.052673
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚     14
â”‚     16
â”‚     18
â”‚     19
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.015341
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚      7
â”‚      9
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.076717
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     15
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.073836
[ Info: iteration 28, average log likelihood -1.074299
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     14
â”‚     16
â”‚     18
â”‚     21
â”‚     22
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.006470
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      4
â”‚      7
â”‚      9
â”‚     19
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.051464
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     15
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.079825
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.089752
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     21
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.040583
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     11
â”‚     14
â”‚     16
â”‚     18
â”‚     19
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.006088
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      7
â”‚     25
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.083203
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.088383
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     21
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.048736
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     14
â”‚     18
â”‚     19
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.020548
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     15
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.067023
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      7
â”‚     16
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.066963
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     21
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.047991
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     14
â”‚     18
â”‚     19
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.026590
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     15
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.078278
[ Info: iteration 44, average log likelihood -1.075246
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      4
â”‚      7
â”‚     11
â”‚     16
â”‚     21
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.005970
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      9
â”‚     14
â”‚     18
â”‚     19
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.052488
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     15
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.091977
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.097027
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚      9
â”‚     21
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.039210
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     14
â”‚     16
â”‚     18
â”‚     19
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.033346
â”Œ Info: EM with 100000 data points 50 iterations avll -1.033346
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.126247     0.0260277   -0.000714559  -0.00705752   0.197047     0.0352972   -0.0356616   0.016751    -0.0249412    0.0236249    -0.129243    0.134285     0.167421    -0.00771321  -0.183337    -0.108486     -0.080955    -0.0384312  -0.0127984  -0.137867     0.0118803   -0.0858572    0.173942     0.190741   -0.0446924    -0.0304652 
  0.0279847    0.0446143    0.0921431     0.130401    -0.0739777   -0.194281     0.137229    0.13995     -0.0649315   -0.103557     -0.0651763  -0.0171664   -0.0111691   -0.0732348    0.0749544   -0.0441234     0.026611     0.0814577   0.191805   -0.241291    -0.127969     0.0395045   -0.0967617    0.105614    0.107973      1.69532   
  0.0615236    0.10265     -0.0562904    -0.0786915   -0.171488     0.0546492   -0.0304938   0.11205      0.105958    -0.0273701     0.0574461   0.0192833   -0.120123     0.00474566   0.105167     0.135607      0.0687856    0.0152186   0.156802    0.036574     0.167679    -0.133452    -0.0604642   -0.0793262   0.136251      0.0436359 
 -0.21402     -0.188294    -0.0335652    -0.0102868    0.151452     0.154066     0.149753    0.126321     0.0727555    0.000785228   0.130109    0.07182     -0.0645904    0.0505121    0.0731629    0.112503     -0.0847409   -0.130466   -0.280895    0.117343     0.162337    -0.106441     0.113043    -0.0596343   0.0467127     0.0268341 
  0.00460432  -0.0967949   -0.0465806    -0.0744633   -0.165624    -0.0159407   -0.129326    0.120095    -0.187185    -0.0183794    -0.0320351  -0.109014     0.234699     0.0440759   -0.179767     0.105791      0.0332112   -0.170113    0.134947   -0.0929505    0.0342227    0.010226    -0.317564     0.0618476   0.146783     -0.0779397 
  0.0097663   -0.0404338    0.189259      0.00214554   0.0491104    0.111932    -0.0514182   0.0230118    0.215029     0.0913694    -0.0938327   0.0851755    0.0413559    0.0709944    0.0759649    0.0476154    -0.00455408  -0.183288    0.0226561  -0.0644479   -0.00103044  -0.198592    -0.079115    -0.109583    0.123654      0.0304862 
  0.042457     0.105651     0.0786013     0.242347     0.114739     0.068191    -0.0654302   0.0449649   -0.0949656    0.101074      0.107964   -0.044117     0.012748    -0.0854261   -0.0498288    0.122619      0.0275973   -0.0214311   0.0489668   0.123246    -0.0156807   -0.00723394  -0.136447     0.0158131   0.138559     -0.00747198
  0.0503666    0.0623621    0.00553341    0.0703777   -0.0980076   -0.0443386   -0.0254688  -0.0253263    0.0385173    0.0317588    -0.0342832   0.0320807    0.128022     0.148788     0.066739     0.0353338     0.0901789    0.0560002   0.0104333  -0.00369687  -0.0800962   -0.0166006    0.178127    -0.0550048   0.0572974     0.148889  
 -0.0592568   -0.0842171   -0.0553719     0.225835     0.00707167  -0.101107    -0.027859    0.07666     -0.0608196   -0.0123129    -0.0073727  -0.0438664    0.0887683    0.00139975  -0.030814     0.0826769     0.00508999  -0.0964538  -0.132572    0.0647066    0.0516871   -0.119022    -0.0173056    0.137595    0.0267176    -0.108243  
  0.113024     0.121248    -0.173978     -0.110393    -0.00774322  -0.0249401    0.116105   -0.0464624   -0.0276223    0.0803595     0.0536886  -0.0240912    0.192257     0.0980867   -0.0786664   -0.0228259    -0.0225672   -0.0691532   0.197373    0.0692592    0.121947     0.0960103    0.0474736   -0.0506018   0.133576     -0.100466  
  0.12246     -0.123149    -0.0719265     0.0278974   -0.0250053    0.182606    -0.0772213  -0.0557556    0.00856044  -0.00250651    0.0498865   0.0962107   -0.119244     0.0520543   -0.0775581   -0.0512586     0.0394374    0.153665   -0.134203   -0.0279108    0.135713     0.0470373    0.00544253   0.0544657  -0.0852768     0.0451841 
  0.174664     0.15373     -0.100092      0.101424    -0.0420418   -0.00950409   0.0815716   0.0500219    0.0476023   -0.0792604    -0.0767479  -0.00764054  -0.0329437    0.145709    -0.071348    -0.0585608     0.111937    -0.0136992  -0.062667    0.128717     0.102185     0.0678793    0.105383    -0.0685531   0.150781      0.022661  
  0.0498095   -0.152539     0.021064      0.128763     0.00513339  -0.0693649   -0.0483969   0.0752143   -0.0110987    0.0184017    -0.0268586   0.00606385  -0.0909731   -0.0441412    0.0903537   -0.0599086    -0.0912735   -0.0246076  -0.0924828   0.0669214    0.143019     0.0363194    0.0724538    0.0508569  -0.0566438     0.0433003 
  0.174726     0.108436     0.0370824     0.0390682   -0.0527499   -0.0450614    0.138715    0.0432484    0.0549209   -0.157032     -0.0813992   0.0558017   -0.0814963    0.0735402    0.108718    -0.000398143  -0.100026     0.0346362   0.160966    0.0850033    0.141394    -0.0118409    0.0903908    0.0997756  -0.0404925     0.060113  
  0.0700898    0.0880821   -0.11662       0.11727     -0.12132     -0.0923303   -0.0463333  -0.159078     0.0897726    0.0671583     0.0728074  -0.0507234    0.040626    -0.197192    -0.0452961    0.0695441    -0.141025     0.125917    0.172156    0.088665     0.0690371   -0.170481    -0.0305476    0.0571153   0.120251      0.0227805 
  0.058837     0.0183747   -0.0575004    -0.0380886    0.0185784    0.116258    -0.006092   -0.088756    -0.0685211   -0.0582608    -0.0343254  -0.0944987   -0.04053     -0.120226     0.0462122   -0.0810632     0.00809989  -0.0810252   0.0910056   0.314614     0.180488    -0.0864029   -0.029686     0.0485333   0.103851     -0.130556  
  0.00810502  -0.0741671    0.0980186     0.129189    -0.0776882   -0.0110798   -0.0748918  -0.0928565   -0.0279971   -0.104403     -0.0936598  -0.0262285    0.00837902   0.0203275    0.0345818    0.0911102    -0.00185058   0.0339357   0.0960271  -0.243359    -0.151636     0.0840835   -0.12654      0.0936687   0.0421421    -0.664882  
 -0.0691509    0.00448973   0.0574237    -0.033036    -0.0861177    0.0673281    0.0188894   0.00371929  -0.0397346   -0.0311431    -0.0236893   0.130868     0.0157141   -0.141797     0.0455792    0.0541768     0.0754512   -0.182525   -0.0339568  -0.0379927    0.0539137   -0.0880309   -0.146136    -0.0729784   0.240868      0.0570369 
  0.0433294    0.124465    -0.169207     -0.0076919    0.0911008   -0.00907067   0.0466518  -0.0618526    0.111547     0.233404      0.0314707   0.0499506   -0.0513298    0.259309    -0.092068     0.0380004     0.147203    -0.0138147  -0.05895    -0.0878848   -0.152955     0.047064     0.0284757   -0.0422957   0.00698571   -0.0132927 
  0.0192542   -0.0813034    0.0403585     0.0627271    0.056961    -0.0556771    0.0268227  -0.040383     0.0374678   -0.24735       0.0249046  -0.164691    -0.0899135   -0.155783     0.164195     0.148801     -0.0895654   -0.164192    0.130066   -0.214598     0.169106    -0.0281643   -0.0542481   -0.022469    0.26776      -0.0647857 
  0.00167351   0.263788    -0.0942798    -0.251446    -0.0310151   -0.0223937   -0.13293     0.105752    -0.256927     0.213061     -0.0550844   0.0740864   -0.0199197   -0.0558924    0.0731612    0.0397541     0.136692    -0.043948   -0.124065   -0.0482078   -0.138542     0.0217618   -0.072207    -0.322323    0.0845406     0.0681193 
  0.144936    -0.068785     0.0800737     0.0750542   -0.141043     0.0593434   -0.27156     0.0569041   -0.136339    -0.0904005    -0.0256266  -0.0685647    0.13154      0.026919     0.0259452    0.0310206     0.161708    -0.0952697   0.213391   -0.140503     0.1229      -0.156096     0.0795441   -0.0596568  -0.000648319  -0.0428784 
  0.0437094   -0.00475341  -0.108906     -0.0704167    0.0242959    0.0318474    0.0313982  -0.0187087   -0.0565904   -0.13708       0.035687    0.101321     0.0840762   -0.0392504   -0.00978595  -0.00546576    0.0095719    0.0436904  -0.0986753   0.0637301   -0.0290743   -0.0068109    0.0159709    0.0790639   0.0253202     0.0150368 
 -0.0546725    0.086268     0.0996319    -0.114241     0.0893162    0.00116464   0.0480989  -0.0384204   -0.310091    -0.101407      0.060711   -0.227086    -0.0379224    0.0808098   -0.093288     0.00298679   -0.103956    -0.0500621   0.0985055  -0.158072    -0.144989    -0.0835104   -0.121621     0.156242    0.0360833    -0.0839331 
 -0.00400129  -0.198229    -0.0280386    -0.253504     0.022774     0.169931     0.0180248   0.0363063   -0.227657     0.0521467     0.0649582   0.0628292    0.0748963   -0.0358666    0.0401467    0.156594      0.146116     0.0858323  -0.128535   -0.00911513  -0.0609096    0.0632889    0.0129992   -0.027735    0.0570083     0.02313   
  0.10445     -0.209914    -0.0693156    -0.0204309   -0.0158851    0.168715    -0.0659307  -0.00890404   0.0342938   -0.00554163    0.0437961   0.136055    -0.30773      0.0942572   -0.0153224    0.031805      0.00612532   0.0567556  -0.124365    0.0189253    0.32978      0.0982708   -0.0508146    0.0167661  -0.0644507     0.059679  
 -0.0463194   -0.036596    -0.0821493     0.0758042    0.0809998    0.205464    -0.0570748   0.0127843    0.0769433   -0.111984     -0.0837464  -0.0756113    0.129322     0.222021     0.103992    -0.175296      0.0539402    0.0209897  -0.0388525  -0.171591    -0.107172     0.0306756    0.0768258    0.0632131   0.0632441    -0.0655609 
 -0.256984     0.0321023    0.226404      0.115886    -0.113953    -0.178777     0.0689805   0.0270556    0.0467402   -0.0283086    -0.0679337  -0.141734     0.00418886  -0.0276797    0.0536536    0.0079759    -0.18889      0.179755    0.0199059  -0.110885    -0.0509838    0.0639826    0.092671     0.133976   -0.0389549     0.00717996
 -0.124654     0.0781966   -0.125531      0.113128     0.157243    -0.0139163   -0.0128457   0.0600629   -0.0748092    0.0559728    -0.0869334  -0.0398323    0.100379    -0.145125    -0.047757    -0.0871875     0.046551    -0.0648489   0.15755    -0.0121154    0.00304334  -0.0630208   -0.0595185   -0.0988819   0.0393133     0.130917  
  0.0456966    0.0703866   -0.0221046     0.210642     0.0618301   -0.0310603    0.0626622  -0.0542707   -0.00100397  -0.156008      0.117564   -0.230896    -0.194825     0.206374     0.109947     0.0727426     0.0849888    0.0796516   0.0184727  -0.119314    -0.011829    -0.446022     0.0747431   -0.0482756  -0.0821814     0.0211382 
  0.0876868   -0.0595888    0.0819086    -0.0443028   -0.202343     0.0508206   -0.0369193   0.112933    -0.148509    -0.029099      0.17534    -0.0672136   -0.0722978    0.0340183   -0.269525     0.0658255    -0.0690678   -0.10994    -0.152912    0.172084    -0.00188965   0.0560611    0.115334    -0.143179    0.0563472     0.214401  
  0.0542104    0.121318    -0.0997743     0.100016    -0.133887     0.0790173   -0.0138141  -0.0121277   -0.152921    -0.091235      0.0525185   0.0104611   -0.0280805   -0.0707833    0.0467565   -0.158976     -0.137071     0.104038    0.0690637   0.0117664    0.0549224    0.222322    -0.127511     0.176504    0.0227311     0.00265961[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     15
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.065040
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      7
â”‚     11
â”‚     15
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.024375
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      7
â”‚      9
â”‚      â‹®
â”‚     21
â”‚     22
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.978872
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     14
â”‚     15
â”‚     16
â”‚     19
â”‚     25
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.004012
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      7
â”‚     11
â”‚     15
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.026785
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      7
â”‚      9
â”‚      â‹®
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.989497
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      7
â”‚     11
â”‚     14
â”‚     15
â”‚     18
â”‚     19
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.009331
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      7
â”‚     11
â”‚     15
â”‚     16
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.024683
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      7
â”‚      9
â”‚      â‹®
â”‚     21
â”‚     22
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.996410
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      7
â”‚     11
â”‚     14
â”‚     15
â”‚     19
â”‚     25
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.003789
â”Œ Info: EM with 100000 data points 10 iterations avll -1.003789
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.0271602   -0.0225086    0.179739      0.0735497   -0.0481193    0.124711    -0.0371896    0.216611     0.0162051   -0.078694    -0.0997782    0.0170057    0.0612547    0.0265894    0.0521701   -0.0513505   -0.00504718   0.0943379  -0.0700608   -0.0665575    0.0126497    0.0202439   -0.0297783    0.0184525   -0.157695    -0.0746516  
  0.137576     0.0173362    0.0386089    -0.0456473    0.0255924   -0.00667541  -0.0676704    0.0503968    0.0264422    0.00248582   0.112725    -0.0648839   -0.108636    -0.1317       0.00823211  -0.0183344   -0.225012     0.0901434   0.0704363    0.317406     0.15086      0.215804    -0.0216446    0.0345128    0.0224686   -0.135705   
  0.0124045   -0.134673    -0.0221396     0.189156    -0.219362     0.0558713   -0.0657735    0.0572153    0.189418     0.017177    -0.0880366   -0.0182746    0.0197531    0.0396794   -0.0864811   -0.0759953    0.0427386   -0.136257    0.00162825  -0.0884419   -0.0125347   -0.155871    -0.0339529    0.124738     0.0129975   -0.034149   
 -0.11601      0.0644283   -0.0593302     0.0700975    0.0691361   -0.0573786    0.0218637   -0.00614571  -0.150084    -0.158643     0.0175558    0.113931    -0.0711205   -0.0196735   -0.00613982   0.142925    -0.0494351   -0.0848863  -0.193777     0.0360723    0.0534997    0.0806572    0.074801     0.0369253    0.0365827   -0.0328068  
  0.135405    -0.0608091    0.202415      0.0174523    0.0207592    0.117239     0.0733561   -0.0104344   -0.105608     0.0154764   -0.111332     0.0109514    0.0465446    0.14416      0.0883841   -0.145282     0.154871    -0.0478266   0.255441    -0.0587884    0.128199    -0.0487286   -0.140186    -0.209702     0.0128274   -0.0761448  
  0.00391008  -0.179793     0.0454257     0.135338    -0.00529464   0.0951603    0.0749008    0.0106206   -0.05473      0.201925     0.255537    -0.0900687   -0.129359     0.0406774   -0.109292    -0.0980488    0.0752563   -0.229614   -0.0145715    0.238152    -0.151317     0.0321379    0.0619721   -0.0603106   -0.139996     0.139049   
 -0.0966026   -0.0698449    0.0135575    -0.144908     0.0101513   -0.178955     0.0702612   -0.151465     0.201148    -0.152454    -3.37011e-6   0.0017466   -0.0699988   -0.00521394  -0.073288    -0.00168044  -0.056755    -0.0816924  -0.0866274    0.186298     0.208608     0.0593098   -0.156214     0.0797394   -0.206154     0.128791   
 -0.0499468    0.0896806    0.0886956     0.095063     0.160192     0.12165     -0.0714825    0.0594439    0.181973     0.0258417   -0.0358373    0.0155097    0.0144982   -0.0103884   -0.07334      0.112515    -0.125582     0.136316    0.0161189   -0.0806332   -0.0322774    0.145607     0.0202025   -0.0197872    0.0159384   -0.148899   
 -0.182292    -0.0331941    0.16905       0.109374    -0.0424572   -0.15469      0.0372991    0.056677    -0.109171     0.00410472   0.0176092    0.155361    -0.0304317    0.0510004    0.14994     -0.01616     -0.00219289  -0.0456478   0.017723    -0.0397705   -0.0495947   -0.0365816    0.00992764  -0.0652301    0.065084    -0.0620103  
  0.0896596   -0.0602739    0.0684228     0.120192    -0.143621    -0.00264126  -0.0902394   -0.0450594    0.0164277   -0.0192098    0.0049844    0.170497    -0.00690516   0.0879568    0.0863147    0.057316    -0.0209477    0.167617    0.110676    -0.0745361    0.123838     0.0384572    0.140234     0.062276    -0.0432247    0.117194   
  0.212322     0.151177     0.0337452     0.0846614    0.0786231   -0.0432548   -0.0530133   -0.094473     0.0907525    0.0179635   -0.0677649    0.0472432    0.0323755   -0.0699212   -0.117517     0.143336    -0.0913027   -0.0747396   0.0056439   -0.0520335   -0.144517     0.0847384   -0.0441553   -0.117311     0.155245    -0.0590247  
  0.0441835    0.0924763    0.0921595    -0.0861039   -0.00545385  -0.0589293   -0.0632175    0.0372405   -0.0808895   -0.110587    -0.137173     0.0908246   -0.0920694   -0.0407167    0.0206512   -0.0243931   -0.0934075   -0.188652   -0.0680198    0.0330551    0.00749518  -0.151615    -0.198341     0.0651096    0.00438313   0.00332008 
  0.00334903  -0.0419872    0.107744      0.0953986    0.00737768   0.0363072   -0.0737342   -0.00457935  -0.0360665   -0.0798093   -0.0369341   -0.102955    -0.00182492   0.0168185    0.040351     0.143406    -0.0480171    0.0225966   0.111999    -0.0261969   -0.0904311    0.0904297    0.0750178    0.0263804    0.129711    -0.0559582  
  0.086456     0.118376    -0.0450198     0.163582    -0.140438    -0.237463     0.137318     0.111011     0.0141692    0.0344674   -0.0390102   -0.0423588   -0.0634512    0.0239507   -0.15765     -0.023369     0.0108412   -0.0660723  -0.192361     0.0338422   -0.0927105   -0.00153103  -0.0784786   -0.0670063    0.120135    -0.161586   
  0.0796098    0.281597     0.0397475    -0.0831626    0.0839642    0.200621    -0.123885     0.169132     0.147697    -0.140748     0.0114773    0.107122    -0.0418545    0.0495664    0.0585822    0.0889474   -0.00757189   0.0176681  -0.0732948    0.11977      0.0533438    0.0881838    0.0465929    0.102875     0.0791889   -0.163412   
 -0.0847897    0.125943    -0.133325      0.0481078    0.0458901    0.0113367   -0.133989    -0.149993     0.0426022    0.149794    -0.00863399   0.0621748   -0.15698      0.124929    -0.0174481    0.170115     0.177219     0.10688    -0.0731337    0.101518     0.0845958   -0.058468    -0.103749     0.0529029    0.10132      0.0751848  
  0.00415945  -0.0900998    0.0112666     0.0174001    0.0514558    0.0821273   -0.0931215    0.0200004    0.0792471    0.0591873    0.0253343   -0.042968    -0.0265997    0.0724078    0.0411389   -0.0510145   -0.149649     0.103077    0.0381827   -0.118826    -0.075285    -0.038757    -0.0606484   -0.172233    -0.10664     -0.0173077  
  0.139972    -0.0384536   -0.000290796   0.100579    -0.107363     0.061331     0.20413      0.0977946    0.118004    -0.0580471    0.139217     0.0822029    0.0781315   -0.0379937    0.278904    -0.266439     0.158475     0.171289   -0.230742     0.0574753    0.120661     0.00257104  -0.1289      -0.0188018    0.0302016    0.0307619  
  0.101419     0.0802577    0.0827198     0.0757989    0.0236725   -0.0741363    0.121616     0.00747712   0.0538514   -0.0327834    0.0959034    0.0364874   -0.0196451   -0.00224912   0.14262     -0.12944      0.0895331    0.136368    0.113227     0.233493    -0.0548668    0.250636    -0.101098     0.124175     0.0764084    0.0788751  
 -0.348036    -0.0774841   -0.0607517    -0.112392    -0.0684637   -0.102431    -0.0139103   -0.115796     0.0510571   -0.127951    -0.0793677   -0.0576147   -0.0419375   -0.0207885    0.092095    -0.11752     -0.0376636   -0.0225896  -0.0268965   -0.061647    -0.111068     0.0945122    0.0392895    0.116029    -0.0410667   -0.0280699  
  0.025845    -0.163168     0.0307934     0.151787     0.0189044   -0.0683468   -0.0536023   -0.0320558   -0.00603894  -0.0507002    0.109222    -0.0841027    0.218763    -0.105075    -0.16321     -0.123631     0.0589328   -0.0512857  -0.0405669    0.0942548   -0.0612132    0.300629     0.028799     0.0149073   -0.0599611   -0.10586    
  0.071343    -0.0353114    0.167381     -0.00310324   0.124902    -0.058366    -0.142473     0.076441    -0.0523124   -0.0268271    0.00558642   0.219342     0.123775    -0.0490378    0.0213549    0.133829     0.0206088    0.094865   -0.119337     0.0433179    0.0183424   -0.0849003    0.0280453    0.0196712   -0.106686    -0.0467235  
  0.0956677   -0.0113291   -0.0336535    -0.0461496    0.050965    -0.126684    -0.00875797  -0.116728    -0.0254067   -0.0670656   -0.210291    -0.015295    -0.0345827   -0.114341    -0.025525     0.0912286    0.0581972    0.0555539  -0.109592     0.160576     0.0147834    0.102069    -0.00285227  -0.091209     0.0932863   -0.0986987  
  0.0806776    0.00328847  -0.019081     -0.0602605   -0.0303639   -0.130931     0.0187598    0.0362761    0.00870433  -0.0985537    0.0302124   -0.0789686    0.00437417  -0.0504949   -0.00846005  -0.107933    -0.0863784    0.182546    0.0191718   -0.143313    -0.0173482   -0.201511    -0.259189     0.0723373    0.06653     -0.000960966
 -0.0194459   -0.0102451    0.107681     -0.0427105   -0.065543    -0.0961458    0.0314639   -0.181319     0.0320724    0.0645097    0.0128938   -0.179735    -0.0133947   -0.0232457    0.158811    -0.140962     0.145375    -0.0396915  -0.0916194    0.0729652    0.0385914    0.187536     0.101983    -0.0538516    0.0876332   -0.14149    
 -0.0169084    0.0374931    0.00666932   -0.12626      0.12379     -0.154723    -0.189303     0.0592385    0.0337194   -0.0139853   -0.138749     0.0353988   -0.0171751   -0.0233969    0.183477     0.0821869    0.0999621   -0.0856123   0.148657    -0.057453     0.0234997    0.0308248    0.115081    -0.0383789    0.0630442    0.0303508  
 -0.0666307   -0.045055    -0.105179     -0.128758    -0.107113    -0.0542752   -0.0236473    0.0227889   -0.106868    -0.0570542   -0.0619735   -0.113568     0.0994453   -0.00374166  -0.0893487    0.053012     0.0238496    0.0751922  -0.00925642  -0.00352421  -0.0184193   -0.165237     0.137544    -0.0285416    0.00143135   0.115296   
 -0.247915     0.104861     0.103354     -0.11903     -0.0808008    0.00123569   0.104331    -0.0914776    0.0270134    0.112918     0.0441142   -0.0610205    0.0542542   -0.0709972   -0.0538297   -0.152562    -0.00804762  -0.0728907   0.174022    -0.142634     0.13634      0.0417627    0.0393585   -0.123632     0.114179     0.183989   
 -0.0300398    0.0131625   -0.185586     -0.191632    -0.0163418    0.107887    -0.0752312    0.135563     0.0300174    0.115797    -0.0444628   -0.0538463   -0.0818851    0.0850071   -0.0500173    0.00842809  -0.10164     -0.0498781   0.0507349   -0.0453772    0.0866846   -0.166243     0.184502     0.0403371   -0.104539    -0.0567135  
  0.091971    -0.121471    -0.143116     -0.00844693   0.0153662    0.0339956    0.0587708    0.109492     0.0402126   -0.0741488   -0.0644348    0.0225478    0.0340401   -0.0426799   -0.160328     0.0734041   -0.110543    -0.117188    0.0839204   -0.190897     0.0873781   -0.0224849   -0.0811352    0.00570108   0.114072     0.210012   
 -0.122011     0.122666    -0.0415311     0.0458664    0.0819194    0.02448      0.0200678    0.0451928   -0.00804438   0.183075     0.0667206    0.00260706   0.08385     -0.117478     0.00138716  -0.173468     0.0371965   -0.103762   -0.0273372   -0.0834891   -0.0362028   -0.0294255   -0.0581817    0.0943637    0.0179138    0.0912784  
 -0.071818     0.0498293   -0.0169574    -0.0408982   -0.195718    -0.0151946    0.0188099    0.0245941   -0.0191978   -0.0792345    0.0729252   -0.0762289    0.12555      0.0449021    0.0987777   -0.068175     0.0211544    0.0100992  -0.0388135   -0.0239991   -0.13911     -0.139395    -0.0431535    0.0769588    0.05615      0.157889   kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4239557521336985
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423975
[ Info: iteration 2, average log likelihood -1.423893
[ Info: iteration 3, average log likelihood -1.423825
[ Info: iteration 4, average log likelihood -1.423741
[ Info: iteration 5, average log likelihood -1.423629
[ Info: iteration 6, average log likelihood -1.423472
[ Info: iteration 7, average log likelihood -1.423237
[ Info: iteration 8, average log likelihood -1.422854
[ Info: iteration 9, average log likelihood -1.422218
[ Info: iteration 10, average log likelihood -1.421277
[ Info: iteration 11, average log likelihood -1.420193
[ Info: iteration 12, average log likelihood -1.419310
[ Info: iteration 13, average log likelihood -1.418797
[ Info: iteration 14, average log likelihood -1.418560
[ Info: iteration 15, average log likelihood -1.418460
[ Info: iteration 16, average log likelihood -1.418418
[ Info: iteration 17, average log likelihood -1.418401
[ Info: iteration 18, average log likelihood -1.418393
[ Info: iteration 19, average log likelihood -1.418389
[ Info: iteration 20, average log likelihood -1.418387
[ Info: iteration 21, average log likelihood -1.418386
[ Info: iteration 22, average log likelihood -1.418385
[ Info: iteration 23, average log likelihood -1.418384
[ Info: iteration 24, average log likelihood -1.418384
[ Info: iteration 25, average log likelihood -1.418383
[ Info: iteration 26, average log likelihood -1.418383
[ Info: iteration 27, average log likelihood -1.418383
[ Info: iteration 28, average log likelihood -1.418382
[ Info: iteration 29, average log likelihood -1.418382
[ Info: iteration 30, average log likelihood -1.418382
[ Info: iteration 31, average log likelihood -1.418381
[ Info: iteration 32, average log likelihood -1.418381
[ Info: iteration 33, average log likelihood -1.418381
[ Info: iteration 34, average log likelihood -1.418381
[ Info: iteration 35, average log likelihood -1.418381
[ Info: iteration 36, average log likelihood -1.418381
[ Info: iteration 37, average log likelihood -1.418381
[ Info: iteration 38, average log likelihood -1.418380
[ Info: iteration 39, average log likelihood -1.418380
[ Info: iteration 40, average log likelihood -1.418380
[ Info: iteration 41, average log likelihood -1.418380
[ Info: iteration 42, average log likelihood -1.418380
[ Info: iteration 43, average log likelihood -1.418380
[ Info: iteration 44, average log likelihood -1.418380
[ Info: iteration 45, average log likelihood -1.418380
[ Info: iteration 46, average log likelihood -1.418380
[ Info: iteration 47, average log likelihood -1.418380
[ Info: iteration 48, average log likelihood -1.418380
[ Info: iteration 49, average log likelihood -1.418380
[ Info: iteration 50, average log likelihood -1.418380
â”Œ Info: EM with 100000 data points 50 iterations avll -1.418380
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4239747755403014
â”‚     -1.4238927572691   
â”‚      â‹®                 
â””     -1.4183798224330715
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418395
[ Info: iteration 2, average log likelihood -1.418322
[ Info: iteration 3, average log likelihood -1.418258
[ Info: iteration 4, average log likelihood -1.418180
[ Info: iteration 5, average log likelihood -1.418083
[ Info: iteration 6, average log likelihood -1.417970
[ Info: iteration 7, average log likelihood -1.417855
[ Info: iteration 8, average log likelihood -1.417753
[ Info: iteration 9, average log likelihood -1.417671
[ Info: iteration 10, average log likelihood -1.417607
[ Info: iteration 11, average log likelihood -1.417556
[ Info: iteration 12, average log likelihood -1.417511
[ Info: iteration 13, average log likelihood -1.417471
[ Info: iteration 14, average log likelihood -1.417434
[ Info: iteration 15, average log likelihood -1.417402
[ Info: iteration 16, average log likelihood -1.417373
[ Info: iteration 17, average log likelihood -1.417348
[ Info: iteration 18, average log likelihood -1.417326
[ Info: iteration 19, average log likelihood -1.417307
[ Info: iteration 20, average log likelihood -1.417289
[ Info: iteration 21, average log likelihood -1.417272
[ Info: iteration 22, average log likelihood -1.417256
[ Info: iteration 23, average log likelihood -1.417242
[ Info: iteration 24, average log likelihood -1.417228
[ Info: iteration 25, average log likelihood -1.417216
[ Info: iteration 26, average log likelihood -1.417204
[ Info: iteration 27, average log likelihood -1.417194
[ Info: iteration 28, average log likelihood -1.417185
[ Info: iteration 29, average log likelihood -1.417176
[ Info: iteration 30, average log likelihood -1.417169
[ Info: iteration 31, average log likelihood -1.417162
[ Info: iteration 32, average log likelihood -1.417156
[ Info: iteration 33, average log likelihood -1.417151
[ Info: iteration 34, average log likelihood -1.417146
[ Info: iteration 35, average log likelihood -1.417142
[ Info: iteration 36, average log likelihood -1.417138
[ Info: iteration 37, average log likelihood -1.417134
[ Info: iteration 38, average log likelihood -1.417131
[ Info: iteration 39, average log likelihood -1.417128
[ Info: iteration 40, average log likelihood -1.417125
[ Info: iteration 41, average log likelihood -1.417122
[ Info: iteration 42, average log likelihood -1.417120
[ Info: iteration 43, average log likelihood -1.417118
[ Info: iteration 44, average log likelihood -1.417115
[ Info: iteration 45, average log likelihood -1.417113
[ Info: iteration 46, average log likelihood -1.417111
[ Info: iteration 47, average log likelihood -1.417109
[ Info: iteration 48, average log likelihood -1.417107
[ Info: iteration 49, average log likelihood -1.417105
[ Info: iteration 50, average log likelihood -1.417104
â”Œ Info: EM with 100000 data points 50 iterations avll -1.417104
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4183950741653815
â”‚     -1.418321614297631 
â”‚      â‹®                 
â””     -1.4171037205318067
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417112
[ Info: iteration 2, average log likelihood -1.417060
[ Info: iteration 3, average log likelihood -1.417013
[ Info: iteration 4, average log likelihood -1.416957
[ Info: iteration 5, average log likelihood -1.416889
[ Info: iteration 6, average log likelihood -1.416806
[ Info: iteration 7, average log likelihood -1.416710
[ Info: iteration 8, average log likelihood -1.416609
[ Info: iteration 9, average log likelihood -1.416510
[ Info: iteration 10, average log likelihood -1.416418
[ Info: iteration 11, average log likelihood -1.416336
[ Info: iteration 12, average log likelihood -1.416263
[ Info: iteration 13, average log likelihood -1.416199
[ Info: iteration 14, average log likelihood -1.416142
[ Info: iteration 15, average log likelihood -1.416092
[ Info: iteration 16, average log likelihood -1.416048
[ Info: iteration 17, average log likelihood -1.416011
[ Info: iteration 18, average log likelihood -1.415979
[ Info: iteration 19, average log likelihood -1.415951
[ Info: iteration 20, average log likelihood -1.415927
[ Info: iteration 21, average log likelihood -1.415906
[ Info: iteration 22, average log likelihood -1.415887
[ Info: iteration 23, average log likelihood -1.415870
[ Info: iteration 24, average log likelihood -1.415854
[ Info: iteration 25, average log likelihood -1.415839
[ Info: iteration 26, average log likelihood -1.415824
[ Info: iteration 27, average log likelihood -1.415811
[ Info: iteration 28, average log likelihood -1.415798
[ Info: iteration 29, average log likelihood -1.415785
[ Info: iteration 30, average log likelihood -1.415773
[ Info: iteration 31, average log likelihood -1.415762
[ Info: iteration 32, average log likelihood -1.415751
[ Info: iteration 33, average log likelihood -1.415740
[ Info: iteration 34, average log likelihood -1.415730
[ Info: iteration 35, average log likelihood -1.415721
[ Info: iteration 36, average log likelihood -1.415712
[ Info: iteration 37, average log likelihood -1.415704
[ Info: iteration 38, average log likelihood -1.415696
[ Info: iteration 39, average log likelihood -1.415689
[ Info: iteration 40, average log likelihood -1.415682
[ Info: iteration 41, average log likelihood -1.415675
[ Info: iteration 42, average log likelihood -1.415669
[ Info: iteration 43, average log likelihood -1.415663
[ Info: iteration 44, average log likelihood -1.415657
[ Info: iteration 45, average log likelihood -1.415652
[ Info: iteration 46, average log likelihood -1.415647
[ Info: iteration 47, average log likelihood -1.415642
[ Info: iteration 48, average log likelihood -1.415637
[ Info: iteration 49, average log likelihood -1.415633
[ Info: iteration 50, average log likelihood -1.415628
â”Œ Info: EM with 100000 data points 50 iterations avll -1.415628
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4171121152150343
â”‚     -1.417059817100184 
â”‚      â‹®                 
â””     -1.4156281772828425
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415632
[ Info: iteration 2, average log likelihood -1.415578
[ Info: iteration 3, average log likelihood -1.415528
[ Info: iteration 4, average log likelihood -1.415470
[ Info: iteration 5, average log likelihood -1.415399
[ Info: iteration 6, average log likelihood -1.415312
[ Info: iteration 7, average log likelihood -1.415211
[ Info: iteration 8, average log likelihood -1.415097
[ Info: iteration 9, average log likelihood -1.414976
[ Info: iteration 10, average log likelihood -1.414854
[ Info: iteration 11, average log likelihood -1.414738
[ Info: iteration 12, average log likelihood -1.414630
[ Info: iteration 13, average log likelihood -1.414533
[ Info: iteration 14, average log likelihood -1.414446
[ Info: iteration 15, average log likelihood -1.414370
[ Info: iteration 16, average log likelihood -1.414302
[ Info: iteration 17, average log likelihood -1.414243
[ Info: iteration 18, average log likelihood -1.414190
[ Info: iteration 19, average log likelihood -1.414143
[ Info: iteration 20, average log likelihood -1.414101
[ Info: iteration 21, average log likelihood -1.414062
[ Info: iteration 22, average log likelihood -1.414027
[ Info: iteration 23, average log likelihood -1.413994
[ Info: iteration 24, average log likelihood -1.413964
[ Info: iteration 25, average log likelihood -1.413936
[ Info: iteration 26, average log likelihood -1.413910
[ Info: iteration 27, average log likelihood -1.413886
[ Info: iteration 28, average log likelihood -1.413863
[ Info: iteration 29, average log likelihood -1.413841
[ Info: iteration 30, average log likelihood -1.413820
[ Info: iteration 31, average log likelihood -1.413800
[ Info: iteration 32, average log likelihood -1.413781
[ Info: iteration 33, average log likelihood -1.413763
[ Info: iteration 34, average log likelihood -1.413746
[ Info: iteration 35, average log likelihood -1.413729
[ Info: iteration 36, average log likelihood -1.413714
[ Info: iteration 37, average log likelihood -1.413699
[ Info: iteration 38, average log likelihood -1.413684
[ Info: iteration 39, average log likelihood -1.413670
[ Info: iteration 40, average log likelihood -1.413657
[ Info: iteration 41, average log likelihood -1.413644
[ Info: iteration 42, average log likelihood -1.413632
[ Info: iteration 43, average log likelihood -1.413621
[ Info: iteration 44, average log likelihood -1.413610
[ Info: iteration 45, average log likelihood -1.413600
[ Info: iteration 46, average log likelihood -1.413590
[ Info: iteration 47, average log likelihood -1.413581
[ Info: iteration 48, average log likelihood -1.413572
[ Info: iteration 49, average log likelihood -1.413563
[ Info: iteration 50, average log likelihood -1.413555
â”Œ Info: EM with 100000 data points 50 iterations avll -1.413555
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4156321390202042
â”‚     -1.4155778976116595
â”‚      â‹®                 
â””     -1.4135553723950012
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413556
[ Info: iteration 2, average log likelihood -1.413488
[ Info: iteration 3, average log likelihood -1.413424
[ Info: iteration 4, average log likelihood -1.413348
[ Info: iteration 5, average log likelihood -1.413251
[ Info: iteration 6, average log likelihood -1.413131
[ Info: iteration 7, average log likelihood -1.412987
[ Info: iteration 8, average log likelihood -1.412825
[ Info: iteration 9, average log likelihood -1.412655
[ Info: iteration 10, average log likelihood -1.412488
[ Info: iteration 11, average log likelihood -1.412331
[ Info: iteration 12, average log likelihood -1.412189
[ Info: iteration 13, average log likelihood -1.412063
[ Info: iteration 14, average log likelihood -1.411953
[ Info: iteration 15, average log likelihood -1.411857
[ Info: iteration 16, average log likelihood -1.411774
[ Info: iteration 17, average log likelihood -1.411701
[ Info: iteration 18, average log likelihood -1.411637
[ Info: iteration 19, average log likelihood -1.411580
[ Info: iteration 20, average log likelihood -1.411528
[ Info: iteration 21, average log likelihood -1.411482
[ Info: iteration 22, average log likelihood -1.411441
[ Info: iteration 23, average log likelihood -1.411403
[ Info: iteration 24, average log likelihood -1.411368
[ Info: iteration 25, average log likelihood -1.411336
[ Info: iteration 26, average log likelihood -1.411306
[ Info: iteration 27, average log likelihood -1.411279
[ Info: iteration 28, average log likelihood -1.411253
[ Info: iteration 29, average log likelihood -1.411229
[ Info: iteration 30, average log likelihood -1.411206
[ Info: iteration 31, average log likelihood -1.411185
[ Info: iteration 32, average log likelihood -1.411164
[ Info: iteration 33, average log likelihood -1.411145
[ Info: iteration 34, average log likelihood -1.411127
[ Info: iteration 35, average log likelihood -1.411109
[ Info: iteration 36, average log likelihood -1.411093
[ Info: iteration 37, average log likelihood -1.411077
[ Info: iteration 38, average log likelihood -1.411062
[ Info: iteration 39, average log likelihood -1.411048
[ Info: iteration 40, average log likelihood -1.411034
[ Info: iteration 41, average log likelihood -1.411021
[ Info: iteration 42, average log likelihood -1.411008
[ Info: iteration 43, average log likelihood -1.410996
[ Info: iteration 44, average log likelihood -1.410984
[ Info: iteration 45, average log likelihood -1.410973
[ Info: iteration 46, average log likelihood -1.410962
[ Info: iteration 47, average log likelihood -1.410952
[ Info: iteration 48, average log likelihood -1.410942
[ Info: iteration 49, average log likelihood -1.410932
[ Info: iteration 50, average log likelihood -1.410923
â”Œ Info: EM with 100000 data points 50 iterations avll -1.410923
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.413556371928656 
â”‚     -1.4134881770313403
â”‚      â‹®                 
â””     -1.4109231682939145
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4239557521336985
â”‚     -1.4239747755403014
â”‚     -1.4238927572691   
â”‚     -1.4238253105292145
â”‚      â‹®                 
â”‚     -1.4109419859412446
â”‚     -1.4109324086145927
â””     -1.4109231682939145
32Ã—26 Array{Float64,2}:
 -0.79708      0.37653     -0.553611     0.576017    0.308082    -0.353459    -0.443248     0.0402741    0.142899   -0.508808     -0.0601476    0.0567736    0.0030828  -0.0623578   -0.236338    -0.171612    -0.317229    0.746065     0.177435     0.031168     0.783116     0.395228   -0.280748   -0.0524581    0.0712741   -0.155086   
  0.949735     0.807986    -9.13392e-5   0.613707    0.115156    -0.315586     0.0838568   -0.594487     0.194767   -0.478247      0.0237871   -0.438653     0.253781    0.149946     0.318317     0.140211     0.0654249   0.552522    -0.240869     0.318429     0.0791125    0.316213    0.149718   -0.1782       0.318449     0.331742   
 -0.186413     0.214655    -0.340537    -0.376383   -0.667056    -0.176055    -0.126562     0.698584    -0.215336    0.128177      0.0149525   -0.233735     0.0963828  -0.0924084   -0.23059      0.0897368   -0.0321908  -0.193787     0.279432    -0.0554916    0.348231    -0.389814   -0.0221461  -0.112143     0.126054     0.0428526  
  0.240184     0.0618764    0.0397029    0.384704    0.863692    -0.202754     0.270716     0.530553     0.10554    -0.0640521    -0.259066     0.0564522    0.157574    0.569975    -0.00747857  -0.0813717    0.468363   -0.150591     0.422225     0.114116     0.561698    -0.623059   -0.537237    0.658951     0.135483    -0.304994   
  0.0918453   -0.537106     0.818441     0.0441098  -0.778864     0.208819     0.232198     0.393266    -0.109817   -0.12322       0.256256     0.174383     0.171658    0.335481    -0.239117     0.188059    -0.670259    0.402053    -0.315291    -0.0256516    0.0552838    0.0513129   0.80188    -0.0200086    0.136274    -0.175083   
  0.267191     0.0482158    0.541313    -0.0649728   0.139546     0.414751    -0.042864    -0.189628    -0.441965    0.436132      0.0306102   -0.310916     0.701763    0.515887    -0.241944     0.325083    -0.0719217  -0.0081349    0.055371    -0.149429     0.182169    -0.158368    0.898677   -0.00063723   0.472657     0.247854   
 -0.09768     -0.397165    -0.301708    -0.0099467  -0.429666     0.0578938   -0.0310696   -0.327112     0.329458   -0.218237      0.216303     0.858132    -0.765592    0.0226046   -0.184769    -0.196648    -0.584081   -1.22113     -0.0854231    0.0706019   -0.0293092    0.339969    0.173555   -0.262513    -0.468443    -0.41421    
 -0.0082322   -0.341487     0.236137     0.165332    0.0354524    0.322247     0.0782244   -0.252653     0.0530859  -0.236186      0.205754     0.45682     -0.0780964   0.239988     0.0729128   -0.231268    -0.597351    0.299167    -0.228545     0.242905     0.154335     0.263524    0.369529    0.0471267   -0.0656669    0.135884   
 -0.349307     0.6314      -0.463645    -0.001149    0.651332    -0.0375698    0.0379993   -0.104298    -0.414379    0.125548     -0.132784    -0.814397    -0.0396241  -0.661163     0.0684424   -0.203827     0.475147    0.167884     0.153801     0.0471556   -0.481007     0.207515   -0.735114   -0.36071     -0.363865    -0.0920934  
  0.07745     -0.0387261    0.636118    -0.428322    0.0986742    0.19336      0.434679    -0.15654      0.331119    0.32192       0.0771519   -0.495956     0.0196315  -0.00961535  -0.0943824   -0.0698632   -0.216094    0.0418422   -0.41127     -0.251063    -0.468741     0.767317   -0.666866    0.471918    -0.467136    -0.695744   
  0.536795     0.0494314    0.282806     0.457331    0.457936    -0.47334      0.441115    -0.894739    -0.361873    0.716199     -0.201476     0.568848    -0.0404032   0.193488    -0.501534    -0.0639872   -0.521498   -0.289924     0.172607     0.126016    -0.380792    -0.178608   -0.220286    0.0606346   -0.13223     -0.55239    
  0.150737     0.150176    -0.136915     0.792774   -0.130951    -0.474346     0.176315    -0.0570801   -0.249885    0.0660398    -0.155077     0.608505    -0.365373   -0.441837    -0.494544    -0.308807     0.311418   -0.301421    -0.770368     0.761336    -0.678995     0.0731138  -0.718255    0.432366     0.0283609   -0.597428   
 -0.402876    -0.504122     0.882351    -0.21238     0.138829    -0.205429    -0.437407    -0.379838     0.512728    0.203968      0.13105     -0.46441     -0.137783   -0.263557    -0.118844     0.350189     0.222452   -0.119885     0.503222    -0.547018    -0.331772     0.751685    0.355687   -0.778694     0.257516     0.536141   
  0.609442    -0.458805     0.126832    -0.0411645   0.373588     0.00715114  -0.347099    -0.492633     0.441727    0.0783329    -0.211394    -0.0297465    0.0251021  -0.554731     0.213045    -0.277488     1.33797    -0.427936     0.245796     0.212305    -0.698921     0.0514176  -0.140762   -0.100659     0.119404     0.358038   
 -0.187097    -0.309863    -0.225397    -0.0106984   0.495673     0.50548     -0.00535646  -0.60413      0.296928   -0.0401779     0.135289    -0.273733    -0.347781    0.318264     0.628454     0.427747    -0.136323    0.115396    -0.538997     0.00786532  -0.220869     0.259459   -0.0784135  -0.0622106   -0.26628     -0.0499718  
  0.226577    -0.325709     0.108849    -0.398631   -0.278883     0.283644    -0.0265817    0.353328     0.378336   -0.165423     -0.0924856   -0.32508     -0.21858     0.114544     0.880679     0.505095     0.481075   -0.247526    -0.433671    -0.152579     0.229882    -0.252393   -0.163375    0.123969    -0.00824172   0.134949   
 -0.112563     0.196455     0.126398    -0.866183   -0.696955    -0.203625    -0.277006     0.0592368    0.278564    0.0481007    -0.594328    -0.317644    -0.023397   -0.677104     0.434545    -0.284868     0.224552    0.190429     0.436381    -0.61225     -0.36809     -0.15695     0.125261    0.14126      0.473258     0.176087   
  0.0564824    0.665894     0.0940846    0.37684    -0.315282    -0.249111    -0.148196     0.753918    -0.843536   -0.37318      -0.0415222    0.117074     0.281679   -0.368144    -0.473148    -0.196035     0.0240209   0.193986     0.302942    -0.394078    -0.0313203   -0.325311    0.245922   -0.0599517    0.465202     0.14254    
  0.224207     0.27193      0.0643588    0.333244   -0.453014    -0.739363     0.402129     0.298425     0.221099   -0.056034      0.221286    -0.421521    -0.075064    0.170054     0.0738373    0.0836054    0.193573   -0.386068    -0.13154     -0.306393    -0.0439141   -0.172669    0.0184081   0.372525     0.639288    -0.448747   
  0.0239352   -0.121827    -0.16329     -0.183885   -0.785526    -0.369281    -0.108261     0.424788     0.207423    0.000175889   0.103945     0.568878     0.0132384   0.0535019   -0.108223    -0.241845    -0.149501   -0.420869     0.486785    -0.00519578   0.538929    -0.560253    0.387136    0.144936     0.298667     0.175701   
 -0.128936    -0.0934732    0.228417     0.049739    0.27145      0.0548144   -0.428136     0.294604    -0.707108   -0.256252     -0.624532     0.216524    -0.386499    0.0857465    0.0791527    0.286573     0.454918   -0.512       -0.283142     0.0250081    0.183996    -0.396189   -0.0977738  -0.091283     0.0527336    0.122666   
  0.0257289   -0.29295      0.106538    -0.0437858   0.333599    -0.167535    -0.151106     0.0548961    0.589107   -0.243193     -0.266142    -0.00498999  -0.529655   -0.187401     0.570209    -0.18789      0.645401   -0.382354     0.161769     0.277944    -0.137424    -0.0350837  -0.19406     0.113517    -0.0610174   -0.020971   
 -0.111292     0.216195     0.0603007   -0.111161    0.0503559   -0.157431    -0.0212231    0.203644     0.154608    0.233341     -0.18662     -0.489061     0.200298   -0.110118     0.138862     0.351139     0.318533    0.179247     0.0558396   -0.482753     0.0507871   -0.182693   -0.118083   -0.223677     0.070637     0.386866   
  0.0848022    0.279807    -0.156261    -0.0538251   0.20461     -0.0939332   -0.145421     0.123078    -0.139345   -0.0521614     0.0528125   -0.0704636    0.376956   -0.232317    -0.169234    -0.173557     0.527133   -0.00466507   0.29038      0.363275    -0.0506505   -0.110382   -0.24071     0.00323354  -0.307872     0.280784   
 -0.0357792   -0.0168971   -0.0307431    0.0238031  -0.00393507   0.046547     0.0464122    0.060746    -0.126521   -0.0219388     0.042865     0.207188    -0.0160302   0.165412     0.0281001    0.00627527  -0.118928   -0.0663719   -0.102844     0.0071486    0.0834714   -0.211982   -0.0105396   0.0646121   -0.0674163   -0.0988842  
  0.00548954  -0.00454711   0.028529    -0.0740765  -0.250203    -0.0438042   -0.0500122   -0.215418     0.186311    0.0307897    -0.00650571  -0.0852945   -0.0961895  -0.158361    -0.140369    -0.0783582   -0.308952    0.140649    -0.00727418   0.0219173   -0.0344957    0.491833    0.0355976   0.00674729   0.141203    -0.192223   
  0.134598    -0.202141     0.650876     0.253657    0.436971     0.0675257   -0.459129    -0.156423     0.0745224  -0.474391     -0.288542     0.295513    -0.200127    0.200728    -0.0696036   -0.386108    -0.331177    0.471596     0.0228724    0.135687     0.40081      0.568175   -0.336028    0.173236     0.353695    -0.000354921
  0.351953    -0.36159      0.432669     0.555822    0.548158     0.167518     0.420317    -0.226469    -0.116874   -0.0191869    -0.089379    -0.0213424   -0.0069234   0.0400015    0.0502262    0.102331    -0.0479503  -0.0533905   -0.240841     0.268017    -0.301062     0.338723    0.316917   -0.12501     -0.0228918   -0.163042   
 -0.666349     0.354209    -1.21218      0.0422725  -0.464142    -0.107833    -0.210269    -0.386315    -0.512168   -0.187392      0.0767498    0.0690774   -0.0157683  -0.296835    -0.0503301   -0.0661249   -0.676544    0.0207109   -1.06393     -0.576241    -0.00817797   0.227057    0.0204818  -0.227533     0.0659502    0.555096   
 -0.48227      0.17326     -0.601743    -0.193509   -0.05623     -0.167713    -0.033596    -0.169014     0.635353    0.150741      0.751188    -0.139353     0.134244    0.0408825    0.0323739    0.11588     -0.490919    0.281251     0.392297     0.0589911    0.0135522    0.277348    0.0527438  -0.336003     0.0426707    0.247458   
 -0.314331    -0.326629    -0.229217    -0.292918   -0.0982109    0.382067     0.263019     0.20832      0.02401    -0.0636813     0.174571     0.620198     0.225013   -0.251387    -0.119072    -0.739315    -0.135012    0.140345     0.17505      0.300676    -0.128796    -0.25729     0.11921    -0.0990788   -0.577067    -0.134478   
 -0.143008     0.261048    -0.568973    -0.146936   -0.0447531    0.529017     0.105862    -0.00387288  -0.457064    0.573588      0.318225     0.389207     0.39221     0.290724    -0.347038     0.292918    -0.313482    0.258026    -0.250859     0.414427     0.188844    -0.179717   -0.366259    0.144512    -0.585363     0.0211695  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410914
[ Info: iteration 2, average log likelihood -1.410906
[ Info: iteration 3, average log likelihood -1.410897
[ Info: iteration 4, average log likelihood -1.410889
[ Info: iteration 5, average log likelihood -1.410881
[ Info: iteration 6, average log likelihood -1.410874
[ Info: iteration 7, average log likelihood -1.410866
[ Info: iteration 8, average log likelihood -1.410859
[ Info: iteration 9, average log likelihood -1.410852
[ Info: iteration 10, average log likelihood -1.410845
â”Œ Info: EM with 100000 data points 10 iterations avll -1.410845
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.208157e+05
      1       7.130620e+05      -2.077538e+05 |       32
      2       6.949008e+05      -1.816122e+04 |       32
      3       6.883962e+05      -6.504518e+03 |       32
      4       6.853051e+05      -3.091124e+03 |       32
      5       6.835465e+05      -1.758584e+03 |       32
      6       6.823406e+05      -1.205917e+03 |       32
      7       6.814709e+05      -8.697568e+02 |       32
      8       6.807474e+05      -7.235042e+02 |       32
      9       6.801570e+05      -5.903709e+02 |       32
     10       6.796443e+05      -5.127154e+02 |       32
     11       6.792239e+05      -4.203518e+02 |       32
     12       6.788535e+05      -3.704421e+02 |       32
     13       6.785460e+05      -3.074785e+02 |       32
     14       6.782653e+05      -2.807090e+02 |       32
     15       6.779969e+05      -2.683599e+02 |       32
     16       6.777655e+05      -2.314051e+02 |       32
     17       6.775611e+05      -2.044170e+02 |       32
     18       6.773578e+05      -2.033227e+02 |       32
     19       6.771758e+05      -1.819651e+02 |       32
     20       6.770200e+05      -1.557652e+02 |       32
     21       6.768861e+05      -1.339017e+02 |       32
     22       6.767697e+05      -1.164174e+02 |       32
     23       6.766589e+05      -1.108748e+02 |       32
     24       6.765449e+05      -1.139832e+02 |       32
     25       6.764376e+05      -1.072369e+02 |       32
     26       6.763381e+05      -9.955397e+01 |       32
     27       6.762502e+05      -8.785525e+01 |       32
     28       6.761686e+05      -8.160065e+01 |       32
     29       6.760883e+05      -8.035710e+01 |       32
     30       6.760211e+05      -6.720196e+01 |       32
     31       6.759568e+05      -6.428758e+01 |       32
     32       6.758892e+05      -6.757210e+01 |       32
     33       6.758186e+05      -7.064739e+01 |       32
     34       6.757498e+05      -6.871291e+01 |       32
     35       6.756805e+05      -6.938119e+01 |       32
     36       6.756058e+05      -7.467444e+01 |       32
     37       6.755256e+05      -8.017726e+01 |       32
     38       6.754566e+05      -6.906027e+01 |       32
     39       6.753851e+05      -7.147546e+01 |       32
     40       6.753270e+05      -5.806983e+01 |       32
     41       6.752749e+05      -5.215571e+01 |       32
     42       6.752261e+05      -4.870748e+01 |       32
     43       6.751800e+05      -4.613060e+01 |       32
     44       6.751405e+05      -3.955996e+01 |       32
     45       6.751063e+05      -3.412287e+01 |       32
     46       6.750802e+05      -2.609417e+01 |       32
     47       6.750535e+05      -2.676373e+01 |       32
     48       6.750243e+05      -2.921784e+01 |       32
     49       6.749932e+05      -3.101662e+01 |       32
     50       6.749663e+05      -2.696191e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 674966.2759345325)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422703
[ Info: iteration 2, average log likelihood -1.417721
[ Info: iteration 3, average log likelihood -1.416373
[ Info: iteration 4, average log likelihood -1.415358
[ Info: iteration 5, average log likelihood -1.414262
[ Info: iteration 6, average log likelihood -1.413218
[ Info: iteration 7, average log likelihood -1.412481
[ Info: iteration 8, average log likelihood -1.412069
[ Info: iteration 9, average log likelihood -1.411848
[ Info: iteration 10, average log likelihood -1.411713
[ Info: iteration 11, average log likelihood -1.411617
[ Info: iteration 12, average log likelihood -1.411543
[ Info: iteration 13, average log likelihood -1.411481
[ Info: iteration 14, average log likelihood -1.411427
[ Info: iteration 15, average log likelihood -1.411380
[ Info: iteration 16, average log likelihood -1.411337
[ Info: iteration 17, average log likelihood -1.411298
[ Info: iteration 18, average log likelihood -1.411261
[ Info: iteration 19, average log likelihood -1.411228
[ Info: iteration 20, average log likelihood -1.411196
[ Info: iteration 21, average log likelihood -1.411166
[ Info: iteration 22, average log likelihood -1.411138
[ Info: iteration 23, average log likelihood -1.411111
[ Info: iteration 24, average log likelihood -1.411086
[ Info: iteration 25, average log likelihood -1.411062
[ Info: iteration 26, average log likelihood -1.411039
[ Info: iteration 27, average log likelihood -1.411017
[ Info: iteration 28, average log likelihood -1.410996
[ Info: iteration 29, average log likelihood -1.410976
[ Info: iteration 30, average log likelihood -1.410958
[ Info: iteration 31, average log likelihood -1.410940
[ Info: iteration 32, average log likelihood -1.410922
[ Info: iteration 33, average log likelihood -1.410906
[ Info: iteration 34, average log likelihood -1.410890
[ Info: iteration 35, average log likelihood -1.410875
[ Info: iteration 36, average log likelihood -1.410860
[ Info: iteration 37, average log likelihood -1.410846
[ Info: iteration 38, average log likelihood -1.410833
[ Info: iteration 39, average log likelihood -1.410820
[ Info: iteration 40, average log likelihood -1.410807
[ Info: iteration 41, average log likelihood -1.410795
[ Info: iteration 42, average log likelihood -1.410783
[ Info: iteration 43, average log likelihood -1.410771
[ Info: iteration 44, average log likelihood -1.410760
[ Info: iteration 45, average log likelihood -1.410749
[ Info: iteration 46, average log likelihood -1.410739
[ Info: iteration 47, average log likelihood -1.410729
[ Info: iteration 48, average log likelihood -1.410720
[ Info: iteration 49, average log likelihood -1.410711
[ Info: iteration 50, average log likelihood -1.410702
â”Œ Info: EM with 100000 data points 50 iterations avll -1.410702
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.167916   -0.546297     1.31777    -0.297575     0.768066    -0.168532     0.379335     0.515595     0.954054     0.0701163  -0.0948421  -0.204545   -0.148652    0.315381   -0.0287853   0.188262    0.603785   -0.388669     0.892056     0.53533     0.438016     -0.335275   -0.443024     0.489838   -0.330992    -0.705137 
 -0.493037    0.160843    -0.42784    -0.00220634  -0.14393     -0.3182       0.514187     0.314918    -0.277474     0.525094    0.609673    0.0073604   0.434428    0.350249   -0.78475     0.183149   -0.635606    0.176015    -0.0511027   -0.230522    0.0986639    -0.217987   -0.350816     0.33171    -0.421789    -0.135948 
 -0.0188189   0.0777313   -0.105023   -0.0438394   -0.225329    -0.00713128   0.0542215   -0.074426    -0.0479283    0.0836564   0.122019    0.172069    0.104871    0.0202868  -0.1937      0.0266561  -0.389284    0.122727    -0.024714     0.0150824   0.0578153     0.0535544   0.0567583    0.0197581   0.0318069   -0.0944815
 -0.619143    0.11919     -0.613617    0.333425    -0.0327941   -0.201193    -0.173277    -0.193511     0.0594736   -0.302044    0.540196    0.631132   -0.0457878  -0.047047   -0.248865   -0.351554   -0.851346    0.208001     0.244692    -0.129337    0.37027      -0.142836    0.462571    -0.317027    0.624909     0.423394 
 -0.226237   -0.0011868    0.14125     0.31802      0.45621     -0.0781676   -0.464827    -0.349031     0.155626    -0.334939   -0.219875    0.250715   -0.166943   -0.0700766  -0.263786   -0.300311   -0.490377    0.876161     0.199327     0.127919    0.456401      0.6395     -0.644392     0.0207516  -0.00550257  -0.0767515
 -0.212109   -0.00844579  -0.716586   -0.217944    -0.555973    -0.387633    -0.463603     0.70666     -0.149102    -0.19743    -0.272837    0.439085   -0.166349   -0.244678   -0.176707   -0.0719552   0.0940047  -0.428219     0.70459      0.347611    0.437648     -0.658297   -0.00329463  -0.127401    0.20056      0.66081  
  0.316298    0.0387569    0.430715   -0.0605397   -0.467831    -0.0588552    0.213186     0.463429    -0.17631     -0.19839    -0.102698    0.293257    0.371724   -0.226946   -0.624998   -0.751582   -0.332534    0.329487     0.368105     0.183636    0.235147      0.0537291   0.291109     0.202494    0.233011    -0.361604 
  0.409254   -0.0198562    0.233778   -0.792431    -0.106104     0.291659    -0.235881     0.100051     0.0717805   -0.0454131  -0.211897   -0.205454   -0.373708    0.239699    0.594891    0.492029    0.601743   -0.500288    -0.403829     0.190926   -0.0373624    -0.248791   -0.592768     0.170256   -0.112726     0.0762278
  0.0562991   0.0301605    0.686377   -0.145897     0.412128     0.361861     0.492719    -0.308273     0.107174     0.210894   -0.0220655  -0.511749   -0.0499853   0.106739    0.139379   -0.017484   -0.267385    0.155051    -0.713535    -0.265987   -0.595364      0.983921   -0.472376     0.340151   -0.30599     -0.658346 
 -0.263504   -0.512246    -0.181814   -0.087746    -0.516578    -0.0527463   -0.107682    -0.435233     0.472161    -0.177616    0.1557      0.784682   -0.945867   -0.0801304  -0.235473   -0.21811    -0.387188   -1.15759      0.00628698  -0.327571   -0.284343      0.353644   -0.0656592   -0.446163   -0.501944    -0.433738 
  0.111025    0.428304     0.666071    0.125103     0.28451     -0.133841    -0.546574     0.0523233   -0.858541     0.298372   -0.135787    0.0745431   0.54055     0.320808   -0.578326    0.329133    0.222305    0.0504869    0.339523    -0.0135065  -0.0910461    -0.155225    0.446117    -0.232744    0.517808     0.43733  
  0.291381    0.109876    -0.421797   -0.0961737    0.130885     0.0942606    0.42822     -0.234832     0.081928     0.56724    -0.0424082   0.100498    0.379791   -0.628613   -0.184562   -0.134027    0.301877   -0.25139      0.124947     0.413809   -0.69061      -0.0444373  -0.428675    -0.180721   -0.692506    -0.107866 
  0.120094   -0.1289       0.181352    0.0945853    0.324582    -0.0483432   -0.186347    -0.0193898    0.0406305   -0.21127    -0.217082   -0.0225034  -0.165623   -0.12552     0.105338   -0.23187     0.27785    -0.0672908    0.0749117    0.250968   -0.000750924   0.249289   -0.172584     0.164733   -0.0269803   -0.0364446
 -0.105438    0.289168    -0.11849    -0.0559449    0.00516938   0.0303049   -0.266599     0.120668     0.211802    -0.306318    0.126078   -0.452981    0.170521    0.192122    0.166909    0.209768    0.0596909   0.190634    -0.0438101    0.0178471   0.350555      0.238571    0.0569933   -0.221983    0.119527     0.193215 
 -0.479169    0.221197     0.105667   -0.322921    -0.355847     0.0545601   -0.208238    -0.313437     0.0562432    0.124341    0.175253   -0.512126   -0.0672384  -0.64841    -0.233544    0.135289   -0.238347    0.00240046   0.0350689   -0.026341   -0.56017       1.079       0.345264    -0.721981    0.0177376    0.0972564
  0.30739    -0.648154     0.715633   -0.18426     -0.745316     0.0528822    0.241995     0.237671    -0.170973     0.162783    0.220196    0.278332    0.0887299   0.163941   -0.116444    0.0285423  -0.293448   -0.152446    -0.0403659   -0.117417   -0.0123392    -0.272003    0.787787     0.174037    0.338901    -0.0728302
  0.0629161  -0.448278     0.444791   -0.190872    -0.280739     0.0662723   -0.213998     0.0309175    0.524004     0.0129066   0.0529829  -0.109423    0.0461344   0.433519    0.365586    0.285682   -0.157575   -0.134211     0.0233806   -0.320558    0.38439       0.222156    0.572712     0.0779524   0.461586     0.18339  
  0.520059    0.216296    -0.291944    0.445437     0.452338    -0.0327776    0.715582     0.320051    -0.253408     0.106584   -0.420771    0.165178    0.249379    0.788047    0.0505755  -0.180707    0.337562    0.185427     0.140836     0.0943841   0.430256     -0.949266   -0.3777       0.664475    0.23581     -0.0771977
 -0.334567   -0.560333    -0.124157   -0.414907     0.108371     1.05883      0.170961    -0.344435    -0.190726     0.0859784   0.277924    0.35151     0.147729    0.182121    0.0127514  -0.0373473  -0.330394    0.492439    -0.236565     0.465393   -0.113657      0.0526162   0.381578    -0.208874   -0.763901     0.369148 
 -0.228844    0.583476    -0.234737   -0.353735     0.0882634   -0.368312    -0.118655     0.0968036   -0.466536     0.393126   -0.132158   -0.73862     0.0207912  -0.773038    0.0136393  -0.445102    0.564665    0.022061     0.555617    -0.256182   -0.42449      -0.189153   -0.588357    -0.0757824  -0.0700149   -0.335305 
 -0.429509    0.872327    -0.879564    0.296153     0.530102    -0.14247     -0.424786    -0.186243     0.0686968   -0.501453   -0.0151051  -0.20224     0.0743188  -0.189119    0.265831   -0.0455015   0.419977    0.140855    -0.245155     0.0473378   0.0972517     0.238115   -0.473937    -0.17936    -0.287334     0.255898 
 -0.22775    -0.346646     0.15826     0.0325852    0.13516      0.441522    -0.126527     0.415296    -0.450124    -0.180767   -0.361674    0.354935   -0.0525708  -0.370359    0.13942    -0.198527    0.325938   -0.338916    -0.276261    -0.318651   -0.000106008  -0.835582    0.0725296    0.172313   -0.0552272   -0.301844 
  0.0423627   0.322716     0.187773    0.754017    -0.296486    -0.96682     -0.00658833   0.567092    -0.00182503  -0.361674   -0.259715   -0.321686   -0.24976    -0.140543   -0.0932061   0.20026     0.334275   -0.310584    -0.418437    -0.165507    0.00696901    0.0962632  -0.155619     0.250359    0.754441    -0.381012 
 -0.259936    0.136768     0.183077   -0.468424    -0.468305    -0.102161    -0.273089     0.425899     0.133789    -0.0250791  -0.388984   -0.624645    0.201205   -0.543235    0.467986    0.209352    0.350596    0.746461     0.276151    -0.99835    -0.100773     -0.15553     0.0372432   -0.226395    0.41094      0.606465 
 -0.314347   -0.37655     -0.563364   -0.275637    -0.352644    -0.0120079    0.146481    -0.146361     0.814849     0.0332105   0.369527   -0.103153   -0.374027   -0.038674    0.61422     0.0931763  -0.46291     0.0556832   -0.316127    -0.0338442   0.0925861     0.179369   -0.441128     0.277731   -0.299809    -0.202379 
 -0.29563     0.170422    -0.227994    0.0270113    0.315509     0.166191     0.0541209    0.00687699  -0.0423412    0.113234    0.0478512  -0.242143    0.0958516   0.0852959   0.151035    0.299256    0.278397    0.0619282   -0.149893    -0.0724443  -0.0305382    -0.19263    -0.128968    -0.273544   -0.209754     0.254555 
  0.031896    0.22803      0.0246752  -0.229363    -0.455677    -0.50143      0.0847817    0.412814     0.220102    -0.0561993   0.173595    0.0222236   0.0855096  -0.0449982   0.197911   -0.237881    0.332751   -0.313302     0.36406     -0.188357   -0.0101111    -0.493585    0.149937     0.0686372   0.15886      0.0733257
  0.346495   -0.706652     0.330009    0.0604449    0.547189    -0.0714178   -0.325228    -0.506324     0.626056     0.0469189  -0.198239   -0.134033   -0.211733   -0.36313     0.240446   -0.108293    0.962458   -0.343772     0.218988    -0.0171984  -0.60185       0.199586   -0.0525466   -0.15447     0.205668     0.439598 
  0.914197    0.519967     0.0985031   0.487685     0.16332     -0.129769     0.44412     -0.75113      0.213895    -0.108287    0.189495   -0.380336    0.137013    0.145056    0.352467    0.0754016  -0.120885    0.361905    -0.0640777    0.0714608  -0.142621      0.141123    0.295554    -0.0176244   0.370428     0.0652114
  0.250404   -0.654445     0.470765    0.688613     0.349993     0.0507542    0.112877    -0.0910844   -0.186808    -0.151899   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.0438382   0.0723425  -0.299827    0.442004    0.0626556   0.358865   -0.224243   -0.147157    -0.522595     0.259876   -0.0745273     0.301713    0.294374    -0.117706    0.0411461   -0.232609 
  0.252073    0.14846     -0.279118    0.678879     0.134151     0.0445914    0.135084    -0.306064    -0.486636     0.183437   -0.0230737   1.09584    -0.194132    0.0747522  -0.445636   -0.429042   -0.129878   -0.378542    -0.494127     1.11692    -0.142201      0.008697   -0.344142     0.408972   -0.414797    -0.591551 
 -0.0679392   0.771462    -0.333812    0.0137313   -0.436451     0.660804    -0.0106054    0.462666    -0.4894      -0.121749   -0.109308    0.0434938   0.129319    0.533938   -0.0816731   0.0853652  -0.941413    0.00538288  -0.243074    -0.07593     1.09917      -0.14147     0.541475    -0.284351   -0.0519472   -0.388041 [ Info: iteration 1, average log likelihood -1.410694
[ Info: iteration 2, average log likelihood -1.410686
[ Info: iteration 3, average log likelihood -1.410678
[ Info: iteration 4, average log likelihood -1.410671
[ Info: iteration 5, average log likelihood -1.410664
[ Info: iteration 6, average log likelihood -1.410657
[ Info: iteration 7, average log likelihood -1.410651
[ Info: iteration 8, average log likelihood -1.410645
[ Info: iteration 9, average log likelihood -1.410638
[ Info: iteration 10, average log likelihood -1.410632
â”Œ Info: EM with 100000 data points 10 iterations avll -1.410632
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
