Julia Version 1.3.1-pre.19
Commit 602e3006ec (2019-12-17 12:50 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed SortingAlgorithms ── v0.3.1
 Installed GaussianMixtures ─── v0.3.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed OrderedCollections ─ v1.1.0
 Installed NearestNeighbors ─── v0.4.4
 Installed StaticArrays ─────── v0.12.1
 Installed DataStructures ───── v0.17.6
 Installed StatsBase ────────── v0.32.0
 Installed BinDeps ──────────── v1.0.0
 Installed LegacyStrings ────── v0.4.1
 Installed URIParser ────────── v0.4.0
 Installed Missings ─────────── v0.4.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed CMake ────────────── v1.1.2
 Installed QuadGK ───────────── v2.3.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Rmath ────────────── v0.6.0
 Installed DataAPI ──────────── v1.1.0
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed BinaryProvider ───── v0.5.8
 Installed StatsFuns ────────── v0.9.3
 Installed JLD ──────────────── v0.9.1
 Installed Blosc ────────────── v0.5.1
 Installed SpecialFunctions ─── v0.9.0
 Installed Parameters ───────── v0.12.0
 Installed PDMats ───────────── v0.9.10
 Installed FileIO ───────────── v1.2.0
 Installed Arpack ───────────── v0.4.0
 Installed FillArrays ───────── v0.8.2
 Installed HDF5 ─────────────── v0.12.5
 Installed Clustering ───────── v0.13.3
 Installed Distances ────────── v0.8.2
 Installed Compat ───────────── v2.2.0
 Installed Distributions ────── v0.21.11
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_R6cCOl/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
┌ Warning: Replacing docs for `FileIO.filename :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
┌ Warning: Replacing docs for `FileIO.file_extension :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
[ Info: Testing Data
(100000, -838393.7676544118, [58354.11133105524, 41645.88866894475], [4646.233263254846 9706.873369641478 -27481.06272368491; -4742.198053401251 -9914.247079131379 27208.652218879935], Array{Float64,2}[[72810.89519190589 12824.26314120228 1940.0547389738108; 12824.263141202278 71067.43921602868 4603.427302829704; 1940.0547389738108 4603.427302829705 59744.52508415777], [28143.916754265498 -12993.83880268831 -2021.6296291767705; -12993.83880268831 28781.113813009495 -4746.972735627391; -2021.629629176771 -4746.972735627391 39492.20390843069]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.101335e+03
      1       9.197569e+02      -1.815777e+02 |        5
      2       9.050316e+02      -1.472537e+01 |        2
      3       8.977396e+02      -7.291999e+00 |        0
      4       8.977396e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 897.7395510500655)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.078774
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.754938
[ Info: iteration 2, lowerbound -3.573792
[ Info: iteration 3, lowerbound -3.388999
[ Info: iteration 4, lowerbound -3.196430
[ Info: iteration 5, lowerbound -3.019707
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.882585
[ Info: iteration 7, lowerbound -2.796565
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.748734
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.711097
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.672837
[ Info: iteration 11, lowerbound -2.633370
[ Info: iteration 12, lowerbound -2.592764
[ Info: iteration 13, lowerbound -2.549356
[ Info: iteration 14, lowerbound -2.505703
[ Info: iteration 15, lowerbound -2.464184
[ Info: iteration 16, lowerbound -2.426129
[ Info: iteration 17, lowerbound -2.391529
[ Info: iteration 18, lowerbound -2.359927
[ Info: iteration 19, lowerbound -2.332460
[ Info: iteration 20, lowerbound -2.313389
[ Info: iteration 21, lowerbound -2.307455
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.302928
[ Info: iteration 23, lowerbound -2.299260
[ Info: iteration 24, lowerbound -2.299256
[ Info: iteration 25, lowerbound -2.299254
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Dec 18 03:18:31 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Dec 18 03:18:38 2019: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Wed Dec 18 03:18:40 2019: EM with 272 data points 0 iterations avll -2.078774
5.8 data points per parameter
, Wed Dec 18 03:18:42 2019: GMM converted to Variational GMM
, Wed Dec 18 03:18:51 2019: iteration 1, lowerbound -3.754938
, Wed Dec 18 03:18:51 2019: iteration 2, lowerbound -3.573792
, Wed Dec 18 03:18:51 2019: iteration 3, lowerbound -3.388999
, Wed Dec 18 03:18:51 2019: iteration 4, lowerbound -3.196430
, Wed Dec 18 03:18:51 2019: iteration 5, lowerbound -3.019707
, Wed Dec 18 03:18:52 2019: dropping number of Gaussions to 7
, Wed Dec 18 03:18:52 2019: iteration 6, lowerbound -2.882585
, Wed Dec 18 03:18:52 2019: iteration 7, lowerbound -2.796565
, Wed Dec 18 03:18:52 2019: dropping number of Gaussions to 5
, Wed Dec 18 03:18:52 2019: iteration 8, lowerbound -2.748734
, Wed Dec 18 03:18:52 2019: dropping number of Gaussions to 4
, Wed Dec 18 03:18:52 2019: iteration 9, lowerbound -2.711097
, Wed Dec 18 03:18:52 2019: dropping number of Gaussions to 3
, Wed Dec 18 03:18:52 2019: iteration 10, lowerbound -2.672837
, Wed Dec 18 03:18:52 2019: iteration 11, lowerbound -2.633370
, Wed Dec 18 03:18:52 2019: iteration 12, lowerbound -2.592764
, Wed Dec 18 03:18:52 2019: iteration 13, lowerbound -2.549356
, Wed Dec 18 03:18:52 2019: iteration 14, lowerbound -2.505703
, Wed Dec 18 03:18:52 2019: iteration 15, lowerbound -2.464184
, Wed Dec 18 03:18:52 2019: iteration 16, lowerbound -2.426129
, Wed Dec 18 03:18:52 2019: iteration 17, lowerbound -2.391529
, Wed Dec 18 03:18:52 2019: iteration 18, lowerbound -2.359927
, Wed Dec 18 03:18:52 2019: iteration 19, lowerbound -2.332460
, Wed Dec 18 03:18:52 2019: iteration 20, lowerbound -2.313389
, Wed Dec 18 03:18:52 2019: iteration 21, lowerbound -2.307455
, Wed Dec 18 03:18:52 2019: dropping number of Gaussions to 2
, Wed Dec 18 03:18:52 2019: iteration 22, lowerbound -2.302928
, Wed Dec 18 03:18:52 2019: iteration 23, lowerbound -2.299260
, Wed Dec 18 03:18:52 2019: iteration 24, lowerbound -2.299256
, Wed Dec 18 03:18:52 2019: iteration 25, lowerbound -2.299254
, Wed Dec 18 03:18:52 2019: iteration 26, lowerbound -2.299254
, Wed Dec 18 03:18:52 2019: iteration 27, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 28, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 29, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 30, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 31, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 32, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 33, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 34, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 35, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 36, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 37, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 38, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 39, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 40, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 41, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 42, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 43, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 44, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 45, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 46, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 47, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 48, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: iteration 49, lowerbound -2.299253
, Wed Dec 18 03:18:52 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601638, 95.95490777398358]
β = [178.04509222601638, 95.95490777398358]
m = [4.25030073326989 79.28686694436156; 2.000229257775348 53.85198717246118]
ν = [180.04509222601638, 97.95490777398358]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554748412 -0.0076440490423273855; 0.0 0.008581705166333185], [0.37587636119487483 -0.00895312382734665; 0.0 0.012748664777409576]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0169249755760144
avll from llpg:  -1.0169249755760246
avll direct:     -1.0169249755760246
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9894478963949057
avll from llpg:  -0.9894478963949055
avll direct:     -0.9894478963949054
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.151627    -0.123333     0.00761345   -0.0666063    0.0798355   0.0446461   -0.00745273   0.133043   -0.0871033   0.0474819   -0.0455841    0.0432885    -0.256132    -0.0237282   -0.189053    -0.189403     0.00378817   0.0306448    0.100551     0.0699642    0.108796     0.0168779    0.160167    -0.0546535   -0.0278298   -0.0732115  
 -0.052398     0.0479129    0.0896377    -0.0347807    0.0192915  -0.0298196   -0.0020417    0.100622    0.0441641   0.184153    -0.0561717    0.0108288     0.0156817   -0.0202943   -0.0545502    0.0939284    0.0116482   -0.0819442   -0.0450277   -0.014468    -0.0982874   -0.191919     0.0815683    0.182651    -0.0177005   -0.0142234  
 -0.214743    -0.0121795   -0.00574264    0.0228707   -0.0163943  -0.0417598    0.0109245   -0.147934    0.180088    0.0469447    0.0857973   -0.0319713    -0.136657    -0.0959382   -0.0342599    0.126985     0.175744     0.0417213    0.00841846   0.0517766    0.00780462  -0.0273862   -0.0341518   -0.160334     0.0899572   -0.169984   
  0.227732    -0.0592337    0.0548233    -0.114829    -0.125105   -0.00858722   0.107422     0.163444    0.106351    0.180584     0.121594    -0.122047      0.0992584    0.0352788   -0.0726612    0.171586     0.00860666  -0.0445199    0.128233     0.110147     0.123531    -0.0654431   -0.0276527   -0.0492863   -0.112825    -0.0131609  
  0.00131696  -0.114631     0.106587     -0.176332    -0.0368989  -0.02849      0.0215172   -0.0288693  -0.102129    0.0775755   -0.0678696    0.0942503     0.0751568    0.0451611    0.0701039   -0.167621    -0.0585921    0.042685    -0.0168213    0.110755     0.0710339   -0.273891     0.0304949    0.146778    -0.0427069   -0.0481773  
 -0.169676     0.0786014    0.0117431     0.0292342   -0.0628382  -0.092776     0.0976126    0.0304947   0.106854   -0.100178    -0.0889315    0.0638276     0.133381     0.0162499   -0.0741681    0.0444525    0.0972421    0.127065     0.0989707   -0.193476     0.0263444    0.0808366   -0.0642012   -0.102759    -0.048231    -0.00841999 
 -0.0700087    0.0946809   -0.192596     -0.088386     0.0801645   0.00474545   0.0427246   -0.0605591   0.116695   -0.0652872   -0.0330561   -0.0167892     0.0507441    0.0450948   -0.00295587   0.051353    -0.132826     0.0998844   -0.102521     0.0289896   -0.164058    -0.0970342    0.0803036    0.0896434   -0.0142749    0.101237   
  0.0364836    0.0426182   -0.110791      0.128114    -0.0432476  -0.0252324    0.0158052   -0.0821677   0.0540519  -0.0765593   -0.0386502    0.182463      0.0926553   -0.0615182    0.0813644   -0.0275049    0.170272    -0.195113    -0.0809617    0.0127724   -0.133493    -0.00806622  -0.195666     0.0297983    0.0535173   -0.0361376  
 -0.157524    -0.101858     0.0221343    -0.0421612    0.105915    0.0847968   -0.0355042   -0.0328939  -0.125832   -0.0332655    0.0921131    0.0303026     0.0145116   -0.167028    -0.06016      0.245456     0.0136795    0.0686086    0.070231     0.0136636    0.108301     0.0566058    0.00713047   0.0982879   -0.00871357  -0.107153   
 -0.182444     0.141675     0.0108805     0.23101      0.0219532   0.026276     0.116524     0.15317     0.0408685  -0.0903348    0.118471     0.171653     -0.032133     0.0662999    0.234713     0.0631178   -0.106103     0.107137     0.0829171   -0.17144     -0.219615     0.0359632   -0.0897687    0.0294558   -0.104166    -0.252052   
 -0.0518484    0.27751     -0.0411604    -0.135739    -0.181638   -0.0254332   -0.0538349   -0.010534    0.091265    0.157612    -0.0602884   -0.0959293    -0.0201372   -0.141085    -0.0192976   -0.0889006    0.0594781    0.0965467   -0.0905612   -0.0113379    0.156665     0.11982     -0.00614302  -0.0632859   -0.0279547    0.0167949  
 -0.0901754    0.0100342    0.0463063     0.301068     0.181817   -0.00806376   0.132771     0.0951629  -0.130441    0.00954564   0.0562854   -0.00289499   -0.119425     0.0673437   -0.0740245   -0.00314521   0.0244926   -0.0237063    0.0143769    0.0568086   -0.122402     0.0262065    0.0460795   -0.115202    -0.0880459   -0.0935428  
  0.0255109    0.240451    -0.115566     -0.0638632   -0.0324885  -0.0148661    0.0903091    0.0404754   0.220398   -0.0500743   -0.0871617   -0.113109      0.0224808    0.00383676  -0.0592858    0.0987325   -0.0526091   -0.0577162    0.150829    -0.0218284   -0.114071     0.073814    -0.0552726    0.0361822   -0.0155807   -0.0531375  
 -0.0847978   -0.0551568   -0.0745137    -0.111097    -0.083738   -0.0465345    0.0338644   -0.10015     0.107626   -0.0646555   -0.0239938   -0.099985     -0.0495673   -0.0836506    0.104879    -0.0480063    0.0287052    0.152801     0.104036     0.0787216    0.0899267   -0.0359599   -0.207163     0.0629344   -0.033933     0.172168   
 -0.00414929  -0.106897     0.141085     -0.0171882    0.15245     0.0567664   -0.162823     0.0698773  -0.140108    0.076823    -0.0130718   -0.105729     -0.0453434   -0.13648      0.0435       0.193988     0.00745407   0.255447    -0.0391814   -0.0477855    0.226764     0.0939659    0.081145    -0.0234999   -0.0919076   -0.000276771
  0.215469     0.0910822    0.0529479     0.0575395    0.0477737   0.0970292    0.205581     0.0271209   0.112954    0.112342     0.0312608    0.0402058     0.0699148    0.024912    -0.116796    -0.1135       0.244579     0.114967     0.0296259   -0.103482     0.16719      0.161768     0.0850021    0.0453277   -0.14604     -0.0220513  
 -0.228848     0.104886     0.203437      0.0714139   -0.0341943   0.00737134  -0.101279     0.202878    0.0499391   0.00726839   0.124313     0.144767      0.120824     0.0876863    0.00548945  -0.193335    -0.0441101    0.0825774    0.0238949    0.0505507   -0.199291     0.0263342    0.25312     -0.144721     0.0716765   -0.173823   
  0.0300724   -0.0575822    0.0306765     0.090323    -0.0656228  -0.326866     0.0328965   -0.0108851  -0.0424728   0.036108     0.04214      0.110461      0.0197285   -0.0254711   -0.0199504    0.0863716   -0.00733498   0.0270453   -0.179254    -0.0318629   -0.0733385   -0.00752492  -0.0793993   -0.148248    -0.0372236   -0.0927211  
  0.00578796   0.0621209    0.0578422    -0.10665     -0.095457    0.0228323    0.0141908   -0.107672   -0.094173    0.063009     0.141847     0.0321264     0.023193     0.0119934    0.107724     0.100047     0.205606    -0.0788293    0.0397182   -0.0510269   -0.260345    -0.127687    -0.11438     -0.0830512    0.135751     0.0686554  
  0.0594077   -0.0941514    0.0679995     0.0876727    0.119571   -0.0842091   -0.22746      0.0365016  -0.152579   -0.022909     0.121957     0.0667575    -0.00499632  -0.0125488   -0.0511956   -0.149762    -0.0931679    0.186757    -0.00526496  -0.157192    -0.0975219   -0.156613    -0.0220624    0.12349     -0.109705     0.0522092  
  0.198259     0.0322169    0.293932      0.00948274  -0.0843285  -0.052332     0.0651137    0.0242166  -0.0510694   0.101663     0.0429352   -0.0597017     0.0272414   -0.0524245    0.0758849    0.0134006    0.0024167   -0.037318    -0.0116691    0.0407316    0.0718601   -0.08322      0.0104169   -0.158454    -0.0624256   -0.119447   
  0.0956334   -0.0447996   -0.00346707   -0.113579     0.0596242   0.0391885   -0.0323561    0.037428    0.0333161  -0.0506687   -0.0756607   -0.0529253    -0.0950871    0.0294867    0.166111    -0.105079    -0.109442     0.0137017   -0.0730561   -0.17522      0.0506648    0.0535119   -0.0156       0.0325647   -0.0871707   -0.0856838  
  0.0844266   -0.0681021   -0.122125      0.0548467    0.0578866  -0.0142512   -0.0800106    0.0828883   0.0546401  -0.0541348   -0.121865     0.119626     -0.0350439   -0.211429    -0.200699     0.00456549  -0.0673727    0.0900051   -0.00696098   0.0274528    0.152182     0.0363537    0.0843731    0.126542     0.00623014  -0.00208989 
 -0.112608    -0.0550861    0.000247849   0.0521335   -0.134724    0.052709     0.151056     0.163807    0.111367   -0.219603    -0.090682     0.0285573    -0.0232158    0.101035    -0.100038     0.0158862   -0.0109727    0.0430779   -0.108233    -0.198722    -0.0834372   -0.0144386    0.0014189    0.0309368   -0.0780591    0.0340961  
  0.00358584   0.0979529    0.000294278  -0.16279      0.0273611  -0.0814126   -0.148511    -0.0246621   0.0591126   0.0296624   -0.0194329    0.085386     -0.0242929    0.0462635    0.0618041   -0.112264     0.0341709    0.00459581  -0.0453075   -0.0180723    0.111549    -0.0807507   -0.0595852   -0.311808     0.0681969    0.0076579  
  0.120055    -0.0433926    0.123965      0.226482    -0.189957   -0.159184     0.0639254    0.0166745   0.0796564  -0.150958     0.065671    -0.0809812     0.00841394   0.0877556   -0.0531006    0.169358     0.0853497    0.150868    -0.0233189    0.124337    -0.100674     0.0439844   -0.0871926   -0.0806384    0.0689389   -0.0156424  
  0.104953    -0.0691579   -0.0220823    -0.0715637    0.0954908  -0.149797     0.0764314    0.0803875   0.0960671  -0.0538321    0.0447809    0.078231     -0.0707318    0.0688243   -0.0293205   -0.100433     0.126537    -0.0347643    0.0337033   -0.153439     0.0375901    0.0614521    0.00211579   0.0127672    0.0475346    0.131803   
 -0.0230853   -0.110798    -0.0241987    -0.00901932   0.0427556   0.0127613    0.0275759    0.215671    0.020051   -0.08241      0.0118041    0.000937444   0.0709219    0.125551    -0.257406    -0.0691735   -0.0209465    0.179288    -0.0594696    0.0292824   -0.160446    -0.0925181   -0.0119912   -0.00187708   0.0436731   -0.113492   
  0.0651938   -0.059197     0.064402      0.0359529   -0.110116   -0.0695471   -0.127857    -0.170621   -0.0510721  -0.0998812    0.167883    -0.17241      -0.0445566    0.15027      0.0435472    0.132482     0.10137     -0.048472    -0.0738139    0.00190663   0.104901    -0.0149463    0.059615    -0.0193385   -0.10926      0.235981   
 -0.148448    -0.00903144   0.289256     -0.0200095    0.0729503   0.0561364    0.075204    -0.0652258  -0.154563    0.185773     0.045409    -0.0120077    -0.182769     0.205311    -0.165064     0.0148273   -0.0569224    0.11305     -0.102941     0.0806795    0.0250308   -0.0251521    0.00203243   0.0920109    0.0498887    0.0451822  
  0.0625136    0.0165533   -0.0064847     0.0730545    0.082754    0.0302669    0.0507899    0.0305179  -0.0874869   0.149534    -0.138598     0.0440332     0.0534035    0.110706    -0.0351052   -0.109404     0.0916282    0.055678    -0.0289055   -0.0636303   -0.0929467   -0.0485644    0.0146786   -0.0840063    0.127179    -0.0615666  
  0.00266227   0.100879    -0.0891907     0.007211     0.0745423   0.0261227   -0.0514256   -0.138687   -0.0199334  -0.0179541   -0.00162554  -0.11334       0.142944    -0.0844302    0.0817543    0.0578869    0.123628    -0.0304776   -0.168697     0.170449     0.0793675    0.0866032   -0.0823831   -0.00729173  -0.127604    -0.000838534kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4039828894807167
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404067
[ Info: iteration 2, average log likelihood -1.403995
[ Info: iteration 3, average log likelihood -1.403653
[ Info: iteration 4, average log likelihood -1.400458
[ Info: iteration 5, average log likelihood -1.389514
[ Info: iteration 6, average log likelihood -1.379662
[ Info: iteration 7, average log likelihood -1.374688
[ Info: iteration 8, average log likelihood -1.372135
[ Info: iteration 9, average log likelihood -1.370961
[ Info: iteration 10, average log likelihood -1.370406
[ Info: iteration 11, average log likelihood -1.370055
[ Info: iteration 12, average log likelihood -1.369622
[ Info: iteration 13, average log likelihood -1.369124
[ Info: iteration 14, average log likelihood -1.368844
[ Info: iteration 15, average log likelihood -1.368704
[ Info: iteration 16, average log likelihood -1.368617
[ Info: iteration 17, average log likelihood -1.368552
[ Info: iteration 18, average log likelihood -1.368497
[ Info: iteration 19, average log likelihood -1.368448
[ Info: iteration 20, average log likelihood -1.368403
[ Info: iteration 21, average log likelihood -1.368363
[ Info: iteration 22, average log likelihood -1.368328
[ Info: iteration 23, average log likelihood -1.368300
[ Info: iteration 24, average log likelihood -1.368277
[ Info: iteration 25, average log likelihood -1.368258
[ Info: iteration 26, average log likelihood -1.368243
[ Info: iteration 27, average log likelihood -1.368231
[ Info: iteration 28, average log likelihood -1.368221
[ Info: iteration 29, average log likelihood -1.368212
[ Info: iteration 30, average log likelihood -1.368205
[ Info: iteration 31, average log likelihood -1.368200
[ Info: iteration 32, average log likelihood -1.368194
[ Info: iteration 33, average log likelihood -1.368190
[ Info: iteration 34, average log likelihood -1.368186
[ Info: iteration 35, average log likelihood -1.368183
[ Info: iteration 36, average log likelihood -1.368180
[ Info: iteration 37, average log likelihood -1.368177
[ Info: iteration 38, average log likelihood -1.368175
[ Info: iteration 39, average log likelihood -1.368173
[ Info: iteration 40, average log likelihood -1.368171
[ Info: iteration 41, average log likelihood -1.368169
[ Info: iteration 42, average log likelihood -1.368167
[ Info: iteration 43, average log likelihood -1.368166
[ Info: iteration 44, average log likelihood -1.368164
[ Info: iteration 45, average log likelihood -1.368163
[ Info: iteration 46, average log likelihood -1.368162
[ Info: iteration 47, average log likelihood -1.368161
[ Info: iteration 48, average log likelihood -1.368160
[ Info: iteration 49, average log likelihood -1.368159
[ Info: iteration 50, average log likelihood -1.368158
┌ Info: EM with 100000 data points 50 iterations avll -1.368158
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4040669196132358
│     -1.4039954735515794
│      ⋮                 
└     -1.3681581230225113
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.368280
[ Info: iteration 2, average log likelihood -1.368156
[ Info: iteration 3, average log likelihood -1.367437
[ Info: iteration 4, average log likelihood -1.361282
[ Info: iteration 5, average log likelihood -1.348355
[ Info: iteration 6, average log likelihood -1.337905
[ Info: iteration 7, average log likelihood -1.332071
[ Info: iteration 8, average log likelihood -1.329620
[ Info: iteration 9, average log likelihood -1.328202
[ Info: iteration 10, average log likelihood -1.327270
[ Info: iteration 11, average log likelihood -1.326651
[ Info: iteration 12, average log likelihood -1.326232
[ Info: iteration 13, average log likelihood -1.325919
[ Info: iteration 14, average log likelihood -1.325643
[ Info: iteration 15, average log likelihood -1.325354
[ Info: iteration 16, average log likelihood -1.325039
[ Info: iteration 17, average log likelihood -1.324743
[ Info: iteration 18, average log likelihood -1.324501
[ Info: iteration 19, average log likelihood -1.324314
[ Info: iteration 20, average log likelihood -1.324174
[ Info: iteration 21, average log likelihood -1.324071
[ Info: iteration 22, average log likelihood -1.323994
[ Info: iteration 23, average log likelihood -1.323936
[ Info: iteration 24, average log likelihood -1.323893
[ Info: iteration 25, average log likelihood -1.323859
[ Info: iteration 26, average log likelihood -1.323832
[ Info: iteration 27, average log likelihood -1.323811
[ Info: iteration 28, average log likelihood -1.323793
[ Info: iteration 29, average log likelihood -1.323778
[ Info: iteration 30, average log likelihood -1.323764
[ Info: iteration 31, average log likelihood -1.323752
[ Info: iteration 32, average log likelihood -1.323740
[ Info: iteration 33, average log likelihood -1.323729
[ Info: iteration 34, average log likelihood -1.323718
[ Info: iteration 35, average log likelihood -1.323707
[ Info: iteration 36, average log likelihood -1.323696
[ Info: iteration 37, average log likelihood -1.323685
[ Info: iteration 38, average log likelihood -1.323674
[ Info: iteration 39, average log likelihood -1.323663
[ Info: iteration 40, average log likelihood -1.323651
[ Info: iteration 41, average log likelihood -1.323639
[ Info: iteration 42, average log likelihood -1.323626
[ Info: iteration 43, average log likelihood -1.323613
[ Info: iteration 44, average log likelihood -1.323599
[ Info: iteration 45, average log likelihood -1.323584
[ Info: iteration 46, average log likelihood -1.323568
[ Info: iteration 47, average log likelihood -1.323550
[ Info: iteration 48, average log likelihood -1.323531
[ Info: iteration 49, average log likelihood -1.323510
[ Info: iteration 50, average log likelihood -1.323487
┌ Info: EM with 100000 data points 50 iterations avll -1.323487
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3682802201370285
│     -1.3681555862289942
│      ⋮                 
└     -1.3234867878089163
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.323622
[ Info: iteration 2, average log likelihood -1.323430
[ Info: iteration 3, average log likelihood -1.322845
[ Info: iteration 4, average log likelihood -1.318083
[ Info: iteration 5, average log likelihood -1.305175
[ Info: iteration 6, average log likelihood -1.293166
[ Info: iteration 7, average log likelihood -1.286063
[ Info: iteration 8, average log likelihood -1.281609
[ Info: iteration 9, average log likelihood -1.278344
[ Info: iteration 10, average log likelihood -1.275929
[ Info: iteration 11, average log likelihood -1.273913
[ Info: iteration 12, average log likelihood -1.272334
[ Info: iteration 13, average log likelihood -1.271203
[ Info: iteration 14, average log likelihood -1.270286
[ Info: iteration 15, average log likelihood -1.269351
[ Info: iteration 16, average log likelihood -1.268286
[ Info: iteration 17, average log likelihood -1.267201
[ Info: iteration 18, average log likelihood -1.266316
[ Info: iteration 19, average log likelihood -1.265683
[ Info: iteration 20, average log likelihood -1.265210
[ Info: iteration 21, average log likelihood -1.264847
[ Info: iteration 22, average log likelihood -1.264582
[ Info: iteration 23, average log likelihood -1.264405
[ Info: iteration 24, average log likelihood -1.264300
[ Info: iteration 25, average log likelihood -1.264243
[ Info: iteration 26, average log likelihood -1.264212
[ Info: iteration 27, average log likelihood -1.264194
[ Info: iteration 28, average log likelihood -1.264185
[ Info: iteration 29, average log likelihood -1.264179
[ Info: iteration 30, average log likelihood -1.264175
[ Info: iteration 31, average log likelihood -1.264173
[ Info: iteration 32, average log likelihood -1.264172
[ Info: iteration 33, average log likelihood -1.264171
[ Info: iteration 34, average log likelihood -1.264170
[ Info: iteration 35, average log likelihood -1.264169
[ Info: iteration 36, average log likelihood -1.264169
[ Info: iteration 37, average log likelihood -1.264169
[ Info: iteration 38, average log likelihood -1.264169
[ Info: iteration 39, average log likelihood -1.264169
[ Info: iteration 40, average log likelihood -1.264168
[ Info: iteration 41, average log likelihood -1.264168
[ Info: iteration 42, average log likelihood -1.264168
[ Info: iteration 43, average log likelihood -1.264168
[ Info: iteration 44, average log likelihood -1.264168
[ Info: iteration 45, average log likelihood -1.264168
[ Info: iteration 46, average log likelihood -1.264168
[ Info: iteration 47, average log likelihood -1.264168
[ Info: iteration 48, average log likelihood -1.264168
[ Info: iteration 49, average log likelihood -1.264168
[ Info: iteration 50, average log likelihood -1.264168
┌ Info: EM with 100000 data points 50 iterations avll -1.264168
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3236224961987562
│     -1.3234298362035892
│      ⋮                 
└     -1.264168192957294 
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.264375
[ Info: iteration 2, average log likelihood -1.264134
[ Info: iteration 3, average log likelihood -1.263125
[ Info: iteration 4, average log likelihood -1.253919
[ Info: iteration 5, average log likelihood -1.225585
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.196360
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.189055
[ Info: iteration 8, average log likelihood -1.200882
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.187383
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.181143
[ Info: iteration 11, average log likelihood -1.203089
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.186854
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.179673
[ Info: iteration 14, average log likelihood -1.192169
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.179416
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.181905
[ Info: iteration 17, average log likelihood -1.192254
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.179511
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.173204
[ Info: iteration 20, average log likelihood -1.193170
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.179559
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.182680
[ Info: iteration 23, average log likelihood -1.193287
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.180809
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.174823
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.188888
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.185738
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.176504
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.189298
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.183347
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.175209
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.189730
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.187009
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.177994
[ Info: iteration 35, average log likelihood -1.191135
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.178957
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.173183
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.187653
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.184466
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.181706
[ Info: iteration 41, average log likelihood -1.192351
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.180057
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.174474
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.189267
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.186467
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.177330
[ Info: iteration 47, average log likelihood -1.190336
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.177954
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.171921
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.192975
┌ Info: EM with 100000 data points 50 iterations avll -1.192975
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2643747994063717
│     -1.2641339116382146
│      ⋮                 
└     -1.192974794998357 
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.187921
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.174241
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.180369
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.160579
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.123781
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      9
│     10
│     11
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.104705
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     11
│     12
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.094852
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.083560
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.073638
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.091232
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.074256
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.080826
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.076055
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.083309
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.062009
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.085190
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.083013
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.079187
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.072729
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.080971
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.068812
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.075340
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.078710
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.069085
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.060482
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.073208
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.072624
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.068650
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.075954
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.068299
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.057663
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.082166
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.072577
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.067175
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.071554
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.064224
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.074322
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.078590
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.066229
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.061958
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.075571
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.073566
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.066319
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.076442
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     11
│     12
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.070239
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.058813
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.078863
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.072594
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.069496
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.072584
┌ Info: EM with 100000 data points 50 iterations avll -1.072584
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1879210486636644
│     -1.1742406028460275
│      ⋮                 
└     -1.0725841670674348
32×26 Array{Float64,2}:
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4039828894807167
│     -1.4040669196132358
│     -1.4039954735515794
│     -1.4036534503378288
│      ⋮                 
│     -1.0725941521086457
│     -1.0694963030888969
└     -1.0725841670674348
 -0.17119      0.0855914   -0.0274764    0.0349684   -0.145638    -0.0900007    0.0829892    0.0508638     0.110806    -0.0584305   -0.0983323    0.0531812     0.162975     0.0164403   -0.0524178    0.0416209   0.101968      0.126689     0.0887595   -0.2118       0.0296141    0.0842111   -0.0661705   -0.0955448   -0.116912    -0.00716607
 -0.0121968   -0.0440341    0.135841    -0.0436989    0.0800586   -0.0493212    0.0802827   -0.0099908    -0.0388956    0.0565994    0.0519727    0.0177079    -0.143084     0.128045    -0.0948614   -0.0274206   0.049479      0.0394295   -0.0231506   -0.0358421    0.0263112    0.00825301  -0.0135605    0.0512713    0.0545754    0.0840594 
 -0.0241585    0.0511318    0.101102    -0.0345554    0.0226887   -0.0278184   -0.00494078   0.12347       0.0300413    0.190015    -0.071621     0.0125789     0.0133243   -0.0167798   -0.049377     0.0900065   0.0268995    -0.0806205   -0.0661192   -0.0223323   -0.0841529   -0.20499      0.0738302    0.17623     -0.0477161    0.0815391 
 -0.0543745    0.277489    -0.0273278   -0.127287    -0.158671     0.00419107  -0.0586871   -0.0124857     0.0912146    0.165807    -0.0570996   -0.0967473    -0.0267114   -0.144307    -0.0288796   -0.0904011   0.0562223     0.0996251   -0.0933382   -0.0149278    0.164435     0.127776    -0.0101166   -0.111474    -0.0230745    0.0276738 
  0.00201147  -0.0174164    0.0493346   -0.164447    -0.0113096   -0.0338945   -0.0407679   -0.0215718    -0.039542     0.0494224   -0.0647694    0.098723      0.0302414    0.0260447    0.0579145   -0.159046   -0.0169373     0.0108489   -0.0323272    0.0311336    0.0921082   -0.177076     0.0176904   -0.0355897    0.00822267   0.00125747
 -0.0418631    0.101843    -0.141208    -0.0376902    0.0772218   -0.0192305   -0.004297    -0.0735111     0.049208    -0.0355452   -0.0245018   -0.0713166     0.0961727   -0.0157692    0.0404121    0.0507961  -0.0082389     0.0357567   -0.131231     0.0905792   -0.0728602   -0.00270937  -0.0117072    0.0227813   -0.0407946    0.0513029 
 -0.00576616  -0.116186     0.123711    -0.204893     0.165588     0.0656498   -0.16563      0.0571308    -0.13896      0.110938    -0.0248688   -0.126087     -0.033968    -0.181779     0.0880838    0.251267    0.0222057     0.289831    -0.120658    -0.00788062   0.270271     0.185515     0.0764584   -0.082548    -0.161232    -0.0430074 
 -0.0079224   -0.0858481    0.180848     0.199696     0.0921071    0.037297    -0.112195     0.0732976    -0.138478     0.0762116    0.00706208  -0.0446785    -0.0747665   -0.00302937  -0.039894     0.171585   -0.00734399    0.198605     0.134148    -0.0763459    0.220282    -0.0543115    0.091265    -0.00447903  -0.0101123    0.0785766 
 -0.284218    -0.04482      0.0534635   -0.107393    -0.21904     -0.020244     0.0919036    0.153361      0.10567      0.172408     0.115718    -0.125473      0.0959625    0.0322106   -0.0722286    0.170868   -0.0302022    -0.0180405    0.134294     0.108644     0.127277    -0.0674065   -0.0628285   -0.0621882   -0.135635    -0.0901376 
  0.975685    -0.0347109   -0.0364762   -0.111136     0.00342919   0.0288696    0.114453     0.180928      0.10669      0.253226     0.109618    -0.0846559     0.0938245    0.0387497   -0.0723762    0.170314    0.0719788    -0.015065     0.110836     0.109996     0.12715     -0.0664044    0.0146609   -0.0502888   -0.106434     0.0853329 
  0.0974019   -0.0739926   -0.502982    -0.0776076    0.0603446    0.0102007    0.148245     0.0393246    -0.00296057   0.27932      0.19909     -0.043368     -0.332823     0.0298483    0.192867    -0.0154972  -0.0475389     0.0560825    0.00535691  -0.17239     -0.141775     0.0533816   -0.015088    -0.0061706   -0.269086    -0.0345592 
  0.0962597   -0.0249783    0.470061    -0.137352     0.0612349    0.0300024   -0.112084     0.0368508     0.0824122   -0.257389    -0.278303    -0.0467739     0.152535     0.0313157    0.145998    -0.149723   -0.196442      0.00436581  -0.183374    -0.190048     0.336919     0.0538116   -0.0115458    0.0556122    0.0312859   -0.159673  
 -0.227589     0.103515     0.232646     0.0763841   -0.0292474    0.00716992  -0.107138     0.207121      0.0428475    0.00276029   0.116101     0.13979       0.11537      0.0732043    0.00744649  -0.181806   -0.0377216     0.0829165    0.0239422    0.0464484   -0.207735     0.038636     0.256007    -0.137314     0.0562999   -0.173893  
  0.0268208    0.211102    -0.109968    -0.0692539   -0.0122469   -0.0288199    0.0967179    0.0309693     0.238043    -0.0305103   -0.0655304   -0.146274      0.00669481  -0.0602364   -0.060644     0.0996547  -0.0660522    -0.0653005    0.154164    -0.0216572   -0.0897155    0.0671371   -0.059747     0.0333909   -0.00546317  -0.0549399 
  0.00902442  -0.00589294   0.0360268   -0.224792     0.0224921    0.0461699    0.00729125  -0.0615986    -0.0951119    0.102025     0.0514616    0.0410192     0.0249344   -0.00380243   0.111592    -0.76853     0.223688     -0.0784762    0.0537091   -0.0409134   -0.276309    -0.162618    -0.111642    -0.082745     0.12609      0.0559059 
  0.00348875   0.151634     0.0624027   -0.120052    -0.240044    -0.00477699  -0.0284552   -0.108505     -0.0970882    0.0386936    0.342832     0.00606965    0.0155335    0.0280916    0.103824     0.930804    0.197731     -0.0712145    0.0677413   -0.0568123   -0.245432    -0.0994833   -0.116871    -0.0691698    0.177366     0.082142  
 -0.0988903   -0.0618745   -0.0708353   -0.110151    -0.0823494   -0.0425635    0.0241302   -0.127203      0.093927    -0.0662537   -0.0253682   -0.11197      -0.0329561   -0.0864986    0.105886    -0.0517023   0.0555743     0.15315      0.106012     0.0791612    0.083349    -0.0364322   -0.207299     0.0652433   -0.030256     0.178316  
  0.0436313    0.0420401   -0.100205     0.129276    -0.0433251   -0.0509488    0.00798307  -0.0839645     0.061536    -0.0683916   -0.0368414    0.175437      0.0859869   -0.0317826    0.0748989   -0.021083    0.16665      -0.178082    -0.0717726    0.013081    -0.140243    -0.0103048   -0.200446     0.0230498    0.0437539   -0.0302133 
 -0.199002     0.129032     0.0141921    0.225063     0.0240897    0.011656     0.117749     0.141286      0.0407662   -0.0940176    0.17501      0.155837     -0.0331704    0.0645632    0.22779      0.0580491  -0.100696      0.101349     0.0758449   -0.16357     -0.208135     0.0507459   -0.0796784    0.0422959   -0.108263    -0.204655  
 -0.118365    -0.0371902   -0.00378878   0.0523426   -0.134684     0.0679896    0.154981     0.156946      0.117845    -0.218758    -0.0864924    0.0130081    -0.0386973    0.0906657   -0.0988691    0.0188328  -0.00554694    0.0307057   -0.091003    -0.194857    -0.0699867   -0.011679    -0.00340144   0.0293296   -0.086646    -0.00486243
  0.061281    -0.0445635    0.0604359    0.0216598   -0.0638199   -0.0712884   -0.128385    -0.169154     -0.0555447   -0.048695     0.160582    -0.150242     -0.0212234    0.162946     0.0207919    0.133797    0.0967954    -0.0379317   -0.057534    -0.00879282   0.162754    -0.0192619    0.0386488   -0.00603044  -0.114191     0.229609  
  0.193925     0.0201092    0.294349     0.0019736   -0.0890912   -0.0515375    0.0811909    0.0200009    -0.0543516    0.104102     0.0478644   -0.0574031     0.0202701   -0.0562712    0.0747181    0.0121181   0.000459964  -0.0240991   -0.0218879    0.0421681    0.0791646   -0.0988014    0.0220507   -0.155704    -0.070224    -0.127147  
  0.216138     0.0911416    0.0465033    0.0650576    0.0414238    0.100382     0.214476     0.0440234     0.129691     0.090951     0.0319001    0.0477232     0.080727     0.0193261   -0.113054    -0.117874    0.281137      0.138556     0.0304355   -0.0822347    0.165755     0.160089     0.0770198    0.0256368   -0.136872    -0.0223218 
 -0.026357    -0.121472     0.0238077   -0.00915608   0.0461481    0.0151281    0.0286208    0.204537      0.0404513   -0.0744037    0.0202751   -0.00175844    0.0558985    0.132701    -0.268554    -0.0378009  -0.0214455     0.185034    -0.0624206    0.0296362   -0.0950361   -0.0936629   -0.0133624   -0.0133987    0.043636    -0.116751  
 -0.488635    -0.0905197    0.0386151   -0.0655037    0.103374     0.132187    -0.0607252   -0.0322603    -0.0494507   -0.0282825    0.138301     0.163489      0.0161228   -0.172387    -0.0774647    0.278114    0.0325971     0.172529     0.131905    -0.00721932   0.118272     0.123155     0.0128272    0.222312     0.272264    -0.106957  
  0.236267    -0.110244     0.00297998  -0.040388     0.10769      0.0382695   -0.014736    -0.0319511    -0.175066    -0.0453414    0.0734627   -0.135717     -0.0342936   -0.169493    -0.0930617    0.07117     0.026852     -0.0479079    0.00578605   0.0418251    0.0938832    0.0417501    0.00435902   0.067394    -0.278672    -0.107184  
  0.0344464    0.0171935    0.0145216    0.0723032    0.0571312    0.0392864    0.0466297    0.000187421  -0.0959415    0.150664    -0.153635     0.056144      0.0019375    0.123036     0.0433038   -0.122377    0.0899558     0.0405491   -0.0187131   -0.0836938   -0.0751614   -0.0477695    0.0157927   -0.0830894    0.127783    -0.0570741 
  0.0458672   -0.0497529   -0.048252     0.0715843   -0.00773866  -0.148006    -0.0469643    0.0405791    -0.0111033   -0.0170929   -0.0389474    0.142357     -0.00455003  -0.114452    -0.120091     0.0582317  -0.0153724     0.0690508   -0.0864913   -0.0192928    0.0365248    0.0195393    0.0206127    0.0120318   -0.0298005   -0.065735  
 -0.0497202   -0.131587     0.0428392    0.00678026   0.102692    -0.0252494   -0.109843     0.0569912    -0.126753    -0.00864326   0.0118756    0.0822059    -0.137963    -0.0319592   -0.119668    -0.163245   -0.0526755     0.102995     0.0625095   -0.043888     0.0172625   -0.06928      0.0734916    0.0250294   -0.0971447   -0.00246511
 -0.085785     0.00642166   0.0393661    0.307854     0.180838    -0.0406919    0.111735     0.070476     -0.112186    -0.0369679    0.104462     0.000295061  -0.121128     0.0270306   -0.0489113   -0.0126048   0.0226307    -0.0334854    0.0168401    0.0516044   -0.0975138    0.0229428    0.0416346   -0.10073     -0.0986398   -0.105809  
  0.0951373   -0.072548     0.166011     0.277267    -0.189834    -0.150755     0.0642911    0.0222461     0.0886665   -0.1502       0.0629272   -0.0900689     0.00726787   0.0836215   -0.0504615    0.167578    0.0199779     0.152624    -0.0466295    0.126924    -0.113672     0.0394547   -0.0921135   -0.0759887    0.0695621   -0.0511967 
 -0.207919    -0.00349322  -0.0601615    0.0298316   -0.0162069   -0.0441893    0.0103243   -0.143897      0.158471     0.0344334    0.0840421   -0.0317489    -0.137055    -0.0965556   -0.0350748    0.119964    0.156218      0.115443    -0.0169021    0.0217152    0.00102714  -0.0397573   -0.0249524   -0.148951     0.0710213   -0.166362  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.060781
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      9
│     10
│      ⋮
│     21
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.039764
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.060723
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      9
│     10
│      ⋮
│     21
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.039662
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.060721
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      9
│     10
│      ⋮
│     21
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.039660
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.060721
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      9
│     10
│      ⋮
│     21
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.039659
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│     11
│     12
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.060720
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      9
│     10
│      ⋮
│     21
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
kind diag, method kmeans
[ Info: iteration 10, average log likelihood -1.039659
┌ Info: EM with 100000 data points 10 iterations avll -1.039659
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.739340e+05
      1       6.740960e+05      -1.998380e+05 |       32
      2       6.430521e+05      -3.104384e+04 |       32
      3       6.292620e+05      -1.379019e+04 |       32
      4       6.222275e+05      -7.034418e+03 |       32
      5       6.175457e+05      -4.681878e+03 |       32
      6       6.138674e+05      -3.678207e+03 |       32
      7       6.109888e+05      -2.878609e+03 |       32
      8       6.086551e+05      -2.333712e+03 |       32
      9       6.066217e+05      -2.033467e+03 |       32
     10       6.048033e+05      -1.818387e+03 |       32
     11       6.029471e+05      -1.856136e+03 |       32
     12       6.011033e+05      -1.843814e+03 |       32
     13       5.995249e+05      -1.578425e+03 |       32
     14       5.983957e+05      -1.129154e+03 |       32
     15       5.977295e+05      -6.662770e+02 |       32
     16       5.973779e+05      -3.516132e+02 |       32
     17       5.972040e+05      -1.738072e+02 |       32
     18       5.971262e+05      -7.789450e+01 |       32
     19       5.970660e+05      -6.012542e+01 |       32
     20       5.969998e+05      -6.624248e+01 |       32
     21       5.969178e+05      -8.201221e+01 |       32
     22       5.967749e+05      -1.428538e+02 |       32
     23       5.965659e+05      -2.090114e+02 |       32
     24       5.963096e+05      -2.563558e+02 |       32
     25       5.960486e+05      -2.609148e+02 |       32
     26       5.958293e+05      -2.193321e+02 |       32
     27       5.956774e+05      -1.519125e+02 |       32
     28       5.955813e+05      -9.610637e+01 |       32
     29       5.955030e+05      -7.829002e+01 |       31
     30       5.954460e+05      -5.699484e+01 |       29
     31       5.954043e+05      -4.165644e+01 |       31
     32       5.953853e+05      -1.902360e+01 |       27
     33       5.953763e+05      -9.007119e+00 |       28
     34       5.953709e+05      -5.432998e+00 |       24
     35       5.953670e+05      -3.849014e+00 |       21
     36       5.953651e+05      -1.933698e+00 |       15
     37       5.953639e+05      -1.173941e+00 |       16
     38       5.953632e+05      -6.755314e-01 |        9
     39       5.953630e+05      -2.406019e-01 |        7
     40       5.953628e+05      -2.274566e-01 |        6
     41       5.953626e+05      -1.404474e-01 |        4
     42       5.953626e+05      -6.202135e-02 |        2
     43       5.953625e+05      -2.894333e-02 |        0
     44       5.953625e+05       0.000000e+00 |        0
K-means converged with 44 iterations (objv = 595362.5486850673)
┌ Info: K-means with 32000 data points using 44 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.325460
[ Info: iteration 2, average log likelihood -1.300103
[ Info: iteration 3, average log likelihood -1.278018
[ Info: iteration 4, average log likelihood -1.252929
[ Info: iteration 5, average log likelihood -1.217889
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.170923
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.134195
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.143709
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.128965
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.099247
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.078884
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     13
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.074595
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.126296
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.091348
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     21
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.056936
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     18
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.078799
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.109202
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.080378
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     20
│     21
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.059030
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.097448
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.093944
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.064008
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      7
│      9
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.030917
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.133396
[ Info: iteration 25, average log likelihood -1.102420
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.054502
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│      9
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.018630
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.143361
[ Info: iteration 29, average log likelihood -1.109064
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.066529
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     18
│     20
│     21
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.024883
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.123164
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.095788
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.075928
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     20
│     23
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.051885
[ Info: iteration 36, average log likelihood -1.122529
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.083476
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     21
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.055159
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      7
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.072807
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.123872
[ Info: iteration 41, average log likelihood -1.090585
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     18
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.044112
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│     23
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.061503
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.110126
[ Info: iteration 45, average log likelihood -1.100509
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.055048
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     18
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.056027
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.109342
[ Info: iteration 49, average log likelihood -1.086370
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     21
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.041636
┌ Info: EM with 100000 data points 50 iterations avll -1.041636
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.215965     0.0913134    0.0502621    0.0635766    0.0453283   0.0997831    0.215644     0.0444469     0.13075     0.0863927    0.0335233     0.0462576    0.0794982    0.0193676  -0.114294    -0.118863     0.278844      0.139398     0.0304614   -0.0844659    0.167763     0.160218     0.0801347    0.0261907   -0.137352    -0.0222347 
  0.0978865   -0.0746506    0.167369     0.279494    -0.189936   -0.151092     0.0648249    0.0211514     0.0907661  -0.152349     0.0624776    -0.0899701    0.0064235    0.0832545  -0.0511238    0.167223     0.0179129     0.154054    -0.0454536    0.127505    -0.113433     0.0429604   -0.0896519   -0.077505     0.070991    -0.0523276 
 -0.0872478    0.00992674   0.0436214    0.318108     0.181227   -0.0400439    0.123437     0.0782224    -0.109832   -0.0419123    0.101285     -0.00584447  -0.121269     0.0331745  -0.0584099   -0.0084972    0.0159466    -0.0355446    0.0165149    0.0557458   -0.0862601    0.0237845    0.0428171   -0.105136    -0.0932318   -0.112636  
  0.310392    -0.0544811    0.0197262   -0.108622    -0.123086   -0.00654361   0.0942269    0.172807      0.100521    0.231486     0.100583     -0.105814     0.0947858    0.0319215  -0.0827416    0.16402      0.0179956     0.0157492    0.122046     0.104263     0.128241    -0.0635817   -0.0169635   -0.0535846   -0.12451     -0.0183127 
  0.19378      0.020049     0.293485     0.00158353  -0.0893465  -0.051553     0.0814466    0.0208348    -0.0537799   0.105457     0.0479287    -0.057215     0.0206749   -0.0560587   0.0743803    0.0126106    0.000580104  -0.0236664   -0.0207785    0.042289     0.0791768   -0.0987733    0.021465    -0.155781    -0.0698418   -0.126467  
  0.0403279   -0.118653    -0.00829001  -0.0452656    0.0693206  -0.0708791    0.0577115    0.143506      0.0617677  -0.068462     0.0341086     0.0308255   -0.00890372   0.0909874  -0.158753    -0.0687959    0.0685894     0.0762494    0.0205756   -0.0647287   -0.0366033   -0.00985255  -0.00131436  -0.00762713   0.0514818    0.0117371 
 -0.170479     0.0839151   -0.0261723    0.036038    -0.14502    -0.0977799    0.0819765    0.0479358     0.110009   -0.057942    -0.108158      0.0520868    0.167668     0.0113934  -0.0504536    0.0414414    0.104846      0.129853     0.0957633   -0.216848     0.0344577    0.0893929   -0.0676046   -0.101005    -0.115938    -0.00837248
 -0.207004    -0.00385243  -0.0643148    0.0312605   -0.0175096  -0.0455479    0.0102897   -0.141416      0.164219    0.0335388    0.0838856    -0.0296161   -0.135971    -0.0991056  -0.0340113    0.121154     0.154481      0.127411    -0.0161688    0.0236249   -0.00206995  -0.0445545   -0.0270979   -0.148126     0.0670017   -0.172876  
 -0.143842    -0.122319     0.00891196  -0.0686152    0.089696    0.0378958   -0.0095396    0.0820112    -0.079492    0.0521844   -0.0651804     0.0418209   -0.242427    -0.0216249  -0.188471    -0.170257    -0.0599276     0.016989     0.105797     0.0768051    0.120662     0.0200945    0.165302    -0.0576369   -0.0408684   -0.0530293 
 -0.196943     0.119492     0.0135833    0.20603      0.0154835   0.00755691   0.117054     0.141052      0.0446697  -0.0943524    0.171788      0.143981    -0.02851      0.0630232   0.207414     0.0652299   -0.0993742     0.0893552    0.0806039   -0.147086    -0.187446     0.0426719   -0.0815735    0.0369458   -0.111153    -0.194212  
  0.006277     0.0741752    0.0492719   -0.171097    -0.110787    0.0203512   -0.0106227   -0.0858176    -0.096442    0.0705475    0.200173      0.0232217    0.0201766    0.0126658   0.107441     0.0962509    0.210933     -0.0749305    0.0611541   -0.0492586   -0.260627    -0.130649    -0.114246    -0.0767632    0.15228      0.0692573 
 -0.228455     0.100889     0.235352     0.075978    -0.0277896   0.0078464   -0.106945     0.209432      0.0441636   0.00257637   0.11848       0.142278     0.116925     0.0725288   0.00759542  -0.182194    -0.0383329     0.0829862    0.0240423    0.0470243   -0.210073     0.0402377    0.256768    -0.139048     0.0556947   -0.175293  
  0.0386335   -0.121666     0.0669727    0.0918945    0.118129   -0.0616528   -0.220289     0.0322744    -0.170702   -0.0696029    0.104599      0.0935836   -0.00726798  -0.0396855  -0.0333138   -0.143636    -0.0568939     0.17692      0.0165949   -0.187727    -0.0956388   -0.156079    -0.0225739    0.132578    -0.135235     0.0495695 
  0.00606996  -0.117705     0.101444    -0.173009    -0.0668337   0.00415241   0.0398967   -0.0259752    -0.120242    0.0737053   -0.101722      0.115695     0.0737111    0.0151437   0.0484599   -0.172909    -0.0629093     0.0439716   -0.026678     0.0742406    0.0865455   -0.252506     0.0790219    0.196713    -0.0501694   -0.0276471 
 -0.124291     0.0143378    0.29492     -0.0181571    0.0686771   0.0720257    0.0827282   -0.113757     -0.149401    0.161259     0.0568264    -0.0150095   -0.216254     0.196965   -0.161728     0.0157447   -0.014573      0.108977    -0.134434     0.0918424    0.0359354   -0.0340177   -0.028687     0.10376      0.0589376    0.046748  
 -0.00760653  -0.105713     0.150245    -0.0104437    0.135237    0.0560063   -0.140583     0.0648057    -0.13878     0.0949093   -0.0102415    -0.0938445   -0.0562909   -0.103054    0.0232503    0.219602     0.00679619    0.25179     -0.00310703  -0.0413758    0.249473     0.0792308    0.0835074   -0.0390716   -0.0955843    0.0123848 
 -0.131226    -0.101561     0.0199845   -0.0532206    0.106429    0.0877311   -0.0375748   -0.033179     -0.111942   -0.0370176    0.111214      0.0159561   -0.00634304  -0.172786   -0.0843767    0.180362     0.0269729     0.0640448    0.0702186    0.0156686    0.106656     0.0855844    0.00789912   0.145675    -0.00800185  -0.106762  
 -0.11822     -0.0380805   -0.00676073   0.0462101   -0.131909    0.0628903    0.150308     0.160407      0.113747   -0.178864    -0.0647391     0.00578696  -0.0186654    0.0909453  -0.100394     0.0352467   -0.0102577     0.0230534   -0.0786498   -0.154655    -0.0527989   -0.0193309   -0.00413939   0.0187128   -0.0827214   -0.0128733 
  0.0314324    0.0171546    0.0139647    0.0723681    0.0586416   0.0419169    0.0461115    0.000611756  -0.0969231   0.149298    -0.157007      0.0559269    0.00380421   0.122149    0.0441567   -0.121953     0.0899645     0.0396897   -0.0172927   -0.0818571   -0.0787225   -0.0491011    0.0192067   -0.0832332    0.129055    -0.0589279 
  0.0727501   -0.0695208   -0.120721     0.0536675    0.0506058  -0.0107295   -0.146927     0.048235      0.0331764  -0.0521735   -0.145793      0.114808    -0.0202966   -0.333512   -0.199618     0.0145948   -0.0385263     0.0978143   -0.0104295    0.0200786    0.116483     0.0308689    0.0968748    0.16199      0.00179549  -0.00548764
  0.102569    -0.0482303    0.0141863   -0.110279     0.0596018   0.0218032    0.0112273    0.0380411     0.0435674  -0.0051031   -0.0528606    -0.0444212   -0.0719972    0.0303648   0.163263    -0.0801326   -0.126522      0.0272468   -0.0859127   -0.17633      0.113328     0.0522146   -0.013161     0.0271909   -0.108834    -0.099098  
 -0.00540165   0.0968081   -0.00497789  -0.168351     0.0432711  -0.0801827   -0.129305    -0.0189666     0.0599294   0.0244425   -0.0361997     0.085952    -0.0245474    0.0447215   0.0563414   -0.119339     0.0442471    -0.0144555   -0.0410397   -0.00973934   0.110013    -0.0894416   -0.0522191   -0.305872     0.0624629    0.0234335 
  0.0484592    0.0402348   -0.10589      0.134527    -0.0446579  -0.0461154    0.0112391   -0.0814873     0.0617078  -0.0594559   -0.0351561     0.18072      0.0916447   -0.0322814   0.0723073   -0.0205147    0.173491     -0.183266    -0.0743973    0.0133916   -0.142977    -0.00857693  -0.198564     0.0269416    0.0428513   -0.0360813 
  0.0322579    0.0307805   -0.115557    -0.0168074    0.0747879  -0.0716172   -0.0033802    0.023979      0.0444097  -0.0399236    0.0386044     0.0615878    0.0015906    0.032151    0.0159426    0.00448444   0.00887739    0.00358588  -0.0305415    0.0499878   -0.0672145   -0.114734     0.0923428    0.0820081   -0.0515818    0.169152  
 -0.0975808   -0.0615942   -0.0686945   -0.106257    -0.0827736  -0.0439227    0.0281604   -0.120298      0.0930292  -0.0669997   -0.0254502    -0.107101    -0.0304017   -0.083773    0.103938    -0.0468556    0.0582696     0.145139     0.105638     0.077937     0.0837644   -0.0354782   -0.205948     0.066765    -0.0289805    0.174701  
 -0.0218549    0.0484918    0.105644    -0.0341969    0.0218412  -0.0299865   -0.00405203   0.130137      0.0311255   0.187385    -0.0573334     0.0126818    0.00413719  -0.0145444  -0.0510079    0.0923472    0.0275493    -0.0817958   -0.0617409   -0.0256088   -0.0866134   -0.204232     0.0811474    0.185116    -0.0432583    0.0705093 
 -0.0587051    0.276883    -0.0272801   -0.127468    -0.159342    0.00523294  -0.0582081   -0.0121676     0.0912102   0.165824    -0.057221     -0.0967412   -0.0270856   -0.143067   -0.0289029   -0.089861     0.0564625     0.0994499   -0.093493    -0.0120593    0.162699     0.125293    -0.00888768  -0.108188    -0.0233311    0.0274622 
  0.00656442   0.107678    -0.0885031    0.00574535   0.0690093  -0.0404681   -0.0481711   -0.112268     -0.0189834   0.00600669   0.000138305  -0.111159     0.128488    -0.0869038   0.0964528    0.0465884    0.121488     -0.030794    -0.17466      0.172306     0.028677     0.0820866   -0.120261    -0.0448343   -0.14079     -0.00336499
  0.0610775   -0.0451667    0.0680177    0.0273352   -0.0700111  -0.065168    -0.115151    -0.15787      -0.0590391  -0.0567708    0.163907     -0.156589    -0.0106594    0.166924    0.006273     0.125369     0.0938389    -0.0332596   -0.0581197   -0.0178923    0.141043    -0.0210899    0.0342214   -0.00343113  -0.10563      0.228521  
  0.0262089    0.215409    -0.114185    -0.0702303   -0.0118454  -0.029368     0.0972305    0.0332196     0.241786   -0.0342965   -0.0678865    -0.145607     0.010251    -0.0583508  -0.0662001    0.100364    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.0678613    -0.063732     0.153727    -0.0217927   -0.0985553    0.0673609   -0.0606897    0.0343129   -0.00463766  -0.0581298 
 -0.08375      0.0955996   -0.187078    -0.0832101    0.0815534  -0.00285375   0.0435168   -0.0329432     0.11571    -0.0790623   -0.0400064    -0.0341876    0.0598434    0.0417165  -0.00289545   0.0517178   -0.13242       0.100907    -0.0950424    0.0267704   -0.157173    -0.0770236    0.0771235    0.0727334    0.0424973    0.109206  
  0.0196932   -0.0429094    0.0237174    0.0857449   -0.055048   -0.284972     0.0380216    0.0259118    -0.0591621   0.0228539    0.0419736     0.148978    -0.00389161   0.0809739  -0.0377597    0.0948229    0.00647983    0.039034    -0.147708    -0.0586588   -0.0333168    0.00403186  -0.0560034   -0.124282    -0.0545644   -0.112953  ┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.072655
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     18
│     20
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.037060
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     20
│     21
│     23
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.021567
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      9
│     18
│      ⋮
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.033836
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     20
│     23
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.036768
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      7
│     18
│      ⋮
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.027327
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     20
│     23
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.036939
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     18
│     20
│     23
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.036564
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     20
│     21
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.029612
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│      9
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.025418
┌ Info: EM with 100000 data points 10 iterations avll -1.025418
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.054532     0.0579081    0.0668321    0.139845      0.00589278  -0.169269     -0.17566     -0.0892646    0.0559641   -0.146801    -0.0961422   -0.0437707   -0.143775     0.105648    -0.072341     -0.0521426    0.0315598    -0.100419     0.00670829  -0.0733558     0.0586935   -0.198622    -0.185688   -0.0239308    0.0108265    0.0933489 
 -0.197195    -0.114471     0.0168524    0.0535608    -0.0189673   -0.036505     -0.0583784   -0.0228237   -0.164196     0.0213755    0.0124118   -0.044272     0.0866247   -0.128379    -0.0642297     0.0804042   -0.026204      0.0844546   -0.164877     0.0311914     0.180047     0.0991441    0.189955    0.169802     0.0774268    0.0857317 
  0.0326187    0.131065    -0.0921216   -0.0373106    -0.117927     0.120386      0.0756571   -0.0633766    0.167589    -0.0104528    0.101813     0.0319002    0.0699854    0.0447106   -0.0353953     0.0427355    0.116011      0.0089089    0.173954     0.0416624    -0.0316121    0.0477185    0.159141    0.00314518  -0.0273387   -0.103109  
 -0.213962    -0.151609     0.0261526   -0.111387     -0.079715    -0.0948261    -0.0025335    0.0602439    0.189684    -0.239354     0.0260423    0.0559243   -0.163424    -0.0570341   -0.0197913     0.113621    -0.0710824    -0.0406245   -0.137122     0.0875083     0.052316     0.00682864  -0.0500263   0.0805925   -0.0220639    0.0241987 
 -0.00749127   0.00791384   0.0890334   -0.0122262     0.00870401  -0.0979804    -0.0651707   -0.0670453   -0.0198149   -0.00788214  -0.0075934    0.0717544   -0.00855977  -0.0448363   -0.0418166    -0.15702     -0.066277     -0.0504715    0.0204645   -0.0318823     0.0664027   -0.146137    -0.015256    0.0575431   -0.114221    -0.0492584 
 -0.0903069    0.0271418    0.0446694    0.00146314    0.0218227    0.000429784  -0.0949337   -0.00617514  -0.0240817    0.00614086  -0.156078    -0.0690461    0.031114    -0.0568686   -0.0426516     0.0119627    0.0447591     0.0130313   -0.108237     0.0236849    -0.133203     0.165205     0.0388137  -0.106499     0.0548592   -0.0313951 
 -0.0713938   -0.0592656   -0.00501697   0.110491      0.0983552   -0.0206697    -0.012236     0.0223137    0.0803226   -0.104314     0.0140836   -0.0253349   -0.0685802    0.0151797   -0.085908     -0.0379397    0.178822     -0.0836102   -0.0966244   -0.0425816    -0.0543838   -0.0292435    0.0735149   0.125262    -0.0215999   -0.00906014
  0.123338    -0.0114151    0.0656824    0.0239763     0.118999    -0.0526379    -0.0260841    0.13711      0.107502    -0.221481    -0.0654269    0.0320743   -0.0246058   -0.00530496   0.0672799    -0.00044653  -0.105018     -0.0498881    0.0844206   -0.0789277     0.101737    -0.109968     0.0501074   9.18648e-5   0.0705183   -0.165745  
 -0.115264     0.094875     0.0446055   -0.12778      -0.0609752   -0.103661      0.037298    -0.0124012    0.0652428    0.00659388  -0.115537    -0.0085916    0.0680891   -0.00232768  -0.0344026    -0.0296709    0.0636877     0.117193     0.034818    -0.198623     -0.0563792   -0.0480416    0.0797072  -0.0918918    0.0545069   -0.0864673 
 -0.0292203    0.0244965   -0.0414239    0.0204219    -0.0219767    0.0360112    -0.0525598    0.158124     0.12275     -0.106021     0.121519     0.0134354    0.119617    -0.0589725    0.0299687    -0.16427      0.118908      0.0968429    0.0632411    0.0143322     0.0263334    0.0331675    0.0400675   0.121787    -0.0497538   -0.205489  
  0.0592628    0.0535246   -0.157273    -0.0839702     0.160713     0.10494      -0.0886511    0.113686    -0.174633    -0.0328284    0.0807505   -0.0230358   -0.0612985   -0.142032    -0.0918976     0.113627    -0.0112425     0.0551729   -0.055874    -0.0470794     0.0796437    0.120535     0.0819975   0.0470704    0.107731    -0.0726074 
 -0.0667945   -0.0108855   -0.0575286   -0.0126523     0.171113    -0.0126375    -0.0359093   -0.0140238   -0.128653     0.0265529    0.154461    -0.180453    -0.016759     0.0325119   -0.0629542     0.0113116    0.0766991     0.113727     0.0571165    0.108283      0.0687077    0.0211872   -0.031158   -0.0252975    0.168161    -0.0660789 
  0.172536    -0.0981834   -0.0277328   -0.0269705     0.0355573   -0.0925214    -0.0844413   -0.0843985   -0.181589     0.0222063   -0.0205905   -0.169827     0.202841    -0.00864529  -0.0556263     0.262304     0.0113109    -0.0430302    0.0531684   -0.0881124     0.00358667  -0.177651     0.0418184   0.0661057   -0.0356566   -0.0383493 
 -0.0987084    0.017786     0.027736     0.00393245   -0.0467168   -0.0517729     0.149447     0.0196233    0.0304159   -0.0138702    0.040976     0.0278252   -0.0455544   -0.14485      0.229936     -0.0725192    0.0740734    -0.0690377    0.0718239   -0.00605449    0.0202955   -0.0627657   -0.0463221  -0.0769249   -0.00334726  -0.102145  
 -0.0554403    0.180403    -0.0968082    0.0421345     0.124372     0.0361209    -0.0375989   -0.097037     0.132283     0.146571     0.0319512   -0.102976    -0.00400422   0.0765631   -0.0977884    -0.0185941    0.0184184     0.0178434   -0.291174     0.0956117     0.0301379   -0.0582019   -0.086121    0.0650442   -0.108996    -0.0541546 
 -0.0154488    0.0940783   -0.0800899   -0.0282943    -0.169792     0.0341725    -0.116206    -0.0269732    0.0660695   -0.0717411   -0.158162     0.142378     0.0777366    0.0777442    0.0332997    -0.159792     0.0126101    -0.0187802    0.0633355   -0.237493      0.070825     0.10457     -0.095384   -0.165885     0.0205627    0.0483448 
  0.137293     0.096894     0.265381    -0.0833181     0.0929318   -0.0280712    -0.00165107   0.0718991   -0.141693    -0.0677808   -0.0746282   -0.228656    -0.0248165    0.0288328    0.0390253     0.117795     0.300423     -0.0364111    0.0582085   -0.0992977     0.0619139    0.012973    -0.0211644  -0.0012376    0.163815    -0.0853357 
 -0.0920309   -0.0334734   -0.0178807    0.11636      -0.0913116    0.00648229    0.116854     0.100363     0.00257727  -0.120368     0.0154057    0.141267    -0.119383     0.0956941    0.124884      0.0496456   -0.0757788    -0.114995    -0.0612696   -0.0780227    -0.093952    -0.0522375    0.0643896   0.0665453    0.234334     0.0674149 
 -0.0968817    0.18306      0.0145731   -0.163898     -0.0103205    0.0539132     0.116454    -0.069154     0.0129023    0.0600575    0.0538196   -0.0395374   -0.0928494    0.0462915   -0.100586      0.0649097   -0.0272373     0.144163     0.0382729   -0.114631      0.134711     0.00188382   0.0615131   0.0419774   -0.00226217   0.021686  
 -0.0633092    0.106294     0.268901    -0.120948      0.0309981   -0.066161     -0.128936     0.186569     0.0566537   -0.202415    -0.0722478   -0.00489741   0.0125246   -0.034625    -0.000920354   0.0564591   -0.0144828    -0.15044      0.00718565  -0.14701      -0.0583166    0.133923     0.0103987   0.0581545    0.145065    -0.00667507
  0.100514    -0.0278704    0.0842139    0.000547484   0.0342245    0.0679637    -0.00855106  -0.0528051   -0.109446     0.144785     0.0482511    0.0400512    0.0227507   -0.0975588   -0.133685      0.140251     0.0688374     0.10394      0.113557     0.000178395  -0.134501    -0.00769032   0.0321744  -0.0846122    0.0090842   -0.0143195 
 -0.0202654   -0.1082      -0.0019485   -0.0160354     0.0576158    0.059762     -0.0315838    0.0862281    0.199176    -0.0892795   -0.010936    -0.197397     0.0105644    0.0143588   -0.0694329    -0.110203    -0.130897      0.00797376  -0.0724209   -0.0845414     0.0641912   -0.0112461   -0.0414347   0.0439678    0.00156143  -0.220223  
 -0.0639152    0.084996    -0.0930333   -0.0681232    -0.0926555    0.0234487    -0.0333874   -0.162597     0.0844244    0.0410268   -0.0698235   -0.114817    -0.0143475    0.11899     -0.0274709     0.0734986   -0.148432      0.0948448   -0.118651    -0.137732     -0.0886256   -0.0614215    0.0707268   0.0559259    0.0143789   -0.14843   
 -0.128958    -0.152479    -0.166236    -0.0204961     0.106645    -0.30467       0.00692004   0.206033    -0.0710062    0.0507515   -0.0328679    0.156369     0.0138836   -0.0393097   -0.0138227     0.203317    -0.131516      0.0899591   -0.0876906    0.196486     -0.0252621    0.100594     0.15717    -0.00472241  -0.0377366   -0.146862  
 -0.0427022    0.112225    -0.0582084    0.0203003    -0.158458     0.0202399     0.0448981    0.0310863   -0.1425       0.0263942    0.0754611    0.043395    -0.153479    -0.0609859    0.109317     -0.106983     0.0970508     0.0251226    0.190919     0.076744      0.0434564    0.0535629   -0.0111569  -0.195966     0.210387     0.108459  
  0.11427     -0.100618    -0.15477      0.0450962     0.183593    -0.00276865    0.0134771    0.0340731   -0.0955365    0.0178371    0.040742     0.0535757   -0.0700786   -0.0921723    0.0107234    -0.232897    -0.000202763  -0.0409259   -0.0882759    0.0340409     0.0988914    0.0956085    0.246198   -0.0320993    0.0242149    0.146485  
  0.0649248   -0.0368278   -0.112975     0.0811934    -0.0228685   -0.0448431    -0.296303     0.106294     0.0175912   -0.0858843   -0.109984    -0.00526619   0.0673769   -0.139894     0.00727897   -0.229252     0.136572      0.0721415    0.0175824    0.0314543     0.0218581    0.0235497    0.0174446   0.0367037    0.228393    -0.167063  
 -0.0844664    0.0199614   -0.1355      -0.055013     -0.0524081    0.0245376    -0.0253751   -0.115399     0.327014     0.0457703    0.00591582   0.0282104    0.0210371    0.0434941    0.0159432    -0.0523883    0.120544      0.00854617  -0.0781162   -0.12522       0.0829277    0.134824     0.127476    0.00918503   0.0804406   -0.0796465 
 -0.0594543    0.1128      -0.112446    -0.0996825    -0.0223579   -0.0407641     0.114876    -0.137253    -0.00964203  -0.0536856   -0.036984     0.0868136    0.051563    -0.0942248   -0.223838      0.0348275   -0.0062963     0.101367    -0.118276     0.0688679    -0.00632699  -0.112431    -0.0228098  -0.0673843   -0.0696757   -0.152359  
  0.0702308    0.00156542  -0.0677719    0.212953     -0.0503097   -0.095987     -0.0286711   -0.0254056    0.0767586   -0.238796    -0.0520448   -0.142952    -0.0710654   -0.0276745   -0.0126706     0.168079    -0.0243131     0.0806137   -0.135465    -0.127786      0.0410946   -0.0206012    0.154107    0.0188453    0.0362556   -0.124223  
 -0.0631199   -0.0652484   -0.0765855    0.00770849    0.0816859    0.0952774     0.0691792    0.110895     0.106057     0.0807127   -0.135818    -0.0334845    0.0602991    0.0205962   -0.0804971    -0.0244758   -0.0804563    -0.112199    -0.0498515    0.00109915    0.14162     -0.15048     -0.0264878   0.0401077    0.00527179   0.224003  
  0.00217129  -0.00239043  -0.123791    -0.0480332     0.0558327    0.0320639     0.0158454   -0.00917889  -0.0856115    0.0207417   -0.0291179   -0.0227935    0.16774     -0.0614979   -0.041175      0.0787793   -0.0284036    -0.0638969    0.0607038   -0.085159      0.116698    -0.135284    -0.0166435   0.0257649   -0.0470092    0.148049  kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4224411318574293
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422460
[ Info: iteration 2, average log likelihood -1.422388
[ Info: iteration 3, average log likelihood -1.422329
[ Info: iteration 4, average log likelihood -1.422255
[ Info: iteration 5, average log likelihood -1.422154
[ Info: iteration 6, average log likelihood -1.422008
[ Info: iteration 7, average log likelihood -1.421771
[ Info: iteration 8, average log likelihood -1.421346
[ Info: iteration 9, average log likelihood -1.420591
[ Info: iteration 10, average log likelihood -1.419471
[ Info: iteration 11, average log likelihood -1.418286
[ Info: iteration 12, average log likelihood -1.417458
[ Info: iteration 13, average log likelihood -1.417050
[ Info: iteration 14, average log likelihood -1.416883
[ Info: iteration 15, average log likelihood -1.416818
[ Info: iteration 16, average log likelihood -1.416793
[ Info: iteration 17, average log likelihood -1.416783
[ Info: iteration 18, average log likelihood -1.416778
[ Info: iteration 19, average log likelihood -1.416776
[ Info: iteration 20, average log likelihood -1.416776
[ Info: iteration 21, average log likelihood -1.416775
[ Info: iteration 22, average log likelihood -1.416775
[ Info: iteration 23, average log likelihood -1.416774
[ Info: iteration 24, average log likelihood -1.416774
[ Info: iteration 25, average log likelihood -1.416774
[ Info: iteration 26, average log likelihood -1.416774
[ Info: iteration 27, average log likelihood -1.416774
[ Info: iteration 28, average log likelihood -1.416774
[ Info: iteration 29, average log likelihood -1.416774
[ Info: iteration 30, average log likelihood -1.416773
[ Info: iteration 31, average log likelihood -1.416773
[ Info: iteration 32, average log likelihood -1.416773
[ Info: iteration 33, average log likelihood -1.416773
[ Info: iteration 34, average log likelihood -1.416773
[ Info: iteration 35, average log likelihood -1.416773
[ Info: iteration 36, average log likelihood -1.416773
[ Info: iteration 37, average log likelihood -1.416773
[ Info: iteration 38, average log likelihood -1.416773
[ Info: iteration 39, average log likelihood -1.416773
[ Info: iteration 40, average log likelihood -1.416773
[ Info: iteration 41, average log likelihood -1.416773
[ Info: iteration 42, average log likelihood -1.416773
[ Info: iteration 43, average log likelihood -1.416773
[ Info: iteration 44, average log likelihood -1.416773
[ Info: iteration 45, average log likelihood -1.416773
[ Info: iteration 46, average log likelihood -1.416773
[ Info: iteration 47, average log likelihood -1.416773
[ Info: iteration 48, average log likelihood -1.416773
[ Info: iteration 49, average log likelihood -1.416773
[ Info: iteration 50, average log likelihood -1.416773
┌ Info: EM with 100000 data points 50 iterations avll -1.416773
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.422459998608781 
│     -1.422388254236236 
│      ⋮                 
└     -1.4167727688627987
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416791
[ Info: iteration 2, average log likelihood -1.416716
[ Info: iteration 3, average log likelihood -1.416654
[ Info: iteration 4, average log likelihood -1.416578
[ Info: iteration 5, average log likelihood -1.416484
[ Info: iteration 6, average log likelihood -1.416379
[ Info: iteration 7, average log likelihood -1.416276
[ Info: iteration 8, average log likelihood -1.416189
[ Info: iteration 9, average log likelihood -1.416125
[ Info: iteration 10, average log likelihood -1.416080
[ Info: iteration 11, average log likelihood -1.416051
[ Info: iteration 12, average log likelihood -1.416029
[ Info: iteration 13, average log likelihood -1.416013
[ Info: iteration 14, average log likelihood -1.415998
[ Info: iteration 15, average log likelihood -1.415986
[ Info: iteration 16, average log likelihood -1.415974
[ Info: iteration 17, average log likelihood -1.415962
[ Info: iteration 18, average log likelihood -1.415951
[ Info: iteration 19, average log likelihood -1.415940
[ Info: iteration 20, average log likelihood -1.415928
[ Info: iteration 21, average log likelihood -1.415917
[ Info: iteration 22, average log likelihood -1.415906
[ Info: iteration 23, average log likelihood -1.415895
[ Info: iteration 24, average log likelihood -1.415884
[ Info: iteration 25, average log likelihood -1.415873
[ Info: iteration 26, average log likelihood -1.415863
[ Info: iteration 27, average log likelihood -1.415853
[ Info: iteration 28, average log likelihood -1.415843
[ Info: iteration 29, average log likelihood -1.415834
[ Info: iteration 30, average log likelihood -1.415826
[ Info: iteration 31, average log likelihood -1.415817
[ Info: iteration 32, average log likelihood -1.415809
[ Info: iteration 33, average log likelihood -1.415801
[ Info: iteration 34, average log likelihood -1.415793
[ Info: iteration 35, average log likelihood -1.415785
[ Info: iteration 36, average log likelihood -1.415777
[ Info: iteration 37, average log likelihood -1.415768
[ Info: iteration 38, average log likelihood -1.415759
[ Info: iteration 39, average log likelihood -1.415750
[ Info: iteration 40, average log likelihood -1.415740
[ Info: iteration 41, average log likelihood -1.415729
[ Info: iteration 42, average log likelihood -1.415718
[ Info: iteration 43, average log likelihood -1.415706
[ Info: iteration 44, average log likelihood -1.415694
[ Info: iteration 45, average log likelihood -1.415681
[ Info: iteration 46, average log likelihood -1.415669
[ Info: iteration 47, average log likelihood -1.415656
[ Info: iteration 48, average log likelihood -1.415643
[ Info: iteration 49, average log likelihood -1.415631
[ Info: iteration 50, average log likelihood -1.415619
┌ Info: EM with 100000 data points 50 iterations avll -1.415619
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4167913536952819
│     -1.4167164567456543
│      ⋮                 
└     -1.415618841830945 
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415619
[ Info: iteration 2, average log likelihood -1.415546
[ Info: iteration 3, average log likelihood -1.415476
[ Info: iteration 4, average log likelihood -1.415390
[ Info: iteration 5, average log likelihood -1.415281
[ Info: iteration 6, average log likelihood -1.415149
[ Info: iteration 7, average log likelihood -1.415003
[ Info: iteration 8, average log likelihood -1.414859
[ Info: iteration 9, average log likelihood -1.414731
[ Info: iteration 10, average log likelihood -1.414624
[ Info: iteration 11, average log likelihood -1.414538
[ Info: iteration 12, average log likelihood -1.414468
[ Info: iteration 13, average log likelihood -1.414412
[ Info: iteration 14, average log likelihood -1.414367
[ Info: iteration 15, average log likelihood -1.414330
[ Info: iteration 16, average log likelihood -1.414299
[ Info: iteration 17, average log likelihood -1.414272
[ Info: iteration 18, average log likelihood -1.414249
[ Info: iteration 19, average log likelihood -1.414227
[ Info: iteration 20, average log likelihood -1.414208
[ Info: iteration 21, average log likelihood -1.414190
[ Info: iteration 22, average log likelihood -1.414173
[ Info: iteration 23, average log likelihood -1.414157
[ Info: iteration 24, average log likelihood -1.414141
[ Info: iteration 25, average log likelihood -1.414126
[ Info: iteration 26, average log likelihood -1.414112
[ Info: iteration 27, average log likelihood -1.414097
[ Info: iteration 28, average log likelihood -1.414084
[ Info: iteration 29, average log likelihood -1.414070
[ Info: iteration 30, average log likelihood -1.414058
[ Info: iteration 31, average log likelihood -1.414045
[ Info: iteration 32, average log likelihood -1.414034
[ Info: iteration 33, average log likelihood -1.414022
[ Info: iteration 34, average log likelihood -1.414012
[ Info: iteration 35, average log likelihood -1.414002
[ Info: iteration 36, average log likelihood -1.413993
[ Info: iteration 37, average log likelihood -1.413984
[ Info: iteration 38, average log likelihood -1.413976
[ Info: iteration 39, average log likelihood -1.413969
[ Info: iteration 40, average log likelihood -1.413962
[ Info: iteration 41, average log likelihood -1.413956
[ Info: iteration 42, average log likelihood -1.413951
[ Info: iteration 43, average log likelihood -1.413945
[ Info: iteration 44, average log likelihood -1.413941
[ Info: iteration 45, average log likelihood -1.413936
[ Info: iteration 46, average log likelihood -1.413932
[ Info: iteration 47, average log likelihood -1.413929
[ Info: iteration 48, average log likelihood -1.413925
[ Info: iteration 49, average log likelihood -1.413922
[ Info: iteration 50, average log likelihood -1.413920
┌ Info: EM with 100000 data points 50 iterations avll -1.413920
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4156188673316006
│     -1.4155457442020023
│      ⋮                 
└     -1.4139195708621621
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413927
[ Info: iteration 2, average log likelihood -1.413871
[ Info: iteration 3, average log likelihood -1.413820
[ Info: iteration 4, average log likelihood -1.413760
[ Info: iteration 5, average log likelihood -1.413687
[ Info: iteration 6, average log likelihood -1.413597
[ Info: iteration 7, average log likelihood -1.413493
[ Info: iteration 8, average log likelihood -1.413381
[ Info: iteration 9, average log likelihood -1.413267
[ Info: iteration 10, average log likelihood -1.413158
[ Info: iteration 11, average log likelihood -1.413058
[ Info: iteration 12, average log likelihood -1.412967
[ Info: iteration 13, average log likelihood -1.412886
[ Info: iteration 14, average log likelihood -1.412814
[ Info: iteration 15, average log likelihood -1.412750
[ Info: iteration 16, average log likelihood -1.412694
[ Info: iteration 17, average log likelihood -1.412645
[ Info: iteration 18, average log likelihood -1.412603
[ Info: iteration 19, average log likelihood -1.412566
[ Info: iteration 20, average log likelihood -1.412534
[ Info: iteration 21, average log likelihood -1.412506
[ Info: iteration 22, average log likelihood -1.412481
[ Info: iteration 23, average log likelihood -1.412458
[ Info: iteration 24, average log likelihood -1.412438
[ Info: iteration 25, average log likelihood -1.412419
[ Info: iteration 26, average log likelihood -1.412401
[ Info: iteration 27, average log likelihood -1.412385
[ Info: iteration 28, average log likelihood -1.412370
[ Info: iteration 29, average log likelihood -1.412355
[ Info: iteration 30, average log likelihood -1.412341
[ Info: iteration 31, average log likelihood -1.412328
[ Info: iteration 32, average log likelihood -1.412315
[ Info: iteration 33, average log likelihood -1.412303
[ Info: iteration 34, average log likelihood -1.412291
[ Info: iteration 35, average log likelihood -1.412280
[ Info: iteration 36, average log likelihood -1.412269
[ Info: iteration 37, average log likelihood -1.412258
[ Info: iteration 38, average log likelihood -1.412248
[ Info: iteration 39, average log likelihood -1.412238
[ Info: iteration 40, average log likelihood -1.412228
[ Info: iteration 41, average log likelihood -1.412219
[ Info: iteration 42, average log likelihood -1.412210
[ Info: iteration 43, average log likelihood -1.412201
[ Info: iteration 44, average log likelihood -1.412193
[ Info: iteration 45, average log likelihood -1.412185
[ Info: iteration 46, average log likelihood -1.412177
[ Info: iteration 47, average log likelihood -1.412169
[ Info: iteration 48, average log likelihood -1.412162
[ Info: iteration 49, average log likelihood -1.412155
[ Info: iteration 50, average log likelihood -1.412148
┌ Info: EM with 100000 data points 50 iterations avll -1.412148
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4139267515177532
│     -1.4138707625168827
│      ⋮                 
└     -1.4121477210773319
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412149
[ Info: iteration 2, average log likelihood -1.412086
[ Info: iteration 3, average log likelihood -1.412026
[ Info: iteration 4, average log likelihood -1.411954
[ Info: iteration 5, average log likelihood -1.411864
[ Info: iteration 6, average log likelihood -1.411753
[ Info: iteration 7, average log likelihood -1.411619
[ Info: iteration 8, average log likelihood -1.411467
[ Info: iteration 9, average log likelihood -1.411305
[ Info: iteration 10, average log likelihood -1.411141
[ Info: iteration 11, average log likelihood -1.410983
[ Info: iteration 12, average log likelihood -1.410833
[ Info: iteration 13, average log likelihood -1.410695
[ Info: iteration 14, average log likelihood -1.410570
[ Info: iteration 15, average log likelihood -1.410458
[ Info: iteration 16, average log likelihood -1.410361
[ Info: iteration 17, average log likelihood -1.410276
[ Info: iteration 18, average log likelihood -1.410202
[ Info: iteration 19, average log likelihood -1.410139
[ Info: iteration 20, average log likelihood -1.410083
[ Info: iteration 21, average log likelihood -1.410033
[ Info: iteration 22, average log likelihood -1.409989
[ Info: iteration 23, average log likelihood -1.409949
[ Info: iteration 24, average log likelihood -1.409912
[ Info: iteration 25, average log likelihood -1.409878
[ Info: iteration 26, average log likelihood -1.409846
[ Info: iteration 27, average log likelihood -1.409816
[ Info: iteration 28, average log likelihood -1.409788
[ Info: iteration 29, average log likelihood -1.409761
[ Info: iteration 30, average log likelihood -1.409735
[ Info: iteration 31, average log likelihood -1.409710
[ Info: iteration 32, average log likelihood -1.409686
[ Info: iteration 33, average log likelihood -1.409663
[ Info: iteration 34, average log likelihood -1.409641
[ Info: iteration 35, average log likelihood -1.409619
[ Info: iteration 36, average log likelihood -1.409598
[ Info: iteration 37, average log likelihood -1.409577
[ Info: iteration 38, average log likelihood -1.409557
[ Info: iteration 39, average log likelihood -1.409538
[ Info: iteration 40, average log likelihood -1.409519
[ Info: iteration 41, average log likelihood -1.409500
[ Info: iteration 42, average log likelihood -1.409482
[ Info: iteration 43, average log likelihood -1.409464
[ Info: iteration 44, average log likelihood -1.409446
[ Info: iteration 45, average log likelihood -1.409428
[ Info: iteration 46, average log likelihood -1.409411
[ Info: iteration 47, average log likelihood -1.409394
[ Info: iteration 48, average log likelihood -1.409378
[ Info: iteration 49, average log likelihood -1.409361
[ Info: iteration 50, average log likelihood -1.409345
┌ Info: EM with 100000 data points 50 iterations avll -1.409345
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412149120903627 
│     -1.4120861921383354
│      ⋮                 
└     -1.4093453482905167
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4224411318574293
│     -1.422459998608781 
│     -1.422388254236236 
│     -1.4223292937482563
│      ⋮                 
│     -1.4093778489819286
│     -1.4093614735365672
└     -1.4093453482905167
32×26 Array{Float64,2}:
 -0.330706   -0.385491   -0.817966   -0.359668    0.377566    -0.167266   -0.674774     0.291877   -0.0575363   0.215147     0.088647    0.485724   -0.221429    -0.251114    -0.407927     0.555326     0.314079    0.499102    -0.377518     0.0117302    0.816915     -0.216379    0.115801   -0.186005   -0.52643     -0.89737  
 -0.157433    0.107182    0.786304    0.0775436   0.386388    -0.0842245   0.277614     0.622161    0.151309    0.046036     0.218826    0.947197   -0.574388     0.0960414    0.643979     0.451929    -0.0786248   0.47409     -0.40939      0.149907     0.307469      0.13966    -0.588112   -0.0979548   0.243065    -0.490426 
 -0.526893    0.543558   -0.0308133  -0.245636   -0.00845908  -0.367753   -0.178767    -0.117681   -0.307893    0.255716    -1.06777     0.710511   -0.239677     0.487461    -0.254482     0.0826818    0.229467    0.308924     0.285996    -0.0654252   -0.0621324     0.059758    0.299552    0.0923342  -0.344069     0.178932 
 -0.452456    0.0594314  -0.227912   -0.118164   -0.412202    -0.910148   -0.144971     0.23169     0.367111    0.64757      0.173908    0.614036   -0.152288     0.443606    -0.0408516   -0.536393     0.225981   -0.00216259  -0.0306334    0.00963912   0.59994       0.228434    0.158286   -0.0329291   0.441422     0.0754146
  0.420654   -0.236746    0.379922    0.288127    0.402451     0.022155    0.126055     0.103525   -0.58302     0.0115039   -0.29032     0.0236486   0.155273    -0.213853     0.173696     0.453245     0.268877    0.328476    -0.287226    -0.584153    -1.00035       0.291597   -0.590752    0.134992   -0.362031    -0.101201 
  0.203238    0.450402    0.21805    -0.261633   -0.339891     0.0779084   0.0236891   -0.602398   -0.508783    0.478384    -0.0718802  -0.145042   -0.00605918  -0.695708     0.51772      0.108103     0.0856706   0.368578    -0.113898     0.147685     0.0565683     0.625145    0.0210798  -0.378471    0.599976     0.121448 
  0.554743    0.527654   -0.175104   -0.494957    0.33565     -0.174344   -0.367804     0.741695   -0.0065492   0.167447    -0.667356    0.150834   -0.083694    -0.58038      0.366755    -0.42834      0.270614   -0.138344    -0.0137462   -0.531833    -0.200211      0.0432848  -0.863597   -0.550477    0.483221     0.063945 
  0.338914    0.149358   -0.426765   -0.271391   -0.317707     0.396197    0.338887     1.0514     -0.244617   -0.0679594    0.194514    0.198358    0.407376    -0.0638053    0.221886     0.196708     0.236556   -0.305204    -0.361425    -0.46495     -0.353325      0.0908684  -0.144137    0.197533    0.196042    -0.241685 
  0.340251    0.173435   -0.477951    0.165358    0.352472    -0.269656    0.186883    -0.517797    0.352427    0.0453581   -0.176785   -0.306162    0.120262    -0.127382    -0.605384    -0.438723    -0.182831   -0.108652    -0.0352034    0.1476       0.0194385     0.542083    0.45734    -0.790993   -0.464531    -0.218741 
  0.389198    0.252138   -0.358456   -0.456471    0.0449123    0.555419    0.304391    -0.378123    0.39871     0.155134    -0.162944   -0.82865     0.496625     0.027984    -0.251522     0.147467    -0.437736   -0.199169    -0.20389      0.00450396   0.0439287    -0.663014    0.283925    0.20071    -0.504246    -0.363062 
  0.26724     0.0778674   0.117363    0.0700449  -0.162277    -0.0796506   0.239207    -0.485441   -0.0684372   0.00880795  -0.298017   -0.806425    0.186648     0.00829772  -0.306063    -0.162769    -0.0401854  -0.0516437    0.3407      -0.0450191   -0.744208      0.0750487   0.138919    0.253449   -0.0402588    0.521722 
 -0.198489   -0.153281   -0.0728654   0.374288    0.187857     0.131699   -0.0278674   -0.143513   -0.0580606  -0.426987     0.376545    0.507062   -0.1951      -0.0131619    0.0743683   -0.12266     -0.0376613  -0.131799    -0.187417     0.112898     0.612624     -0.0166932   0.269036    0.0608837  -0.229523     0.0090841
 -0.303287   -0.207872    0.388278   -0.271223   -0.0654841    0.0279565  -0.533399    -0.102504    0.0578556  -0.412697    -0.0696774  -0.44129    -0.181901     0.323531    -0.0465001    0.101118    -0.087223   -0.0413819   -0.0100799    0.0780519    0.046176     -1.08285    -0.478609    0.527569    0.34578     -0.0853539
 -0.14099    -0.189099   -0.0642491  -0.0246847  -0.0932869    0.167356   -0.472513     0.031806    0.439488   -0.21791      0.260369   -0.953491    0.307204    -0.026965    -0.589765    -0.367377     0.192826   -0.259672     0.569441     0.292475     0.351944     -0.402388    0.433926    0.112984    0.680414    -0.156355 
 -0.360016   -0.557382    0.108126    0.560244   -0.131457    -0.0304141  -0.392281    -0.0274912  -0.564438   -0.898609     0.283187    0.075197   -0.210283    -0.210576    -0.378656     0.0850069    0.554792    0.0700192    0.167327     0.293704     0.322154      0.512071    0.439744    0.284264    0.140732    -0.10985  
 -0.222056   -0.745459   -0.0818666   0.143427    0.235394    -0.215676   -0.242159     0.195571   -0.589777    0.925923     0.38695    -0.330884    0.185974    -0.372175    -0.621735     0.580511     0.0668432   0.590607     0.190505     0.0638269   -0.0950245     0.568399    0.371921    0.0265175   0.499992     0.096007 
  0.0189655   0.245049    0.287565   -0.43996     0.0417963   -0.690085   -0.315233    -0.065415    0.444874    0.422242    -0.541763   -0.586824    0.0998789   -0.0864766   -0.273293    -0.047659     0.0147187  -0.0433029    0.257453    -0.46025     -0.489767     -0.127884   -0.321869   -0.0481641   0.151483     0.0906964
  0.181961    0.061463    0.46999    -0.556575    0.117001     0.321616   -0.0558324    0.25151     0.190171    0.260858    -0.0779943  -0.323478   -0.181757    -0.363752     0.0508901    0.304462     0.332849    0.590184    -0.00717535  -0.263004    -0.000665443  -0.254914   -0.357564    0.301427    0.564435    -0.495462 
 -0.526796   -0.481935    0.0994035  -0.246248   -0.178741     0.134216    0.0536475    0.207444    0.233056    0.24307      0.0568759  -0.117446    0.147285     0.556376    -0.0961684   -0.0185917   -0.15722     0.45345      0.115334    -0.297367     0.0103606    -0.227095    0.240663    0.666947    0.276188     0.0399699
  0.147538   -0.0933052   0.61045    -0.248541    0.44937      0.187192    0.604981    -0.277923    0.286397   -0.137185     0.360863    0.0416837  -0.349586    -0.189468    -0.16624      0.0263894   -0.379659    0.352414    -0.307401     0.42091      0.16422       0.0914684   0.717544    0.326224   -0.0268576    0.175681 
  0.0252119   0.662945    0.21603    -0.113149   -0.0299384    0.178017   -0.0167301    0.0830949   0.54399    -0.5529      -0.402661    0.257493   -0.0978929    0.298611     0.40109     -0.3871      -0.0213043  -0.555069    -0.21636     -0.0166097    0.293793     -0.447492   -0.220073   -0.207299   -0.128763    -0.428293 
  0.483103    0.222759    0.677912    0.237891   -0.233489     0.666995    0.273863    -0.219817    0.47605    -0.122761     0.191426   -0.474555    0.397883    -0.106106     0.517727    -0.163024    -0.59013    -0.501799    -0.0712137   -0.139986    -0.0119876     0.0125998  -0.538578   -0.203137    0.194607     0.410666 
 -0.355702   -0.212355   -0.364782    0.905688   -0.0457921   -0.268779    0.426554     0.189688    0.172473   -0.50528      0.423484    0.391221    0.198132     0.491953     0.20497     -0.273499    -0.319871   -0.392383     0.306482    -0.151813    -0.0781708    -0.092467    0.34386    -0.221608   -0.350345     0.0987566
  0.746457    0.794908    0.304833   -0.147547   -0.181375    -0.179629    0.207267    -0.0679163   0.347881   -0.53016      0.0530169   0.291444    0.0106369    0.631632     0.659732    -0.620881     0.142252   -0.214905     0.431734     0.128115    -0.367103      0.264988    0.543782    0.458134    0.0126421   -0.0475394
 -0.0380946   0.0108148  -0.661972   -0.0155059  -0.12805     -0.212022   -0.0414371   -0.2802     -0.547295    0.0300279   -0.169431    0.0853184  -0.00468136  -0.178909     0.173603     0.563918    -0.737995   -0.155688    -0.243534     0.366759    -0.262716      0.0170844  -0.394374   -0.378748   -0.440627     0.199464 
 -1.03547    -0.084221   -0.410188    0.486361   -0.0547586   -0.0285891  -0.553932     0.0772614   0.128928   -0.148173    -0.177633    0.049794   -0.100875    -0.219776    -0.400838     0.445105     0.158944   -0.162666    -0.0784266   -0.561309     0.340864     -0.0174096  -0.573419   -0.344923   -0.276368     0.0710451
  0.025359   -0.0933435   0.0932368   0.269845   -0.110783    -0.191014   -0.0396152   -0.159028   -0.0679454  -0.156124     0.142822   -0.470544    0.12965      0.135106     0.0330613   -0.331738     0.14557    -0.0977441    0.275745     0.015126    -0.145232     -0.228871   -0.206227    0.110671    0.298612     0.304587 
 -0.0985957  -0.344074   -0.48563    -0.218748    0.0554183   -0.0143423  -0.11881     -0.309705   -0.224951   -0.238515     0.0617897  -0.229312   -0.0551073   -0.0399777   -0.321944    -0.0535995   -0.145111   -0.433864     0.14987     -0.135005     0.247743     -0.343069    0.814829    0.17764    -0.044646     0.334317 
 -0.225624    0.0241058   0.0360289  -0.127017   -0.0814974   -0.154206   -0.0358536    0.0587761  -0.016052    0.103053    -0.0863159   0.167773   -0.0870237    0.0791289   -0.0694654    0.0814167   -0.0668019   0.136937    -0.0558207   -0.0487367    0.0642066    -0.0446822   0.0515295   0.0631647   0.00233229   0.0119419
  0.084119    0.289202   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.0400242   0.34474    -0.0436039   -0.472472    0.0606255    0.40518    -0.314324   -0.109685     0.0924658   0.60415    -0.316903    -0.41963      0.210805    -0.0557625    0.426972    0.195363    -0.245834     0.0952975    0.0308286     0.682448   -0.191832   -0.354786    0.091542     0.0304825
  0.300335   -0.0150653  -0.307345    0.0968719   0.244542     0.206054   -0.00743048   0.143973    0.151129   -0.146914     0.126604   -0.171394    0.210628    -0.319631    -0.0515052    0.00244108   0.0878673  -0.254522    -0.0223599   -0.0701114   -0.00495134    0.0387766  -0.0120395  -0.192314    0.0622902   -0.427154 
  0.136973    0.163639   -0.291267   -0.0849433   0.167563     0.554614    0.243991    -0.17994    -0.116333    0.0145113   -0.21931     0.304618   -0.0100931    0.0671639   -0.00748849   0.288118     0.0422706   0.193131    -0.337569     0.213439     0.208802      0.264871    0.350379   -0.0217979  -0.331771    -0.30985  [ Info: iteration 1, average log likelihood -1.409329
[ Info: iteration 2, average log likelihood -1.409314
[ Info: iteration 3, average log likelihood -1.409299
[ Info: iteration 4, average log likelihood -1.409284
[ Info: iteration 5, average log likelihood -1.409269
[ Info: iteration 6, average log likelihood -1.409254
[ Info: iteration 7, average log likelihood -1.409240
[ Info: iteration 8, average log likelihood -1.409227
[ Info: iteration 9, average log likelihood -1.409213
kind full, method kmeans
[ Info: iteration 10, average log likelihood -1.409201
┌ Info: EM with 100000 data points 10 iterations avll -1.409201
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.199201e+05
      1       7.052087e+05      -2.147113e+05 |       32
      2       6.900571e+05      -1.515161e+04 |       32
      3       6.845416e+05      -5.515520e+03 |       32
      4       6.818065e+05      -2.735053e+03 |       32
      5       6.801325e+05      -1.674048e+03 |       32
      6       6.790315e+05      -1.101013e+03 |       32
      7       6.782724e+05      -7.591135e+02 |       32
      8       6.776932e+05      -5.791476e+02 |       32
      9       6.772040e+05      -4.892263e+02 |       32
     10       6.767805e+05      -4.234803e+02 |       32
     11       6.763883e+05      -3.922302e+02 |       32
     12       6.760555e+05      -3.327860e+02 |       32
     13       6.757643e+05      -2.911731e+02 |       32
     14       6.755029e+05      -2.614318e+02 |       32
     15       6.752558e+05      -2.470694e+02 |       32
     16       6.750206e+05      -2.352203e+02 |       32
     17       6.748033e+05      -2.172694e+02 |       32
     18       6.746240e+05      -1.793560e+02 |       32
     19       6.744739e+05      -1.500777e+02 |       32
     20       6.743310e+05      -1.429065e+02 |       32
     21       6.742044e+05      -1.265761e+02 |       32
     22       6.740726e+05      -1.318379e+02 |       32
     23       6.739568e+05      -1.157957e+02 |       32
     24       6.738446e+05      -1.121363e+02 |       32
     25       6.737243e+05      -1.203525e+02 |       32
     26       6.735866e+05      -1.376754e+02 |       32
     27       6.734578e+05      -1.288498e+02 |       32
     28       6.733440e+05      -1.138011e+02 |       32
     29       6.732352e+05      -1.087171e+02 |       32
     30       6.731306e+05      -1.046529e+02 |       32
     31       6.730349e+05      -9.570881e+01 |       32
     32       6.729360e+05      -9.888455e+01 |       32
     33       6.728552e+05      -8.081719e+01 |       32
     34       6.727920e+05      -6.312525e+01 |       32
     35       6.727396e+05      -5.248210e+01 |       32
     36       6.726821e+05      -5.747303e+01 |       32
     37       6.726185e+05      -6.361756e+01 |       32
     38       6.725562e+05      -6.223610e+01 |       32
     39       6.724979e+05      -5.836580e+01 |       32
     40       6.724412e+05      -5.667174e+01 |       32
     41       6.723829e+05      -5.826590e+01 |       32
     42       6.723308e+05      -5.214707e+01 |       32
     43       6.722869e+05      -4.389675e+01 |       32
     44       6.722478e+05      -3.904809e+01 |       32
     45       6.722146e+05      -3.327271e+01 |       32
     46       6.721863e+05      -2.823007e+01 |       32
     47       6.721610e+05      -2.531514e+01 |       32
     48       6.721370e+05      -2.404272e+01 |       32
     49       6.721173e+05      -1.968324e+01 |       32
     50       6.720997e+05      -1.757271e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672099.7251778629)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421093
[ Info: iteration 2, average log likelihood -1.416223
[ Info: iteration 3, average log likelihood -1.414977
[ Info: iteration 4, average log likelihood -1.414078
[ Info: iteration 5, average log likelihood -1.413058
[ Info: iteration 6, average log likelihood -1.411985
[ Info: iteration 7, average log likelihood -1.411153
[ Info: iteration 8, average log likelihood -1.410660
[ Info: iteration 9, average log likelihood -1.410387
[ Info: iteration 10, average log likelihood -1.410218
[ Info: iteration 11, average log likelihood -1.410098
[ Info: iteration 12, average log likelihood -1.410003
[ Info: iteration 13, average log likelihood -1.409924
[ Info: iteration 14, average log likelihood -1.409857
[ Info: iteration 15, average log likelihood -1.409798
[ Info: iteration 16, average log likelihood -1.409746
[ Info: iteration 17, average log likelihood -1.409700
[ Info: iteration 18, average log likelihood -1.409659
[ Info: iteration 19, average log likelihood -1.409622
[ Info: iteration 20, average log likelihood -1.409588
[ Info: iteration 21, average log likelihood -1.409557
[ Info: iteration 22, average log likelihood -1.409528
[ Info: iteration 23, average log likelihood -1.409501
[ Info: iteration 24, average log likelihood -1.409476
[ Info: iteration 25, average log likelihood -1.409452
[ Info: iteration 26, average log likelihood -1.409430
[ Info: iteration 27, average log likelihood -1.409408
[ Info: iteration 28, average log likelihood -1.409388
[ Info: iteration 29, average log likelihood -1.409368
[ Info: iteration 30, average log likelihood -1.409348
[ Info: iteration 31, average log likelihood -1.409330
[ Info: iteration 32, average log likelihood -1.409311
[ Info: iteration 33, average log likelihood -1.409293
[ Info: iteration 34, average log likelihood -1.409276
[ Info: iteration 35, average log likelihood -1.409258
[ Info: iteration 36, average log likelihood -1.409241
[ Info: iteration 37, average log likelihood -1.409224
[ Info: iteration 38, average log likelihood -1.409208
[ Info: iteration 39, average log likelihood -1.409191
[ Info: iteration 40, average log likelihood -1.409175
[ Info: iteration 41, average log likelihood -1.409160
[ Info: iteration 42, average log likelihood -1.409144
[ Info: iteration 43, average log likelihood -1.409129
[ Info: iteration 44, average log likelihood -1.409115
[ Info: iteration 45, average log likelihood -1.409101
[ Info: iteration 46, average log likelihood -1.409087
[ Info: iteration 47, average log likelihood -1.409074
[ Info: iteration 48, average log likelihood -1.409061
[ Info: iteration 49, average log likelihood -1.409049
[ Info: iteration 50, average log likelihood -1.409038
┌ Info: EM with 100000 data points 50 iterations avll -1.409038
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.392871     0.0379016   -0.801769    0.0577148    0.00562396  -0.0599603    0.414384    0.391102   -0.693815   -0.014098   -0.0326255     0.307274    0.158515    -0.087291    0.462713     0.25852    -0.230055   -0.306291    -0.334723    -0.278741   -0.523015     0.247832   -0.389463    -0.229127    -0.407525   -0.0395181 
  0.303775     0.496467    -0.11439     0.289866    -0.215035    -0.0911001    0.305117    0.0604104   0.283263   -0.521648    0.0394997     0.295255    0.0262951    0.409395    0.416658    -0.400919   -0.19182    -0.637523     0.176462    -0.0895027  -0.150992     0.0806474   0.314953    -0.15898     -0.482377   -0.0197843 
  0.335356     0.121892    -0.418306    0.188404     0.499544    -0.0941643    0.0639585  -0.451861    0.4544     -0.0358786  -0.220282     -0.275054    0.182728    -0.0932694  -0.560243    -0.329624   -0.167706   -0.14529     -0.0766881    0.192446    0.072418     0.475057    0.305406    -0.731619    -0.410773   -0.527831  
  0.499375     0.528664     0.439571   -0.00809085   0.416297    -0.487925     0.384172    0.236858    0.201589    0.484222   -0.1235        0.388797   -0.78361     -0.724024    0.349294    -0.0703277   0.295142    0.474535    -0.496327    -0.106382    0.139874     0.268093   -0.659575    -0.316145    -0.0911448  -0.230934  
 -0.0483335   -0.740226    -0.0459025   0.0588655    0.21839     -0.30693     -0.13263     0.203064   -0.481915    0.447055    0.306813     -0.0635751   0.0312419   -0.118779   -0.42761      0.281307    0.134301    0.46974      0.00664279  -0.104311   -0.100784     0.37592     0.177079     0.18176      0.148128    0.14906   
  1.08258     -0.026424     0.664882    0.699347    -0.0468131    0.825246     0.301553   -0.14239     0.72857    -0.185221    0.483342     -0.614195    0.42999     -0.799623    0.548387     0.195464   -0.885411   -0.518514     0.526648     0.301998    0.455671    -0.211442   -0.729131    -0.130856    -0.535466   -0.01786   
  0.122005     0.187392     0.170956   -0.134037     0.134937     0.186269    -0.0808769   0.102325    0.225938   -0.375262   -0.019229      0.197489   -0.0677745    0.377681    0.312143    -0.259242   -0.111666   -0.397234    -0.19016     -0.0464658   0.237085    -0.374361   -0.141954     0.0839212    0.0291814  -0.166784  
  0.428757     0.600401     0.145461    0.247894     0.0323352   -0.176997    -0.128341    0.143568   -0.156856   -0.414971   -0.0114727     0.512873   -0.0569187   -0.447048    0.670667    -0.363985    0.695143   -0.0497922   -0.0932288    0.0962788  -0.103673     0.576956   -0.173529    -0.415546     0.435915   -0.0471274 
 -0.471599    -0.443568    -0.33304     0.481578     0.087558    -0.534685    -0.0723253  -0.0912531   0.0121782  -0.358154    0.356852      0.325653   -0.00598102   0.254693   -0.247128    -0.615338   -0.159938   -0.559767     0.184713     0.285467    0.53629     -0.17165     0.535356    -0.0293133    0.0752281   0.393654  
 -0.0875784    0.077072     0.331836    0.0421178   -0.387844     0.448925     0.123813    0.869392    0.441844    0.170341    0.255465     -0.186807    0.184044     0.0877528   0.0774206    0.0408508   0.599297    0.305315    -0.220438    -0.922899   -0.138278    -0.065613   -0.24753      0.518844     0.586203   -0.534619  
  0.262427    -0.330536     0.558534    0.154207     0.250446     0.04429     -0.313759    0.0925499  -0.701079   -0.0936691  -0.469698     -0.272807    0.298917    -0.394656    0.0378798    0.3995      0.266859    0.263885    -0.0280219   -0.542464   -1.25624      0.128622   -0.511894     0.100483     0.0253083  -0.11979   
 -0.142306     0.378596     0.394388   -0.886902    -0.194238     0.0228257    0.0628208  -0.193895    0.496793   -0.23501    -0.518293      0.043222   -0.2813       0.416835    0.252749    -0.0943463  -0.0822896   0.0402315    0.0104197   -0.172499   -0.135512    -0.583074    0.158998     0.584904    -0.0259727  -0.216608  
  0.106718     0.0152272   -0.288346   -0.0705464   -0.223659    -0.422329    -0.0265505  -0.257084    0.15988     0.202364   -0.498737     -0.80742     0.0337523   -0.0704883  -0.92662      0.0580426   0.100171    0.120618     0.530262    -0.051105   -0.561738    -0.0226308   0.401303     0.0381841   -0.28269     0.456229  
 -0.491959    -0.23868     -0.877119   -0.390153     0.142993    -0.378823    -0.944415    0.263091   -0.0752312   0.182117   -0.0710947     0.394971   -0.230166    -0.166385   -0.377258     0.442903    0.347596    0.203263    -0.315367    -0.152731    0.802423    -0.368123    0.0111041   -0.2573      -0.495787   -0.71616   
  0.38008      0.470564     0.794363    0.341131    -0.0368644    0.288285     0.913251   -0.417722    0.322662   -0.0945067   0.0881919    -0.563811    0.370313     0.348799    0.0650402   -0.385722   -0.283716   -0.165017     0.213932     0.153221   -0.973026     0.262818    0.0363094    0.256557     0.440642    0.732738  
 -0.241463     0.0841661   -0.452545    0.207787    -0.143983    -0.151139    -0.0897957   0.0579589  -0.162283   -0.0758519  -0.0312226     0.158301   -0.012704    -0.223575   -0.225368     0.184801    0.0205622  -0.00935146  -0.206656     0.069346    0.132866     0.304125   -0.0381765   -0.354168    -0.264521   -0.110146  
 -0.0508536   -0.0434548    0.568414    0.243999    -0.49209     -0.397904    -0.534624   -0.257512    0.184201   -0.324825    0.100386     -0.520225   -0.0418913    0.221134    0.246745    -0.463442    0.208733   -0.432966     0.0463168    0.0628763   0.0394762   -0.272446   -0.541498     0.346196     0.409563    0.234485  
  0.106035     0.122786    -0.043208   -0.626527     0.189549    -0.180843    -0.132292    0.210295    0.552636    0.59424    -0.167043     -0.488145    0.350502    -0.142698    0.0955732   -0.0817252  -0.470581   -0.0168764    0.0511265   -0.247069   -0.169563    -0.423529   -0.509896    -0.391838     0.726606   -0.164184  
  0.0391589    0.383871    -0.305977   -0.0525414    0.149279     0.546648     0.274155   -0.413978    0.344137    0.417889   -0.357838     -0.210553    0.453297     0.665838   -0.129777     0.253579   -0.475808    0.332754    -0.2282       0.0284329   0.0973429   -0.386089    0.224418     0.075648    -0.930621   -0.0402309 
 -0.578281     0.0206933    0.471257   -0.130107     0.279853     0.0608089   -0.475244   -0.54157     0.388522    0.147927    0.15333      -0.741155   -0.191538    -0.0280159  -0.545328     0.102583    0.203836    0.678481     0.458149     0.43222     0.431453    -0.186534    0.160327     0.233152     0.580296   -0.0132237 
 -0.319076     0.532451     0.50408    -0.0642443   -0.588607    -0.136204     0.549105   -0.600793   -0.928688    0.306583   -0.523738      0.34048     0.100048     0.183614    0.167168     0.068289   -0.0437789   0.653111    -0.189926    -0.306529    0.139215     0.142127   -0.393329    -0.209329     0.0611863   0.691203  
 -0.415677    -0.283423    -0.0308259   0.165843    -0.0232841   -0.198908    -0.184721    0.0257522  -0.43881     0.220707    0.29852       0.045755    0.0843361   -0.628533    0.00544363   0.253317    0.271457    0.427304     0.0590146    0.225072    0.181151     0.761861    0.153919    -0.191062     0.530179   -0.0343379 
 -0.745842    -0.63139     -0.303733    0.119824    -0.474383     0.172671    -0.120384    0.278455   -0.0728003  -0.283697    0.377538     -0.521718    0.355967     0.572134   -0.211791     0.0668582  -0.270638    0.123346     0.415685     0.0187465   0.0947409   -0.440178    0.410279     0.534032     0.406169    0.101316  
  0.00156234  -0.00241886   0.0500292  -0.0306339    0.0441753    0.00144634   0.0325842  -0.0220026   0.071196   -0.0182684  -0.000885524  -0.135614    0.0115126    0.0565281  -0.0144874   -0.0986923   0.0413736   0.00797236   0.0850805   -0.104223   -0.00540872  -0.164815    0.0497235    0.132257     0.153376    0.00601716
  0.825591     0.517534    -0.108166   -0.763193    -0.154803     0.635607     0.113512    0.176201   -0.305638    0.171276   -0.308137     -0.321893    0.143639    -0.527993    0.0580149    0.102078    0.298084   -0.0861199   -0.0167973   -0.0637509  -0.0198148    0.251633   -0.00312542   0.166469     0.440011   -0.184484  
 -0.129223    -0.061407     0.288217   -0.200399     0.232967     0.262685     0.213136    0.52923     0.0128299  -0.218418    0.0860976     0.537105   -0.0121959    0.0853236   0.254822     0.562446    0.075535    0.322221    -0.447749     0.311359    0.27328     -0.144299   -0.129643     0.00487741   0.0831793  -0.409046  
 -0.036764    -0.226113    -0.337393   -0.144275     0.0785915    0.0623111   -0.405087   -0.73257    -0.476179   -0.261919   -0.294253     -0.427091   -0.0401546   -0.457597    0.0438024    0.442696   -0.498692   -0.221433     0.135059     0.325758   -0.194477    -0.354407   -0.0622638   -0.0984872   -0.20677     0.178704  
 -0.960049     0.161111    -0.148644    0.339638     0.142321     0.300318    -0.414348    0.245949    0.32189    -0.282684   -0.291402      0.174597   -0.262151    -0.248856   -0.283779     0.426269    0.0446113  -0.277699    -0.074744    -0.931443    0.274226    -0.0461606  -0.512952    -0.352955    -0.267857    0.123337  
  0.208227    -0.157998     0.280775   -0.396064     0.37344      0.245649     0.61398    -0.368114    0.206101   -0.0280917   0.413672      0.0474225  -0.439016    -0.330675   -0.173553     0.0528882  -0.582175    0.207488    -0.485159     0.266375    0.238096     0.179068    0.829959     0.19158     -0.117417    0.117751  
  0.457773    -0.159459    -0.347072   -0.238821     0.0575001    0.190038    -0.183811   -0.0763419   0.171683   -0.300871    0.128436     -0.869305    0.409131    -0.271011   -0.582449    -0.503447    0.378307   -0.67298      0.179711    -0.139959    0.264186    -0.426221    0.580449     0.141272     0.239517   -0.0640105 
 -0.513108     0.100364    -0.128293   -0.0467609   -0.188095    -0.765247    -0.210768    0.267004    0.0675404   0.498893   -0.371471      0.997808   -0.322703     0.558883   -0.00840931  -0.111882    0.272024    0.186319     0.2113       0.0242404   0.152549     0.397203    0.306026     0.0977767    0.192389   -0.021221  
 -0.239287    -0.276547     0.0545358   0.96773      0.0698847    0.374219    -0.0408187  -0.0439352  -0.446876   -0.780613    0.44642       0.631569   -0.563273    -0.0960443  -0.288282     0.0989358   0.321269    0.315386     0.0681322    0.199859    0.575538     0.287211    0.484801     0.495104    -0.364716   -0.125552  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409027
[ Info: iteration 2, average log likelihood -1.409016
[ Info: iteration 3, average log likelihood -1.409006
[ Info: iteration 4, average log likelihood -1.408996
[ Info: iteration 5, average log likelihood -1.408986
[ Info: iteration 6, average log likelihood -1.408977
[ Info: iteration 7, average log likelihood -1.408969
[ Info: iteration 8, average log likelihood -1.408961
[ Info: iteration 9, average log likelihood -1.408953
[ Info: iteration 10, average log likelihood -1.408945
┌ Info: EM with 100000 data points 10 iterations avll -1.408945
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
