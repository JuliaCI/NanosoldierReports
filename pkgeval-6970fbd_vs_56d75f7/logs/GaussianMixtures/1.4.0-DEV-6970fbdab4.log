Julia Version 1.4.0-DEV.528
Commit 6970fbdab4 (2019-11-27 09:37 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed DataAPI ──────────── v1.1.0
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed URIParser ────────── v0.4.0
 Installed JLD ──────────────── v0.9.1
 Installed NearestNeighbors ─── v0.4.4
 Installed Parameters ───────── v0.12.0
 Installed StatsBase ────────── v0.32.0
 Installed Rmath ────────────── v0.6.0
 Installed SortingAlgorithms ── v0.3.1
 Installed QuadGK ───────────── v2.3.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed CMake ────────────── v1.1.2
 Installed Arpack_jll ───────── v3.5.0+2
 Installed HDF5 ─────────────── v0.12.5
 Installed Compat ───────────── v2.2.0
 Installed Missings ─────────── v0.4.3
 Installed Arpack ───────────── v0.4.0
 Installed BinDeps ──────────── v1.0.0
 Installed PDMats ───────────── v0.9.10
 Installed FileIO ───────────── v1.2.0
 Installed LegacyStrings ────── v0.4.1
 Installed Blosc ────────────── v0.5.1
 Installed Distances ────────── v0.8.2
 Installed SpecialFunctions ─── v0.9.0
 Installed StaticArrays ─────── v0.12.1
 Installed Clustering ───────── v0.13.3
 Installed BinaryProvider ───── v0.5.8
 Installed CMakeWrapper ─────── v0.2.3
 Installed FillArrays ───────── v0.8.2
 Installed Distributions ────── v0.21.11
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed StatsFuns ────────── v0.9.3
 Installed OrderedCollections ─ v1.1.0
 Installed DataStructures ───── v0.17.6
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
Status `/tmp/jl_yF7F2Z/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
┌ Warning: Replacing docs for `FileIO.filename :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
┌ Warning: Replacing docs for `FileIO.file_extension :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
[ Info: Testing Data
(100000, -3.2286101786948554e6, [74379.86334438769, 25620.13665561232], [14502.366335870622 -7027.956906055382 -5752.972151731339; -14485.440674178793 7132.51455742295 5879.481846360405], [[79539.6046752713 -3211.271727207374 505.0930628198094; -3211.271727207374 77491.74677661475 -6050.955415022765; 505.0930628198094 -6050.955415022765 93645.69801827404], [20410.92056312415 3140.2447571055723 -231.69320661689625; 3140.2447571055723 22458.421972534714 5968.913039348443; -231.69320661689625 5968.913039348444 5648.387760998753]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.704990e+03
      1       1.224840e+03      -4.801491e+02 |        7
      2       1.021890e+03      -2.029506e+02 |        4
      3       9.801739e+02      -4.171593e+01 |        0
      4       9.801739e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 980.1739171005993)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.073941
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.802492
[ Info: iteration 2, lowerbound -3.669211
[ Info: iteration 3, lowerbound -3.527444
[ Info: iteration 4, lowerbound -3.366944
[ Info: iteration 5, lowerbound -3.204791
[ Info: iteration 6, lowerbound -3.060031
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.923470
[ Info: iteration 8, lowerbound -2.785104
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.650353
[ Info: iteration 10, lowerbound -2.534973
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.441098
[ Info: iteration 12, lowerbound -2.371016
[ Info: iteration 13, lowerbound -2.329284
[ Info: iteration 14, lowerbound -2.315533
[ Info: dropping number of Gaussions to 2
[ Info: iteration 15, lowerbound -2.306653
[ Info: iteration 16, lowerbound -2.299269
[ Info: iteration 17, lowerbound -2.299260
[ Info: iteration 18, lowerbound -2.299256
[ Info: iteration 19, lowerbound -2.299254
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Dec 17 15:48:09 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Dec 17 15:48:18 2019: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Tue Dec 17 15:48:20 2019: EM with 272 data points 0 iterations avll -2.073941
5.8 data points per parameter
, Tue Dec 17 15:48:22 2019: GMM converted to Variational GMM
, Tue Dec 17 15:48:32 2019: iteration 1, lowerbound -3.802492
, Tue Dec 17 15:48:32 2019: iteration 2, lowerbound -3.669211
, Tue Dec 17 15:48:32 2019: iteration 3, lowerbound -3.527444
, Tue Dec 17 15:48:32 2019: iteration 4, lowerbound -3.366944
, Tue Dec 17 15:48:32 2019: iteration 5, lowerbound -3.204791
, Tue Dec 17 15:48:32 2019: iteration 6, lowerbound -3.060031
, Tue Dec 17 15:48:32 2019: dropping number of Gaussions to 6
, Tue Dec 17 15:48:32 2019: iteration 7, lowerbound -2.923470
, Tue Dec 17 15:48:32 2019: iteration 8, lowerbound -2.785104
, Tue Dec 17 15:48:32 2019: dropping number of Gaussions to 5
, Tue Dec 17 15:48:32 2019: iteration 9, lowerbound -2.650353
, Tue Dec 17 15:48:32 2019: iteration 10, lowerbound -2.534973
, Tue Dec 17 15:48:32 2019: dropping number of Gaussions to 4
, Tue Dec 17 15:48:32 2019: iteration 11, lowerbound -2.441098
, Tue Dec 17 15:48:32 2019: iteration 12, lowerbound -2.371016
, Tue Dec 17 15:48:32 2019: iteration 13, lowerbound -2.329284
, Tue Dec 17 15:48:32 2019: iteration 14, lowerbound -2.315533
, Tue Dec 17 15:48:32 2019: dropping number of Gaussions to 2
, Tue Dec 17 15:48:32 2019: iteration 15, lowerbound -2.306653
, Tue Dec 17 15:48:32 2019: iteration 16, lowerbound -2.299269
, Tue Dec 17 15:48:32 2019: iteration 17, lowerbound -2.299260
, Tue Dec 17 15:48:32 2019: iteration 18, lowerbound -2.299256
, Tue Dec 17 15:48:33 2019: iteration 19, lowerbound -2.299254
, Tue Dec 17 15:48:33 2019: iteration 20, lowerbound -2.299254
, Tue Dec 17 15:48:33 2019: iteration 21, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 22, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 23, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 24, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 25, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 26, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 27, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 28, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 29, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 30, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 31, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 32, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 33, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 34, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 35, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 36, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 37, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 38, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 39, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 40, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 41, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 42, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 43, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 44, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 45, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 46, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 47, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 48, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 49, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: iteration 50, lowerbound -2.299253
, Tue Dec 17 15:48:33 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601374, 95.95490777398626]
β = [178.04509222601374, 95.95490777398626]
m = [4.250300733269911 79.28686694436186; 2.0002292577753713 53.851987172461314]
ν = [180.04509222601374, 97.95490777398626]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484569 -0.007644049042327326; 0.0 0.00858170516633351], [0.3758763611948366 -0.008953123827346032; 0.0 0.012748664777409555]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9910343303919545
avll from llpg:  -0.9910343303919544
avll direct:     -0.9910343303919544
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9761112377279278
avll from llpg:  -0.9761112377279278
avll direct:     -0.976111237727928
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0384395    0.113398   -0.00617388    0.0509879    0.0141007   -0.0793154    -0.00114195  -0.0673109    0.00399188    0.0107344    0.111649    -0.177112    -0.0547106   0.0935786    0.0273586   -0.032322     0.120787     0.00995755   0.126219     0.0108389    0.147352     -0.112023    -0.168539   -0.179199     0.00427106   0.0210836
  0.00654121  -0.168332   -0.0526914     0.106134     0.0244494    0.00117404    0.0288189    0.178355    -0.0672188    -0.0237814    0.113846    -0.148195     0.0374323  -0.0219275   -0.0699256   -0.0240915    0.166805     0.0822485   -0.0580064    0.193375    -0.0210066     0.00569272   0.0494301  -0.0211154   -0.0723439    0.0356781
  0.0376332    0.0134625  -0.0223117    -0.010253     0.0581098   -0.0879466     0.0920592    0.0945265    0.0705859     0.0141946   -0.0125398   -0.00124286  -0.0151249   0.119589    -0.145934     0.119016     0.165914    -0.155975     0.0801325    0.113754     0.0950849     0.156454    -0.0440837   0.0913252   -0.163128     0.0866022
 -0.0866422   -0.161286    0.241657     -0.00908175  -0.0411149    0.0583411    -0.118822    -0.135888     0.0524069    -0.101745     0.0171304    0.0692164    0.13307     0.0439648   -0.0244425   -0.0417824   -0.0709511   -0.0688928    0.0523475    0.175618     0.084446      0.138558     0.0138318   0.146395     0.269731    -0.00250656
  0.123899    -0.226813   -0.0119344     0.0805062    0.0452782    0.0460575    -0.0964299    0.035522     0.0809021     0.0195082    0.0384612    0.165065    -0.117922    0.0536268   -0.0575403    0.0586029    0.12009      0.0561373   -0.0135587    0.127245     0.0702139     0.0101058   -0.0365313   0.164603    -0.0807551    0.0903899
 -0.173804     0.154396    0.0759366    -0.0284589    0.0345612   -0.0129719     0.0468537    0.0903011   -0.0621983     0.0429588   -0.0298364   -0.0457204   -0.0244683  -0.0413831    0.0307278    0.0264905   -0.103402    -0.091597    -0.00470928   0.0751211   -0.0776372     0.0403096    0.133283   -0.0452471   -0.0829382   -0.118379
 -0.024665     0.0250399   0.000501192   0.010218     0.176975    -0.212623      0.0189259    0.0269366   -0.0860744     0.102552     0.0152194   -0.040326    -0.0680996   0.0490117   -0.0479312   -0.0193712   -0.0149287    0.0443305    0.0762607   -0.00643678   0.15511      -0.10607     -0.0298626  -0.0686442    0.00263877   0.168913
  0.134163    -0.189136    0.0630944    -0.109734    -0.0353894   -0.078735      0.00347739  -0.204554    -0.256733     -0.0509019   -0.181085     0.0189731    0.011441   -0.108684    -0.142904     0.00404292  -0.113943     0.19766     -0.0118395   -0.239015    -0.00841274   -0.0546063    0.0906643  -0.0231646    0.109074     0.0724773
 -0.0535095    0.0552317   0.139076     -0.0584612   -0.00998165  -0.126612     -0.0103614   -0.0279545    0.0919608    -0.0101878    0.148917    -0.17745      0.242734   -0.0290438   -0.00700555  -0.0423419    0.129975     0.0854804    0.0240971   -0.165263    -0.0305742    -0.149117     0.0997687  -0.0160453    0.11193      0.0350968
  0.144681     0.0395534  -0.0814971     0.160891    -0.367374     0.022774     -0.0830692   -0.105967     0.00745382    0.0907725    0.211855     0.13006      0.0759939  -0.018282     0.0821998    0.0422119    0.0480221   -0.0928195    0.0316519    0.0841529   -0.0924335    -0.161096     0.0957242  -0.0798174    0.036517    -0.0863374
 -0.0633354   -0.0380937  -0.0913837    -0.0131824    0.0985196    0.0690835     0.0618829   -0.159339     0.0546801     0.152626     0.0694213   -0.0846136   -0.127529    0.137775    -0.0479359    0.159856    -0.0712812    0.13162     -0.012362    -0.141014     0.0535887     0.00722808   0.0258606   0.245048    -0.0530473   -0.0219671
  0.12302      0.0129907   0.0441046    -0.173168    -0.100345     0.000973707  -0.0370509    0.0440149    0.130743      0.028606     0.121414     0.0423821   -0.0774001  -0.0174513    0.0777104   -0.0248931    0.0112557   -0.0381765    0.0748526   -0.194979     0.0313803     0.0196464    0.188473    0.0988876    0.07222     -0.0099723
  0.0314582    0.0333866  -0.176195     -0.0329348   -0.137597    -0.0689058    -0.0142116    0.00483899  -0.116007      0.0319801    0.185642     0.129294    -0.068989   -0.120151     0.147161    -0.122711    -0.0816379   -0.0341056    0.0110206   -0.0387893    0.00862675   -0.101887    -0.123789   -0.0977513    0.0527735    0.142221
  0.0494787    0.0748358   0.167494     -0.0815938   -0.0964963    0.00949374   -0.0903102   -0.145933     0.330048     -0.0541511   -0.106806    -0.154547    -0.165658   -0.132595    -0.0992926   -0.180039    -0.103774    -0.0674079    0.0263151    0.308004    -0.0990629    -0.0579769   -0.0781013  -0.204508    -0.199474    -0.0617791
  0.00787323   0.118593    0.0466036     0.149112    -0.00101654  -0.0182459    -0.0316896    0.0446796    0.0656662     0.0497679    0.0649604   -0.0753959    0.0395356   0.0013201    0.250342    -0.22799      0.0620061    0.196034     0.0104704    0.0704726   -0.00959831    0.0653247    0.0701271   0.0205824    0.0655697   -0.170417
 -0.0235484    0.0598543   0.0315396    -0.0200355    0.0108654    0.0734399    -0.0963118   -0.0779328   -0.0893013    -0.0132211    0.0705552    0.0908078    0.0226487   0.00230216   0.0820011    0.2139       0.069931    -0.0908514    0.00743499  -0.155984     0.0349231     0.0628854   -0.144713   -0.113083     0.0530934   -0.0536605
 -0.157114     0.0814049  -0.0055206     0.0461832    0.0141707   -0.0682396     0.0396709   -0.0255238    0.130661      0.0542243   -0.0193711    0.110385     0.0744814  -0.243679     0.194036    -0.0442749    0.0460282   -0.00656037  -0.0473272    0.0882745    0.131977      0.0865037    0.0349769   0.0598083   -0.00288792   0.00324585
  0.0718565   -0.119608    0.0138682     0.0472678   -0.0427758    0.0270183     0.102819     0.0818107    0.0224813     0.0907752   -0.0184918   -0.192695    -0.220358   -0.0373937   -0.178987     0.227064    -0.0469692    0.034014    -0.0831426    0.0242302    0.095183     -0.204633     0.0871049   0.0172685   -0.154923    -0.128929
 -0.0288496    0.0817696   0.00377386   -0.0202899    0.0835698   -0.0440005     0.248406     0.0365794   -0.108925     -0.0526081    0.0591688   -0.0565551   -0.0762847  -0.18044     -0.05249      0.0315826    0.116251    -0.117097     0.121615    -0.00344844   0.0707913    -0.177929    -0.0611738  -0.0258775   -0.0720214   -0.100867
 -0.00988868  -0.0536946   0.000937978   0.0355528   -0.0509131   -0.126455      0.0929459    0.205555    -0.094509      0.00509196  -0.075099    -0.0919257   -0.0573111   0.195161     0.133076     0.018667     0.00469335   0.0432858   -0.0253241   -0.155422    -0.114078      0.0726476    0.342117    0.0857406   -0.082906     0.0521376
  0.0570909    0.0906706   0.0510589    -0.0410443   -0.00715362   0.0584693     0.0967719    0.0243307   -0.128665      0.135563    -0.0408066    0.128949     0.137459    0.0675175    0.101861    -0.179711    -0.117155     0.00210222  -0.0106783    0.0969851   -0.0354431     0.0056733    0.0438764  -0.0421464   -0.0352719   -0.0746676
 -0.0420197    0.0627121  -0.141037     -0.158866     0.298023     0.0543909     0.222331     0.17802      0.0581042    -0.0585344   -0.0932317    0.0366772    0.0702005   0.156418    -0.0587206   -0.0824685    0.0345846   -0.063464    -0.176589     0.00232443   0.0748578    -0.215202    -0.098299    0.0450041   -0.0934122    0.137857
  0.0172575    0.0532992  -0.032599     -0.161994     0.0219719    0.03693      -0.202059     0.0183609   -0.176413     -0.149019     0.0415297    0.149219     0.0195643   0.202268     0.0051111   -0.015178    -0.156341     0.108352     0.0643111    0.0297534    0.0219774     0.125863     0.0111533  -7.56038e-5   0.0122934   -0.0204982
 -0.118053    -0.064992   -0.081239      0.0659721   -0.0534059   -0.087498     -0.12818      0.198234    -0.075142      0.0244822   -0.00774989   0.120568     0.0834789   0.0196409    0.0548171   -0.282045     0.112713     0.0108596   -0.0840937    0.071293    -0.137653     -0.0835485   -0.188008   -0.018237    -0.174757    -0.0509258
  0.119183    -0.0714605   0.08906      -0.062435    -0.0528687    0.0534724     0.246182     0.23583     -0.147401      0.00566841  -0.0287656    0.00523348   0.0539592   0.0908931    0.0899921   -0.0879099    0.00255931  -0.108683    -0.152543     0.032869    -0.0709843     0.0434671    0.0214395   0.00596243   0.0310782    0.00894613
  0.141876    -0.127401    0.019651      0.137341    -0.0203408   -0.00517345    0.017782    -0.0584184    0.000443321  -0.238611    -0.00810718   0.0735211   -0.0103912  -0.0668035   -0.141782     0.0711641   -0.0816326   -0.0550106    0.0630393   -0.138777     0.115251      0.116591    -0.114938    0.011055     0.0264818    0.0307231
 -0.0361331    0.0619336   0.0248534    -0.0593856    0.0717315   -0.130715     -0.0909635    0.0400082   -0.0278778    -0.0984962    0.154529    -0.0347104    0.130675   -0.0299885   -0.136999    -0.0536746   -0.0645113    0.16184     -0.178757    -0.0541204   -0.089808     -0.0355014   -0.0570627   0.0243464    0.0160316    0.127048
 -0.291341     0.0622739  -0.0667349    -0.088084    -0.0545541    0.00620756    0.0569839    0.153369    -0.101802      0.0876457   -0.0117328   -0.103442    -0.0144615   0.17803     -0.138291     0.108006     0.166314    -0.0410262   -0.0187261   -0.190829     0.0489591     0.246037     0.146807    0.165445     0.0846332    0.0501939
  0.0874417    0.139723   -0.000562772  -0.0402389    0.088226    -0.0131529     0.164313    -0.0525551   -0.0948832    -0.0679477   -0.0526449   -0.13721     -0.248692   -0.0917283   -0.128667    -0.0788344    0.140488     0.0656236    0.00460104  -0.124258    -0.0587543     0.0499332   -0.128664   -0.138705    -0.0191755   -0.145933
  0.0322746   -0.0277826  -0.0611147     0.0748026    0.151384    -0.0940514    -0.00919206   0.116468    -0.227923      0.096532     0.0560764    0.0185592   -0.109369    0.0160194   -0.302568     0.0366075    0.00653052  -0.00974551  -0.117024    -0.121696     0.00356735   -0.0844608   -0.0814942  -0.103784     0.135487     0.0758163
  0.0604795   -0.103157   -0.00628676   -0.102484     0.0269199   -0.0765614    -0.0253615   -0.117677    -0.0365208    -0.0521221   -0.0567702   -0.0379925   -0.0870673   0.0887629    0.136556    -0.0593488    0.0999492   -0.133147     0.0218965   -0.0452794   -0.000327688   0.0236892   -0.114662   -0.162057     0.0339987   -0.133828
  0.23417      0.12442     0.0380678    -0.0924495   -0.0573336    0.0118128     0.10029      0.0498244    0.0625739     0.146779     0.0401442   -0.143195     0.0352152   0.15396     -0.198803    -0.0873308   -0.0983136   -0.0315176    0.0363822    0.121625    -0.0643759     0.0945689   -0.0187278  -0.0284436    0.00426703  -0.0131455kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4483020058523919
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.448409
[ Info: iteration 2, average log likelihood -1.448291
[ Info: iteration 3, average log likelihood -1.446766
[ Info: iteration 4, average log likelihood -1.433002
[ Info: iteration 5, average log likelihood -1.414130
[ Info: iteration 6, average log likelihood -1.410113
[ Info: iteration 7, average log likelihood -1.408955
[ Info: iteration 8, average log likelihood -1.408261
[ Info: iteration 9, average log likelihood -1.407610
[ Info: iteration 10, average log likelihood -1.406781
[ Info: iteration 11, average log likelihood -1.406040
[ Info: iteration 12, average log likelihood -1.405572
[ Info: iteration 13, average log likelihood -1.405314
[ Info: iteration 14, average log likelihood -1.405156
[ Info: iteration 15, average log likelihood -1.405040
[ Info: iteration 16, average log likelihood -1.404942
[ Info: iteration 17, average log likelihood -1.404852
[ Info: iteration 18, average log likelihood -1.404765
[ Info: iteration 19, average log likelihood -1.404678
[ Info: iteration 20, average log likelihood -1.404590
[ Info: iteration 21, average log likelihood -1.404499
[ Info: iteration 22, average log likelihood -1.404404
[ Info: iteration 23, average log likelihood -1.404302
[ Info: iteration 24, average log likelihood -1.404187
[ Info: iteration 25, average log likelihood -1.404048
[ Info: iteration 26, average log likelihood -1.403845
[ Info: iteration 27, average log likelihood -1.403517
[ Info: iteration 28, average log likelihood -1.403082
[ Info: iteration 29, average log likelihood -1.402606
[ Info: iteration 30, average log likelihood -1.402138
[ Info: iteration 31, average log likelihood -1.401681
[ Info: iteration 32, average log likelihood -1.401214
[ Info: iteration 33, average log likelihood -1.400740
[ Info: iteration 34, average log likelihood -1.400290
[ Info: iteration 35, average log likelihood -1.399860
[ Info: iteration 36, average log likelihood -1.399432
[ Info: iteration 37, average log likelihood -1.399021
[ Info: iteration 38, average log likelihood -1.398669
[ Info: iteration 39, average log likelihood -1.398417
[ Info: iteration 40, average log likelihood -1.398246
[ Info: iteration 41, average log likelihood -1.398141
[ Info: iteration 42, average log likelihood -1.398078
[ Info: iteration 43, average log likelihood -1.398038
[ Info: iteration 44, average log likelihood -1.398013
[ Info: iteration 45, average log likelihood -1.397995
[ Info: iteration 46, average log likelihood -1.397984
[ Info: iteration 47, average log likelihood -1.397975
[ Info: iteration 48, average log likelihood -1.397969
[ Info: iteration 49, average log likelihood -1.397965
[ Info: iteration 50, average log likelihood -1.397961
┌ Info: EM with 100000 data points 50 iterations avll -1.397961
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.448408600126195
│     -1.4482911930044482
│      ⋮
└     -1.3979614874288628
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.398109
[ Info: iteration 2, average log likelihood -1.397927
[ Info: iteration 3, average log likelihood -1.396078
[ Info: iteration 4, average log likelihood -1.382225
[ Info: iteration 5, average log likelihood -1.363979
[ Info: iteration 6, average log likelihood -1.358293
[ Info: iteration 7, average log likelihood -1.356674
[ Info: iteration 8, average log likelihood -1.355689
[ Info: iteration 9, average log likelihood -1.354852
[ Info: iteration 10, average log likelihood -1.354016
[ Info: iteration 11, average log likelihood -1.353068
[ Info: iteration 12, average log likelihood -1.351971
[ Info: iteration 13, average log likelihood -1.350780
[ Info: iteration 14, average log likelihood -1.349553
[ Info: iteration 15, average log likelihood -1.348166
[ Info: iteration 16, average log likelihood -1.346340
[ Info: iteration 17, average log likelihood -1.344192
[ Info: iteration 18, average log likelihood -1.342697
[ Info: iteration 19, average log likelihood -1.341835
[ Info: iteration 20, average log likelihood -1.341286
[ Info: iteration 21, average log likelihood -1.340877
[ Info: iteration 22, average log likelihood -1.340553
[ Info: iteration 23, average log likelihood -1.340291
[ Info: iteration 24, average log likelihood -1.340055
[ Info: iteration 25, average log likelihood -1.339793
[ Info: iteration 26, average log likelihood -1.339459
[ Info: iteration 27, average log likelihood -1.339093
[ Info: iteration 28, average log likelihood -1.338735
[ Info: iteration 29, average log likelihood -1.338458
[ Info: iteration 30, average log likelihood -1.338281
[ Info: iteration 31, average log likelihood -1.338179
[ Info: iteration 32, average log likelihood -1.338125
[ Info: iteration 33, average log likelihood -1.338095
[ Info: iteration 34, average log likelihood -1.338078
[ Info: iteration 35, average log likelihood -1.338068
[ Info: iteration 36, average log likelihood -1.338062
[ Info: iteration 37, average log likelihood -1.338058
[ Info: iteration 38, average log likelihood -1.338055
[ Info: iteration 39, average log likelihood -1.338053
[ Info: iteration 40, average log likelihood -1.338051
[ Info: iteration 41, average log likelihood -1.338050
[ Info: iteration 42, average log likelihood -1.338050
[ Info: iteration 43, average log likelihood -1.338049
[ Info: iteration 44, average log likelihood -1.338049
[ Info: iteration 45, average log likelihood -1.338048
[ Info: iteration 46, average log likelihood -1.338048
[ Info: iteration 47, average log likelihood -1.338048
[ Info: iteration 48, average log likelihood -1.338048
[ Info: iteration 49, average log likelihood -1.338048
[ Info: iteration 50, average log likelihood -1.338048
┌ Info: EM with 100000 data points 50 iterations avll -1.338048
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3981085281413232
│     -1.3979271670454665
│      ⋮
└     -1.338047724267188
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.338207
[ Info: iteration 2, average log likelihood -1.338025
[ Info: iteration 3, average log likelihood -1.336684
[ Info: iteration 4, average log likelihood -1.326204
[ Info: iteration 5, average log likelihood -1.302806
[ Info: iteration 6, average log likelihood -1.288251
[ Info: iteration 7, average log likelihood -1.282666
[ Info: iteration 8, average log likelihood -1.279026
[ Info: iteration 9, average log likelihood -1.277075
[ Info: iteration 10, average log likelihood -1.276054
[ Info: iteration 11, average log likelihood -1.275498
[ Info: iteration 12, average log likelihood -1.275142
[ Info: iteration 13, average log likelihood -1.274919
[ Info: iteration 14, average log likelihood -1.274783
[ Info: iteration 15, average log likelihood -1.274699
[ Info: iteration 16, average log likelihood -1.274645
[ Info: iteration 17, average log likelihood -1.274608
[ Info: iteration 18, average log likelihood -1.274580
[ Info: iteration 19, average log likelihood -1.274557
[ Info: iteration 20, average log likelihood -1.274538
[ Info: iteration 21, average log likelihood -1.274521
[ Info: iteration 22, average log likelihood -1.274505
[ Info: iteration 23, average log likelihood -1.274491
[ Info: iteration 24, average log likelihood -1.274476
[ Info: iteration 25, average log likelihood -1.274460
[ Info: iteration 26, average log likelihood -1.274443
[ Info: iteration 27, average log likelihood -1.274423
[ Info: iteration 28, average log likelihood -1.274401
[ Info: iteration 29, average log likelihood -1.274374
[ Info: iteration 30, average log likelihood -1.274342
[ Info: iteration 31, average log likelihood -1.274304
[ Info: iteration 32, average log likelihood -1.274258
[ Info: iteration 33, average log likelihood -1.274208
[ Info: iteration 34, average log likelihood -1.274155
[ Info: iteration 35, average log likelihood -1.274099
[ Info: iteration 36, average log likelihood -1.274040
[ Info: iteration 37, average log likelihood -1.273982
[ Info: iteration 38, average log likelihood -1.273929
[ Info: iteration 39, average log likelihood -1.273879
[ Info: iteration 40, average log likelihood -1.273832
[ Info: iteration 41, average log likelihood -1.273784
[ Info: iteration 42, average log likelihood -1.273734
[ Info: iteration 43, average log likelihood -1.273680
[ Info: iteration 44, average log likelihood -1.273619
[ Info: iteration 45, average log likelihood -1.273548
[ Info: iteration 46, average log likelihood -1.273468
[ Info: iteration 47, average log likelihood -1.273382
[ Info: iteration 48, average log likelihood -1.273311
[ Info: iteration 49, average log likelihood -1.273268
[ Info: iteration 50, average log likelihood -1.273246
┌ Info: EM with 100000 data points 50 iterations avll -1.273246
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3382070989677888
│     -1.3380248944000586
│      ⋮
└     -1.2732457862976634
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.273506
[ Info: iteration 2, average log likelihood -1.273195
[ Info: iteration 3, average log likelihood -1.271327
[ Info: iteration 4, average log likelihood -1.252202
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.212994
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.201521
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.194679
[ Info: iteration 8, average log likelihood -1.188001
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.172537
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.192222
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.191111
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.180442
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.187111
[ Info: iteration 14, average log likelihood -1.184005
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.170228
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.189152
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.187696
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.189370
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.189796
[ Info: iteration 20, average log likelihood -1.184893
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.170753
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.189902
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.189260
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.179059
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.186166
[ Info: iteration 26, average log likelihood -1.183578
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.169715
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.188470
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.199198
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.182340
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.187003
[ Info: iteration 32, average log likelihood -1.184063
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.170255
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.189779
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.189079
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.178980
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.185943
[ Info: iteration 38, average log likelihood -1.183753
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.170105
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.189741
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.189024
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.178944
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.185875
[ Info: iteration 44, average log likelihood -1.183704
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.170031
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.189621
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.188779
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.178403
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.184620
[ Info: iteration 50, average log likelihood -1.193807
┌ Info: EM with 100000 data points 50 iterations avll -1.193807
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2735058684422802
│     -1.2731950401174073
│      ⋮
└     -1.1938072234689112
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│      4
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.173766
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│      4
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.171146
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│      4
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.169103
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.151080
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.106173
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.067016
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.054901
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│      ⋮
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.093783
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.074120
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.057668
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│     10
│      ⋮
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.066305
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.072981
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.065518
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.067824
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.077978
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.074929
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│      ⋮
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.075406
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.058740
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.073488
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│      ⋮
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.088973
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.065705
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.061026
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.089702
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│      ⋮
│     20
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.063610
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.056089
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│     10
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.087966
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.072773
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.064301
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.071522
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.079193
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.066083
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.092517
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.053679
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.071172
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.092756
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.056761
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.056847
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.097325
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│      ⋮
│     20
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.066864
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.057443
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│     10
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.080437
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.070385
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.063546
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.079642
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.081663
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.067199
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.085094
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.051706
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.070912
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.100345
┌ Info: EM with 100000 data points 50 iterations avll -1.100345
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1737658641479385
│     -1.171146066938308
│      ⋮
└     -1.1003452751961171
32×26 Array{Float64,2}:
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4483020058523919
│     -1.448408600126195
│     -1.4482911930044482
│     -1.4467663145556675
│      ⋮
│     -1.0517055629347756
│     -1.0709116328757962
└     -1.1003452751961171
  0.0499435   -0.107656    -0.204617    -0.0981797     0.0395137   -0.0909411   -0.269377     0.0303976  -0.0701555    0.0157793   -0.0416814   -0.0955784    0.200646     -0.155509     0.137112    -0.0526831    0.100138    -0.151284     0.00779383  -0.100967     0.0395233  -0.251395    -0.162956   -0.176377    -0.0242866   -0.105307
 -0.00345226  -0.083851     0.204832    -0.103202      0.00716424  -0.064556     0.149329    -0.239832   -0.00215229  -0.0334352   -0.06139      0.0100645   -0.333055      0.260103     0.130743    -0.0679131    0.0995779   -0.120604     0.0420355   -0.0407888   -0.0182315   0.299942    -0.083433   -0.149454     0.027735    -0.148035
  0.023979    -0.371107    -0.0222391    0.032885      0.0499858   -0.126183     0.0849991   -0.0306193  -0.0176252    0.0607684   -0.0820821   -0.0931953   -0.363828      0.191005     0.130524     0.0833844   -0.166018     0.033649    -0.0219368   -0.164239    -0.0669064   0.0663424    0.207375    0.110099    -0.0876974    0.0518948
 -0.0194916    0.333979     0.167701     0.0923326    -0.143307    -0.125875     0.0854967    0.446451   -0.181501    -0.0202469   -0.071562    -0.0914402    0.186824      0.208206     0.133946    -0.0669769    0.21313      0.0197228   -0.0285166   -0.11401     -0.134785    0.0726614    0.455634    0.0465011   -0.0820342    0.0524414
  0.283382    -0.0935403    0.0250688    0.145541     -0.0291031   -0.0396672   -0.0835845   -0.16093     0.0166237   -0.215883     0.105495     0.0744914   -0.0552816    -0.0627975   -0.149186     0.0127064   -0.126822    -0.00747567   0.105665    -0.597642     0.0966765  -0.0925628   -0.463597   -0.124127     0.0215275    0.0450526
 -0.0268765   -0.153548    -0.00508631   0.1169        0.0332929    0.00805104   0.0585773    0.0444356  -0.0358366   -0.154319    -0.104517     0.0724072   -0.00261459   -0.074959    -0.137279     0.0677562   -0.0516263   -0.0551282    0.0343014    0.345755     0.0722521   0.287775     0.169646    0.0957115    0.0259046    0.00204472
  0.0395894   -0.165523    -0.0307143    0.079787     -0.0113308    0.0149295    0.0681463    0.153803   -0.0346537    0.0185304    0.0576819   -0.167089    -0.0773535    -0.0291106   -0.139443     0.0912282    0.0868652    0.0662752   -0.0711561    0.126391     0.0628871  -0.090604     0.0680449  -0.0233334   -0.119775    -0.0265739
  0.0321284    0.0995553    0.0657538    0.143362      0.0047598   -0.0144961   -0.0258669    0.0397298   0.0865959    0.0496788    0.0325207   -0.097511     0.0174113    -0.0107717    0.224123    -0.196813     0.0554336    0.152288    -0.00492937   0.0780145   -0.0146764   0.0323808    0.073231    0.041882     0.0441286   -0.159248
  0.129459    -0.270634    -0.0145092    0.0746136     0.0454553    0.0371628   -0.144185     0.0388666   0.0909551    0.00580536   0.0409527    0.168379    -0.0974911     0.0432829   -0.0702037    0.0572825    0.111881     0.113504     0.0110033    0.121948     0.0601203   0.00960791  -0.0505658   0.134105    -0.0761934    0.0887936
 -0.163721     0.159856     0.0775048   -0.000938528   0.0226006   -0.0174018    0.0577858    0.081581   -0.0631144    0.054897    -0.0140446   -0.0490716   -0.0879647    -0.0541954    0.0515883    0.0265541   -0.0865272   -0.104334    -0.0228768    0.0717314   -0.132951    0.0564069    0.128913   -0.0966922   -0.0592772   -0.115172
  0.0981204   -0.160684     0.0681538   -0.112047     -0.00978056  -0.0656287    0.0737173   -0.17342    -0.224188    -0.0481001   -0.200718     0.0229495    0.0245277    -0.1172      -0.132684    -0.00844461  -0.118113     0.175919    -0.0152205   -0.214875     0.0039079  -0.0227652    0.0680952  -0.0270718    0.0426031    0.0706821
 -0.0965349    0.0993104   -0.0113861    0.0421592     0.014632    -0.0629641    0.0231296   -0.0433627   0.063128     0.0408197    0.0461576   -0.0310694    0.0284557    -0.0477715    0.0880215   -0.0349992    0.0739774    0.00491323   0.0571043    0.0471099    0.138571   -0.0171795   -0.0672953  -0.0608003   -0.00574863   0.0232233
  0.145057     0.065014    -0.090078     0.154443     -0.364398     0.0323567   -0.0987285   -0.102007    0.00651297   0.0507973    0.225836     0.100692     0.0653292    -0.0224255    0.0639857    0.0526458    0.0412625   -0.0764014    0.0471011    0.0764564   -0.0913853  -0.157554     0.0674124  -0.0715256    0.0226419   -0.0928296
  0.0562769    0.0911881    0.0677197   -0.0366449     0.0139116    0.0236086    0.0944238    0.0187356  -0.125772     0.115868    -0.0615635    0.138625     0.13977       0.0537479    0.0786668   -0.175691    -0.118644    -0.0174942    0.0135621    0.0989369   -0.0484413   0.0054056    0.0374468  -0.0428702   -0.0293196   -0.0774076
  0.0449389    0.0420471    0.159335    -0.0788133    -0.0962235    0.0101867   -0.0908657   -0.129349    0.326726    -0.0460023   -0.0927431   -0.147186    -0.161048     -0.120579     0.0198905   -0.172416    -0.117259    -0.0666256    0.0194556    0.302111    -0.111684   -0.04507     -0.0769131  -0.205376    -0.190911    -0.0621324
 -0.0578461   -0.00594371   0.120623    -0.043323     -0.0105451   -0.12683     -0.0601779   -0.0301936   0.0921055   -0.012606     0.148587    -0.190544     0.266062     -0.0477029   -0.00169879  -0.0268165    0.128142     0.0881665    0.027202    -0.158682    -0.0358299  -0.148743     0.102259   -0.00486757   0.124066     0.0384181
 -0.24182      0.0723978   -0.0393314   -0.0673872    -0.055359     0.0129351    0.0567158    0.151987   -0.110438     0.0898286   -0.0842806   -0.0766545    0.000641468   0.173264    -0.15377      0.294457     0.173058    -0.0212507   -0.140034    -0.336042     0.063822    0.213765     0.146204    0.159826     0.162059    -0.228969
 -0.345011     0.0579781   -0.0826642   -0.0989671    -0.0556453    0.0115422    0.056898     0.153256   -0.0974692    0.0879482    0.0540849   -0.130099    -0.0100694     0.178251    -0.133442    -0.0855283    0.146243    -0.0620288    0.0861561   -0.168544     0.0425415   0.270218     0.145079    0.159608    -0.00232607   0.313372
  0.234286     0.132043    -0.0986202   -0.0472215    -0.0176467    0.0327542    0.175955     0.0494215  -0.171872     0.370205     0.0240199   -0.0386345    0.131127      0.125211    -0.255023    -0.181736    -0.108084    -0.0316321    0.0540312    0.215496    -0.0533922   0.285743     0.0266013   0.0333318   -0.0343692    0.0967358
  0.240543     0.11248      0.234117    -0.144567     -0.0987671   -0.0873052    0.0316083    0.0508447   0.343557    -0.0515817    0.0544416   -0.274486    -0.101818      0.20097     -0.175724     0.0404033   -0.0971315   -0.0316734    0.0265445    0.052907    -0.056758   -0.158746    -0.0551253  -0.109726     0.00473414  -0.162262
 -0.0122905    0.0248048   -0.00255087  -0.0534359     0.17483     -0.177671     0.00971395   0.0214199  -0.0202156    0.0950309    0.0132345   -0.0482346   -0.0689217     0.0365664   -0.0452533   -0.0514071   -0.0183822    0.0441686    0.0690167    0.0273906    0.150053   -0.118143    -0.0291931  -0.0626939    0.00106206   0.180841
 -0.114377    -0.0568651   -0.0884988    0.0842191    -0.0619017   -0.0593539   -0.107873     0.194282   -0.0649161    0.0242245   -0.0064429    0.117937     0.0694689     0.0391951    0.066477    -0.273835     0.10501      0.0108924   -0.0860179    0.0578973   -0.126474   -0.0779002   -0.184516   -0.00940418  -0.181045    -0.0456424
  0.0192372    0.00585445  -0.0690426    0.00470612    0.0697229   -0.0610137    0.0787479    0.024741    0.0784849    0.0400325   -0.00436296  -0.0141004   -0.0466033     0.13415     -0.0830896    0.130615     0.129519    -0.104845     0.0624182    0.0637169    0.102343    0.139923    -0.0414792   0.13985     -0.168495     0.0702535
  0.0509538    0.0585938   -0.0105117   -0.0579584     0.0178332    0.0228173    0.0671215   -0.0466203   0.0230656    0.0192358    0.0508402   -0.0744223   -0.144199      0.00202653  -0.0197935   -0.0131917    0.0329054    0.0472163    0.0247865   -0.161593    -0.0197748   0.0158632    0.0363029   0.0518618    0.00422539  -0.0796414
 -0.0406105    0.0689859   -0.157642    -0.138993      0.258668     0.0569875    0.200811     0.172393    0.0473494   -0.0605249   -0.0807938    0.0480358    0.0915783     0.136936    -0.0666484   -0.0728882    0.0534553   -0.0721438   -0.192801     0.0129824    0.0867003  -0.196904    -0.092646    0.00445984  -0.0828718    0.143664
  0.0838239   -0.0250827   -0.0917685   -0.0410016    -0.112964    -0.00688923   0.118603     0.120118   -0.144199     0.0279445    0.107566     0.0233403   -0.00630026   -0.0171578    0.125573    -0.111934    -0.0361961   -0.0639383   -0.0689442   -4.61421e-6  -0.0368995  -0.0187706   -0.0451022  -0.042594     0.071482     0.0682441
 -0.10362     -0.159951     0.289416    -0.0203298    -0.0454528    0.0697611   -0.143008    -0.139715    0.0507927   -0.110189    -0.0122805    0.025659     0.12956       0.0555042   -0.0632339   -0.0921546    0.00550102  -0.0686261    0.0530064    0.181588     0.0874127   0.121647     0.0236191   0.13661      0.27354     -0.00137203
 -0.0128238    0.0840435    0.00339688  -0.0522998     0.105135    -0.0435097    0.30505      0.0311029  -0.100281    -0.052401     0.0510134   -0.0546196   -0.0975001    -0.181859    -0.0347262    0.0268813    0.0761594   -0.116887     0.122304     0.00811987   0.0812837  -0.170314    -0.065629   -0.0647762   -0.0654007   -0.0825719
  0.0255261    0.049048    -0.0422954   -0.144176      0.0148208    0.0365197   -0.195748     0.0194311  -0.147682    -0.145981     0.0261803    0.208394     0.012667      0.204943     0.00835753   0.0152405   -0.144036     0.109347     0.0488554   -0.013532     0.0311693   0.119488     0.0121935  -0.00622475   0.00885809  -0.0118238
  0.0165814   -0.0296034   -0.0714605    0.0721241     0.120768    -0.0923406   -0.00581661   0.116846   -0.220531     0.0847315    0.053432    -0.00304452  -0.102027      0.0373885   -0.297315     0.0357309    0.0204961   -0.00376429  -0.126291    -0.142        0.0102663  -0.102754    -0.0660754  -0.117764     0.14459      0.0768077
 -0.028957     0.0593006    0.0488172   -0.0574042     0.0277367   -0.108662    -0.0780417    0.050941   -0.0378411   -0.0303588    0.125469    -0.0386934    0.125413     -0.0310858   -0.153034     0.0485163   -0.091615     0.16818     -0.188248    -0.020515    -0.0548474  -0.0381766   -0.0514449   0.0280732    0.00253897   0.113076
 -0.041101     0.0575305    0.0401701   -0.0192277     0.00986552   0.041274    -0.0946924   -0.0755926  -0.130222    -0.0113682    0.0602679    0.0644133    0.0187227     0.00137502   0.0849442    0.215192     0.0591546   -0.0934773    0.00762216  -0.199272     0.0492558   0.0365517   -0.131631   -0.110545     0.0812363   -0.0664658[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.059320
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.041096
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.055107
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.038961
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.059282
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.041309
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     20
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.051787
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.043103
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.056783
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.038558
┌ Info: EM with 100000 data points 10 iterations avll -1.038558
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind diag, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.328045e+05
      1       7.240182e+05      -2.087863e+05 |       32
      2       6.900289e+05      -3.398928e+04 |       32
      3       6.737186e+05      -1.631031e+04 |       32
      4       6.639469e+05      -9.771740e+03 |       32
      5       6.586094e+05      -5.337492e+03 |       32
      6       6.555212e+05      -3.088114e+03 |       32
      7       6.526224e+05      -2.898871e+03 |       32
      8       6.479848e+05      -4.637624e+03 |       32
      9       6.438934e+05      -4.091359e+03 |       32
     10       6.420399e+05      -1.853458e+03 |       32
     11       6.411140e+05      -9.258881e+02 |       32
     12       6.405754e+05      -5.386840e+02 |       32
     13       6.402557e+05      -3.196483e+02 |       32
     14       6.400871e+05      -1.686523e+02 |       32
     15       6.399972e+05      -8.987741e+01 |       32
     16       6.399448e+05      -5.235378e+01 |       32
     17       6.399044e+05      -4.044984e+01 |       31
     18       6.398770e+05      -2.736881e+01 |       31
     19       6.398529e+05      -2.409573e+01 |       30
     20       6.398339e+05      -1.897533e+01 |       30
     21       6.398138e+05      -2.012712e+01 |       28
     22       6.397986e+05      -1.522302e+01 |       32
     23       6.397875e+05      -1.110197e+01 |       28
     24       6.397789e+05      -8.543854e+00 |       28
     25       6.397723e+05      -6.631086e+00 |       26
     26       6.397673e+05      -5.033969e+00 |       23
     27       6.397636e+05      -3.643568e+00 |       25
     28       6.397605e+05      -3.153536e+00 |       23
     29       6.397578e+05      -2.635792e+00 |       19
     30       6.397555e+05      -2.389933e+00 |       20
     31       6.397533e+05      -2.155935e+00 |       19
     32       6.397514e+05      -1.876293e+00 |       21
     33       6.397495e+05      -1.879247e+00 |       25
     34       6.397471e+05      -2.465412e+00 |       23
     35       6.397451e+05      -1.975539e+00 |       18
     36       6.397434e+05      -1.680776e+00 |       20
     37       6.397415e+05      -1.879427e+00 |       19
     38       6.397401e+05      -1.399934e+00 |       16
     39       6.397392e+05      -9.230533e-01 |       16
     40       6.397386e+05      -6.199286e-01 |       18
     41       6.397377e+05      -8.763595e-01 |       13
     42       6.397371e+05      -6.220552e-01 |       14
     43       6.397362e+05      -9.283623e-01 |       12
     44       6.397354e+05      -7.635600e-01 |        9
     45       6.397349e+05      -5.090526e-01 |        8
     46       6.397344e+05      -4.872615e-01 |       13
     47       6.397336e+05      -8.011450e-01 |       16
     48       6.397329e+05      -6.721638e-01 |       13
     49       6.397325e+05      -4.749032e-01 |       11
     50       6.397321e+05      -3.879414e-01 |       14
K-means terminated without convergence after 50 iterations (objv = 639732.0779817733)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.335530
[ Info: iteration 2, average log likelihood -1.289310
[ Info: iteration 3, average log likelihood -1.247599
[ Info: iteration 4, average log likelihood -1.212306
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.163251
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.131336
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.125307
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.097641
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.094088
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     13
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.074822
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     10
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.095409
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.101754
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.086673
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      9
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.093899
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.106965
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.066609
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.099555
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│     21
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.090396
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.118030
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.082563
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     10
│     14
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.064039
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.107290
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.100837
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.068179
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.102710
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.117950
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.094215
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     19
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.060631
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.113163
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.078924
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      7
│     16
│     19
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.081580
[ Info: iteration 32, average log likelihood -1.129038
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.073735
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     15
│     20
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.064531
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.103401
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.096815
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.075125
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      9
│     13
│     14
│      ⋮
│     21
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.038273
[ Info: iteration 39, average log likelihood -1.156589
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.089063
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│      7
│      9
│     19
│     20
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.052294
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.141364
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.096910
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     16
│     19
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.055699
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│     15
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.085688
[ Info: iteration 46, average log likelihood -1.125129
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.068655
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     14
│     19
│     20
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.052562
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.127702
[ Info: iteration 50, average log likelihood -1.111568
┌ Info: EM with 100000 data points 50 iterations avll -1.111568
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0446391     0.00372331   0.0374639    0.10446     -0.0227444    0.0051537    0.0365794     0.0703837   0.0484095    0.07259      0.00634303  -0.134345    -0.0945499   -0.0167322    0.0378265   -0.00317552   0.0144211    0.0878802   -0.0392366     0.0530461    0.0600707   -0.0753114    0.0864153   0.0295888   -0.0448648   -0.136675
  0.0127337    -0.0291998   -0.0784968    0.0716072    0.119335    -0.0919846   -0.00656748    0.116864   -0.220908     0.0860062    0.0527136   -0.00197717  -0.102525     0.0394299   -0.296354     0.0403942    0.0224607   -0.00573013  -0.12806      -0.140702     0.0123884   -0.102303    -0.0651618  -0.117381     0.143928     0.0769417
  0.0744371     0.0409068    0.00476729  -0.0609486    0.114037     0.074827     0.24463      -0.0254474  -0.0933355   -0.0720719   -0.0575583   -0.182075    -0.222185    -0.0622502   -0.169694    -0.0575597    0.134262     0.058722     0.0323315    -0.132391    -0.215969     0.0523907   -0.209313   -0.192295    -0.09862     -0.153097
 -0.0391097     0.115082    -0.0210971    0.0428901    0.00655533  -0.0805402   -0.000368992  -0.0704367  -0.00319547   0.0276077    0.120587    -0.177334    -0.0327895    0.142243     0.012271    -0.0336492    0.131733     0.0159308    0.139864      0.0127495    0.150332    -0.113086    -0.162559   -0.182662    -0.00224591   0.022669
  0.0587597     0.0929518    0.119605    -0.040702     0.0349632   -0.0919778    0.095751      0.286309   -0.104676    -0.769481    -0.234613     0.678025     0.0841488    0.123541     0.18211     -0.216522    -0.1751       1.0447      -0.0525422     0.136505     0.105826     0.0121943    0.0403639   0.00471221   0.0193893   -0.0681111
  0.0766869    -0.257288    -0.0225172    0.0599622    0.0701239    0.0772964   -0.142309      0.0662707   0.0917639   -0.0102121    0.00983187   0.191805    -0.118043     0.0483316   -0.102358     0.0593128    0.115285     0.0914399   -0.0222417     0.0998458    0.0626903    0.0127939   -0.0588232   0.139734    -0.0746385    0.0829234
  0.016186     -0.0312447    0.0713528    0.0782887   -0.0333947   -0.112291     0.0758947     0.180975   -0.0799633    0.0178633   -0.0613186   -0.0552671   -0.0733438    0.182583     0.116221     0.00309658   0.0374719    0.0261172   -0.0285326    -0.0877861   -0.0781894    0.0616286    0.270274    0.0854363   -0.0736878    0.0553316
 -0.0547928    -0.0263064    0.130741    -0.0454818    0.0395406    0.00835025   0.101597     -0.0522935  -0.0376133   -0.0800063    0.0229585   -0.0193702    0.00868953  -0.0802994   -0.0463118   -0.0274638    0.0412898   -0.0944139    0.0944859     0.0937744    0.0833427   -0.0399119   -0.0288561   0.0267001    0.0861244   -0.0496056
 -0.156844      0.155126     0.0670268   -0.0144766    0.0349679   -0.0105023    0.0564609     0.0845221  -0.0532983    0.0402163   -0.0114292   -0.0285748   -0.0573205   -0.0320004    0.0290295    0.029988    -0.0871396   -0.0869376   -0.0174364     0.0678232   -0.109859     0.0579552    0.127555   -0.0621593   -0.0583225   -0.0992168
 -0.0463088     0.0529404   -0.0947493   -0.129503     0.305641     0.0875456    0.042849      0.0324726   0.0653473   -0.0374363   -0.104572     0.103899     0.148223     0.121354    -0.01524      0.141658     0.0887393   -0.145189    -0.0167629    -0.0356943    0.079204    -0.403176    -0.0934729  -0.0446233   -0.0660617    0.0329264
  0.0869594     0.176344    -0.0122262   -0.0285126    0.0520755   -0.0811466    0.0782015    -0.0751125  -0.0983744   -0.0616696   -0.0404817   -0.069627    -0.263945    -0.0548384    0.0115063   -0.0822369    0.145875     0.0712862   -0.033885     -0.101436     0.046944     0.0470013   -0.0405816  -0.140645     0.107165    -0.141008
  0.116912      0.0550612    0.0457601   -0.147421    -0.0942026    0.00372236  -0.0189327     0.0423082   0.1313       0.0135384    0.121932     0.00455035  -0.0489543   -0.0161671    0.0621281   -0.0735456    0.00552414  -0.0309394    0.0739951    -0.190316     0.0289759    0.0190502    0.189378    0.108736     0.0709973   -0.0296177
  0.000632685   0.0973359    0.0038112   -0.0904713   -0.057262    -0.00504792   0.0838123     0.0961325  -0.0125328    0.12704      0.0132507   -0.126292     0.00623139   0.168857    -0.18543      0.0065191    0.0175453   -0.03902      0.0152366    -0.0507638   -0.00605966   0.148769     0.0588224   0.052081     0.0299082    0.00841971
 -0.0691411     0.0576291    0.05477     -0.0232349    0.0226073    0.0662216   -0.089724     -0.0694009  -0.173505    -0.0148339    0.0588126    0.0559381    0.0168424   -0.00648089   0.0754419    0.215169     0.0575636   -0.122312     0.00432767   -0.235395     0.051262     0.0783264   -0.146973   -0.10488      0.108695    -0.0839396
  0.00258271    0.0554603    0.033625    -0.00496291  -0.0642021   -0.0171975   -0.1158       -0.071558   -0.0919425   -0.0279833    0.0838266    0.0612773    0.0766982    0.0271393    0.0775435    0.207872     0.0875553   -0.0398758    0.011658     -0.2135       0.0368178    0.080188    -0.121171   -0.0964249    0.0804145   -0.044679
 -0.0663224     0.11272     -0.169363    -0.158891     0.380425     0.0582904    0.257777      0.157625    0.059107    -0.0633411   -0.087629     0.0293688    0.134645     0.148785    -0.086677    -0.0841674    0.071201    -0.0908016   -0.204969      0.00445854   0.0829951   -0.269314    -0.0885084  -0.00219239  -0.0920259    0.187279
  0.145205      0.0639991   -0.0915309    0.157135    -0.366118     0.0314011   -0.110407     -0.0995862   0.00685826   0.0530832    0.229423     0.10193      0.0663631   -0.0204036    0.0656144    0.051268     0.0432933   -0.0767959    0.0491043     0.0778561   -0.092665    -0.159277     0.0682603  -0.0692011    0.0269542   -0.0936575
  0.080949     -0.0226541   -0.096604    -0.0461794   -0.0994872   -0.00186413   0.124724      0.124498   -0.131123     0.0227574    0.0963932    0.0251021   -0.00607062  -0.00990024   0.112248    -0.114073    -0.0364415   -0.0687674   -0.0839948     0.00556629  -0.0269352   -0.0265663   -0.0481364  -0.041702     0.0639695    0.0743203
 -0.00480044   -0.177133    -0.0522334    0.103122     0.0139534   -0.00213873   0.0312524     0.182126   -0.056544    -0.0381828    0.100898    -0.146325     0.0379602   -0.0236402   -0.0518233   -0.0259122    0.17294      0.114225    -0.0554277     0.183583    -0.00324071   0.0153763    0.0466639  -0.0412331   -0.0794783    0.0344873
  0.0469717     0.0278042    0.135999    -0.0713538   -0.0781183    0.0251218   -0.0864642    -0.0969186   0.317496    -0.0491497   -0.070544    -0.100599    -0.169242    -0.0899964    0.00994716  -0.144118    -0.103766    -0.0735993    0.0129793     0.276343    -0.0771817   -0.0472178   -0.0711969  -0.179456    -0.1831      -0.0451384
  0.124252     -0.204547     0.0674514   -0.118534    -0.0356301   -0.0797124    0.0742389    -0.187038   -0.247964    -0.0478152   -0.210592     0.0279163    0.0342498   -0.120076    -0.141747    -0.00573241  -0.119145     0.202736    -0.0128017    -0.226432     0.00389523  -0.0337377    0.066592   -0.023093     0.0624022    0.0844176
 -0.0679629    -0.0140278   -0.0451591    0.012306     0.0587151   -0.123744    -0.0502103     0.111784   -0.0506457    0.0596116    0.00211295   0.0307039    0.00109055   0.0383638    0.0169105   -0.163609     0.0427353    0.0271064   -0.00893179    0.044004     0.0148648   -0.0977091   -0.10258    -0.036961    -0.0874384    0.0722534
 -0.0340058     0.0683594    0.0374754   -0.0604658    0.032683    -0.110601    -0.0740202     0.0546621  -0.0331115   -0.0392564    0.123823    -0.028121     0.133396    -0.0305307   -0.142443     0.010916    -0.0718988    0.15941     -0.180713     -0.0309222   -0.0569954   -0.0258042   -0.0566836   0.0239125    0.020529     0.123686
 -0.054592     -0.00209734   0.11867     -0.0485817   -0.0140435   -0.121595    -0.0649853    -0.0348542   0.0924445   -0.0108013    0.129474    -0.191218     0.247814    -0.0501958   -0.00179237  -0.0381422    0.121088     0.102649     0.0236108    -0.137678    -0.0411495   -0.145984     0.0926978  -0.00384803   0.116895     0.0348745
  0.0403497     0.017338    -0.0561146    0.00162994   0.0545577   -0.101554     0.0798611     0.0747114   0.0974609   -0.00453117  -0.0179479   -0.0103564   -0.0159869    0.114716    -0.0992595    0.110197     0.17016     -0.168204     0.0739009     0.105509     0.107719     0.150062    -0.0482881   0.10878     -0.193297     0.0849509
  0.134767     -0.39698      0.0471574    0.028685     0.0935444    0.142656    -0.338161     -0.0205222  -0.0453428   -0.022817     0.0469245    0.112245    -0.0886413    0.0239241   -0.133779     0.0792836    0.0961931    0.151936     0.010668      0.0529897    0.0410524    0.0112155   -0.0705011   0.100526    -0.0825951    0.0701553
 -0.153566      0.0833977   -0.00192891   0.0401102    0.0185034   -0.0430548    0.0479672    -0.0204669   0.124901     0.0557069   -0.0313026    0.118258     0.0959459   -0.244747     0.15481     -0.0442228    0.0126674   -0.00818451  -0.0315867     0.0798303    0.129469     0.0804831    0.0210645   0.0532381   -0.0131275    0.0211462
  0.117179     -0.128987     0.00942959   0.129996     0.00237231  -0.0133724   -0.00387487   -0.0555783  -0.0133077   -0.189292    -0.00755687   0.0733053   -0.0180201   -0.0703224   -0.144568     0.0446109   -0.0886759   -0.0354794    0.0669944    -0.0813016    0.0815629    0.119887    -0.12248    -0.00277933   0.0235495    0.022884
  0.055814      0.0905255    0.0558287   -0.0344263    0.00750215   0.0498354    0.0936303    -0.0474981  -0.130701     0.333497    -0.018723     0.009408     0.149477     0.0381047    0.0563439   -0.165303    -0.103684    -0.279601     0.032396      0.0871685   -0.0855346    0.00316313   0.0360158  -0.0533466   -0.041434    -0.0799703
 -0.0690611    -0.0449559   -0.0906904    0.031983     0.0839933    0.0650422    0.0599706    -0.163928    0.044015     0.161935     0.070621    -0.0939069   -0.128639     0.13396     -0.0522486    0.162767    -0.0591238    0.120969    -0.000868736  -0.141245     0.0236909    0.00387977   0.0132001   0.247302    -0.0989449   -0.0241227
  0.0241118    -0.0934488    0.00782967  -0.0995402    0.0227244   -0.0774316   -0.0499311    -0.108024   -0.0336849   -0.00953528  -0.0507028   -0.0402131   -0.0723445    0.0623801    0.132923    -0.0596471    0.100588    -0.135721     0.0252081    -0.0666701    0.00832677   0.0385663   -0.120427   -0.159108     0.00403319  -0.124507
  0.0137133     0.0500184   -0.0376549   -0.146659     0.0162826    0.0361601   -0.192677      0.0225099  -0.147022    -0.142145     0.0290388    0.212605     0.0175489    0.208419     0.00458567   0.0249955   -0.137404     0.107883     0.0520632    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.00893293   0.0269253    0.126536     0.0149374  -0.00451137   0.00981684  -0.0161212┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.057179
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      7
│      9
│     14
│      ⋮
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.025556
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.050812
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      7
│      9
│     14
│      ⋮
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.027191
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.049153
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      6
│      7
│      9
│     14
│      ⋮
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.015716
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.042579
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      7
│      9
│     14
│      ⋮
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.018780
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     16
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.038641
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      7
│      9
│     14
│      ⋮
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.025507
┌ Info: EM with 100000 data points 10 iterations avll -1.025507
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0631444   -0.030886    -0.0945239   -4.81676e-5   0.161895     0.00565792   0.143584     0.0795224   0.0222399   -0.0318659    -0.214542    -0.0889352   -0.0385367   -0.165499     0.0938995    0.105046     0.0377232     0.11054     -0.110878     0.0603598     0.0717294    0.0950301    0.0693334    0.0595469   -0.0342078    0.073983
  0.024475    -0.0452568    0.0783891   -0.0975526    0.0140616    0.15064     -0.0468458   -0.0350453   0.054293     0.0372441     0.0780351    0.062941     0.247272     0.0154894   -0.0617706    0.0140156   -0.01751      -0.128175     0.0194537   -0.0119104    -0.0508813   -0.034334    -0.0588923   -0.0422143    0.0825554   -0.23403
 -0.128584     0.076708    -0.0259296   -0.143948     0.0195648    0.1077       0.0382574   -0.0290459  -0.0319862    0.0199663     0.0143664    0.0827203   -0.0414667   -0.0999016   -0.05985      0.076391    -0.0177451    -0.145446    -0.0111144   -0.116098     -0.0332901   -0.0123435   -0.0350504    0.0531986    0.0354805   -0.19382
  0.0178964    0.0730561    0.00272822  -0.0739962    0.0124819   -0.0455788   -0.102652     0.0239122   0.0401302   -0.0846241     0.113488    -0.0167961    0.0711574    0.0413814   -0.0199361    0.0686324   -0.000983371  -0.1475       0.0295079   -0.101892     -0.0600837   -0.112551    -0.284728     0.112507     0.233808    -0.00208555
 -0.0210799   -0.0650307    0.145398    -0.310238     0.210906     0.0631081    0.081475    -0.126684    0.0861535   -0.14161      -0.0110812   -0.0596657    0.0470125    0.0481968   -0.123837     0.0564268   -0.0844084     0.0992056   -0.075319    -0.123998     -0.168248    -0.00194903   0.00188562   0.0588482    0.0365257   -0.0242608
 -0.104869    -0.153277     0.147334     0.0711844   -0.165044     0.0604472   -0.035596    -0.0916744  -0.105491    -0.020792      0.104399    -0.0902088    0.27822      0.133949    -0.10355      0.108783    -0.0807971    -0.095589    -0.00505264  -0.012064      0.050871    -0.134892     0.069595     0.0742774   -0.0532544    0.0159704
 -0.170316    -0.147088    -0.129896     0.00487174   0.0362497    0.110141     0.0310018    0.130442    0.0951646    0.147505     -0.0321912    0.00279743  -0.0932525   -0.00641947   0.0852829    0.182108    -0.181012      0.122407    -0.0985391   -0.0146057    -0.0599151   -0.0962269    0.0117452    0.0678475    0.148758     0.0232195
  0.153285     0.0454064    0.0849179    0.0654093   -0.169905     0.0105117    0.13231      0.0618955  -0.0106573    0.0648588    -0.197594     0.0326752    0.0460538   -0.0251236    0.0350569   -0.00372578  -0.0552821    -0.0568581    0.0643948    0.0252234     0.00183074   0.100829     0.136071     0.0474542   -0.145488     0.0102028
 -0.0764436    0.0445537   -0.0512676   -0.0962221   -0.00943055  -0.00121417   0.0701346   -0.0339853   0.0339232    0.0364414    -0.0421785    0.0221733   -0.0272071    0.0514827   -0.035138    -0.108831     0.201104      0.112523    -0.0343393    0.00515528   -0.0121328   -0.181209     0.055386    -0.00526684   0.00695344   0.0219433
  0.0751269    0.0611954    0.104583    -0.210075     0.193448    -0.037633    -0.082941    -0.0272971  -0.119655     0.0597281    -0.0129669   -0.130655     0.00991281  -0.00900902   0.00378467  -0.115248     0.0222464    -0.0416628   -0.0993674   -0.00329033   -0.0583733    0.109979     0.0638147    0.0655206    0.0350518   -0.0974454
  0.0900072    0.14144     -0.160143     0.0679107   -0.0204658    0.0836693    0.0277619   -0.0590615   0.197405     0.0473939     0.0811105   -0.0770896    0.0334224    0.0243016   -0.0713831   -0.026404    -0.0774235     0.0586066   -0.0540797    0.0492421     0.266447    -0.0284972   -0.0428043    0.0516833   -0.153096     0.0381624
 -0.0543603   -0.0880131   -0.171416    -0.133499     0.128404    -0.0172204    0.0235908    0.0677822  -0.0150879   -0.0474511    -0.0457433    0.0300857   -0.208369     0.0168006   -0.0776372    0.00482012   0.0897565     0.0541323   -0.011552     0.0778591    -0.085662    -0.00240748  -0.140834     0.134794    -0.149581    -0.124501
 -0.115889    -0.0366659    0.136408    -0.17119     -0.0554828    0.10477      0.0899828    0.154219   -0.127645     0.123272     -0.119616     0.0304036    0.201315     0.0855196    0.0480179    0.0277273    0.0400438     0.0749673    0.134051    -0.0161727    -0.157005     0.0462923    0.0214916    0.0285776   -0.158157    -0.0310889
  0.0544078    0.0726118   -0.0751554    0.0202534    0.0847369   -0.0165768    0.00352955  -0.0309434  -0.0704533   -0.0909413     0.00561083  -0.0179161   -0.0461961   -0.0598215    0.0133285   -0.0650679   -0.111954      0.249405     0.077389     0.102554      0.00308744  -0.033164     0.196631     0.129228     0.0330628   -0.0208389
 -0.0565661   -0.0257723    0.041908    -0.0294189   -0.153394     0.0926307   -0.249706     0.0338237  -0.0620427   -0.0766081    -0.143257     0.0788451   -0.0737354    0.0165566    0.0578977    0.159863     0.202127      0.0783248    0.0631699    0.00355591    0.0818581   -0.0646944    0.0497154   -0.045424     0.0640428   -0.219725
 -0.00505508  -0.0509607   -0.21373      0.0332583    0.0373077   -0.123036     0.11675     -0.084404   -0.0127715   -0.0256038     0.057553    -0.00624633  -0.137827     0.0747233    0.138944    -0.23531     -0.0787467     0.0535032   -0.113997     0.00456466   -0.0101734    0.108414     0.102872     0.0809852    0.129553     0.0697512
  0.125903     0.0906847    0.088714     0.0422198    0.008516    -0.0522229   -0.168266    -0.0132711   0.182297    -0.000260527   0.201704     0.331588     0.13647      0.178552    -0.0257096    0.0154739    0.0876484     0.0228155   -0.183829    -0.105747     -0.041235     0.033545    -0.0432382   -0.0247983   -0.0327187   -0.0969216
 -0.148884    -0.0264354    0.0807923   -0.0445908    0.0673304   -0.0677439   -0.151186     0.128029    0.205375     0.00567314   -0.107992    -0.0700105   -0.0543325   -0.132983    -0.186639     0.0208319    0.140055     -0.00238697  -0.129303    -0.00470886   -0.120107    -0.028573     0.10848      0.0366199    0.0829707    0.101772
  0.0931447   -0.0235616   -0.106588    -0.04772      0.140156    -0.0063243   -0.117018    -0.170529    0.00113123   0.039723     -0.12141      0.156699    -0.0305887   -0.0727262   -0.0824867   -0.0177817    0.148455     -0.0911912   -0.0198269    0.0133488    -0.0156821    0.0574165   -0.131187    -0.0479731    0.061875     0.0986035
  0.00755482  -0.00625237   0.0139075   -0.0225905   -0.135017    -0.169296    -0.149299    -0.0262068  -0.0828888    0.0791269    -0.0951244   -0.0764903    0.00819186  -0.0119339   -0.13428     -0.11267      0.0516414     0.0034292   -0.143828    -0.0715756    -0.11758     -0.0929394   -0.084771     0.146167    -0.102264     0.184858
 -0.0915963   -0.142719     0.215324     0.0751425   -0.0751525    0.0117407   -0.155207    -0.147808    0.0720331   -0.0325346     0.00545343   0.0597665    0.0237588    0.035977    -0.00189657  -0.0207978   -0.0500815    -0.00978031   0.0310119    0.000470629  -0.0151997   -0.0432048    0.0188053   -0.116541    -0.0387488    0.084368
  0.0638251    0.0469612   -0.0642096   -0.166253    -0.202254    -0.0271876    0.0758157    0.14391     0.105579    -0.0827267     0.076795     0.126172    -0.126317    -0.140792    -0.00231245  -0.0640741   -0.0637661     0.0286057    0.0286486    0.0223818    -0.0998478    0.171882    -0.0413655    0.132249    -0.172341     0.239388
  0.135892    -0.162971     0.0847599   -0.138533     0.05301     -0.070878    -0.095008    -0.0564863   0.0206925    0.143838     -0.0222359   -0.079708    -0.0306675   -0.0540745    0.279779    -0.0553712   -0.0524386     0.0315704   -0.0216711   -0.00815929   -0.124957    -0.033167    -0.104751    -0.0651897    0.00706081   0.0408345
  0.0661776   -0.0761073   -0.0646112    0.14823     -0.045595    -0.0539905    0.0747686    0.0414633   0.136337     0.0645191    -0.228071     0.0813297    0.0556124   -0.138026    -0.0452665   -0.0207084    0.139362     -0.037951    -0.00349309   0.0360628    -0.0604268   -0.0502034    0.0136539    0.0212063   -0.0290319   -0.0669039
  0.111083     0.0277298    0.126286     0.033731    -0.0233991    0.0195157   -0.186567    -0.164834    0.0188482    0.0454176    -0.0166001    0.183571     0.105161     0.0664578    0.0490807   -0.00497964   0.0691243    -0.0178824   -0.0711181    0.115037      0.0588766   -0.049745    -0.00540134   0.112507     0.0482329   -0.0446461
 -0.0106846   -0.0814134   -0.117513     0.0586699    0.0754015   -0.086379     0.108655     0.0292196   0.0420686   -0.0128271     0.0459913   -0.131771     0.180934    -0.0106416   -0.0306877   -0.0957243   -0.0366321    -0.00412845   0.0280025    0.171784      0.0428386   -0.0646278    0.0440559    0.0466894   -0.093145     0.107483
  0.0720436    0.0294814    0.036728     0.0908173    0.099619    -0.0695734   -0.0107769   -0.20269     0.0663833   -0.0572694     0.268007     0.145275     0.0460334   -0.207957    -0.0449319    0.059081     0.120424      0.0851088    0.115651     0.146254     -0.0656032    0.103328    -0.0613753   -0.042463     0.184712    -0.0135502
 -0.191489    -0.0611753   -0.0344395   -0.0802008   -0.0362095    0.00376818   0.0107465    0.0384945  -0.0760024    0.0073551    -0.0870075   -0.132705    -0.0214881    0.0761129   -0.0726535   -0.152906     0.151554      0.0539351   -0.00744344   0.0676503    -0.0742933   -0.163602     0.106425    -0.0576929    0.0472997   -0.0722503
  0.0769717   -0.0108256   -0.00637461  -0.153916    -0.00565078   0.296908    -0.0960565    0.0848951   0.0698911   -0.0479181     0.0468032    0.100084    -0.0721505    0.0316228   -0.147917    -0.163193     0.261613     -0.113973     0.0405758    0.0659248     0.0484827    0.18472      0.0260848    0.0284658    0.0492022   -0.0547923
 -0.0876936   -0.234791    -0.0516218   -0.0926518    0.00948798   0.107488    -0.0794846   -0.0421651   0.0799446    0.127328      0.0129324    0.144694     0.0388605    0.0196546    0.00111024  -0.010551     0.101707     -0.0190698   -0.0761829    0.0545973    -0.122971     0.00670262  -0.0164833   -0.0816956    0.126256    -0.117675
  0.00715191   0.149174    -0.119651     0.00857259   0.110704     0.06935     -0.0120158   -0.0164249  -0.130384    -0.00977608   -0.0373358    0.108808     0.0349064    0.00298647  -0.100988    -0.0590387   -0.146651     -0.121531    -0.140583     0.0122003     0.0648493    0.0218572    0.0904471   -0.0333009   -0.033938    -0.0759919
  0.150566    -0.0321585   -0.0290768   -0.0737319    0.0326862    0.0569446   -0.00922226  -0.0428986   0.22086     -0.151814     -0.00648157   0.108471    -0.143605     0.0245793   -0.0568675    0.0733448   -0.0955708    -0.00888495  -0.0235657    0.0420954    -0.141784    -0.0618455    0.0198926   -0.123451    -0.0851098   -0.163159kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.416459370232396
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416478
[ Info: iteration 2, average log likelihood -1.416396
[ Info: iteration 3, average log likelihood -1.416331
[ Info: iteration 4, average log likelihood -1.416254
[ Info: iteration 5, average log likelihood -1.416164
[ Info: iteration 6, average log likelihood -1.416064
[ Info: iteration 7, average log likelihood -1.415964
[ Info: iteration 8, average log likelihood -1.415873
[ Info: iteration 9, average log likelihood -1.415794
[ Info: iteration 10, average log likelihood -1.415719
[ Info: iteration 11, average log likelihood -1.415627
[ Info: iteration 12, average log likelihood -1.415474
[ Info: iteration 13, average log likelihood -1.415195
[ Info: iteration 14, average log likelihood -1.414694
[ Info: iteration 15, average log likelihood -1.413898
[ Info: iteration 16, average log likelihood -1.412893
[ Info: iteration 17, average log likelihood -1.411985
[ Info: iteration 18, average log likelihood -1.411407
[ Info: iteration 19, average log likelihood -1.411125
[ Info: iteration 20, average log likelihood -1.411006
[ Info: iteration 21, average log likelihood -1.410958
[ Info: iteration 22, average log likelihood -1.410939
[ Info: iteration 23, average log likelihood -1.410931
[ Info: iteration 24, average log likelihood -1.410928
[ Info: iteration 25, average log likelihood -1.410926
[ Info: iteration 26, average log likelihood -1.410926
[ Info: iteration 27, average log likelihood -1.410925
[ Info: iteration 28, average log likelihood -1.410925
[ Info: iteration 29, average log likelihood -1.410925
[ Info: iteration 30, average log likelihood -1.410925
[ Info: iteration 31, average log likelihood -1.410924
[ Info: iteration 32, average log likelihood -1.410924
[ Info: iteration 33, average log likelihood -1.410924
[ Info: iteration 34, average log likelihood -1.410924
[ Info: iteration 35, average log likelihood -1.410924
[ Info: iteration 36, average log likelihood -1.410924
[ Info: iteration 37, average log likelihood -1.410924
[ Info: iteration 38, average log likelihood -1.410924
[ Info: iteration 39, average log likelihood -1.410924
[ Info: iteration 40, average log likelihood -1.410923
[ Info: iteration 41, average log likelihood -1.410923
[ Info: iteration 42, average log likelihood -1.410923
[ Info: iteration 43, average log likelihood -1.410923
[ Info: iteration 44, average log likelihood -1.410923
[ Info: iteration 45, average log likelihood -1.410923
[ Info: iteration 46, average log likelihood -1.410923
[ Info: iteration 47, average log likelihood -1.410923
[ Info: iteration 48, average log likelihood -1.410923
[ Info: iteration 49, average log likelihood -1.410923
[ Info: iteration 50, average log likelihood -1.410923
┌ Info: EM with 100000 data points 50 iterations avll -1.410923
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4164775829890772
│     -1.4163964236630737
│      ⋮
└     -1.4109230908912882
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410941
[ Info: iteration 2, average log likelihood -1.410857
[ Info: iteration 3, average log likelihood -1.410788
[ Info: iteration 4, average log likelihood -1.410705
[ Info: iteration 5, average log likelihood -1.410605
[ Info: iteration 6, average log likelihood -1.410494
[ Info: iteration 7, average log likelihood -1.410385
[ Info: iteration 8, average log likelihood -1.410291
[ Info: iteration 9, average log likelihood -1.410217
[ Info: iteration 10, average log likelihood -1.410164
[ Info: iteration 11, average log likelihood -1.410125
[ Info: iteration 12, average log likelihood -1.410095
[ Info: iteration 13, average log likelihood -1.410072
[ Info: iteration 14, average log likelihood -1.410052
[ Info: iteration 15, average log likelihood -1.410034
[ Info: iteration 16, average log likelihood -1.410018
[ Info: iteration 17, average log likelihood -1.410005
[ Info: iteration 18, average log likelihood -1.409992
[ Info: iteration 19, average log likelihood -1.409981
[ Info: iteration 20, average log likelihood -1.409972
[ Info: iteration 21, average log likelihood -1.409963
[ Info: iteration 22, average log likelihood -1.409956
[ Info: iteration 23, average log likelihood -1.409950
[ Info: iteration 24, average log likelihood -1.409945
[ Info: iteration 25, average log likelihood -1.409941
[ Info: iteration 26, average log likelihood -1.409938
[ Info: iteration 27, average log likelihood -1.409935
[ Info: iteration 28, average log likelihood -1.409932
[ Info: iteration 29, average log likelihood -1.409930
[ Info: iteration 30, average log likelihood -1.409929
[ Info: iteration 31, average log likelihood -1.409927
[ Info: iteration 32, average log likelihood -1.409926
[ Info: iteration 33, average log likelihood -1.409925
[ Info: iteration 34, average log likelihood -1.409924
[ Info: iteration 35, average log likelihood -1.409923
[ Info: iteration 36, average log likelihood -1.409922
[ Info: iteration 37, average log likelihood -1.409922
[ Info: iteration 38, average log likelihood -1.409921
[ Info: iteration 39, average log likelihood -1.409920
[ Info: iteration 40, average log likelihood -1.409920
[ Info: iteration 41, average log likelihood -1.409919
[ Info: iteration 42, average log likelihood -1.409919
[ Info: iteration 43, average log likelihood -1.409918
[ Info: iteration 44, average log likelihood -1.409918
[ Info: iteration 45, average log likelihood -1.409918
[ Info: iteration 46, average log likelihood -1.409917
[ Info: iteration 47, average log likelihood -1.409917
[ Info: iteration 48, average log likelihood -1.409916
[ Info: iteration 49, average log likelihood -1.409916
[ Info: iteration 50, average log likelihood -1.409916
┌ Info: EM with 100000 data points 50 iterations avll -1.409916
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.410941077158847
│     -1.4108572241129183
│      ⋮
└     -1.4099155760731799
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409925
[ Info: iteration 2, average log likelihood -1.409861
[ Info: iteration 3, average log likelihood -1.409797
[ Info: iteration 4, average log likelihood -1.409716
[ Info: iteration 5, average log likelihood -1.409609
[ Info: iteration 6, average log likelihood -1.409473
[ Info: iteration 7, average log likelihood -1.409311
[ Info: iteration 8, average log likelihood -1.409136
[ Info: iteration 9, average log likelihood -1.408964
[ Info: iteration 10, average log likelihood -1.408810
[ Info: iteration 11, average log likelihood -1.408684
[ Info: iteration 12, average log likelihood -1.408587
[ Info: iteration 13, average log likelihood -1.408516
[ Info: iteration 14, average log likelihood -1.408468
[ Info: iteration 15, average log likelihood -1.408435
[ Info: iteration 16, average log likelihood -1.408412
[ Info: iteration 17, average log likelihood -1.408397
[ Info: iteration 18, average log likelihood -1.408386
[ Info: iteration 19, average log likelihood -1.408377
[ Info: iteration 20, average log likelihood -1.408371
[ Info: iteration 21, average log likelihood -1.408366
[ Info: iteration 22, average log likelihood -1.408362
[ Info: iteration 23, average log likelihood -1.408359
[ Info: iteration 24, average log likelihood -1.408356
[ Info: iteration 25, average log likelihood -1.408353
[ Info: iteration 26, average log likelihood -1.408351
[ Info: iteration 27, average log likelihood -1.408349
[ Info: iteration 28, average log likelihood -1.408347
[ Info: iteration 29, average log likelihood -1.408345
[ Info: iteration 30, average log likelihood -1.408343
[ Info: iteration 31, average log likelihood -1.408342
[ Info: iteration 32, average log likelihood -1.408340
[ Info: iteration 33, average log likelihood -1.408339
[ Info: iteration 34, average log likelihood -1.408338
[ Info: iteration 35, average log likelihood -1.408336
[ Info: iteration 36, average log likelihood -1.408335
[ Info: iteration 37, average log likelihood -1.408334
[ Info: iteration 38, average log likelihood -1.408333
[ Info: iteration 39, average log likelihood -1.408332
[ Info: iteration 40, average log likelihood -1.408331
[ Info: iteration 41, average log likelihood -1.408330
[ Info: iteration 42, average log likelihood -1.408329
[ Info: iteration 43, average log likelihood -1.408328
[ Info: iteration 44, average log likelihood -1.408328
[ Info: iteration 45, average log likelihood -1.408327
[ Info: iteration 46, average log likelihood -1.408326
[ Info: iteration 47, average log likelihood -1.408325
[ Info: iteration 48, average log likelihood -1.408324
[ Info: iteration 49, average log likelihood -1.408324
[ Info: iteration 50, average log likelihood -1.408323
┌ Info: EM with 100000 data points 50 iterations avll -1.408323
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4099248994132203
│     -1.409860986571456
│      ⋮
└     -1.4083227875969264
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408331
[ Info: iteration 2, average log likelihood -1.408274
[ Info: iteration 3, average log likelihood -1.408221
[ Info: iteration 4, average log likelihood -1.408157
[ Info: iteration 5, average log likelihood -1.408075
[ Info: iteration 6, average log likelihood -1.407972
[ Info: iteration 7, average log likelihood -1.407847
[ Info: iteration 8, average log likelihood -1.407707
[ Info: iteration 9, average log likelihood -1.407562
[ Info: iteration 10, average log likelihood -1.407420
[ Info: iteration 11, average log likelihood -1.407290
[ Info: iteration 12, average log likelihood -1.407175
[ Info: iteration 13, average log likelihood -1.407077
[ Info: iteration 14, average log likelihood -1.406993
[ Info: iteration 15, average log likelihood -1.406925
[ Info: iteration 16, average log likelihood -1.406868
[ Info: iteration 17, average log likelihood -1.406822
[ Info: iteration 18, average log likelihood -1.406785
[ Info: iteration 19, average log likelihood -1.406754
[ Info: iteration 20, average log likelihood -1.406728
[ Info: iteration 21, average log likelihood -1.406706
[ Info: iteration 22, average log likelihood -1.406687
[ Info: iteration 23, average log likelihood -1.406671
[ Info: iteration 24, average log likelihood -1.406656
[ Info: iteration 25, average log likelihood -1.406643
[ Info: iteration 26, average log likelihood -1.406631
[ Info: iteration 27, average log likelihood -1.406619
[ Info: iteration 28, average log likelihood -1.406609
[ Info: iteration 29, average log likelihood -1.406599
[ Info: iteration 30, average log likelihood -1.406589
[ Info: iteration 31, average log likelihood -1.406580
[ Info: iteration 32, average log likelihood -1.406572
[ Info: iteration 33, average log likelihood -1.406563
[ Info: iteration 34, average log likelihood -1.406555
[ Info: iteration 35, average log likelihood -1.406548
[ Info: iteration 36, average log likelihood -1.406540
[ Info: iteration 37, average log likelihood -1.406533
[ Info: iteration 38, average log likelihood -1.406525
[ Info: iteration 39, average log likelihood -1.406518
[ Info: iteration 40, average log likelihood -1.406511
[ Info: iteration 41, average log likelihood -1.406505
[ Info: iteration 42, average log likelihood -1.406498
[ Info: iteration 43, average log likelihood -1.406491
[ Info: iteration 44, average log likelihood -1.406485
[ Info: iteration 45, average log likelihood -1.406479
[ Info: iteration 46, average log likelihood -1.406472
[ Info: iteration 47, average log likelihood -1.406466
[ Info: iteration 48, average log likelihood -1.406460
[ Info: iteration 49, average log likelihood -1.406454
[ Info: iteration 50, average log likelihood -1.406448
┌ Info: EM with 100000 data points 50 iterations avll -1.406448
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.408330909498186
│     -1.4082743018987351
│      ⋮
└     -1.4064483817727802
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406451
[ Info: iteration 2, average log likelihood -1.406385
[ Info: iteration 3, average log likelihood -1.406321
[ Info: iteration 4, average log likelihood -1.406244
[ Info: iteration 5, average log likelihood -1.406146
[ Info: iteration 6, average log likelihood -1.406023
[ Info: iteration 7, average log likelihood -1.405879
[ Info: iteration 8, average log likelihood -1.405721
[ Info: iteration 9, average log likelihood -1.405560
[ Info: iteration 10, average log likelihood -1.405403
[ Info: iteration 11, average log likelihood -1.405258
[ Info: iteration 12, average log likelihood -1.405126
[ Info: iteration 13, average log likelihood -1.405007
[ Info: iteration 14, average log likelihood -1.404902
[ Info: iteration 15, average log likelihood -1.404809
[ Info: iteration 16, average log likelihood -1.404726
[ Info: iteration 17, average log likelihood -1.404652
[ Info: iteration 18, average log likelihood -1.404587
[ Info: iteration 19, average log likelihood -1.404529
[ Info: iteration 20, average log likelihood -1.404477
[ Info: iteration 21, average log likelihood -1.404429
[ Info: iteration 22, average log likelihood -1.404386
[ Info: iteration 23, average log likelihood -1.404346
[ Info: iteration 24, average log likelihood -1.404309
[ Info: iteration 25, average log likelihood -1.404274
[ Info: iteration 26, average log likelihood -1.404241
[ Info: iteration 27, average log likelihood -1.404209
[ Info: iteration 28, average log likelihood -1.404179
[ Info: iteration 29, average log likelihood -1.404150
[ Info: iteration 30, average log likelihood -1.404121
[ Info: iteration 31, average log likelihood -1.404093
[ Info: iteration 32, average log likelihood -1.404066
[ Info: iteration 33, average log likelihood -1.404039
[ Info: iteration 34, average log likelihood -1.404012
[ Info: iteration 35, average log likelihood -1.403986
[ Info: iteration 36, average log likelihood -1.403959
[ Info: iteration 37, average log likelihood -1.403933
[ Info: iteration 38, average log likelihood -1.403907
[ Info: iteration 39, average log likelihood -1.403881
[ Info: iteration 40, average log likelihood -1.403857
[ Info: iteration 41, average log likelihood -1.403833
[ Info: iteration 42, average log likelihood -1.403811
[ Info: iteration 43, average log likelihood -1.403790
[ Info: iteration 44, average log likelihood -1.403770
[ Info: iteration 45, average log likelihood -1.403751
[ Info: iteration 46, average log likelihood -1.403733
[ Info: iteration 47, average log likelihood -1.403716
[ Info: iteration 48, average log likelihood -1.403700
[ Info: iteration 49, average log likelihood -1.403685
32×26 Array{Float64,2}:
 -0.0596831   0.0797754   -0.310878    0.173359    -0.241973    -0.254887     0.453448   -0.00633392   0.265299   -1.03071     [ Info: iteration 50, average log likelihood -1.403670
┌ Info: EM with 100000 data points 50 iterations avll -1.403670
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4064508785553869
│     -1.4063851138281203
│      ⋮
└     -1.4036703951679879
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.416459370232396
│     -1.4164775829890772
│     -1.4163964236630737
│     -1.4163308833873591
│      ⋮
│     -1.4037004163275135
│     -1.4036850777585508
└     -1.4036703951679879
-0.592645    -0.70698     -0.516533    0.292787    -0.722268   -0.0495882   0.0815963  -0.217551     -0.17672     0.22972    -0.235293   -0.431196    -0.573308    0.392151     0.449991     0.485252
 -0.638612    0.196897     0.279572   -0.550181    -0.0526936    0.0409451    0.565215    0.462275     0.348503   -0.291306    -0.0101413    0.417594    -0.438092    0.541551    -0.0705613   0.0432785   0.345317   -0.126402      0.507846   -0.126488   -0.025913    0.225432     0.201659    0.440323     0.535927    -0.077597
  0.0910909  -0.800645     0.333453    0.201251    -0.0885452   -0.344941     0.340015   -0.0618428   -0.516063   -0.376393     0.0114324    0.131545    -0.209482   -0.577758    -0.153133    0.70312     0.219994    0.448309      0.686817    0.0166199   0.878265    0.25959      0.0716156   0.448658    -0.0738824   -0.00906109
  0.125664    0.106973    -0.300564    0.0230996    0.373914    -0.287222    -0.0927232  -0.613061    -0.0852922  -0.236727    -0.25473     -0.159899     0.763101    0.570145    -0.095689    0.725948    0.160929    0.490069      0.488013    0.0545788   0.366154    0.180528    -0.138592    0.372686     0.12965     -0.420565
 -0.958183   -0.122103     0.584176    0.279232    -0.946445     0.82734     -0.455087    0.534001     0.170302   -0.386699     0.102502    -0.233103     0.281356    0.0103919    0.270451   -0.0553391  -0.19589     0.251106      0.256458   -0.14786    -0.427761    0.236462    -0.687405    0.642726    -0.847076     0.590079
  0.471184   -0.211639     0.298739    0.104979    -0.142059     0.762735    -0.296498    0.00968721   0.408032   -0.338865    -0.238759     0.556193    -0.256129   -0.784125    -0.193651   -0.135245   -0.0947983  -0.00355868   -0.227674    0.0803474   0.0631943   0.0553092   -0.583146    0.0693008   -0.288973     0.987565
  0.292845   -0.0198205   -0.052703   -0.275738    -0.756794     0.524898     0.380406   -0.252216     0.273459   -0.945797     0.799361    -0.908443    -0.502034   -0.768539     0.291312   -0.436974   -0.0968441  -0.759254      0.179264   -0.484024   -0.204688    0.696993     0.133886   -0.782305    -0.350773     0.512663
  0.515838    0.638533     0.600046    0.414271     0.132541     0.359235     0.250813    0.375394    -0.173375   -0.779342     0.352818    -0.475643    -0.597945   -0.335791    -0.0350385  -0.293436    1.18332    -0.000487367   0.578182    0.524875    0.254338    0.582162    -0.0324044   0.0458675   -0.344251    -0.623912
 -0.154854    0.160651    -0.887102   -0.0921621   -0.330437    -0.468411     0.1303      0.0250129    0.650833    0.831432    -0.098024     0.0928116    0.215923   -0.0930101    0.179912   -0.347574   -0.530268    0.141643     -0.631084   -0.0892361  -0.710133   -0.467836    -0.322661    0.148783     0.371146    -0.177363
 -0.159052   -0.553999     0.0505985  -0.0443695   -0.354859    -0.142367    -0.129915    0.143381    -0.348143    0.525938    -0.012329    -0.103385     0.135055    0.037398     0.0473986  -0.132548   -0.443465   -0.207961     -0.195608   -0.128471   -0.568012    0.0168705    0.185209    0.120918     0.0329177   -0.0956517
 -0.775639    0.148567     0.325805    0.0697921   -0.00140517   0.0108775   -0.155524    0.0953459    0.258684    0.104619     0.183597     0.372564    -0.790985   -0.286246     0.738157   -0.0221666   0.281684    0.365874     -0.151182    0.22606    -0.0972066  -0.149458     0.354097   -0.215626    -0.644077    -0.194931
 -0.0978759   0.0492853   -0.0624204  -0.351993     0.195263     0.300474    -0.323608    0.432082     0.194134    0.872743     0.537571     1.03469      0.808951    0.0352247    0.516172   -0.267647    0.0239516   0.0754487    -0.115065   -0.0331772  -0.113703    0.371875    -0.043446   -0.0658701   -0.326896    -0.412982
  0.207866    0.254469    -0.55752    -0.46972      0.82746     -0.638046     0.516511   -0.14102     -0.0362939   0.554705    -0.106073     0.212599     0.346354    0.51573     -0.25772     0.0245124   0.167069   -0.0806303    -0.144623    0.0964411   0.188162   -0.182614     0.491194   -0.287539     0.827274    -0.825551
  0.324924    0.0842478   -0.439393   -0.526556     1.06175      0.671082     0.183805    0.0437915    0.23816     0.112179    -0.714797     0.00709906   0.0251287   0.180998    -0.221209    0.224173    0.0671568   0.0318816    -0.0643374  -0.258029   -0.076155   -0.468574    -0.0515779  -0.229534    -0.0812825    0.269965
  0.391955    0.694892     0.348889   -0.461362     0.0809619   -0.375905    -0.236976   -0.30357     -0.0175103  -0.180873     0.310307     0.189432    -0.0791226   0.00429804  -0.261962   -0.659392   -0.0409501  -0.151241     -0.111917    0.40039     0.219047   -0.437728     0.14644    -0.758731     0.312769     0.195509
  0.693045    0.377949     0.159867    0.188024     0.236527    -0.0188062   -0.219593   -0.573007     0.114342    0.175128     0.829977    -0.0282518    0.406582   -0.648707     0.182069    0.563134    0.0520618   0.234029     -0.133861   -0.195788    0.324889   -0.355957    -0.0360442  -0.582721    -0.0850231   -0.159442
 -0.0130671  -0.0676041    0.126063    0.232239    -0.47551     -0.0432072   -0.0983426  -0.0367453    0.120247   -0.279371     0.166888    -0.348922    -0.185488   -0.445503    -0.0363452   0.0218011  -0.132959   -0.458157      0.0972193  -0.0397672  -0.215158   -0.0958987   -0.101326    0.191418     0.0345462    0.383322
 -0.219552   -0.0166387    0.258218    0.248188    -0.287117    -0.209834    -0.248871   -0.134547    -0.556564   -0.189598     0.0880595   -0.239895    -0.728437   -0.238473    -0.709672   -0.388895    0.149421    0.625238      0.205177    0.318416   -0.426242   -0.0739504    0.0202113   0.160823     0.114799    -0.184266
 -0.189479   -0.0845375   -0.108443   -0.274415    -0.320224     0.165203    -0.152488    0.351331    -0.0490675   0.220101    -0.0812678    0.260675    -0.268604   -0.0165807    0.189204   -0.328789   -0.114143   -0.0738402    -0.15031    -0.151995   -0.540809   -0.182853    -0.0232143  -0.208952    -0.149946    -0.00521956
  0.0404311  -0.196194     0.465453   -0.452137    -0.387224    -0.202828    -0.0338055   0.200406    -0.0814215   0.201388     0.384178     0.459226    -0.126423   -0.349989    -0.0555227  -0.128996   -0.225312    0.0453508     0.238398    0.129708   -0.113758   -0.0151714   -0.018025   -0.133371     0.106216    -0.198177
  0.0450994   0.142396    -0.0299763  -0.112736     0.136252     0.449628    -0.62353    -0.510878    -0.0967412   0.0347999    0.162326    -0.159155    -0.4674      0.0927608   -0.337153    0.0992246  -0.420754   -0.267466      0.405428   -0.475471   -0.556115   -0.00116264   0.434878    0.201102    -0.303243    -0.073319
 -0.0686663   0.00784761   0.135551   -0.0327185    0.33733      0.123703    -0.358411   -0.215692     0.015609   -0.502424    -0.010043    -0.165337    -0.0931249   0.58316     -0.34284    -0.0175765  -0.227839   -0.21382      -0.175304    0.0786522   0.877682    0.0108469    0.804679    0.105543    -0.227775     0.177101
  0.101283    0.172195    -0.0605019   0.0407754    0.159659     0.03341      0.0166745  -0.144069     0.0306973  -0.115881     0.0123806   -0.173637    -0.005078    0.153484    -0.0959325  -0.0117409   0.177517    0.00917123    0.141365   -0.026088    0.172192   -0.0358525    0.0966246   0.03447      0.141873    -0.175427
  0.0291082   0.259704    -0.0808396  -0.102525     0.441284    -0.00846979   0.273335   -0.223756     0.095074   -0.174422    -0.157783     0.456666    -0.287556   -0.017452     0.147561    0.0904975   0.273118    0.55246       0.228202    0.0448268  -0.0347647   0.286733    -0.22295    -0.0143647   -0.299833    -0.0687242
 -0.187577   -0.227085    -0.0666431  -0.258691     0.180696     0.0298758    0.186344    0.0528645    0.28665     0.121703    -0.278051    -0.0392056    0.196371   -0.0139204   -0.0570033  -0.0327603  -0.248828    0.0192657    -0.617208    0.0316343   0.0489924  -0.387336     0.136081    0.0599857   -0.00530224   0.298133
 -0.707901   -0.165127    -0.3156      0.584955     0.176871    -0.155627     0.0639504   0.372771     0.323206    0.00291741  -0.00619736   0.209825     0.106425    0.125899     0.0470031  -0.068202    0.328302    0.198593     -0.763201    0.624221    0.414298   -0.268871     0.23996     0.0296415   -0.281171     0.384647
  0.0958516  -0.422489    -0.2137     -0.0427461   -0.131025    -0.0467783    0.241575    0.395374    -0.260167   -0.0203508   -0.940641    -0.0808758    0.179875    0.434954     0.028593   -0.661465    0.28628    -0.200463     -0.368789    0.19369    -0.286906    0.394566    -0.133609    0.112127     0.129875     0.0327869
 -0.288188   -0.465597    -0.354583    0.378261     0.0925109    0.377653     0.303502    0.432239     0.239448    0.0673134   -0.48613     -0.452206     0.200871    0.0279391    0.39796     0.354507    0.334737    0.0906492     0.154184   -0.523899   -0.251874    0.204797    -0.13085     0.472587    -0.202532    -0.305813
  0.843463   -0.148984    -0.0250737   0.146999    -0.183505     0.0787518    0.316451    0.109129     0.138258    0.132341     0.170445    -0.332051     0.645424   -0.280042    -0.354461    0.150694   -0.0574761  -0.478037      0.0336897  -0.219023    0.255693    0.0500908   -0.194571   -0.0804337    0.969026    -0.205854
 -0.0714466   0.0623263    0.237851    0.0434868   -0.0847561   -0.411222    -0.204121   -0.175523    -0.033006    0.435466     0.548591    -0.0548388    0.65152     0.196402     0.38283     0.247787    0.451226   -0.52422       0.0288045   0.247355    0.147345    0.230513     0.0486841  -0.00620752   0.36533     -0.247582
  0.421934   -0.163389    -0.419459    0.385533     0.177862     0.164574    -0.543416   -0.285037    -0.179932    0.393185    -0.0121313   -0.250787     0.665992   -0.291355     0.195788    0.0488413   0.0517515   0.466721     -0.437484    0.29014     0.0862591   0.046978    -0.236767   -0.171207    -0.330176    -0.139131
  0.153405   -0.394821     0.137434   -0.00162155  -0.187441    -0.184061    -0.0525952  -0.338246    -0.402148    0.0536173   -0.240485     0.473864     0.305317   -0.0633143    0.0679669   0.635314   -0.245415   -0.151801     -0.264424    0.147192    0.111536    0.359418    -0.394309    0.187001    -0.459884     0.178491[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403656
[ Info: iteration 2, average log likelihood -1.403643
[ Info: iteration 3, average log likelihood -1.403630
[ Info: iteration 4, average log likelihood -1.403617
[ Info: iteration 5, average log likelihood -1.403605
[ Info: iteration 6, average log likelihood -1.403593
[ Info: iteration 7, average log likelihood -1.403582
[ Info: iteration 8, average log likelihood -1.403571
[ Info: iteration 9, average log likelihood -1.403560
[ Info: iteration 10, average log likelihood -1.403550
kind full, method kmeans┌ Info: EM with 100000 data points 10 iterations avll -1.403550
└ 59.0 data points per parameter

[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.120586e+05
      1       7.000121e+05      -2.120465e+05 |       32
      2       6.836089e+05      -1.640324e+04 |       32
      3       6.782364e+05      -5.372551e+03 |       32
      4       6.756409e+05      -2.595482e+03 |       32
      5       6.740750e+05      -1.565829e+03 |       32
      6       6.729269e+05      -1.148101e+03 |       32
      7       6.719967e+05      -9.302552e+02 |       32
      8       6.712516e+05      -7.450461e+02 |       32
      9       6.706527e+05      -5.989255e+02 |       32
     10       6.701042e+05      -5.484952e+02 |       32
     11       6.695944e+05      -5.098412e+02 |       32
     12       6.691060e+05      -4.883621e+02 |       32
     13       6.686558e+05      -4.501960e+02 |       32
     14       6.682507e+05      -4.051343e+02 |       32
     15       6.678792e+05      -3.715308e+02 |       32
     16       6.675598e+05      -3.193819e+02 |       32
     17       6.672815e+05      -2.782312e+02 |       32
     18       6.670421e+05      -2.394097e+02 |       32
     19       6.668251e+05      -2.170043e+02 |       32
     20       6.666284e+05      -1.967107e+02 |       32
     21       6.664378e+05      -1.906020e+02 |       32
     22       6.662814e+05      -1.564227e+02 |       32
     23       6.661481e+05      -1.333316e+02 |       32
     24       6.660307e+05      -1.173922e+02 |       32
     25       6.659250e+05      -1.056752e+02 |       32
     26       6.658282e+05      -9.674817e+01 |       32
     27       6.657299e+05      -9.835647e+01 |       32
     28       6.656350e+05      -9.491155e+01 |       32
     29       6.655499e+05      -8.508998e+01 |       32
     30       6.654707e+05      -7.919756e+01 |       32
     31       6.653903e+05      -8.036319e+01 |       32
     32       6.653022e+05      -8.809225e+01 |       32
     33       6.652210e+05      -8.124897e+01 |       32
     34       6.651519e+05      -6.907679e+01 |       32
     35       6.650926e+05      -5.932772e+01 |       32
     36       6.650409e+05      -5.166260e+01 |       32
     37       6.650004e+05      -4.047144e+01 |       32
     38       6.649653e+05      -3.510679e+01 |       32
     39       6.649301e+05      -3.520159e+01 |       32
     40       6.648993e+05      -3.079310e+01 |       32
     41       6.648734e+05      -2.591226e+01 |       32
     42       6.648491e+05      -2.431459e+01 |       32
     43       6.648199e+05      -2.921239e+01 |       32
     44       6.647864e+05      -3.350431e+01 |       32
     45       6.647559e+05      -3.045885e+01 |       32
     46       6.647277e+05      -2.826836e+01 |       32
     47       6.647031e+05      -2.455799e+01 |       32
     48       6.646784e+05      -2.473658e+01 |       32
     49       6.646539e+05      -2.443991e+01 |       32
     50       6.646327e+05      -2.126377e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 664632.6792279857)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415464
[ Info: iteration 2, average log likelihood -1.410335
[ Info: iteration 3, average log likelihood -1.408928
[ Info: iteration 4, average log likelihood -1.407839
[ Info: iteration 5, average log likelihood -1.406729
[ Info: iteration 6, average log likelihood -1.405791
[ Info: iteration 7, average log likelihood -1.405194
[ Info: iteration 8, average log likelihood -1.404870
[ Info: iteration 9, average log likelihood -1.404685
[ Info: iteration 10, average log likelihood -1.404562
[ Info: iteration 11, average log likelihood -1.404468
[ Info: iteration 12, average log likelihood -1.404392
[ Info: iteration 13, average log likelihood -1.404326
[ Info: iteration 14, average log likelihood -1.404266
[ Info: iteration 15, average log likelihood -1.404212
[ Info: iteration 16, average log likelihood -1.404162
[ Info: iteration 17, average log likelihood -1.404115
[ Info: iteration 18, average log likelihood -1.404070
[ Info: iteration 19, average log likelihood -1.404027
[ Info: iteration 20, average log likelihood -1.403986
[ Info: iteration 21, average log likelihood -1.403947
[ Info: iteration 22, average log likelihood -1.403909
[ Info: iteration 23, average log likelihood -1.403872
[ Info: iteration 24, average log likelihood -1.403837
[ Info: iteration 25, average log likelihood -1.403803
[ Info: iteration 26, average log likelihood -1.403770
[ Info: iteration 27, average log likelihood -1.403739
[ Info: iteration 28, average log likelihood -1.403709
[ Info: iteration 29, average log likelihood -1.403680
[ Info: iteration 30, average log likelihood -1.403652
[ Info: iteration 31, average log likelihood -1.403625
[ Info: iteration 32, average log likelihood -1.403599
[ Info: iteration 33, average log likelihood -1.403574
[ Info: iteration 34, average log likelihood -1.403550
[ Info: iteration 35, average log likelihood -1.403527
[ Info: iteration 36, average log likelihood -1.403505
[ Info: iteration 37, average log likelihood -1.403484
[ Info: iteration 38, average log likelihood -1.403464
[ Info: iteration 39, average log likelihood -1.403445
[ Info: iteration 40, average log likelihood -1.403427
[ Info: iteration 41, average log likelihood -1.403410
[ Info: iteration 42, average log likelihood -1.403394
[ Info: iteration 43, average log likelihood -1.403379
[ Info: iteration 44, average log likelihood -1.403365
[ Info: iteration 45, average log likelihood -1.403351
[ Info: iteration 46, average log likelihood -1.403338
[ Info: iteration 47, average log likelihood -1.403326
[ Info: iteration 48, average log likelihood -1.403314
[ Info: iteration 49, average log likelihood -1.403303
[ Info: iteration 50, average log likelihood -1.403293
┌ Info: EM with 100000 data points 50 iterations avll -1.403293
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.257564   -0.198109    -0.0723313  -0.0481633  -0.270275    -0.267092     0.282736     0.132698   -0.189082     0.785199   -0.000616215  -0.0171359  -0.222548    0.202252     0.0670856   -0.0380173   -0.387746     0.160651   -0.171481   -0.315557   -0.51037     -0.213609     0.36186      0.0608844   0.255776    -0.611291
 -0.145248   -0.0590237    0.214724    0.169893    0.00148677   0.0783918   -0.00347512  -0.0312178  -0.0100684   -0.2914      0.049555      0.0764657  -0.192197   -0.118843     0.0785959    0.158105     0.186363     0.167184    0.137836    0.0461655   0.206186     0.14659      0.0274768    0.15548    -0.208947    -0.0552877
 -0.167017   -0.18214     -0.0113539  -0.150345    0.335611     0.744016    -0.029336     0.128611    0.25376     -0.140604   -0.395714     -0.436335   -0.379365   -0.0792032    0.067155     0.849643     0.0945415   -0.337486    0.074119   -0.622107   -0.370195    -0.236857     0.0723697    0.306526   -0.485448     0.0985736
  0.133703    0.05564     -0.0657281  -0.197545    0.232848    -0.254926     0.674035     0.278572    0.0220661   -0.0920431  -0.293333     -0.0672223  -0.0230825  -0.0153408    0.26388     -0.288801     0.710402     0.440325   -0.28069     0.599878    0.401385     0.00851366  -0.276445    -0.338154    0.102399    -0.402359
 -0.336869   -0.0813249   -0.053144   -0.825497    0.446375     0.0437009    0.716044     0.386184    0.264899    -0.0489132  -0.316706      0.257344   -0.165665    0.9218      -0.146038     0.192491     0.402693     0.254386    0.292077    0.0903525   0.262663     0.392869     0.445356     0.598414    0.244524    -0.223001
  0.0151215  -0.582438    -0.384254    0.621228   -0.0728677    0.027613    -0.00765027   0.109608   -0.234402     0.0396019  -0.458945     -0.325028    0.641423   -0.0029243    0.276513     0.303215     0.1986       0.317577    0.178717   -0.172192   -0.0743839    0.569324    -0.278355     0.510288   -0.226795    -0.297322
  0.0430343   0.427945    -0.447175   -0.0854478   0.93584      0.376895     0.177215    -0.273199    0.0559166   -0.0744736  -0.290919      0.943506   -0.202897    0.119225    -0.226558     0.0370731    0.147775     0.550987    0.299889   -0.140491    0.0367518    0.165771    -0.215688    -0.325756   -0.357538     0.224356
  0.0259147  -0.00136637   0.433328    0.165613   -0.176792    -0.0691233   -0.263216    -0.215741   -0.510334    -0.313029    0.151631     -0.0866111  -0.924042   -0.356101    -0.762465    -0.23625      0.249983     0.54781     0.488186    0.347068   -0.270857     0.0997656    0.128066     0.124265    0.167375    -0.28766
 -0.264381    0.156095    -0.687897   -0.0590437  -0.388269    -0.152843     0.0621288    0.358618    0.611625     0.625756    0.0660292     0.269416    0.266684    0.195384     0.0836105   -0.619208    -0.193118    -0.0341308  -0.62246     0.140569   -0.595098    -0.256892    -0.229087     0.0650992   0.249182    -0.136149
 -0.595344   -0.352866     0.114686   -0.314569   -0.761        0.33674     -0.334705     0.380489   -0.122777    -0.130101   -0.326198      0.232192   -0.441798    0.113389     0.32505     -0.61829     -0.239905     0.160293   -0.182522   -0.0379922  -0.645694    -0.053891    -0.133693    -0.129452   -0.609561     0.366115
  0.180664    0.291873    -1.12017    -1.02923    -0.250713     0.0454842   -0.46058     -1.52493    -0.0784522   -0.487747   -0.796062     -0.0710614   0.959076    1.02197     -0.310867     0.885742    -0.487476     1.34142     0.466968    0.0036234   0.492498    -0.581983     0.169684     0.199224    0.457897    -0.565874
  0.848537    0.166167     0.155907    0.437382    0.231586    -0.0873768    0.163887    -0.517644    0.199351     0.12385     0.422986     -0.411483    0.74853    -0.21905     -0.320391     0.827752     0.203714    -0.211875    0.0993895  -0.0969784   0.588482    -0.0841371   -0.0670248   -0.0575153   0.45047     -0.274608
 -0.170648   -0.0256665    0.0097256  -0.21145     0.199392     0.460461    -0.842796    -0.300507    0.0488279    0.0498028   0.169409      0.121686   -0.302721    0.270998    -0.344056    -0.134584    -0.604091    -0.561044    0.104754   -0.20454     0.11384      0.0931875    0.980113     0.21692    -0.22387      0.0587361
  0.154643    0.135138    -0.0554138   0.105633   -0.419424     0.056517    -0.441779    -0.0427398   0.00766434   0.0348944   0.36802      -0.21896     0.11407    -0.274154    -0.119343    -0.268503    -0.00867387  -0.437056    0.115281    0.0720049  -0.27669     -0.198645    -0.0698947   -0.184556    0.125784     0.115876
 -0.0132331  -0.0545127   -0.240878   -0.0910864   0.227115     0.402927     0.214794     0.299945    0.290435    -0.0712944  -0.45731      -0.130152   -0.177174   -0.0485166   -0.00781692  -0.227697     0.136501     0.0180333  -0.12831    -0.181556   -0.236182    -0.155777    -0.0794471    0.194594   -0.00349369   0.128242
 -0.570863   -0.528743    -0.0104299   0.249223    0.127626    -0.186392    -0.080602     0.237738    0.069017     0.134427   -0.465479      0.192004    0.197841    0.198325    -0.0748015   -0.00427049  -0.203257     0.0324063  -0.923632    0.396286    0.153655    -0.2336       0.44652      0.177728   -0.0185734    0.544775
  0.303131   -0.138506    -0.0404107  -0.253359    0.256732    -0.883736     0.107898    -0.452263   -0.511913     0.73821     0.616449      0.108064    0.722954    0.238192    -0.0466585    0.275623     0.0637042   -0.167191    0.159954    0.253439    0.0846827    0.415509     0.567332    -0.419666    0.236696    -0.358671
  0.245178   -0.0396489    0.306709    0.217109    0.5019       0.332963    -0.33455     -0.395818    0.108249    -0.819137    0.183863      0.0459306   0.305137   -0.0262654   -0.157438     0.173962     0.110049    -0.09183    -0.173555    0.359718    0.916251     0.0527501    0.142803    -0.185646   -0.453995     0.758739
  0.0329587   0.0910681   -0.355446    0.315965   -0.323784     0.080321     0.250003    -0.338419    0.485767    -0.739612   -0.389382     -0.0531408  -0.368227   -0.564752    -0.327982     0.0827815   -0.224426     0.262523   -0.268509    0.195379   -0.281819    -0.0414306   -0.554665     0.435966   -0.293512     0.638537
 -0.967384    0.402377     0.463402    0.396475    0.166799     0.0269819   -0.79346      0.169761   -0.126241     0.0984527   0.388225      0.289581    0.447872    0.780102    -0.0676836    0.341626     0.358662     0.167368    0.34263     0.25404    -0.229303     0.178351    -0.224772     0.786977    0.0154503   -0.0610749
  0.368062   -0.0156091   -0.436166   -0.415656    0.921159    -0.211498     0.137679    -0.229103    0.031737     0.508012   -0.667927     -0.254472    0.34084     0.0820951   -0.16422      0.228592    -0.601689    -0.306673   -0.202028   -0.379161   -0.200518    -0.838407    -0.0369459   -0.0278551   0.693046     0.00242037
  0.0647422  -0.134788     0.0429068  -0.0848242   0.0224221   -0.0558555   -0.0277587   -0.0913047  -0.100729     0.0413594  -0.00977965    0.141535    0.0653634   0.00700809  -0.0289706    0.111247    -0.022909     0.0426818  -0.0913638   0.0746661   0.0251303    0.0462245   -0.0516885    0.0188579  -0.0352137   -0.0453914
  0.104116    0.0549516   -0.264396   -0.220869    0.291767     0.106845     0.104093     0.235315    0.447288     0.526629    0.136494      0.367116    0.868593    0.218348     0.397232     0.024074     0.227289    -0.529696   -0.325235   -0.0585824   0.143156     0.135168     0.00201539  -0.171367    0.307433    -0.168119
 -0.317275   -0.269546    -0.0942325   0.262137   -0.190752    -0.829875    -0.179506     0.431148   -0.433592    -0.508813   -0.337948     -1.02785    -0.0424995   0.353905    -1.09516     -0.545756     0.156249     0.0260626  -0.271818    0.365748   -0.0515656   -0.598132    -0.145858     0.475879   -0.0271235    0.522024
  0.416628    0.690444     0.326161   -0.8172      0.17272     -0.24827     -0.173599    -0.265916    0.128333    -0.103546    0.243544      0.242286   -0.407015    0.0434476   -0.233607    -0.394871    -0.0514086   -0.173117   -0.170113    0.236446    0.193328    -0.677155     0.291578    -0.7608      0.350144     0.0170516
 -0.364786   -0.0252159    0.397552   -0.0818773  -0.312269    -0.331755     0.0769113   -0.0056755   0.196449    -0.0619526   0.373208      0.303561   -0.308882   -0.274627     0.443115     0.264847     0.0716044    0.0249178   0.258959    0.187468    0.149565    -0.00421209  -0.0293528    0.187027   -0.244061     0.116374
  0.0298294   0.527533    -0.1596      0.191228    0.390833    -0.0321598   -0.0417647   -0.346668   -0.0106427   -0.299886    0.0588668    -0.368386   -0.0620779   0.361048    -0.0408126   -0.160259     0.207715     0.190242    0.225803   -0.082038    0.303553     0.0392034    0.345385    -0.10959     0.00403682  -0.424848
  0.250531   -0.155729    -0.0201264   0.332043    0.118987     0.145677    -0.805732    -0.083702   -0.0128471    0.771569    0.560407      0.292986    0.32383    -0.831587     0.340334     0.134743    -0.0335387    0.645166   -0.437368    0.123611    0.00701798  -0.294778    -0.0548456   -0.436149   -0.561676    -0.357278
 -0.062229   -0.0132088    0.195506   -0.0955354  -0.522198    -0.196334     0.811457     0.205505    0.181358    -0.902092   -0.184588     -0.163561   -0.371994    0.277508    -0.456859     0.00856423   0.0501852   -0.656162    0.511465   -0.211049    0.112369     0.0327943   -0.227344     0.199451    0.974005     0.0204632
  0.660473   -0.535738     0.194069   -0.23899    -0.635288    -0.00871036   0.0306331   -0.189748   -0.569081     0.375059   -0.243693      0.357841    0.465672   -0.296516    -0.0127735   -0.133678    -0.253269    -0.254366   -0.376871   -0.0673805  -0.128714     0.397678    -0.66912     -0.0904174   0.066279     0.313619
  0.256594    0.158501     0.484845   -0.800216   -0.185862     0.346534    -0.0684722    0.118394   -0.0111618    0.124818    0.322189      0.345105   -0.105836   -0.419711     0.210993    -0.103903    -0.373957     0.134196    0.899935   -0.527438   -0.821691     0.447025    -0.276987     0.0761603   0.0700668   -0.370777
  0.229202   -0.0920345    0.353137    0.27336    -0.581901     0.332981     0.103118     0.2345     -0.0108243   -0.347588    0.715689     -0.676495   -0.62842    -0.842181     0.268572    -0.628154     0.117439    -0.830752   -0.0788717  -0.175379   -0.22687      0.450874     0.180214    -0.423179   -0.225395     0.439802[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403283
[ Info: iteration 2, average log likelihood -1.403274
[ Info: iteration 3, average log likelihood -1.403265
[ Info: iteration 4, average log likelihood -1.403256
[ Info: iteration 5, average log likelihood -1.403248
[ Info: iteration 6, average log likelihood -1.403240
[ Info: iteration 7, average log likelihood -1.403233
[ Info: iteration 8, average log likelihood -1.403225
[ Info: iteration 9, average log likelihood -1.403219
[ Info: iteration 10, average log likelihood -1.403212
┌ Info: EM with 100000 data points 10 iterations avll -1.403212
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
