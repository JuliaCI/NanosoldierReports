Julia Version 1.4.0-DEV.565
Commit 83d7466c15 (2019-12-09 08:03 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)

   Cloning default registries into `~/.julia`
   Cloning registry from "https://github.com/JuliaRegistries/General.git"
[?25l    Fetching: [>                                        ]  0.0 %    Fetching: [=============>                           ]  31.9 %    Fetching: [=================================>       ]  80.4 %[2K[?25h     Added registry `General` to `~/.julia/registries/General`
 Resolving package versions...
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed SpecialFunctions â”€â”€â”€ v0.9.0
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.6
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+1
 Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.2
 Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.0
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed OrderedCollections â”€ v1.1.0
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed OpenSpecFun_jll â”€â”€â”€â”€ v0.5.3+1
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.21.11
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
 Installed Polynomials â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [f27b6e38] + Polynomials v0.6.0
  [1fd47b50] + QuadGK v2.2.0
  [3cdcf5f2] + RecipesBase v0.7.0
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Building Rmath â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Testing GaussianMixtures
Status `/tmp/jl_qVzA23/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [f27b6e38] Polynomials v0.6.0
  [1fd47b50] QuadGK v2.2.0
  [3cdcf5f2] RecipesBase v0.7.0
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -1.5302016001798555e6, [24844.66720465286, 75155.33279534717], [-23183.62638648292 -5958.015868869403 10.787967184715457; 23200.90917637036 5922.392820283994 -392.89467601448104], [[25844.311627985702 -403.7678828919692 -1454.8625306908216; -403.7678828919691 23451.462728922896 -506.6820177692106; -1454.8625306908216 -506.6820177692105 24922.449018130683], [74425.18792447489 -6.117204549670944 1277.6142679290256; -6.117204549670824 76391.1703793531 421.61279380983507; 1277.6142679290256 421.61279380983507 75719.16911507538]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.247874e+03
      1       9.620838e+02      -2.857897e+02 |        7
      2       8.829659e+02      -7.911787e+01 |        0
      3       8.829659e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 882.9658997328706)
â”Œ Info: K-means with 272 data points using 3 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.066225
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.892566
[ Info: iteration 2, lowerbound -3.829532
[ Info: iteration 3, lowerbound -3.773277
[ Info: iteration 4, lowerbound -3.709252
[ Info: iteration 5, lowerbound -3.639696
[ Info: iteration 6, lowerbound -3.567932
[ Info: iteration 7, lowerbound -3.496032
[ Info: dropping number of Gaussions to 7
[ Info: iteration 8, lowerbound -3.412033
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -3.309841
[ Info: iteration 10, lowerbound -3.204138
[ Info: iteration 11, lowerbound -3.113457
[ Info: dropping number of Gaussions to 5
[ Info: iteration 12, lowerbound -3.035768
[ Info: iteration 13, lowerbound -2.968670
[ Info: dropping number of Gaussions to 4
[ Info: iteration 14, lowerbound -2.911790
[ Info: iteration 15, lowerbound -2.859374
[ Info: iteration 16, lowerbound -2.820798
[ Info: iteration 17, lowerbound -2.795320
[ Info: iteration 18, lowerbound -2.781543
[ Info: dropping number of Gaussions to 3
[ Info: iteration 19, lowerbound -2.758835
[ Info: iteration 20, lowerbound -2.730275
[ Info: iteration 21, lowerbound -2.697388
[ Info: iteration 22, lowerbound -2.656453
[ Info: iteration 23, lowerbound -2.608945
[ Info: iteration 24, lowerbound -2.557927
[ Info: iteration 25, lowerbound -2.507339
[ Info: iteration 26, lowerbound -2.460632
[ Info: iteration 27, lowerbound -2.419508
[ Info: iteration 28, lowerbound -2.383701
[ Info: iteration 29, lowerbound -2.352313
[ Info: iteration 30, lowerbound -2.326440
[ Info: iteration 31, lowerbound -2.310467
[ Info: iteration 32, lowerbound -2.308126
[ Info: dropping number of Gaussions to 2
[ Info: iteration 33, lowerbound -2.302915
[ Info: iteration 34, lowerbound -2.299259
[ Info: iteration 35, lowerbound -2.299256
[ Info: iteration 36, lowerbound -2.299254
[ Info: iteration 37, lowerbound -2.299254
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Dec  9 17:34:15 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Dec  9 17:34:23 2019: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Mon Dec  9 17:34:26 2019: EM with 272 data points 0 iterations avll -2.066225
5.8 data points per parameter
, Mon Dec  9 17:34:27 2019: GMM converted to Variational GMM
, Mon Dec  9 17:34:38 2019: iteration 1, lowerbound -3.892566
, Mon Dec  9 17:34:38 2019: iteration 2, lowerbound -3.829532
, Mon Dec  9 17:34:38 2019: iteration 3, lowerbound -3.773277
, Mon Dec  9 17:34:38 2019: iteration 4, lowerbound -3.709252
, Mon Dec  9 17:34:38 2019: iteration 5, lowerbound -3.639696
, Mon Dec  9 17:34:38 2019: iteration 6, lowerbound -3.567932
, Mon Dec  9 17:34:38 2019: iteration 7, lowerbound -3.496032
, Mon Dec  9 17:34:38 2019: dropping number of Gaussions to 7
, Mon Dec  9 17:34:38 2019: iteration 8, lowerbound -3.412033
, Mon Dec  9 17:34:38 2019: dropping number of Gaussions to 6
, Mon Dec  9 17:34:38 2019: iteration 9, lowerbound -3.309841
, Mon Dec  9 17:34:38 2019: iteration 10, lowerbound -3.204138
, Mon Dec  9 17:34:38 2019: iteration 11, lowerbound -3.113457
, Mon Dec  9 17:34:38 2019: dropping number of Gaussions to 5
, Mon Dec  9 17:34:38 2019: iteration 12, lowerbound -3.035768
, Mon Dec  9 17:34:38 2019: iteration 13, lowerbound -2.968670
, Mon Dec  9 17:34:38 2019: dropping number of Gaussions to 4
, Mon Dec  9 17:34:38 2019: iteration 14, lowerbound -2.911790
, Mon Dec  9 17:34:38 2019: iteration 15, lowerbound -2.859374
, Mon Dec  9 17:34:38 2019: iteration 16, lowerbound -2.820798
, Mon Dec  9 17:34:38 2019: iteration 17, lowerbound -2.795320
, Mon Dec  9 17:34:38 2019: iteration 18, lowerbound -2.781543
, Mon Dec  9 17:34:38 2019: dropping number of Gaussions to 3
, Mon Dec  9 17:34:38 2019: iteration 19, lowerbound -2.758835
, Mon Dec  9 17:34:38 2019: iteration 20, lowerbound -2.730275
, Mon Dec  9 17:34:38 2019: iteration 21, lowerbound -2.697388
, Mon Dec  9 17:34:38 2019: iteration 22, lowerbound -2.656453
, Mon Dec  9 17:34:38 2019: iteration 23, lowerbound -2.608945
, Mon Dec  9 17:34:38 2019: iteration 24, lowerbound -2.557927
, Mon Dec  9 17:34:38 2019: iteration 25, lowerbound -2.507339
, Mon Dec  9 17:34:38 2019: iteration 26, lowerbound -2.460632
, Mon Dec  9 17:34:38 2019: iteration 27, lowerbound -2.419508
, Mon Dec  9 17:34:38 2019: iteration 28, lowerbound -2.383701
, Mon Dec  9 17:34:38 2019: iteration 29, lowerbound -2.352313
, Mon Dec  9 17:34:38 2019: iteration 30, lowerbound -2.326440
, Mon Dec  9 17:34:38 2019: iteration 31, lowerbound -2.310467
, Mon Dec  9 17:34:38 2019: iteration 32, lowerbound -2.308126
, Mon Dec  9 17:34:38 2019: dropping number of Gaussions to 2
, Mon Dec  9 17:34:38 2019: iteration 33, lowerbound -2.302915
, Mon Dec  9 17:34:38 2019: iteration 34, lowerbound -2.299259
, Mon Dec  9 17:34:38 2019: iteration 35, lowerbound -2.299256
, Mon Dec  9 17:34:38 2019: iteration 36, lowerbound -2.299254
, Mon Dec  9 17:34:38 2019: iteration 37, lowerbound -2.299254
, Mon Dec  9 17:34:38 2019: iteration 38, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: iteration 39, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: iteration 40, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: iteration 41, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: iteration 42, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: iteration 43, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: iteration 44, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: iteration 45, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: iteration 46, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: iteration 47, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: iteration 48, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: iteration 49, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: iteration 50, lowerbound -2.299253
, Mon Dec  9 17:34:38 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [95.95490775755134, 178.04509224244876]
Î² = [95.95490775755134, 178.04509224244876]
m = [2.000229257637322 53.85198717174231; 4.250300733136611 79.28686694240145]
Î½ = [97.95490775755134, 180.04509224244876]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763614243226 -0.00895312383007037; 0.0 0.012748664778107224], [0.18404155545647227 -0.007644049044078769; 0.0 0.008581705163869545]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0170409801252598
avll from llpg:  -1.0170409801252605
avll direct:     -1.0170409801252605
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9806443238320959
avll from llpg:  -0.9806443238320958
avll direct:     -0.9806443238320958
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
 -0.0385781   -0.0891658    -0.0792334   0.124222     0.0954698    0.106918     -0.0611958    0.0798624   -0.0872104    -0.114308    -0.00811461  -0.0199533   -0.226654    -0.053835    -0.0129894    0.0282484    -0.02293      0.0306857    0.198235      0.00185127   0.0040119    0.140292    -0.0349146    -0.119508     -0.06133      0.0191021
 -0.0376396   -0.0617725     0.035884   -0.0191115   -0.0885661   -0.00396894    0.0507237    0.0921257    0.0519789    -0.159357    -0.00490224   0.0625949    0.157802    -0.139398     0.0210775   -0.106278      0.198942    -0.0633175    0.156262      0.0994611    0.137461    -0.188782     0.0294751     0.000514242  -0.0605161   -0.18643
  0.0520718    0.03235      -0.083894   -0.0489724   -0.132105    -0.222993     -0.056439     0.00931885  -0.0459029     0.033629    -0.0322606   -0.204083    -0.171062    -0.116122     0.0152188   -0.128735     -0.139479    -0.00471627   0.142667     -0.0235957    0.0514507   -0.0174242   -0.203365     -0.0304334    -0.0502605   -0.0020778
  0.0308552    0.0642699    -0.0218386   0.137779     0.133988     0.246637     -0.0764745   -0.209494    -0.0607656    -0.0301978    0.0554336   -0.143114     0.0524266   -0.213002    -0.0168831   -0.000642123  -0.150798     0.191538     0.0200178    -0.0608927   -0.0769636   -0.0319234    0.0406297    -0.00826609   -0.194788     0.141879
  0.0578807    0.0223817    -0.0271252  -0.0224947    0.0884017    0.0254814    -0.0397105    0.0513501   -0.0097138    -0.0750572   -0.0829593    0.260906     0.106442    -0.112777    -0.0995971   -0.0920112    -0.0167173    0.00427761   0.0615514    -0.0435883   -0.131289    -0.00229695  -0.133354     -0.0603877     0.0187268    0.185759
 -0.0513841    0.0783048    -0.0697368  -0.0533941    0.0490655   -0.0345036    -0.0216459    0.0303627    0.14732      -0.0997675    0.121382     0.00748156  -0.059741    -0.0023175   -0.0709614    0.0716773    -0.10847      0.184534    -0.0570545    -0.0181747   -0.0535783   -0.0552386    0.0348271    -0.051851     -0.100474     0.0679425
  0.013606    -0.0361497    -0.0980106   0.108913    -0.141286    -0.0827679     0.0617276    0.0419769   -0.142742     -0.0232655    0.0161077    0.0642967   -0.102516    -0.159418     0.00436143  -0.147709      0.117579    -0.127347    -0.0346368    -0.0957479    0.039102     0.0235943    0.102385      0.0294709     0.00754678  -0.137042
  0.00774557   0.0231371     0.0350947   0.0170137   -0.0904975   -0.0972653    -3.31476e-5  -0.00748584   0.098333     -0.0655734   -0.0254689   -0.126526    -0.122269    -0.069911     0.0684992   -0.163895     -0.0712062    0.00175123   0.0344018    -0.03025     -0.0144802   -0.260604    -0.110928      0.132584      0.170568     0.0222841
 -0.138098     0.215639      0.0856254   0.142808     0.191443     0.0655872     0.029259    -0.033101    -0.00280059   -0.00508456  -0.179712    -0.0223133   -0.0321229    0.0823023    0.168605    -0.0454417     0.021986    -0.0421765   -0.0764624     0.00251764   0.0581986    0.0462399    0.0408596     0.166846     -0.0599365    0.0866121
  0.0036969    0.0329234    -0.0447136   0.140669     0.0792782   -0.243031     -0.0664153   -0.164821    -0.0747033    -0.0368611   -0.0627629    0.0191809   -0.238733    -0.00341362   0.180651    -0.0634841    -0.0771796   -0.0922406   -0.234572     -0.179044    -0.0423754    0.0119066   -0.148853     -0.136571     -0.259601     0.226495
 -0.0298003   -0.0468524     0.0776057  -0.0388687   -0.107235    -0.011653      0.0216094    0.191733    -0.000816808   0.222637     0.033988    -0.108591    -0.118035    -0.0468241   -0.0259329    0.0993818    -0.0952405   -0.0316432   -0.218226      0.0546104    0.0569629   -0.0988399    0.154036     -0.0276235    -0.217415     0.0885693
 -0.035093    -0.151447      0.102043    0.0492644   -0.113561    -0.0334566     0.0595819   -0.00803594  -0.142277      0.00147875   0.0829096   -0.247577     0.23355      0.0120134    0.106439     0.0569408    -0.0082369    0.0530757   -0.0312766     0.0250311    0.0030078    0.127094    -0.0169781     0.0845207    -0.0610283   -0.130225
  0.0212674   -0.0212307    -0.0418507  -0.0649956   -0.0238943   -0.0835003    -0.0393693   -0.0788363    0.0403919    -0.0523949   -0.0322783   -0.382709     0.131109    -0.0203974   -0.0644179   -0.0149173    -0.022729    -0.0280368    0.00434365   -0.0433232   -0.140843    -0.0754474   -0.0204625    -0.056047     -0.105472    -0.0166281
 -0.0944549   -0.116801      0.104366    0.0259938   -0.0387489    0.191285     -0.0967161   -0.0883298    0.124446      0.182549    -0.00807635   0.0911856    0.0223273   -0.123929    -0.183534     0.0826968    -0.00170159   0.0342227    0.108305      0.157715    -0.103985     0.0577828    0.0966974    -0.0904504     0.0138222   -0.264122
  0.00772331  -0.0260242     0.105511    0.101067     0.0694458   -0.0552712    -0.10188      0.0368351    0.206204      0.027873    -0.185498     0.169634     0.0564263    0.109324     0.0342351   -0.0804989     0.0531651   -0.0279297    0.194872      0.0630821   -0.00160661   0.111335    -0.00827397   -0.149042      0.239672     0.0649582
 -0.162348    -0.0414767     0.0257676   0.0466996    0.138804    -0.191884     -0.0405688    0.1905      -0.0261659     0.0210948    0.066056     0.0757987    0.109277     0.0901529    0.0714412    0.157263     -0.0861935    0.21529      0.0661816     0.0107659   -0.0565259    0.0820354   -0.0795959     0.0934507     0.0566654    0.0441486
 -0.00203908  -0.03552      -0.0579873   0.101881    -0.0292728   -0.043985      0.00753377  -0.083654    -0.138935     -0.0022684    0.222727    -0.0770863    0.0610344    0.102923    -0.021107     0.136689      0.110637     0.0913086   -0.109306      0.0455728    0.100632    -0.0898583    0.000284971   0.112767     -0.0119246   -0.0313507
 -0.0861127   -0.180394     -0.10431     0.127439    -0.0465027    0.0844465    -0.126778    -0.0837908   -0.0483659     0.208461    -0.0368014    0.171987    -0.056832     0.159616     0.0712677   -0.0667666    -0.0450751    0.0502655    0.0462152    -0.266809     0.12391      0.118653    -0.0298017     0.0767644    -0.0519336   -0.0113347
 -0.016072     0.0487473     0.0887267  -0.0693203    0.121616    -0.0212477    -0.0223112   -0.109538     0.0200258     0.0806621    0.0140346   -0.145573     0.109081     0.074453    -0.089736    -0.168366      0.0356251    0.0535932   -0.0636785    -0.0215004    0.081381    -0.101301    -0.105823     -0.202805      0.0890022   -0.115482
 -0.0772891    0.144477     -0.0181822   0.0597972   -0.0611444   -0.137515     -0.0509074   -0.207906    -0.0409569     0.0607778    0.0967855    0.0010361    0.0559042    0.015817     0.0701438   -0.0776784    -0.115211    -0.00330413   0.080321     -0.0141734    0.0115881    0.147859     0.0157446     0.000833684  -0.0521243    0.220221
  0.292149    -0.0932537    -0.0642451  -0.0092627    0.00281974   0.206218     -0.0939226   -0.180462    -0.0953194    -0.00712626  -0.0612081    0.0613271   -0.122603     0.025499     0.0289563   -0.0157863    -0.0610921   -0.306001    -0.121012     -0.0107464   -0.0271818   -0.0848806   -0.0558717     0.0544889    -0.0512697    0.0619065
  0.0418154   -0.0470715     0.0554859  -0.0996968   -0.149722     0.0107364    -0.0365404   -0.0454874   -0.00149915    0.0904304   -0.0157965    0.103241    -0.0264576    0.0141701   -0.0113743    0.0512107     0.0520225    0.0924744   -0.000858391   0.0813483    0.190142     0.0352571    0.087197     -0.0785505     0.109748     0.0532706
  0.0311103    0.00107751   -0.103931    0.0340065    0.00562155  -0.00498016    0.140306     0.16674     -0.128089     -0.0396064   -0.102738     0.074259    -0.114694    -0.0329608    0.100997    -0.0896129     0.111869     0.0983478   -0.0962763    -0.0233652    0.136764     0.131965    -0.168533      0.0405932    -0.250142    -0.0316118
  0.028996    -0.193773     -0.0435749  -0.0534028   -0.120736     0.122326     -0.0387843   -0.0602095   -0.0606465     0.0333511    0.100134     0.0751744   -0.0115325    0.0425117    0.0377964    0.179679     -0.121256    -0.00294359   0.0613432    -0.0473676    0.0757669    0.167986     0.0811436     0.165357     -0.0785345    0.140266
 -0.160939    -0.0600753    -0.0169582  -0.0968059    0.0288339    0.000720408  -0.0377337   -0.0926578   -0.150333      0.230974     0.224431     0.0357478    0.0185713   -0.0828469   -0.0651305    0.213456     -0.121934    -0.0705997   -0.20015      -0.148569    -0.0558991    0.0575082   -0.162186      0.0330022    -0.104684    -0.0123041
  0.174578    -0.0261497    -0.0178027   0.100806    -0.0371053   -0.145321     -0.17222     -0.00323942   0.0422415    -0.168167     0.0121021    0.100804    -0.0173081   -0.0934527   -0.187578     0.0283451     0.0413978    0.0673055    0.0525218    -0.0154762   -0.00043697   0.153211     0.108659     -0.036942      0.0945463    0.0496577
  0.0955476    0.0617323     0.108537    0.16032      0.247141     0.155255      0.043042    -0.0191018    0.138903      0.0849513    0.088275     0.140283     0.00755997   0.015775    -0.0129818   -0.0948031    -0.234369     0.00996307   0.0195745    -0.0435959   -0.0118269   -0.0840662   -0.116435      0.0323948     0.0748731   -0.070083
  0.157468     0.134165      0.126229   -0.00885233   0.00673876  -0.148372     -0.0100407   -0.0146161    0.0693491    -0.0223492    0.084062    -0.20706     -0.0552603   -0.00925955  -0.223471    -0.115428      0.106318    -0.171579     0.0161689    -0.0941149   -0.0801416   -0.0898812   -0.00662299   -0.0409063     0.0572417   -0.0933165
  0.0665736    0.000901202  -0.0713627  -0.026183     0.229758    -0.113231     -0.102465     0.0602127   -0.0810599    -0.00259555  -0.0296126    0.127252     0.011993     0.037463    -0.153924    -0.0638029     0.0908941   -0.0723811   -0.192762     -0.0177289   -0.0875284    0.0583141   -0.0163038    -0.0172175     0.0751758    0.0214763
 -0.178921     0.0446603     0.14222     0.101865     0.0411083    0.077533     -0.00432401   0.0649167   -0.075038      0.0176956    0.090129     0.128235     0.00661604   0.0378002    0.0627742   -0.143151     -0.176232    -0.122924    -0.146019      0.0667195   -0.101413    -0.00827142   0.159242     -0.10255       0.134199     0.0959187
 -0.0348106   -0.101987     -0.0465541   0.0865648   -0.153048    -0.188868      0.0493604   -0.162377     0.0510096    -0.101861     0.0825284   -0.0413551   -0.00421681   0.0409801    0.0606503    0.0379711     0.177002    -0.123671     0.0742336    -0.0906419   -0.138059    -0.17277     -0.0613757     0.036234      0.0359985   -0.0283158
  0.0530343    0.0586116    -0.0351748  -0.0627146   -0.0191808   -0.0857391     0.284565     0.103658    -0.00596234   -0.131182    -0.265073     0.0614155   -0.0765357   -0.0538419   -0.0102278   -0.195323     -0.0176728    0.0690122    0.0443113    -0.157099     0.0994754    0.00761872  -0.044058     -0.184044      0.138756     0.0118105kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.443270260406455
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.443382
[ Info: iteration 2, average log likelihood -1.443269
[ Info: iteration 3, average log likelihood -1.442416
[ Info: iteration 4, average log likelihood -1.434007
[ Info: iteration 5, average log likelihood -1.417043
[ Info: iteration 6, average log likelihood -1.411235
[ Info: iteration 7, average log likelihood -1.408771
[ Info: iteration 8, average log likelihood -1.407103
[ Info: iteration 9, average log likelihood -1.406179
[ Info: iteration 10, average log likelihood -1.405694
[ Info: iteration 11, average log likelihood -1.405397
[ Info: iteration 12, average log likelihood -1.405187
[ Info: iteration 13, average log likelihood -1.405025
[ Info: iteration 14, average log likelihood -1.404898
[ Info: iteration 15, average log likelihood -1.404797
[ Info: iteration 16, average log likelihood -1.404720
[ Info: iteration 17, average log likelihood -1.404666
[ Info: iteration 18, average log likelihood -1.404634
[ Info: iteration 19, average log likelihood -1.404617
[ Info: iteration 20, average log likelihood -1.404608
[ Info: iteration 21, average log likelihood -1.404603
[ Info: iteration 22, average log likelihood -1.404600
[ Info: iteration 23, average log likelihood -1.404598
[ Info: iteration 24, average log likelihood -1.404597
[ Info: iteration 25, average log likelihood -1.404596
[ Info: iteration 26, average log likelihood -1.404595
[ Info: iteration 27, average log likelihood -1.404595
[ Info: iteration 28, average log likelihood -1.404595
[ Info: iteration 29, average log likelihood -1.404595
[ Info: iteration 30, average log likelihood -1.404594
[ Info: iteration 31, average log likelihood -1.404594
[ Info: iteration 32, average log likelihood -1.404594
[ Info: iteration 33, average log likelihood -1.404594
[ Info: iteration 34, average log likelihood -1.404594
[ Info: iteration 35, average log likelihood -1.404594
[ Info: iteration 36, average log likelihood -1.404594
[ Info: iteration 37, average log likelihood -1.404594
[ Info: iteration 38, average log likelihood -1.404594
[ Info: iteration 39, average log likelihood -1.404594
[ Info: iteration 40, average log likelihood -1.404594
[ Info: iteration 41, average log likelihood -1.404594
[ Info: iteration 42, average log likelihood -1.404594
[ Info: iteration 43, average log likelihood -1.404594
[ Info: iteration 44, average log likelihood -1.404594
[ Info: iteration 45, average log likelihood -1.404594
[ Info: iteration 46, average log likelihood -1.404594
[ Info: iteration 47, average log likelihood -1.404594
[ Info: iteration 48, average log likelihood -1.404594
[ Info: iteration 49, average log likelihood -1.404594
[ Info: iteration 50, average log likelihood -1.404594
â”Œ Info: EM with 100000 data points 50 iterations avll -1.404594
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.443382238514351
â”‚     -1.4432685146084252
â”‚      â‹®
â””     -1.4045941014502714
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404808
[ Info: iteration 2, average log likelihood -1.404626
[ Info: iteration 3, average log likelihood -1.404013
[ Info: iteration 4, average log likelihood -1.396745
[ Info: iteration 5, average log likelihood -1.377245
[ Info: iteration 6, average log likelihood -1.367427
[ Info: iteration 7, average log likelihood -1.364920
[ Info: iteration 8, average log likelihood -1.363892
[ Info: iteration 9, average log likelihood -1.363298
[ Info: iteration 10, average log likelihood -1.362899
[ Info: iteration 11, average log likelihood -1.362612
[ Info: iteration 12, average log likelihood -1.362401
[ Info: iteration 13, average log likelihood -1.362244
[ Info: iteration 14, average log likelihood -1.362127
[ Info: iteration 15, average log likelihood -1.362038
[ Info: iteration 16, average log likelihood -1.361969
[ Info: iteration 17, average log likelihood -1.361914
[ Info: iteration 18, average log likelihood -1.361868
[ Info: iteration 19, average log likelihood -1.361828
[ Info: iteration 20, average log likelihood -1.361791
[ Info: iteration 21, average log likelihood -1.361753
[ Info: iteration 22, average log likelihood -1.361713
[ Info: iteration 23, average log likelihood -1.361668
[ Info: iteration 24, average log likelihood -1.361616
[ Info: iteration 25, average log likelihood -1.361557
[ Info: iteration 26, average log likelihood -1.361491
[ Info: iteration 27, average log likelihood -1.361419
[ Info: iteration 28, average log likelihood -1.361350
[ Info: iteration 29, average log likelihood -1.361288
[ Info: iteration 30, average log likelihood -1.361235
[ Info: iteration 31, average log likelihood -1.361191
[ Info: iteration 32, average log likelihood -1.361156
[ Info: iteration 33, average log likelihood -1.361129
[ Info: iteration 34, average log likelihood -1.361109
[ Info: iteration 35, average log likelihood -1.361094
[ Info: iteration 36, average log likelihood -1.361084
[ Info: iteration 37, average log likelihood -1.361076
[ Info: iteration 38, average log likelihood -1.361070
[ Info: iteration 39, average log likelihood -1.361065
[ Info: iteration 40, average log likelihood -1.361062
[ Info: iteration 41, average log likelihood -1.361060
[ Info: iteration 42, average log likelihood -1.361058
[ Info: iteration 43, average log likelihood -1.361056
[ Info: iteration 44, average log likelihood -1.361055
[ Info: iteration 45, average log likelihood -1.361054
[ Info: iteration 46, average log likelihood -1.361053
[ Info: iteration 47, average log likelihood -1.361052
[ Info: iteration 48, average log likelihood -1.361052
[ Info: iteration 49, average log likelihood -1.361051
[ Info: iteration 50, average log likelihood -1.361051
â”Œ Info: EM with 100000 data points 50 iterations avll -1.361051
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4048076421212747
â”‚     -1.4046259662838072
â”‚      â‹®
â””     -1.3610510352996472
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.361364
[ Info: iteration 2, average log likelihood -1.361060
[ Info: iteration 3, average log likelihood -1.359828
[ Info: iteration 4, average log likelihood -1.350125
[ Info: iteration 5, average log likelihood -1.330252
[ Info: iteration 6, average log likelihood -1.316597
[ Info: iteration 7, average log likelihood -1.311136
[ Info: iteration 8, average log likelihood -1.308495
[ Info: iteration 9, average log likelihood -1.306291
[ Info: iteration 10, average log likelihood -1.304006
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.301962
[ Info: iteration 12, average log likelihood -1.311651
[ Info: iteration 13, average log likelihood -1.305683
[ Info: iteration 14, average log likelihood -1.303757
[ Info: iteration 15, average log likelihood -1.302502
[ Info: iteration 16, average log likelihood -1.301423
[ Info: iteration 17, average log likelihood -1.300378
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.299330
[ Info: iteration 19, average log likelihood -1.309877
[ Info: iteration 20, average log likelihood -1.303970
[ Info: iteration 21, average log likelihood -1.301987
[ Info: iteration 22, average log likelihood -1.300480
[ Info: iteration 23, average log likelihood -1.298997
[ Info: iteration 24, average log likelihood -1.297554
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.296191
[ Info: iteration 26, average log likelihood -1.306899
[ Info: iteration 27, average log likelihood -1.300843
[ Info: iteration 28, average log likelihood -1.298751
[ Info: iteration 29, average log likelihood -1.297319
[ Info: iteration 30, average log likelihood -1.296120
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.295088
[ Info: iteration 32, average log likelihood -1.305979
[ Info: iteration 33, average log likelihood -1.300264
[ Info: iteration 34, average log likelihood -1.298373
[ Info: iteration 35, average log likelihood -1.297055
[ Info: iteration 36, average log likelihood -1.295924
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.294938
[ Info: iteration 38, average log likelihood -1.305941
[ Info: iteration 39, average log likelihood -1.300225
[ Info: iteration 40, average log likelihood -1.298325
[ Info: iteration 41, average log likelihood -1.297013
[ Info: iteration 42, average log likelihood -1.295893
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.294910
[ Info: iteration 44, average log likelihood -1.305926
[ Info: iteration 45, average log likelihood -1.300212
[ Info: iteration 46, average log likelihood -1.298304
[ Info: iteration 47, average log likelihood -1.296995
[ Info: iteration 48, average log likelihood -1.295880
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.294898
[ Info: iteration 50, average log likelihood -1.305914
â”Œ Info: EM with 100000 data points 50 iterations avll -1.305914
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3613638279403486
â”‚     -1.3610596257996126
â”‚      â‹®
â””     -1.3059135274875973
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.300551
[ Info: iteration 2, average log likelihood -1.298279
[ Info: iteration 3, average log likelihood -1.296096
[ Info: iteration 4, average log likelihood -1.286987
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.261465
[ Info: iteration 6, average log likelihood -1.245421
[ Info: iteration 7, average log likelihood -1.228042
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     14
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.216710
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.216611
[ Info: iteration 10, average log likelihood -1.232374
[ Info: iteration 11, average log likelihood -1.224766
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.212651
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.205398
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     1
â”‚     3
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.211680
[ Info: iteration 15, average log likelihood -1.222737
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.205910
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.202594
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.212458
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.222037
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.211190
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.219402
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.202682
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     14
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.211516
[ Info: iteration 24, average log likelihood -1.223072
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.206581
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     1
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.218260
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.211475
[ Info: iteration 28, average log likelihood -1.213887
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.195680
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     1
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.213050
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.216762
[ Info: iteration 32, average log likelihood -1.224778
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.204347
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.198353
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.209945
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.202739
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.207406
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     1
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.208888
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.211298
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.204002
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.195187
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.198396
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     13
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.217631
[ Info: iteration 44, average log likelihood -1.220523
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.204529
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     13
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.194483
[ Info: iteration 47, average log likelihood -1.211428
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.195664
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.213325
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.209111
â”Œ Info: EM with 100000 data points 50 iterations avll -1.209111
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3005511766204387
â”‚     -1.2982786416282939
â”‚      â‹®
â””     -1.209110857986613
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.218880
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.200548
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.191099
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     20
â”‚     25
â”‚     26
â”‚     27
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.165346
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      4
â”‚      6
â”‚     15
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.134504
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     19
â”‚     25
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.129951
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.137435
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚     15
â”‚     19
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.097985
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.116594
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      7
â”‚     15
â”‚     19
â”‚     20
â”‚     22
â”‚     25
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.097559
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      4
â”‚      6
â”‚     16
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.114193
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     15
â”‚     25
â”‚     26
â”‚     27
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.106932
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     16
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.113030
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚     10
â”‚     15
â”‚     22
â”‚     25
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.081638
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     16
â”‚     19
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.107388
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     15
â”‚     16
â”‚      â‹®
â”‚     26
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.084795
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      4
â”‚      6
â”‚     19
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.113092
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      7
â”‚     16
â”‚     25
â”‚     26
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.116851
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     15
â”‚     19
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.093642
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚     15
â”‚     16
â”‚     22
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.089227
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚      â‹®
â”‚     27
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.087890
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      7
â”‚     16
â”‚     20
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.119842
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      4
â”‚      6
â”‚     15
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.098512
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     16
â”‚     19
â”‚     25
â”‚     26
â”‚     27
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.095014
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.107597
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚     10
â”‚     16
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.072968
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     15
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.119137
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      7
â”‚     16
â”‚     19
â”‚     20
â”‚     25
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.102315
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.098301
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      7
â”‚     16
â”‚     22
â”‚     25
â”‚     26
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.100446
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     15
â”‚     19
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.101823
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚     16
â”‚     25
â”‚     26
â”‚     27
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.091415
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     15
â”‚     19
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.102592
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      7
â”‚     16
â”‚     20
â”‚     25
â”‚     26
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.102505
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      4
â”‚      6
â”‚     15
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.101223
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     16
â”‚     22
â”‚      â‹®
â”‚     26
â”‚     27
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.080774
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     15
â”‚     19
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.111871
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚     16
â”‚     25
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.102070
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     15
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.096484
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      7
â”‚     16
â”‚     22
â”‚     25
â”‚     26
â”‚     27
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.090793
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      4
â”‚      6
â”‚     15
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.109033
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     16
â”‚     19
â”‚     25
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.101294
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     15
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.106306
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚     10
â”‚     16
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.083441
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.112490
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      7
â”‚     16
â”‚     19
â”‚     20
â”‚      â‹®
â”‚     26
â”‚     27
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.082790
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     15
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.103857
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      7
â”‚     16
â”‚     25
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.122036
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     15
â”‚     19
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.100521
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚     16
â”‚     22
â”‚     25
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.088771
â”Œ Info: EM with 100000 data points 50 iterations avll -1.088771
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2188800674804139
â”‚     -1.2005478067405624
â”‚      â‹®
â””     -1.0887714618008064
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.443270260406455
â”‚     -1.443382238514351
â”‚     -1.4432685146084252
â”‚     -1.4424160941998359
â”‚      â‹®
â”‚     -1.1220361426774856
â”‚     -1.1005211942022886
â””     -1.0887714618008064
32Ã—26 Array{Float64,2}:
 -0.0785919    0.144814     -0.0139958    0.0550671  -0.0641278    -0.135667   -0.0455501   -0.20155      -0.0148687     0.0600816    0.0957458    0.00648423   0.0527375    0.00789687   0.0589956    -0.0817162  -0.114432    -0.0143912    0.0567939   -0.0228872    0.00865268   0.143169     0.00151302    0.0329292   -0.042662      0.235308
  0.0635189   -0.000749732  -0.0620511    0.0230687   0.232375     -0.12609    -0.10039      0.0525313    -0.0838108    -0.00343586  -0.0319343    0.12816     -0.010054     0.0423457   -0.181256     -0.053063    0.0895366   -0.0764618   -0.192582    -0.0737545   -0.0793072    0.0562116   -0.000935133  -0.0315138    0.0861125     0.0221429
  0.411389    -0.762202      0.0707996   -0.0521181  -0.00960311   -0.077317    0.078757    -0.0103337     0.106861      0.00551006   0.091446    -0.215186    -0.167722    -0.203485    -0.372962     -0.101667    0.0975965   -0.171144     0.0136855   -0.049953    -0.0804789   -0.0744636   -0.0341697    -0.185193     0.0208524    -0.113779
 -0.183193     1.07458       0.146993     0.0497383   0.0623662    -0.212087   -0.140555    -0.0173061     0.0345997    -0.0623571    0.114867    -0.191392    -0.00271493   0.0579817   -0.0591539    -0.148631    0.104418    -0.159496    -0.00305066  -0.092654    -0.0801193   -0.0736121    0.0325535     0.19564      0.0221055    -0.0474662
 -0.189402     0.0408868     0.147551     0.0902959   0.0313707     0.0788317  -0.0296875    0.0522431    -0.0600385     0.0186334    0.0850708    0.12483      0.0173895    0.0355942   -0.000384631  -0.1402     -0.177618    -0.113321    -0.166663     0.0550851   -0.0991609   -0.00560343   0.143679     -0.113953     0.183204      0.0918325
 -0.0154423    0.0250603    -0.036444     0.137818    0.0777073    -0.237435   -0.0554908   -0.167381     -0.0839008    -0.0325538   -0.0657215    0.0154816   -0.241721    -0.011123     0.153099     -0.0622884  -0.0902938   -0.0941181   -0.230398    -0.241419    -0.033731     0.0111655   -0.143356     -0.143649    -0.250734      0.219464
 -0.137429     0.197145      0.085366     0.142263    0.193623      0.075358    0.0256692   -0.0408373    -0.0146965    -0.0712522   -0.171324    -0.0320455   -0.0320684    0.0835699    0.154228     -0.0268936   0.0217892   -0.0439997   -0.0824413    0.010409     0.0533682    0.0533523    0.0306439     0.164552    -0.0573206     0.0672408
  0.0188358   -0.0441141    -0.0810552    0.10909    -0.149815     -0.126003    0.0609757    0.0458966    -0.166942     -0.0310726    0.0216369    0.0463624   -0.101239    -0.159939     0.0182368    -0.123954    0.108408    -0.115731    -0.017515    -0.0829486    0.0508537    0.0192656    0.086629      0.0405161    0.00553208   -0.136732
 -0.0360551   -0.0622437    -0.0951868    0.137849    0.0974912     0.111122   -0.0576934    0.106726     -0.0912958    -0.113389     0.0141251   -0.00717727  -0.235044    -0.0849693   -0.0233067     0.0273194  -0.0620132    0.0248813    0.216964     0.0121711   -0.00728253   0.162619    -0.0284977    -0.116945    -0.0317029     0.0404274
  0.00327353   0.0026662     0.0751008   -0.0514036   0.124349     -0.0148313  -0.00947555  -0.0135866     0.0259623     0.0562514   -0.00905726  -0.120808     0.0543073    0.0939729   -0.0789559    -0.154768    0.0264078    0.0447572   -0.038281    -0.026864     0.079316    -0.0926547   -0.118296     -0.191432     0.0926567    -0.114906
  0.180914    -0.037688     -0.0178104    0.0923412  -0.0407358    -0.138255   -0.179751     0.00296906    0.041519     -0.252369     0.00573142   0.106464    -0.0212656   -0.126174    -0.194073      0.0499575   0.0611229    0.0672478    0.0252824   -0.0284469    0.00615344   0.157337     0.135667     -0.0450553    0.0915043     0.0503554
  0.0474355   -0.00246861   -0.104648     0.017451    0.00532801   -0.0134326   0.0616668    0.202497     -0.134833     -0.0378925   -0.105114     0.0818544   -0.116724    -0.0576294    0.131564     -0.0923641   0.131286     0.0984116   -0.102167    -0.0280131    0.133248     0.136693    -0.1768        0.0489706   -0.24859      -0.0301048
  0.0285855    0.0597089    -0.0706121   -0.0571588   0.0197461    -0.0574407   0.247405     0.111067     -0.00697578   -0.114337    -0.251866     0.0409768   -0.073358    -0.0240502   -0.0175813    -0.220274    0.00348828   0.0423571    0.0428837   -0.097238     0.098259    -0.00682019  -0.0546177    -0.159715     0.146544      0.0066476
  0.0231662   -0.00513543    0.00584659   0.0241653   0.114279      0.0216981  -0.0337157    0.00618483    0.0356527     0.0303028    0.0651781    0.0655032   -0.0165978    0.0334711   -0.00297959    0.0166684  -0.136948     0.0244461   -0.0314881   -0.0307424   -0.0651445   -0.0292799   -0.0701566     0.0481927    0.000540136   0.0240075
 -0.012202     0.0250043     0.0362431    0.0190468  -0.107119     -0.0789022  -0.0003584   -0.0197369     0.099936     -0.0597884   -0.00617554  -0.0958245   -0.108952    -0.0636843    0.0668519    -0.124614   -0.0695642   -0.00239034   0.0754756   -0.0293508    0.00120473  -0.281784    -0.111852      0.134534     0.17492       0.0113844
 -0.0410321   -0.089743     -0.0301443    0.068721   -0.14758      -0.191089    0.0330193   -0.163596      0.0506558    -0.139002     0.0930305   -0.0686534   -0.00386725   0.0469245    0.0600164     0.0681374   0.183937    -0.122544     0.0872329   -0.0843407   -0.154137    -0.174411    -0.0608768     0.0373819    0.0676802    -0.0210399
 -0.0642996   -0.00858697    0.101215     0.113363    0.0544548    -0.0620726  -0.126291     0.033611      0.187129     -0.0146336   -0.172251     0.164875     0.0549346    0.12298      0.0199733    -0.0637489  -0.00324303  -0.0296405    0.19542      0.0315322    0.00766125   0.107132    -0.000776917  -0.145555     0.234835      0.0312132
 -0.107887    -0.159035     -0.0567523    0.0598212  -0.0262452     0.0606816  -0.10426     -0.0878166    -0.106577      0.222475     0.0505835    0.145447    -0.0344492    0.0936299    0.0456281     0.0183242  -0.0769057    0.0223176   -0.0429843   -0.273715     0.0697313    0.120582    -0.0549606     0.0647715   -0.0953766    -0.0475932
  0.0311813   -0.0500936     0.0507386   -0.0983932  -0.138892     -0.0799779  -0.0582429   -0.0369108     0.0165596     0.170198     0.00456815   0.102289    -0.0378763    0.0113195   -0.0169377     0.0661628   0.0553331    0.0907496   -0.0460269    0.0605623    0.192602     0.00846349   0.0725652    -0.0960557    0.101141      0.0580434
  0.0470194    0.0489998    -0.0533561   -0.0359777  -0.116846     -0.205144   -0.0420189    0.0426076    -0.0249691     0.0494877   -0.017681    -0.195495    -0.160898    -0.10526      0.010443     -0.1109     -0.125601    -0.00733722   0.128327    -0.0304021    0.0455956   -0.0164284   -0.21322      -0.0235503   -0.0929568     0.000671452
  0.0270476    0.0647085    -0.0277365    0.140168    0.141791      0.239484   -0.0780003   -0.200366     -0.0620529    -0.0672199    0.0575021   -0.145033     0.0831794   -0.210785    -0.0134107     0.0139205  -0.146663     0.187676     0.00888772  -0.0514597   -0.0770716   -0.0305748    0.0359496    -0.00788833  -0.184478      0.139686
 -0.025038    -0.0594122     0.0706067   -0.0444389  -0.0950302    -0.0119426   0.0271002    0.188435     -0.000879465   0.229515     0.0378796   -0.108739    -0.115404    -0.0548553   -0.0317292     0.094795   -0.0955813   -0.027308    -0.213626     0.049289     0.0569697   -0.092166     0.175127     -0.0144823   -0.215737      0.0645764
 -0.0744714   -0.115611      0.0922878    0.0149177  -0.0563906     0.200477   -0.101667    -0.0760836     0.127128      0.178715    -0.0175821    0.0915917    0.0179154   -0.119711    -0.165888      0.0788997  -0.0133388    0.0328826    0.102861     0.154212    -0.10241      0.0604318    0.0844927    -0.0693679    0.00301701   -0.262017
 -0.0197398   -0.0563961     0.104436    -0.0205104  -0.0657266    -0.029918    0.0609452    0.0808933     0.0300771    -0.159528    -0.00784434   0.0730584    0.151803    -0.170594    -0.0243236    -0.0648036   0.184445    -0.06343      0.154477     0.0445795    0.13643     -0.197721     0.0311487     0.0113996   -0.068478     -0.188454
 -0.0361178    0.0473526     0.152803    -0.418268   -0.0264546    -0.110182    0.00684121   0.0274827    -0.0104012     0.0141888    0.247637    -0.118786     0.0601508   -0.0350489   -0.0183997     0.470656    0.106553     0.130002    -0.0720049    0.133787     0.104423     0.0458493    0.0831284     0.107696    -0.0860384     0.269366
  0.0115415   -0.0701056    -0.270371     0.312473   -0.0333172     0.0180042   0.00683851  -0.142798     -0.296376     -0.00415311   0.154076    -0.0319111    0.0598052    0.132704    -0.018392     -0.0271828   0.114626     0.0621091   -0.129566     0.00273494   0.110748    -0.185009    -0.0305024     0.099371    -0.0180611    -0.277434
 -0.028707    -0.0250609     0.0397456   -0.0168371   0.0723497    -0.110929   -0.0389146   -0.0574671     0.0286868    -0.0252752    0.0300038   -0.166626     0.108165     0.11314     -0.0324335    -0.184519   -0.019887    -0.014206     0.00141139  -0.0266853   -0.136322     0.0222747   -0.058802     -0.0977536    0.153332     -0.034588
  0.00337301  -0.00278361   -0.0478431   -0.0655482   0.000948416  -0.0790211  -0.0342585   -0.0723784     0.0704546    -0.0588431   -0.0264373   -0.375639     0.118382     0.0618094   -0.0675005    -0.0413281  -0.0382397   -0.0212822    0.00190348  -0.0278759   -0.141336    -0.0563204   -0.0185184    -0.0642623   -0.156193     -0.0119206
  0.0196094    0.0196519    -0.0107035   -0.0197708   0.0913161     0.0270734  -0.0528964    0.047149      0.00437704   -0.0379475   -0.105226     0.259886     0.101448    -0.109366    -0.101626     -0.183064   -0.0190227    0.00509699   0.059985    -0.0558614   -0.11173     -0.00196479  -0.134743     -0.0637723    0.0220532     0.163439
  0.0277709   -0.196128     -0.0208501   -0.0557327  -0.107269      0.123438   -0.0356103   -0.0478609    -0.0725802     0.0406404    0.0917305    0.0468778   -0.00721049   0.0377617    0.033391      0.213986   -0.116817    -0.00477379   0.0619006   -0.0579965    0.075776     0.168688     0.0665643     0.161768    -0.0747175     0.137844
 -0.0287229   -0.147253      0.070533     0.0820793  -0.125678     -0.0215777  -0.0177649   -0.000232202  -0.150601      0.0298234   -0.466982    -0.271055     0.206619     0.00243124   0.113917      0.0713809  -0.0139011    0.0477743   -0.0735364    0.0284925   -0.182205     0.320115    -0.00555633    0.084392    -0.0569835    -0.134601
 -0.0255265   -0.14895       0.146443     0.0433157  -0.112358     -0.0527391   0.131465    -0.0247664    -0.141255     -0.0191847    0.639815    -0.224406     0.251109     0.0169741    0.112284      0.0393689  -0.0091709    0.0659784    0.00167105   0.0249633    0.141715     0.0189288   -0.0849609     0.078879    -0.0634619    -0.126376[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     15
â”‚     19
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.101345
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚      7
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.062216
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      4
â”‚      6
â”‚      â‹®
â”‚     23
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.070552
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚      7
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.081637
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚     15
â”‚     19
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.074365
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    17-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      4
â”‚      6
â”‚      â‹®
â”‚     26
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.039021
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚     10
â”‚      â‹®
â”‚     23
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.090418
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚      7
â”‚      â‹®
â”‚     26
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.066897
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      4
â”‚      6
â”‚      â‹®
â”‚     22
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.068155
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      6
â”‚      7
â”‚      â‹®
â”‚     26
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.074033
â”Œ Info: EM with 100000 data points 10 iterations avll -1.074033
â”” 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.124689e+05
      1       7.468861e+05      -1.655828e+05 |       32
      2       7.028055e+05      -4.408054e+04 |       32
      3       6.785370e+05      -2.426854e+04 |       32
      4       6.676952e+05      -1.084182e+04 |       32
      5       6.635362e+05      -4.158960e+03 |       32
      6       6.613311e+05      -2.205135e+03 |       32
      7       6.593348e+05      -1.996281e+03 |       32
      8       6.577729e+05      -1.561936e+03 |       32
      9       6.570886e+05      -6.842400e+02 |       32
     10       6.565479e+05      -5.406845e+02 |       32
     11       6.560514e+05      -4.965543e+02 |       32
     12       6.557725e+05      -2.789057e+02 |       32
     13       6.555864e+05      -1.860980e+02 |       32
     14       6.554420e+05      -1.443954e+02 |       32
     15       6.553253e+05      -1.167216e+02 |       32
     16       6.552175e+05      -1.077606e+02 |       32
     17       6.551216e+05      -9.588707e+01 |       32
     18       6.550253e+05      -9.629709e+01 |       32
     19       6.549232e+05      -1.021403e+02 |       32
     20       6.547921e+05      -1.311297e+02 |       31
     21       6.546508e+05      -1.412731e+02 |       32
     22       6.544846e+05      -1.661583e+02 |       32
     23       6.542679e+05      -2.167209e+02 |       32
     24       6.539714e+05      -2.965473e+02 |       32
     25       6.535828e+05      -3.886030e+02 |       31
     26       6.531073e+05      -4.754096e+02 |       31
     27       6.525445e+05      -5.628270e+02 |       31
     28       6.521267e+05      -4.178283e+02 |       32
     29       6.519162e+05      -2.105152e+02 |       32
     30       6.517816e+05      -1.345865e+02 |       32
     31       6.516830e+05      -9.860178e+01 |       31
     32       6.516041e+05      -7.891191e+01 |       32
     33       6.515171e+05      -8.697924e+01 |       31
     34       6.514104e+05      -1.066723e+02 |       31
     35       6.512806e+05      -1.298550e+02 |       31
     36       6.510993e+05      -1.812810e+02 |       31
     37       6.508777e+05      -2.215751e+02 |       31
     38       6.506611e+05      -2.165622e+02 |       31
     39       6.504999e+05      -1.612903e+02 |       31
     40       6.503968e+05      -1.030462e+02 |       31
     41       6.503291e+05      -6.774491e+01 |       31
     42       6.502879e+05      -4.111928e+01 |       31
     43       6.502656e+05      -2.235895e+01 |       31
     44       6.502492e+05      -1.635256e+01 |       30
     45       6.502350e+05      -1.420456e+01 |       31
     46       6.502241e+05      -1.096355e+01 |       29
     47       6.502154e+05      -8.678354e+00 |       29
     48       6.502091e+05      -6.287052e+00 |       22
     49       6.502047e+05      -4.387463e+00 |       22
     50       6.502000e+05      -4.728767e+00 |       26
K-means terminated without convergence after 50 iterations (objv = 650199.9837792821)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.345932
[ Info: iteration 2, average log likelihood -1.308111
[ Info: iteration 3, average log likelihood -1.272260
[ Info: iteration 4, average log likelihood -1.233879
[ Info: iteration 5, average log likelihood -1.188777
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚     15
â”‚     21
â”‚     24
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.138938
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚      6
â”‚      7
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.167187
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     14
â”‚     16
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.140733
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚     15
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.128110
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      5
â”‚     21
â”‚     24
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.120148
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      6
â”‚      7
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.148279
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     14
â”‚     15
â”‚     16
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.118903
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     17
â”‚     26
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.136412
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚     21
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.122985
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.132219
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚     14
â”‚     19
â”‚     26
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.107923
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     16
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.132739
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚     21
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.111898
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      6
â”‚     15
â”‚     20
â”‚     24
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.113252
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      5
â”‚     13
â”‚     14
â”‚     19
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.111520
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     16
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.144312
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚     21
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.128351
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     15
â”‚     24
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.125931
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     13
â”‚     14
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.101717
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     19
â”‚     20
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.100741
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     15
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.155095
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      6
â”‚     24
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.128316
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     13
â”‚     14
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.131267
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.114341
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      5
â”‚     15
â”‚     16
â”‚     17
â”‚     19
â”‚     20
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.092663
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚     24
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.122641
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚     13
â”‚     14
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.133195
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     4
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.154923
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     15
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.102209
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      5
â”‚     16
â”‚     21
â”‚     24
â”‚     26
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.061062
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     13
â”‚     14
â”‚     17
â”‚     20
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.134392
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.168754
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.140204
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.087839
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     13
â”‚      â‹®
â”‚     24
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.059818
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      6
â”‚     17
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.162385
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.155735
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     15
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.131035
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.110671
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚     14
â”‚     16
â”‚     19
â”‚      â‹®
â”‚     26
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.070315
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚     15
â”‚     17
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.136713
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      4
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.155276
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚      6
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.131494
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚     19
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.103363
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     14
â”‚     15
â”‚     16
â”‚     21
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.085384
â”Œ Info: EM with 100000 data points 50 iterations avll -1.085384
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0192387   -0.00579207   -0.0377532  -0.0652003   -0.0102079   -0.0809822   -0.0378488    -0.0772355    0.0648238    -0.0565802   -0.0288015   -0.380192    0.119639     0.07176     -0.0681835   -0.0606393  -0.0366795   -0.025781     0.0019861   -0.029036    -0.144217    -0.0537258   -0.0207375   -0.0636407   -0.145335    -0.0160783
  0.0400807   -0.0425873     0.0563864  -0.0952638   -0.148242    -0.0795472   -0.0600425    -0.0383706    0.0294669     0.155611    -0.0171822    0.0992312  -0.0538175    0.0126183   -0.0113275    0.0553246   0.0535527    0.0894016   -0.0179261    0.0776892    0.190522     0.0151986    0.1047      -0.103397     0.11274      0.0449257
 -0.00798784  -0.0209163    -0.0999596   0.00660334  -0.0307947   -0.0322072    0.00717194   -0.0749944   -0.185014      0.00145502   0.194713    -0.0672723   0.0593858    0.0702615   -0.0177491    0.165813    0.1111       0.087424    -0.109273     0.0537815    0.108936    -0.095217     0.0146419    0.103095    -0.0499623   -0.0606437
  0.132176     0.0844167     0.112646   -0.00226198   0.0242108   -0.14185     -0.0196128    -0.0128821    0.0768977    -0.0258703    0.0975146   -0.203791   -0.0923823   -0.0835677   -0.231806    -0.127985    0.100301    -0.161235     0.00627763  -0.0688374   -0.0805442   -0.0713872    0.00235491  -0.0133461    0.03238     -0.0885433
  0.168193     0.0412802     0.112282    0.139638     0.303161     0.17103      0.0199003    -0.00939831   0.161935      0.149039     0.069446     0.1497     -0.0116067    0.011252    -0.0360682   -0.0621885  -0.24324      0.017363     0.0225972   -0.0450439   -0.0872774   -0.0889866   -0.0820148    0.0787779    0.0943212   -0.0595637
 -0.0327292   -0.061004      0.0952117  -0.0293248   -0.054707     0.236186    -0.115726     -0.0611524    0.201756      0.264834     0.00376024   0.0823138   0.00825396  -0.119058    -0.139807     0.0869058  -0.0117499    0.0214824    0.0873191    0.207475    -0.136599     0.100982     0.228547    -0.120397    -0.00871827  -0.185935
 -0.0781125    0.147719     -0.0160192   0.0542946   -0.0674553   -0.140469    -0.0466252    -0.200941    -0.0169759     0.0598728    0.0951119    0.011314    0.0508279    0.00923988   0.0581878   -0.0813717  -0.117658    -0.0129386    0.0555371   -0.0220986    0.010691     0.146644     0.00705044   0.0369448   -0.042729     0.238423
 -0.178181    -0.0810328    -0.0190275  -0.0941436    0.0319702   -0.0131887   -0.00990936   -0.0934637   -0.146887      0.244038     0.224305     0.0329986   0.00771123  -0.0846734   -0.0422513    0.216086   -0.100102    -0.0533242   -0.224529    -0.145226    -0.0753401    0.0728401   -0.190629     0.0324756   -0.125266    -0.022515
 -0.0320923   -0.0622089    -0.0802072   0.12665      0.125671     0.0967231   -0.052562      0.106476    -0.0679313    -0.102092     0.0148113   -0.0173387  -0.224307    -0.0681462   -0.0305557    0.0117147  -0.047612     0.0323542    0.198542     0.00288429  -0.00330837   0.142162    -0.0323266   -0.117883    -0.0179308    0.0225011
 -0.0268416   -0.147887      0.108469    0.0623302   -0.119135    -0.0374609    0.0585433    -0.0129752   -0.145857      0.00544145   0.0871424   -0.247522    0.229203     0.00970222   0.112676     0.0548856  -0.0117478    0.056832    -0.0355353    0.0268347   -0.0193458    0.169319    -0.0434964    0.0813296   -0.0592335   -0.130559
  0.026498     0.0601395    -0.0322423   0.135656     0.134084     0.241652    -0.0791893    -0.199125    -0.0580503    -0.061361     0.0559449   -0.142378    0.0742845   -0.210905    -0.0152006    0.019437   -0.152102     0.184076     0.0132707   -0.0429209   -0.0779669   -0.0294479    0.0388493   -0.00759165  -0.182886     0.127048
  0.0502827   -0.00197521   -0.104607    0.0175971    0.00492165  -0.014075     0.0532284     0.201966    -0.132694     -0.0383224   -0.105821     0.083695   -0.115876    -0.0575453    0.127362    -0.0916623   0.131633     0.0982669   -0.101878    -0.0286667    0.133753     0.137368    -0.174768     0.0493492   -0.245888    -0.0290589
 -0.0239896    0.017888      0.031677    0.0168803   -0.122755    -0.0783701   -0.000134784  -0.0199403    0.0966894    -0.0557438   -0.0104556   -0.0851664  -0.106525    -0.0643634    0.0530519   -0.123915   -0.0597497   -0.00148206   0.0910329   -0.0279843   -0.0043035   -0.284584    -0.118814     0.122073     0.170572     0.00209284
 -0.0272331   -0.0602732     0.0702154  -0.0462072   -0.0950375   -0.0100445    0.0287603     0.189823    -0.000969862   0.230305     0.038704    -0.109567   -0.115129    -0.0542616   -0.0307387    0.0937847  -0.0958273   -0.0273774   -0.215356     0.0502742    0.0573309   -0.0911775    0.179408    -0.00956822  -0.216938     0.0639537
 -0.00672259   0.0232898     0.0887035  -0.0672006    0.120981    -0.0227314    0.000303095  -0.0221189    0.0346135     0.0725585   -0.00913205  -0.140754    0.0828426    0.0987212   -0.085682    -0.169016    0.0347974    0.0530324   -0.0486391   -0.0261798    0.08711     -0.0994393   -0.126675    -0.200568     0.0985581   -0.123105
 -0.163095    -0.0299055     0.0216014   0.012867     0.124911    -0.186609    -0.0417946     0.162992    -0.00105483    0.0745743    0.0657446    0.0859724   0.112058     0.116186     0.0714303    0.0832595  -0.0886955    0.235988     0.0687848    0.00422838  -0.0419205    0.069676    -0.0678443    0.0924386    0.0840603    0.0445593
 -0.138054     0.197495      0.0853262   0.142902     0.194136     0.0745445    0.0259474    -0.0463279   -0.0168788    -0.0736149   -0.173681    -0.0334312  -0.0330053    0.0834711    0.156654    -0.0269816   0.0228389   -0.0477913   -0.0750521    0.00549446   0.0546569    0.0526663    0.0294316    0.164652    -0.0518814    0.0668202
 -0.190402     0.0389486     0.1488      0.0922643    0.0297477    0.0770981   -0.0351512     0.0432096   -0.0587144     0.0163085    0.0833386    0.129858    0.0121079    0.0344598   -0.00122413  -0.140555   -0.17884     -0.111393    -0.165164     0.0580833   -0.0994572   -0.00281396   0.150791    -0.117216     0.181549     0.0887395
 -0.0462864   -0.048309     -0.0195033   0.0720564   -0.17815     -0.159903     0.0266476    -0.140392     0.0789197    -0.127541     0.095487    -0.0971824  -0.010171     0.0356216    0.0315068    0.0537053   0.146935    -0.100949     0.0857648   -0.0814275   -0.1852      -0.174349    -0.0469914    0.0194587    0.061486    -0.0266946
  0.289748    -0.111837     -0.0630568   0.0142562    0.022671     0.176085    -0.116048     -0.172163    -0.0835963    -0.0124814   -0.0483336    0.0626559  -0.112894     0.0170026    0.00462114  -0.0743296  -0.102802    -0.293999    -0.111956    -0.0232498   -0.0153361   -0.084159    -0.0901377    0.0359498   -0.0404279    0.0584132
 -0.00845316   0.0252152    -0.0420184   0.141014     0.0772689   -0.24324     -0.0513051    -0.168976    -0.0860981    -0.0348288   -0.0690439    0.0130147  -0.240479    -0.00995111   0.163766    -0.0660534  -0.0877265   -0.102616    -0.233833    -0.249663    -0.0323247    0.0119657   -0.151099    -0.144512    -0.256368     0.224634
  0.0202986   -0.0433987    -0.0805591   0.109044    -0.150531    -0.124699     0.0607996     0.0457497   -0.165735     -0.0327207    0.0212626    0.0463102  -0.102218    -0.160073     0.0191137   -0.122615    0.108399    -0.114537    -0.0203103   -0.082453     0.0497167    0.0199329    0.0871421    0.0401153    0.00505379  -0.136774
  0.112763     0.00717783   -0.0337674   0.0354589   -0.0875099   -0.193318    -0.114342      0.0240641    0.0152065    -0.105759    -0.0129878   -0.0528338  -0.0973206   -0.116581    -0.0905597   -0.0383404  -0.0372253    0.0351531    0.0904826   -0.0255974    0.0364808    0.07005     -0.033865    -0.035445     0.00341419   0.0196595
 -0.0230394   -0.0452481    -0.0951651   0.236247    -0.0836141   -0.103938     0.00532355   -0.110866     0.0226873    -0.0891289    0.160442    -0.127906    0.0260025   -0.0149658    0.00892776   0.13482     0.141193    -0.00234927  -0.00951165   0.039867     0.00192866  -0.0512388    0.0341953    0.0558083    0.116166     0.041248
  0.0268854   -0.194279     -0.0276607  -0.0558435   -0.106679     0.124575    -0.034926     -0.0456877   -0.0711923     0.0393852    0.088444     0.0487864  -0.0094938    0.035959     0.0312446    0.21165    -0.117421    -0.00679815   0.06197     -0.0531465    0.0753399    0.168328     0.0664346    0.161657    -0.0735917    0.136367
  0.0220302    0.00654537    0.0132465  -0.0103196    0.0837698    0.0323341   -0.0468758     0.0368009    0.0146275    -0.00718291  -0.0968733    0.25542     0.0958524   -0.106987    -0.104527    -0.171055   -0.0137176    0.0094713    0.0651379   -0.0422525   -0.125463     0.00258573  -0.127095    -0.064212     0.0161058    0.112973
 -0.0220822   -0.0648781     0.105952   -0.0232553   -0.0765676    0.00696487   0.0489569     0.063954     0.0342522    -0.147064    -0.00559644   0.076973    0.149306    -0.166633    -0.0420882   -0.0400011   0.155356    -0.0530614    0.149101     0.0676293    0.121757    -0.171718     0.0424618    0.00342822  -0.0670011   -0.198192
 -0.123509     0.0545166    -0.055832   -0.0557629    0.092735     0.00582575  -0.0288322     0.100479     0.145168     -0.223883     0.140372    -0.0175467  -0.100993    -0.00217744  -0.078245     0.0592163  -0.110586     0.22128     -0.0526328   -0.0139848   -0.0348926   -0.0280565    0.0350872   -0.0683198   -0.199986     0.0154655
  0.0632236   -0.000415143  -0.0645599   0.0262167    0.234741    -0.124935    -0.102343      0.0531866   -0.0839115    -0.0056306   -0.0343745    0.128333   -0.00677319   0.0408534   -0.18242     -0.054079    0.0942227   -0.0768765   -0.192613    -0.0733416   -0.0777606    0.0589569   -0.00161312  -0.0301748    0.0881013    0.0219941
 -0.0747078   -0.0252193     0.10129     0.111758     0.0440801   -0.0351624   -0.122661      0.021287     0.177815      0.0259736   -0.154725     0.160682    0.0547513    0.0788774   -0.0144267   -0.035426   -0.00142949  -0.0158289    0.183535     0.051949    -0.0132909    0.112422     0.00533438  -0.138097     0.206037     0.000566322
  0.038763     0.0546935    -0.0722703  -0.0595223    0.0165687   -0.0469142    0.247981      0.104644    -0.00965034   -0.109708    -0.265227     0.0422401  -0.0741765   -0.0361059   -0.0235104   -0.224273    0.00950539   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
0.0386609    0.0423995   -0.090505     0.101516     0.0054666   -0.0453485   -0.159736     0.149866    -0.00299489
 -0.084937    -0.174726     -0.0685427   0.12371     -0.0474335    0.0846816   -0.150976     -0.0854022   -0.0853953     0.209719    -0.0411213    0.178901   -0.0496789    0.157165     0.0702354   -0.0564853  -0.060517     0.052139     0.0401756   -0.3005       0.120515     0.113618    -0.0257406    0.0759719   -0.0545538   -0.0428838â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚     17
â”‚     20
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.139569
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚     13
â”‚     17
â”‚     20
â”‚     24
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.072255
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     24
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.042801
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      6
â”‚     13
â”‚      â‹®
â”‚     21
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.073471
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚     17
â”‚     20
â”‚     24
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.090731
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     13
â”‚      â‹®
â”‚     26
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.049614
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚     17
â”‚     20
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.083153
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      6
â”‚     13
â”‚      â‹®
â”‚     24
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.052389
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      5
â”‚     15
â”‚     16
â”‚      â‹®
â”‚     20
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.069462
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.076166
â”Œ Info: EM with 100000 data points 10 iterations avll -1.076166
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0762691   0.034569    -0.116599    -0.176328    -0.0713678   -0.0755025   -0.164524     0.0508244     0.0599662    0.0936083    0.150517     0.150208    -0.156836    -0.164319   -0.118109      0.00166434  -0.0210564    0.00748793  -0.067995     0.0744979   -0.101979    -0.0144398   -0.0626403     0.0769634   -0.0896966   -0.0841491
 -0.13322     0.0230848   -0.0793252   -0.112878     0.0422108    0.0445466    0.0548417    0.182302     -0.0481164    0.100437    -0.0849343    0.128481    -0.101157     0.0281779  -0.022759     -0.0521767   -0.0871797    0.034512     0.0272168    0.0742184   -0.128669    -0.0677809   -0.131228      0.048312    -0.0226258    0.0488071
  0.0468895  -0.0352313   -0.0825253   -0.0609037    0.0398944    0.0786286   -0.0769133    0.00511247   -0.0328513    0.17899      0.04428      0.0503543    0.0520531   -0.0286217  -0.0380641     0.0146226    0.106837     0.081965     0.224591     0.194501    -0.017085     0.095313     0.0300576     0.0311243   -0.118039     0.0105905
 -0.0912119  -0.048993    -0.0196807    0.0433543    0.218139    -0.0549601    0.218179    -0.0722777    -0.0677495   -0.00874816  -0.01254      0.0173952    0.0603303   -0.0569528   0.000319601   0.0237287    0.0583515    0.084203     0.00643846  -0.00590322  -0.00301264   0.0730322    0.0141158     0.0109429    0.0433767    0.0193118
  0.108294   -0.0107263   -0.0427275    0.00313077   0.132141     0.0617544   -0.114196    -0.264079     -0.104444    -0.0518495    0.0437857    0.00890168   0.0549241    0.123856   -0.0398739    -0.071479     0.0617522   -0.0433937    0.0331585    0.0783968   -0.159986     0.0388859   -0.00425153    0.0607159   -0.0517229   -0.0456987
  0.170712   -0.11509      0.213079    -0.0876476    0.0359157    0.0855716    0.0939623   -0.0558451     0.105794     0.0106911   -0.104392    -0.0303816   -0.108322    -0.0228609  -0.132921      0.194269    -0.0342101    0.0627154    0.098035    -0.0330842    0.107183     0.0120256   -0.0538868    -0.00507664   0.0232857    0.0868453
 -0.0585834   0.0951794    0.0204669    0.0155787    0.0601727    0.211331    -0.00577611   0.157451     -0.11637      0.00220846  -0.0388897   -0.233645    -0.0670959   -0.242584   -0.107742     -0.0815607   -0.0596087    0.0692313   -0.0101114   -0.0223157   -0.00909865  -0.172832    -0.0164577    -0.127584    -0.0137587   -0.0372827
  0.0226775   0.178084    -0.0609124   -0.0816999    0.0703137    0.134626    -0.0494874   -0.201298     -0.173399    -0.0616455   -0.185867    -0.0440207    0.0663537   -0.0489584   0.218057      0.00586699  -0.0821404    0.0670154   -0.15421      0.0183861    0.0220323    0.0565213    0.0233759    -0.188481     0.0116567   -0.0407744
 -0.0262508  -0.0300666   -0.0946231    0.197383    -0.136297    -0.0413375   -0.0928509    0.082927      0.00354351   0.0627116   -0.0326486   -0.0136063   -0.119883     0.114943    0.0368964    -0.0464337    0.0461892    0.0670787   -0.0435618    0.00460751   0.0556418    0.120111    -0.100472     -0.126538    -0.0293747    0.107814
 -0.0347069   0.134629    -0.0931209   -0.173477     0.00581736  -0.128329    -0.102157    -0.0554753    -0.00685491   0.134575    -0.0018589    0.0999886    0.00646763  -0.129544   -0.149083      0.0170259    0.120542     0.145324    -0.0388668    0.0547464   -0.086468    -0.119449     0.15791      -0.201064     0.0656337   -0.0542765
  0.0849323   0.193394     0.178871     0.0713801    0.0422208   -0.0519495    0.0467884    0.0479022     0.218949    -0.01123      0.127886    -0.0372024    0.0243426   -0.0996318  -0.0671005    -0.120782    -0.218238    -0.172304     0.00800962  -0.128721    -0.109851     0.132694    -0.0184337     0.0960691   -0.0288957    0.115518
 -0.0837456  -0.00446634   0.0079334   -0.00322067   0.10181     -0.0752799    0.145659    -0.0103779     0.00539158  -0.00889478  -0.034071    -0.00241089   0.0328287    0.048858    0.042888     -0.0611189   -0.109255    -0.0957262   -0.140344    -0.154578    -0.0471842    0.010859    -0.171202      0.109924    -0.076349     0.117035
  0.139542   -0.0764136    0.0248257    0.183013    -0.0599164    0.0106426   -0.185605     0.250157      0.0300095   -0.0576766   -0.126907     0.097802    -0.149232     0.0241578  -0.021221      0.0908809    0.0906972   -0.154811    -0.00907314  -0.196288    -0.136578    -0.137026     0.14992      -0.0965543   -0.0252249    0.135322
  0.103056    0.0660453    0.0297536    0.180026     0.00942636   0.00541618  -0.187704     0.0176776    -0.061877    -0.0680938   -0.164412    -0.0466666   -0.0444691    0.233839    0.173822     -0.0365998    0.0312893   -0.0585836   -0.0968356   -0.168197    -0.105521    -0.035874    -0.121403      0.0415613    0.00266929   0.133863
 -0.11581    -0.104728    -0.0186846   -0.0678156   -0.128915    -0.0252477   -0.141445    -0.000623424  -0.15502     -0.0902524    0.0154203   -0.0370908    0.0609695   -0.166343    0.088563      0.0490606   -0.0757929    0.0643564    0.143013    -0.0249523   -0.163368     0.0963153   -0.187816      0.120087     0.00874327   0.287607
 -0.0233725   0.0605213   -0.0192649    0.0872206   -0.0374684    0.0534091   -0.0477895    0.0404303     0.0753136    0.043024    -0.0331629   -0.00928675   0.0365901    0.075229    0.0250787    -0.101834     0.0827772    0.0768169    0.149488    -0.133633    -0.15573     -0.0692591    0.154539     -0.0543354    0.0597814    0.0406769
  0.0229052  -0.0131996   -0.13999     -0.0332094    0.00011451  -0.151438     0.0749123    0.100699      0.047714     0.136588     0.0919081    0.0716817   -0.108567     0.133663   -0.172031      0.00996796  -0.145808    -0.0945518    0.156746     0.119995    -0.092422    -0.0205147    0.206248      0.0856721    0.0683234   -0.114217
  0.0358529   0.0204858    0.00978837  -0.109309     0.0852636   -0.272574     0.0163532   -0.0528992     0.0909343    0.0947145    0.0347814   -0.084125    -0.0582184   -0.113342   -0.131382      0.152382    -0.0789313    0.0440354    0.0452799    0.218158     0.0508919   -0.13643     -0.102838     -0.204014    -0.122767    -0.0630888
  0.0285785  -0.121295    -0.0173547    0.0492569   -0.214281    -0.092739     0.0807351    0.0711743     0.0660774   -0.0945714   -0.049064     0.168368     0.0177449    0.0249041   0.116525     -0.135067    -0.0606263   -0.111506    -0.0206021   -0.0610288   -0.0951356    0.0302262    0.000586482  -0.0479928    0.033522    -0.173364
  0.0925926  -0.0676186    0.00942795   0.0646527   -0.0688269   -0.0602248   -0.0640546   -0.220244      0.00490345  -0.202046     0.00281938  -0.0177231   -0.0665329    0.0415151  -0.0404024    -0.112558    -0.0496933    0.00646186  -0.0187833    0.0911513   -0.0840465    0.041985     0.0878594    -0.0943551    0.0762325    0.166863
  0.0140629  -0.177465     0.0533004    0.0155303   -0.0184891   -0.0862113   -0.0575868    0.112824     -0.0612577    0.0768438    0.0919311   -0.0418723   -0.00186869  -0.0747747   0.0157025     0.112189    -0.0288504   -0.0157404   -0.0121719    0.0801613    0.153054     0.147898     0.0190311    -0.0925744   -0.162403     0.0820437
 -0.184864    0.111825    -0.0757211    0.0747402    0.0127971   -0.0563242   -0.0450911    0.0621585     0.130303    -0.143727    -0.128824     0.143296     0.0985876    0.0682943   0.0941138     0.199425    -0.0544009   -0.0645587    0.303902     0.111839    -0.198679     0.145442    -0.0888009     0.0233372    0.118654    -0.0848593
 -0.0749085  -0.064979     0.117089    -0.167439     0.0574899    0.10571     -0.0429724    0.00208396    0.143752     0.121042    -0.0914025   -0.0346427   -0.0339254   -0.0138224   0.0656499    -0.0800328    0.0084791   -0.144691    -0.0696786   -0.0144055   -0.113391     0.103811     0.15875      -0.179816     0.0631131    0.118992
  0.0116482   0.108574    -0.0320357   -0.0956144   -0.209337     0.0291476    0.0485953    0.289821      0.132926    -0.0670463    0.0152799   -0.00731074  -0.0416688    0.140924    0.0187895     0.0755039    0.0109917    0.101016     0.162219    -0.011493     0.145384    -0.0963514    0.0877673     0.016387     0.0350028   -0.0643731
  0.126521    0.0639663   -0.0777965    0.0196312    0.00140362   0.0732398    0.0135342    0.14404      -0.0153293   -0.0251526   -0.0564656    0.100203     0.0247222    0.0759688   0.127376     -0.00467211   0.0681954    0.210556    -0.14325     -0.0284083   -0.0461267   -0.0642262    0.0779821     0.0875237   -0.0482991    0.120963
 -0.0841119  -0.0786538   -0.0817433   -0.108929    -0.0384392   -0.184341    -0.0654882   -0.276782      0.0270478   -0.0494405   -0.10119     -0.105053    -0.0570455    0.0879552  -0.115523     -0.0630813    0.0730395    0.0616417   -0.0991507   -0.0803981   -0.108212    -0.00425356  -0.00925889    0.0201085    0.155794    -0.112084
  0.311287    0.0684831   -0.0840174    0.0679197    0.0219325   -0.0851344    0.018393     0.0270443     0.101428     0.0552615    0.0509428    0.0044965   -0.108374    -0.0273022   0.00503987   -0.142104    -0.0425274   -0.138362    -0.174152    -0.0354261   -0.192073     0.106973     0.169868      0.0518038    0.0889083   -0.0792326
  0.0378825   0.0701663   -0.00117184   0.0649899   -0.089431     0.0749457   -0.157271    -0.153095     -0.0955286   -0.114793    -0.0295893    0.0494991    0.0802574    0.164127    0.0588974    -0.0896136    0.00766592   0.151151     0.0092977    0.133313    -0.0589844   -0.121147     0.0788247     0.039285    -0.0178515    0.210391
 -0.0199221   0.153471    -0.10599      0.0196787   -0.0893869    0.0486194   -0.0582325   -0.0236226     0.0935702   -0.0434186   -0.0728054    0.0772715   -0.13611     -0.0687779  -0.0759291    -0.0370359    0.0591602    0.0589495   -0.0868937   -0.0764326   -0.127018    -0.00856976  -0.152848      0.0749068    0.0671195    0.126289
 -0.0504211   0.00727052  -0.0555107   -0.142732    -0.0219261    0.044706    -0.032816     0.00126881   -0.0740949    0.0646868    0.130688     0.0201057    0.0351212   -0.0963314   0.134787     -0.101877     0.0203223    0.0809107   -0.160458     0.198751    -0.0438245    0.0218543   -0.14631      -0.127324     0.0337076   -0.197056
  0.0675846  -0.0171363    0.0906654    0.122761     0.00640867  -0.103314    -0.0128617    0.233283     -0.144259     0.103318    -0.0878489   -0.146562     0.145413    -0.0607457   0.12002       0.0966905   -0.137442    -0.063697     0.0738351    0.0371084   -0.0835625    0.158429     0.262271     -0.010576     0.0372779   -0.133351
 -0.0414852   0.0373474    0.107928     0.0472117   -0.151147    -0.0988467   -0.116224     0.0644316     0.0959576   -0.0691311    0.117339    -0.0147753   -0.0190224   -0.210662   -0.0322752    -0.0176089    0.0148752    0.0415691   -0.170069     0.0243055    0.0698503   -0.0865914   -0.011371     -0.221942    -0.00700519   0.141335kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4216365828654445
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421656
[ Info: iteration 2, average log likelihood -1.421617
[ Info: iteration 3, average log likelihood -1.421599
[ Info: iteration 4, average log likelihood -1.421580
[ Info: iteration 5, average log likelihood -1.421559
[ Info: iteration 6, average log likelihood -1.421531
[ Info: iteration 7, average log likelihood -1.421495
[ Info: iteration 8, average log likelihood -1.421446
[ Info: iteration 9, average log likelihood -1.421379
[ Info: iteration 10, average log likelihood -1.421291
[ Info: iteration 11, average log likelihood -1.421176
[ Info: iteration 12, average log likelihood -1.421029
[ Info: iteration 13, average log likelihood -1.420840
[ Info: iteration 14, average log likelihood -1.420589
[ Info: iteration 15, average log likelihood -1.420236
[ Info: iteration 16, average log likelihood -1.419731
[ Info: iteration 17, average log likelihood -1.419042
[ Info: iteration 18, average log likelihood -1.418228
[ Info: iteration 19, average log likelihood -1.417452
[ Info: iteration 20, average log likelihood -1.416871
[ Info: iteration 21, average log likelihood -1.416514
[ Info: iteration 22, average log likelihood -1.416322
[ Info: iteration 23, average log likelihood -1.416225
[ Info: iteration 24, average log likelihood -1.416177
[ Info: iteration 25, average log likelihood -1.416153
[ Info: iteration 26, average log likelihood -1.416141
[ Info: iteration 27, average log likelihood -1.416135
[ Info: iteration 28, average log likelihood -1.416132
[ Info: iteration 29, average log likelihood -1.416130
[ Info: iteration 30, average log likelihood -1.416129
[ Info: iteration 31, average log likelihood -1.416128
[ Info: iteration 32, average log likelihood -1.416128
[ Info: iteration 33, average log likelihood -1.416127
[ Info: iteration 34, average log likelihood -1.416127
[ Info: iteration 35, average log likelihood -1.416127
[ Info: iteration 36, average log likelihood -1.416127
[ Info: iteration 37, average log likelihood -1.416126
[ Info: iteration 38, average log likelihood -1.416126
[ Info: iteration 39, average log likelihood -1.416126
[ Info: iteration 40, average log likelihood -1.416126
[ Info: iteration 41, average log likelihood -1.416126
[ Info: iteration 42, average log likelihood -1.416125
[ Info: iteration 43, average log likelihood -1.416125
[ Info: iteration 44, average log likelihood -1.416125
[ Info: iteration 45, average log likelihood -1.416125
[ Info: iteration 46, average log likelihood -1.416125
[ Info: iteration 47, average log likelihood -1.416125
[ Info: iteration 48, average log likelihood -1.416125
[ Info: iteration 49, average log likelihood -1.416125
[ Info: iteration 50, average log likelihood -1.416125
â”Œ Info: EM with 100000 data points 50 iterations avll -1.416125
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4216555408769533
â”‚     -1.4216166289840602
â”‚      â‹®
â””     -1.4161247587303416
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416140
[ Info: iteration 2, average log likelihood -1.416068
[ Info: iteration 3, average log likelihood -1.416001
[ Info: iteration 4, average log likelihood -1.415916
[ Info: iteration 5, average log likelihood -1.415808
[ Info: iteration 6, average log likelihood -1.415680
[ Info: iteration 7, average log likelihood -1.415546
[ Info: iteration 8, average log likelihood -1.415422
[ Info: iteration 9, average log likelihood -1.415314
[ Info: iteration 10, average log likelihood -1.415222
[ Info: iteration 11, average log likelihood -1.415140
[ Info: iteration 12, average log likelihood -1.415062
[ Info: iteration 13, average log likelihood -1.414989
[ Info: iteration 14, average log likelihood -1.414921
[ Info: iteration 15, average log likelihood -1.414860
[ Info: iteration 16, average log likelihood -1.414807
[ Info: iteration 17, average log likelihood -1.414764
[ Info: iteration 18, average log likelihood -1.414728
[ Info: iteration 19, average log likelihood -1.414698
[ Info: iteration 20, average log likelihood -1.414674
[ Info: iteration 21, average log likelihood -1.414654
[ Info: iteration 22, average log likelihood -1.414637
[ Info: iteration 23, average log likelihood -1.414623
[ Info: iteration 24, average log likelihood -1.414611
[ Info: iteration 25, average log likelihood -1.414601
[ Info: iteration 26, average log likelihood -1.414592
[ Info: iteration 27, average log likelihood -1.414584
[ Info: iteration 28, average log likelihood -1.414578
[ Info: iteration 29, average log likelihood -1.414572
[ Info: iteration 30, average log likelihood -1.414567
[ Info: iteration 31, average log likelihood -1.414562
[ Info: iteration 32, average log likelihood -1.414558
[ Info: iteration 33, average log likelihood -1.414554
[ Info: iteration 34, average log likelihood -1.414551
[ Info: iteration 35, average log likelihood -1.414548
[ Info: iteration 36, average log likelihood -1.414545
[ Info: iteration 37, average log likelihood -1.414542
[ Info: iteration 38, average log likelihood -1.414540
[ Info: iteration 39, average log likelihood -1.414537
[ Info: iteration 40, average log likelihood -1.414535
[ Info: iteration 41, average log likelihood -1.414533
[ Info: iteration 42, average log likelihood -1.414531
[ Info: iteration 43, average log likelihood -1.414530
[ Info: iteration 44, average log likelihood -1.414528
[ Info: iteration 45, average log likelihood -1.414526
[ Info: iteration 46, average log likelihood -1.414525
[ Info: iteration 47, average log likelihood -1.414524
[ Info: iteration 48, average log likelihood -1.414522
[ Info: iteration 49, average log likelihood -1.414521
[ Info: iteration 50, average log likelihood -1.414520
â”Œ Info: EM with 100000 data points 50 iterations avll -1.414520
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.416139898493729
â”‚     -1.4160679169979924
â”‚      â‹®
â””     -1.4145199851747954
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414535
[ Info: iteration 2, average log likelihood -1.414493
[ Info: iteration 3, average log likelihood -1.414469
[ Info: iteration 4, average log likelihood -1.414445
[ Info: iteration 5, average log likelihood -1.414417
[ Info: iteration 6, average log likelihood -1.414386
[ Info: iteration 7, average log likelihood -1.414350
[ Info: iteration 8, average log likelihood -1.414308
[ Info: iteration 9, average log likelihood -1.414261
[ Info: iteration 10, average log likelihood -1.414210
[ Info: iteration 11, average log likelihood -1.414154
[ Info: iteration 12, average log likelihood -1.414097
[ Info: iteration 13, average log likelihood -1.414041
[ Info: iteration 14, average log likelihood -1.413987
[ Info: iteration 15, average log likelihood -1.413937
[ Info: iteration 16, average log likelihood -1.413891
[ Info: iteration 17, average log likelihood -1.413849
[ Info: iteration 18, average log likelihood -1.413810
[ Info: iteration 19, average log likelihood -1.413774
[ Info: iteration 20, average log likelihood -1.413738
[ Info: iteration 21, average log likelihood -1.413702
[ Info: iteration 22, average log likelihood -1.413666
[ Info: iteration 23, average log likelihood -1.413628
[ Info: iteration 24, average log likelihood -1.413590
[ Info: iteration 25, average log likelihood -1.413551
[ Info: iteration 26, average log likelihood -1.413511
[ Info: iteration 27, average log likelihood -1.413472
[ Info: iteration 28, average log likelihood -1.413433
[ Info: iteration 29, average log likelihood -1.413395
[ Info: iteration 30, average log likelihood -1.413359
[ Info: iteration 31, average log likelihood -1.413324
[ Info: iteration 32, average log likelihood -1.413291
[ Info: iteration 33, average log likelihood -1.413260
[ Info: iteration 34, average log likelihood -1.413231
[ Info: iteration 35, average log likelihood -1.413204
[ Info: iteration 36, average log likelihood -1.413179
[ Info: iteration 37, average log likelihood -1.413154
[ Info: iteration 38, average log likelihood -1.413132
[ Info: iteration 39, average log likelihood -1.413110
[ Info: iteration 40, average log likelihood -1.413090
[ Info: iteration 41, average log likelihood -1.413071
[ Info: iteration 42, average log likelihood -1.413053
[ Info: iteration 43, average log likelihood -1.413036
[ Info: iteration 44, average log likelihood -1.413020
[ Info: iteration 45, average log likelihood -1.413005
[ Info: iteration 46, average log likelihood -1.412991
[ Info: iteration 47, average log likelihood -1.412978
[ Info: iteration 48, average log likelihood -1.412966
[ Info: iteration 49, average log likelihood -1.412955
[ Info: iteration 50, average log likelihood -1.412945
â”Œ Info: EM with 100000 data points 50 iterations avll -1.412945
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.414534820525056
â”‚     -1.414493381860075
â”‚      â‹®
â””     -1.4129447311357164
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412946
[ Info: iteration 2, average log likelihood -1.412887
[ Info: iteration 3, average log likelihood -1.412832
[ Info: iteration 4, average log likelihood -1.412771
[ Info: iteration 5, average log likelihood -1.412698
[ Info: iteration 6, average log likelihood -1.412610
[ Info: iteration 7, average log likelihood -1.412509
[ Info: iteration 8, average log likelihood -1.412399
[ Info: iteration 9, average log likelihood -1.412283
[ Info: iteration 10, average log likelihood -1.412168
[ Info: iteration 11, average log likelihood -1.412059
[ Info: iteration 12, average log likelihood -1.411958
[ Info: iteration 13, average log likelihood -1.411868
[ Info: iteration 14, average log likelihood -1.411789
[ Info: iteration 15, average log likelihood -1.411720
[ Info: iteration 16, average log likelihood -1.411660
[ Info: iteration 17, average log likelihood -1.411608
[ Info: iteration 18, average log likelihood -1.411563
[ Info: iteration 19, average log likelihood -1.411524
[ Info: iteration 20, average log likelihood -1.411490
[ Info: iteration 21, average log likelihood -1.411459
[ Info: iteration 22, average log likelihood -1.411432
[ Info: iteration 23, average log likelihood -1.411408
[ Info: iteration 24, average log likelihood -1.411385
[ Info: iteration 25, average log likelihood -1.411364
[ Info: iteration 26, average log likelihood -1.411344
[ Info: iteration 27, average log likelihood -1.411325
[ Info: iteration 28, average log likelihood -1.411307
[ Info: iteration 29, average log likelihood -1.411290
[ Info: iteration 30, average log likelihood -1.411274
[ Info: iteration 31, average log likelihood -1.411257
[ Info: iteration 32, average log likelihood -1.411242
[ Info: iteration 33, average log likelihood -1.411227
[ Info: iteration 34, average log likelihood -1.411212
[ Info: iteration 35, average log likelihood -1.411198
[ Info: iteration 36, average log likelihood -1.411184
[ Info: iteration 37, average log likelihood -1.411170
[ Info: iteration 38, average log likelihood -1.411157
[ Info: iteration 39, average log likelihood -1.411144
[ Info: iteration 40, average log likelihood -1.411132
[ Info: iteration 41, average log likelihood -1.411119
[ Info: iteration 42, average log likelihood -1.411108
[ Info: iteration 43, average log likelihood -1.411096
[ Info: iteration 44, average log likelihood -1.411085
[ Info: iteration 45, average log likelihood -1.411075
[ Info: iteration 46, average log likelihood -1.411064
[ Info: iteration 47, average log likelihood -1.411054
[ Info: iteration 48, average log likelihood -1.411045
[ Info: iteration 49, average log likelihood -1.411035
[ Info: iteration 50, average log likelihood -1.411026
â”Œ Info: EM with 100000 data points 50 iterations avll -1.411026
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4129458220608084
â”‚     -1.4128865131818085
â”‚      â‹®
â””     -1.4110261440038376
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411026
[ Info: iteration 2, average log likelihood -1.410964
[ Info: iteration 3, average log likelihood -1.410903
[ Info: iteration 4, average log likelihood -1.410830
[ Info: iteration 5, average log likelihood -1.410734
[ Info: iteration 6, average log likelihood -1.410612
[ Info: iteration 7, average log likelihood -1.410460
[ Info: iteration 8, average log likelihood -1.410287
[ Info: iteration 9, average log likelihood -1.410104
[ Info: iteration 10, average log likelihood -1.409923
[ Info: iteration 11, average log likelihood -1.409754
[ Info: iteration 12, average log likelihood -1.409604
[ Info: iteration 13, average log likelihood -1.409471
[ Info: iteration 14, average log likelihood -1.409356
[ Info: iteration 15, average log likelihood -1.409257
[ Info: iteration 16, average log likelihood -1.409170
[ Info: iteration 17, average log likelihood -1.409094
[ Info: iteration 18, average log likelihood -1.409027
[ Info: iteration 19, average log likelihood -1.408966
[ Info: iteration 20, average log likelihood -1.408912
[ Info: iteration 21, average log likelihood -1.408862
[ Info: iteration 22, average log likelihood -1.408816
[ Info: iteration 23, average log likelihood -1.408773
[ Info: iteration 24, average log likelihood -1.408733
[ Info: iteration 25, average log likelihood -1.408696
[ Info: iteration 26, average log likelihood -1.408662
[ Info: iteration 27, average log likelihood -1.408630
[ Info: iteration 28, average log likelihood -1.408599
[ Info: iteration 29, average log likelihood -1.408571
[ Info: iteration 30, average log likelihood -1.408544
[ Info: iteration 31, average log likelihood -1.408519
[ Info: iteration 32, average log likelihood -1.408495
[ Info: iteration 33, average log likelihood -1.408472
[ Info: iteration 34, average log likelihood -1.408451
[ Info: iteration 35, average log likelihood -1.408431
[ Info: iteration 36, average log likelihood -1.408411
[ Info: iteration 37, average log likelihood -1.408393
[ Info: iteration 38, average log likelihood -1.408375
[ Info: iteration 39, average log likelihood -1.408358
[ Info: iteration 40, average log likelihood -1.408342
[ Info: iteration 41, average log likelihood -1.408326
[ Info: iteration 42, average log likelihood -1.408311
[ Info: iteration 43, average log likelihood -1.408296
[ Info: iteration 44, average log likelihood -1.408282
[ Info: iteration 45, average log likelihood -1.408268
[ Info: iteration 46, average log likelihood -1.408254
[ Info: iteration 47, average log likelihood -1.408241
[ Info: iteration 48, average log likelihood -1.408228
[ Info: iteration 49, average log likelihood -1.408216
[ Info: iteration 50, average log likelihood -1.408203
â”Œ Info: EM with 100000 data points 50 iterations avll -1.408203
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4110264242539734
â”‚     -1.410964060401165
â”‚      â‹®
â””     -1.4082033272570136
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4216365828654445
â”‚     -1.4216555408769533
â”‚     -1.4216166289840602
â”‚     -1.42159858551365
â”‚      â‹®
â”‚     -1.4082281570484443
â”‚     -1.4082156098569674
â””     -1.4082033272570136
32Ã—26 Array{Float64,2}:
  0.274524     0.275631     0.0633089  -0.372797    0.032794     0.000770009  -0.462545    -0.123106     0.113334      0.135762    -0.105034    0.127263   -0.111366    -0.243356   -0.0193801    -0.157818     0.281999    0.167335     0.0442588   -0.208434    -0.306402     0.124105   -0.169106   -0.375182   -0.273278     0.0739137
 -0.00731554  -0.119871    -0.262056   -0.0449289  -0.25753      0.203133     -0.377126     0.230016     0.0499269    -0.0513068   -0.303619    0.080725    0.0283115   -0.397564   -0.112339      0.0715191    0.155663   -0.459474    -0.0439938   -0.0703489   -0.0920881    0.148244    0.393663   -0.0737402  -0.350617     0.449719
 -0.0161043   -0.0369309   -0.0525597  -0.040971    0.154334    -0.144933     -0.0147401    0.00876798   0.0172998     0.0438392   -0.0510414   0.0387895  -0.00549111   0.183988    0.0455087     0.0664485    0.018574    0.00550036  -0.117596     0.172108     0.0511139   -0.0423712  -0.282533    0.104017    0.231816     0.0752277
 -0.0264336    0.0168498    0.16369     0.24906    -0.207551    -0.0211604     0.0879419    0.00754747  -0.000829823   0.0121103    0.0545315  -0.121862   -0.08451     -0.130877    0.0433609     0.047643    -0.0695875   0.134686     0.19455     -0.0539266   -0.00092294   0.108924    0.293867    0.023115   -0.194581    -0.169339
 -0.018357    -0.209376     0.280672   -0.231336    0.437694    -0.53213      -0.627336    -0.0678191   -0.238008     -0.17878      0.0116766   0.0197244  -0.207399     0.0475003  -0.176794      0.660581     0.379491    0.130441    -0.0209325    0.359181     0.0219606   -0.376352   -0.43742    -0.217434    0.746017     0.50128
  0.204585     0.0755197    0.274493   -0.0336084   0.121293    -0.417508     -0.340353     0.354149     0.0891        0.326557    -0.574861    0.0699983  -0.184143     0.428169   -0.163357      0.322198     0.143913    0.243308     0.10088      1.04688      0.438818     0.0856375   0.0586589  -0.021589    0.0951462    0.718032
 -0.299216    -0.288839    -0.449233   -0.0437135   0.148984     0.0708458     0.249413     0.548844     0.0248607    -0.412238    -0.0490783   0.286752    0.234806     0.236864    0.000302321   0.530757    -0.34734    -0.0739626   -0.0984694    0.50525     -0.110154    -0.387703    0.160395   -0.166954    0.203805    -0.113059
 -0.111714     0.044922    -0.0510215  -0.117951    0.140319     0.350806      0.415998     0.454975    -0.322283      0.243154     0.158199    0.202382    0.293873     0.118913   -0.045314      0.223592     0.692482   -0.286727     0.0462534    0.52644     -0.303983    -0.591697    0.233873    0.210565   -0.061354    -0.357632
  0.0521831   -0.00623583  -0.140607    0.276611   -0.475206     0.505708      0.301655    -0.0375513    0.432417      0.034401    -0.100292    0.117866   -0.0621677   -0.0889967   0.10597      -0.536395    -0.463288   -0.167106    -0.215503    -0.680538    -0.119496     0.506692    0.160515   -0.0891325  -0.811858    -0.472508
 -0.152333    -0.266019     0.0336287   0.112234    0.00585522   0.596906      0.463187    -0.684216     0.0862996    -0.323713     0.396412   -0.159795   -0.0640411   -0.499537    0.140745     -0.17928      0.337892   -0.496723     0.163579    -0.743977     0.0724629   -0.139643    0.110519   -0.177019    0.0794134   -0.419245
 -0.0577564    0.325733    -0.127346   -0.281879   -0.803901    -0.512159     -0.041415     0.0524967   -0.00938674   -0.00566743   0.419133   -0.212791    0.146325     0.0103582   0.877277      0.00322757  -0.331775   -0.23598      0.744587    -0.240895    -0.33298      0.768737    0.61613    -0.0618409  -0.20182     -0.225791
 -0.00995318  -0.166714     0.109039    0.319298   -0.136089     0.153369      0.543954     0.399666    -0.608325     -0.545769     0.149749    0.318538   -0.342634     0.211185    0.0227482    -0.160489    -0.323152    0.670301     0.346775    -0.505619    -0.28768      0.207107   -0.0562936   0.186994   -0.0914519   -0.0754912
 -0.0755463    0.105923    -0.0974447   0.0386517  -0.0549666    0.0082729     0.251932    -0.426949     0.236145      0.0038832   -0.360726   -0.542571   -0.256295     0.523534   -0.254188     -0.595539    -0.05375    -0.590195    -0.0520872   -0.610376     0.0940109    0.0791564  -0.0547041   0.270085    0.666086     0.341311
  0.244342    -0.179891    -0.163336    0.323083   -0.484746     0.186298      0.174343    -0.237432    -0.29968      -0.371825    -0.0221955  -0.372379   -0.603191     0.444765   -0.589803     -0.375749     0.0377247  -0.49232     -0.234916     0.289433    -0.192173    -0.689899    0.0350206   0.24796     0.308636     0.0473665
  0.0151545    0.250484     0.103555    0.0972658   0.277394    -0.0178013    -0.0163991   -0.289751    -0.155899      0.232282     0.218773    0.0944303   0.108465    -0.0243619  -0.233766     -0.64829     -0.257103    0.436624    -0.467305     0.0175611    0.0147133   -0.0928021  -0.05331    -0.405543    0.613164     0.0492291
  0.0223955    0.202294    -0.471046   -0.243547    0.285669     0.223981      0.357734     0.0250769    0.138906     -0.0470551    0.375683   -0.0341116   0.0675295    0.340867   -0.10129      -0.382414    -0.608104   -0.177743    -0.455644    -0.518455    -0.771248    -0.274637   -0.525171    0.713198    0.127975    -0.306471
  0.740561    -0.0362374   -0.229713   -0.963246    0.011569    -0.265522     -0.90067     -0.367008     0.341475     -0.0461515   -0.032282   -0.0540532  -0.14243      0.274125    0.282266     -0.096623     0.525588   -0.326775     0.0303827   -0.056224    -0.731054     0.020841   -0.407179    0.131952    0.0613573    0.405624
 -0.366972    -0.0494997   -0.227764   -0.838111   -0.0549338    0.491589     -0.129638    -0.308754     0.784705      0.594944    -0.0123926   0.13008     0.326068    -0.829529   -0.242091     -0.349975     0.455268   -0.867387     0.00481978   0.00141141   0.235071    -0.290583    0.309952   -0.133034    1.95551e-5   0.146702
  0.109311     0.0379046   -0.496629    0.316486    0.0021908   -0.082203     -0.163752     0.1078       1.06247       0.396205     0.015384    0.201474   -0.226473     0.631947    0.0936003    -0.19792     -0.503184   -0.512051    -0.678681    -0.188542     0.112488    -0.116503   -0.22692    -0.675436    0.529564     0.154472
 -0.429737    -0.257564     0.244833    0.278493   -0.411007    -0.518403      0.0660955    0.50846      0.659654      0.0872316   -0.0462128  -0.0300703   0.299761    -0.361336    0.0201405     0.525061     0.0583539  -0.25059     -0.42303     -0.0788125    0.860715     0.218795   -0.104806    0.550564   -0.0613294    0.393836
  0.0477615    0.0897064    0.139405    0.048029    0.0535829   -0.098043     -0.322398    -0.0374773   -0.063507      0.0142891   -0.12669     0.0506468  -0.117934    -0.197475   -0.0256338     0.0045442   -0.0624567   0.365474     0.0627395   -0.141351    -0.187415     0.237748    0.0543161  -0.271331   -0.155223     0.0156558
 -0.190488    -0.125102    -0.320939    0.205406   -0.0429058    0.234935      0.608971     0.0720072    0.143568     -0.207462     0.0791333   0.130922    0.0336823    0.395672   -0.125599     -0.0870534    0.0451429  -0.551084    -0.320614     0.121589     0.117874    -0.543624   -0.0317995   0.250537    0.350274     0.022828
 -0.327145    -0.0140268   -0.181489    0.641731    0.0763101    0.441142      0.313628     0.0411686   -0.420268      0.400043     0.244076   -0.731253   -0.220098     0.343197   -0.264289     -0.350194    -0.428517    0.115152     0.498717    -0.240866    -0.0207675   -0.195266    0.328438   -0.173259    0.605016    -0.737125
  0.556322    -0.484109     0.246561   -0.103687    0.265842     0.0484653    -0.220159     0.0257836    0.152534      0.790938    -0.159549   -0.544151   -0.445523     0.463707    0.299815      0.387765     0.208733    0.0282499    0.180293    -0.361289     0.493111     0.406907   -0.41576     0.261885    0.438776    -0.845729
  0.453795     0.0202594    0.439782    0.0840552  -0.0374201   -0.276398     -0.181221     0.121594    -0.00331207   -0.00303953   0.427419    0.448033    0.333432    -0.236734    0.371719      0.292035     0.113037    0.858142     0.11699      0.672891     0.100471    -0.556117   -0.324487   -0.291475   -0.46729     -0.269187
  0.150715    -0.0138924    0.204667   -0.412758    0.551079    -0.230815     -0.127095     0.0724012    0.189726      0.241593     0.164643    0.70078     0.67976     -0.498914    0.771136      0.31133     -0.0375378   0.555678    -0.201446    -0.0684858    0.0693128    0.695451   -0.236357   -0.384714   -0.167214    -0.00653609
 -0.331493     0.468662     0.066426   -0.0889015  -0.0449014   -0.108275      0.109655    -0.0271136    0.0234406    -0.337683     0.0112148   0.754001    0.395574    -0.383286   -0.334483     -0.29755     -0.197942    0.123946    -0.287807     0.441164    -0.586865    -0.122732    0.489392   -0.189336   -0.837546     0.837722
  0.112909     0.734586    -0.0697662  -0.5459      0.277457    -0.192735     -0.00156542  -0.0893297   -0.192226      0.243241    -0.13586     0.418433   -0.294421    -0.488763    0.16704      -0.195156     0.185861    0.70101      0.313108     0.180235    -0.258759     0.726828   -0.313263    0.579284   -0.787012     0.090158
  0.473426     0.0829615    0.55302    -0.323074   -0.360742    -0.146386     -0.284447    -0.219857    -0.293042      0.698557    -0.659909   -0.208027    0.355794     0.705889   -0.336093     -0.329406    -1.32943     0.740281    -0.644673    -0.057443    -0.961793     0.63156     0.499654   -0.194286   -0.287965     0.390669
  0.314472     0.289264     0.147694    0.806024    0.158366    -0.569868     -0.394703     0.418769    -0.390325     -0.650232    -0.327841   -0.511954   -0.357698     0.0863865  -0.0158162     0.134953    -1.01089     0.644055     0.158939    -0.278451     0.274219     0.665804   -0.191284    0.118518    0.128808     0.153166
 -0.32973      0.0484872   -0.919195    0.178743   -0.0633526   -0.147308     -0.626567    -0.370507    -0.227968     -0.424577    -0.248663   -0.460185   -0.100101    -0.0756533   0.400998      0.515647     0.288713   -0.37329      0.701091     0.518252    -0.0575016   -0.39016     0.0106387  -0.114962   -0.195059     0.0681416
  0.029886    -0.0380368    0.706453   -0.180906   -0.196679    -0.15056      -0.266514     0.0140706   -0.655873     -0.279354    -0.143553   -0.271735    0.228398    -0.796379   -0.14943       0.245324     0.595422    0.482844     0.583011     0.108467    -0.0845565    0.314947    0.442738    0.0383414  -0.478521     0.049963[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408191
[ Info: iteration 2, average log likelihood -1.408179
[ Info: iteration 3, average log likelihood -1.408168
[ Info: iteration 4, average log likelihood -1.408156
[ Info: iteration 5, average log likelihood -1.408145
[ Info: iteration 6, average log likelihood -1.408134
[ Info: iteration 7, average log likelihood -1.408123
[ Info: iteration 8, average log likelihood -1.408112
[ Info: iteration 9, average log likelihood -1.408101
[ Info: iteration 10, average log likelihood -1.408091
â”Œ Info: EM with 100000 data points 10 iterations avll -1.408091
â”” 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.388151e+05
      1       7.023904e+05      -2.364247e+05 |       32
      2       6.883622e+05      -1.402819e+04 |       32
      3       6.829235e+05      -5.438697e+03 |       32
      4       6.801791e+05      -2.744366e+03 |       32
      5       6.784987e+05      -1.680405e+03 |       32
      6       6.774096e+05      -1.089160e+03 |       32
      7       6.765020e+05      -9.075834e+02 |       32
      8       6.757662e+05      -7.357397e+02 |       32
      9       6.751575e+05      -6.087242e+02 |       32
     10       6.746460e+05      -5.115206e+02 |       32
     11       6.742322e+05      -4.137982e+02 |       32
     12       6.738852e+05      -3.470507e+02 |       32
     13       6.735809e+05      -3.042908e+02 |       32
     14       6.733289e+05      -2.519592e+02 |       32
     15       6.730991e+05      -2.297804e+02 |       32
     16       6.728759e+05      -2.232545e+02 |       32
     17       6.726763e+05      -1.995824e+02 |       32
     18       6.725073e+05      -1.689849e+02 |       32
     19       6.723472e+05      -1.600821e+02 |       32
     20       6.721791e+05      -1.681369e+02 |       32
     21       6.720137e+05      -1.653640e+02 |       32
     22       6.718675e+05      -1.461721e+02 |       32
     23       6.717290e+05      -1.385935e+02 |       32
     24       6.716020e+05      -1.269840e+02 |       32
     25       6.714857e+05      -1.163087e+02 |       32
     26       6.713737e+05      -1.119760e+02 |       32
     27       6.712740e+05      -9.966739e+01 |       32
     28       6.711880e+05      -8.598313e+01 |       32
     29       6.711134e+05      -7.467580e+01 |       32
     30       6.710526e+05      -6.076615e+01 |       32
     31       6.709954e+05      -5.724016e+01 |       32
     32       6.709376e+05      -5.778861e+01 |       32
     33       6.708672e+05      -7.033160e+01 |       32
     34       6.708028e+05      -6.445908e+01 |       32
     35       6.707356e+05      -6.715063e+01 |       32
     36       6.706731e+05      -6.253023e+01 |       32
     37       6.706186e+05      -5.449452e+01 |       32
     38       6.705665e+05      -5.208849e+01 |       32
     39       6.705205e+05      -4.601817e+01 |       32
     40       6.704755e+05      -4.498473e+01 |       32
     41       6.704404e+05      -3.508173e+01 |       32
     42       6.704053e+05      -3.509169e+01 |       32
     43       6.703774e+05      -2.794765e+01 |       32
     44       6.703483e+05      -2.907938e+01 |       32
     45       6.703212e+05      -2.706225e+01 |       32
     46       6.702953e+05      -2.590523e+01 |       32
     47       6.702693e+05      -2.606504e+01 |       32
     48       6.702478e+05      -2.146350e+01 |       32
     49       6.702298e+05      -1.797347e+01 |       32
     50       6.702115e+05      -1.836268e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 670211.474609084)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420254
[ Info: iteration 2, average log likelihood -1.415248
[ Info: iteration 3, average log likelihood -1.413897
[ Info: iteration 4, average log likelihood -1.412940
[ Info: iteration 5, average log likelihood -1.411958
[ Info: iteration 6, average log likelihood -1.411021
[ Info: iteration 7, average log likelihood -1.410322
[ Info: iteration 8, average log likelihood -1.409898
[ Info: iteration 9, average log likelihood -1.409651
[ Info: iteration 10, average log likelihood -1.409493
[ Info: iteration 11, average log likelihood -1.409377
[ Info: iteration 12, average log likelihood -1.409284
[ Info: iteration 13, average log likelihood -1.409204
[ Info: iteration 14, average log likelihood -1.409134
[ Info: iteration 15, average log likelihood -1.409071
[ Info: iteration 16, average log likelihood -1.409014
[ Info: iteration 17, average log likelihood -1.408962
[ Info: iteration 18, average log likelihood -1.408913
[ Info: iteration 19, average log likelihood -1.408868
[ Info: iteration 20, average log likelihood -1.408827
[ Info: iteration 21, average log likelihood -1.408788
[ Info: iteration 22, average log likelihood -1.408751
[ Info: iteration 23, average log likelihood -1.408717
[ Info: iteration 24, average log likelihood -1.408685
[ Info: iteration 25, average log likelihood -1.408655
[ Info: iteration 26, average log likelihood -1.408627
[ Info: iteration 27, average log likelihood -1.408600
[ Info: iteration 28, average log likelihood -1.408575
[ Info: iteration 29, average log likelihood -1.408550
[ Info: iteration 30, average log likelihood -1.408527
[ Info: iteration 31, average log likelihood -1.408504
[ Info: iteration 32, average log likelihood -1.408483
[ Info: iteration 33, average log likelihood -1.408462
[ Info: iteration 34, average log likelihood -1.408441
[ Info: iteration 35, average log likelihood -1.408421
[ Info: iteration 36, average log likelihood -1.408402
[ Info: iteration 37, average log likelihood -1.408383
[ Info: iteration 38, average log likelihood -1.408364
[ Info: iteration 39, average log likelihood -1.408346
[ Info: iteration 40, average log likelihood -1.408328
[ Info: iteration 41, average log likelihood -1.408311
[ Info: iteration 42, average log likelihood -1.408294
[ Info: iteration 43, average log likelihood -1.408278
[ Info: iteration 44, average log likelihood -1.408262
[ Info: iteration 45, average log likelihood -1.408246
[ Info: iteration 46, average log likelihood -1.408231
[ Info: iteration 47, average log likelihood -1.408216
[ Info: iteration 48, average log likelihood -1.408201
[ Info: iteration 49, average log likelihood -1.408187
32Ã—26 Array{Float64,2}:
[ Info: iteration 50, average log likelihood -1.408174
â”Œ Info: EM with 100000 data points 50 iterations avll -1.408174
â”” 59.0 data points per parameter
  0.162826    0.4821       0.077567     1.0102      0.148154   -0.770252     -0.212845     0.594657    -0.202359    -0.924854    -0.183846    -0.612818    -0.283356   -0.00653778  -0.0763813    0.0626686  -1.24986     0.60307     0.235496   -0.330928    0.820882     0.662377   -0.02309     0.368692    0.232022    0.19364
  0.014407   -0.175737    -0.670045     0.341801    0.0292543   0.0106419     0.0219484    0.367356     0.815775     0.200895     0.0682564    0.298438    -0.130935    0.782011     0.080373    -0.0030388  -0.529766   -0.56478    -0.634536   -0.147742    0.0144648   -0.252089   -0.176826   -0.721831    0.892249   -0.0172371
 -0.125786   -0.121139     0.101504     0.178313   -0.28452     0.28454       0.736264    -0.367576     0.509992    -0.541375     0.19149     -0.00625848   0.0685718  -0.172425     0.0398774   -0.350669   -0.31292    -0.502334   -0.200955   -1.06504     0.0475705    0.238554   -0.0480561   0.106095   -0.160124   -0.326359
 -0.0422489  -0.0310043   -0.16847      0.211432   -0.0444121   0.0602341     0.216081    -0.203705     0.00512806   0.00863641  -0.0379865   -0.438451    -0.208514    0.409606    -0.0382979   -0.312616   -0.160881   -0.17057     0.037806   -0.244671   -0.0158849    0.0044842  -0.136742    0.182589    0.365528   -0.108744
 -0.0937696   0.00679645   0.00177555  -0.0528246   0.072638   -0.116832     -0.0318829    0.174397    -0.0934097   -0.0960208   -0.014728     0.155393     0.0625473  -0.0522361    0.0500662    0.304055    0.0571407   0.0702281   0.0459221   0.304173    0.0180794   -0.11137     0.0392565   0.0464     -0.0255749   0.0502631
  0.0833504  -0.169555    -0.0357026    0.398738   -0.490953    0.208292      0.474222    -0.0256163   -0.213416    -0.471238     0.147276    -0.08678     -0.640004    0.326807    -0.525644    -0.27899     0.0636331  -0.485913   -0.160615    0.22011    -0.0528079   -0.728987    0.0907063   0.181807    0.222138    0.192179
  0.242789    0.114306     0.111909     0.271446   -0.195957    0.0441242     0.136558     0.304134    -0.0436486   -0.159713     0.169998     0.406887    -0.0804616   0.147885     0.066474    -0.225435   -0.397327    0.603934   -0.116072   -0.136497   -0.354472     0.167834   -0.151895   -0.0798685  -0.494384   -0.0267672
  0.606091   -0.0288612    0.00943412   0.295105    0.0657042   0.889137     -0.0323012   -0.18294     -0.182394     0.467075     0.366002    -0.324264    -0.986812   -0.0901851    0.181887    -0.332368    0.0229635   0.379707    0.348368   -0.785596    0.16348      0.233071    0.0803509  -0.209645    0.340286   -0.69
 -0.315368   -0.118704    -0.0833774   -0.0607539  -0.3368      0.386626      0.19376     -0.4272       0.457352     0.414195     0.118738    -0.268436     0.228735   -0.174933    -0.142088    -0.258419    0.55629    -0.880763   -0.122664   -0.278005    0.105658    -0.589091    0.421223   -0.208775    0.13217    -0.15814
 -0.298083    0.00666498  -0.404198    -0.126607    0.157839    0.1748        0.624627     0.723877     0.238862    -0.136687    -0.144849     0.557827     0.640755    0.0101523   -0.109028     0.332272    0.0429648  -0.315681   -0.375606    0.601702    0.0496215   -0.315272    0.0546595   0.53594    -0.120037    0.107808
  0.0357664  -0.251252    -0.228762     0.449816   -0.309567   -0.381021     -0.0580314    0.0824403   -0.624863    -0.168438    -0.205156    -0.755317    -0.0973147   0.886836     0.00838804   0.578225    0.227554    0.0796232   0.29804     0.611267   -0.137746    -0.298198    0.260218   -0.0114294   0.331655   -0.628178
  0.104856   -0.0774506    0.0211084   -0.129751    0.0349365   0.165365     -0.31629     -0.155273     0.394739     0.258802    -0.141718     0.0464288    0.004899   -0.343116    -0.02159     -0.137354    0.213189   -0.17025    -0.0792115  -0.224313    0.00714513   0.0791256  -0.0290108  -0.351871   -0.0885229   0.0845312
  0.338491    0.359696    -0.140359    -0.118196    0.122331   -0.000390063  -0.0441622   -0.342623    -0.0785294    0.140539    -0.00444481  -0.0303872    0.261393    0.276003    -0.22204     -0.649299   -0.387422    0.163168   -0.72173     0.0211561  -0.497209    -0.0471903  -0.0190427  -0.0779805   0.404914    0.159738
  0.202555   -0.354411     0.4981       0.325191   -0.199905   -0.532167     -0.0283232    0.212959     0.348244     0.279183     0.495803    -0.0358311    0.725872   -0.385328     0.237622     0.584248   -0.0355856   0.462315   -0.322834    0.57595     0.6015      -0.798758   -0.242105   -0.310797    0.0661591  -0.200744
  0.280012    0.0222239   -0.280161    -0.147366    0.282653    0.195697      0.105369    -0.466244     0.130923     0.0415101   -0.118083    -0.450118    -0.402101    0.725506    -0.331445    -0.496954   -0.112264   -0.399977   -0.206151   -0.301151   -0.0765343   -0.365483   -0.53187     0.499781    0.866732    0.106496
  0.260586   -0.534915     0.0380848   -0.362305   -0.0331503  -0.258751     -0.257835     0.471126     0.649075     0.675443    -0.399667    -0.469394    -0.193666    0.35608      0.394897     0.520903    0.261721   -0.29349     0.0601877  -0.117507    0.464872     0.425082   -0.655547    0.632248   -0.030278   -0.353782
  0.164433    0.0717545    0.231781     0.0461911  -0.095431   -0.113942     -0.124413     0.0298964   -0.195495     0.0745182   -0.313641     0.0277082   -0.116817    0.171271    -0.0903104   -0.191698   -0.438373    0.516928   -0.0196929  -0.0486004  -0.415511     0.466027    0.0660919  -0.0270625  -0.342516    0.0874989
 -0.400348   -0.140647    -0.694896     0.204444    0.587721    0.149358      0.115018    -0.290328    -0.0226362   -0.756834     0.286744     0.0850274   -0.203848   -0.449153     0.620581     0.615094    0.751249   -0.469044    0.54074     0.489759    0.808845    -0.695464   -0.0329088  -0.128006    0.162499   -0.0512558
 -0.868395    0.0191057   -0.709487    -0.19225    -0.0578822  -0.136983     -0.990495    -0.286475    -0.263481     0.15088     -0.157256    -0.778021     0.297898   -0.578374    -0.235198    -0.237457   -0.0394593  -1.00164     0.483811    0.508533   -0.194708    -0.296408   -0.221636   -0.25911     0.268381    1.06239
  0.120907    0.0492515    0.216342    -0.146756    0.060171   -0.468574     -0.565399     0.13253      0.424009     0.112956    -0.353483     0.259645    -0.112454    0.295071    -0.240437     0.386198    0.223106   -0.131624   -0.237168    0.542698    0.237484     0.0787637   0.0241504  -0.082745    0.100658    0.915052
 -0.0691499   0.155625    -0.362198     0.0698237  -0.577526   -0.545495     -0.876734    -0.778206     0.691601    -0.266183     0.137992    -0.35481     -0.585519    0.373643     0.714141     0.256042   -0.281616   -0.0481183   0.631858   -0.329258   -0.281525     0.282996    0.171428   -0.330789   -0.110761    0.282724
  0.182652    0.00304536   0.281914    -0.119273    0.404457   -0.479063     -0.591505     0.196559    -0.662728    -0.30589     -0.210249     0.0457386   -0.240354   -0.0643889   -0.121494     0.490501    0.165929    0.604785    0.251875    0.343963   -0.1439      -0.049276   -0.362272   -0.187816    0.432464    0.466455
  0.192684    0.0448865    0.124929    -0.464961    0.486084   -0.222131     -0.100281    -0.00965583   0.356875     0.180345     0.203913     0.783925     0.608219   -0.478407     0.799367     0.255123    0.0130138   0.51044    -0.164085   -0.0869955   0.0824276    0.615796   -0.333287   -0.336036   -0.208544   -0.04889
  0.307996    0.726027     0.400512    -0.292751    0.0795331  -0.49256      -0.145077    -0.329423    -0.222125     0.416624     0.0123669   -0.0274102   -0.274004   -0.36825      0.0478288   -0.214895    0.315577    0.727861    0.423068    0.05853     0.0151482    0.344008   -0.198055    0.267979   -0.472056   -0.0992173
 -0.125981   -0.255017    -0.0128446   -0.307957    0.46654     0.388628      0.11543      0.143689    -0.62662     -0.0539635    0.228205    -0.113006     0.145216   -0.0417749   -0.0725708    0.0587473   0.217458   -0.14823     0.301674   -0.0879516  -0.764526    -0.236389    0.134594    0.186519    0.0641465  -0.671624
 -0.17483     0.0486273   -0.727917     0.295573   -0.364918    0.5174        0.00783629   0.149058    -0.0250668   -0.244886    -0.702192    -0.110887    -0.393209   -0.145001    -0.0486976   -0.0161026  -0.0225348  -0.289618    0.0969871  -0.135539   -0.173603     0.424901    0.410228    0.29938    -0.636106    0.100651
 -0.0223104  -0.0441562    0.466447    -0.0874675  -0.197516   -0.0949268    -0.174897     0.0583417   -0.345849    -0.445514    -0.0788688    0.231324     0.317789   -0.863464     0.0211762    0.250261    0.416943    0.364721    0.258141    0.181435   -0.139114     0.308014    0.3978     -0.104436   -0.821605    0.312233
 -0.698112    0.105571    -0.201095     0.755592    0.083889    0.524559      0.675085     0.251228    -0.382832     0.231957     0.264671    -0.213676     0.178394    0.152664    -0.292459    -0.380286   -0.696294    0.294597    0.368572   -0.0432179   0.137191    -0.287336    0.363508   -0.33141     0.197502   -0.541601
 -0.360073   -0.338872     0.65695      0.303663    0.309796   -0.433308     -0.118214    -0.0855139   -0.15722      0.491843     0.007783    -0.227305    -0.122487    0.0304027   -0.274645    -0.0342867  -0.125611    0.304897   -0.118589   -0.080635    0.473599     0.377313    0.0399413   0.0744048   0.675583   -0.0190372
 -0.199151    0.591551    -0.122203    -0.476128    0.136162    0.487635     -0.235029    -0.258688     0.320097     0.280058     0.499258     0.98086      0.0472616  -0.940989    -0.429211    -0.978161   -0.216677   -0.10105    -0.325794   -0.0283501  -0.26148      0.0256523   0.297588   -0.0653957  -0.434616    0.58814
  0.12689     0.161043     0.0183157   -0.297639   -0.689131   -0.230651     -0.0794724    0.266799    -0.142496     0.156072     0.144806    -0.254843     0.306664   -0.193644     0.461946    -0.0753724  -0.135709   -0.117714    0.430651   -0.271574   -0.288477     0.722241    0.547346   -0.0954832  -0.267971   -0.236616
  0.188219    0.459842    -0.419296    -0.879299   -0.0667174  -0.13201      -0.2845       0.156191     0.0821896   -0.126345    -0.0648881    0.55337      0.0123927   0.283465     0.322916     0.231467    0.331396   -0.0531232   0.0931227   0.523378   -0.701675    -0.918633   -0.179458   -0.471456   -0.361963    0.0942543[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408160
[ Info: iteration 2, average log likelihood -1.408147
[ Info: iteration 3, average log likelihood -1.408135
[ Info: iteration 4, average log likelihood -1.408123
[ Info: iteration 5, average log likelihood -1.408111
[ Info: iteration 6, average log likelihood -1.408099
[ Info: iteration 7, average log likelihood -1.408088
[ Info: iteration 8, average log likelihood -1.408078
[ Info: iteration 9, average log likelihood -1.408068
[ Info: iteration 10, average log likelihood -1.408058
â”Œ Info: EM with 100000 data points 10 iterations avll -1.408058
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
 â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
     2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
