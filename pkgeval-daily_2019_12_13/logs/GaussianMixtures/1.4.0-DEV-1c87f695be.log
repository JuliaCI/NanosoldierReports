Julia Version 1.4.0-DEV.596
Commit 1c87f695be (2019-12-12 22:34 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed Distances ────────── v0.8.2
 Installed FillArrays ───────── v0.8.2
 Installed Compat ───────────── v2.2.0
 Installed NearestNeighbors ─── v0.4.4
 Installed Rmath ────────────── v0.6.0
 Installed SpecialFunctions ─── v0.9.0
 Installed SortingAlgorithms ── v0.3.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed CMake ────────────── v1.1.2
 Installed DataStructures ───── v0.17.6
 Installed Clustering ───────── v0.13.3
 Installed StatsBase ────────── v0.32.0
 Installed PDMats ───────────── v0.9.10
 Installed BinaryProvider ───── v0.5.8
 Installed StaticArrays ─────── v0.12.1
 Installed Distributions ────── v0.21.11
 Installed Missings ─────────── v0.4.3
 Installed URIParser ────────── v0.4.0
 Installed FileIO ───────────── v1.2.0
 Installed QuadGK ───────────── v2.3.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed DataAPI ──────────── v1.1.0
 Installed LegacyStrings ────── v0.4.1
 Installed Blosc ────────────── v0.5.1
 Installed JLD ──────────────── v0.9.1
 Installed HDF5 ─────────────── v0.12.5
 Installed OrderedCollections ─ v1.1.0
 Installed Arpack ───────────── v0.4.0
 Installed Parameters ───────── v0.12.0
 Installed BinDeps ──────────── v1.0.0
 Installed StatsFuns ────────── v0.9.2
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
Status `/tmp/jl_230tFw/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
┌ Warning: Replacing docs for `FileIO.filename :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
┌ Warning: Replacing docs for `FileIO.file_extension :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
[ Info: Testing Data
(100000, -1.4921539486569422e6, [6278.105901765321, 93721.89409823467], [-7490.563599488269 6065.4390233907925 -4006.9944416106487; 7158.297533510894 -6582.192826340561 4744.129389572676], [[12299.245915755399 -4679.380177986451 3106.1669534916073; -4679.380177986451 10195.471537513 -2371.6734914436765; 3106.1669534916073 -2371.6734914436765 7690.106838040808], [87633.29779528783 4593.324961346622 -2897.1730892683004; 4593.324961346622 89676.56482651742 2489.7831455465794; -2897.1730892683004 2489.7831455465794 92320.88604664967]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.073097e+03
      1       1.089176e+03      -9.839205e+02 |        6
      2       1.011782e+03      -7.739417e+01 |        2
      3       9.821350e+02      -2.964720e+01 |        0
      4       9.821350e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 982.135031488554)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.077000
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.775138
[ Info: iteration 2, lowerbound -3.651779
[ Info: iteration 3, lowerbound -3.526163
[ Info: iteration 4, lowerbound -3.375913
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.196705
[ Info: iteration 6, lowerbound -3.006914
[ Info: iteration 7, lowerbound -2.844451
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.712496
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.611963
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.537074
[ Info: iteration 11, lowerbound -2.483828
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.435777
[ Info: iteration 13, lowerbound -2.394568
[ Info: iteration 14, lowerbound -2.361745
[ Info: iteration 15, lowerbound -2.333780
[ Info: iteration 16, lowerbound -2.314117
[ Info: iteration 17, lowerbound -2.307414
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302935
[ Info: iteration 19, lowerbound -2.299260
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Dec 13 11:56:30 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Dec 13 11:56:39 2019: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Fri Dec 13 11:56:41 2019: EM with 272 data points 0 iterations avll -2.077000
5.8 data points per parameter
, Fri Dec 13 11:56:43 2019: GMM converted to Variational GMM
, Fri Dec 13 11:56:53 2019: iteration 1, lowerbound -3.775138
, Fri Dec 13 11:56:53 2019: iteration 2, lowerbound -3.651779
, Fri Dec 13 11:56:53 2019: iteration 3, lowerbound -3.526163
, Fri Dec 13 11:56:53 2019: iteration 4, lowerbound -3.375913
, Fri Dec 13 11:56:53 2019: dropping number of Gaussions to 7
, Fri Dec 13 11:56:53 2019: iteration 5, lowerbound -3.196705
, Fri Dec 13 11:56:53 2019: iteration 6, lowerbound -3.006914
, Fri Dec 13 11:56:53 2019: iteration 7, lowerbound -2.844451
, Fri Dec 13 11:56:53 2019: dropping number of Gaussions to 6
, Fri Dec 13 11:56:53 2019: iteration 8, lowerbound -2.712496
, Fri Dec 13 11:56:53 2019: dropping number of Gaussions to 5
, Fri Dec 13 11:56:53 2019: iteration 9, lowerbound -2.611963
, Fri Dec 13 11:56:53 2019: dropping number of Gaussions to 4
, Fri Dec 13 11:56:53 2019: iteration 10, lowerbound -2.537074
, Fri Dec 13 11:56:53 2019: iteration 11, lowerbound -2.483828
, Fri Dec 13 11:56:53 2019: dropping number of Gaussions to 3
, Fri Dec 13 11:56:53 2019: iteration 12, lowerbound -2.435777
, Fri Dec 13 11:56:53 2019: iteration 13, lowerbound -2.394568
, Fri Dec 13 11:56:53 2019: iteration 14, lowerbound -2.361745
, Fri Dec 13 11:56:53 2019: iteration 15, lowerbound -2.333780
, Fri Dec 13 11:56:53 2019: iteration 16, lowerbound -2.314117
, Fri Dec 13 11:56:53 2019: iteration 17, lowerbound -2.307414
, Fri Dec 13 11:56:53 2019: dropping number of Gaussions to 2
, Fri Dec 13 11:56:53 2019: iteration 18, lowerbound -2.302935
, Fri Dec 13 11:56:53 2019: iteration 19, lowerbound -2.299260
, Fri Dec 13 11:56:53 2019: iteration 20, lowerbound -2.299256
, Fri Dec 13 11:56:53 2019: iteration 21, lowerbound -2.299255
, Fri Dec 13 11:56:53 2019: iteration 22, lowerbound -2.299254
, Fri Dec 13 11:56:53 2019: iteration 23, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 24, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 25, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 26, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 27, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 28, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 29, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 30, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 31, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 32, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 33, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 34, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 35, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 36, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 37, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 38, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 39, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 40, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 41, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 42, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 43, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 44, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 45, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 46, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 47, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 48, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 49, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: iteration 50, lowerbound -2.299253
, Fri Dec 13 11:56:53 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601396, 95.95490777398606]
β = [178.04509222601396, 95.95490777398606]
m = [4.250300733269909 79.28686694436183; 2.0002292577753695 53.85198717246129]
ν = [180.04509222601396, 97.95490777398606]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484555 -0.007644049042327318; 0.0 0.00858170516633351], [0.37587636119483947 -0.008953123827345914; 0.0 0.012748664777409432]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -1.0158326891587268
avll from llpg:  -1.0158326891587461
avll direct:     -1.0158326891587461
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9950918263986277
avll from llpg:  -0.9950918263986277
avll direct:     -0.9950918263986277
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.00613763   0.0179694    0.0948939    0.177911    -0.0315626   -0.0448055    0.00455311   0.0874812   -0.0998195    -0.161992     0.0450198   -0.0375435    0.232175    -0.0750924    0.0663766   -0.118257     -0.101615    -0.0800771    0.225981     -0.14885      -0.112388      0.0878311  -0.0670153    0.0204337    0.0619611  -0.122613
  0.0108766   -0.0229267    0.117946    -0.0264246   -0.102063    -0.0263583    0.121744     0.0479181    0.0148037     0.10907      0.00119212   0.105469     0.152666     0.0435302    0.0402384    0.0364166    -0.14047      0.0861797    0.15979      -0.0190297     0.00273818   -0.021973    0.109984     0.00585194  -0.210981    0.0140463
 -0.155738    -0.087017    -0.0479189    0.0236909    0.114699    -0.101867     0.146951     0.215389     0.137281     -0.0865167   -0.116054     0.0441744    0.0266325   -0.112542     0.0136943   -0.110252     -0.0540817   -0.216643    -0.271884      0.0870219     0.0460253    -0.0906793  -0.0320621    0.160986     0.0460024   0.0203411
 -0.0656727   -0.076353    -0.0556801    0.0763997    0.258847    -0.0724167    0.256021    -0.0321165    0.127294     -0.0872715   -0.111559    -0.0817126   -0.268921    -0.0711004    0.044479     0.10708       0.0455777   -0.0285637    0.241843      0.220528      0.000373571  -0.107588    0.0752674   -0.0359279    0.119172   -0.0550833
  0.00951929  -0.0528549   -0.0545051   -0.0934685   -0.00161096  -0.104948    -0.0369705   -0.16053      0.233681     -0.0735061   -0.0355895   -0.0211283   -0.081596    -0.119039    -0.116223    -0.0551449    -0.146585    -0.0763352    0.159747     -0.00856853   -0.0967414     0.0918456  -0.119993    -0.0677379   -0.0445408  -0.0877711
 -0.140357    -0.0315114    0.0725032   -0.10653     -0.0194214    0.121187     0.130127    -0.0774194    0.0735697     0.130084    -0.0394171    0.0310331    0.221066     0.0810492    0.131944     0.0108154    -0.028477     0.0540733    0.00983466    0.0832371    -0.015176     -0.141102    0.00811202   0.00581466   0.149329   -0.100435
  0.0807976   -0.12462     -0.104672    -0.0975009    0.135512    -0.0442719   -0.143657     0.0967572   -0.0588429    -0.11678     -0.0715839   -0.133659     0.178519     0.0427035   -0.00350537   0.0899799    -0.0970299   -0.24457     -0.0195296    -0.178484      0.124578     -0.0122638  -0.0591183    0.0548805    0.0551258   0.155131
 -0.0258959    0.0288173   -0.0585069   -0.0797839    0.0809674    0.0127731    0.028675    -0.104137    -0.112166      0.00541463  -0.0985494    0.00531569  -0.0548163   -0.064311    -0.0878165   -0.034782      0.078755    -0.116452     0.0869683     0.023653      0.0869003    -0.21972    -0.205338     0.0592507   -0.126491   -0.0501352
 -0.0344726    0.0927839    0.0250261    0.228939     0.0251385   -0.132151     0.0686781   -0.0728361    0.220714      0.162596    -0.0116976   -0.0965776    0.217737     0.100567     0.206089     0.0351825     0.0611046    0.148925     0.0175234     0.246391     -0.0380743    -0.0978869   0.0622525   -0.0277725    0.153761    0.0321598
 -0.0561532    0.104837    -0.177784     0.117262     0.0567303   -0.0574677    0.0126197   -0.0309763   -0.0332262    -0.0110531    0.099539    -0.0240895   -0.0521304   -0.193047    -0.012235     0.014944     -0.0253829    0.043714     0.0606743    -0.108156     -0.0841103    -0.0556582  -0.102289    -0.0966072    0.0601492   0.0631542
  0.0276938   -0.05662      0.136776     0.0452419   -0.0101409    0.0624769    0.0103372   -0.13322      0.07444       0.181992     0.082581     0.0300092   -0.0697643   -0.101323    -0.0702286    0.137825      0.161183     0.0414545    0.0815769    -0.0200125     0.0528733     0.0194567  -0.147724     0.151471    -0.0501825  -0.0789435
  0.327308     0.114808    -0.0231221   -0.110462    -0.124079    -0.10643      0.106222     0.0249117    0.00641896   -0.134576    -0.232442     0.185988    -0.0347118   -0.00418528   0.181763     0.0355809    -0.053071    -0.0632372    0.164103     -0.0645564    -0.0520894     0.106145    0.0550882   -0.0112331    0.119724    0.101761
  0.0561368   -0.140259     0.107888    -0.0364927    0.0801789    0.0146291   -0.0809119    0.0656059   -0.0883062    -0.0118099   -0.135466    -0.133879    -0.00533553   0.145383     0.107339    -0.000301144   0.0325031    0.185885     0.00523525   -0.0267703     0.0192162     0.0061756  -0.00883758   0.118797    -0.0264022  -0.182275
  0.135972    -0.0335457    0.00311176   0.187995     0.0993186    0.0259685   -0.00434709  -0.114247     0.19427      -0.0106921   -0.146049    -0.0589492    0.224778    -0.193702     0.0423986    0.0359216     0.0162117   -0.00740396  -0.0768849     0.0888378    -0.023047      0.067988    0.114971    -0.0364003   -0.146569   -0.0355141
  0.02256      0.332203     0.0310329    0.0562217    0.126218    -0.00130365   0.0450077   -0.107248    -0.00359493   -0.16745     -0.101896     0.0779719    0.102821    -0.0995288   -0.0720519   -0.181277      0.0299482    0.00853575   0.0316232     0.151636     -0.0353351     0.020874   -0.0185582    0.0868594   -0.118834   -0.117506
 -0.0400369   -0.031892     0.0729958   -0.038421    -0.00684973  -0.0689758    0.0244965   -0.0072706    0.0343362    -0.0722516    0.102368     0.0351464    0.0102956    0.112165     0.128745     0.0583451    -0.011394     0.02868     -0.0178425     0.0366976    -0.076892      0.0103847  -0.00196211  -0.143424     0.207694    0.116213
  0.0390376    0.0319263   -0.162345     0.011691     0.0641234    0.00270907  -0.132723    -0.245013     0.21624       0.225418    -0.0672453    0.182361     0.188494     0.072095    -0.0407714    0.138488     -0.166965     0.0411141   -0.095211     -0.046037      0.034622      0.077449    0.0386699    0.0792126    0.167038   -0.0537748
  0.0246747   -0.0421943   -0.00366239  -0.00949075   0.0324292   -0.0399835    0.0438252   -0.00863791   0.0597638     0.03433      0.0388483   -0.11848     -0.0181946   -0.0180367    0.0577425   -0.131754      0.0181705   -0.00344602  -0.0593482     0.01066       0.193502      0.101174    0.110021    -0.155013    -0.0649925  -0.112262
  0.0255009    0.0680939   -0.167933    -0.0438286    0.0431841    0.122103    -0.0549971    0.0506281    0.0423074     0.105206    -0.0176348    0.0311013    0.0730753    0.0394843    0.0627042    0.0541762     0.107524     0.194254     0.0966053    -0.100995     -0.0152035     0.0998259  -0.099951     0.0344244   -0.116733   -0.0333168
 -0.153764     0.148029    -0.105875    -0.0930592    0.0457053    0.0413809    0.008623     0.0678789    0.00786624    0.0255474   -0.0974508    0.113333     0.116781     0.0489974   -0.0783145   -0.0885648    -0.0129632    0.0755145   -0.0980886     0.0551084     0.0150732     0.0841778  -0.0854692   -0.00583066  -0.0606355  -0.18288
  0.170405    -0.192276     0.064818     0.0663453    0.040507     0.091109     0.0344719   -0.0446452   -0.00319285    0.0210098   -0.148487    -0.112088     0.0215782   -0.0497611    0.0242037   -0.00779655   -0.250862    -0.0608793   -0.000387229   0.0668023     0.131659     -0.229365    0.170894    -0.0449091   -0.107388   -0.105452
 -0.172983     0.0181029   -0.100323     0.0477547    0.0284246    0.0798614   -0.0223361   -0.00236412   0.000429509  -0.025332     0.152104    -0.0298511   -0.0745754    0.0743782   -0.00400712   0.0493855     0.0335327   -0.0520657    0.21643       0.0213574    -0.0403898     0.0966432  -0.0036329   -0.10396      0.0375593   0.024656
 -0.0486525   -0.0839402    0.0219506   -0.184509     0.166255    -0.00126575  -0.0549225    0.0962977   -0.0843973    -0.0299314   -0.125435     0.0996201   -0.0256675   -0.0385959    0.101094    -0.02772      -0.193771    -0.201205     0.000590257  -0.0168584     0.0335       -0.0134276   0.204392     0.194795     0.0699546  -0.056784
 -0.0465848   -0.0450271    0.0425813    0.0118017    0.0646903   -0.123372    -0.240307    -0.132428    -0.12601      -0.141821    -0.0866094    0.0547004    0.0190149   -0.0227929    0.0489927    0.0343677    -0.108562     0.192848    -0.0624939     0.0228787    -0.0248899    -0.096829   -0.0945608    0.0326945   -0.0673206   0.0145777
  0.186795     0.0101078    0.107467     0.193219     0.0710967   -0.0912405    0.00377806  -0.0683252   -0.00876721    0.0765069    0.0122826   -0.00774077  -0.0840951    0.038826    -0.00448445   0.0651408     0.00810264   0.0368324    0.0249424     0.0392094     0.0806344     0.194075    0.0992382   -0.0192204   -0.0371026   0.000464791
  0.100288    -0.0423661   -0.103375     0.126356     0.0477572   -0.00205429   0.0301871    0.0443189   -0.0220886     0.115334    -0.0163617    0.153856    -0.0695398    0.016523    -0.149994    -0.113152      0.0504319    0.0473217    0.00835257    0.0172361    -0.177949     -0.0353016  -0.0460828   -0.103717    -0.0823492   0.250047
  0.0572084    0.00837231  -0.122393    -0.0641235   -0.0378494   -0.0416989    0.0734411   -0.123667     0.0474439     0.0539493    0.0462962   -0.0688322   -0.199312    -0.0168758   -0.0233071    0.00977271   -0.0539396   -0.0649884    0.098653     -0.0421015    -0.0361794    -0.0612983   0.0746726   -0.120375    -0.051261    0.0891052
 -0.142894    -0.064437     0.08497     -0.0307463    0.111833    -0.00335606  -0.0860316   -0.0532731   -0.0979366     0.130951    -0.0549807    0.0773614   -0.0601644   -0.18475     -0.172383     0.109772     -0.108545    -0.102395     0.0619843    -0.0267873     0.0212304    -0.0517175   0.0931897    0.0461503   -0.0106564  -0.138058
 -0.0435744    0.162827    -0.0575262   -0.0266024   -0.0512818   -0.0213104   -0.14588      0.0386021    0.00902282    0.0264209   -0.0353847   -0.198779    -0.0638387   -0.198677    -0.119441    -0.0920365     0.181751     0.23286     -0.0936952    -0.0117287     0.117946      0.184344   -0.0175401    0.0548311    0.0219937  -0.0531319
 -0.00108926  -0.0766718   -0.157458     0.052432     0.0700618    0.0871909    0.0937422    0.0671116    0.0634837     0.264763    -0.0200041   -0.1272      -0.15018     -0.0179779    0.0441091    0.0394947     0.066783     0.00112519   0.0161282    -0.105114     -0.0300135    -0.197508    0.0218092    0.0739125   -0.0555995   0.115646
  0.132936     0.141267     0.0318242    0.190474     0.0839529   -0.0651044   -0.00813938   0.0771605    0.200132     -0.134132    -0.210358     0.0226046    0.137193     0.022899    -0.0764329   -0.105836     -0.0970352   -0.207193    -0.0421727    -0.142424     -0.0136846     0.0377051   0.0754498    0.0153241    0.0616849  -0.0757777
  0.153672    -0.0454339   -0.140492    -0.152133    -0.0150594   -0.0545475    0.058284     0.0627341   -0.205204     -0.0702347   -0.117307    -0.0502492   -0.0474035   -0.0783389   -0.0286753    0.0735968    -0.0493424    0.106716     0.00370843    0.000111086   0.12388       0.130469   -0.135865    -0.121356     0.0777093   0.0887799kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4162145129321904
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416298
[ Info: iteration 2, average log likelihood -1.416228
[ Info: iteration 3, average log likelihood -1.415854
[ Info: iteration 4, average log likelihood -1.410792
[ Info: iteration 5, average log likelihood -1.391087
[ Info: iteration 6, average log likelihood -1.379841
[ Info: iteration 7, average log likelihood -1.377765
[ Info: iteration 8, average log likelihood -1.376921
[ Info: iteration 9, average log likelihood -1.376477
[ Info: iteration 10, average log likelihood -1.376217
[ Info: iteration 11, average log likelihood -1.376044
[ Info: iteration 12, average log likelihood -1.375916
[ Info: iteration 13, average log likelihood -1.375817
[ Info: iteration 14, average log likelihood -1.375739
[ Info: iteration 15, average log likelihood -1.375676
[ Info: iteration 16, average log likelihood -1.375625
[ Info: iteration 17, average log likelihood -1.375583
[ Info: iteration 18, average log likelihood -1.375548
[ Info: iteration 19, average log likelihood -1.375519
[ Info: iteration 20, average log likelihood -1.375495
[ Info: iteration 21, average log likelihood -1.375474
[ Info: iteration 22, average log likelihood -1.375456
[ Info: iteration 23, average log likelihood -1.375442
[ Info: iteration 24, average log likelihood -1.375429
[ Info: iteration 25, average log likelihood -1.375419
[ Info: iteration 26, average log likelihood -1.375410
[ Info: iteration 27, average log likelihood -1.375402
[ Info: iteration 28, average log likelihood -1.375396
[ Info: iteration 29, average log likelihood -1.375390
[ Info: iteration 30, average log likelihood -1.375385
[ Info: iteration 31, average log likelihood -1.375380
[ Info: iteration 32, average log likelihood -1.375376
[ Info: iteration 33, average log likelihood -1.375373
[ Info: iteration 34, average log likelihood -1.375370
[ Info: iteration 35, average log likelihood -1.375367
[ Info: iteration 36, average log likelihood -1.375364
[ Info: iteration 37, average log likelihood -1.375362
[ Info: iteration 38, average log likelihood -1.375360
[ Info: iteration 39, average log likelihood -1.375358
[ Info: iteration 40, average log likelihood -1.375356
[ Info: iteration 41, average log likelihood -1.375354
[ Info: iteration 42, average log likelihood -1.375353
[ Info: iteration 43, average log likelihood -1.375351
[ Info: iteration 44, average log likelihood -1.375350
[ Info: iteration 45, average log likelihood -1.375348
[ Info: iteration 46, average log likelihood -1.375347
[ Info: iteration 47, average log likelihood -1.375346
[ Info: iteration 48, average log likelihood -1.375345
[ Info: iteration 49, average log likelihood -1.375344
[ Info: iteration 50, average log likelihood -1.375343
┌ Info: EM with 100000 data points 50 iterations avll -1.375343
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4162975989483881
│     -1.4162277416155176
│      ⋮
└     -1.3753425536006212
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.375468
[ Info: iteration 2, average log likelihood -1.375343
[ Info: iteration 3, average log likelihood -1.374824
[ Info: iteration 4, average log likelihood -1.370099
[ Info: iteration 5, average log likelihood -1.355867
[ Info: iteration 6, average log likelihood -1.345551
[ Info: iteration 7, average log likelihood -1.341389
[ Info: iteration 8, average log likelihood -1.339333
[ Info: iteration 9, average log likelihood -1.338239
[ Info: iteration 10, average log likelihood -1.337527
[ Info: iteration 11, average log likelihood -1.336978
[ Info: iteration 12, average log likelihood -1.336497
[ Info: iteration 13, average log likelihood -1.336049
[ Info: iteration 14, average log likelihood -1.335616
[ Info: iteration 15, average log likelihood -1.335199
[ Info: iteration 16, average log likelihood -1.334799
[ Info: iteration 17, average log likelihood -1.334418
[ Info: iteration 18, average log likelihood -1.334068
[ Info: iteration 19, average log likelihood -1.333773
[ Info: iteration 20, average log likelihood -1.333542
[ Info: iteration 21, average log likelihood -1.333363
[ Info: iteration 22, average log likelihood -1.333212
[ Info: iteration 23, average log likelihood -1.333068
[ Info: iteration 24, average log likelihood -1.332926
[ Info: iteration 25, average log likelihood -1.332786
[ Info: iteration 26, average log likelihood -1.332659
[ Info: iteration 27, average log likelihood -1.332559
[ Info: iteration 28, average log likelihood -1.332487
[ Info: iteration 29, average log likelihood -1.332435
[ Info: iteration 30, average log likelihood -1.332397
[ Info: iteration 31, average log likelihood -1.332366
[ Info: iteration 32, average log likelihood -1.332339
[ Info: iteration 33, average log likelihood -1.332314
[ Info: iteration 34, average log likelihood -1.332289
[ Info: iteration 35, average log likelihood -1.332263
[ Info: iteration 36, average log likelihood -1.332235
[ Info: iteration 37, average log likelihood -1.332204
[ Info: iteration 38, average log likelihood -1.332170
[ Info: iteration 39, average log likelihood -1.332130
[ Info: iteration 40, average log likelihood -1.332086
[ Info: iteration 41, average log likelihood -1.332038
[ Info: iteration 42, average log likelihood -1.331983
[ Info: iteration 43, average log likelihood -1.331926
[ Info: iteration 44, average log likelihood -1.331869
[ Info: iteration 45, average log likelihood -1.331813
[ Info: iteration 46, average log likelihood -1.331760
[ Info: iteration 47, average log likelihood -1.331712
[ Info: iteration 48, average log likelihood -1.331666
[ Info: iteration 49, average log likelihood -1.331624
[ Info: iteration 50, average log likelihood -1.331585
┌ Info: EM with 100000 data points 50 iterations avll -1.331585
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3754675483538992
│     -1.3753427608826143
│      ⋮
└     -1.331585084957619
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.331727
[ Info: iteration 2, average log likelihood -1.331517
[ Info: iteration 3, average log likelihood -1.331057
[ Info: iteration 4, average log likelihood -1.327091
[ Info: iteration 5, average log likelihood -1.312216
[ Info: iteration 6, average log likelihood -1.297807
[ Info: iteration 7, average log likelihood -1.291279
[ Info: iteration 8, average log likelihood -1.287861
[ Info: iteration 9, average log likelihood -1.285617
[ Info: iteration 10, average log likelihood -1.284126
[ Info: iteration 11, average log likelihood -1.283051
[ Info: iteration 12, average log likelihood -1.282177
[ Info: iteration 13, average log likelihood -1.281390
[ Info: iteration 14, average log likelihood -1.280597
[ Info: iteration 15, average log likelihood -1.279701
[ Info: iteration 16, average log likelihood -1.278567
[ Info: iteration 17, average log likelihood -1.277219
[ Info: iteration 18, average log likelihood -1.275825
[ Info: iteration 19, average log likelihood -1.274738
[ Info: iteration 20, average log likelihood -1.274114
[ Info: iteration 21, average log likelihood -1.273786
[ Info: iteration 22, average log likelihood -1.273596
[ Info: iteration 23, average log likelihood -1.273467
[ Info: iteration 24, average log likelihood -1.273369
[ Info: iteration 25, average log likelihood -1.273290
[ Info: iteration 26, average log likelihood -1.273224
[ Info: iteration 27, average log likelihood -1.273169
[ Info: iteration 28, average log likelihood -1.273121
[ Info: iteration 29, average log likelihood -1.273081
[ Info: iteration 30, average log likelihood -1.273046
[ Info: iteration 31, average log likelihood -1.273016
[ Info: iteration 32, average log likelihood -1.272989
[ Info: iteration 33, average log likelihood -1.272965
[ Info: iteration 34, average log likelihood -1.272943
[ Info: iteration 35, average log likelihood -1.272923
[ Info: iteration 36, average log likelihood -1.272904
[ Info: iteration 37, average log likelihood -1.272886
[ Info: iteration 38, average log likelihood -1.272867
[ Info: iteration 39, average log likelihood -1.272849
[ Info: iteration 40, average log likelihood -1.272831
[ Info: iteration 41, average log likelihood -1.272812
[ Info: iteration 42, average log likelihood -1.272791
[ Info: iteration 43, average log likelihood -1.272771
[ Info: iteration 44, average log likelihood -1.272750
[ Info: iteration 45, average log likelihood -1.272730
[ Info: iteration 46, average log likelihood -1.272712
[ Info: iteration 47, average log likelihood -1.272696
[ Info: iteration 48, average log likelihood -1.272682
[ Info: iteration 49, average log likelihood -1.272671
[ Info: iteration 50, average log likelihood -1.272662
┌ Info: EM with 100000 data points 50 iterations avll -1.272662
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3317266837268005
│     -1.3315165534122209
│      ⋮
└     -1.272661610067338
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.272835
[ Info: iteration 2, average log likelihood -1.272605
[ Info: iteration 3, average log likelihood -1.271804
[ Info: iteration 4, average log likelihood -1.264071
[ Info: iteration 5, average log likelihood -1.234525
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.202817
[ Info: iteration 7, average log likelihood -1.200000
[ Info: iteration 8, average log likelihood -1.186942
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.176441
[ Info: iteration 10, average log likelihood -1.181476
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.172116
[ Info: iteration 12, average log likelihood -1.177597
[ Info: iteration 13, average log likelihood -1.170569
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.165169
[ Info: iteration 15, average log likelihood -1.176522
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.169709
[ Info: iteration 17, average log likelihood -1.176283
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.169562
[ Info: iteration 19, average log likelihood -1.176086
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.169345
[ Info: iteration 21, average log likelihood -1.175841
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.169073
[ Info: iteration 23, average log likelihood -1.175524
[ Info: iteration 24, average log likelihood -1.168769
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.163584
[ Info: iteration 26, average log likelihood -1.175101
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.168341
[ Info: iteration 28, average log likelihood -1.174859
[ Info: iteration 29, average log likelihood -1.168231
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.163139
[ Info: iteration 31, average log likelihood -1.174598
[ Info: iteration 32, average log likelihood -1.167975
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.162965
[ Info: iteration 34, average log likelihood -1.174493
[ Info: iteration 35, average log likelihood -1.167941
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.162977
[ Info: iteration 37, average log likelihood -1.174469
[ Info: iteration 38, average log likelihood -1.167948
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.162999
[ Info: iteration 40, average log likelihood -1.174464
[ Info: iteration 41, average log likelihood -1.167955
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.163011
[ Info: iteration 43, average log likelihood -1.174463
[ Info: iteration 44, average log likelihood -1.167959
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.163017
[ Info: iteration 46, average log likelihood -1.174462
[ Info: iteration 47, average log likelihood -1.167961
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.163020
[ Info: iteration 49, average log likelihood -1.174462
[ Info: iteration 50, average log likelihood -1.167962
┌ Info: EM with 100000 data points 50 iterations avll -1.167962
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2728345250356972
│     -1.2726054969657057
│      ⋮
└     -1.167961939389083
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.163288
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.162886
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.159442
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.130181
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.090460
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.086404
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.077911
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.085523
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     16
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.070211
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.089712
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.072742
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.081776
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.073824
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.079108
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.073178
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.075948
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.064509
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.081167
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.058764
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.065943
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     16
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.060925
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.070563
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.068417
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.088394
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.067051
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     16
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.072338
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.070467
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.068003
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.067223
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.086987
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     16
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.064929
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.078462
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.067901
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.066765
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.066032
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.085253
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.071087
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.076141
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.067106
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.065432
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     14
│     16
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.063947
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.091223
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.068904
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.075501
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.065936
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     16
│     19
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.063666
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.070017
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.088906
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.068155
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.074273
┌ Info: EM with 100000 data points 50 iterations avll -1.074273
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1632878192024165
│     -1.1628855155787943
│      ⋮
└     -1.07427346022331
32×26 Array{Float64,2}:
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4162145129321904
│     -1.4162975989483881
│     -1.4162277416155176
│     -1.41585394067055
│      ⋮
│     -1.0889062460884218
│     -1.068155397184627
└     -1.07427346022331
 -0.15832      0.150479   -0.0819745   -0.088605     0.0466997    0.10845       0.00902903   0.111539    -0.0110763   -0.0431231   -0.103636      0.0956022    0.1236      0.0503331   -0.0686198   -0.0808615   -0.0228555     0.0632014   -0.0949953     0.0687684     0.0198151     0.0660694   -0.0674586   0.00754043  -0.0477369   -0.171869
 -0.0378666   -0.0273468   0.0596843    0.00383929   0.0594376   -0.0137692    -0.0156481    0.0861222   -0.0928679   -0.094141    -0.0409561     0.0416555    0.0963624  -0.0634905    0.0722236   -0.0675493   -0.150065     -0.168633     0.132463     -0.0780924    -0.0415817     0.0424348    0.0454496   0.103729     0.0696779   -0.0924206
  0.0089553   -0.0896703   0.0636498    0.00509956   0.0731545    0.0319169    -0.0244804   -0.0576657   -0.0370376    0.0776401   -0.111955     -0.0149681   -0.0221683  -0.111473    -0.0382442    0.0448065   -0.167797     -0.0858858    0.0459957     0.017961      0.101025     -0.162249     0.0907518   0.00560789  -0.0627124   -0.11213
  0.216632     0.123598    0.0178971    0.0513376   -0.00956068  -0.0787482     0.0460042    0.0417379    0.1014      -0.115463    -0.221928      0.0881807    0.0404881   0.0175554    0.0377632   -0.0496141   -0.0654229    -0.128976     0.0771401    -0.0990392    -0.0150799     0.0509832    0.0440909   0.004512     0.0967315   -0.000820478
  0.0262073   -0.0258114  -0.141334    -0.0175296    0.0055914    0.0111717     0.0880918   -0.0392438    0.0626018    0.144194     0.0364639    -0.0617188   -0.173129   -0.0179622    0.0101001    0.024438    -0.0116323    -0.0381041    0.0164423    -0.0749119    -0.000306891  -0.131234     0.0611454  -0.0378637   -0.0608941    0.0825094
  0.12279     -0.0422389  -0.128085    -0.152769    -0.0292146   -0.0511647     0.0575236    0.0576679   -0.172507     0.0178193   -0.0796255    -0.089903    -0.0470799  -0.0847203   -0.0167038    0.0921831   -0.0379107     0.0992966    0.0117113     0.00360683    0.101251      0.130214    -0.135711   -0.113094     0.0815076    0.0888573
  0.00885278   0.0660269  -0.164131    -0.0889931    0.0373816    0.117539     -0.122534     0.0557384    0.0611916    0.0972734   -0.0207167     0.142626     0.0646663   0.0310746   -0.260676     0.0441269    0.0881479     0.310453     0.128851     -0.167847      0.0193708     0.0783894   -0.115637    0.0296362   -0.123666    -0.0402519
  0.0314917    0.0680828  -0.154933    -0.013012     0.0628342    0.133366      0.0670862    0.030724    -0.0818136    0.129501    -0.0190318    -0.0373766    0.0451662   0.0435143    0.396793     0.0553329    0.10388       0.0818376    0.141581     -0.0113092    -0.0674606     0.0869844   -0.0826553   0.0454392   -0.0794063    0.0219319
  0.110841    -0.035379   -0.0534474    0.129352     0.0485293   -0.000630928   0.0268454    0.0441629   -0.0194421    0.113351     0.000277502   0.151143    -0.0448792   0.00526177  -0.157477    -0.10996      0.0511585     0.0388817   -0.00559049    0.0164128    -0.176732     -0.0339785   -0.0710727  -0.105312    -0.0704419    0.254977
  0.0240985    0.338668    0.0293415    0.0767982    0.100353    -0.00204913    0.0454151   -0.101548    -0.00344259  -0.163825    -0.0516772     0.0653782    0.063543   -0.100955    -0.0885838   -0.180623     0.0275226    -0.0121018    0.0117754     0.140916     -0.0370627     0.033495    -0.0230181   0.0712475   -0.1246      -0.11386
 -0.0355584    0.21774     0.00674949   0.231127    -0.0290232   -0.131651      0.0408274   -0.0699276    0.221902     0.164237    -0.977427     -0.0789791    0.184806    0.101906     0.218498     0.030599     0.121433      0.163276     0.0293406     0.247079     -0.00556561   -0.0990064    0.0597308  -0.0176932    0.0484926    0.0179938
 -0.0336355    0.0148447   0.0747582    0.236006     0.0750036   -0.13384       0.0662696   -0.0807495    0.221403     0.161803     1.08344      -0.110479     0.274657    0.0864648    0.188419     0.0476465    0.064182      0.166936     0.0555834     0.243978     -0.135903     -0.0761132    0.0636413  -0.0336733    0.270851     0.030557
 -0.162842     0.0129036  -0.105388     0.0129194    0.0207121    0.0895239    -0.0901875    0.00263553  -0.00339314  -0.0104818    0.134357     -0.0412844   -0.0673209   0.0610503   -0.0347036    0.0223257    0.0408705    -0.0282861    0.21531       0.0206552    -0.0505782     0.11682     -0.0842901  -0.10508      0.00921883  -0.0177951
  0.0149927   -0.0385687  -0.00285606  -0.0124136    0.0170455   -0.0380507     0.0426076   -0.010903     0.0481313   -0.00846625   0.0218695    -0.0984621   -0.0458704   0.00993284   0.0875477   -0.130875     0.0166805     0.0262961   -0.0505665    -0.000198887   0.175768      0.0969626    0.101252   -0.126004    -0.0590461   -0.0931835
 -0.0857635   -0.0284368   0.0644042   -0.0658673   -0.018842     0.0349209     0.0381869   -0.0455354    0.0540192    0.0290062    0.0250361     0.0106926    0.121544    0.109757     0.127269     0.0349554   -0.0307542     0.0495777    0.0124744     0.0681867    -0.0533702    -0.068033     0.0112393  -0.0741858    0.175331     0.00330812
  0.0474657   -0.145858    0.109116    -0.0447714    0.0269916   -0.00769971   -0.0763003    0.0198427   -0.0921386   -0.0126511   -0.1007       -0.0973939   -0.0059349   0.142492     0.10955      0.014352     0.0306221     0.15128      0.000887148  -0.0296806     0.0131165     0.0171432   -0.0563569   0.103965    -0.0416497   -0.195189
  0.0637789   -0.062485    0.109418     0.0771838   -0.0150892    0.295075      0.0317749   -0.13358      0.146155     0.199303    -0.406062      0.0303523   -0.0655157  -0.174656    -0.0525365    0.123162     0.218728      0.0507376    0.0883634    -0.0152657     0.0512264     0.0189478   -0.0448341   0.148871    -0.0542892   -0.272972
 -0.00367345  -0.0338618   0.167077    -0.00523437  -0.00453317  -0.153557     -0.00144924  -0.135691    -0.0542665    0.189415     0.562174      0.0273785   -0.0772924  -0.0858307   -0.0504872    0.163566     0.103514      0.0384896    0.072062     -0.00012948    0.0460933    -0.0190017   -0.269741    0.15377     -0.0441593    0.0221239
 -0.0374515   -0.137267   -0.0680043   -0.0976647    0.0103083   -0.147601     -0.0434685   -0.194801     0.231853    -0.0927162   -0.0310394    -0.0215205   -0.0935991  -0.119753    -0.149052    -0.0502492   -0.10963      -0.0855519    0.162525     -0.0377536    -0.0990403     0.0899242   -0.13819    -0.0700041   -0.00104156  -0.0702103
 -0.0115629   -0.0281221   0.120136    -0.0313908   -0.0804289   -0.0270559     0.130442     0.0808066    0.0158898    0.0788259    0.000287726   0.10278      0.149662    0.0463866    0.038207     0.0335916   -0.135374      0.0856289    0.15465      -0.0211635     0.00470077   -0.0305199    0.107316    0.00213846  -0.208039     0.0182997
  0.0406485    0.0300236  -0.16426      0.0200033    0.0322494   -0.00717781   -0.118458    -0.231476     0.204388     0.204232    -0.0658481     0.183414     0.174149    0.0606247   -0.0720437    0.134159    -0.1452        0.0405331   -0.0912912    -0.0431902     0.0155884     0.0576563    0.0312806   0.082245     0.124567    -0.0734931
 -0.0401931   -0.045492    0.0404603    0.00810527   0.059593    -0.134215     -0.218198    -0.15883     -0.136901    -0.127926    -0.0834709     0.0554808    0.0475695  -0.00207814   0.0586693    0.00784277  -0.13927       0.187252    -0.0609987     0.112979     -0.022959     -0.106267    -0.09872     0.0445708   -0.0731033    0.0200963
 -0.0581141    0.0440358  -0.0594995    0.0221379    0.102715    -0.0464674     0.0386224   -0.0137801    0.0495173   -0.0345015   -0.0656911    -0.140434    -0.184815   -0.133579    -0.0053692    0.0111564    0.124373      0.104305     0.0696803     0.0993549     0.0603399     0.0446205    0.0267297   0.0245543    0.0704412   -0.0661418
  0.077115    -0.122961   -0.101013    -0.094576     0.12182     -0.0532452    -0.185376     0.080609    -0.00514255  -0.105568    -0.0704784    -0.134051     0.172717    0.00788599   0.0238102    0.0772953   -0.0967455    -0.244583    -0.0186727    -0.116099      0.126012     -0.0104354   -0.0563008   0.0502476    0.0633404    0.150829
  0.196487     0.0140853   0.0252973    0.237057    -0.35831     -0.0907695     0.00500753  -0.0526544   -0.00359516   0.0509242    0.0792834    -0.00819636  -0.456108    0.0274858   -0.00626058   0.0561698   -0.117265     -0.0269603    0.0243884     0.0264322     0.011765      0.135874     0.0991726   0.00964232  -0.0333629    0.00159463
  0.151744     0.003596    0.22609      0.118848     0.620691    -0.0884438     0.00305818  -0.0621372   -0.00882531   0.114793    -0.0540751    -0.00870392   0.282661    0.0382603   -0.00464462   0.0779867    0.159794      0.103623     0.0257751     0.0566795     0.192759      0.226209     0.0991974  -0.0315104   -0.0388737    0.00300453
 -0.0363384    0.124341   -0.201777     0.262068     0.0352932   -0.0588514     0.031283    -0.0570702   -0.0248877   -0.0567083    0.106122      0.0741536   -0.429439   -0.140703     0.077223     0.0146634    0.0731852     0.0474378    0.0677014    -0.117413     -0.124863     -0.0194378   -0.0932555  -0.101825     0.0363334    0.189769
 -0.0365472    0.0775074  -0.139611    -0.0806623    0.0470422   -0.0546184    -0.01972     -0.0130641   -0.0411789    0.0674014    0.111905     -0.123747     0.370632   -0.192624    -0.100227     0.0059139   -0.163587      0.0434482    0.0728434    -0.143839     -0.0498006    -0.00551002  -0.107856   -0.0775046    0.0748887   -0.111324
 -0.276555    -0.114987   -0.0387538    0.133522    -0.640234    -0.0981562     0.152284     0.245287     0.13032     -0.0858912   -0.127183      0.0366049   -0.0284853  -0.0104306    0.0132495   -0.181457    -0.0952036    -0.218292    -0.259106      0.152225      0.0350649    -0.0147286   -0.0280034   0.171197     0.102619     0.02402
 -5.64393e-5  -0.128924   -0.0656368   -0.17541      0.907223    -0.0951546     0.133917     0.165576     0.104446    -0.0889704   -0.0920702     0.0466102    0.130055   -0.235749     0.0362583   -0.0227819    0.0410945    -0.21676     -0.282253      0.0790786     0.0444373    -0.163854    -0.037219    0.191278    -0.0103377    0.0187222
 -0.0496054    0.0116238  -0.0439675   -0.0238119    0.0785304   -0.028807      0.033528    -0.0877874   -0.0595448    0.00290626  -0.112493      0.0212238   -0.0515145  -0.0498719   -0.0754579   -0.0319425    0.0670636    -0.0886584    0.0714324     0.0253676     0.0846365    -0.216111    -0.212578    0.0789194   -0.144119    -0.0373441
  0.147026    -0.0429932   0.00568198   0.204781     0.103932     0.0170376    -0.00459008  -0.124514     0.199746    -0.00157741  -0.151101     -0.0768104    0.206595   -0.212741     0.0504984    0.0309365    0.000819626  -0.00486422  -0.0917701     0.076089     -0.0222233     0.122109     0.1224     -0.0649521   -0.134071    -0.0351201[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     16
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.064034
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     14
│     16
│     19
│     20
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.045513
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     14
│     16
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.052599
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     14
│     16
│     19
│     20
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.052825
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     16
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.056031
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     14
│     16
│     19
│     20
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.042220
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     16
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.063232
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     14
│     16
│     19
│     20
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.045615
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     14
│     16
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.052623
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     14
│     16
│     19
│     20
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.052816
┌ Info: EM with 100000 data points 10 iterations avll -1.052816
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind diag, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.179247e+05
      1       6.965847e+05      -1.213400e+05 |       32
      2       6.660676e+05      -3.051712e+04 |       32
      3       6.514968e+05      -1.457080e+04 |       32
      4       6.413947e+05      -1.010209e+04 |       32
      5       6.344934e+05      -6.901288e+03 |       32
      6       6.288278e+05      -5.665561e+03 |       32
      7       6.245024e+05      -4.325401e+03 |       32
      8       6.213626e+05      -3.139799e+03 |       32
      9       6.190170e+05      -2.345662e+03 |       32
     10       6.170622e+05      -1.954726e+03 |       32
     11       6.155972e+05      -1.465011e+03 |       32
     12       6.145434e+05      -1.053808e+03 |       32
     13       6.137527e+05      -7.907466e+02 |       32
     14       6.131852e+05      -5.675116e+02 |       32
     15       6.128387e+05      -3.464987e+02 |       32
     16       6.125769e+05      -2.618084e+02 |       32
     17       6.123794e+05      -1.974428e+02 |       32
     18       6.122095e+05      -1.698996e+02 |       32
     19       6.120647e+05      -1.448602e+02 |       32
     20       6.119462e+05      -1.184706e+02 |       32
     21       6.118542e+05      -9.194805e+01 |       32
     22       6.117873e+05      -6.690742e+01 |       32
     23       6.117315e+05      -5.586883e+01 |       32
     24       6.116913e+05      -4.015721e+01 |       32
     25       6.116632e+05      -2.810489e+01 |       31
     26       6.116421e+05      -2.109437e+01 |       31
     27       6.116209e+05      -2.116029e+01 |       29
     28       6.115998e+05      -2.115801e+01 |       32
     29       6.115753e+05      -2.443776e+01 |       32
     30       6.115535e+05      -2.180244e+01 |       31
     31       6.115390e+05      -1.455903e+01 |       30
     32       6.115286e+05      -1.038309e+01 |       28
     33       6.115176e+05      -1.100910e+01 |       29
     34       6.115076e+05      -1.002192e+01 |       28
     35       6.114994e+05      -8.182632e+00 |       29
     36       6.114928e+05      -6.573018e+00 |       31
     37       6.114854e+05      -7.403678e+00 |       28
     38       6.114793e+05      -6.075536e+00 |       30
     39       6.114728e+05      -6.586377e+00 |       29
     40       6.114663e+05      -6.444044e+00 |       27
     41       6.114600e+05      -6.309090e+00 |       30
     42       6.114561e+05      -3.901953e+00 |       26
     43       6.114520e+05      -4.059307e+00 |       27
     44       6.114462e+05      -5.857297e+00 |       26
     45       6.114417e+05      -4.441579e+00 |       27
     46       6.114367e+05      -4.998912e+00 |       22
     47       6.114329e+05      -3.826271e+00 |       22
     48       6.114299e+05      -3.016630e+00 |       22
     49       6.114273e+05      -2.642232e+00 |       23
     50       6.114251e+05      -2.140575e+00 |       22
K-means terminated without convergence after 50 iterations (objv = 611425.1140999128)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.334872
[ Info: iteration 2, average log likelihood -1.307396
[ Info: iteration 3, average log likelihood -1.276019
[ Info: iteration 4, average log likelihood -1.237174
[ Info: iteration 5, average log likelihood -1.194442
[ Info: iteration 6, average log likelihood -1.149532
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.108369
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.100507
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     17
│     18
│     23
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.067982
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.127378
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.083860
[ Info: iteration 12, average log likelihood -1.089821
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.045730
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     16
│     17
│     18
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.026332
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.088032
[ Info: iteration 16, average log likelihood -1.081594
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      4
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.033696
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     13
│     16
│     17
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.042558
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.089767
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.054275
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      6
│      8
│     16
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.020612
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.080653
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.081741
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.055128
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     16
│     18
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.030264
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│     17
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.051088
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.075846
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.065893
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.033299
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      6
│     12
│     13
│     18
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.036181
[ Info: iteration 31, average log likelihood -1.101164
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      8
│     16
│     17
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.037939
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.052564
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.084287
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.063833
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.033845
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      8
│     13
│     17
│     23
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.022923
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.100233
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.064974
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.033540
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      8
│     13
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.029296
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.087386
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.075224
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.027841
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      6
│      8
│     13
│     18
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.024172
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.101760
[ Info: iteration 47, average log likelihood -1.085916
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.019948
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│      6
│      8
│      ⋮
│     18
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.003660
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.112132
┌ Info: EM with 100000 data points 50 iterations avll -1.112132
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0448043    -0.13433      0.270534    -0.045167    0.0262933    0.0300735   -0.075342     0.0773897   -0.0780478    -0.0463006    -0.104438    -0.140803    -0.0156511   0.117739     0.105125      0.0447882    0.0274229    0.302205     0.00156981  -0.0343018   -0.000861086   0.0268783    -0.0860188     0.116172    -0.0869286   -0.215845
  0.133391     -0.0383842    0.00933028   0.192152    0.105892     0.018693     0.00053977  -0.123618     0.185061      0.000524609  -0.144991    -0.0663063    0.179488   -0.204657     0.0418407     0.0271649   -0.00611826  -0.00736499  -0.0802504    0.0760206   -0.0211706     0.100898      0.0937574    -0.0528784   -0.133308    -0.0371592
  0.0262265     0.320769     0.0310982    0.0727407   0.116838     0.00242813   0.0476102   -0.108662    -0.000305849  -0.150107     -0.0546676    0.0637527    0.0746229  -0.0852658   -0.080357     -0.174133     0.0234856   -0.0158687    0.0109071    0.136812    -0.0424732     0.0295601    -0.021806      0.063583    -0.114065    -0.112169
  0.0130734    -0.0434055   -0.00428857  -0.0408311   0.0181365   -0.0327871    0.039731    -0.00379601   0.0564448     0.018935      0.0280098   -0.152432    -0.0403504   0.021796     0.114687     -0.160036     0.00943934   0.0411013   -0.065677     0.0144278    0.179486      0.0853369     0.104203     -0.123119    -0.0551022   -0.103194
 -0.13709      -0.119642    -0.051855    -0.0141266   0.110258    -0.0945412    0.14195      0.204921     0.115587     -0.0870516    -0.10938      0.0408891    0.0501142  -0.121053     0.0241777    -0.101049    -0.0309466   -0.216785    -0.266861     0.110529     0.0407754    -0.0862549    -0.0309325     0.178335     0.0464398    0.0214149
 -0.0166342    -0.014052     0.0943171    0.136042   -0.0420492   -0.0882838    0.00184978   0.0972265   -0.112883     -0.291803      0.0295019   -0.0395533    0.367004   -0.0735656    0.0769517    -0.131681    -0.106666    -0.285333     0.294958    -0.110974    -0.0685892     0.0774532    -0.141952      0.0325908    0.0746341   -0.15273
 -0.0420024     0.117725    -0.0652476   -0.0203607  -0.0660651   -0.039055    -0.170508    -0.00215713   0.0109759     0.00420154   -0.0329734   -0.160276    -0.083404   -0.154559    -0.0821517    -0.0689286    0.158095     0.189069    -0.0697271   -0.0242423    0.0919306     0.147858     -0.000905349   0.0455195    0.0254122   -0.0483757
 -0.0744516     0.0259002   -0.056903    -0.0682268   0.0676081   -0.0468478    0.0289453   -0.0929569   -0.134444     -0.00809726   -0.0812459    0.00291298  -0.0455285  -0.0952342   -0.0700047    -0.0336091    0.146416    -0.148401     0.0965298    0.00698569   0.064924     -0.229743     -0.237131      0.0417642   -0.133401    -0.0290502
  0.135242      0.140567     0.0424554    0.213306    0.0864767   -0.0594981   -0.00441384   0.079355     0.253437     -0.135834     -0.208325     0.0146182    0.111155    0.0164874   -0.077417     -0.103687    -0.0880227   -0.18721     -0.0355422   -0.137049     0.00852582    0.0381473     0.0837071     0.013133     0.0792013   -0.0758167
  0.0431337     0.0303459   -0.170225     0.0276335   0.0480909   -0.011569    -0.117474    -0.232303     0.196904      0.199622     -0.0690346    0.172821     0.179638    0.0607443   -0.0775102     0.137325    -0.149239     0.04028     -0.0937668   -0.0331028    0.0184534     0.0624874     0.0286502     0.0832727    0.130955    -0.0738112
 -0.0270586     0.0971275   -0.173819     0.0886384   0.0396615   -0.0560786    0.00644266  -0.0383373   -0.0328333     0.00609751    0.10697     -0.0257498   -0.0255176  -0.164163    -0.0125248     0.0123777   -0.0407778    0.0440418    0.0655674   -0.12718     -0.0847083    -0.0133545    -0.0932317    -0.0885666    0.0556727    0.0349582
 -0.0105408    -0.0218219    0.121806    -0.0242069  -0.0782209   -0.029963     0.124336     0.0823381    0.0152266     0.0822114     0.00118132   0.100754     0.150951    0.0447012    0.0408652     0.0364277   -0.139315     0.0868187    0.154404    -0.0206229    0.00484032   -0.0162107     0.105352      0.00181457  -0.207524     0.0104069
 -0.0635386    -0.175727    -0.120341    -0.0956829  -0.0245281   -0.226678    -0.0426459   -0.26149      0.192969     -0.175985     -0.0252646   -0.0321761   -0.0921604  -0.124317    -0.167768     -0.0614679   -0.217627    -0.107132     0.167358    -0.0447068   -0.0754981     0.0829722    -0.176443     -0.0491821    0.0258589   -0.0534352
 -0.0345816     0.118475     0.0400042    0.233498    0.0226222   -0.132668     0.0536489   -0.0752139    0.221633      0.163051      0.0307244   -0.094278     0.22974     0.0946614    0.203711      0.0389977    0.093573     0.165016     0.0419431    0.245589    -0.0688259    -0.0878516     0.0616458    -0.0255768    0.157137     0.0240763
  0.0301922    -0.0469359    0.138802     0.0354403  -0.00982445   0.0708969    0.0142445   -0.133987     0.0447474     0.193021      0.0847145    0.0290335   -0.0720226  -0.130067    -0.0515145     0.14395      0.162018     0.0446665    0.0798327   -0.0074244    0.0486876    -0.000109819  -0.157976      0.152615    -0.0489578   -0.125842
 -0.138794     -0.023805     0.0785462   -0.0415171   0.094424    -0.00948408  -0.0738688   -0.0349035   -0.0600036     0.122474     -0.0812199    0.0711083   -0.0385756  -0.162238    -0.122864      0.0997946   -0.105593    -0.11715      0.0712358   -0.0210831    0.0644197    -0.0663756     0.0837281     0.030294    -0.0258287   -0.120209
 -0.142812     -0.0065916    0.0838557   -0.0604196  -0.124047     0.19149      0.0282337   -0.0678551    0.0246432     0.106053     -0.0451311    0.0200155    0.317863    0.167912     0.0730846    -0.00326834  -0.0647805    0.0201772    0.0588435    0.0227792   -0.0243469    -0.116321     -0.0136107     0.0185652    0.0817241   -0.0706761
  0.084984     -0.111338    -0.105755    -0.0872355   0.180671    -0.0719429   -0.235146     0.135497    -0.013355     -0.11164      -0.0813857   -0.120888     0.154405    0.00804372   0.0443561     0.0924018   -0.107447    -0.369941    -0.0343023   -0.167323     0.107788      0.00482409   -0.0604832     0.0402352    0.123424     0.128451
  0.000880918  -0.074702    -0.161072     0.0522818   0.0435415    0.072222     0.0860707    0.0645434    0.10023       0.276113     -0.00755429  -0.0821618   -0.125202   -0.0162398    0.0214669     0.0390053    0.0678842    0.0113671    0.0329637   -0.0977716   -0.0427713    -0.174446      0.0276769     0.0620548   -0.0618337    0.108331
 -0.0455103    -0.0390484    0.0741771   -0.030248    0.00799627  -0.0466864    0.0214742   -0.0329021    0.0310537    -0.0460327     0.0595519   -0.00708667   0.0361246   0.126982     0.12821       0.0474451   -0.00119608   0.0775568   -0.00323835   0.0431679   -0.0699681    -0.00379143    0.0101541    -0.108258     0.191062     0.0564239
  0.0206767     0.0680083   -0.163778    -0.0548808   0.0483036    0.127022    -0.0371019    0.0447321    0.00041761    0.112587     -0.0190451    0.0636648    0.0538658   0.03636      0.0370587     0.0492131    0.0955065    0.210272     0.132834    -0.0989288   -0.022395      0.0872998    -0.10076       0.0345722   -0.106377    -0.0132571
 -0.0682098    -0.0736209   -0.0574015    0.0675284   0.269431    -0.0709783    0.246629    -0.0432782    0.0829559    -0.0835715    -0.107211    -0.0793895   -0.26009    -0.0874309    0.0684684     0.107045     0.0340527   -0.0218215    0.234433     0.219758     0.00189725   -0.0968216     0.0592122    -0.00909187   0.116151    -0.056245
 -0.029976     -0.0425505    0.0512987    0.0217232   0.0506826   -0.133641    -0.190565    -0.152712    -0.136441     -0.139981     -0.0786062    0.0543203    0.0702649   0.00472163   0.0507376     0.00136066  -0.143702     0.191339    -0.0584577    0.107202    -0.0323252    -0.101608     -0.107627      0.0488502   -0.0761507    0.0177548
  0.127871     -0.0415126   -0.130597    -0.155902   -0.0322852   -0.0495159    0.0553466    0.0544093   -0.18257       0.00527953   -0.0706431   -0.0859111   -0.0461652  -0.0854751   -0.0138602     0.0922098   -0.0413041    0.0985279    0.0109399    0.00303112   0.11045       0.14342      -0.137353     -0.120765     0.0883105    0.085983
  0.100586     -0.0588661   -0.121479     0.118855    0.0271457    0.0103955    0.0104851    0.0532816   -0.0373006     0.149301      0.0212574    0.134952    -0.0442679   0.0165125   -0.0949377    -0.123828     0.0681807    0.0540394   -0.00884199  -0.00511699  -0.136931     -0.0148803    -0.10544      -0.0740417   -0.0835145    0.188986
  0.0486536     0.0160358   -0.127097    -0.0649981  -0.0357756   -0.0452728    0.0732498   -0.122584     0.0442638     0.0364024     0.0448595   -0.0323235   -0.193151   -0.017187    -0.0110651     0.00978093  -0.0644262   -0.0671159    0.00933841  -0.0458198    0.0493065    -0.0690476     0.0755945    -0.11782     -0.0638223    0.0606478
 -0.0443728    -0.0785155    0.0359326   -0.172724    0.159945     0.0154076   -0.0479584    0.103932    -0.0775645     0.0044462    -0.126263     0.11511     -0.0545328  -0.0373434    0.0935481    -0.0201147   -0.196927    -0.199591     0.034634    -0.01318      0.0334896    -0.00280427    0.203299      0.196532     0.0814238   -0.0585003
  0.187709     -0.175777     0.0578122    0.0601092   0.0315373    0.0862898    0.0261373   -0.0974247    0.0286444     0.0205681    -0.132001    -0.119961     0.0197444  -0.0373239    0.0685063    -0.0206974   -0.262679    -0.0560572    0.0278076    0.060825     0.116509     -0.226721      0.114705     -0.0330039   -0.0845993   -0.11107
 -0.15476       0.00708869  -0.101241     0.0121647   0.0198316    0.0874359   -0.0782869    0.00139849  -0.00567049    0.00156735    0.130578    -0.0388964   -0.0701113   0.0596506   -0.0300365     0.0197407    0.0407715   -0.0395812    0.195757     0.0206043   -0.0410398     0.11382      -0.0757372    -0.10516      0.00434059  -0.0320267
  0.167961     -0.0060763    0.136381     0.149326    0.166416    -0.0518286    0.00399207  -0.0423238    0.00762317    0.0852266     0.0122288    0.0128787   -0.081567    0.0369718   -0.000888768   0.0338283    0.0322971    0.0569558    0.0307173    0.0409941    0.0497574     0.14844       0.0878283    -0.0255503   -0.0192728    0.0120506
 -0.150131      0.143058    -0.0669132   -0.0746496   0.0402381    0.0906946    0.00906456   0.121441    -0.0168894    -0.0588872    -0.102873     0.0853253    0.128303    0.0488897   -0.0651422    -0.0787972   -0.0252122    0.0604882   -0.0888753    0.0516261    0.00922651    0.0711915    -0.0738074     0.01197     -0.0373575   -0.178446
  0.324209      0.103796     0.00162207  -0.0977742  -0.129766    -0.0994633    0.107201     0.0251201   -0.0193635    -0.137794     -0.250987     0.180547    -0.0207137   0.00662496   0.180414      0.0168823   -0.0526692   -0.0445212    0.185252    -0.0639422   -0.0559905     0.0813004     0.0443563    -0.0296854    0.14085      0.0960653[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.077694
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.019684
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      8
│     13
│      ⋮
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.993479
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     12
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.038587
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.025735
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      8
│     13
│      ⋮
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.986542
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     12
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.038684
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.025785
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      8
│     13
│      ⋮
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.986545
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     12
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.038737
┌ Info: EM with 100000 data points 10 iterations avll -1.038737
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0186877   -0.15842      -0.165631     0.346147     0.00584307  -0.0462522    0.128068     -0.0784305   -0.104182     0.0367453     0.00242292   -0.0541194    0.00868107  -0.131064     0.032162     0.0954752     0.0805785  -0.0611339   -0.0619373  -0.065011     0.185179    -0.170973    -0.11311     -0.120382    -0.10796     -0.113496
  0.00712829   0.162962      0.0809872    0.00742694  -0.124534     0.0200697    0.101103     -0.135503     0.0383105   -0.123927      0.0788084     0.0483307    0.110297     0.00297571   0.0127163   -0.000764878   0.131921   -0.199306    -0.0307198  -0.0834572   -0.0598793   -0.0257423    0.221004    -0.00143992   0.00301992   0.114676
  0.0448661   -0.110845     -0.123725     0.0644606   -0.052869     0.103634     0.123749      0.0806466   -0.0481966    0.0980304     0.193037     -0.015332    -0.00211156   0.17093     -0.0908627    0.0228793     0.0122087  -0.0677595   -0.0454633  -0.00843668   0.052124    -0.0245113    0.0476851    0.0740043    0.177217     0.0191633
 -0.0847213   -0.0367595     0.0073374    0.0741435   -0.236703    -0.0539477    0.00967347   -0.258046     0.0736808   -0.134013      0.131738     -0.0521173   -0.040039    -0.00207725  -0.194786     0.0300519    -0.134055    0.0287611   -0.205006   -0.00606307   0.0905512   -0.168204    -0.0106292   -0.00905724   0.0355731    0.0380617
 -0.061308    -0.0467835     0.107618     0.171128    -0.169682    -0.0893734   -0.0376798     0.0992245    0.102468    -0.0678611     0.122343      0.0254396    0.126722    -0.136285     0.0672591   -0.101468      0.150543   -0.069948    -0.247951    0.0312379    0.251771     0.115556    -0.0953669    0.0479922   -0.0596182    0.0727076
  0.144703    -0.0999331    -0.11401     -0.00770437   0.0231305    0.0548508   -0.0545942     0.0216233   -0.00333825  -0.0665662     0.0859953    -0.0496028   -0.0702541   -0.0831344    0.0336024   -0.0642446    -0.0560671   0.189051     0.0251528  -0.100997    -0.0156595   -0.139398     0.140825     0.00137446   0.0108962    0.148304
  0.013269     0.0504671     0.0797157   -0.00928384   0.0972613   -0.0106713   -0.0857105    -0.013483    -0.146725    -0.0120139    -0.0189374    -0.0531999    0.0131738    0.0338104    0.0443034    0.109614     -0.0929374   0.157317    -0.0356086  -0.0808706   -0.127506     0.136686    -0.0920109   -0.0576443   -0.0861813   -0.0424106
 -0.0785904    0.0767596     0.13153      0.0773745    0.0588843   -0.0522929    0.020346     -0.0325181   -0.10739     -0.0536254    -0.0827735     0.124107     0.0676243    0.0299066    0.0217285    0.0630441     0.0195734   0.022081    -0.0163629   0.0142764   -0.0792477    0.00643233  -0.110437    -0.137727     0.00276573   0.0521396
  0.092541     0.0305948     0.00310401   0.218213     0.0615885    0.0172539    0.069342     -0.102991    -0.0256129    0.168746     -0.188761     -0.0822341    0.0987706   -0.0209183    3.88137e-5   0.03782      -0.109489    0.0177965   -0.0553046   0.0149872    0.0956995   -0.0438707   -0.0433955   -0.00519874  -0.101246    -0.143355
 -0.065915    -0.0205656     0.0719203    0.0255442   -0.183537    -0.155864     0.0149603    -0.010359     0.0856328   -0.155437      0.128901      0.217049    -0.0406146    0.00642239  -0.0467147    0.0200597     0.0543723   0.147371    -0.0204828  -0.0419371   -0.158024    -0.0337796   -0.0459812    0.156337    -0.147935    -0.131103
  0.0772383   -0.10946      -0.253403     0.107847     0.0202287    0.115967     0.0575407     0.0887537    0.0448112    0.0805831    -0.0539073    -0.00686686   0.157747     0.0713324   -0.0190292    0.10343       0.0185983  -0.0148955   -0.130967   -0.0545357    0.0109132    0.189286     0.0767854    0.00825877  -0.0577605   -0.0101728
 -0.0808428   -0.0144706    -0.0293625    0.173157    -0.0605469    0.0906254   -0.0656869     0.0990859   -0.0871789   -0.125857      0.0630196     0.107392    -0.103249     0.0291511   -0.0296338   -0.0876651     0.175137   -0.0810488    0.10571    -0.0415572   -0.124009     0.125087     0.177844    -0.0430814   -0.0855824   -0.124716
  0.129561     0.211316      0.0648293   -0.1164      -0.145314    -0.0321043    0.0353663     0.0687233    0.0310247   -0.142565     -0.0548391    -0.0884186   -0.0363332   -0.00162637   0.00789503  -0.0712674    -0.0925184   0.0163789    0.0184516  -0.089866     0.138829     0.0258484   -0.00971893   0.0673594   -0.188126     0.0521628
  0.137827     0.00944292    0.141514    -0.0644026    0.0147392    0.158268    -0.0922594     0.0632434    0.0505574    0.055897      0.0132988     0.0233146   -0.167806    -0.0875275    0.117612    -0.0124959     0.0184638  -0.0650379    0.0944997   0.0981186    0.0223581    0.00556553  -0.0310574    0.172739     0.0212213    0.00348919
  0.0914781   -0.0190192    -0.048315     0.124532     0.0931181    0.0817116    0.196923     -0.0443355   -0.130573    -0.190969      0.00463742    0.166941    -0.0470038    0.00992146  -0.189031     0.0500569     0.0651421  -0.279317    -0.0296744   0.0397867   -0.0699725    0.0388197    0.0914988   -0.0901579    0.162106    -0.0744725
  0.189581     0.111542      0.0682013   -0.0719408   -0.0545076    0.042042     0.0190479     0.0939702   -0.0606769   -0.062797      0.137639     -0.131999     0.170767     0.151114    -0.038045    -0.103616     -0.196724   -0.152496    -0.0383195  -0.0436186    0.0905029   -0.187988     0.166681    -0.00641928  -0.0200683    0.0376518
 -0.0848017   -0.070835      0.254643     0.165887    -0.152435     0.00796767   0.219427     -0.154046     0.0719137   -0.000539804   0.0986448    -0.0733427    0.186154     0.10999     -0.0046616    0.107164      0.0777494   0.119083     0.0336427  -0.128755    -0.0922561   -0.0574314   -0.0532074   -0.125248     0.071409    -0.0188977
 -0.212628    -0.0404581     0.0355782   -0.049744     0.0577054   -0.044365     0.174294      0.143633     0.00116548  -0.0497242     0.138501      0.0408691    0.198857    -0.0306737    0.129767     0.0250962     0.0197187  -0.0120633   -0.0567994  -0.0670798   -0.152834     0.0909309   -0.0370606   -0.0829891   -0.119692    -0.121056
  0.133811    -0.121736     -0.0184784   -0.0140183    0.179951    -0.00152403   0.0128387    -0.0346727    0.00664987  -0.0118295     0.0342174     0.0257798    0.0611136   -0.0462559   -0.0741201   -0.0458337     0.154354   -0.155195     0.0431255   0.0308252   -0.121825     0.019889     0.0930929   -0.0974504    0.00211527  -0.0655772
 -0.0157356    0.0160889    -0.072889     0.0825116   -0.157743     0.13892      0.0764303    -0.0269896    0.0576763   -0.0765513     0.0555529     0.0994118   -0.0100957   -0.00776797  -0.00288611  -0.075869      0.0224621  -0.0808343   -0.0789079   0.0581358    0.140257    -0.0166364    0.00239225  -0.148246     0.179855     0.0386275
  0.00382353   0.033727     -0.00842298   0.0916415   -0.185521    -0.0386813    0.0458553     0.0863782    0.0239241   -0.165216     -0.137551     -0.158595    -0.0259051   -0.0454685    0.0125046   -0.00895895    0.155682    0.0178363   -0.0961587   0.0226115    0.042196     0.0138745   -0.0078281   -0.0461096   -0.0879809    0.128205
 -0.0325391    0.0388364    -0.0279885   -0.0486478    0.053183    -0.0470058   -0.053019      0.00108372   0.0821633    0.0896644     0.000485118   0.0537958   -0.0188375   -0.0589171    0.0968972    0.0554613     0.134709    0.0424113    0.0869954  -0.108096    -0.0237291    0.210246     0.0470645    0.0845278   -0.0736083   -0.0894821
  0.0606066    0.035253      0.10526      0.00487224   0.0201886   -0.0300041   -0.197826     -0.167719     0.0112468   -0.0889772    -0.113497     -0.0235067   -0.0167109   -0.0534152   -0.011245    -0.163863     -0.0695723   0.14736      0.0673678   0.00630351  -0.123233    -0.0515223   -0.034019    -0.0472078   -0.104841    -0.110078
 -0.126046    -0.109476     -0.126356    -0.0546559   -0.0472934    0.0147591    0.0351988     0.0503668   -0.0402037    0.0476508    -0.0113968    -0.0732378    0.00869465   0.0273771    0.033144    -0.0155416     0.0993286  -0.115974    -0.147575    0.0691045    0.0522375    0.0871013   -0.00642875  -0.1764       0.0509547    0.131045
 -0.0745203    0.0428494    -0.0124868    0.0103424   -0.0169955    0.0244654    0.0410018    -0.0187681   -0.0503625   -0.14665      -0.0406787     0.181861    -0.106946    -0.0303356   -0.0510347   -0.28926      -0.083339    0.0641414    0.106922   -0.119987     0.00721094  -0.0434873   -0.0358171   -0.0767964   -0.131908     0.0861735
 -0.0876804    0.196889     -0.0467676   -0.0580977    0.0903051    0.00403282   0.0773689    -0.0677863   -0.0392224   -0.0383719     0.165624     -0.0930786    0.00303339  -0.113299    -0.00719705   0.080823     -0.0181057  -0.168504     0.0305761   0.0748301    0.0997252    0.0434568    0.127638     0.062343    -0.143003     0.13875
 -0.08446      0.0453544     0.0161253    0.165618    -0.00289334  -0.0425926    0.158828     -0.0815415   -0.0500218   -0.154169      0.14665      -0.0717334   -0.0820172    0.0475329    0.011299    -0.0180876     0.0653771   0.174012    -0.112245    0.101848    -0.0582179    0.0017238    0.0842676   -0.118595    -0.118911     0.0849923
  0.1725       0.054762     -0.0852275    0.0750755    0.120994    -0.130179    -0.0453298    -0.175723    -0.0608742   -0.236303     -0.0534378    -0.0888666    0.133807     0.167095    -0.0771186    0.243695     -0.0110088   0.11982     -0.148953   -0.122436     0.0155545   -0.115397    -0.0619474    0.115331     0.108563     0.0603169
  0.00106088  -0.00343723   -0.122023     0.0553632   -0.0630388    0.150263    -0.000505692  -0.110464    -0.0976897    0.0407807    -0.00375443    0.0541477   -0.0269974   -0.037922     0.0403105    0.0201634    -0.134268    0.00417465   0.0947234  -0.183333    -0.100111    -0.112064    -0.042535     0.0955594   -0.136953     0.00862971
  0.0850884    0.000540956   0.0656234    0.0661136    0.0940268   -0.0628752    0.0486027     0.0457149    0.0114786   -0.0670048     0.0950699    -0.0412382   -0.0977001    0.0955594    0.0717242   -0.0215555     0.102937    0.112864     0.0965304  -0.0111473   -0.137692    -0.048199    -0.113179     0.208283    -0.0918088    0.137568
  0.0532267   -0.0550858    -0.119714     0.13204      0.0320646   -0.057023    -0.099373     -0.145904     0.0553836    0.14943       0.0533839     0.0281841   -0.00155312  -0.15916      0.090437    -0.0475258    -0.0670329  -0.00119863  -0.12568     0.049829     0.0354916   -0.135121     0.0392525    0.0703613   -0.0242172   -0.0120909
  0.0983769    0.0642936     0.0151052    0.19598      0.30872     -0.0020965    0.0768877    -0.0856401    0.0143551    0.112672     -0.180645     -0.0474026   -0.00703661  -0.173194     0.0192232    0.0910941    -0.0402419   0.10899      0.0600439  -0.104694    -0.150174    -0.029693     0.113671    -0.0147427    0.0670927    0.0688083kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4208067472117598
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420825
[ Info: iteration 2, average log likelihood -1.420769
[ Info: iteration 3, average log likelihood -1.420725
[ Info: iteration 4, average log likelihood -1.420673
[ Info: iteration 5, average log likelihood -1.420609
[ Info: iteration 6, average log likelihood -1.420532
[ Info: iteration 7, average log likelihood -1.420443
[ Info: iteration 8, average log likelihood -1.420340
[ Info: iteration 9, average log likelihood -1.420211
[ Info: iteration 10, average log likelihood -1.420016
[ Info: iteration 11, average log likelihood -1.419669
[ Info: iteration 12, average log likelihood -1.419037
[ Info: iteration 13, average log likelihood -1.418053
[ Info: iteration 14, average log likelihood -1.416925
[ Info: iteration 15, average log likelihood -1.416053
[ Info: iteration 16, average log likelihood -1.415581
[ Info: iteration 17, average log likelihood -1.415372
[ Info: iteration 18, average log likelihood -1.415287
[ Info: iteration 19, average log likelihood -1.415251
[ Info: iteration 20, average log likelihood -1.415236
[ Info: iteration 21, average log likelihood -1.415230
[ Info: iteration 22, average log likelihood -1.415227
[ Info: iteration 23, average log likelihood -1.415225
[ Info: iteration 24, average log likelihood -1.415224
[ Info: iteration 25, average log likelihood -1.415223
[ Info: iteration 26, average log likelihood -1.415222
[ Info: iteration 27, average log likelihood -1.415221
[ Info: iteration 28, average log likelihood -1.415221
[ Info: iteration 29, average log likelihood -1.415220
[ Info: iteration 30, average log likelihood -1.415220
[ Info: iteration 31, average log likelihood -1.415220
[ Info: iteration 32, average log likelihood -1.415219
[ Info: iteration 33, average log likelihood -1.415219
[ Info: iteration 34, average log likelihood -1.415219
[ Info: iteration 35, average log likelihood -1.415218
[ Info: iteration 36, average log likelihood -1.415218
[ Info: iteration 37, average log likelihood -1.415218
[ Info: iteration 38, average log likelihood -1.415218
[ Info: iteration 39, average log likelihood -1.415218
[ Info: iteration 40, average log likelihood -1.415218
[ Info: iteration 41, average log likelihood -1.415217
[ Info: iteration 42, average log likelihood -1.415217
[ Info: iteration 43, average log likelihood -1.415217
[ Info: iteration 44, average log likelihood -1.415217
[ Info: iteration 45, average log likelihood -1.415217
[ Info: iteration 46, average log likelihood -1.415217
[ Info: iteration 47, average log likelihood -1.415217
[ Info: iteration 48, average log likelihood -1.415217
[ Info: iteration 49, average log likelihood -1.415217
[ Info: iteration 50, average log likelihood -1.415217
┌ Info: EM with 100000 data points 50 iterations avll -1.415217
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4208252083788628
│     -1.420768507640652
│      ⋮
└     -1.4152168325424932
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415232
[ Info: iteration 2, average log likelihood -1.415175
[ Info: iteration 3, average log likelihood -1.415126
[ Info: iteration 4, average log likelihood -1.415065
[ Info: iteration 5, average log likelihood -1.414987
[ Info: iteration 6, average log likelihood -1.414890
[ Info: iteration 7, average log likelihood -1.414776
[ Info: iteration 8, average log likelihood -1.414655
[ Info: iteration 9, average log likelihood -1.414537
[ Info: iteration 10, average log likelihood -1.414433
[ Info: iteration 11, average log likelihood -1.414348
[ Info: iteration 12, average log likelihood -1.414283
[ Info: iteration 13, average log likelihood -1.414236
[ Info: iteration 14, average log likelihood -1.414201
[ Info: iteration 15, average log likelihood -1.414176
[ Info: iteration 16, average log likelihood -1.414157
[ Info: iteration 17, average log likelihood -1.414141
[ Info: iteration 18, average log likelihood -1.414128
[ Info: iteration 19, average log likelihood -1.414117
[ Info: iteration 20, average log likelihood -1.414106
[ Info: iteration 21, average log likelihood -1.414097
[ Info: iteration 22, average log likelihood -1.414089
[ Info: iteration 23, average log likelihood -1.414081
[ Info: iteration 24, average log likelihood -1.414074
[ Info: iteration 25, average log likelihood -1.414068
[ Info: iteration 26, average log likelihood -1.414062
[ Info: iteration 27, average log likelihood -1.414057
[ Info: iteration 28, average log likelihood -1.414052
[ Info: iteration 29, average log likelihood -1.414047
[ Info: iteration 30, average log likelihood -1.414043
[ Info: iteration 31, average log likelihood -1.414039
[ Info: iteration 32, average log likelihood -1.414036
[ Info: iteration 33, average log likelihood -1.414032
[ Info: iteration 34, average log likelihood -1.414029
[ Info: iteration 35, average log likelihood -1.414026
[ Info: iteration 36, average log likelihood -1.414023
[ Info: iteration 37, average log likelihood -1.414021
[ Info: iteration 38, average log likelihood -1.414018
[ Info: iteration 39, average log likelihood -1.414016
[ Info: iteration 40, average log likelihood -1.414014
[ Info: iteration 41, average log likelihood -1.414011
[ Info: iteration 42, average log likelihood -1.414009
[ Info: iteration 43, average log likelihood -1.414007
[ Info: iteration 44, average log likelihood -1.414006
[ Info: iteration 45, average log likelihood -1.414004
[ Info: iteration 46, average log likelihood -1.414002
[ Info: iteration 47, average log likelihood -1.414000
[ Info: iteration 48, average log likelihood -1.413999
[ Info: iteration 49, average log likelihood -1.413997
[ Info: iteration 50, average log likelihood -1.413996
┌ Info: EM with 100000 data points 50 iterations avll -1.413996
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4152318167737417
│     -1.4151750574582227
│      ⋮
└     -1.4139960548701822
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414004
[ Info: iteration 2, average log likelihood -1.413943
[ Info: iteration 3, average log likelihood -1.413888
[ Info: iteration 4, average log likelihood -1.413826
[ Info: iteration 5, average log likelihood -1.413751
[ Info: iteration 6, average log likelihood -1.413661
[ Info: iteration 7, average log likelihood -1.413558
[ Info: iteration 8, average log likelihood -1.413449
[ Info: iteration 9, average log likelihood -1.413340
[ Info: iteration 10, average log likelihood -1.413237
[ Info: iteration 11, average log likelihood -1.413145
[ Info: iteration 12, average log likelihood -1.413067
[ Info: iteration 13, average log likelihood -1.413003
[ Info: iteration 14, average log likelihood -1.412952
[ Info: iteration 15, average log likelihood -1.412912
[ Info: iteration 16, average log likelihood -1.412881
[ Info: iteration 17, average log likelihood -1.412857
[ Info: iteration 18, average log likelihood -1.412838
[ Info: iteration 19, average log likelihood -1.412823
[ Info: iteration 20, average log likelihood -1.412811
[ Info: iteration 21, average log likelihood -1.412801
[ Info: iteration 22, average log likelihood -1.412792
[ Info: iteration 23, average log likelihood -1.412784
[ Info: iteration 24, average log likelihood -1.412776
[ Info: iteration 25, average log likelihood -1.412769
[ Info: iteration 26, average log likelihood -1.412763
[ Info: iteration 27, average log likelihood -1.412756
[ Info: iteration 28, average log likelihood -1.412750
[ Info: iteration 29, average log likelihood -1.412744
[ Info: iteration 30, average log likelihood -1.412738
[ Info: iteration 31, average log likelihood -1.412732
[ Info: iteration 32, average log likelihood -1.412726
[ Info: iteration 33, average log likelihood -1.412720
[ Info: iteration 34, average log likelihood -1.412715
[ Info: iteration 35, average log likelihood -1.412709
[ Info: iteration 36, average log likelihood -1.412703
[ Info: iteration 37, average log likelihood -1.412698
[ Info: iteration 38, average log likelihood -1.412692
[ Info: iteration 39, average log likelihood -1.412687
[ Info: iteration 40, average log likelihood -1.412681
[ Info: iteration 41, average log likelihood -1.412676
[ Info: iteration 42, average log likelihood -1.412670
[ Info: iteration 43, average log likelihood -1.412665
[ Info: iteration 44, average log likelihood -1.412660
[ Info: iteration 45, average log likelihood -1.412654
[ Info: iteration 46, average log likelihood -1.412649
[ Info: iteration 47, average log likelihood -1.412644
[ Info: iteration 48, average log likelihood -1.412639
[ Info: iteration 49, average log likelihood -1.412633
[ Info: iteration 50, average log likelihood -1.412628
┌ Info: EM with 100000 data points 50 iterations avll -1.412628
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4140043363183212
│     -1.413942759214555
│      ⋮
└     -1.4126280804726496
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412632
[ Info: iteration 2, average log likelihood -1.412566
[ Info: iteration 3, average log likelihood -1.412504
[ Info: iteration 4, average log likelihood -1.412430
[ Info: iteration 5, average log likelihood -1.412337
[ Info: iteration 6, average log likelihood -1.412223
[ Info: iteration 7, average log likelihood -1.412090
[ Info: iteration 8, average log likelihood -1.411947
[ Info: iteration 9, average log likelihood -1.411804
[ Info: iteration 10, average log likelihood -1.411670
[ Info: iteration 11, average log likelihood -1.411551
[ Info: iteration 12, average log likelihood -1.411447
[ Info: iteration 13, average log likelihood -1.411358
[ Info: iteration 14, average log likelihood -1.411281
[ Info: iteration 15, average log likelihood -1.411216
[ Info: iteration 16, average log likelihood -1.411160
[ Info: iteration 17, average log likelihood -1.411112
[ Info: iteration 18, average log likelihood -1.411069
[ Info: iteration 19, average log likelihood -1.411031
[ Info: iteration 20, average log likelihood -1.410998
[ Info: iteration 21, average log likelihood -1.410967
[ Info: iteration 22, average log likelihood -1.410939
[ Info: iteration 23, average log likelihood -1.410913
[ Info: iteration 24, average log likelihood -1.410888
[ Info: iteration 25, average log likelihood -1.410865
[ Info: iteration 26, average log likelihood -1.410843
[ Info: iteration 27, average log likelihood -1.410822
[ Info: iteration 28, average log likelihood -1.410802
[ Info: iteration 29, average log likelihood -1.410783
[ Info: iteration 30, average log likelihood -1.410764
[ Info: iteration 31, average log likelihood -1.410746
[ Info: iteration 32, average log likelihood -1.410728
[ Info: iteration 33, average log likelihood -1.410711
[ Info: iteration 34, average log likelihood -1.410694
[ Info: iteration 35, average log likelihood -1.410678
[ Info: iteration 36, average log likelihood -1.410662
[ Info: iteration 37, average log likelihood -1.410647
[ Info: iteration 38, average log likelihood -1.410632
[ Info: iteration 39, average log likelihood -1.410618
[ Info: iteration 40, average log likelihood -1.410604
[ Info: iteration 41, average log likelihood -1.410591
[ Info: iteration 42, average log likelihood -1.410578
[ Info: iteration 43, average log likelihood -1.410565
[ Info: iteration 44, average log likelihood -1.410553
[ Info: iteration 45, average log likelihood -1.410542
[ Info: iteration 46, average log likelihood -1.410531
[ Info: iteration 47, average log likelihood -1.410520
[ Info: iteration 48, average log likelihood -1.410510
[ Info: iteration 49, average log likelihood -1.410500
[ Info: iteration 50, average log likelihood -1.410490
┌ Info: EM with 100000 data points 50 iterations avll -1.410490
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4126315124873545
│     -1.4125662733842093
│      ⋮
└     -1.410489868435294
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410489
[ Info: iteration 2, average log likelihood -1.410423
[ Info: iteration 3, average log likelihood -1.410358
[ Info: iteration 4, average log likelihood -1.410282
[ Info: iteration 5, average log likelihood -1.410185
[ Info: iteration 6, average log likelihood -1.410062
[ Info: iteration 7, average log likelihood -1.409914
[ Info: iteration 8, average log likelihood -1.409747
[ Info: iteration 9, average log likelihood -1.409572
[ Info: iteration 10, average log likelihood -1.409400
[ Info: iteration 11, average log likelihood -1.409238
[ Info: iteration 12, average log likelihood -1.409090
[ Info: iteration 13, average log likelihood -1.408957
[ Info: iteration 14, average log likelihood -1.408839
[ Info: iteration 15, average log likelihood -1.408734
[ Info: iteration 16, average log likelihood -1.408641
[ Info: iteration 17, average log likelihood -1.408559
[ Info: iteration 18, average log likelihood -1.408485
[ Info: iteration 19, average log likelihood -1.408419
[ Info: iteration 20, average log likelihood -1.408358
[ Info: iteration 21, average log likelihood -1.408303
[ Info: iteration 22, average log likelihood -1.408253
[ Info: iteration 23, average log likelihood -1.408206
[ Info: iteration 24, average log likelihood -1.408163
[ Info: iteration 25, average log likelihood -1.408122
[ Info: iteration 26, average log likelihood -1.408085
[ Info: iteration 27, average log likelihood -1.408049
[ Info: iteration 28, average log likelihood -1.408016
[ Info: iteration 29, average log likelihood -1.407985
[ Info: iteration 30, average log likelihood -1.407956
[ Info: iteration 31, average log likelihood -1.407929
[ Info: iteration 32, average log likelihood -1.407903
[ Info: iteration 33, average log likelihood -1.407878
[ Info: iteration 34, average log likelihood -1.407855
[ Info: iteration 35, average log likelihood -1.407833
[ Info: iteration 36, average log likelihood -1.407812
[ Info: iteration 37, average log likelihood -1.407793
[ Info: iteration 38, average log likelihood -1.407775
[ Info: iteration 39, average log likelihood -1.407757
[ Info: iteration 40, average log likelihood -1.407741
[ Info: iteration 41, average log likelihood -1.407726
[ Info: iteration 42, average log likelihood -1.407711
[ Info: iteration 43, average log likelihood -1.407698
[ Info: iteration 44, average log likelihood -1.407685
[ Info: iteration 45, average log likelihood -1.407673
[ Info: iteration 46, average log likelihood -1.407661
[ Info: iteration 47, average log likelihood -1.407650
[ Info: iteration 48, average log likelihood -1.407639
[ Info: iteration 49, average log likelihood -1.407629
[ Info: iteration 50, average log likelihood -1.407619
┌ Info: EM with 100000 data points 50 iterations avll -1.407619
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.410488914408505
│     -1.4104225039040612
│      ⋮
└     -1.4076191154547164
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4208067472117598
│     -1.4208252083788628
│     -1.420768507640652
│     -1.420725383129467
│      ⋮
│     -1.4076390930680183
│     -1.4076289053738011
└     -1.4076191154547164
32×26 Array{Float64,2}:
 -0.543141   -0.163838   -0.0257372   0.406116    0.317968    0.0158126   0.247058   -0.0429591   0.458432     0.538176    -0.122152    -0.0780404   0.138875    0.209239     0.622969    -0.324906   -0.0396959   0.172173   -0.0469076  -0.58895    -0.0235017   -0.106215    -0.234515    -0.739227   -0.062154    0.295969
 -0.114749    0.245373   -0.0721013   0.296784   -0.184405    0.159217   -0.0937886   0.141755   -0.205528    -0.198144     0.201824     0.0804377  -0.0170649  -0.25094     -0.239734     0.0657511  -0.140668   -0.0402346   0.0648992   0.3316      0.0568744    0.077484     0.129832     0.0506872  -0.15533     0.0671388
 -0.476868    0.1921     -0.162017    0.214969    0.0807559  -0.12274     0.0848797  -0.475436    0.0173573   -0.255155     0.0532113   -0.77278     0.236368   -0.581026     0.421365    -0.0678638  -0.850267   -0.563768   -0.016903   -0.22209     0.258165     0.400096     0.311813    -0.338017    0.0717531   0.242143
  0.287135    0.0653694   0.19295     0.636609    0.213957    0.517609    0.271292   -0.223542    0.092141     0.349488     0.515684    -0.13853    -0.0449649  -0.694422     0.934045    -0.507754   -0.663322    0.289736   -0.0843287   0.492969   -0.229803    -0.171442     0.45793     -0.306973   -0.175552   -0.401645
  0.538391   -0.415007    0.121908   -0.659968    0.1426     -0.407875    0.0278417  -0.511348   -0.154755    -0.217089    -0.0025302   -0.282637    0.278914    0.100229    -0.00459122   0.110993    0.17588    -0.0908836  -0.177895   -0.1111     -0.170461     0.0454375   -0.00959759   0.334461    0.0396587  -0.738772
  0.275719   -0.239416    0.0962393  -0.360836   -0.1601      0.527642    0.328627   -0.579965   -0.330909    -0.599782     0.391849     0.738867   -0.307292    0.346481     0.767006    -0.154306    0.344551   -0.107479    0.0145814  -0.470757    0.212434     0.148626     0.745527     0.0338129   0.530535    0.322321
  0.127978   -0.29301    -0.0241504   0.845357   -0.254853    0.49798     0.263072   -0.546279   -0.088314     0.370232     0.760544     0.491107    0.0812503  -0.219207     0.122336    -0.100973   -0.32305    -0.210007   -0.649652   -0.0515622  -0.317524    -0.185132    -0.503135     0.503544    0.508376   -0.460561
 -0.364228   -0.347835    0.304241    0.983552    0.0164416  -0.146917   -0.110322   -0.114244   -0.408099    -0.152944    -0.055842    -0.176062    0.612853    0.312418    -0.106454    -0.709066    0.0789451  -0.55578     0.951736   -0.213089    0.277362    -0.279833     0.201152     0.770969    0.0563331  -0.464157
 -0.328395   -0.148571   -0.461497   -0.137878   -0.442495   -0.43494     0.280649    0.279962   -0.147389    -0.125033    -0.0855137    0.0664708  -0.0676669   0.465217    -0.714457     0.333684    0.616714   -0.654955    0.42304    -0.88305     0.00502175  -0.00127555  -0.478062     0.248251    0.375944    0.517582
  0.488782    0.1237     -0.292962    0.162353    0.14859     0.174128    0.30199     0.227506   -0.12398     -0.0130663   -0.0415968    0.0663959   0.0549934   0.625261    -0.5028       0.558493   -0.203256    0.106524   -0.252017   -0.0405713   0.404493     0.282141    -0.32902     -0.512613    0.342283    1.02157
  0.0613078  -0.882863    0.841199   -0.242296   -0.297512   -0.237522    0.660293    0.113717   -0.14807     -0.247958     0.146498     0.0434847  -0.752905    0.00623643  -0.368232     0.248226   -0.042205   -0.0541799  -0.327936    0.356235    0.171753    -0.148474    -0.100064    -0.665751   -0.029222    0.169451
  0.13386    -0.72843     0.935174    0.112052   -0.357384   -0.110192    0.150812    0.0814995  -0.191055     0.0274056    0.157366     0.0564214   0.0532309   0.219158    -0.0576644    0.101873    0.633726    0.996979   -0.448496   -0.403129    1.01412     -0.317548     0.0337675   -0.0492774   0.163404    0.631949
 -0.0754224   0.238543    0.127042    0.142355   -0.0316749  -0.40933    -0.311835    0.522248    0.0179476    0.717311    -0.00683494  -0.80356     0.189555   -0.435593    -0.580937     0.193616   -0.0822919  -0.167785   -0.15431     0.433963   -0.609472     0.132624    -0.673285     0.0406883  -0.623997   -0.363136
 -0.0906716   0.583513   -0.353538   -0.173555    0.603501   -0.380038   -0.254004    0.661819   -0.507512    -0.442479    -0.834928    -0.64596     0.187745   -0.27997     -0.380343     0.440299   -0.106832    0.553731    0.647208    0.424194    0.281667    -0.170126     0.164749     0.0949197  -0.736683   -0.124444
  0.0509      0.0569174   0.087351   -0.492115   -0.255851   -0.422313    0.0565197   0.261158    0.776572    -0.202874    -0.286585    -0.178981    0.0866393  -0.016485    -0.00669983  -0.517536    0.283716    0.353331   -0.508775    0.211222    0.176684    -0.172703     0.0449471    0.368646   -0.23649    -0.671753
  0.140541    0.335084   -0.37314    -0.632773   -0.383709   -0.455842    0.0255302   0.262468    0.993332     0.0552407   -0.251967    -0.330304   -0.270425   -0.324201     0.0105912    0.301488    0.143088    0.264081   -0.0631856  -0.176875    0.408943     0.0691498    0.222539    -0.486943   -0.218794   -0.0657798
 -0.44728    -0.102723    0.446071    0.361419    0.4577     -0.171865   -0.444368    0.233925   -0.375097     0.205949    -0.132552     0.363594   -0.186119    0.506341    -0.213136    -0.212604    0.460037    0.234122    0.117553   -0.11415    -0.548613    -0.304137    -0.168592     0.269687   -0.153456   -0.103986
  0.586325   -0.625788    0.0652377  -0.132172    0.168882    0.130231    0.0673807  -0.0417279  -0.219334     0.111564    -0.223588    -0.0794466   0.32057     0.491589     0.378393    -0.34789     0.490191    0.0134224  -0.434568   -0.362092   -0.326683     0.557154    -0.0341968   -0.0872406  -0.537468   -0.125181
 -0.175854   -0.34599    -0.211677    0.530198    0.35942    -0.450284    0.26134    -0.0349343   0.315573     0.279283    -0.0386084   -0.123431   -0.0198799   0.407768     0.0114713    0.204698   -0.463011   -0.168366   -0.276249    0.121982    0.240877    -0.470115    -0.0748908   -0.420225   -0.0251276  -0.168898
 -0.555534   -0.183673   -0.170194    0.341498    0.0908083   0.637305   -0.384285    0.571537    0.616347     0.518309     0.427998    -0.126248   -0.133363    0.351243     0.0765782   -0.427558    0.0764877   0.0696924  -0.433352   -0.34432     0.0758662   -0.289408    -0.342555    -0.227946    0.0988277   0.0670527
  0.0629499   0.611146   -0.632944    0.422097    0.692155   -0.214441    0.164398   -0.372595    0.160763     0.477732    -0.498585     0.798744   -0.287511    0.207978     0.142133    -0.360977    0.159014   -0.0621831   0.371913   -0.0967257  -0.241876    -0.262261     0.0610336   -0.0498928  -0.333625   -0.202035
  0.120396    0.942581   -0.662964    0.102074    0.0603573   0.321268   -0.58757    -0.113652    0.123579     0.132719    -0.226896    -0.018415    0.726044    0.0643433    0.732328    -0.337778    0.0115531   0.220888    0.509371   -0.402562   -0.424234     0.0526525    0.173104     1.04686    -0.0568218  -0.188339
  0.17711     0.787992    0.84627     0.389831    0.198186   -0.0361354  -0.498503    0.624771   -0.00620691   0.00546075  -0.37783      0.445857   -0.146393   -0.326767    -0.508965     0.432209   -0.0590603  -0.0540757  -0.15432     0.518628   -0.76634     -0.13092      0.26403      0.606195    0.243734    0.73064
 -0.242014    0.665871    0.26083     0.29337     0.025099   -0.13809    -0.269607   -0.088483    0.28877      0.114923    -0.977865     0.208055    0.0285683  -0.0512666    0.171425     0.268444    0.0371547   0.133249    0.315123    0.189623    0.356068    -0.431819     0.142314    -0.145594   -0.191811    0.598481
 -0.46417    -0.0627443   0.0427675   0.184702   -0.0876084   0.647636   -0.0972426  -0.0663379  -0.788428    -0.569081     0.489058     0.22126    -0.132046   -0.0945801   -0.258501     0.171835   -0.145849   -0.0902474   0.18889    -0.0501386  -0.318078    -0.0996071   -0.0840538   -0.0102298  -0.0467737   0.307547
 -0.406701    0.300683   -0.147323    0.650317   -0.496242    0.728535   -0.0123114   0.172842    0.00125473   0.154575     0.506262     0.491659    0.0210633  -0.454626     0.241086    -0.27687     0.163628   -0.355054    0.598488    0.386043    0.0169661   -0.0062483    0.278302    -0.415976   -0.337784    0.0492721
  0.255991   -0.367082    0.0111284  -0.53868    -0.160099    0.27959    -0.274485    0.221285   -0.0679694   -0.415348     0.631616    -0.283112    0.0192511  -0.269849     0.00998688  -0.116789    0.0159978   0.407918    0.0173638  -0.293191   -0.386676     0.376775     0.125506     0.354622    0.322657   -0.0667898
  0.32102     0.739656   -0.0546555  -0.485979   -0.162268    0.191657   -0.0437359  -0.135875   -0.162124    -0.363423     0.272196     0.0966565   0.0120134  -0.506641     0.182423    -0.0614282  -0.104849    0.63468    -0.57858     0.399317   -0.216488     0.596849    -0.311501    -0.504762    0.0719763   0.35796
  0.179627   -0.467505   -0.0871655  -0.321296    0.206739   -0.369814    0.107597   -0.316657   -0.280134    -0.555233    -0.0677282   -0.161047    0.0334139   0.298276    -0.269549     0.554716    0.0272765  -0.0628226  -0.257031   -0.112796    0.388052    -0.219807    -0.0761538    0.0791181   0.131706   -0.0692455
  0.461535    0.240454   -0.0021113  -0.0928677  -0.413222   -0.128141    0.367534   -0.469903   -0.222197    -0.379254    -0.0461516    0.104478    0.0761324  -0.283761    -0.306305     0.325361    0.0549638  -0.467925    0.203281    0.382911    0.186523     0.343626     0.471228     0.471621    0.251001   -0.31151
  0.0611089   0.13936    -0.218835    0.117878   -0.119163    0.0369351   0.172408    0.0690689   0.037795     0.0835408    0.0664384    0.0752385  -0.0182216   0.101543    -0.0358036   -0.0712718   0.0720988   0.0235738  -0.0100168  -0.074195    0.111015     0.0488971   -0.0752864   -0.102012    0.0259682   0.204372
 -0.0447381  -0.0311433   0.225628    0.0533      0.0527852  -0.0552547  -0.048909   -0.0779813   0.0405281   -0.0280018   -0.0668276   -0.0539413  -0.0203811  -0.262171     0.126649    -0.0893551  -0.0252641  -0.0510533   0.0528402[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
  -0.0238957  -0.191092    -0.0718831    0.153799     0.0589771  -0.177616   -0.196264[ Info: iteration 1, average log likelihood -1.407610
[ Info: iteration 2, average log likelihood -1.407601
[ Info: iteration 3, average log likelihood -1.407592
[ Info: iteration 4, average log likelihood -1.407583
[ Info: iteration 5, average log likelihood -1.407575
[ Info: iteration 6, average log likelihood -1.407566
[ Info: iteration 7, average log likelihood -1.407558
[ Info: iteration 8, average log likelihood -1.407550
[ Info: iteration 9, average log likelihood -1.407542
[ Info: iteration 10, average log likelihood -1.407534
┌ Info: EM with 100000 data points 10 iterations avll -1.407534
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.405790e+05
      1       7.086488e+05      -2.319302e+05 |       32
      2       6.932550e+05      -1.539377e+04 |       32
      3       6.869177e+05      -6.337369e+03 |       32
      4       6.838719e+05      -3.045760e+03 |       32
      5       6.819938e+05      -1.878063e+03 |       32
      6       6.806428e+05      -1.351049e+03 |       32
      7       6.796338e+05      -1.008950e+03 |       32
      8       6.787894e+05      -8.444795e+02 |       32
      9       6.780994e+05      -6.899248e+02 |       32
     10       6.775097e+05      -5.897110e+02 |       32
     11       6.770087e+05      -5.010060e+02 |       32
     12       6.765668e+05      -4.419195e+02 |       32
     13       6.761559e+05      -4.109083e+02 |       32
     14       6.758145e+05      -3.414350e+02 |       32
     15       6.755290e+05      -2.854590e+02 |       32
     16       6.752934e+05      -2.355522e+02 |       32
     17       6.750864e+05      -2.070587e+02 |       32
     18       6.749296e+05      -1.567609e+02 |       32
     19       6.747856e+05      -1.439808e+02 |       32
     20       6.746556e+05      -1.300576e+02 |       32
     21       6.745284e+05      -1.272355e+02 |       32
     22       6.743960e+05      -1.323366e+02 |       32
     23       6.742630e+05      -1.329985e+02 |       32
     24       6.741393e+05      -1.236800e+02 |       32
     25       6.740308e+05      -1.084957e+02 |       32
     26       6.739169e+05      -1.139332e+02 |       32
     27       6.738088e+05      -1.081111e+02 |       32
     28       6.737095e+05      -9.933676e+01 |       32
     29       6.736193e+05      -9.013696e+01 |       32
     30       6.735382e+05      -8.108544e+01 |       32
     31       6.734527e+05      -8.551249e+01 |       32
     32       6.733639e+05      -8.884617e+01 |       32
     33       6.732809e+05      -8.296379e+01 |       32
     34       6.732060e+05      -7.494869e+01 |       32
     35       6.731255e+05      -8.050673e+01 |       32
     36       6.730502e+05      -7.523136e+01 |       32
     37       6.729850e+05      -6.524505e+01 |       32
     38       6.729171e+05      -6.787241e+01 |       32
     39       6.728513e+05      -6.582740e+01 |       32
     40       6.727757e+05      -7.560875e+01 |       32
     41       6.727123e+05      -6.338078e+01 |       32
     42       6.726591e+05      -5.315342e+01 |       32
     43       6.726075e+05      -5.166812e+01 |       32
     44       6.725584e+05      -4.912091e+01 |       32
     45       6.725140e+05      -4.436733e+01 |       32
     46       6.724709e+05      -4.309577e+01 |       32
     47       6.724264e+05      -4.449713e+01 |       32
     48       6.723840e+05      -4.234933e+01 |       32
     49       6.723445e+05      -3.950112e+01 |       32
     50       6.723061e+05      -3.842579e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672306.1196448224)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419353
[ Info: iteration 2, average log likelihood -1.414487
[ Info: iteration 3, average log likelihood -1.413206
[ Info: iteration 4, average log likelihood -1.412249
[ Info: iteration 5, average log likelihood -1.411188
[ Info: iteration 6, average log likelihood -1.410137
[ Info: iteration 7, average log likelihood -1.409361
[ Info: iteration 8, average log likelihood -1.408910
[ Info: iteration 9, average log likelihood -1.408661
[ Info: iteration 10, average log likelihood -1.408506
[ Info: iteration 11, average log likelihood -1.408395
[ Info: iteration 12, average log likelihood -1.408307
[ Info: iteration 13, average log likelihood -1.408233
[ Info: iteration 14, average log likelihood -1.408170
[ Info: iteration 15, average log likelihood -1.408113
[ Info: iteration 16, average log likelihood -1.408062
[ Info: iteration 17, average log likelihood -1.408016
[ Info: iteration 18, average log likelihood -1.407974
[ Info: iteration 19, average log likelihood -1.407936
[ Info: iteration 20, average log likelihood -1.407902
[ Info: iteration 21, average log likelihood -1.407870
[ Info: iteration 22, average log likelihood -1.407842
[ Info: iteration 23, average log likelihood -1.407815
[ Info: iteration 24, average log likelihood -1.407792
[ Info: iteration 25, average log likelihood -1.407770
[ Info: iteration 26, average log likelihood -1.407750
[ Info: iteration 27, average log likelihood -1.407731
[ Info: iteration 28, average log likelihood -1.407714
[ Info: iteration 29, average log likelihood -1.407698
[ Info: iteration 30, average log likelihood -1.407683
[ Info: iteration 31, average log likelihood -1.407669
[ Info: iteration 32, average log likelihood -1.407656
[ Info: iteration 33, average log likelihood -1.407644
[ Info: iteration 34, average log likelihood -1.407632
[ Info: iteration 35, average log likelihood -1.407621
[ Info: iteration 36, average log likelihood -1.407610
[ Info: iteration 37, average log likelihood -1.407600
[ Info: iteration 38, average log likelihood -1.407590
[ Info: iteration 39, average log likelihood -1.407580
[ Info: iteration 40, average log likelihood -1.407571
[ Info: iteration 41, average log likelihood -1.407562
[ Info: iteration 42, average log likelihood -1.407553
[ Info: iteration 43, average log likelihood -1.407545
[ Info: iteration 44, average log likelihood -1.407537
[ Info: iteration 45, average log likelihood -1.407529
[ Info: iteration 46, average log likelihood -1.407521
[ Info: iteration 47, average log likelihood -1.407513
[ Info: iteration 48, average log likelihood -1.407506
[ Info: iteration 49, average log likelihood -1.407498
[ Info: iteration 50, average log likelihood -1.407491
┌ Info: EM with 100000 data points 50 iterations avll -1.407491
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.133146    -0.820787    0.610201   -0.321874    -0.507782   -0.16115      0.51306      0.147984   -0.194334   -0.460597      0.220806    -0.233588   -0.421955   -0.290921   -0.388633     0.350477    -0.0820035    0.153011   -0.37304       0.139875      0.514773    -0.203989    -0.181206    -0.471662    0.0857477   0.183856
 -0.103365    -0.280489   -0.211434    0.418455    -0.0363317  -0.149756     0.421432    -0.446138   -0.228916   -0.314768     -0.287469     0.14522     0.12902     0.389777    0.178612    -0.0365723   -0.120709    -0.664941    0.68704      -0.267664      0.73508      0.0522879    0.381576    -0.0997335   0.109585    0.262085
 -0.539188     0.0842225  -0.170399   -0.0317772    0.0440921  -0.215055     0.187775    -0.146147    0.475753    0.238559     -0.103479    -0.603457   -0.10328    -0.40299     0.572596     0.0913146   -0.509883    -0.0399462  -0.159918     -0.280261      0.0429399    0.100281     0.00409393  -0.887408   -0.36361     0.172945
 -0.209942     0.302003    0.0426187   0.386209     0.135981   -0.511895    -0.0989786    0.479249    0.0967157   0.841154     -0.381569    -0.761585    0.343572   -0.180746   -0.524306     0.188589    -0.157609    -0.334612    0.0507104     0.546697     -0.202151    -0.113945    -0.719045     0.0316405  -0.845914   -0.323307
  0.122762    -0.307609   -0.0217992   0.809025    -0.281106    0.488395     0.413847    -0.366424    0.364656    0.482478      0.889593     0.171599    0.18426    -0.28094     0.346859    -0.177409    -0.484045    -0.137767   -0.766265     -0.032869     -0.198149    -0.174537    -0.233065     0.218342    0.514888   -0.519709
  0.254389    -0.479107    0.117598   -0.145734     0.133624   -0.102217     0.187322    -0.0616423   0.330585    0.000975106   0.0582402   -0.0955335  -0.0985638  -0.0507307   0.413957    -0.231237    -0.0784464    0.0155767   0.0101607    -0.0574576    -0.227956    -0.132162     0.401805     0.189115   -0.122756   -0.59431
 -0.370409     0.231279    0.735479    0.0547483   -0.0203664   0.0341666   -0.304388    -0.141977    0.599196   -0.127032     -0.391512     0.125472   -0.142431   -0.115853    0.0845437   -0.329908    -0.137906     0.273668   -0.67522       1.04487       0.388647     0.180213     0.620475    -0.386635   -0.556085   -0.4882
 -0.167963     0.549991   -0.0601098   0.0590378    0.395819   -0.614874    -0.481088     0.139202    0.010052   -0.137915     -1.05866      0.146559   -0.227567    0.235187   -0.277845    -0.0696409    0.239449     0.396237    0.825906     -0.0450095    -0.00788593  -0.415741     0.0886712   -0.227054   -0.536783    0.553063
 -0.701323    -0.108173   -0.128324    0.67714      0.231588    0.485235    -0.391956     0.406975    0.525363    0.567535      0.310301    -0.0251721  -0.0468023   0.330019    0.25417     -0.649099     0.0896851    0.101496   -0.0916754    -0.337301      0.0222376   -0.332379    -0.191454    -0.497217   -0.0264463   0.182421
  0.217294     0.0555436   0.0615056  -0.435282    -0.0264389   0.0709772   -0.38321     -0.0123481  -0.196747   -0.318783      0.415451    -0.223481    0.186327   -0.388017   -0.166302    -0.0795863   -0.0383907    0.247441   -0.136377      0.0658029    -0.418954     0.346704    -0.0591557    0.139952    0.0387106  -0.241255
  0.468592     0.13884     0.0412033  -0.276298    -0.357425   -0.198378     0.35592     -0.574472   -0.2502     -0.454474     -0.00607118   0.0573198   0.114611   -0.276207   -0.266315     0.317755     0.0347209   -0.479005    0.204608      0.322107      0.129774     0.400225     0.428159     0.462631    0.395997   -0.247761
 -0.0704743    0.393896   -0.098791    0.759166    -0.463667    0.825414     0.183214    -0.0362018  -0.410861    0.0198078     0.631099     0.457807   -0.0673771  -0.809624    0.48644     -0.107747    -0.0793647   -0.301974    0.653395      0.545448     -0.109649     0.0573505    0.371755    -0.462061   -0.512906    0.0846131
 -0.126551     0.345028   -0.123946    0.44513      0.217129    0.0373834   -0.555309    -0.0290442  -0.485913   -0.154107      0.282735    -0.600527    0.99458     0.0231256   0.248412    -0.613383    -0.342664     0.0538795   0.663897     -0.288127     -0.133176     0.123033    -0.00720962   0.883158    0.326387   -0.315565
 -1.08339      0.751651   -0.545635    0.485701    -0.422327   -0.0216593    0.124227     0.177593    0.253719   -0.122573      0.390774     0.0540721  -0.251616   -0.542483   -0.48565      0.288405    -0.364374    -0.375161    0.527104      0.000528157   0.428137    -0.25538     -0.0737234    0.0706158   0.64384     0.391642
  0.40734      0.50197    -0.57789    -0.558463    -0.596548   -0.0670499   -0.0889471    0.310393    1.1015      0.136135     -0.352149    -0.0179704   0.0884564  -0.175242    0.265798    -0.0798382    0.398291     0.400553    0.0583285    -0.00679808    0.323065    -0.0443485    0.00487189   0.16334     0.026888   -0.263416
  0.122582     0.617342   -0.527954    0.448767     0.552067    0.0777927   -0.0776643   -0.421544    0.170112    0.441816     -0.44402      0.570876    0.126728    0.195299    0.457393    -0.348397     0.185257    -0.114894    0.417609     -0.145983     -0.384334    -0.0717795    0.166421     0.329536   -0.394975   -0.26188
  0.788482    -0.670208    0.140641   -0.133179     0.297108    0.505609    -0.102755    -0.0161536  -0.533218    0.11099      -0.130329    -0.2846      0.463083    0.313073    0.456944    -0.438996     0.33176      0.170105   -0.701863     -0.224236     -0.384536     0.777857    -0.156541    -0.0767942  -0.739582   -0.151638
  0.254425    -0.536      -0.019223    0.262135     0.517672   -0.41636     -0.0354171   -0.714814   -0.15947    -0.282311     -0.213682     0.0103701   0.171097    0.561905   -0.286188     0.757324    -0.239627    -0.0574455  -0.479462      0.447288      0.32219     -0.489913    -0.478301     0.0559817   0.487686   -0.10602
 -0.111342    -0.42404    -0.0904385  -0.350111     0.34478    -0.734457    -0.00647916   0.122342    0.227621   -0.0844949    -0.396667    -0.235114   -0.0184702   0.670773   -0.326336     0.0212034    0.481333     0.0759408  -0.405085     -0.827952      0.229735    -0.0264809   -0.143637     0.201261    0.155371   -0.0649804
  0.370474     0.495579   -0.24557     0.00145076  -0.484166   -0.410057    -0.14414     -0.155244    0.0122348  -0.448835     -0.103847    -0.368068    0.379331   -0.402173   -0.221761     0.117648     0.138632    -0.280051   -0.448779     -0.33448       0.780147    -0.027027     1.09002      0.113773   -0.836918   -0.335293
  0.00888248  -0.0790721   0.267642    0.381935    -0.268008    0.154098     0.109382     0.597948   -0.236278    0.0800638     0.0028335    0.874405    0.0256738   0.784967   -0.892579     0.38011      0.339942     0.40543    -0.048003     -0.00429449    0.296165    -0.284842    -0.270663    -0.154266    0.0162329   0.440612
  0.134279    -0.4474      0.355118    0.00798285   0.0886369  -0.376309     0.521391    -0.0979969   0.182919    0.345597     -0.197266     0.255784   -0.290552    0.440187    0.230715    -0.0180312    0.26537     -0.0522973  -0.401711     -0.161307      0.0556302   -0.3075       0.0173687   -0.179199   -0.12284    -0.0972324
  0.0319861    0.876823    0.711492    0.543894     0.191877    0.0871481   -0.394946     0.478292    0.175133    0.195647     -0.574731     0.212632   -0.088791   -0.403261    0.00371493   0.39115     -0.189101    -0.0622289  -0.000712883   0.47595      -0.43435     -0.218061     0.30816      0.356733    0.293527    0.888867
  0.247201    -0.315211    0.307742   -0.554624    -0.138331    0.589893     0.00250918  -0.298682   -0.322217   -0.772078      0.542762     0.465665   -0.226933    0.104755    0.574348    -0.0112441    0.470002     0.307317   -0.110462     -0.585255      0.31349      0.197535     0.796936     0.231025    0.672663    0.380516
  0.239536    -0.450475   -0.558552   -0.483265    -0.486735   -0.0893764    0.376848     0.101186   -0.435598   -0.175013      0.419571    -0.154543    0.0821484   0.372255   -0.334666     0.101684     0.45243     -0.519952    0.266731     -0.886175     -0.346169     0.191368    -0.614959     0.0952887   0.344581    0.320464
  0.139908     0.341938   -0.0601556  -0.255512    -0.20943     0.262647    -0.092524    -0.0575994  -0.0860168  -0.32565       0.302813     0.175872   -0.0328143  -0.383018    0.128348    -0.175174    -0.0387357    0.489816   -0.24504       0.0515492    -0.225355     0.355675    -0.184861    -0.189732    0.111497    0.348655
  0.632942     0.0750435  -0.393934   -0.0352212    0.472926    0.0806515    0.420623     0.167676    0.102377    0.061475      0.0605709   -0.34051    -0.0795315   0.386329   -0.0559661    0.537595    -0.492371     0.256969   -0.562267      0.0699067     0.262101     0.319064    -0.102518    -0.712399    0.315271    0.877456
 -0.310889    -0.11668    -0.0591269   0.393237     0.345727    0.726885     0.127709    -0.315682   -0.882771   -0.0559261     0.533761     0.729683   -0.414603    0.330939   -0.00190525  -0.20619     -0.126248    -0.122333    0.0241756     0.101524     -0.737021    -0.162117    -0.0779219    0.274023    0.352244    0.0965835
 -0.034921     0.0459881  -0.0854098   0.173155    -0.0375816  -0.00873217   0.118292    -0.045951   -0.0272825   0.0172885    -0.00778783   0.0310573   0.0394853   0.0415691   0.0111327    0.00657442   0.0137445   -0.109088    0.0440337    -0.0666182     0.15189     -0.0658112    0.0475922   -0.0973969  -0.0566228   0.121306
  0.0845272    0.572233   -0.704273   -0.26926      0.415231   -0.201786     0.173087     0.310001   -0.791464   -0.838847     -0.450847    -0.567215    0.144778   -0.298464   -0.29118      0.861667     0.00338192   0.500323    0.377711      0.458855      0.295357    -0.0797849    0.224332     0.230452   -0.711077   -0.277244
 -0.563525    -0.286402    0.599292    0.223151     0.0224762   0.0902583   -0.291369    -0.16628    -0.687302   -0.441088     -0.00315435   0.0853204   0.0807536   0.03487    -0.121273     0.0208823    0.167908    -0.219245    0.251409     -0.0779381    -0.349456    -0.121417    -0.0734723   -0.011655   -0.399332   -0.00743143
  0.0184732    0.141974    0.175149    0.0103174   -0.087466   -0.126219    -0.221581     0.441162    0.105353    0.199235      0.0431794   -0.205487   -0.180291   -0.215256   -0.472802     0.0531726    0.12549      0.0669414  -0.166448      0.255485     -0.367372    -0.00432896  -0.246499     0.353032   -0.132284   -0.389037[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407484
[ Info: iteration 2, average log likelihood -1.407477
[ Info: iteration 3, average log likelihood -1.407470
[ Info: iteration 4, average log likelihood -1.407464
[ Info: iteration 5, average log likelihood -1.407457
[ Info: iteration 6, average log likelihood -1.407450
[ Info: iteration 7, average log likelihood -1.407444
[ Info: iteration 8, average log likelihood -1.407438
[ Info: iteration 9, average log likelihood -1.407432
[ Info: iteration 10, average log likelihood -1.407426
┌ Info: EM with 100000 data points 10 iterations avll -1.407426
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
