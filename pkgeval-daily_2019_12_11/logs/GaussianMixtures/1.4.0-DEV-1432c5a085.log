Julia Version 1.4.0-DEV.577
Commit 1432c5a085 (2019-12-11 08:20 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed PDMats ───────────── v0.9.10
 Installed Rmath ────────────── v0.6.0
 Installed JLD ──────────────── v0.9.1
 Installed SpecialFunctions ─── v0.9.0
 Installed DataStructures ───── v0.17.6
 Installed StatsBase ────────── v0.32.0
 Installed Clustering ───────── v0.13.3
 Installed URIParser ────────── v0.4.0
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed ScikitLearnBase ──── v0.5.0
 Installed Compat ───────────── v2.2.0
 Installed Distances ────────── v0.8.2
 Installed HDF5 ─────────────── v0.12.5
 Installed NearestNeighbors ─── v0.4.4
 Installed StatsFuns ────────── v0.9.2
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Arpack ───────────── v0.4.0
 Installed DataAPI ──────────── v1.1.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed BinaryProvider ───── v0.5.8
 Installed Blosc ────────────── v0.5.1
 Installed StaticArrays ─────── v0.12.1
 Installed Distributions ────── v0.21.11
 Installed Missings ─────────── v0.4.3
 Installed FillArrays ───────── v0.8.2
 Installed SortingAlgorithms ── v0.3.1
 Installed BinDeps ──────────── v1.0.0
 Installed OrderedCollections ─ v1.1.0
 Installed Parameters ───────── v0.12.0
 Installed LegacyStrings ────── v0.4.1
 Installed FileIO ───────────── v1.1.0
 Installed QuadGK ───────────── v2.3.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed CMake ────────────── v1.1.2
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.0
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
Status `/tmp/jl_OOmis5/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.0
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -5.992029305408634e6, [50260.4357135305, 49739.56428646951], [-28609.48900766944 -2784.5332441953406 27820.235138680626; 28542.057125903368 2716.405658202656 -27525.21326133639], [[49530.88029064478 321.07601769675864 -226.24150892868676; 321.0760176967587 50791.471865090425 175.21417552236443; -226.24150892868673 175.21417552236437 50399.106535634855], [49484.09390875284 -512.2226663160909 165.6911191052506; -512.2226663160909 49450.25126390367 -275.46354506047123; 165.6911191052506 -275.46354506047123 49897.85569208778]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.090433e+03
      1       1.333587e+03      -7.568466e+02 |        5
      2       1.294866e+03      -3.872105e+01 |        2
      3       1.275028e+03      -1.983825e+01 |        2
      4       1.254630e+03      -2.039733e+01 |        2
      5       1.253789e+03      -8.415946e-01 |        0
      6       1.253789e+03       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 1253.788655299808)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.082935
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.693097
[ Info: iteration 2, lowerbound -3.538378
[ Info: iteration 3, lowerbound -3.383757
[ Info: iteration 4, lowerbound -3.215801
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.036074
[ Info: iteration 6, lowerbound -2.872843
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.750471
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.656169
[ Info: iteration 9, lowerbound -2.594965
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.535294
[ Info: iteration 11, lowerbound -2.479260
[ Info: iteration 12, lowerbound -2.435703
[ Info: iteration 13, lowerbound -2.397804
[ Info: iteration 14, lowerbound -2.364640
[ Info: iteration 15, lowerbound -2.336142
[ Info: iteration 16, lowerbound -2.315473
[ Info: iteration 17, lowerbound -2.307439
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302956
[ Info: iteration 19, lowerbound -2.299261
[ Info: iteration 20, lowerbound -2.299257
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Dec 11 16:57:20 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Dec 11 16:57:28 2019: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Wed Dec 11 16:57:31 2019: EM with 272 data points 0 iterations avll -2.082935
5.8 data points per parameter
, Wed Dec 11 16:57:33 2019: GMM converted to Variational GMM
, Wed Dec 11 16:57:42 2019: iteration 1, lowerbound -3.693097
, Wed Dec 11 16:57:42 2019: iteration 2, lowerbound -3.538378
, Wed Dec 11 16:57:42 2019: iteration 3, lowerbound -3.383757
, Wed Dec 11 16:57:42 2019: iteration 4, lowerbound -3.215801
, Wed Dec 11 16:57:43 2019: dropping number of Gaussions to 7
, Wed Dec 11 16:57:43 2019: iteration 5, lowerbound -3.036074
, Wed Dec 11 16:57:43 2019: iteration 6, lowerbound -2.872843
, Wed Dec 11 16:57:43 2019: dropping number of Gaussions to 6
, Wed Dec 11 16:57:43 2019: iteration 7, lowerbound -2.750471
, Wed Dec 11 16:57:43 2019: dropping number of Gaussions to 5
, Wed Dec 11 16:57:43 2019: iteration 8, lowerbound -2.656169
, Wed Dec 11 16:57:43 2019: iteration 9, lowerbound -2.594965
, Wed Dec 11 16:57:43 2019: dropping number of Gaussions to 3
, Wed Dec 11 16:57:43 2019: iteration 10, lowerbound -2.535294
, Wed Dec 11 16:57:43 2019: iteration 11, lowerbound -2.479260
, Wed Dec 11 16:57:43 2019: iteration 12, lowerbound -2.435703
, Wed Dec 11 16:57:43 2019: iteration 13, lowerbound -2.397804
, Wed Dec 11 16:57:43 2019: iteration 14, lowerbound -2.364640
, Wed Dec 11 16:57:43 2019: iteration 15, lowerbound -2.336142
, Wed Dec 11 16:57:43 2019: iteration 16, lowerbound -2.315473
, Wed Dec 11 16:57:43 2019: iteration 17, lowerbound -2.307439
, Wed Dec 11 16:57:43 2019: dropping number of Gaussions to 2
, Wed Dec 11 16:57:43 2019: iteration 18, lowerbound -2.302956
, Wed Dec 11 16:57:43 2019: iteration 19, lowerbound -2.299261
, Wed Dec 11 16:57:43 2019: iteration 20, lowerbound -2.299257
, Wed Dec 11 16:57:43 2019: iteration 21, lowerbound -2.299255
, Wed Dec 11 16:57:43 2019: iteration 22, lowerbound -2.299254
, Wed Dec 11 16:57:43 2019: iteration 23, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 24, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 25, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 26, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 27, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 28, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 29, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 30, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 31, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 32, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 33, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 34, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 35, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 36, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 37, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 38, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 39, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 40, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 41, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 42, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 43, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 44, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 45, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 46, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 47, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 48, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 49, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: iteration 50, lowerbound -2.299253
, Wed Dec 11 16:57:43 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601396, 95.95490777398608]
β = [178.04509222601396, 95.95490777398608]
m = [4.250300733269909 79.2868669443618; 2.00022925777537 53.85198717246128]
ν = [180.04509222601396, 97.95490777398608]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484904 -0.007644049042327558; 0.0 0.008581705166333409], [0.37587636119484197 -0.008953123827345928; 0.0 0.012748664777409342]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9807173608727329
avll from llpg:  -0.980717360872718
avll direct:     -0.980717360872718
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9952290521737942
avll from llpg:  -0.995229052173794
avll direct:     -0.9952290521737941
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0267685   -0.164672    0.00675288  -0.0939197   -0.0616539    -0.0795072   -0.0191519    0.157058    -0.0498876   -0.0743122    0.0452534    0.097369    -0.000645783   0.0600732    0.098683     0.118885      0.0403335   -0.00333518   0.0118138    0.164073     0.107969    -0.148622    -0.0220308   -0.0598103    0.0970582   -0.137566
 -0.0969029   -0.0748175   0.063266     0.0763254    0.0847002    -0.0549244    0.200308     0.164192     0.0544042    0.101749     0.0106232   -0.192838    -0.115465     -0.0838113   -0.00327838   0.029323     -0.14275     -0.116122     0.0533799    0.0561563   -0.0941724   -0.0141912    0.15972     -0.0574339   -0.250452    -0.0527952
  0.246838     0.0218757   0.0549473   -0.0777194   -0.0402666    -0.061428     0.0559631    0.0828775   -0.138523    -0.0459941    0.0951712   -0.0614868   -0.226048     -0.0133286   -0.201976     0.0417692     0.11185      0.0269335   -0.0279059    0.00394833  -0.00894491  -0.0484674    0.0223388   -0.00654917   0.0969513   -0.0593719
  0.0962777    0.051797    0.0584235   -0.0783724    0.114267      0.0915053    0.0147035    0.0892387   -0.0843888   -0.106085     0.0102227    0.150111     0.213912      0.0417575    0.0976125    0.143459     -0.205548    -0.0883579    0.0410819    0.108573    -0.296945     0.109435    -0.0365854   -0.101488    -0.179109    -0.131729
  0.011242    -0.118969    0.15349     -0.00625316   0.0363217    -0.108309    -0.19339     -0.118866    -0.124576    -0.00110155   0.0905213   -0.108954     0.216308      0.0603739    0.0469003    0.112235     -0.170793     0.0255856   -0.0154682   -0.0596781    0.222416     0.0138664    0.0351393    0.0508355   -0.013296    -0.233257
  0.0729603    0.0780396  -0.0144408    0.122614    -0.058981     -0.0216309    0.0332802   -0.0720432   -0.125976    -0.198425    -0.164743     0.0830229    0.00436867   -0.14118      0.0107561    0.253525     -0.15991     -0.16304      0.0674966   -0.0113392    0.0392983    0.20545      0.11402      0.0913097   -0.0372196    0.0598905
  0.0387138    0.0241089  -0.0114449   -0.147781    -0.0785615     0.217132    -0.113197     0.00931002  -0.125362     0.0287232   -0.0745261    0.131952    -0.119026      0.125325    -0.0755442   -0.0784759     0.279995     0.0345597    0.0874331   -0.143586     0.0411537   -0.0273186    0.149581    -0.0253781   -0.0186539    0.104661
 -0.0567849   -0.112447   -0.113119    -0.0487783    0.0826491     0.00336908  -0.0341383   -0.0533987    0.101768     0.0664121    0.0691342    0.058398     0.0484944     0.00610023   0.136923    -0.0267307    -0.0786795   -0.0750002    0.0464797    0.0537882    0.106097    -0.112607    -0.066129     0.0825039    0.0434824    0.00424642
 -0.0176378   -0.0202828  -0.0806911    0.0849581   -0.129542     -0.0650757    0.113302     0.00130946  -0.0594677    0.0920961   -0.0311652    0.165284    -0.116072     -0.107277     0.0626614    0.00575058    0.0782891    0.0936688   -0.00150357   0.193051     0.0418246   -0.223234    -0.191861    -0.00571508   0.00629406  -0.00949206
  0.00463139  -0.0573749  -0.0340243    0.0164846   -0.103978     -0.0806589   -0.0180083    0.103474     0.0578734   -0.044258    -0.0284702   -0.0074541   -0.0447599    -0.0244272   -0.0254786   -0.0483268    -0.139069    -0.107002    -0.0759443   -0.256115    -0.0788706    0.0359511    0.114538    -0.203931    -0.00477726   0.0274704
 -0.126386     0.052997   -0.0920382    0.0239087    0.0771333     0.149596    -0.0654017   -0.102559    -0.140228    -0.0250534    0.0719409    0.0182959    0.00833803   -0.067285    -0.0130238   -0.123302     -0.104227    -0.112381     0.099968     0.110008     0.0777314    0.0207551   -0.0166636   -0.0168112   -0.126182    -0.00796028
  0.049322     0.0607969  -0.227973     0.0592146    0.175973      0.0591563    0.115114    -0.0805785   -0.113818    -0.0680305    0.149042    -0.128384     0.0946492     0.0287855   -0.0757037    0.0696772     0.0312167   -0.00104897   0.00176597   0.00794745   0.125998    -0.14253     -0.144532     0.181555    -0.129125     0.128302
  0.102087     0.0657824   0.163921     0.0805929    0.0200053     0.010429     0.0216961    0.129158     0.147873    -0.0102762   -0.00142702  -0.070986    -0.119949      0.0298872   -0.101274    -0.0639803     0.00314371  -0.0454912   -0.00950677   0.11035      0.071451     0.157604     0.0162482   -0.0260266   -0.00314761   0.0973225
  0.121199    -0.16981     0.0690028    0.142275     0.0570116    -0.0555251    0.187788     0.0794353   -0.0305312    0.194698    -0.0305818   -0.257955     0.00168963    0.125665    -0.0298757   -0.0965018    -0.0999568    0.0529831    0.114558    -0.103213     0.040759    -0.292762    -0.0100752   -0.0353812    0.168743    -0.0284366
 -0.0355298    0.169478   -0.00720848   0.0235157    0.0678394     0.06169     -0.12624      0.0346043    0.025601    -0.0220565   -0.128437    -0.0905412    0.0168523    -0.0147772    0.0119711   -0.0930445    -0.0376228    0.154784    -0.00536736  -0.0265605    0.089999     0.0910779   -0.0333289    0.0179453    0.0422155    0.261925
  0.0250703    0.0701533  -0.0620175   -0.0282348    0.0776711    -0.0173963    0.0878368   -0.0736085    0.0152768    0.159032    -0.0913715   -0.0790679    0.111581     -0.0604064    0.0833685    0.000549612  -0.116291    -0.182604     0.118971     0.209708    -0.0227417    0.0401995   -0.0391713   -0.0497132    0.089189    -0.169075
 -0.0062583   -0.0967545  -0.0673188    0.14627     -0.103653     -0.0369321   -0.030209     0.185984     0.0407798    0.064016    -0.067551    -0.0825954    0.000132576  -0.0190908   -0.141603    -0.0274127     0.202511     0.0360149    0.108224    -0.0367943   -0.0359349   -0.0630224    0.068109     0.09712     -0.0694901    0.0983429
 -0.0514903   -0.281312    0.00188354  -0.0641453   -0.0557032     0.108913    -0.0800443    0.0166715    0.0200528    0.120131    -0.0219624   -0.015019    -0.135542      0.0033242    0.0446954    0.0335139    -0.0361333   -0.00916546  -0.0745562   -0.133602    -0.107495     0.00984124  -0.142601     0.0155008    0.135181    -0.268754
  0.161014     0.165271    0.0770307   -0.0447451   -0.130438      0.0844812   -0.0448602   -0.0930551   -0.0401305    0.102372    -0.0423704    0.0398922   -0.15637      -0.121637    -0.0976744   -0.162957     -0.0605664   -0.00358655   0.090638    -0.0976454   -0.153043     0.0607537    0.0275988   -0.0493125    0.0209458   -0.0322902
 -0.195858     0.0151614   0.130191    -0.0639589    0.0342829    -0.0019328   -0.0719168    0.00528988  -0.144055     0.0364541   -0.0480935    0.188314     0.0959204    -0.0245914    0.140413     0.214242     -0.110403    -0.181882     0.00556233   0.0110928    0.0668358    0.214108    -0.0613832   -0.0813831   -0.0361816   -0.0919002
  0.252061    -0.0142754  -0.0527122    0.0938695   -0.0271216    -0.148228    -0.149296    -0.0503128    0.0213534    0.17538     -0.0973634    0.00937954   0.0766702     0.0339202    0.059473     0.162418     -0.0220671   -0.0269208   -0.0642012    0.176223    -0.167345    -0.205724     0.0364097    0.0179934    0.0141264    0.079223
 -0.1055      -0.101877    0.0738824   -0.0203905   -0.0905625     0.114859     0.0471647    0.0819875   -0.165704     0.104752     0.0221097    0.0233825    0.115188     -0.0254928    0.00729696   0.0425667    -0.00375455   0.0110833    0.124129     0.0476621   -0.0245747   -0.117833    -0.212993     0.0555928    0.14597      0.0718777
 -0.152075     0.033164    0.0469836   -0.019961    -0.115316     -0.0760569   -0.0852083    0.0217293    0.0583115   -0.126436    -0.134903     0.00233485  -0.105026     -0.00418018  -0.0190846    0.0621948     0.0072874    0.162471     0.0731504    0.0396043   -0.21496      0.0830829   -0.0900721    0.13499     -0.0676032    0.0140904
  0.0324966    0.124879    0.0317299    0.0146449    0.000976128   0.113152    -0.0675231    0.149262    -0.103851    -0.0798838   -0.0415086   -0.0482653   -0.00678956    0.188345    -0.0234149   -0.0442251    -0.167593    -0.105539     0.120717     0.0260498    0.0694299   -0.0532276   -0.0771119    0.0526004    0.0196635   -0.155639
 -0.127413     0.162809    0.200364     0.0497699    0.11092       0.0691275   -0.0234382    0.0434871   -0.130765    -0.00506436  -0.0475782   -0.0197384    0.0671787     0.0959157   -0.219615    -0.0876482     0.0898189    0.018756     0.110663     0.208943    -0.195363    -0.128551    -0.00292981  -0.135333     0.0325826    0.0156371
 -0.0623955   -0.0175583   0.160686    -0.108941    -0.0455338     0.193774    -0.116137    -0.00642796   0.0108372   -0.0611656   -0.00174759  -0.0932861   -0.0552142     0.134696     0.156534     0.118097      0.00710222  -0.0299246   -0.0312993    0.064819    -0.09791      0.0953925    0.18105      0.0159112    0.0287748   -0.220972
 -0.00365417  -0.0283653   0.0806576   -0.10423      0.146051     -0.0566187   -0.0403871   -0.0219487    0.13176      0.0342008   -0.103317    -0.153619    -0.0591979    -0.057997     0.00145532  -0.0590714    -0.0770836    0.17045      0.00536463  -0.0127931   -0.0736612    0.0413868   -0.0464113    0.0893777   -0.145211    -0.00260861
  0.0193622   -0.0329454  -0.134979     0.0259994    0.188061      0.0836724    0.101785     0.151505    -0.1715       0.159151    -0.0839999    0.114006    -0.175807      0.0391821    0.0142672   -0.113142     -0.128951    -0.0867523    0.0221242    0.156614     0.0390999    0.249236    -0.18122     -0.0158037   -0.020982    -0.0183584
 -0.122293     0.0719642   0.164124    -0.0203318   -0.0455324     0.161912    -0.0675157    0.074627     0.126555    -0.0974613   -0.0307836   -0.0297489   -0.00302924    0.068236    -0.161493    -0.0304444     0.101577     0.0345201    0.0177007    0.160054     0.071431    -0.0232437    0.057887     0.0288949   -0.0684372   -0.0318923
  0.0337992   -0.213796   -0.0215529   -0.0431754   -0.0473926     0.0476162   -0.00229131   0.0307565   -0.00146739  -0.0117805   -0.041937    -0.038044    -0.0854054     0.150913     0.00758379   0.125921     -0.0154741   -0.0270835   -0.00817739   0.0671312   -0.125115     0.0547448   -0.00199204  -0.0260721    0.117819    -0.118617
  0.0231285    0.0454144   0.0211276    0.0975123    0.0155449    -0.0205253   -0.0539189    0.078116     0.0288769   -0.04579     -0.0816436   -0.125091    -0.0304861    -0.127616    -0.0960574   -0.0635201    -0.0446445    0.105478    -0.110923    -0.0829854   -0.0148173    0.0113186    0.113745    -0.147845    -0.170603     0.0168887
 -0.111914     0.0566217   0.0678226   -0.147201    -0.0640946    -0.112228     0.116772     0.00828358  -0.111395     0.157956    -0.0503499   -0.0382537    0.0444646     0.0867803   -0.0458067   -0.119791      0.190981    -0.0270538   -0.109289    -0.117202     0.0547407    0.0299037   -0.0195801   -0.0695227   -0.0870414    0.0354891kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4030779828197477
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403168
[ Info: iteration 2, average log likelihood -1.403065
[ Info: iteration 3, average log likelihood -1.401743
[ Info: iteration 4, average log likelihood -1.389003
[ Info: iteration 5, average log likelihood -1.367664
[ Info: iteration 6, average log likelihood -1.363572
[ Info: iteration 7, average log likelihood -1.363069
[ Info: iteration 8, average log likelihood -1.362849
[ Info: iteration 9, average log likelihood -1.362712
[ Info: iteration 10, average log likelihood -1.362616
[ Info: iteration 11, average log likelihood -1.362547
[ Info: iteration 12, average log likelihood -1.362496
[ Info: iteration 13, average log likelihood -1.362459
[ Info: iteration 14, average log likelihood -1.362431
[ Info: iteration 15, average log likelihood -1.362409
[ Info: iteration 16, average log likelihood -1.362389
[ Info: iteration 17, average log likelihood -1.362373
[ Info: iteration 18, average log likelihood -1.362357
[ Info: iteration 19, average log likelihood -1.362341
[ Info: iteration 20, average log likelihood -1.362326
[ Info: iteration 21, average log likelihood -1.362308
[ Info: iteration 22, average log likelihood -1.362286
[ Info: iteration 23, average log likelihood -1.362253
[ Info: iteration 24, average log likelihood -1.362204
[ Info: iteration 25, average log likelihood -1.362133
[ Info: iteration 26, average log likelihood -1.362038
[ Info: iteration 27, average log likelihood -1.361916
[ Info: iteration 28, average log likelihood -1.361775
[ Info: iteration 29, average log likelihood -1.361622
[ Info: iteration 30, average log likelihood -1.361467
[ Info: iteration 31, average log likelihood -1.361311
[ Info: iteration 32, average log likelihood -1.361153
[ Info: iteration 33, average log likelihood -1.360982
[ Info: iteration 34, average log likelihood -1.360799
[ Info: iteration 35, average log likelihood -1.360607
[ Info: iteration 36, average log likelihood -1.360400
[ Info: iteration 37, average log likelihood -1.360181
[ Info: iteration 38, average log likelihood -1.359965
[ Info: iteration 39, average log likelihood -1.359749
[ Info: iteration 40, average log likelihood -1.359523
[ Info: iteration 41, average log likelihood -1.359271
[ Info: iteration 42, average log likelihood -1.359049
[ Info: iteration 43, average log likelihood -1.358895
[ Info: iteration 44, average log likelihood -1.358789
[ Info: iteration 45, average log likelihood -1.358709
[ Info: iteration 46, average log likelihood -1.358644
[ Info: iteration 47, average log likelihood -1.358593
[ Info: iteration 48, average log likelihood -1.358553
[ Info: iteration 49, average log likelihood -1.358523
[ Info: iteration 50, average log likelihood -1.358502
┌ Info: EM with 100000 data points 50 iterations avll -1.358502
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4031684791690753
│     -1.4030649477173727
│      ⋮
└     -1.3585019594674383
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.358633
[ Info: iteration 2, average log likelihood -1.358485
[ Info: iteration 3, average log likelihood -1.357629
[ Info: iteration 4, average log likelihood -1.350078
[ Info: iteration 5, average log likelihood -1.332113
[ Info: iteration 6, average log likelihood -1.322535
[ Info: iteration 7, average log likelihood -1.319243
[ Info: iteration 8, average log likelihood -1.317270
[ Info: iteration 9, average log likelihood -1.316060
[ Info: iteration 10, average log likelihood -1.315324
[ Info: iteration 11, average log likelihood -1.314819
[ Info: iteration 12, average log likelihood -1.314452
[ Info: iteration 13, average log likelihood -1.314155
[ Info: iteration 14, average log likelihood -1.313887
[ Info: iteration 15, average log likelihood -1.313605
[ Info: iteration 16, average log likelihood -1.313293
[ Info: iteration 17, average log likelihood -1.312988
[ Info: iteration 18, average log likelihood -1.312740
[ Info: iteration 19, average log likelihood -1.312561
[ Info: iteration 20, average log likelihood -1.312439
[ Info: iteration 21, average log likelihood -1.312362
[ Info: iteration 22, average log likelihood -1.312313
[ Info: iteration 23, average log likelihood -1.312279
[ Info: iteration 24, average log likelihood -1.312257
[ Info: iteration 25, average log likelihood -1.312241
[ Info: iteration 26, average log likelihood -1.312230
[ Info: iteration 27, average log likelihood -1.312221
[ Info: iteration 28, average log likelihood -1.312216
[ Info: iteration 29, average log likelihood -1.312211
[ Info: iteration 30, average log likelihood -1.312207
[ Info: iteration 31, average log likelihood -1.312204
[ Info: iteration 32, average log likelihood -1.312201
[ Info: iteration 33, average log likelihood -1.312198
[ Info: iteration 34, average log likelihood -1.312195
[ Info: iteration 35, average log likelihood -1.312191
[ Info: iteration 36, average log likelihood -1.312187
[ Info: iteration 37, average log likelihood -1.312182
[ Info: iteration 38, average log likelihood -1.312176
[ Info: iteration 39, average log likelihood -1.312168
[ Info: iteration 40, average log likelihood -1.312157
[ Info: iteration 41, average log likelihood -1.312144
[ Info: iteration 42, average log likelihood -1.312126
[ Info: iteration 43, average log likelihood -1.312102
[ Info: iteration 44, average log likelihood -1.312071
[ Info: iteration 45, average log likelihood -1.312028
[ Info: iteration 46, average log likelihood -1.311972
[ Info: iteration 47, average log likelihood -1.311899
[ Info: iteration 48, average log likelihood -1.311810
[ Info: iteration 49, average log likelihood -1.311705
[ Info: iteration 50, average log likelihood -1.311584
┌ Info: EM with 100000 data points 50 iterations avll -1.311584
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.35863259402763
│     -1.3584851626171734
│      ⋮
└     -1.311584171007748
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.311657
[ Info: iteration 2, average log likelihood -1.311310
[ Info: iteration 3, average log likelihood -1.310362
[ Info: iteration 4, average log likelihood -1.303108
[ Info: iteration 5, average log likelihood -1.283440
[ Info: iteration 6, average log likelihood -1.268084
[ Info: iteration 7, average log likelihood -1.260807
[ Info: iteration 8, average log likelihood -1.256711
[ Info: iteration 9, average log likelihood -1.254483
[ Info: iteration 10, average log likelihood -1.253312
[ Info: iteration 11, average log likelihood -1.252609
[ Info: iteration 12, average log likelihood -1.252057
[ Info: iteration 13, average log likelihood -1.251528
[ Info: iteration 14, average log likelihood -1.251005
[ Info: iteration 15, average log likelihood -1.250517
[ Info: iteration 16, average log likelihood -1.250112
[ Info: iteration 17, average log likelihood -1.249811
[ Info: iteration 18, average log likelihood -1.249604
[ Info: iteration 19, average log likelihood -1.249461
[ Info: iteration 20, average log likelihood -1.249356
[ Info: iteration 21, average log likelihood -1.249273
[ Info: iteration 22, average log likelihood -1.249204
[ Info: iteration 23, average log likelihood -1.249141
[ Info: iteration 24, average log likelihood -1.249078
[ Info: iteration 25, average log likelihood -1.249006
[ Info: iteration 26, average log likelihood -1.248913
[ Info: iteration 27, average log likelihood -1.248787
[ Info: iteration 28, average log likelihood -1.248604
[ Info: iteration 29, average log likelihood -1.248308
[ Info: iteration 30, average log likelihood -1.247828
[ Info: iteration 31, average log likelihood -1.247195
[ Info: iteration 32, average log likelihood -1.246500
[ Info: iteration 33, average log likelihood -1.245812
[ Info: iteration 34, average log likelihood -1.245205
[ Info: iteration 35, average log likelihood -1.244776
[ Info: iteration 36, average log likelihood -1.244557
[ Info: iteration 37, average log likelihood -1.244473
[ Info: iteration 38, average log likelihood -1.244443
[ Info: iteration 39, average log likelihood -1.244429
[ Info: iteration 40, average log likelihood -1.244422
[ Info: iteration 41, average log likelihood -1.244417
[ Info: iteration 42, average log likelihood -1.244414
[ Info: iteration 43, average log likelihood -1.244412
[ Info: iteration 44, average log likelihood -1.244411
[ Info: iteration 45, average log likelihood -1.244410
[ Info: iteration 46, average log likelihood -1.244409
[ Info: iteration 47, average log likelihood -1.244409
[ Info: iteration 48, average log likelihood -1.244408
[ Info: iteration 49, average log likelihood -1.244408
[ Info: iteration 50, average log likelihood -1.244408
┌ Info: EM with 100000 data points 50 iterations avll -1.244408
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.311657121911682
│     -1.3113097264201568
│      ⋮
└     -1.244407592646384
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.244678
[ Info: iteration 2, average log likelihood -1.244326
[ Info: iteration 3, average log likelihood -1.242123
[ Info: iteration 4, average log likelihood -1.225960
[ Info: iteration 5, average log likelihood -1.195870
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.177509
[ Info: iteration 7, average log likelihood -1.183998
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.171921
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.173127
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.170763
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.169046
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.170969
[ Info: iteration 13, average log likelihood -1.176854
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.166013
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.168535
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.169983
[ Info: iteration 17, average log likelihood -1.170336
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.162875
[ Info: iteration 19, average log likelihood -1.174692
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.164546
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.166546
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.167625
[ Info: iteration 23, average log likelihood -1.166724
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.158063
[ Info: iteration 25, average log likelihood -1.179386
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.163889
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.164841
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.173499
[ Info: iteration 29, average log likelihood -1.169828
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.160846
[ Info: iteration 31, average log likelihood -1.172248
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.161340
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.163330
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.172121
[ Info: iteration 35, average log likelihood -1.168584
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.159488
[ Info: iteration 37, average log likelihood -1.170659
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.159993
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.169239
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.168059
[ Info: iteration 41, average log likelihood -1.166833
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.158372
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.169872
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.166562
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.165909
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.166597
[ Info: iteration 47, average log likelihood -1.165782
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.157621
[ Info: iteration 49, average log likelihood -1.176423
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.163263
┌ Info: EM with 100000 data points 50 iterations avll -1.163263
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2446777854220044
│     -1.2443262538337188
│      ⋮
└     -1.1632625298275576
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.164942
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.158290
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.161705
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.146834
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│      8
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.112289
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     11
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.074340
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│      8
│     16
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.092142
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     11
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.081499
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│      8
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.089852
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│     11
│     12
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.064087
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│      7
│      8
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.085102
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     11
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.070478
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│      8
│     16
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.080160
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     11
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.069641
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│      8
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.081311
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│     11
│     12
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.058537
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│      8
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.083020
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│     11
│     12
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.057750
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.074314
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      7
│      8
│      ⋮
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.050297
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│      8
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.091393
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.063844
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.045830
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.083414
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.059858
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.073103
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.063408
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.075081
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      5
│      7
│      8
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.055650
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.088667
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│      8
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.064579
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│     11
│     12
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.045881
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│      8
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.083572
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│     11
│     12
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.058772
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.074729
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│     11
│     12
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.061500
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│      8
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.076571
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      7
│      8
│     11
│     12
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.053892
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│      8
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.090452
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.063290
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.047865
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.082197
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.059074
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.073178
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.062913
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.075006
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│      5
│      7
│      8
│     16
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.049116
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.083198
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.054623
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.068959
┌ Info: EM with 100000 data points 50 iterations avll -1.068959
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1649417901246768
│     -1.158290400563793
│      ⋮
└     -1.0689591801592822
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4030779828197477
│     -1.4031684791690753
│     -1.4030649477173727
│     -1.401742944651987
│      ⋮
│     -1.0831978957524473
│     -1.0546225118321813
└     -1.0689591801592822
32×26 Array{Float64,2}:
  0.0280375   -0.164011    -0.0071749   -0.0984473   -0.0630652  -0.0912524    -0.0338405     0.156347    -0.117595    -0.087244     0.0478079    0.0919472    -0.00466651   0.0559603    0.0899553    0.120141     0.0312169  -0.0408825    0.0153719    0.160132     0.109376   -0.127754    -0.0166673    -0.0608621    0.0883483    -0.153989
  0.244439     0.00782436   0.0679293   -0.0921208   -0.0376084  -0.0574064     0.0525138     0.0923278   -0.153315    -0.072991     0.112701    -0.0603971    -0.220032    -0.00698926  -0.21412      0.0437336    0.0542189   0.016127    -0.0323497   -0.00359589  -0.0221818  -0.0420409    0.0178236     0.00977702   0.111319     -0.0289612
  0.0631472    0.00239541   0.0139731   -0.0288986    0.026143   -0.018235     -0.000676995   0.0942446   -0.00877424  -0.0796312   -0.0108609    0.0868896     0.0996561    0.00916936   0.0476687    0.0462599   -0.18733    -0.11853     -0.0330775   -0.0446144   -0.203457    0.0659446    0.0114148    -0.143485    -0.106311     -0.0427462
  0.0351528    0.0155423   -0.0714957   -0.104278    -0.146099    0.219354     -0.106097      0.0149908   -0.103928     0.0369304   -0.0687995    0.12403      -0.145822     0.118264    -0.0685525   -0.0797574    0.207942    0.0221398    0.0431036   -0.152383     0.0319171  -0.0217412    0.14644      -0.0745727   -0.00241471    0.137846
 -0.0373244    0.157103    -0.0535855    0.0223174    0.111358    0.0642788    -0.11796       0.0396199    0.0101459   -0.0222094   -0.138022    -0.0880276     0.00760976  -0.0120822    0.00815398  -0.157548     0.0517133   0.156743    -0.00464933  -0.0264261    0.0897633   0.105108    -0.0339194     0.0158425    0.0453382     0.277737
  0.11834     -0.176225     0.0635808    0.150821     0.0237762  -0.057032      0.192038      0.099552    -0.0165734    0.191788    -0.00924974  -0.267782     -0.0323695    0.205674    -0.0479139   -0.0661813   -0.114719    0.051608     0.116084    -0.103185     0.0497442  -0.236791    -0.0104465    -0.0351049    0.187421     -0.0335414
 -0.105185    -0.111422     0.0742474   -0.0417639    0.0128069   0.202667      0.0444314     0.164493    -0.134599     0.116243     0.344241     0.0694043     0.0869998   -0.0300148    0.00901308   0.023409    -0.0131158   0.0111695    0.15141      0.0661519   -0.213157   -0.120732    -0.21243      -0.0536337   -0.27178       0.0244105
 -0.113617    -0.103742     0.0787993    0.00709655  -0.151931   -0.0150429     0.0439928    -0.0129229   -0.125856     0.10212     -0.218624     0.0216009     0.141369    -0.0436534    0.0174559    0.0798388    0.0171844   0.0108986    0.105795     0.0227785    0.224037   -0.0927897   -0.213631      0.181797     0.780692      0.243755
 -0.141887     0.0222158    0.0900424   -0.0151713   -1.54171    -0.0572732    -0.114435     -0.0781477    0.0395137   -0.12823     -0.122701     0.00083013   -0.0306502   -0.032786    -0.0146133    0.0821324    0.0263266   0.105369     0.0366517   -0.0375764   -0.171273    0.0917723   -0.0889499     0.183514    -0.092872      0.127679
 -0.149047     0.0242029    0.00586589  -0.0242001    1.3098     -0.0782041    -0.0495261     0.0209933    0.0760298   -0.132035    -0.0857332    0.00458572   -0.148665     0.00730533  -0.0133517    0.00871029   0.0146533   0.180525     0.10461      0.0719409   -0.264275    0.0709011   -0.0932656     0.122643    -0.0636068    -0.0692668
 -0.0332587   -0.107347     0.0714434   -0.00690636  -0.0160716  -0.069252     -0.188017     -0.116263    -0.127315    -0.724566     0.0876108   -0.120096      0.175943     0.0565824    0.0746908    0.139135    -0.169639    0.0830709   -0.0143852    0.0956349    0.218499    0.0198017    0.0351143     0.0280858   -0.0912635    -0.282109
  0.0724214   -0.148611     0.203145    -0.00536973   0.102109   -0.132777     -0.186364     -0.127233    -0.11703      0.492944     0.0888056   -0.0972182     0.212864     0.062579     0.00948769   0.106367    -0.176706    0.0208103   -0.0166144   -0.132643     0.222281    0.00882388   0.0352253     0.0589236    0.0294769    -0.197793
  0.0452411    0.0756502   -0.011632     0.105723    -0.0545669  -0.0127965     0.0493319    -0.0779631   -0.116692    -0.204969    -0.159186     0.073825      0.0139458   -0.150999     0.0138764    0.23677     -0.160449   -0.17602      0.00141769   0.00659337   0.0400207   0.215706     0.119622      0.0427252   -0.0541876     0.0596777
 -0.0824544    0.139574     0.119637     0.0292347    0.0552126   0.0879712    -0.0460327     0.106324    -0.124676    -0.0462634   -0.042217    -0.0383299     0.0337311    0.139983    -0.12657     -0.0653207   -0.0436655  -0.0398214    0.109174     0.136427    -0.0517718  -0.118438    -0.0522699    -0.0473136    0.011406     -0.0728162
 -0.0280879   -0.0919197   -0.0847363    0.0451213    0.0127874  -0.016822     -0.0359233     0.0672714    0.0879886    0.0526896   -0.0060936   -0.0174121     0.0233094   -0.0105292   -0.00371968  -0.00981489   0.0595133  -0.00847648   0.112852     0.00888451   0.0349329  -0.0857296    0.00468809    0.0918632   -0.0130768     0.0695517
 -0.114515    -0.0397244    0.0637242    0.0646293    0.0401687  -0.0589723     0.210146      0.139646     0.0610249    0.105126    -0.00281334  -0.185419     -0.117225    -0.0860418   -0.00781577   0.0429693   -0.113104   -0.115664     0.0673872    0.0538      -0.0972511  -0.0150391    0.156476     -0.0941679   -0.263005     -0.0544612
 -0.0566467   -1.3627      -0.00708858  -0.0696106   -0.0573856   0.104622     -0.0814865     0.0104629    0.00578406   0.0924544   -0.0175943   -0.0393419    -0.129759     0.0263884   -0.00358555  -0.0707318    0.0106541   0.00327877  -0.0733295   -0.0465445   -0.0974334  -0.0484052   -0.138717      0.0345772    0.174825     -0.278648
 -0.0318874    0.639149     0.0201391   -0.123451    -0.0535973   0.107808     -0.0463789     0.0219796    0.0390775    0.125608     0.0120732    0.000104631  -0.133299    -0.00916023   0.0576035    0.0936755   -0.0812998  -0.0190086   -0.0575654   -0.182278    -0.118059    0.0670415   -0.210382     -0.109496     0.149214     -0.267938
  0.152324     0.107764     0.014218     0.117316     0.0159796   0.0240992     0.0044877     0.142982     0.0286628   -0.0484241   -0.538317    -0.15325      -0.0126389   -0.123624    -0.0577248   -0.0242332   -0.108171    0.0853657    0.0959111   -0.0897399   -0.0153332  -0.0727696    0.106845     -0.163673    -0.097695      0.0287514
 -0.109302     0.0771033    0.0352164    0.0817943    0.0152095  -0.0412825    -0.103735      0.0295334    0.0285469   -0.034919     0.402926    -0.0992316    -0.0482729   -0.131672    -0.114313    -0.087127    -0.011655    0.115549    -0.337963    -0.0657378   -0.0172271   0.134599     0.0818704    -0.138371    -0.170862      0.000241355
 -0.0777365   -0.100301     0.0560483   -0.0486265   -0.0167563  -0.000672975  -0.0277155     0.00881342  -0.0811433    0.0146933   -0.0273004    0.0802476     0.0108962    0.0540754    0.0775201    0.17094     -0.0351688  -0.110877    -0.0351378    0.051285    -0.0107175   0.15118     -0.0830613    -0.050184     0.0365488    -0.105966
  0.023543     0.083415    -0.0569948   -0.0216242    0.0907167  -0.00485231    0.103575     -0.0677343    0.0196929    0.159012    -0.0944279   -0.0771718     0.154895    -0.0590795    0.0461371    0.00345251  -0.103148   -0.177903     0.115809     0.208707    -0.0197008   0.052777    -0.042155     -0.0437391    0.078017     -0.165791
 -0.0224306   -0.0209241   -0.0804586    0.092408    -0.110135   -0.056001      0.151202     -0.0264568   -0.0712269    0.0802827   -0.0350894    0.160021     -0.108719    -0.116023     0.0348046    0.0318042    0.0634475   0.0704519   -0.0345314    0.185862     0.038952   -0.22975     -0.190729     -0.0040513   -0.00834291   -0.00919407
 -0.0184842   -0.0117231    0.0191479   -0.0526533    0.070369    0.137024     -0.0131857     0.0637772   -0.0941911    0.0479214   -0.0451567    0.0336342    -0.119431     0.0746019    0.0939213   -0.0198272   -0.0594341  -0.0567382    0.00573208   0.116662    -0.0318868   0.136409     0.0210489    -0.00456562   0.0153847    -0.125222
  0.159904     0.1646       0.0764457   -0.0600273   -0.123886    0.069819     -0.0309469    -0.0784223   -0.0401081    0.0881474   -0.0440516    0.0307244    -0.151536    -0.124757    -0.105003    -0.158125    -0.0637992  -0.00117999   0.093977    -0.0912728   -0.175093    0.027947     0.0266251    -0.0556497    0.0177192    -0.0201003
 -0.00244943  -0.0352837    0.076727    -0.0262469    0.147905   -0.0635223    -0.0430085    -0.0153547    0.144439     0.0408541   -0.105348    -0.149694     -0.0936372   -0.0553024    0.00852145  -0.0584903   -0.0755745   0.171157     0.0106695    0.00866317  -0.0791595   0.0439064   -0.0565031     0.0731402   -0.151371      0.00431202
 -0.111107     0.0650708   -0.0901276    0.0394013    0.0327171   0.181376     -0.0754234    -0.0978602   -0.144769    -0.0268897    0.0591775    0.0601027    -0.005366    -0.0816889   -0.00547712  -0.117098    -0.120177   -0.12148      0.0959908    0.120326     0.0767514   0.0148793   -0.0013128    -0.0112057   -0.105641     -0.0346324
 -0.0786685    0.0638375    0.176542    -0.0290427   -0.0498596   0.178921     -0.0989934     0.0621585    0.127048    -0.100834    -0.0316896    0.021145      0.0357089    0.114438    -0.177639    -0.0305032    0.0932437   0.0357525    0.0107189    0.11918      0.0686409  -0.0232581    0.0815595     0.013552    -0.0673389     0.00129547
 -0.109303     0.037581     0.0898816   -0.185606    -0.0633508  -0.115547      0.127162      0.0166145   -0.112635     0.150017    -0.0456412   -0.0534254     0.0511961    0.0857173   -0.0542863   -0.115286     0.179128   -0.0325918   -0.105301    -0.109033     0.0384039   0.0171207   -0.0280237    -0.062997    -0.0812271     0.026773
  0.273274    -0.00664152  -0.0292434    0.103274    -0.0236801  -0.148452     -0.159399     -0.0499323    0.0223463    0.168138    -0.0912475    0.0126544     0.0676929    0.0442598    0.0709701    0.170193    -0.0314941  -0.0315859   -0.0638382    0.170512    -0.171807   -0.190065     0.0423758    -0.0493692    0.0173665     0.125929
  0.0867803    0.0628031    0.159723     0.0523801    0.0449679   0.0370249     0.0133375     0.115485     0.122316    -0.00759475  -0.00174496  -0.0689159    -0.109754     0.0142867   -0.0963538   -0.0582476    0.0425494  -0.0453951   -0.0279581    0.104258     0.0703057   0.157253    -0.000375893  -0.0304553    0.000808518   0.0696164
  0.0574549    0.0166593   -0.255101     0.0751105    0.171851    0.0774163     0.105748     -0.0867763   -0.124265    -0.0606757    0.148878    -0.124838      0.11099      0.0561292   -0.103334     0.0857421    0.0489024  -0.00281887  -0.0372003    0.020582     0.116292   -0.145316    -0.137948      0.178005    -0.12506       0.137706[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.057449
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     11
│     12
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.045050
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     16
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.045397
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      5
│      7
│      ⋮
│     12
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.046766
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.051814
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│      ⋮
│     16
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.040145
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      5
│      7
│      8
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.053540
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     11
│     12
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.046298
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│     16
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.046305
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      5
│      7
│      ⋮
│     12
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.047479
┌ Info: EM with 100000 data points 10 iterations avll -1.047479
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.740841e+05
      1       6.727156e+05      -2.013685e+05 |       32
      2       6.357437e+05      -3.697195e+04 |       32
      3       6.219074e+05      -1.383629e+04 |       32
      4       6.165164e+05      -5.390972e+03 |       32
      5       6.133503e+05      -3.166065e+03 |       32
      6       6.103509e+05      -2.999479e+03 |       32
      7       6.062176e+05      -4.133278e+03 |       32
      8       6.023476e+05      -3.869967e+03 |       32
      9       5.994167e+05      -2.930958e+03 |       32
     10       5.981218e+05      -1.294840e+03 |       32
     11       5.974404e+05      -6.813957e+02 |       32
     12       5.970159e+05      -4.245464e+02 |       32
     13       5.966684e+05      -3.474687e+02 |       32
     14       5.963424e+05      -3.259798e+02 |       32
     15       5.960365e+05      -3.059630e+02 |       32
     16       5.956746e+05      -3.619116e+02 |       32
     17       5.951748e+05      -4.998037e+02 |       32
     18       5.945191e+05      -6.556976e+02 |       32
     19       5.937659e+05      -7.531359e+02 |       32
     20       5.931951e+05      -5.708502e+02 |       32
     21       5.928628e+05      -3.322956e+02 |       32
     22       5.926693e+05      -1.934875e+02 |       32
     23       5.924873e+05      -1.820025e+02 |       32
     24       5.922765e+05      -2.107902e+02 |       32
     25       5.919961e+05      -2.804089e+02 |       32
     26       5.916695e+05      -3.266255e+02 |       32
     27       5.913131e+05      -3.563349e+02 |       32
     28       5.910234e+05      -2.897426e+02 |       32
     29       5.907235e+05      -2.999054e+02 |       32
     30       5.903647e+05      -3.587659e+02 |       32
     31       5.900429e+05      -3.217876e+02 |       32
     32       5.898837e+05      -1.591812e+02 |       31
     33       5.898255e+05      -5.827818e+01 |       32
     34       5.897992e+05      -2.626114e+01 |       30
     35       5.897887e+05      -1.054672e+01 |       27
     36       5.897820e+05      -6.611973e+00 |       29
     37       5.897747e+05      -7.319472e+00 |       24
     38       5.897690e+05      -5.759290e+00 |       28
     39       5.897633e+05      -5.645837e+00 |       29
     40       5.897572e+05      -6.117826e+00 |       25
     41       5.897527e+05      -4.497765e+00 |       24
     42       5.897473e+05      -5.356108e+00 |       24
     43       5.897419e+05      -5.403179e+00 |       24
     44       5.897370e+05      -4.985730e+00 |       26
     45       5.897335e+05      -3.461570e+00 |       22
     46       5.897303e+05      -3.176445e+00 |       25
     47       5.897268e+05      -3.542522e+00 |       23
     48       5.897244e+05      -2.368003e+00 |       22
     49       5.897219e+05      -2.516842e+00 |       28
     50       5.897177e+05      -4.191030e+00 |       23
K-means terminated without convergence after 50 iterations (objv = 589717.7010517556)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.303830
[ Info: iteration 2, average log likelihood -1.271239
[ Info: iteration 3, average log likelihood -1.243390
[ Info: iteration 4, average log likelihood -1.211395
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.164758
[ Info: iteration 6, average log likelihood -1.124256
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     19
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.075379
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.107644
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.113435
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.082623
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.026453
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│      7
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.043513
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.084572
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.065632
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     19
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.030467
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      6
│      7
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.053259
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.063489
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.061141
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.066669
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│      7
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.028224
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     21
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.069149
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.073726
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      7
│     12
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.030809
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     21
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.074720
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.071067
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.045711
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      7
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.050186
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.081692
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.048525
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.056030
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      7
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.053711
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.050460
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.064429
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.055631
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      6
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.043314
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     21
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.065285
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.068400
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     19
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.037644
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      6
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.056134
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.068887
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.049261
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     19
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.052189
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      6
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.057180
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.050433
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.063851
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.055808
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│     22
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.035094
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     21
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.065683
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.069378
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.039421
┌ Info: EM with 100000 data points 50 iterations avll -1.039421
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.16743      0.166815     0.0766463   -0.0550377   -0.127005     0.0722357   -0.0229567    -0.0771412   -0.0418998    0.0852013  -0.0439816     0.0343246    -0.151013    -0.113211    -0.106881    -0.156875    -0.0719161   -0.00617495   0.0929821   -0.0948242   -0.168318     0.0286061    0.0259306   -0.0555358    0.0179354    -0.0204997
  0.0281417   -0.164424    -0.00677001  -0.0982773   -0.0641176   -0.0916258   -0.0331462     0.156487    -0.115728    -0.0864721   0.0478734     0.0923068    -0.00453311   0.0558779    0.0904987    0.120212     0.0309274   -0.0400873    0.0154562    0.16069      0.109583    -0.126782    -0.0163316   -0.061734     0.0873988    -0.156534
  0.114386    -0.17043      0.0591086    0.148894     0.0276519   -0.0552305    0.181785      0.0983243   -0.0144065    0.191454   -0.0196764    -0.259226     -0.0362702    0.194719    -0.0455122   -0.0677469   -0.113122     0.0544359    0.11421     -0.0989638    0.0489116   -0.22473     -0.0115688   -0.0332281    0.186128     -0.0268368
  0.100634     0.064804     0.184704     0.0717881    0.0426495    0.0270658    0.0190515     0.133132     0.136539    -0.0252454  -0.0024161    -0.0740641    -0.110987     0.010962    -0.103256    -0.0547306    0.0428985   -0.0505803   -0.0180848    0.100909     0.0740266    0.162734     0.0044849   -0.0389882    0.000153507   0.056583
 -0.0777728    0.0632885    0.174949    -0.0291734   -0.0481237    0.180523    -0.100312      0.0632794    0.127369    -0.100837   -0.0315954     0.0209783     0.0366883    0.112757    -0.178255    -0.0305028    0.0936257    0.0355292    0.0107806    0.12003      0.0686398   -0.0233957    0.0814259    0.0137146   -0.0674386    -0.000431542
 -0.0512712    0.018879     0.167665    -0.128518    -0.0488252    0.192038    -0.116296     -0.00811777  -0.00713925  -0.0590435  -0.00385932   -0.0708722    -0.0606157    0.109848     0.172145     0.119983     0.00900858  -0.0341318   -0.0200875    0.0738721   -0.101277     0.0778501    0.206466    -0.00878937   0.0325864    -0.226249
 -0.109982    -0.111324     0.075367    -0.020961    -0.0668151    0.0986871    0.0437184     0.0809007   -0.134076     0.114764    0.078449      0.0510388     0.112938    -0.0365668    0.0159604    0.0470218    0.00658695   0.00879046   0.129483     0.0433457   -3.89222e-5  -0.106031    -0.210658     0.0603828    0.249886      0.129098
 -0.112098     0.0642482   -0.0946433    0.0388363    0.0344854    0.183803    -0.0729325    -0.103232    -0.145198    -0.0286546   0.059563      0.0541625    -0.0135709   -0.0809648   -0.00902569  -0.126996    -0.116633    -0.120932     0.0961365    0.117476     0.0792804    0.0140018   -0.00266059  -0.0110584   -0.110824     -0.0369564
  0.0129606   -0.0503047   -0.0675701    0.0238185   -0.129925    -0.0662331   -0.0195239     0.108768     0.0794792   -0.0333079  -0.0146676     0.00187449   -0.0455239   -0.0324327   -0.0477206   -0.0599938   -0.142877    -0.10333     -0.0764329   -0.255955    -0.0473886    0.0223063    0.114251    -0.205376    -0.0109355     0.0503337
 -0.131449    -0.141486     0.0707285    0.0889566    0.0668011   -0.0734266    0.327928      0.144303     0.0670636    0.178891   -0.00660971   -0.178399     -0.111621    -0.118693     0.00273248   0.05983     -0.065304    -0.197749     0.0490648    0.0500718   -0.126688    -0.0282617    0.154575    -0.108221    -0.337718     -0.0446227
 -0.145523     0.022423     0.0429041   -0.0196417   -0.0846468   -0.0697572   -0.0817713    -0.0283878    0.0557589   -0.130455   -0.100212      0.000699573  -0.0864191   -0.0108512   -0.013533     0.0448716    0.017656     0.137362     0.070125     0.0130947   -0.209951     0.0804527   -0.0883978    0.151307    -0.0786616     0.022318
  0.0284392   -0.22823     -0.0253923   -0.0284665   -0.0560904    0.0533153    0.00102576    0.0172917   -0.0122642   -0.0115986  -0.0121645    -0.0383166    -0.0811502    0.15361      0.0110033    0.140524    -0.0236024   -0.0270655   -0.0506856    0.0679131   -0.0918807    0.0644962   -0.0303333   -0.0260968    0.117804     -0.120547
  0.0634954    0.0583983    0.0253407   -0.0593079    0.0542652    0.026888    -0.0281413     0.041761     0.0113372    0.0427586   0.00449381   -0.105332     -0.099302     0.0335145   -0.0440467   -0.064612    -0.0706842    0.00239257  -0.0553319    0.115474     0.0931055    0.130916    -0.0287252    0.0398427   -0.0506413     0.126977
 -0.0408997    0.114406     0.102026     0.0793846    0.0355261    0.03434      0.0224687    -0.0112573   -0.12953     -0.0834331  -0.0986624     0.016792      0.0419343   -0.0272932   -0.108527     0.0606719   -0.024145    -0.0797255    0.0649955    0.113317    -0.0841168    0.0360311    0.0516966   -0.0465428   -0.00246725    0.0292699
  0.0234655    0.0930686    0.0245283    0.0997013    0.0155614   -0.00804195  -0.0485448     0.0871193    0.0286102   -0.0418273  -0.075829     -0.126619     -0.0299977   -0.127628    -0.0861627   -0.055142    -0.0605773    0.100223    -0.117182    -0.0776864   -0.0162187    0.0291545    0.0945224   -0.151328    -0.134154      0.0141344
 -0.0582225   -0.114488    -0.116954    -0.051768     0.10744      0.00061484  -0.0308963    -0.0521112    0.0772613    0.0422862   0.0687658     0.0650327     0.0467686   -0.00423834   0.161706    -0.0129661   -0.0831778   -0.0725416    0.0689462    0.0527626    0.108633    -0.112641    -0.0707496    0.0960108    0.0441633     0.0181595
  0.018599    -0.027282    -0.129942     0.0233463    0.195342     0.0860339    0.0937994     0.142958    -0.173249     0.155      -0.0889515     0.128533     -0.1725       0.0437284    0.00542877  -0.15305     -0.111939    -0.0825544    0.0216149    0.163969     0.0395336    0.214993    -0.138309     0.0116352   -0.020071     -0.0255644
  0.0986172    0.0453127    0.0665187   -0.0729318    0.144328     0.0881541   -0.00427993    0.0887222   -0.0823988   -0.110903   -0.0153273     0.147185      0.211862     0.0362513    0.120983     0.125095    -0.217095    -0.104966     0.00873437   0.125198    -0.307457     0.104873    -0.0758851   -0.101054    -0.17482      -0.102883
 -0.17615      0.0159656    0.128604    -0.0605968    0.00801139  -0.0491174   -0.0489384    -0.00178105  -0.143036     0.0360722  -0.0366572     0.185762      0.0941825   -0.0366602    0.138715     0.210889    -0.0568629   -0.186261    -0.0178933    0.026738     0.0647818    0.210869    -0.129373    -0.071978    -0.0356741    -0.0917873
 -0.0223611   -0.017131    -0.0787467    0.0895568   -0.117291    -0.0550627    0.150031     -0.0320916   -0.0702378    0.0836654  -0.0344286     0.15115      -0.10951     -0.115906     0.0315938    0.0359201    0.0629672    0.0718606   -0.0356631    0.187678     0.0379295   -0.224219    -0.185235    -0.00294298  -0.0182944    -0.0110007
  0.0470289    0.0327271   -0.0553663   -0.142331    -0.129007     0.208172    -0.108465     -0.011367    -0.149101     0.0505733  -0.0741224     0.159172     -0.166104     0.149821    -0.074678    -0.077998     0.287731     0.0288378    0.0829571   -0.119791     0.0457175   -0.0317332    0.145179    -0.0395926   -0.0128017     0.168102
 -0.040733     0.16875     -0.0476288    0.0226888    0.103363     0.0676096   -0.127447      0.036614     0.0183677   -0.0251776  -0.136564     -0.0905966     0.0106102   -0.0148596    0.0110368   -0.144405     0.0403458    0.155527    -0.00736202  -0.0264279    0.0943739    0.103451    -0.0320524    0.0179858    0.0415208     0.280901
  0.243915    -0.00762271   0.0684654   -0.083656    -0.0361082   -0.0576052    0.059987      0.095447    -0.154901    -0.0758035   0.110103     -0.067036     -0.214938    -0.00960391  -0.208597     0.0452861    0.0492758    0.0196726   -0.0316745   -0.00296158  -0.0217903   -0.0474641    0.0162195    0.0127242    0.0956612    -0.0356709
 -0.00215812  -0.0327486    0.0774904   -0.0361707    0.142954    -0.0639463   -0.0432772    -0.016119     0.140929     0.0416062  -0.104359     -0.147621     -0.101113    -0.0592057    0.00767044  -0.0601497   -0.0757897    0.16976      0.0127195    0.00363605  -0.0799577    0.041281    -0.0554805    0.0700384   -0.152223      0.00290413
  0.0257552   -0.14662      0.147687    -0.00132129   0.05603     -0.102065    -0.169703     -0.108207    -0.105463     0.0169592   0.0826459    -0.115809      0.162258     0.0513101    0.0319829    0.129432    -0.174357     0.0398542   -0.00999078  -0.026414     0.19663      0.00878128   0.0422137    0.0272285   -0.0491256    -0.220621
  0.090601     0.0187399    0.0241378   -0.0297782   -0.0357382   -0.133354    -0.0133144    -0.0237545   -0.0444777    0.151095   -0.0599625    -0.0294824     0.0651555    0.0662105    0.00320366   0.032104     0.0774985   -0.0311987   -0.0848136    0.032492    -0.0667441   -0.095248     0.0051982   -0.0423686   -0.0372251     0.0850863
 -0.00285854  -0.090998    -0.0576293    0.134899    -0.0752584   -0.0385587   -0.0372812     0.177869     0.107665     0.0515421  -0.0680502    -0.0964295    -0.00428878  -0.0145696   -0.156182    -0.00870723   0.195958     0.0514012    0.151191    -0.031397    -0.0446392   -0.0553921    0.0762261    0.0765483   -0.0770837     0.0988183
 -0.0899005    0.176727     0.0427325    0.0235297   -0.00577305   0.0548019   -0.000826846   0.161819    -0.0812914   -0.0931299  -0.0326133    -0.0768885    -0.0322685    0.0989191   -0.0234313   -0.0191172   -0.201518    -0.118832     0.0834656    0.0634245    0.036369    -0.0679079   -0.00883378   0.00654491  -0.0651353    -0.116511
  0.0234271    0.0829716   -0.0574717   -0.0218282    0.0882257   -0.00640717   0.10269      -0.0676948    0.0199327    0.159027   -0.0947897    -0.0778598     0.152832    -0.0587925    0.049285     0.00285736  -0.100377    -0.176959     0.119275     0.208912    -0.0192304    0.051378    -0.0426423   -0.0420166    0.0789534    -0.165467
  0.0597227    0.00593135  -0.296981     0.0838846    0.173659     0.091834     0.111415     -0.0905828   -0.122637    -0.0607234   0.150315     -0.123571      0.128739     0.0466345   -0.113104    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
 0.0924495    0.0572323    0.00147227  -0.038124     0.0192264    0.138166    -0.157296    -0.141749     0.185653    -0.128763      0.147292
 -0.0454969   -0.291842     0.00760286  -0.0987503   -0.0554492    0.103866    -0.0604623     0.0170119    0.0229633    0.111406    2.32502e-5   -0.0193847    -0.128803     0.00713773   0.0254714    0.0132247   -0.0374087   -0.00915573  -0.0665537   -0.119776    -0.107042     0.0110785   -0.174497    -0.0498204    0.150638     -0.271139
 -0.0575376   -0.27423      0.0651857   -0.0460178   -0.0425252    0.0489463   -0.0826895     0.0298461   -0.0538505   -0.0579998   0.000791157   0.0962924     0.0316389    0.0493387    0.136008     0.0649631   -0.181043    -0.0198917    0.0041193   -0.0716611   -0.0318665   -0.136956    -0.101437     0.0655494    0.263518     -0.0646241┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│      7
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.048142
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      6
│      7
│     10
│     21
│     23
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.015330
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     19
│      ⋮
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.995790
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      6
│      7
│     10
│      ⋮
│     23
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.019370
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.027414
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      6
│      7
│     10
│      ⋮
│     23
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.000989
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│     23
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.028786
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      6
│      7
│     12
│     21
│     23
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.009734
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      6
│      7
│     10
│      ⋮
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.998420
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      6
│      7
│     13
│     21
│     23
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.033410
┌ Info: EM with 100000 data points 10 iterations avll -1.033410
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0813652    0.0557904    0.0121783     0.0684535   0.187442    -0.113388     0.00403263  -0.00745859  -0.181534     0.0590922    0.149991     0.157784     0.0575875    0.165542     0.0695832    0.000599689   0.0664333   -0.0611124   0.0140308    -0.0499946    0.110808   -0.177396     -0.0578061   -0.0138081   -0.0863611    -0.175416
 -0.103926     0.0734972   -0.0803593    -0.154368   -0.0702431   -0.0983896    0.0780096   -0.116384     0.157968    -0.0848755    0.0185838   -0.203106    -0.0220682   -0.0246589    0.0666626   -0.0958818     0.0332473   -0.0276259  -0.0591279    -0.133609     0.0345759   0.0644469    -0.0738545   -0.112017     0.00776172   -0.00747624
 -0.0276462    0.0555917   -0.0753126    -0.0716236   0.024278     0.0782891    0.0104486   -0.105197    -0.0327829    0.116607     0.0946328   -0.0277705    0.100556    -0.0899165    0.0487616    0.123173     -0.0535347   -0.116053   -0.0448812     0.00863457   0.0450642  -0.153702      0.306168    -0.0477477    0.0199622    -0.0842042
 -0.10315      0.0970811    0.0362659    -0.128253   -0.208966     0.070359     0.128197    -0.025083     0.0512621    0.239414    -0.0967596    0.0719736   -0.0948485   -0.052494    -0.0811994    0.0916858    -0.183396    -0.0499592   0.00455833   -0.140828    -0.120892    0.114383      0.0343264   -0.133456     0.0632204     0.22596
 -0.0371604   -0.111834    -0.0451612    -0.0561575   0.0195129   -0.00499267   0.0989665    0.0495106   -0.0433317    0.0444939   -0.155748     0.107939     0.0530049   -0.0628783    0.0254126   -0.0433859     0.0099762    0.0868374  -0.000930016   0.0092568   -0.107079   -0.158082      0.140974    -0.0545072   -0.0691687    -0.0407016
 -0.108852     0.0800641    0.10374      -0.122479   -0.120489    -0.015562     0.0386847   -0.114339     0.175722    -0.0567415    0.22519      0.00476436   0.259335     0.0343203    0.0607738   -0.0746031    -0.0190314    0.0665882   0.0771413    -0.00361374  -0.0665047  -0.00831395    0.0633059    0.0803608   -0.161398      0.0346413
  0.0789055   -0.0743917   -0.0642999     0.124381   -0.0341514   -0.0360467    0.0261541    0.0451031    0.149856    -0.00371462   0.0750243   -0.0102654    0.148738     0.0671012   -0.00480559  -0.0452412    -0.15335      0.17561     0.113977      0.219194    -0.200427    0.133416      0.20152     -0.099394     0.0992896     0.0172029
 -0.082274     0.020036    -0.0145533    -0.0225613  -0.0374419    0.0870547   -0.0173652   -0.100203     0.0260035   -0.0484195   -0.0531838   -0.0604394    0.0183505    0.0627706   -0.0514899   -0.0288253    -0.0392547   -0.0181721   0.0153525    -0.0645339   -0.107115   -0.127492      0.0460101    0.0485042   -0.150223     -0.0656969
  0.0377351    0.0495444   -0.0165959     0.132617    0.0486198   -0.0291304   -0.0263158   -0.0341345   -0.0258771   -0.162859    -0.0625242   -0.0761129   -0.174105     0.0429047    0.0237247    0.136595     -0.092946     0.0281981   0.0682648    -0.111139     0.112736    0.167493      0.0845062    0.0555969    0.0883141     0.0842301
 -0.107999     0.0155717   -0.0228729    -0.161713   -0.0076544    0.0263108    0.0774618    0.0629053   -0.182728    -0.0905146    0.0430668    0.0279108   -0.0134716    0.0946406    0.0413585   -0.179652      0.0234426    0.136823   -0.0671242    -0.075317     0.0207651   0.0473153     0.0571545   -0.03122      0.0460232     0.0140589
  0.09589     -0.00310569  -0.0777916     0.140002   -0.0782081    0.110327     0.0338526    0.0826889    0.037336    -0.155351    -0.128679     0.0818772   -0.0233234   -0.0708693   -0.124717     0.0394142    -0.245013     0.138858   -0.085306     -0.0321152    0.0444864   0.0140141     0.123523     0.0635282    0.0252809     1.52904e-5
 -0.171969     0.0902145   -0.0417048     0.112892    0.00442634  -0.167318    -0.0549023    0.0390293    0.00958834  -0.158248     0.351143    -0.00369787  -0.181744    -0.155324     0.0371892   -0.0599547    -0.0293487   -0.0536381   0.0489971    -0.182211     0.024244   -0.0495839    -0.029339     0.040136     0.101011      0.0446586
 -0.00316388   0.118093    -0.039512     -0.0705151   0.148979    -0.00645051  -0.00231619  -0.0106673   -0.0631272   -0.00127675   0.0869664   -0.0613948   -0.195617    -0.0555411   -0.072269    -0.204879      0.118303     0.060908   -0.0669807    -0.195474    -0.0719548   0.0899704     0.130895     0.0320403    0.0347262    -0.0307035
  0.109129    -0.0659588   -0.0326668     0.0803518  -0.0306045   -0.00988688  -0.145304    -0.0154067    0.0827426   -0.076265    -0.0899824   -0.120179    -0.0413601   -0.0889521   -0.071479    -0.0557671     0.0518247    0.0987667   0.190349      0.117569     0.0956279  -0.0288751     0.0241622    0.13627      0.0460107    -0.0546112
  0.0290819    0.0800763   -0.0828909     0.0114191   0.198663     0.123986     0.00622647  -0.104656     0.0621852   -0.00507878  -0.0427343    0.212575     0.145474    -0.0453592    0.0417584    0.0958559    -0.00429409  -0.115001    0.0571874    -0.0801615    0.0851264  -0.0444192    -0.133695    -0.104524    -0.00506243    0.00500851
 -0.0991376    0.103642    -0.107778      0.0473645  -0.0671852    0.122493    -0.0816591   -0.0367175   -0.0976404   -0.0418949   -0.0327129    0.0394062   -0.0664725   -0.204093    -0.156018    -0.187106      0.165681    -0.207972    0.0930749     0.11121      0.126313   -0.301942     -0.175357     0.0741695    0.0201416    -0.120531
  0.104933     0.0952688    0.178611     -0.0421164  -0.132816    -0.0757426    0.104369     0.0272933    0.0205979   -0.0157574   -0.0785171   -0.0124596    0.0963987   -0.102042    -0.190998    -0.215046     -0.11785      0.0449211   0.0195055    -0.0470387    0.0663266   0.00215504    0.0566644    0.00979586   0.183522     -0.0149544
 -0.0125791    0.0423751    0.0775228     0.0169475   0.0585005    0.00782597   0.0148603    0.00740353   0.172649     0.0369079    0.00478563   0.0945685   -0.194418    -0.0083497    0.0887361    0.076313      0.150731     0.159542    0.0961956     0.0293277    0.203697    0.0273659    -0.0490892    0.0640785    0.0492309    -0.153563
 -0.0174231   -0.0267613   -0.00239671    0.274021    0.0624913   -0.0188217    0.0664925    0.163089     0.139489    -0.0724145    0.0520048    0.0510431    0.0111001    0.00905117  -0.00276631   0.0656311    -0.175133    -0.199723    0.163263      0.00772652  -0.129554    0.0967611    -0.0482287   -0.0546597    0.213957      0.0475774
  0.0108837    0.0414938   -0.000693411   0.0617459   0.10127     -0.0108805    0.0615603    0.0797212   -0.00673761  -0.0643426    0.0147769   -0.0493401    0.119781     0.0462405    0.00692738   0.012737     -0.0219367   -0.115605   -0.120703     -0.089711    -0.0262206   0.108924     -0.056797     0.048661    -0.0524445    -0.212539
 -0.0319025   -0.0278074    0.102204      0.0326565  -0.199446     0.00582194   0.138958    -0.0401285   -0.0364178    0.18294      0.159788     0.0845173    0.202131     0.130604     0.0297738   -0.0339219     0.0317501   -0.0338926   0.195362      0.01774     -0.0537541   0.128817     -0.106239    -0.0460449    0.000569488  -0.00436165
 -0.0859825    0.0355011   -0.130047      0.0260908   0.012836     0.142812     0.0669399    0.135593     0.0250184   -0.21033      0.0525734    0.0220113   -0.00115217   0.121911     0.0952703    0.135734      0.0231005    0.0375406  -0.0432891     0.144895    -0.0656418  -0.125437      0.116055    -0.063079    -0.200763      0.0201191
 -0.0509534    0.0757833    0.0534703    -0.0577198  -0.0521256    0.145083     0.00832764   0.0371082    0.1813      -0.0689894    0.260645     0.0129262   -0.0617161   -0.0742237    0.0499924    0.161612     -0.0688698   -0.0875202  -0.13315      -0.127075     0.0235441  -0.0239177    -0.00429092   0.043943     0.033425      0.0169045
  0.0858067    0.0904553   -0.104546     -0.0334817   0.0707072   -0.151469     0.0225493   -0.0630812    0.152915     0.023014    -0.0181525    0.0510141    0.0466031   -0.0906035    0.0950409   -0.120311     -0.124199    -0.100242   -0.0400393    -0.00903747  -0.0558033   0.110975      0.00852454  -0.0314671   -0.284923      0.0809825
  0.140772    -0.0408638    0.0517252    -0.0397171   0.128127     0.182887    -0.154784     0.0876237   -0.0654159   -0.065893     0.0505594   -0.04575     -0.0563411   -0.00945917   0.0623346   -0.0849798    -0.0555193   -0.19082    -0.0189315     0.0114721   -0.0259668  -0.0704642     0.154392    -0.00738597  -0.0256332     0.0134443
 -0.0177973   -0.0618471    0.219646      0.096753   -0.0118207   -0.133564     0.0148747   -0.0398113   -0.0475142    0.0257937    0.0596909    0.0857156   -0.104851     0.0757254   -0.162485     0.227905     -0.0614203   -0.0946002  -0.135823     -0.115422     0.0780071  -0.109621     -0.0971096    0.0559026    0.00974577    0.142505
  0.136338    -0.099463    -0.147636     -0.0991416  -0.0985409    0.0105014   -0.136603     0.102692     0.00567544  -0.208926    -0.225413    -0.0472746    0.257124     0.0722648    0.0478111   -0.0266221     0.101868    -0.0306056  -0.150824      0.0433351    0.132458   -0.124548     -0.00667915   0.0302155   -0.0120917     0.166978
 -0.0484189    0.0664173   -0.137312      0.0286636  -0.0206557    0.021572     0.0108877    0.156714     0.0676323    0.0722567   -0.0646027   -0.00482425   0.0541977    0.0384175    0.230326     0.159757     -0.0204242   -0.120546   -0.00302508   -0.140718     0.0555591   0.000490851  -0.257293     0.232148    -0.0531489     0.0572487
  0.00838411  -0.125165     0.0242024    -0.136435    0.021585    -0.0356401   -0.124532     0.133735     0.128044     0.222094     0.0250979    0.0704456   -0.0256129    0.0623511    0.0661452   -0.0550816    -0.0984808   -0.150991    0.125935     -0.197291     0.0368902   0.0573046    -0.112247     0.0865105   -0.174294     -0.0240637
 -0.0367255   -0.195107    -0.00564791    0.153235   -0.0198107    0.0369714   -0.160219    -0.170902    -0.0851875   -0.0869555    0.0488976    0.058055    -0.116851    -0.0749717   -0.20568      0.0431414     0.25025     -0.0203432  -0.174524     -0.0716769   -0.077484    0.0291724    -0.117727    -0.102809    -0.067315      0.163655
 -0.231047    -0.07615     -0.156046     -0.0157974   0.0287613   -0.116059     0.0574546   -0.00521027  -0.214803     0.0861111   -0.115268     0.143468    -0.0835094   -0.0853003   -0.0326172   -0.0400662     0.00464778   0.0754438  -0.119673      0.00958996   0.171969    0.19432      -0.073471     0.0228704    0.0109442    -0.107001
 -0.11687      0.122926    -0.0377311    -0.203261    0.00148638  -0.0351767   -0.0817259    0.142339     0.101265    -0.119141    -0.13694      0.00816241  -0.0292274    0.143524     0.142501     0.119942      0.00583309   0.0271792  -0.108583     -0.0562426    0.0529061   0.0143746     0.0227502   -0.131622    -0.181573      0.123267kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4302436747561509
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.430263
[ Info: iteration 2, average log likelihood -1.430205
[ Info: iteration 3, average log likelihood -1.430168
[ Info: iteration 4, average log likelihood -1.430129
[ Info: iteration 5, average log likelihood -1.430081
[ Info: iteration 6, average log likelihood -1.430012
[ Info: iteration 7, average log likelihood -1.429894
[ Info: iteration 8, average log likelihood -1.429643
[ Info: iteration 9, average log likelihood -1.429089
[ Info: iteration 10, average log likelihood -1.428051
[ Info: iteration 11, average log likelihood -1.426713
[ Info: iteration 12, average log likelihood -1.425676
[ Info: iteration 13, average log likelihood -1.425173
[ Info: iteration 14, average log likelihood -1.424986
[ Info: iteration 15, average log likelihood -1.424921
[ Info: iteration 16, average log likelihood -1.424898
[ Info: iteration 17, average log likelihood -1.424889
[ Info: iteration 18, average log likelihood -1.424886
[ Info: iteration 19, average log likelihood -1.424885
[ Info: iteration 20, average log likelihood -1.424884
[ Info: iteration 21, average log likelihood -1.424883
[ Info: iteration 22, average log likelihood -1.424883
[ Info: iteration 23, average log likelihood -1.424883
[ Info: iteration 24, average log likelihood -1.424883
[ Info: iteration 25, average log likelihood -1.424883
[ Info: iteration 26, average log likelihood -1.424883
[ Info: iteration 27, average log likelihood -1.424883
[ Info: iteration 28, average log likelihood -1.424882
[ Info: iteration 29, average log likelihood -1.424882
[ Info: iteration 30, average log likelihood -1.424882
[ Info: iteration 31, average log likelihood -1.424882
[ Info: iteration 32, average log likelihood -1.424882
[ Info: iteration 33, average log likelihood -1.424882
[ Info: iteration 34, average log likelihood -1.424882
[ Info: iteration 35, average log likelihood -1.424882
[ Info: iteration 36, average log likelihood -1.424882
[ Info: iteration 37, average log likelihood -1.424882
[ Info: iteration 38, average log likelihood -1.424882
[ Info: iteration 39, average log likelihood -1.424882
[ Info: iteration 40, average log likelihood -1.424882
[ Info: iteration 41, average log likelihood -1.424882
[ Info: iteration 42, average log likelihood -1.424882
[ Info: iteration 43, average log likelihood -1.424882
[ Info: iteration 44, average log likelihood -1.424882
[ Info: iteration 45, average log likelihood -1.424882
[ Info: iteration 46, average log likelihood -1.424882
[ Info: iteration 47, average log likelihood -1.424882
[ Info: iteration 48, average log likelihood -1.424882
[ Info: iteration 49, average log likelihood -1.424882
[ Info: iteration 50, average log likelihood -1.424882
┌ Info: EM with 100000 data points 50 iterations avll -1.424882
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4302630241275733
│     -1.4302050048810162
│      ⋮
└     -1.4248817043230944
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424897
[ Info: iteration 2, average log likelihood -1.424843
[ Info: iteration 3, average log likelihood -1.424802
[ Info: iteration 4, average log likelihood -1.424755
[ Info: iteration 5, average log likelihood -1.424700
[ Info: iteration 6, average log likelihood -1.424636
[ Info: iteration 7, average log likelihood -1.424562
[ Info: iteration 8, average log likelihood -1.424485
[ Info: iteration 9, average log likelihood -1.424409
[ Info: iteration 10, average log likelihood -1.424338
[ Info: iteration 11, average log likelihood -1.424275
[ Info: iteration 12, average log likelihood -1.424220
[ Info: iteration 13, average log likelihood -1.424173
[ Info: iteration 14, average log likelihood -1.424132
[ Info: iteration 15, average log likelihood -1.424097
[ Info: iteration 16, average log likelihood -1.424067
[ Info: iteration 17, average log likelihood -1.424041
[ Info: iteration 18, average log likelihood -1.424017
[ Info: iteration 19, average log likelihood -1.423996
[ Info: iteration 20, average log likelihood -1.423976
[ Info: iteration 21, average log likelihood -1.423958
[ Info: iteration 22, average log likelihood -1.423942
[ Info: iteration 23, average log likelihood -1.423927
[ Info: iteration 24, average log likelihood -1.423913
[ Info: iteration 25, average log likelihood -1.423901
[ Info: iteration 26, average log likelihood -1.423890
[ Info: iteration 27, average log likelihood -1.423880
[ Info: iteration 28, average log likelihood -1.423872
[ Info: iteration 29, average log likelihood -1.423864
[ Info: iteration 30, average log likelihood -1.423857
[ Info: iteration 31, average log likelihood -1.423851
[ Info: iteration 32, average log likelihood -1.423846
[ Info: iteration 33, average log likelihood -1.423841
[ Info: iteration 34, average log likelihood -1.423837
[ Info: iteration 35, average log likelihood -1.423833
[ Info: iteration 36, average log likelihood -1.423830
[ Info: iteration 37, average log likelihood -1.423827
[ Info: iteration 38, average log likelihood -1.423824
[ Info: iteration 39, average log likelihood -1.423821
[ Info: iteration 40, average log likelihood -1.423819
[ Info: iteration 41, average log likelihood -1.423817
[ Info: iteration 42, average log likelihood -1.423815
[ Info: iteration 43, average log likelihood -1.423813
[ Info: iteration 44, average log likelihood -1.423811
[ Info: iteration 45, average log likelihood -1.423810
[ Info: iteration 46, average log likelihood -1.423808
[ Info: iteration 47, average log likelihood -1.423807
[ Info: iteration 48, average log likelihood -1.423806
[ Info: iteration 49, average log likelihood -1.423804
[ Info: iteration 50, average log likelihood -1.423803
┌ Info: EM with 100000 data points 50 iterations avll -1.423803
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4248973663632534
│     -1.4248426733799149
│      ⋮
└     -1.4238032907997893
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423815
[ Info: iteration 2, average log likelihood -1.423764
[ Info: iteration 3, average log likelihood -1.423727
[ Info: iteration 4, average log likelihood -1.423686
[ Info: iteration 5, average log likelihood -1.423639
[ Info: iteration 6, average log likelihood -1.423585
[ Info: iteration 7, average log likelihood -1.423524
[ Info: iteration 8, average log likelihood -1.423459
[ Info: iteration 9, average log likelihood -1.423394
[ Info: iteration 10, average log likelihood -1.423331
[ Info: iteration 11, average log likelihood -1.423274
[ Info: iteration 12, average log likelihood -1.423222
[ Info: iteration 13, average log likelihood -1.423177
[ Info: iteration 14, average log likelihood -1.423137
[ Info: iteration 15, average log likelihood -1.423101
[ Info: iteration 16, average log likelihood -1.423068
[ Info: iteration 17, average log likelihood -1.423038
[ Info: iteration 18, average log likelihood -1.423010
[ Info: iteration 19, average log likelihood -1.422984
[ Info: iteration 20, average log likelihood -1.422959
[ Info: iteration 21, average log likelihood -1.422934
[ Info: iteration 22, average log likelihood -1.422910
[ Info: iteration 23, average log likelihood -1.422886
[ Info: iteration 24, average log likelihood -1.422862
[ Info: iteration 25, average log likelihood -1.422838
[ Info: iteration 26, average log likelihood -1.422815
[ Info: iteration 27, average log likelihood -1.422791
[ Info: iteration 28, average log likelihood -1.422769
[ Info: iteration 29, average log likelihood -1.422747
[ Info: iteration 30, average log likelihood -1.422726
[ Info: iteration 31, average log likelihood -1.422705
[ Info: iteration 32, average log likelihood -1.422686
[ Info: iteration 33, average log likelihood -1.422668
[ Info: iteration 34, average log likelihood -1.422651
[ Info: iteration 35, average log likelihood -1.422635
[ Info: iteration 36, average log likelihood -1.422620
[ Info: iteration 37, average log likelihood -1.422606
[ Info: iteration 38, average log likelihood -1.422592
[ Info: iteration 39, average log likelihood -1.422580
[ Info: iteration 40, average log likelihood -1.422568
[ Info: iteration 41, average log likelihood -1.422557
[ Info: iteration 42, average log likelihood -1.422547
[ Info: iteration 43, average log likelihood -1.422537
[ Info: iteration 44, average log likelihood -1.422528
[ Info: iteration 45, average log likelihood -1.422519
[ Info: iteration 46, average log likelihood -1.422510
[ Info: iteration 47, average log likelihood -1.422502
[ Info: iteration 48, average log likelihood -1.422495
[ Info: iteration 49, average log likelihood -1.422487
[ Info: iteration 50, average log likelihood -1.422480
┌ Info: EM with 100000 data points 50 iterations avll -1.422480
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4238147367853151
│     -1.423764295218247
│      ⋮
└     -1.4224804542290446
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422484
[ Info: iteration 2, average log likelihood -1.422433
[ Info: iteration 3, average log likelihood -1.422388
[ Info: iteration 4, average log likelihood -1.422338
[ Info: iteration 5, average log likelihood -1.422278
[ Info: iteration 6, average log likelihood -1.422205
[ Info: iteration 7, average log likelihood -1.422118
[ Info: iteration 8, average log likelihood -1.422020
[ Info: iteration 9, average log likelihood -1.421914
[ Info: iteration 10, average log likelihood -1.421809
[ Info: iteration 11, average log likelihood -1.421710
[ Info: iteration 12, average log likelihood -1.421620
[ Info: iteration 13, average log likelihood -1.421541
[ Info: iteration 14, average log likelihood -1.421472
[ Info: iteration 15, average log likelihood -1.421412
[ Info: iteration 16, average log likelihood -1.421359
[ Info: iteration 17, average log likelihood -1.421313
[ Info: iteration 18, average log likelihood -1.421272
[ Info: iteration 19, average log likelihood -1.421235
[ Info: iteration 20, average log likelihood -1.421202
[ Info: iteration 21, average log likelihood -1.421173
[ Info: iteration 22, average log likelihood -1.421145
[ Info: iteration 23, average log likelihood -1.421120
[ Info: iteration 24, average log likelihood -1.421097
[ Info: iteration 25, average log likelihood -1.421075
[ Info: iteration 26, average log likelihood -1.421055
[ Info: iteration 27, average log likelihood -1.421035
[ Info: iteration 28, average log likelihood -1.421016
[ Info: iteration 29, average log likelihood -1.420998
[ Info: iteration 30, average log likelihood -1.420980
[ Info: iteration 31, average log likelihood -1.420963
[ Info: iteration 32, average log likelihood -1.420946
[ Info: iteration 33, average log likelihood -1.420930
[ Info: iteration 34, average log likelihood -1.420914
[ Info: iteration 35, average log likelihood -1.420898
[ Info: iteration 36, average log likelihood -1.420883
[ Info: iteration 37, average log likelihood -1.420869
[ Info: iteration 38, average log likelihood -1.420854
[ Info: iteration 39, average log likelihood -1.420840
[ Info: iteration 40, average log likelihood -1.420827
[ Info: iteration 41, average log likelihood -1.420814
[ Info: iteration 42, average log likelihood -1.420802
[ Info: iteration 43, average log likelihood -1.420790
[ Info: iteration 44, average log likelihood -1.420778
[ Info: iteration 45, average log likelihood -1.420767
[ Info: iteration 46, average log likelihood -1.420757
[ Info: iteration 47, average log likelihood -1.420747
[ Info: iteration 48, average log likelihood -1.420738
[ Info: iteration 49, average log likelihood -1.420730
[ Info: iteration 50, average log likelihood -1.420721
┌ Info: EM with 100000 data points 50 iterations avll -1.420721
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4224838237064974
│     -1.4224326485391625
│      ⋮
└     -1.4207213782691617
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420722
[ Info: iteration 2, average log likelihood -1.420662
[ Info: iteration 3, average log likelihood -1.420605
[ Info: iteration 4, average log likelihood -1.420540
[ Info: iteration 5, average log likelihood -1.420460
[ Info: iteration 6, average log likelihood -1.420360
[ Info: iteration 7, average log likelihood -1.420239
[ Info: iteration 8, average log likelihood -1.420099
[ Info: iteration 9, average log likelihood -1.419947
[ Info: iteration 10, average log likelihood -1.419792
[ Info: iteration 11, average log likelihood -1.419642
[ Info: iteration 12, average log likelihood -1.419503
[ Info: iteration 13, average log likelihood -1.419378
[ Info: iteration 14, average log likelihood -1.419268
[ Info: iteration 15, average log likelihood -1.419173
[ Info: iteration 16, average log likelihood -1.419090
[ Info: iteration 17, average log likelihood -1.419018
[ Info: iteration 18, average log likelihood -1.418955
[ Info: iteration 19, average log likelihood -1.418900
[ Info: iteration 20, average log likelihood -1.418851
[ Info: iteration 21, average log likelihood -1.418807
[ Info: iteration 22, average log likelihood -1.418767
[ Info: iteration 23, average log likelihood -1.418730
[ Info: iteration 24, average log likelihood -1.418696
[ Info: iteration 25, average log likelihood -1.418663
[ Info: iteration 26, average log likelihood -1.418633
[ Info: iteration 27, average log likelihood -1.418604
[ Info: iteration 28, average log likelihood -1.418577
[ Info: iteration 29, average log likelihood -1.418550
[ Info: iteration 30, average log likelihood -1.418525
[ Info: iteration 31, average log likelihood -1.418500
[ Info: iteration 32, average log likelihood -1.418476
[ Info: iteration 33, average log likelihood -1.418453
[ Info: iteration 34, average log likelihood -1.418430
[ Info: iteration 35, average log likelihood -1.418408
[ Info: iteration 36, average log likelihood -1.418387
[ Info: iteration 37, average log likelihood -1.418366
[ Info: iteration 38, average log likelihood -1.418346
[ Info: iteration 39, average log likelihood -1.418326
[ Info: iteration 40, average log likelihood -1.418307
[ Info: iteration 41, average log likelihood -1.418288
[ Info: iteration 42, average log likelihood -1.418269
[ Info: iteration 43, average log likelihood -1.418251
[ Info: iteration 44, average log likelihood -1.418234
[ Info: iteration 45, average log likelihood -1.418216
[ Info: iteration 46, average log likelihood -1.418199
[ Info: iteration 47, average log likelihood -1.418181
[ Info: iteration 48, average log likelihood -1.418164
[ Info: iteration 49, average log likelihood -1.418147
[ Info: iteration 50, average log likelihood -1.418130
┌ Info: EM with 100000 data points 50 iterations avll -1.418130
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4207222243304163
│     -1.4206615325891387
│      ⋮
└     -1.4181303375563317
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4302436747561509
│     -1.4302630241275733
│     -1.4302050048810162
│     -1.4301684375616295
│      ⋮
│     -1.4181643264224353
│     -1.4181472958458194
└     -1.4181303375563317
32×26 Array{Float64,2}:
 -0.175713    0.316208     0.0343472  -0.274131    -0.281932    -0.191485    -0.201073   -0.509617    0.123079    -0.0920818   -0.199073      0.261229     0.255178     0.0604664   0.457863    0.295035     0.00749519   0.392368    -0.346321   -0.676141   -0.00571064   0.186775   -0.141206    -0.580974     0.00706665   0.509779
 -0.268002    0.613359     0.503732   -0.366754     0.0233863   -0.520509     0.0290621  -0.174715    0.277861    -0.261261     0.0131914     0.360297     0.00396013   0.0438418   0.448238   -0.331326     0.112389     0.0837011    0.24236     0.620136    0.291776     0.0087637  -0.284056    -0.291204    -0.0938893    0.341922
 -0.0852222   0.0176845   -0.123879    0.0202896   -0.122849    -0.284037    -0.107096    0.237616   -0.00537026   0.0630947   -0.16177      -0.130827    -0.146145    -0.0777243   0.0439859  -0.0231924   -0.21433     -0.259533    -0.0663576   0.0273793   0.0560808    0.0345312  -0.194284     0.0812904    0.11817      0.0139367
  0.0156186  -0.100438     0.137464   -0.074045     0.0593215    0.122933     0.0324151  -0.0764257   0.0981772   -0.0468656    0.145732      0.0196896    0.120251     0.0549522  -0.0133303   0.141503     0.0100641    0.0682126    0.0525474  -0.0853305   0.0255698   -0.0143526   0.140889    -0.0609836   -0.0539156    0.062456
  0.118161    0.0759855    0.619469    0.0203061   -0.347219    -0.168636     0.313757   -0.0329013   0.297823     0.0253694    0.102738     -0.0560383   -0.0213863    0.21338     0.195179    0.403289    -0.533255     0.101509    -0.253996   -0.229887    0.0395747   -0.207515   -0.278086     0.0757106    0.83687     -0.378594
  0.0271603  -0.0932656   -0.211383    0.246649    -0.142266     0.0665531    0.148767    0.124344    0.225789    -0.157033     0.326194     -0.00378248  -0.0241466   -0.228597    0.364312   -0.0134047    0.50062      0.0115577   -0.352036   -0.69278     0.276517    -0.782969   -0.310214     0.077902     0.230227    -0.371637
  0.0349415  -0.271105    -0.0470224   0.170561    -0.112995     0.101739     0.466495    0.0249025  -0.336505     0.257934     0.200827      0.203928     0.477612    -0.241717   -0.650289    0.168621     0.180567     0.0635698    0.0336103  -0.243109   -0.273183     0.0674642   0.656113    -0.0297642    0.594785    -0.415067
 -0.138191    0.249253    -0.404714    0.193829    -0.132841     0.438416     0.534002   -0.360421    0.546889    -0.113425    -0.562591      0.335538     0.138594     0.0796748  -0.0227257  -0.384202    -0.380651     0.109462    -0.514417   -0.19257     0.0256024    0.212942    0.306424    -0.0313962    0.401671    -0.267575
 -0.19905    -0.383183     0.300398   -0.310918    -0.259931     0.571429    -0.0787727   0.137165   -0.32987     -0.196131    -0.0904524     0.167231    -0.0466459    0.127388    0.144859   -0.292578     0.111288     0.43795     -0.346582    0.175075   -0.272372     0.0877779   0.1868       0.682419    -0.309053    -0.328683
 -0.29051    -0.0780811   -0.0865732  -0.22356      0.725426     0.399265    -0.797754   -0.149085    0.0518025    0.101207    -0.312414     -0.197067    -0.231408     0.363605    0.0239434  -0.00551162  -0.38951      0.076968    -0.062266    0.344598   -0.0819347    0.498699   -0.134911     0.348111    -0.827332     0.174948
  0.0244537   0.520655    -0.145465    0.205949     0.158223     0.192939     0.163819   -0.244652   -0.188218    -0.0976914   -0.110843     -0.016757    -0.355286     0.0111693  -0.187808   -0.232932     0.223627     0.149572    -0.164318   -0.0130902   0.274758     0.23771    -0.45921      0.382925    -0.0712005   -0.305846
 -0.0880752  -0.0736387   -0.611041    0.303203     0.352297     0.10401     -0.179155    0.0357892  -0.289725     0.0852679    0.0281063     0.215578     0.0127465    0.110052   -0.350636   -0.366137     0.283281    -0.0970956    0.284456    0.141227   -0.100063     0.248591    0.439195     0.113543    -0.543573    -0.0796726
  0.513103    0.0897782   -0.239766    0.0310454   -0.523312     0.37201     -0.393515    0.367895    0.45489     -0.629457     0.3135        0.166565     0.0859954   -0.293764   -0.668377    0.0875117   -0.0672849   -0.242221    -0.0931414   0.0219336  -0.760815    -0.0548856  -0.245672    -0.159861    -0.47961      0.0613962
  0.204848    0.0256732    0.268771   -0.0231081    0.23247      0.30782     -0.140582    0.03435     0.647682     0.514224     0.262061     -0.543122    -0.406046    -0.254042    0.072994   -0.0914811   -0.286035    -0.252001     0.311848    0.285846   -0.831301    -0.397618    0.292935     0.138851    -0.106788    -0.204777
  0.243326   -0.464031    -0.347821    0.00380099   0.0711633    0.0633915   -0.217909    0.656027    0.186902    -0.391385    -0.149425     -0.133672     0.250774     0.0663019   0.330024    0.169076    -0.595769    -0.223203     0.384476   -0.16945    -0.0110594   -0.35354     0.342306    -0.601774     0.187642     0.478006
  0.356251   -0.0553806   -0.104513   -0.101707     0.00508189  -0.256913    -0.146143    0.411348    0.067887     0.221391     0.352975     -0.709704     0.112165    -0.0471312   0.152741    0.114099     0.38002     -0.118069     0.714767    0.0402676   0.32465     -0.0306619   0.228222    -0.202668    -0.232113     0.447084
  0.0738763   0.328431     0.353996   -0.0811541   -0.489399     0.196775     0.709121    0.20654     0.00492157  -0.380646    -0.194519     -0.353718    -0.356555    -0.0222566  -0.646476   -0.875016     0.143171    -0.0745538    0.537768    0.605728    0.18043     -0.376838   -0.166398     0.530466    -0.0841564    0.0278135
 -0.612489   -0.0664075    0.529844   -0.0658389   -0.494173     0.0420514    0.70302     0.403446   -0.0574061   -0.0716603    0.21437      -0.0385406   -0.850832    -0.431547   -0.0101061   0.491424    -0.467323    -0.289064    -0.163947    0.214854    0.374098     0.255347    0.00454411   0.586403    -0.185981    -0.00836597
 -0.259525   -0.486605    -0.379725   -0.0413334   -0.37617      0.98226      0.946837   -0.290516   -0.633797     0.141259    -0.264447     -0.393862    -0.694275     0.477306   -0.540227    0.144267    -0.11657     -0.0433476    0.604817   -0.19322    -0.426855     0.212558    0.785622     0.00220288  -0.43024     -0.0293288
  0.113562   -0.259583    -0.0636204   0.0600302    0.279761     0.558446    -0.0285012   0.0483166  -0.129148    -0.240606    -0.00378427    0.257166     0.194659    -0.124207   -0.222668   -0.0254763    0.029252     0.129154    -0.233377   -0.0787519  -0.163246    -0.127506    0.245494     0.411701    -0.199376    -0.290477
 -0.316539    0.411574    -0.424991   -0.361501     0.135701    -0.505532    -0.53728     0.84521     0.270926     0.69229     -0.951926     -0.248603     0.651351    -0.123301    0.196225   -0.411914    -0.452874    -0.0601662    0.174671    0.555094   -0.290403     0.486902    0.152005     0.400846     0.498908     0.35489
 -0.604071    0.505492    -0.404398    0.7609       0.0622483   -0.00129482  -0.696954    0.35072    -0.302941    -0.00192194  -0.380411      0.2146      -0.391542    -0.60932     0.101531   -0.223959    -0.0697326    0.1353      -0.87894     0.140534   -0.262894     0.333409   -0.543877     0.383308     0.507473     0.439445
 -0.234065    0.499735    -0.0902602  -0.283436    -0.234148    -0.0486852   -0.372573   -0.283166   -0.0836989   -0.406622     0.15799       0.244558     0.281416    -0.287409   -0.486051   -0.133155     0.222918     0.37655      0.156825    0.516231   -0.200913     1.08274     0.285659    -0.0793312   -0.203617     0.434367
 -0.0213042   0.0298747    0.147262   -0.190657    -0.296482     0.57464     -0.172818    0.262026    0.152404    -0.863212     0.14483       0.146286     0.701097     0.734026   -0.142916    0.170615    -0.23025      0.198906     0.111077    0.32631     0.75343      0.548989   -0.571365     0.126468     0.263535     0.0954256
  0.0829836   0.0560764   -0.151215    0.104515    -0.35887     -0.403121     0.0958515  -0.0330868   0.197034     0.303023    -0.0679049     0.0190006   -0.294897     0.0411901   0.386035    0.0930512   -0.02366     -0.0789051   -0.0813109  -0.394504    0.0207266   -0.136047   -0.0990446   -0.436843     0.205053     0.0443521
  0.0820988   0.251273     0.832488   -0.429873     0.513603    -0.551839    -0.397824    0.288366    0.293105    -0.374707     0.649032     -0.0330208    0.52133     -0.226698    0.7598      0.284521    -0.107841     0.141095    -0.18958     0.145493    0.111269    -0.669971   -0.244407    -0.153774    -0.0933618    0.217829
  0.853896    0.125962    -0.79538     0.0289995    0.570711    -0.246815    -0.709854   -0.347327    0.299506     0.146903     0.0393569     0.0776404    0.747817     0.387118    0.204315   -0.450623     0.661833    -0.00793916   0.191669   -0.325711   -0.185982    -0.390487   -0.566866    -0.369148     0.179339    -0.333204
  0.421481   -0.150017     0.0859652   0.128292    -0.205854     0.590261     0.299509   -0.699134    0.268327    -0.462935     0.237109     -0.00995209   0.100917     0.197723   -0.0995398   0.693342     0.830315     0.0313359   -0.0307487  -0.428335    0.138285    -0.608415   -0.218463    -0.518352    -0.256487    -0.0610701
 -0.0508102  -0.630688     0.466323   -0.832467     0.185022    -0.547099     0.577083   -0.288551   -0.11716      0.379357     0.251278      0.312905     0.0583319    0.466433    0.0767898   0.0873478   -0.194554    -0.259455     0.0138366  -0.136638    0.37348     -0.160861    0.257026    -0.582949    -0.391742     0.262483
 -0.337134   -0.169393     0.30224     0.404179     0.282346    -0.24079      0.305544   -0.0556923  -0.619795     0.7261       0.000940135  -0.140345     0.286927     0.826837    0.649566   -0.145072    -0.115674     0.158779     0.658727    0.0678479   0.762727     0.0457407   0.037317     0.668513    -0.0676299   -0.36249
 -0.22203     0.00648184  -0.326142    0.162909     0.28889     -0.850056    -0.36754    -0.114679   -0.158587     0.00524453   0.236037      0.305577    -0.0646098   -0.332337   -0.542197    0.308385    -0.063451    -1.02716     -0.124806   -0.0937728   0.101129     0.0929844  -0.326773    -0.438962     0.098136     0.136833
 -0.215576   -0.0375289   -0.362882    0.528579     0.456579    -0.632582     0.0489789  -0.0981897  -0.627384     0.362127    -0.1381        0.163831    -0.431764    -0.623133    0.232792    0.120722     0.0328127    0.0392061   -0.0252205  -0.613848   -0.0192612   -0.184337    0.737639    -0.25878     -0.128909     0.229644[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418113
[ Info: iteration 2, average log likelihood -1.418097
[ Info: iteration 3, average log likelihood -1.418080
[ Info: iteration 4, average log likelihood -1.418064
[ Info: iteration 5, average log likelihood -1.418048
[ Info: iteration 6, average log likelihood -1.418032
[ Info: iteration 7, average log likelihood -1.418017
[ Info: iteration 8, average log likelihood -1.418002
[ Info: iteration 9, average log likelihood -1.417988
[ Info: iteration 10, average log likelihood -1.417974
┌ Info: EM with 100000 data points 10 iterations avll -1.417974
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.072650e+05
      1       7.100272e+05      -1.972378e+05 |       32
      2       6.996878e+05      -1.033936e+04 |       32
      3       6.952978e+05      -4.389993e+03 |       32
      4       6.928559e+05      -2.441938e+03 |       32
      5       6.912489e+05      -1.606965e+03 |       32
      6       6.900671e+05      -1.181868e+03 |       32
      7       6.891379e+05      -9.291489e+02 |       32
      8       6.884244e+05      -7.135488e+02 |       32
      9       6.878374e+05      -5.870249e+02 |       32
     10       6.873459e+05      -4.914446e+02 |       32
     11       6.869423e+05      -4.036516e+02 |       32
     12       6.865670e+05      -3.752778e+02 |       32
     13       6.862103e+05      -3.566603e+02 |       32
     14       6.859067e+05      -3.036475e+02 |       32
     15       6.856115e+05      -2.951460e+02 |       32
     16       6.853493e+05      -2.622650e+02 |       32
     17       6.851111e+05      -2.381733e+02 |       32
     18       6.848909e+05      -2.201563e+02 |       32
     19       6.847031e+05      -1.878237e+02 |       32
     20       6.845620e+05      -1.410601e+02 |       32
     21       6.844502e+05      -1.118878e+02 |       32
     22       6.843388e+05      -1.113607e+02 |       32
     23       6.842333e+05      -1.055148e+02 |       32
     24       6.841487e+05      -8.453822e+01 |       32
     25       6.840699e+05      -7.881793e+01 |       32
     26       6.839983e+05      -7.161395e+01 |       32
     27       6.839392e+05      -5.910620e+01 |       32
     28       6.838832e+05      -5.605764e+01 |       32
     29       6.838296e+05      -5.358952e+01 |       32
     30       6.837694e+05      -6.015695e+01 |       32
     31       6.837070e+05      -6.243789e+01 |       32
     32       6.836512e+05      -5.575762e+01 |       32
     33       6.835963e+05      -5.489018e+01 |       32
     34       6.835391e+05      -5.719692e+01 |       32
     35       6.834845e+05      -5.459056e+01 |       32
     36       6.834409e+05      -4.361698e+01 |       32
     37       6.833964e+05      -4.449787e+01 |       32
     38       6.833459e+05      -5.054273e+01 |       32
     39       6.832980e+05      -4.788012e+01 |       32
     40       6.832539e+05      -4.411800e+01 |       32
     41       6.832117e+05      -4.219392e+01 |       32
     42       6.831703e+05      -4.137024e+01 |       32
     43       6.831266e+05      -4.374016e+01 |       32
     44       6.830848e+05      -4.173266e+01 |       32
     45       6.830431e+05      -4.178092e+01 |       32
     46       6.830028e+05      -4.030180e+01 |       32
     47       6.829629e+05      -3.989007e+01 |       32
     48       6.829244e+05      -3.846698e+01 |       32
     49       6.828779e+05      -4.649875e+01 |       32
     50       6.828307e+05      -4.720332e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 682830.697163527)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.430041
[ Info: iteration 2, average log likelihood -1.424851
[ Info: iteration 3, average log likelihood -1.423327
[ Info: iteration 4, average log likelihood -1.422104
[ Info: iteration 5, average log likelihood -1.420903
[ Info: iteration 6, average log likelihood -1.419977
[ Info: iteration 7, average log likelihood -1.419437
[ Info: iteration 8, average log likelihood -1.419144
[ Info: iteration 9, average log likelihood -1.418964
[ Info: iteration 10, average log likelihood -1.418835
[ Info: iteration 11, average log likelihood -1.418732
[ Info: iteration 12, average log likelihood -1.418647
[ Info: iteration 13, average log likelihood -1.418574
[ Info: iteration 14, average log likelihood -1.418511
[ Info: iteration 15, average log likelihood -1.418456
[ Info: iteration 16, average log likelihood -1.418407
[ Info: iteration 17, average log likelihood -1.418363
[ Info: iteration 18, average log likelihood -1.418323
[ Info: iteration 19, average log likelihood -1.418287
[ Info: iteration 20, average log likelihood -1.418254
[ Info: iteration 21, average log likelihood -1.418224
[ Info: iteration 22, average log likelihood -1.418196
[ Info: iteration 23, average log likelihood -1.418170
[ Info: iteration 24, average log likelihood -1.418146
[ Info: iteration 25, average log likelihood -1.418123
[ Info: iteration 26, average log likelihood -1.418102
[ Info: iteration 27, average log likelihood -1.418083
[ Info: iteration 28, average log likelihood -1.418065
[ Info: iteration 29, average log likelihood -1.418048
[ Info: iteration 30, average log likelihood -1.418031
[ Info: iteration 31, average log likelihood -1.418016
[ Info: iteration 32, average log likelihood -1.418002
[ Info: iteration 33, average log likelihood -1.417988
[ Info: iteration 34, average log likelihood -1.417975
[ Info: iteration 35, average log likelihood -1.417963
[ Info: iteration 36, average log likelihood -1.417951
[ Info: iteration 37, average log likelihood -1.417939
[ Info: iteration 38, average log likelihood -1.417928
[ Info: iteration 39, average log likelihood -1.417918
[ Info: iteration 40, average log likelihood -1.417907
[ Info: iteration 41, average log likelihood -1.417897
[ Info: iteration 42, average log likelihood -1.417888
[ Info: iteration 43, average log likelihood -1.417878
[ Info: iteration 44, average log likelihood -1.417869
[ Info: iteration 45, average log likelihood -1.417860
[ Info: iteration 46, average log likelihood -1.417852
[ Info: iteration 47, average log likelihood -1.417844
[ Info: iteration 48, average log likelihood -1.417836
[ Info: iteration 49, average log likelihood -1.417829
[ Info: iteration 50, average log likelihood -1.417821
┌ Info: EM with 100000 data points 50 iterations avll -1.417821
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.00192694   0.910188   -0.0772655   0.480224      0.396554    -0.224168    -0.156466    0.322922    -0.321189   -0.191846     0.428423    -0.024509   -0.458276    -0.386635     -0.104274    -0.688608    0.264123    0.301459    -0.149887      0.363459     0.00820093   0.0171432    -0.0361599    0.409019   -0.0179193    0.224288
  0.136495    -0.845516   -0.525515    0.579716     -0.156924    -0.0341836    0.130825    0.762375    -0.227557    0.232842     0.149411    -0.165875   -0.220581    -0.0974539     0.437356    -0.0726892   0.122486   -0.282265     0.168018     -0.644257     0.0118215   -1.08831       0.17446      0.205276   -0.306841    -0.471967
  0.606074     0.429516   -0.0373633   0.307843     -0.0853815    0.504335    -0.0797516  -0.443642    -0.115847    0.0922133    0.202417    -0.683393    0.0430155    0.568812     -0.0363385    0.359965    0.912642    0.350922     0.630331     -0.3592      -0.0790183   -0.13148       0.547555    -0.609395   -0.128823     0.584618
  0.015274    -0.187264   -0.0250609   0.312196     -0.0103168   -0.356128    -0.397861    0.0987204    0.454565    0.118821     0.0247098   -0.295317   -0.214257    -0.343883      0.223991     0.5863     -0.361648   -0.685147    -0.0143008    -0.454213    -0.700757    -0.510012     -0.0394627   -0.61215     0.250027     0.258379
  0.253723    -0.235638    0.0608282  -0.290534      0.00578572  -0.267588    -0.132344    0.302731     0.124103    0.0671263    0.246334    -0.274935    0.108598    -0.102722     -0.0796361    0.199289   -0.122129   -0.268866     0.383929     -0.0207288   -0.0320609   -0.014915      0.19471     -0.288387   -0.158324     0.411619
  0.147826    -0.145796   -0.764646    0.128331      0.133852    -0.0535766   -0.0909231   0.213709    -0.15429    -0.289398    -0.601448     0.0549384   0.250577     0.0300133     0.474506    -0.182523   -0.386581    0.38224      0.358473     -0.454991     0.303123    -0.102044      0.646627    -0.784605    0.0425613    0.591246
  0.186903    -0.0447782   0.258936   -0.446123     -0.660668     0.317221     0.0126691   0.403987     0.113498   -0.0437721   -0.657144    -0.315746   -0.0594852    0.0797672     0.323685    -0.763185   -0.102436    0.619954     0.0630841     0.26265     -0.583358    -0.0740365     0.404721     0.751817   -0.00261392  -0.54834
 -0.041576    -0.0844145   0.049798    0.0957287     0.00822322   0.162644     0.0517759   0.0958391    0.13968     0.0604933    0.128899     0.0920402   0.107778     0.0144532    -0.225571     0.0917465  -0.220857   -0.0978422   -0.144363      0.0405971   -0.250935    -0.0300953     0.175261     0.170062    0.273673    -0.357433
  0.0788458   -0.178844    0.117376   -0.0346329    -0.167083     0.480393    -0.55633     0.295       -0.176206   -0.799079     0.37154      0.386266    0.587603     0.10134      -0.054746     0.212404    0.0466575   0.460259    -0.0877873     0.195496     0.0260727    0.37113      -0.236797     0.242417   -0.179584     0.135588
  0.0345959    0.665571   -0.0066114  -0.66111      -0.44441      0.00339306   0.083462   -0.59561      0.798471   -0.5047       0.075329     0.552694   -0.0168075   -0.476815     -0.170981     0.0258937  -0.0027251   0.38318     -0.360279     -0.104736    -0.411119     0.586901      0.248079    -0.611614   -0.225913     0.578787
 -0.328695     0.0613172   0.558631   -0.444689      0.354593    -0.815578     0.146591   -0.0934147   -0.0216664   0.225469     0.180878     0.0361957   0.198704     0.102323      0.526383    -0.0260229   0.0813474  -0.0332736    0.26048       0.191602     0.495747    -0.20271       0.0708916   -0.316788   -0.201379     0.492613
  0.170791     0.176765   -0.099081    0.467434     -0.730835    -0.409569     0.816751    0.0317236   -0.0430693  -0.00187243   0.107902     0.441335    0.195339     0.00814507   -0.0473862   -0.0339473   0.0920631   0.0765078   -0.211361     -0.337039     0.384494    -0.00238456    0.0132207   -0.284187    0.907093    -0.359437
 -0.032222     0.0103289   0.0748216  -0.150809     -0.167818     0.0329606    0.0473192   0.0841981   -0.0232099  -0.0797091    0.0514007   -0.0392304  -0.00701292  -0.0331148     0.00821136   0.0407944  -0.0608912   0.0374937    0.0100047     0.00259296   0.0699181    0.0731933     0.0189525    0.0567892  -0.0226481    0.0604396
 -1.0785       0.148761   -0.344675    0.164527      0.149932     0.0424764   -0.200634    0.00914396   0.204294    0.120062    -0.557641     0.900104    0.207677    -0.157258      0.360022    -0.021037   -0.60019    -0.00104684  -0.788779     -0.281064     0.00581015   0.0846551    -0.145518    -0.0683646   0.456412     0.0462776
 -0.54807     -0.638698   -0.0668603  -0.276805     -0.2019       0.291714     0.41457    -0.455112    -0.928186    0.257862    -0.00671045   0.324053   -0.260107    -0.0184599    -0.222295    -0.197162    0.131049    0.155138     0.0176935     0.0547702   -0.0508971    0.530822      0.513288     0.021119   -0.405069     0.0880566
  0.257754     0.0862413  -0.14589     0.499334      0.433986     0.119568     0.0846491  -0.767687    -0.151456    0.422544    -0.252727     0.256208   -0.472131     0.036325     -0.236056    -0.0967982   0.0965216   0.356719    -0.116222     -0.449713    -0.347554     0.000519977   0.079282     0.0877928  -0.327387    -0.730625
  0.120062    -0.217053   -0.848578    0.265789      0.72104     -0.279478    -0.091404    0.0852282   -0.514514    0.15467      0.168848     0.592013    0.349119    -0.465681     -0.617619     0.242624    0.206813   -0.77394      0.000736187  -0.326623     0.341092     0.3213        0.0866868   -0.325508    0.167591     0.36666
  0.733946     0.449892   -0.037167   -0.184923      0.280179    -0.124152    -0.332169    0.336762     0.55847    -0.113078     0.433514    -0.309965    0.257658     0.0936885     0.108263    -0.204121    0.0859693  -0.309969     0.0353863     0.109912     0.0805903   -0.591454     -0.730281    -0.130647    0.154981    -0.363174
 -0.0654937    0.171211   -0.139193    0.0375542     0.0480848   -0.0350099    0.0133805  -0.127638    -0.060403   -0.0398875   -0.0977434    0.0424624  -0.156861    -0.000411355   0.0872976   -0.165056    0.168147    0.026266    -0.0518899    -0.0454058    0.199072     0.0732641    -0.151254     0.0668542  -0.145992     0.00900528
 -0.311293     0.431053   -0.106045    0.000486489  -0.0503023   -1.07865     -0.72871    -0.226991    -0.23994    -0.433633    -0.111099     0.353238   -0.0844057   -0.156173     -0.420941     0.067918    0.0533361  -0.700779    -0.215152      0.107616    -0.215969     0.472998     -0.38255     -0.310493   -0.0206099   -0.0473139
 -0.268288     0.54753    -0.635365    0.0082171     0.137509    -0.413741    -0.727861    0.534716     0.235165    0.791071    -0.874423    -0.729366    0.344769    -0.0946303     0.0518601   -0.0681877   0.0806811   0.00528441   0.0588504     0.48638     -0.16617      0.530324     -0.153324     0.192443    0.328551     0.536819
  0.077869     0.057363    0.56199    -0.211174     -0.407355    -0.109564     0.0977443   0.00560354   0.343561   -0.0836673   -0.0943829   -0.217339    0.0688591    0.276521      0.523143     0.464237   -0.361041    0.210976    -0.148458     -0.278655     0.246442    -0.175103     -0.451416    -0.0661895   0.574586     0.07766
  0.0207447   -0.239447   -0.0465051   0.0120588    -0.314634     0.432381     0.217386   -0.903727     0.449882   -0.658829     0.299516     0.0921549  -0.0356139   -0.104014     -0.113209     0.657082    0.751157   -0.24968     -0.477315     -0.477826     0.299644    -0.719671     -0.666497    -0.355554   -0.191316    -0.216518
 -0.0724787   -0.322297   -0.210741   -0.145849      0.326012     0.63347      0.388794    0.00725544   0.0404533  -0.0460996    0.145003     0.0786884   0.968389    -0.208583     -0.0489807    0.24278     0.349416    0.439318    -0.152847     -0.957656    -0.276483    -0.405535      0.861711    -0.195316    0.147073    -0.289575
 -0.635721    -0.0139701   0.101197    0.223607     -0.143765    -0.200647     0.276791    0.317602    -0.35101     0.294173    -0.117976    -0.0782376  -1.0584      -0.529738     -0.0209225    0.417916   -0.531611   -0.207352    -0.289186      0.122028     0.175873     0.451429     -0.00524986   0.692374    0.0279782   -0.0498196
 -0.184145    -0.117609   -0.0807467  -0.282525      0.517688     0.493889    -0.777076   -0.0439512    0.152732    0.0584138   -0.16007     -0.316452   -0.240128     0.329143      0.0583608   -0.168092   -0.299231   -0.0353528    0.0716384     0.377759    -0.280373     0.357197     -0.0174504    0.275608   -0.90845      0.217385
 -0.877995     0.114896    0.918101   -0.169686     -0.46419      0.0842486    0.397318    0.0160511    0.366038   -0.190228     0.675253    -0.0140588  -0.503841    -0.0424989    -0.0174474   -0.127997   -0.156634    0.336057    -0.526783      0.322894     0.109016    -0.231656     -0.106882     0.299015   -0.227279    -0.492847
 -0.0563154    0.342988    0.0520949   0.0723567    -0.148574     0.904549     0.601414   -0.242738     0.14042    -0.469118    -0.707953    -0.128142   -0.0426673    0.238748     -0.641029    -0.505304   -0.142386    0.101409    -0.0269278     0.391262     0.339997     0.151723     -0.263051     0.50646     0.171962    -0.0234241
  0.39386     -0.256178    1.13654    -0.197312     -0.0907431    0.173336     1.10543    -0.313292     0.13928    -0.0680607    0.840919     0.190032   -0.328596     0.207341      0.263611     0.606539   -0.552698   -0.542452     0.0963773    -0.65787      0.109138    -0.572911      0.242708     0.159706   -0.128792    -0.0632935
  0.134256    -0.185539   -0.343421    0.080709     -0.171516     0.292219     0.303714    0.539212     0.32956    -0.140398     0.250961    -0.0838298  -0.103786    -0.119296     -0.655759    -0.127961    0.212226   -0.518729     0.67638       0.566013    -0.246008    -0.0418152     0.652254     0.103332   -0.210613     0.0256464
  0.733951    -0.104095   -0.714723    0.0488624     0.526172    -0.221976    -0.852933   -0.654907     0.214014    0.160359    -0.0734466    0.272485    0.795281     0.395467      0.522869    -0.388776    0.595898    0.271301    -0.106056     -0.533133    -0.275945    -0.230721     -0.494006    -0.406523    0.231917    -0.328195
 -0.287399    -0.257774    0.252695    0.469884      0.121249    -0.169594     0.125554    0.283198    -0.934612    0.767053     0.121092    -0.430954    0.526867     0.983682      0.302429    -0.104879   -0.290459    0.0112045    0.837857      0.317993     0.527928     0.276921      0.0815138    0.941174   -0.0220342   -0.564231[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417815
[ Info: iteration 2, average log likelihood -1.417808
[ Info: iteration 3, average log likelihood -1.417802
[ Info: iteration 4, average log likelihood -1.417796
[ Info: iteration 5, average log likelihood -1.417790
[ Info: iteration 6, average log likelihood -1.417784
[ Info: iteration 7, average log likelihood -1.417779
[ Info: iteration 8, average log likelihood -1.417774
[ Info: iteration 9, average log likelihood -1.417769
[ Info: iteration 10, average log likelihood -1.417764
┌ Info: EM with 100000 data points 10 iterations avll -1.417764
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
