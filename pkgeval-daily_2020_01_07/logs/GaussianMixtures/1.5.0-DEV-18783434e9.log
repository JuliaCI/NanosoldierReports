Julia Version 1.5.0-DEV.11
Commit 18783434e9 (2020-01-04 00:48 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Blosc ────────────── v0.5.1
 Installed CMake ────────────── v1.1.2
 Installed JLD ──────────────── v0.9.1
 Installed StatsFuns ────────── v0.9.3
 Installed BinDeps ──────────── v1.0.0
 Installed QuadGK ───────────── v2.3.1
 Installed Missings ─────────── v0.4.3
 Installed Parameters ───────── v0.12.0
 Installed DataAPI ──────────── v1.1.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed OrderedCollections ─ v1.1.0
 Installed Rmath ────────────── v0.6.0
 Installed HDF5 ─────────────── v0.12.5
 Installed SpecialFunctions ─── v0.9.0
 Installed URIParser ────────── v0.4.0
 Installed LegacyStrings ────── v0.4.1
 Installed NearestNeighbors ─── v0.4.4
 Installed ScikitLearnBase ──── v0.5.0
 Installed Compat ───────────── v2.2.0
 Installed SortingAlgorithms ── v0.3.1
 Installed Arpack ───────────── v0.4.0
 Installed StatsBase ────────── v0.32.0
 Installed FillArrays ───────── v0.8.2
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed DataStructures ───── v0.17.7
 Installed Clustering ───────── v0.13.3
 Installed BinaryProvider ───── v0.5.8
 Installed FileIO ───────────── v1.2.1
 Installed Distributions ────── v0.22.0
 Installed OpenBLAS_jll ─────── v0.3.7+3
 Installed PDMats ───────────── v0.9.10
 Installed Distances ────────── v0.8.2
 Installed StaticArrays ─────── v0.12.1
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.0
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+3
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_5ngmxI/Project.toml`
 [no changes]
  Updating `/tmp/jl_5ngmxI/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_UV1gMb/Project.toml`
 [no changes]
  Updating `/tmp/jl_UV1gMb/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_ZQab8S/Project.toml`
 [no changes]
  Updating `/tmp/jl_ZQab8S/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_cxnk4R/Project.toml`
 [no changes]
  Updating `/tmp/jl_cxnk4R/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_FNmxSl/Project.toml`
 [no changes]
  Updating `/tmp/jl_FNmxSl/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_FNmxSl/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.0
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -6.605300787016587e6, [91268.42747100643, 8731.572528993569], [14502.166989706602 1449.5191413146079 7049.546206382723; -14071.855156756947 -1004.5267606962287 -7253.259366617809], [[74857.1026831497 -1082.0118123893471 -9098.888675731456; -1082.0118123893471 91492.52957138371 -988.9524327965902; -9098.888675731454 -988.9524327965903 86197.99617917619], [25675.635650984077 1321.8979261422414 8649.66198347055; 1321.8979261422414 8868.829837875213 685.4833184149292; 8649.66198347055 685.4833184149292 13467.368524048201]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.016882e+03
      1       8.837163e+02      -1.331659e+02 |        5
      2       8.617433e+02      -2.197302e+01 |        0
      3       8.617433e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 861.743271905545)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.081872
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.889849
[ Info: iteration 2, lowerbound -3.750090
[ Info: iteration 3, lowerbound -3.582803
[ Info: iteration 4, lowerbound -3.376308
[ Info: iteration 5, lowerbound -3.160029
[ Info: iteration 6, lowerbound -2.970950
[ Info: iteration 7, lowerbound -2.837014
[ Info: dropping number of Gaussions to 7
[ Info: iteration 8, lowerbound -2.764229
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.720989
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.668423
[ Info: iteration 11, lowerbound -2.618067
[ Info: iteration 12, lowerbound -2.570902
[ Info: iteration 13, lowerbound -2.522804
[ Info: iteration 14, lowerbound -2.476967
[ Info: iteration 15, lowerbound -2.435478
[ Info: iteration 16, lowerbound -2.398704
[ Info: iteration 17, lowerbound -2.365905
[ Info: iteration 18, lowerbound -2.337280
[ Info: iteration 19, lowerbound -2.316154
[ Info: iteration 20, lowerbound -2.307493
[ Info: dropping number of Gaussions to 2
[ Info: iteration 21, lowerbound -2.302969
[ Info: iteration 22, lowerbound -2.299261
[ Info: iteration 23, lowerbound -2.299257
[ Info: iteration 24, lowerbound -2.299255
[ Info: iteration 25, lowerbound -2.299254
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Jan  7 15:19:37 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Jan  7 15:19:45 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Tue Jan  7 15:19:48 2020: EM with 272 data points 0 iterations avll -2.081872
5.8 data points per parameter
, Tue Jan  7 15:19:51 2020: GMM converted to Variational GMM
, Tue Jan  7 15:20:02 2020: iteration 1, lowerbound -3.889849
, Tue Jan  7 15:20:02 2020: iteration 2, lowerbound -3.750090
, Tue Jan  7 15:20:02 2020: iteration 3, lowerbound -3.582803
, Tue Jan  7 15:20:02 2020: iteration 4, lowerbound -3.376308
, Tue Jan  7 15:20:02 2020: iteration 5, lowerbound -3.160029
, Tue Jan  7 15:20:02 2020: iteration 6, lowerbound -2.970950
, Tue Jan  7 15:20:02 2020: iteration 7, lowerbound -2.837014
, Tue Jan  7 15:20:03 2020: dropping number of Gaussions to 7
, Tue Jan  7 15:20:03 2020: iteration 8, lowerbound -2.764229
, Tue Jan  7 15:20:03 2020: dropping number of Gaussions to 5
, Tue Jan  7 15:20:03 2020: iteration 9, lowerbound -2.720989
, Tue Jan  7 15:20:03 2020: dropping number of Gaussions to 3
, Tue Jan  7 15:20:03 2020: iteration 10, lowerbound -2.668423
, Tue Jan  7 15:20:03 2020: iteration 11, lowerbound -2.618067
, Tue Jan  7 15:20:03 2020: iteration 12, lowerbound -2.570902
, Tue Jan  7 15:20:03 2020: iteration 13, lowerbound -2.522804
, Tue Jan  7 15:20:03 2020: iteration 14, lowerbound -2.476967
, Tue Jan  7 15:20:03 2020: iteration 15, lowerbound -2.435478
, Tue Jan  7 15:20:03 2020: iteration 16, lowerbound -2.398704
, Tue Jan  7 15:20:03 2020: iteration 17, lowerbound -2.365905
, Tue Jan  7 15:20:03 2020: iteration 18, lowerbound -2.337280
, Tue Jan  7 15:20:03 2020: iteration 19, lowerbound -2.316154
, Tue Jan  7 15:20:03 2020: iteration 20, lowerbound -2.307493
, Tue Jan  7 15:20:03 2020: dropping number of Gaussions to 2
, Tue Jan  7 15:20:03 2020: iteration 21, lowerbound -2.302969
, Tue Jan  7 15:20:03 2020: iteration 22, lowerbound -2.299261
, Tue Jan  7 15:20:03 2020: iteration 23, lowerbound -2.299257
, Tue Jan  7 15:20:03 2020: iteration 24, lowerbound -2.299255
, Tue Jan  7 15:20:03 2020: iteration 25, lowerbound -2.299254
, Tue Jan  7 15:20:03 2020: iteration 26, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 27, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 28, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 29, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 30, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 31, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 32, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 33, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 34, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 35, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 36, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 37, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 38, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 39, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 40, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 41, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 42, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 43, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 44, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 45, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 46, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 47, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 48, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 49, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: iteration 50, lowerbound -2.299253
, Tue Jan  7 15:20:03 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601502, 95.95490777398501]
β = [178.04509222601502, 95.95490777398501]
m = [4.2503007332699 79.28686694436169; 2.0002292577753606 53.851987172461236]
ν = [180.04509222601502, 97.95490777398501]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484596 -0.007644049042327554; 0.0 0.008581705166333246], [0.3758763611948586 -0.008953123827346487; 0.0 0.012748664777409383]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000007
avll from stats: -0.9807846571192842
avll from llpg:  -0.9807846571192733
avll direct:     -0.9807846571192733
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9993759865426113
avll from llpg:  -0.9993759865426111
avll direct:     -0.9993759865426111
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0420066   -0.0674649   -0.231105     -0.0622238   -0.179934    -0.0921435   -0.00291119  -0.0630515    -0.286852     0.0116692    -0.0532567   -0.137818     0.0735317   -0.131911     -0.0554558  -0.0109877    0.0304427   -0.102549     -0.0287578    0.00929697   0.0105729   -0.0775494    0.0537993   -0.111885     0.0637794   -0.0510096
 -0.0114045    0.0364477    0.133553      0.0390411   -0.0249248   -0.00683639   0.0734368    0.208468     -0.0872004   -0.00599697    0.128206    -0.0569187   -0.0709992    0.0264469     0.147254   -0.0181168    0.0851253    0.0580493    -0.0423654   -0.134978     0.0839221   -0.0870671    0.0408186    0.0137342   -0.0724172    0.0261696
  0.0141546    0.121228     0.214293      0.0884631    0.116148     0.00207285  -0.00233476  -0.00848711    0.0430286   -0.230331      0.0999364   -0.17271     -0.0171172   -0.110451      0.0376005   0.239589    -0.0406721    0.109544     -0.119722    -0.040771    -0.020938    -0.122577    -0.0112765    0.0326739    0.165773    -0.125186
 -0.0532551   -0.0138663    0.115506      0.0268829    0.0435138    0.204229     0.0335565    0.0753902    -0.0896083    0.153964      0.136608    -0.0216132   -0.0235509    0.116354     -0.0522402  -0.101035     0.0134827   -0.000985212  -0.00424244   0.0571847    0.143465    -0.0188642    0.134685     0.129532    -0.00210709  -0.0462521
  0.0448434    0.158324    -0.12879       0.137168     0.124499    -0.00248394   0.0273407   -0.178085     -0.0666255   -0.134776      0.0157413   -0.137353     0.0563112   -0.0809823    -0.108057   -0.0372862   -0.133699     0.0495349     0.10571      0.0884234    0.119359     0.00310858   0.0802585   -0.121191    -0.0143959   -0.0681324
  0.0188507   -0.0530337    0.00704091    0.110961     0.0627978   -0.0832673    0.0779163   -0.0168033    -0.00362077  -0.0208668     0.0142423   -0.190089    -0.0353695    0.0113984    -0.0626481  -0.103982    -0.00351584   0.162265      0.0352706   -0.0392945   -0.0158565    0.0567035   -0.00339321  -0.195341     0.0574427   -0.0253734
 -0.025039    -0.151292    -0.000954024   0.0232727    0.0929501    0.00566473  -0.108999    -0.126602     -0.0341282   -0.122914      0.00698119  -0.0235878    0.0740277    0.075402      0.065352   -0.0111367    0.0612916    0.0930013    -0.139114     0.0804418   -0.228701    -0.125219     0.0364681   -0.0276706   -0.0159563   -0.00433855
 -0.0751729    0.00214213   0.131894      0.077508     0.0383966    0.0821592   -0.0313147   -0.0480738    -0.0104098    0.141372      0.101761     0.129034    -0.0320875   -0.0340619     0.0113562   0.0122867   -0.0213845    0.180789      0.0135033    0.0780868    0.1323       0.0493933    0.0011208   -0.056823    -0.128616    -0.0141796
 -0.045388    -0.116602     0.03607       0.164447    -0.187914     0.0593928   -0.235133    -0.171003      0.124857    -0.135128     -0.0341283    0.0677941   -0.05799      0.102428     -0.0245787   0.186033     0.0340519    0.00937935    0.0533862   -0.188605     0.0310896   -0.00753505  -0.144279    -0.144446     0.0792286   -0.0207133
  0.121744     0.100646     0.139593      0.109667    -0.0546174   -0.20226     -0.00898563   0.0147411    -0.0405719   -0.08315       0.00256382  -0.0066716    0.0076803    0.151876     -0.0242599  -0.178623    -0.0580813    0.0488792    -0.0121004   -0.11175      0.0755215   -0.0888837    0.0968187   -0.00516087   0.0106884    0.0276897
 -0.0439593    0.00803412  -0.201347      0.0176078   -0.044405     0.165572    -0.0253544   -0.0811998    -0.072933     0.061906     -0.0772353    0.214178    -0.0101581    0.0149708    -0.0157002   0.168967     0.0481539    0.303951     -0.101791     0.167781     0.1518      -0.155992     0.0474562   -0.0105192    0.0168329   -0.0354183
  0.0383259    0.0765795   -0.0757337    -0.090655    -0.166116     0.00369721  -0.0441335    0.177963     -0.00115372   0.147711     -0.0455588   -0.0648756   -0.0233102    0.0739613    -0.15005     0.0547769   -0.0101638   -0.0620979     0.0897622    0.147281    -0.163417     0.0568847    0.0674324   -0.0207932    0.0235776    0.203889
 -0.0562708    0.00910756  -0.0783981     0.0859822   -0.161899    -0.154756    -0.0621902   -0.0640782     0.143987     0.0599119    -0.195396     0.106683     0.102606    -0.257455     -0.0781757  -0.00553103  -0.00276183  -0.0156033     0.0464923    0.0969738   -0.197423    -0.0220281    0.0162953    0.0433427    0.13621      0.0307193
  0.0857292    0.0991299    0.0209996    -0.00664903  -0.15132      0.0493897    0.119439    -0.000675496   0.160228    -0.0631304     0.139936    -0.0565382    0.0479865    0.000878753  -0.0803518  -0.0195683    0.0231529   -0.060894     -0.0611704    0.00719061   0.0952537    0.0445662    0.0342744    0.012248    -0.159946     0.0367136
 -0.152743    -0.0673052    0.0641998     0.0951584    0.217198    -0.0134207   -0.0978506    0.00659341   -0.0293886   -0.027516      0.0879058   -0.197975    -0.131209    -0.120431     -0.0353195  -0.100337    -0.220071     0.184524     -0.0638713   -0.0468268    0.15148      0.124049    -0.124998    -0.0351533    0.0770372    0.0291801
 -0.0367099   -0.0252291    0.00613063   -0.0670938   -0.0981452    0.0826835   -0.0980856    0.0626308    -0.0231995   -0.138714     -0.00440424   0.0149614   -0.0397962    0.106163     -0.107559    0.0205393    0.090125    -0.0731085    -0.211472     0.0542924    0.00380664  -0.146011    -0.0635897    0.0427575    0.0153209   -0.142007
 -4.28189e-5  -0.0233565    0.0384422     0.0887566    0.131977     0.201081    -0.0245545    0.333986      0.0649075    0.0738008     0.0286441    0.0592129   -0.152702    -0.0961989     0.0497811  -0.139738    -0.0817375   -0.154186     -0.151404     0.0321798   -0.0957319    0.0889102    0.0901296   -0.0953883    0.021171    -0.0959757
 -0.0577018   -0.00292304   0.0362645     0.0275109    0.0627165   -0.0195938    0.156491    -0.055916     -0.0152114   -0.0696266    -0.0195852   -0.0630617    0.180996    -0.102399      0.0185765   0.147723    -0.0324484    0.013872     -0.0427646    0.0020948    0.225097    -0.0124523   -0.197203    -0.100418     0.0493912    0.156267
 -0.0761931   -0.0451809   -0.0391236     0.221664     0.00124461  -0.0816279    0.0224131   -0.0517507     0.137703    -0.0338145     0.0897347    0.0447366    0.153071     0.115102      0.115865   -0.0149974    0.144496     0.00235815   -0.238194    -0.0763908   -0.130262     0.0677767    0.116193     0.0267707   -0.00698157  -0.0709218
  0.00956359  -0.186997     0.0269787    -0.0346638    0.170882     0.0639961    0.0939871    0.154084      0.070183     0.152455     -0.0613135   -0.102166     0.0363987    0.158164     -0.170505   -0.0636086   -0.145707    -0.0531712    -0.0935564    0.0473596    0.0822899   -0.0248319    0.0518855   -0.073579    -0.0934733    0.00608452
 -0.119926    -0.0953576   -0.0732126    -0.0229741   -0.261506    -0.105619    -0.0387943   -0.0432649    -0.251316    -0.025587     -0.0570816   -0.0898164    0.00630397   0.017732     -0.0814774   0.0613837   -0.0889532   -0.123749     -0.193063    -0.0218527   -0.109147     0.0483614    0.140929     0.0499542    0.180501     0.151585
  0.00132154  -0.0199811    0.0947571     0.00739789   0.0772703   -0.0966235   -0.0104414    0.0169781    -0.0691619    0.0158921    -0.0534789    0.101591     0.0146789   -0.0246108    -0.102113    0.0266078    0.085785     0.0243388    -0.0465159    0.0496368    0.0232659   -0.0190868    0.0747106    0.0498936    0.102058     0.277892
 -0.105396    -0.195642    -0.0752084    -0.100899     0.0358342    0.132749    -0.0120059   -0.0780908    -0.0721567   -0.0024085     0.0547662    0.196975     0.0889219    0.085293      0.0132307   0.084403     0.00949114   0.0555963    -0.0455861    0.120172     0.0620554    0.00977258   0.0321437   -0.00556447  -0.137442    -0.113212
  0.095148    -0.0707834   -0.0407966     0.0984644   -0.155441    -0.027822    -0.0382868    0.0594683     0.0243642    0.0291008     0.133311     0.0240056    0.167198    -0.0656097    -0.0497485  -0.0434799    0.0289858   -0.00110347   -0.14114      0.0216366   -0.0243215    0.0264086   -0.0259445   -0.065998    -0.0488042    0.120981
  0.172347     0.102161     0.0473859     0.147622     0.110831     0.00838614  -0.0351916    0.0617024    -0.0415756   -0.233389     -0.159171     0.0749499   -0.0111054   -0.0355273    -0.193555   -0.213257    -0.0640522    0.0557659    -0.145021    -0.0565811    0.0138249    0.0924842    0.0632976    0.0993735   -0.139769    -0.108373
  0.0293275    0.0604914    0.0230433     0.0238821   -0.0016801   -0.0145787    0.0768701   -0.156377      0.0685603   -0.0242861     0.0903724    0.060725     0.11006      0.294311     -0.0238083  -0.0172656   -0.0378913   -0.0749165    -0.040202    -0.0622092   -0.0729151   -0.0268039   -0.119065     0.0334366   -0.0353894    0.0244681
  0.0499302    0.0803303   -0.0738811     0.0472556   -0.0658553    0.0743807    0.0388131    0.116631     -0.102019    -0.15863      -0.016748    -0.181867    -0.0524369   -0.0484236    -0.131946   -0.0597614   -0.0300726   -0.00886851    0.105193     0.117058    -0.0362957   -0.0205294    0.0861872    0.220137     0.0879263    0.079058
  0.0302109   -0.0470888    0.116723     -0.0872764   -0.00842414   0.0204827   -0.043052    -0.122908     -0.0679585   -0.042692     -0.125858    -0.0285448    0.00799986   0.0905147     0.114371    0.192479     0.143125     0.097867     -0.0844414   -0.168234    -0.139888    -0.0621845    0.152766     0.0388165   -0.0155764    0.0837487
  0.0842932    0.0916388   -0.134593      0.0853686   -0.0580208   -0.00249022  -0.0471765    0.112415      0.109852    -0.000909734  -0.053381     0.00629665  -0.050737    -0.0835708     0.0385644   0.0304166    0.0151795    0.0486133    -0.0407376   -0.0454993    0.0654799   -0.015478     0.0423057   -0.155032    -0.0143508    0.0787468
 -0.0171471    0.0520425   -0.0412318     0.0615037    0.0779928    0.113214     0.182261     0.107764     -0.163983     0.0544948     0.0480493    0.114399    -0.0105494    0.101193     -0.0779784   0.0833632    0.294098    -0.0649828     0.0877993    0.0382671   -0.0801812   -0.00223001   0.0775461   -0.141009     0.0632753    0.202455
 -0.115733    -0.0465307    0.144146      0.110894    -0.0433622   -0.256679    -0.0729363   -0.14226       0.0843986   -0.0335795     0.162738     0.02811      0.0237843    0.0232436     0.122067    0.0757108   -0.0886248    0.283342     -0.174289    -0.141532     0.0183355    0.0702388   -0.0721343    0.156346     0.0742917    0.0923751
  0.108985    -0.101623     0.0955545     0.0303658   -0.00637643  -0.0319326    0.11559      0.22987      -0.0707587    0.227132     -0.0825509    0.0342681   -0.0663569    0.246718      0.0888018  -0.181814     0.0810669   -0.172915      0.21718     -0.119489     0.057336     0.0241706   -0.10542     -0.166534     0.119959     0.0185537kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3079228509782381
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.308032
[ Info: iteration 2, average log likelihood -1.307937
[ Info: iteration 3, average log likelihood -1.307348
[ Info: iteration 4, average log likelihood -1.300019
[ Info: iteration 5, average log likelihood -1.280624
[ Info: iteration 6, average log likelihood -1.273356
[ Info: iteration 7, average log likelihood -1.271441
[ Info: iteration 8, average log likelihood -1.270274
[ Info: iteration 9, average log likelihood -1.269536
[ Info: iteration 10, average log likelihood -1.269006
[ Info: iteration 11, average log likelihood -1.268474
[ Info: iteration 12, average log likelihood -1.267786
[ Info: iteration 13, average log likelihood -1.266982
[ Info: iteration 14, average log likelihood -1.266192
[ Info: iteration 15, average log likelihood -1.265523
[ Info: iteration 16, average log likelihood -1.264998
[ Info: iteration 17, average log likelihood -1.264643
[ Info: iteration 18, average log likelihood -1.264432
[ Info: iteration 19, average log likelihood -1.264315
[ Info: iteration 20, average log likelihood -1.264255
[ Info: iteration 21, average log likelihood -1.264225
[ Info: iteration 22, average log likelihood -1.264209
[ Info: iteration 23, average log likelihood -1.264201
[ Info: iteration 24, average log likelihood -1.264197
[ Info: iteration 25, average log likelihood -1.264194
[ Info: iteration 26, average log likelihood -1.264193
[ Info: iteration 27, average log likelihood -1.264192
[ Info: iteration 28, average log likelihood -1.264191
[ Info: iteration 29, average log likelihood -1.264191
[ Info: iteration 30, average log likelihood -1.264191
[ Info: iteration 31, average log likelihood -1.264190
[ Info: iteration 32, average log likelihood -1.264190
[ Info: iteration 33, average log likelihood -1.264190
[ Info: iteration 34, average log likelihood -1.264190
[ Info: iteration 35, average log likelihood -1.264190
[ Info: iteration 36, average log likelihood -1.264190
[ Info: iteration 37, average log likelihood -1.264190
[ Info: iteration 38, average log likelihood -1.264190
[ Info: iteration 39, average log likelihood -1.264190
[ Info: iteration 40, average log likelihood -1.264190
[ Info: iteration 41, average log likelihood -1.264190
[ Info: iteration 42, average log likelihood -1.264190
[ Info: iteration 43, average log likelihood -1.264190
[ Info: iteration 44, average log likelihood -1.264190
[ Info: iteration 45, average log likelihood -1.264190
[ Info: iteration 46, average log likelihood -1.264190
[ Info: iteration 47, average log likelihood -1.264190
[ Info: iteration 48, average log likelihood -1.264190
[ Info: iteration 49, average log likelihood -1.264190
[ Info: iteration 50, average log likelihood -1.264190
┌ Info: EM with 100000 data points 50 iterations avll -1.264190
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3080321954767897
│     -1.307937087405711
│      ⋮
└     -1.2641897270986775
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.264337
[ Info: iteration 2, average log likelihood -1.264189
[ Info: iteration 3, average log likelihood -1.263195
[ Info: iteration 4, average log likelihood -1.255168
[ Info: iteration 5, average log likelihood -1.237601
[ Info: iteration 6, average log likelihood -1.227385
[ Info: iteration 7, average log likelihood -1.223966
[ Info: iteration 8, average log likelihood -1.221808
[ Info: iteration 9, average log likelihood -1.220161
[ Info: iteration 10, average log likelihood -1.218877
[ Info: iteration 11, average log likelihood -1.217800
[ Info: iteration 12, average log likelihood -1.216908
[ Info: iteration 13, average log likelihood -1.216261
[ Info: iteration 14, average log likelihood -1.215795
[ Info: iteration 15, average log likelihood -1.215440
[ Info: iteration 16, average log likelihood -1.215146
[ Info: iteration 17, average log likelihood -1.214868
[ Info: iteration 18, average log likelihood -1.214583
[ Info: iteration 19, average log likelihood -1.214289
[ Info: iteration 20, average log likelihood -1.214002
[ Info: iteration 21, average log likelihood -1.213747
[ Info: iteration 22, average log likelihood -1.213526
[ Info: iteration 23, average log likelihood -1.213330
[ Info: iteration 24, average log likelihood -1.213151
[ Info: iteration 25, average log likelihood -1.212973
[ Info: iteration 26, average log likelihood -1.212790
[ Info: iteration 27, average log likelihood -1.212609
[ Info: iteration 28, average log likelihood -1.212455
[ Info: iteration 29, average log likelihood -1.212325
[ Info: iteration 30, average log likelihood -1.212217
[ Info: iteration 31, average log likelihood -1.212125
[ Info: iteration 32, average log likelihood -1.212048
[ Info: iteration 33, average log likelihood -1.211984
[ Info: iteration 34, average log likelihood -1.211930
[ Info: iteration 35, average log likelihood -1.211887
[ Info: iteration 36, average log likelihood -1.211853
[ Info: iteration 37, average log likelihood -1.211828
[ Info: iteration 38, average log likelihood -1.211809
[ Info: iteration 39, average log likelihood -1.211795
[ Info: iteration 40, average log likelihood -1.211786
[ Info: iteration 41, average log likelihood -1.211779
[ Info: iteration 42, average log likelihood -1.211775
[ Info: iteration 43, average log likelihood -1.211771
[ Info: iteration 44, average log likelihood -1.211769
[ Info: iteration 45, average log likelihood -1.211768
[ Info: iteration 46, average log likelihood -1.211767
[ Info: iteration 47, average log likelihood -1.211766
[ Info: iteration 48, average log likelihood -1.211766
[ Info: iteration 49, average log likelihood -1.211766
[ Info: iteration 50, average log likelihood -1.211765
┌ Info: EM with 100000 data points 50 iterations avll -1.211765
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2643374386761208
│     -1.2641892692957926
│      ⋮
└     -1.2117653573288512
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.211954
[ Info: iteration 2, average log likelihood -1.211752
[ Info: iteration 3, average log likelihood -1.210719
[ Info: iteration 4, average log likelihood -1.203829
[ Info: iteration 5, average log likelihood -1.187814
[ Info: iteration 6, average log likelihood -1.175072
[ Info: iteration 7, average log likelihood -1.169726
[ Info: iteration 8, average log likelihood -1.166971
[ Info: iteration 9, average log likelihood -1.165079
[ Info: iteration 10, average log likelihood -1.163392
[ Info: iteration 11, average log likelihood -1.161807
[ Info: iteration 12, average log likelihood -1.160490
[ Info: iteration 13, average log likelihood -1.159420
[ Info: iteration 14, average log likelihood -1.158462
[ Info: iteration 15, average log likelihood -1.157568
[ Info: iteration 16, average log likelihood -1.156786
[ Info: iteration 17, average log likelihood -1.156077
[ Info: iteration 18, average log likelihood -1.155384
[ Info: iteration 19, average log likelihood -1.154738
[ Info: iteration 20, average log likelihood -1.154231
[ Info: iteration 21, average log likelihood -1.153892
[ Info: iteration 22, average log likelihood -1.153673
[ Info: iteration 23, average log likelihood -1.153509
[ Info: iteration 24, average log likelihood -1.153352
[ Info: iteration 25, average log likelihood -1.153193
[ Info: iteration 26, average log likelihood -1.153031
[ Info: iteration 27, average log likelihood -1.152870
[ Info: iteration 28, average log likelihood -1.152706
[ Info: iteration 29, average log likelihood -1.152511
[ Info: iteration 30, average log likelihood -1.152215
[ Info: iteration 31, average log likelihood -1.151704
[ Info: iteration 32, average log likelihood -1.151019
[ Info: iteration 33, average log likelihood -1.150406
[ Info: iteration 34, average log likelihood -1.150034
[ Info: iteration 35, average log likelihood -1.149750
[ Info: iteration 36, average log likelihood -1.149449
[ Info: iteration 37, average log likelihood -1.149090
[ Info: iteration 38, average log likelihood -1.148587
[ Info: iteration 39, average log likelihood -1.147850
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.146938
[ Info: iteration 41, average log likelihood -1.160125
[ Info: iteration 42, average log likelihood -1.153123
[ Info: iteration 43, average log likelihood -1.151699
[ Info: iteration 44, average log likelihood -1.151119
[ Info: iteration 45, average log likelihood -1.150623
[ Info: iteration 46, average log likelihood -1.149997
[ Info: iteration 47, average log likelihood -1.149330
[ Info: iteration 48, average log likelihood -1.148926
[ Info: iteration 49, average log likelihood -1.148755
[ Info: iteration 50, average log likelihood -1.148598
┌ Info: EM with 100000 data points 50 iterations avll -1.148598
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2119542982351155
│     -1.2117517076485431
│      ⋮
└     -1.1485976980731265
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.148581
[ Info: iteration 2, average log likelihood -1.147881
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.145754
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.131957
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.100891
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.077115
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.095049
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.080408
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.067397
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.081104
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.078499
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.059503
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.055967
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.071644
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│      9
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.054527
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.068793
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.075128
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.058760
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.055801
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.072171
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.063935
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.056908
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.071973
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.056933
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.053497
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.072799
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      9
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.057217
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.064530
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.063903
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.064807
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      5
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.058601
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.069164
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.065963
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.058423
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.062595
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.062922
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.061993
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      9
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.060432
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.071092
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.059538
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.063415
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.069669
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.065480
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.065407
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.054543
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.064163
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.064739
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.059247
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.062566
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.059140
┌ Info: EM with 100000 data points 50 iterations avll -1.059140
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1485805554885633
│     -1.1478807692672741
│      ⋮
└     -1.0591402596786779
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│     17
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.062009
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.051786
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│     17
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.054508
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.037547
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│     11
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.016285
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.986850
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.985288
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.969543
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│     11
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.996755
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.987907
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│     11
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -0.985473
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -0.975895
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -0.990954
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -0.983115
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -0.974275
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -0.985506
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -0.990874
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -0.974703
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      9
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.001249
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -0.980556
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│     11
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -0.977455
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -0.970936
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -0.977983
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -0.986058
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      9
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.005369
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.985929
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -0.970973
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -0.971341
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.004135
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -0.970522
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      9
│     11
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.005415
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -0.979981
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -0.965390
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -0.985564
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.001829
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -0.969959
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -0.973488
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -0.972565
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│     11
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.999237
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -0.980878
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│     11
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -0.996943
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -0.980432
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -0.976745
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -0.991200
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│     10
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -0.970472
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -0.984861
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      9
│     11
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.005918
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -0.967022
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│     11
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -0.987759
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -0.985336
┌ Info: EM with 100000 data points 50 iterations avll -0.985336
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.0620085718759507
│     -1.0517861577335692
│      ⋮
└     -0.9853359996833292
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3079228509782381
│     -1.3080321954767897
│     -1.307937087405711
│     -1.3073480166585214
│      ⋮
│     -0.9670223791665777
│     -0.9877585472885719
└     -0.9853359996833292
32×26 Array{Float64,2}:
 -0.0412528     0.0806905   -0.118888    -0.0301725   -0.428963     0.166418   -0.0239005    -0.0745121    -0.104241     0.0672665  -0.0528598     0.213363    0.0330818    0.0089379   -0.0457254   0.171127     0.0295512   -0.108866    -0.148654     0.156252     0.081589    -0.123406     0.0365141  -0.0176599    0.0627857  -0.204908
 -0.0368367    -0.0662876   -0.36282      0.0868221    0.401151     0.165923   -0.0251066    -0.12107      -0.0608022    0.0500987  -0.0705425     0.213675   -0.0373168    0.0279461    0.0189199   0.170536     0.0662751    0.644365    -0.132998     0.174195     0.202298    -0.175486     0.0591394  -0.00541285  -0.0139953   0.0661538
  0.00488413   -0.031327    -0.00763029   0.0624456    0.148244     0.208528    0.0974114     0.333991      0.0654734    0.0701955   0.0268195     0.0676284  -0.15183     -0.0894913    0.04073    -0.134623    -0.0821116   -0.138498    -0.141782     0.0194924   -0.0689716   -0.0816031    0.084427   -0.0636673   -0.043839   -0.107739
 -0.00128355   -0.0232844    0.114219     0.127851     0.102936     0.19684    -0.153188      0.334187      0.0731688    0.0750372   0.0288821     0.0421506  -0.15225     -0.111044     0.062807   -0.146445    -0.0827273   -0.139975    -0.139162     0.073742    -0.109759     0.312292     0.0860316  -0.0928844    0.0717081  -0.0849
  0.0500961    -0.180404     0.0366568   -0.0108721    0.162363     0.0578289   0.0647374     0.168541      0.0660055    0.153184   -0.0590037    -0.0983649   0.0399543    0.146248    -0.153741   -0.0451016   -0.146956    -0.0512158   -0.0898995    0.0473627    0.0833107   -0.0254739    0.0458433  -0.0717214   -0.0815129   0.0187187
  0.0875276     0.0153631   -0.0310468    0.0308446   -0.0361597   -0.0227105   0.0290492     0.169993      0.0176393    0.103226   -0.0698142     0.0177696  -0.0408839    0.0676189    0.072938   -0.0745192    0.0570512   -0.0630639    0.0751064   -0.0744432    0.0769961   -0.00356851  -0.0256024  -0.151999     0.0604004   0.0464153
  0.165909      0.0999674    0.056565     0.148794     0.12769      0.0249331  -0.0322142     0.0579154    -0.0522596   -0.22626    -0.149329      0.0492912  -0.0132986   -0.0343046   -0.177994   -0.206751    -0.041866     0.0300556   -0.137874    -0.0768734    0.00399298   0.0955692    0.0562617   0.0916941   -0.132747   -0.106689
  0.0882983    -0.0771461   -0.0381743    0.098486    -0.160659    -0.0263969  -0.0208668     0.0584451     0.0438161    0.0311007   0.132217      0.0207568   0.170526    -0.0646284    0.0285576  -0.0350582    0.0278374   -0.0205951   -0.14897      0.0199383   -0.00419803   0.0136469   -0.0277027  -0.0510206   -0.0424847   0.122373
 -0.0944184     0.0927995   -0.257276    -0.00266789  -0.0379016    0.0782744   0.0311282     0.109376     -0.104665    -0.467752    0.0359155    -0.339978    0.0689682   -0.0295315   -0.153414   -0.535857    -0.0618876    0.0164647    0.141521    -0.0756696   -0.0940597   -0.0302974    0.0411626   0.126598     0.175278    0.056665
  0.147902      0.0714796   -0.0457023    0.0661924   -0.0659753    0.0662577   0.0651511     0.0617969    -0.0882641   -0.056592   -0.0316124    -0.131501   -0.130835    -0.0431825   -0.139268    0.222267    -0.0550691   -0.0109641    0.0535653    0.159454    -0.0298799   -0.0121075    0.109698    0.245199    -0.0304144   0.0289379
 -0.11853      -0.0451933   -0.07457     -0.0239496   -0.225765    -0.106496   -0.00699958   -0.0643308    -0.235364    -0.0122914   0.0753819    -0.0978709   0.0413061    0.0234023   -0.0835723   0.0658432   -0.0880679   -0.115504    -0.210587     0.0347828   -0.116957     0.0481833    0.0959974   0.0563528   -0.283537    0.12257
 -0.119098     -0.125494    -0.0746551   -0.0154092   -0.266035    -0.108773   -0.0922491     0.0409577    -0.266296    -0.0605155  -0.180239     -0.0701902  -0.0145823    0.0207257   -0.0682157   0.0401728   -0.0865984   -0.117888    -0.185163    -0.0998083   -0.112496     0.0479263    0.15283     0.0438947    0.693035    0.185129
 -0.0150787     0.0360392   -0.0667394   -0.0101395   -0.0185979    0.0266865  -0.00233141   -0.00197473   -0.122797     0.0368121   0.0192482    -0.0871837   0.0378569   -0.0150602   -0.0842933  -0.0303482   -0.0215421   -0.0292916    0.00824237   0.0635729    0.0486913   -0.0237605    0.078328   -0.030615     0.0151626  -0.00881352
  0.0328626    -0.00299417   0.0938609    0.0690112    0.0252502   -0.0674793   0.000463186  -0.0494144    -0.0277899   -0.126665    0.00686531   -0.0681942   0.0505012    0.0576866   -0.0173578   0.00744269  -0.0129349    0.0644384   -0.0732497   -0.00737818  -0.0325568   -0.0843283    0.0302411  -0.0431236    0.0270769   0.0110381
 -0.00173406    0.0314523    0.114674     0.0444908   -0.0306268    0.0636118   0.0634007     0.173983     -0.0886021   -0.0270469   0.121728     -0.0753428  -0.0755118    0.0274259    0.122173   -0.0215338    0.0903636    0.0514051   -0.0340203   -0.104552     0.0907876   -0.0938005    0.0371545   0.0115154   -0.0624392   0.0496739
 -0.017805      0.0453403   -0.0378411    0.0936963    0.0827629    0.106532    0.165211      0.147581     -0.162878     0.0639291   0.0532394     0.11503    -0.0259636    0.115452    -0.0771427   0.093794     0.306246    -0.0671526    0.0828116    0.0390016   -0.117403    -0.00184231   0.0924355  -0.140054     0.054095    0.224209
 -0.136822     -0.0706937    0.0635731   -0.144391     0.196795    -0.0142161  -0.0978967    -0.728667     -0.0296293   -0.515929   -0.0291435    -0.204472   -0.128522     0.253294    -0.0420603  -0.0725452   -0.409397     0.757084    -0.114121    -0.0523812    0.15255      0.0917956   -0.100723   -0.0366051    0.0805391  -0.0323137
 -0.166582     -0.0690718    0.0633178    0.322234     0.231414     0.0941421  -0.0845503     0.77735      -0.0293245    0.364337    0.193917     -0.18954    -0.129515    -0.452489    -0.0289725  -0.126559    -0.100043    -0.316638    -0.0105298   -0.062437     0.159441     0.140504    -0.196976   -0.0329162    0.073352    0.134457
  0.0517677     0.0500077    0.0249105    0.00653585  -0.01521      0.0531876   0.0818157    -0.232737      0.0864803   -0.0125859   0.0847028     0.0441479   0.093011     0.366785    -0.0519837  -0.0297709   -0.0423093   -0.00553245  -0.0398903   -0.0066296   -0.108765    -0.113796    -0.599882    0.114789     0.133193    0.0426532
  0.000698989   0.0729898    0.0233105    0.0585072    0.00010164  -0.094118    0.072994     -0.119867      0.0574728   -0.0353478   0.0686179     0.052079    0.143031     0.256945     0.0107943   0.00342053  -0.037311    -0.171224    -0.0357598   -0.103042    -0.080346    -0.00892279   0.324951   -0.0179436   -0.20955     0.0002426
 -0.0717253    -0.00474319   0.125973     0.0846016    0.0330292    0.0808789  -0.0799933    -0.0820784    -0.0155171    0.107041    0.102948      0.104948   -0.0388004   -0.022996     0.0304593   0.00630053  -0.0534155    0.181531     0.0245245    0.0737094    0.143042     0.0578428    0.00695    -0.0837757   -0.115637   -0.0213791
  0.0264583    -0.0421428   -0.00374639   0.110869     0.0557658   -0.104162    0.0816525    -0.0216147    -0.00694772  -0.0623897  -0.000177661  -0.231508   -0.0169803   -0.0523886   -0.0793708  -0.123388     0.0422024    0.199757     0.0393218   -0.0459558   -0.0452252    0.0414113    0.0189059  -0.196284     0.0654883  -0.0276567
 -0.042323     -0.00128725  -0.0398264    0.0278018   -0.131724    -0.0377219  -0.0828042     0.0127891     0.0625419   -0.0301863  -0.105182      0.0617604   0.0385071   -0.0752565   -0.0791341   0.0012358    0.0642894   -0.0451356   -0.0487409    0.0707065   -0.119655    -0.0761889   -0.0441193   0.0445821    0.0817076  -0.0415558
 -0.0714335    -0.0507983   -0.0486859    0.199498    -0.00756639  -0.0813084   0.0210095    -0.0523885     0.13468     -0.0237499   0.0916942     0.0415442   0.152356     0.112587     0.0952299  -0.0106453    0.170189    -0.0361702   -0.226395    -0.0759442   -0.114426     0.0671874    0.171952   -0.00788337  -0.0152264  -0.0709075
 -0.0362561    -0.103802     0.0395695    0.191696    -0.178207     0.055935   -0.20162      -0.16566       0.136167    -0.144669   -0.0571536     0.0465526  -0.0742748    0.103052    -0.032866    0.184987     0.02718      0.00675554   0.050745    -0.182146     0.00351515  -0.00557722  -0.141166   -0.129817     0.0772023  -0.0201776
 -0.00346649   -0.0221276    0.108503    -0.00153548   0.0703148   -0.0846847   0.0164459     0.0120812    -0.069668     0.0144471   0.00873467    0.0921933   0.0243286   -0.0266191   -0.109377    0.0548325    0.087328     0.0095358   -0.047641     0.0408697    0.0413241   -0.0200279    0.0718604   0.0549291    0.104015    0.274395
  0.01443       0.0338182    0.108846    -0.0410831    0.0208924    0.0225288  -0.0303237    -0.105969     -0.0437924   -0.0734205  -0.0730715    -0.0320366   0.015247     0.0455917    0.100159    0.213241     0.104127     0.100685    -0.0948824   -0.127887    -0.113457    -0.0668071    0.0637383   0.0566047    0.0178323   0.0664887
 -0.0980433    -0.161656    -0.0613833   -0.0787526    0.0491692    0.107619    0.000677531  -0.0976366    -0.0593834   -0.0120631   0.0390422     0.156816    0.082934     0.0379938    0.0141302   0.0951841   -0.00121166   0.0491185   -0.0395566    0.0959472    0.0872967    0.0205062   -0.064146   -0.0327191   -0.0884207  -0.0818476
 -0.111231      0.0154428    0.148032     0.166183    -0.0523473   -0.253751   -0.0765849    -0.135049      0.0796875   -0.0343826   0.160025     -0.0868132  -0.00261744   0.153692     0.134198    0.0556648   -0.089766     0.386882    -0.181997     0.0834115    0.0190986    0.0719322   -0.105098   -0.2254       0.0521984   0.0811557
 -0.11849      -0.0879434    0.143259     0.075106    -0.0354534   -0.262325   -0.0265995    -0.128046      0.0897608   -0.0340665   0.161615      0.206254    0.0536247   -0.127135     0.0989206   0.00805527  -0.08707      0.177028    -0.190926    -0.418575     0.0421167    0.0728012   -0.0604126   0.53537      0.108761    0.097997
  0.100095      0.0820352    0.0214368   -0.0270541    0.32116      0.0648904   0.112188     -0.00125378    0.14353     -0.0627734   0.111925     -0.0716927   0.15341      0.00350558  -0.0884559  -0.0531745    0.0394326   -0.0570482   -0.0688345   -0.103724     0.0886924   -1.08095      0.0408469  -0.0430146   -0.149065    0.038934
  0.0540724     0.117721     0.00791828  -0.0413752   -0.79417      0.0698176   0.113153     -0.000928826   0.158567    -0.0630949   0.231352     -0.0530394  -0.0749382    0.00737529  -0.0941301   0.0118001   -0.00774989  -0.0586344   -0.0691251    0.0456829    0.0814256    1.8066       0.0487058   0.0577658   -0.135387    0.0434855[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│     11
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.981033
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.951649
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│     10
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.954186
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.938572
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.974590
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.945845
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.961297
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.941684
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.969571
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.951514
┌ Info: EM with 100000 data points 10 iterations avll -0.951514
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       7.197707e+05
      1       5.501840e+05      -1.695867e+05 |       32
      2       5.295365e+05      -2.064747e+04 |       32
      3       5.181295e+05      -1.140701e+04 |       32
      4       5.094058e+05      -8.723740e+03 |       32
      5       5.038260e+05      -5.579816e+03 |       32
      6       5.006554e+05      -3.170580e+03 |       32
      7       4.988389e+05      -1.816520e+03 |       32
      8       4.976575e+05      -1.181395e+03 |       32
      9       4.966651e+05      -9.924128e+02 |       32
     10       4.958710e+05      -7.940475e+02 |       32
     11       4.952626e+05      -6.084428e+02 |       32
     12       4.947642e+05      -4.983375e+02 |       32
     13       4.943594e+05      -4.048660e+02 |       32
     14       4.940712e+05      -2.882256e+02 |       32
     15       4.938680e+05      -2.031313e+02 |       32
     16       4.937377e+05      -1.302777e+02 |       32
     17       4.936399e+05      -9.785851e+01 |       32
     18       4.935469e+05      -9.299146e+01 |       32
     19       4.934555e+05      -9.139669e+01 |       32
     20       4.933764e+05      -7.912128e+01 |       31
     21       4.932952e+05      -8.115684e+01 |       30
     22       4.932127e+05      -8.249344e+01 |       31
     23       4.931291e+05      -8.359882e+01 |       31
     24       4.930522e+05      -7.695812e+01 |       31
     25       4.929781e+05      -7.408567e+01 |       31
     26       4.929065e+05      -7.154974e+01 |       30
     27       4.928428e+05      -6.371732e+01 |       30
     28       4.927917e+05      -5.114263e+01 |       30
     29       4.927429e+05      -4.872416e+01 |       31
     30       4.926984e+05      -4.457786e+01 |       31
     31       4.926343e+05      -6.410030e+01 |       31
     32       4.925587e+05      -7.552101e+01 |       31
     33       4.924907e+05      -6.802163e+01 |       31
     34       4.924234e+05      -6.734476e+01 |       31
     35       4.923680e+05      -5.539077e+01 |       31
     36       4.923253e+05      -4.266685e+01 |       30
     37       4.922895e+05      -3.582775e+01 |       30
     38       4.922337e+05      -5.580050e+01 |       29
     39       4.920791e+05      -1.546221e+02 |       29
     40       4.917590e+05      -3.200303e+02 |       31
     41       4.912569e+05      -5.021778e+02 |       31
     42       4.907923e+05      -4.645888e+02 |       31
     43       4.905448e+05      -2.474347e+02 |       31
     44       4.904386e+05      -1.062178e+02 |       31
     45       4.903886e+05      -5.003307e+01 |       31
     46       4.903637e+05      -2.487851e+01 |       29
     47       4.903420e+05      -2.172869e+01 |       30
     48       4.903194e+05      -2.254928e+01 |       31
     49       4.903028e+05      -1.663001e+01 |       29
     50       4.902892e+05      -1.361449e+01 |       27
K-means terminated without convergence after 50 iterations (objv = 490289.1918743367)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.206794
[ Info: iteration 2, average log likelihood -1.168308
[ Info: iteration 3, average log likelihood -1.131141
[ Info: iteration 4, average log likelihood -1.096480
[ Info: iteration 5, average log likelihood -1.061937
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.015639
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     11
│     18
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.008793
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.989362
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     16
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.951782
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      6
│      8
│     12
│     15
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.982289
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     11
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -0.995233
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      7
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.001529
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -0.969129
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     12
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -0.948311
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     11
│     15
│     21
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -0.962361
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.023129
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -0.986007
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -0.943067
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      7
│     11
│     23
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -0.933018
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     16
│     18
│     21
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -0.997161
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.008334
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      4
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -0.972555
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     11
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -0.968912
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -0.976092
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     15
│     18
│     21
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -0.957587
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     11
│     12
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.976564
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -0.986757
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      3
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -0.968110
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     12
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -0.957425
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      8
│     11
│     15
│     21
│     22
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -0.957809
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      4
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -0.993490
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -0.989360
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     16
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -0.964374
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     11
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -0.969086
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│     12
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -0.957044
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -0.992335
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│     16
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -0.952329
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     11
│     12
│     21
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -0.960813
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.977967
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -0.970652
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     11
│     12
│     16
│     18
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -0.944018
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -0.989461
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      8
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -0.939453
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -0.995144
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -0.983623
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -0.957278
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     21
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -0.927779
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     11
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.006856
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -0.997693
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     12
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -0.943601
┌ Info: EM with 100000 data points 50 iterations avll -0.943601
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0138676    0.0281746    0.13694      0.0581296   -0.0396066    0.0748791    0.0518697    0.244078   -0.0745734   -0.108939      0.11134      -0.157181    -0.0745265    0.0197036     0.197773    -0.0441342    0.072075     0.0715039   -0.0635555  -0.153215     0.263926    -0.115916     0.0354605   0.0191929   -0.153998     0.00675978
 -0.149383    -0.0701991    0.0642765    0.098836     0.21508      0.0447246   -0.0906872    0.0403237  -0.0293516   -0.0679916     0.0821658    -0.193126    -0.129548    -0.106412     -0.0344982   -0.1013      -0.250897     0.214624    -0.0616512  -0.0537617    0.151984     0.111035    -0.146828   -0.0342284    0.0750714    0.0480574
  0.0300711    0.0211475    0.113701    -0.0766215    0.00271629   0.0287059   -0.0630296   -0.121328   -0.0684125   -0.0423517    -0.124861     -3.83115e-5   0.00634228   0.0841772     0.119896     0.196772     0.142614     0.101587    -0.0944243  -0.156926    -0.139162    -0.063466     0.130192    0.0654667   -0.0230941    0.0815011
  0.0579005   -0.176308     0.0452448   -0.0137889    0.166297     0.0595987    0.0620454    0.171771    0.0794157    0.128953     -0.0568424    -0.091321     0.036107     0.137631     -0.1577      -0.0605539   -0.163258    -0.0502086   -0.109451    0.0458447    0.0914305   -0.0288674    0.0509589  -0.0636651   -0.096877     0.019003
 -0.114781    -0.0346148    0.145695     0.121498    -0.0441084   -0.257723    -0.0517129   -0.131054    0.0846527   -0.034237      0.160803      0.0581485    0.0248675    0.0153584     0.11671      0.0328627   -0.0884648    0.284108    -0.18709    -0.163262     0.0299154    0.0725672   -0.0830399   0.150027     0.0795257    0.0894609
 -0.0149506    0.0658924    0.00386272   0.115211     0.0630731    0.0373123   -0.0300321   -0.121515   -0.0390344    0.0246393     0.0619479    -0.0166248    0.0121063   -0.0587362    -0.0400753   -0.00995875  -0.0900359    0.118015     0.0561669   0.0829301    0.121514     0.032033     0.0409661  -0.0925827   -0.086321    -0.0405688
  0.0345418   -0.0125891    0.061286     0.126066     0.152598     0.178425    -0.0313308    0.357207    0.062806     0.00271902   -0.0165747     0.0256779   -0.116653    -0.102184      0.023195    -0.157317    -0.0749232   -0.15119     -0.132413    0.0267533   -0.0812944    0.216241     0.0933237  -0.112187     0.00601018  -0.122616
  0.11693      0.0959899    0.156534     0.111886    -0.068506    -0.201929     0.00812078   0.0168359  -0.0749897   -0.110636      0.0120676    -0.00209015   0.0137782    0.147164     -0.02245     -0.170838    -0.0488829    0.0583555   -0.0222033  -0.112042     0.0970997   -0.0883772    0.112894   -0.00497691  -0.0137381    0.0289547
  0.0804554    0.0767726   -0.123281     0.0472593   -0.0657612    0.0724199    0.056737     0.0836214  -0.0964303   -0.17393      -0.0177819    -0.188271    -0.0746375   -0.0404293    -0.143187    -0.0161221   -0.0528798   -0.00567565   0.0861443   0.0962987   -0.0491241   -0.0124056    0.0923261   0.218359     0.0231492    0.0441316
 -0.0552341   -0.0700114   -0.231724    -0.0888094   -0.149325    -0.118589     0.0060919   -0.0748564  -0.284727    -0.000417765  -0.0669955    -0.136503     0.060746    -0.135871     -0.0767233   -0.01116      0.0275948   -0.116056    -0.0650123   0.00550566   0.0409668   -0.0877009    0.050006   -0.131373     0.0679807   -0.0399908
 -0.031049    -0.0222508    0.0133257   -0.0520521   -0.0965503    0.0873725   -0.0951509    0.0660183  -0.0266444   -0.129637     -0.0246694     0.0247499   -0.0290692    0.100641     -0.110881     0.012219     0.0930663   -0.0901518   -0.180414    0.0292119   -0.012486    -0.141606    -0.0611972   0.0365713    0.0203411   -0.131829
 -0.118997    -0.0866489   -0.0743714   -0.0186707   -0.244928    -0.107365    -0.0476975   -0.0105486  -0.248672    -0.0430585    -0.0548839    -0.0839724    0.00990117   0.0222311    -0.0733301    0.0508998   -0.0860662   -0.116332    -0.198087   -0.034918    -0.114414     0.0478944    0.125735    0.0499579    0.210069     0.154407
  0.0129464   -0.0544836    0.0147651    0.108444     0.0488955   -0.0909564    0.0698577   -0.0158666  -0.00403409  -0.0383816     0.000404425  -0.195041    -0.0277785   -0.0369085    -0.0633058   -0.109683     0.0289606    0.204496     0.0347772  -0.0372926   -0.0190401    0.0509081    0.0090431  -0.196578     0.061882    -0.0246237
 -0.0714715   -0.0509682   -0.0482081    0.20046     -0.00788574  -0.0814307    0.0206602   -0.0523534   0.134746    -0.0236138     0.0919202     0.0418415    0.152934     0.113166      0.0944146   -0.010035     0.170655    -0.035316    -0.22643    -0.0759989   -0.115302     0.0675961    0.17223    -0.00777602  -0.0148536   -0.0707325
  0.0136636    0.0764281   -0.0752663   -0.0770476   -0.169554    -0.0189928   -0.0621926    0.169945    0.00945226   0.131568     -0.0383836    -0.0611235    0.00611376   0.0699822    -0.160255     0.036894    -0.00758237  -0.0639734    0.0951689   0.147918    -0.162443     0.0557647    0.0704393  -0.0336376   -0.0147975    0.196348
  0.0809283    0.0973744    0.0127936   -0.023863    -0.131571     0.077878     0.11324      0.0108497   0.155824    -0.059399      0.165203     -0.0547417    0.0587112    0.000938816  -0.0846972   -0.0279578    0.0156213   -0.0578074   -0.064986   -0.035999     0.0862184    0.103552     0.0422064  -0.0134717   -0.149638     0.0309615
 -0.0708396   -0.00650514   0.101955    -0.00432931   0.094161     0.200865     0.0160252    0.0891909  -0.0864521    0.133292      0.120872     -0.0225225    0.00703652   0.120005     -0.0685497   -0.108849     0.0126877   -0.00507282  -0.0551951   0.0572917    0.13158     -0.0197679    0.118482    0.10808     -0.0111321   -0.0438436
  0.160954     0.123989     0.0564675    0.183318     0.156939     0.0117952   -0.0254359    0.0270457  -0.0794524   -0.215416     -0.132604      0.0466615   -0.00479135  -0.0506315    -0.204495    -0.225524    -0.0438035    0.0749844   -0.14146    -0.123718    -0.00245201   0.117989     0.064301    0.146888    -0.161657    -0.167737
  0.117151    -0.0928282    0.0901787    0.0294912    6.70657e-5  -0.0340191    0.122878     0.231404   -0.0638158    0.223531     -0.0832488     0.0295138   -0.0565624    0.246447      0.102829    -0.185962     0.0901413   -0.181507     0.198731   -0.0895598    0.0871444    0.0372293   -0.102685   -0.134477     0.112376     0.0219472
 -0.00780602  -0.157557     0.0471533    0.0118683    0.101221     0.032466    -0.11034     -0.134964   -0.0512974   -0.132606      0.00492892   -0.0134827    0.0886735    0.103636      0.00432385  -0.0116623    0.0505878    0.0944505   -0.142997    0.0717511   -0.225338    -0.108905     0.0366922  -0.0423099   -0.0125416   -0.0232984
 -0.0254267   -0.105132     0.0411668    0.208308    -0.208318     0.0507197   -0.233954    -0.18154     0.147893    -0.152305     -0.073415      0.0513266   -0.0841144    0.103462     -0.0332934    0.183056     0.0330883    0.0093787    0.0474514  -0.210259    -0.0207678   -0.00365377  -0.134179   -0.121288     0.0745739   -0.0191531
 -0.091228    -0.238532    -0.0783176   -0.0962088    0.0458447    0.141639    -0.043997    -0.103027   -0.0685381    0.000381232   0.0503266     0.215421     0.0471813    0.0733168     0.0123953    0.0517833    0.00566759   0.0548226   -0.038681    0.125633     0.0311603    0.0333272    0.0105372  -0.0152315   -0.134021    -0.118088
 -0.0121375    0.0295027    0.0410538    0.103797     0.0420604    0.142701     0.14945      0.175373   -0.161953     0.0973128     0.106361      0.0833501   -0.0793961    0.066149     -0.0225311    0.0444802    0.174713    -0.0134375    0.0462233  -0.0155042   -0.149762    -0.0526444    0.0436687  -0.0719151    0.0378486    0.188914
  0.0844451   -0.0768884   -0.0373735    0.0971637   -0.157144    -0.0240998   -0.0246564    0.0629194   0.0441538    0.0300326     0.126852      0.0184613    0.160068    -0.0631226     0.0278749   -0.0396251    0.024281    -0.0252778   -0.150133    0.0207857   -0.00799777   0.0172518   -0.0239405  -0.0494533   -0.0417275    0.115418
  0.012264     0.124097     0.176978     0.0842872    0.115663     0.00377012   0.0265775   -0.0223296   0.0287337   -0.225999      0.106875     -0.173578    -0.0336061   -0.0899042     0.047533     0.240084    -0.0246867    0.113789    -0.097442   -0.0407122   -0.0240785   -0.128245    -0.0179718   0.0177705    0.174783    -0.12122
  0.00428026  -0.0320499    0.109804    -0.00946629   0.0717086   -0.083764     0.00197566   0.0328985  -0.0581159    0.0147163     0.00385801    0.0983936    0.00519919  -0.0218945    -0.116776     0.0315862    0.0883486    0.0102609   -0.0516794   0.0454803    0.00794952  -0.0126009    0.0725207   0.0569646    0.0969078    0.260292
 -0.0464085    0.00770701  -0.0792652    0.0944095   -0.162526    -0.147695    -0.0829343   -0.0387874   0.137861     0.0445744    -0.18442       0.112439     0.0990658   -0.241449     -0.0539834   -0.0109045    0.0387024   -0.0120986    0.0470269   0.0982516   -0.202348    -0.0219743   -0.0224092   0.0605219    0.136272     0.0284464
 -0.0150803    0.0461604   -0.0377031    0.0746489    0.0854328    0.131935     0.163007     0.120631   -0.149911     0.0413577     0.0376032     0.0990037   -0.00649592   0.10916      -0.0771767    0.0971858    0.313686    -0.0661755    0.0762303   0.038564    -0.0899897    0.00311181   0.106813   -0.140259     0.0547278    0.195787
  0.0620768    0.0927308   -0.137273     0.0397816   -0.0568466    0.00371455  -0.0466269    0.123534    0.104562    -0.00137934   -0.0560892     0.00314464  -0.0304921   -0.0912106     0.0404265    0.0260043    0.0188919    0.0528808   -0.0433523  -0.0510294    0.063605    -0.0395199    0.0442632  -0.159067     0.00544195   0.0629376
 -0.0344384   -0.00132683  -0.205164     0.0356499    0.0179472    0.17139     -0.0252692   -0.0374771  -0.0644957    0.0594712    -0.0513892     0.20451     -0.0261667    0.000809217  -0.00532683   0.13474      0.0286831    0.209028    -0.142797    0.15581      0.114688    -0.152884     0.0561129  -0.0171565    0.0231274   -0.0682789
  0.0254662    0.0569624    0.0233723    0.0349457   -0.00760913  -0.00924383   0.0767902   -0.139151    0.0707296   -0.0176847     0.0725355     0.0491743    0.100865     0.28707      -0.0139159   -0.0216294   -0.0423232   -0.101578    -0.0462623  -0.0556945   -0.0915364   -0.0416076   -0.102559    0.0453519   -0.0437111    0.0175868
 -0.0738744    0.0213268    0.0269925    0.0331906    0.0606188    0.00357252   0.13388     -0.112588   -0.00715915  -0.0758291    -0.0134433    -0.0296481    0.144545    -0.0816148     0.0213741    0.153464    -0.0304793    0.0137965   -0.0462456  -0.00942025   0.19121     -0.0138731   -0.191997   -0.0760057    0.0489981    0.120624[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.922482
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.876350
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.878809
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      4
│      7
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.900044
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.891377
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.857669
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│     11
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.920689
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.874653
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.878532
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      4
│      7
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.900070
┌ Info: EM with 100000 data points 10 iterations avll -0.900070
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0324108    0.187334     0.0728735   -0.0863255   -0.0739126   0.0923028   -0.0981318   -0.0244668   -0.148411     0.15873      -0.0298342     0.115661    0.191976     0.241081    -0.0746564   -0.00146635   0.198874     0.0510128    0.152992    -0.145523     0.0622565   0.271053    -0.130025     0.162491     0.0975015     0.04096
  0.145421     0.0431552   -0.110858     0.0129932    0.188829    0.0467465    0.00985166   0.0158132   -0.00695159   0.0457022    -0.10982      -0.0182765  -0.0797109   -0.121338    -0.03261     -0.0265877    0.0756096    0.236904    -0.106598    -0.060133     0.0864172  -0.0802443   -0.246108    -0.0463055   -0.109296      0.131873
  0.201493     0.261154    -0.00586222  -0.00424586   0.020201    0.155084     0.127205     0.00261651   0.13656     -0.0203114    -0.0162546     0.118049   -0.0684153   -0.134068     0.0491344    0.313616    -0.102658     0.0806939   -0.15296     -0.0933687    0.0419632  -0.060845     0.0616925    0.0464043    0.102564      0.0370986
 -0.098249     0.0512123   -0.0169721    0.0956642   -0.130524   -0.161494    -0.0480316    0.0488281    0.00190561   0.0248342     0.0779794    -0.0721476  -0.00583489   0.0170381   -0.179462    -0.0209819   -0.09715      0.0473359   -0.0724452    0.144623     0.0499525  -0.0923641    0.0366837    0.199566     0.0491128    -0.018509
  0.087893     0.0216512   -0.245108     0.0316766   -0.0781967  -0.0892559    0.0335544    0.04487      0.0773577   -0.0151944     0.0391162    -0.0638203   0.0321926   -0.235839     0.0758319    0.193523    -0.136752    -0.0920152    0.063406     0.0503493   -0.0774323   0.133815    -0.107557    -0.0190184   -0.02536      -0.0490895
  0.0437969   -0.112867    -0.180048    -0.0419281    0.331494   -0.0402077   -0.0991126   -0.0339027    0.0692607    0.16578       0.0412325     0.20626    -0.127885     0.0965895   -0.0340301    0.0131656   -0.0151772   -0.116845    -0.0320364   -0.186517     0.0376405  -0.0214153   -0.0440654    0.00467994  -0.00356413    0.0080405
  0.131563     0.251786     0.0479018   -0.121418    -0.0853939   0.0378087    0.202982    -0.00586853   0.0560955    0.0188738     0.0626787     0.10448    -0.0116586    0.0339495    0.0369186   -0.0248998    0.0632657   -0.0294601    0.199706    -0.0920325    0.152096    0.0908499   -0.0842383    0.0982414   -0.073361      0.0287771
 -0.0313281    0.0274152    0.0921946    0.0378746   -0.0913259  -0.0490591   -0.0568878   -0.0291063    0.0427771    0.00967397   -0.0730003    -0.0191655   0.0534926   -0.11393     -0.0728807   -0.129354     0.0477286   -0.0107279    0.0302468    0.111472    -0.0412651   0.0470217   -0.0433159    0.0381138    0.0445582     0.0588996
  0.0405413    0.112954    -0.0636928    0.12031     -0.216908    0.0601585    0.0216542   -0.0913718    0.0105244   -0.0309745     0.0650955    -0.0673276  -0.0383796    0.18572     -0.0395793   -0.0879398   -0.0859038    0.0331696   -0.134298    -0.0427941   -0.0658642  -0.0186136   -0.0437483   -0.0272613    0.0539495     0.00613205
  0.0102743    0.0255226    0.137172     0.0438933    0.0638155   0.0768536   -0.0723614    0.0259363   -0.0432768    0.0182396     0.0835565     0.0177577  -0.0438499    0.00148008   0.0956802    0.157032     0.0401267    0.0675373   -0.0251453    0.00296765   0.136456   -0.0670516    0.0396003   -0.0685993   -0.138861      0.248784
 -0.0132332    0.276601    -0.0763827   -0.0191583   -0.127623   -0.0739891    0.0391458   -0.0947376   -0.137545     0.0647516     0.168755      0.0920129  -0.134591    -0.184949    -0.0773162    0.067556     0.00966954   0.0285233    0.0591468    0.0901383   -0.0878205   0.0139736    0.0661169   -0.0926134    0.0526859     0.0520375
 -0.0760148    0.148968     0.121082     0.0821639   -0.102793    0.150283    -0.0186436    0.0657649    0.0153412   -0.0428731     0.0480037     0.135993   -0.0490936   -0.030158     0.0750469    0.0438447    0.0434413    0.219479    -0.0534564   -0.16481      0.0561758   0.0639063    0.098654     0.00813063  -0.0463238    -0.10885
  0.0682037   -0.163258     0.0540604   -0.091237     0.0371675  -0.0328794   -0.0941662   -0.00161986   0.0954592   -0.0694485     0.109996     -0.051632    0.0696184    0.0228751   -0.110963     0.114433     0.20956     -0.0708837   -0.0874373   -0.00642116  -0.0139271   0.0900348   -0.123596    -0.0329961    0.042819     -0.0742532
 -0.0544374   -0.0200067    0.0969275    0.228729    -0.0698398   0.00606093  -0.0339887    0.0994519   -0.0704996   -0.0245409    -0.000938399   0.0835565  -0.0597875    0.0510218   -0.173082    -0.127889     0.0335424   -0.0279915   -0.0040039    0.0188116    0.059714   -0.0778538   -0.15663      0.0719241    0.18462      -0.0563921
  0.0879801    0.110608    -0.0385494   -0.0536116    0.0815194  -0.0775218   -0.0669579   -0.0513174    0.0638873    0.0285488     0.146049      0.0475015   0.0732365   -0.0969656    0.00367748  -0.086665    -0.0511977    0.00736542  -0.00704299   0.0806101   -0.0141127   0.0252993    0.152462     0.00740983   0.0733277     0.0324111
  0.172413    -0.0569379   -0.060713     0.0166993    0.192678    0.0474141   -0.217786    -0.0311198   -0.0782238   -0.0473242     0.00589829   -0.0872192  -0.0709463    0.00162394  -0.11205     -0.0703351   -0.108718    -0.122019    -0.22291     -0.163746    -0.085685    0.102219     0.0537655    0.0456741   -0.00390616    0.153811
 -0.0274056    0.0652208   -0.217598    -0.125606    -0.145112   -0.127408    -0.0690671   -0.122491     0.127588    -0.0218696    -0.000839517  -0.080149   -0.0356743    0.0199082   -0.0178898    0.131509    -0.175677    -0.209874    -0.102493    -0.116702    -0.0266431  -0.0899676   -0.247314     0.184583     0.0155217     0.142786
  0.0783986    0.140254    -0.0895356    0.0864427   -0.137137    0.0176345   -0.0209189    0.163183    -0.0563059   -0.0588929    -0.0525        0.0568922  -0.00135175   0.038793     0.0698773    0.207981     0.0270993    0.00314369   0.0852488   -0.0677386    0.0279725   0.0516492    0.00961758  -0.0290541    0.194844      0.069544
  0.00528101   0.0546807   -0.033157     0.096712    -0.0276009  -0.0242171   -0.0926525    0.179108    -0.0691186    0.18045       0.0439186    -0.0834795  -0.0722039   -0.0584991    0.0966721   -0.0789792    0.0252287   -0.0125865   -0.158133     0.013915     0.0393313   0.200047    -0.182627     0.11935     -0.115347      0.0351844
  0.139165    -0.0568936   -0.0780151   -0.0242986   -0.0151047   0.00676536   0.0645127    0.221293    -0.0899838    0.000663606  -0.0259473     0.048375    0.0169786   -0.197338     0.108714    -0.0159907    0.120411     0.0158311   -0.0718422    0.0829196    0.0306894   0.00927508   0.1402      -0.0120677    0.198065     -0.163355
  0.170544    -0.111403     0.153914     0.1977       0.0252704   0.067289     0.00177939   0.0282597   -0.0797206    0.0819597    -0.068306     -0.025574   -0.0956593    0.071596     0.100229    -0.0395762    0.0705467    0.0963517    0.0341177   -0.037143     0.127583    0.206456     0.105351    -0.0390131    0.131185     -0.0641955
  0.0515392    0.133415    -0.184974    -0.00269243   0.0816014   0.052785    -0.0348793    0.11367     -0.0383389    0.154741      0.06317      -0.106583   -0.00107674   0.0474599    0.0667688   -0.060286     0.130191    -2.99411e-5   0.0550161    0.0381761    0.0861196  -0.0544084    0.103154     0.112971     0.0258593     0.0494732
 -0.0296364   -0.0857196    0.139114     0.0718075   -0.0727939   0.0345461    0.0961245   -0.0145304   -0.0472632    0.0856188    -0.104474      0.0492545  -0.107412     0.101999    -0.0573518   -0.134353    -0.0420378   -0.0241276    0.0103357   -0.0318266    0.0490321   0.0982905   -0.0513704    0.0694506    0.000514364  -0.0200951
 -0.0293419   -0.0954496   -0.0199135   -0.0489506    0.0243836   0.0136427   -0.0585715   -0.102242    -0.122704    -0.22674      -0.182048      0.143772    0.0435856    0.0236714    0.0351782    0.0282215    0.134487     0.182254     0.155103    -0.0933392    0.070811   -0.0693884   -0.19082      0.0296476   -0.0969438    -0.0893074
 -0.0662832    0.0865713   -0.0766901    0.0403152    0.059074   -0.174596     0.107435    -0.0685488    0.282322     0.12072      -0.0351379     0.0574426   0.020259    -0.146396     0.095296    -0.0807565    0.0717901    0.0564615   -0.221697     0.176799    -0.0681525   0.10325     -0.113383     0.0282778    0.0752654     0.0861606
  0.155412    -0.30156     -0.0111128    0.183092    -0.157797    0.0853646   -0.0549624   -0.13123     -0.0399966    0.0256527     0.0998396     0.0605712   0.0852748    0.0501288   -0.0683771    0.174514     0.147607     0.1937       0.0417234    0.137647     0.257222   -0.0822796   -0.0181769   -0.0172118    0.053811     -0.040134
  0.193494    -0.0063806   -0.0129976    0.061575    -0.289367   -0.231949    -0.106216    -0.00709735   0.0388112    0.0839046    -0.0374241    -0.318602    0.0681187   -0.0540973   -0.12372      0.104352     0.0773219    0.00834545  -0.0402818    0.0631228   -0.175066    0.0293161    0.049026     0.150549    -0.00997642    0.0820174
 -0.0405175   -0.0694832    0.081713    -0.019174    -0.137344    0.0336085    0.0715285   -0.0651777   -0.104561     0.0909048     0.13042      -0.0128242   0.0631933   -0.131657    -0.113197     0.0629881   -0.0741848   -0.0510542   -0.136175     0.139726    -0.0875245   0.086318    -0.0329814   -0.0220294   -0.201153      0.0440378
 -0.112427     0.041477    -0.0876578   -0.0367195   -0.18485    -0.124222    -0.0741982   -0.103794     0.0343389   -0.0281325     0.0270044     0.242331   -0.0174845    0.164181    -0.153691     0.0742369    0.0419697    0.178531     0.0842086    0.0764356    0.128435   -0.291964    -0.0720252    0.107451    -0.00673814    0.048922
 -0.110563    -0.198122    -0.0943062   -0.15922     -0.0986687   0.0614129   -0.018677    -0.0158194   -0.166807    -0.00188187    0.0350298    -0.185597   -0.0542075   -0.0132967    0.0944084    0.0888545    0.0827757    0.0782906    0.163378     0.116271    -0.128949    0.175317    -0.208535    -0.192154     0.0770747     0.0902547
 -0.0607804    0.00754158   0.0508384    0.0293838   -0.065537    0.0149118   -0.129308     0.013217     0.0224364    0.241058     -0.0845237    -0.0150262   0.170095    -0.153201    -0.140485    -0.107268    -0.0202611   -0.0106486    0.137652     0.0207534    0.0995111   0.0670743    0.00801032   0.0554697   -0.0401568    -0.0790926
  0.094436     0.0211261   -0.0571414    0.04011      0.060721    0.0113875    0.0412461    0.0308569   -0.0480197    0.0217948    -0.0659553     0.224555    0.116755    -0.0169137    0.00824986  -0.263004     0.0329613    0.101853    -0.0213264   -0.0129995   -0.191312    0.0689346   -0.154544    -0.0613248    0.0697765     0.172369kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4229351172973659
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422954
[ Info: iteration 2, average log likelihood -1.422852
[ Info: iteration 3, average log likelihood -1.422760
[ Info: iteration 4, average log likelihood -1.422650
[ Info: iteration 5, average log likelihood -1.422518
[ Info: iteration 6, average log likelihood -1.422376
[ Info: iteration 7, average log likelihood -1.422241
[ Info: iteration 8, average log likelihood -1.422129
[ Info: iteration 9, average log likelihood -1.422041
[ Info: iteration 10, average log likelihood -1.421963
[ Info: iteration 11, average log likelihood -1.421869
[ Info: iteration 12, average log likelihood -1.421722
[ Info: iteration 13, average log likelihood -1.421466
[ Info: iteration 14, average log likelihood -1.421029
[ Info: iteration 15, average log likelihood -1.420354
[ Info: iteration 16, average log likelihood -1.419492
[ Info: iteration 17, average log likelihood -1.418653
[ Info: iteration 18, average log likelihood -1.418049
[ Info: iteration 19, average log likelihood -1.417710
[ Info: iteration 20, average log likelihood -1.417546
[ Info: iteration 21, average log likelihood -1.417472
[ Info: iteration 22, average log likelihood -1.417439
[ Info: iteration 23, average log likelihood -1.417424
[ Info: iteration 24, average log likelihood -1.417417
[ Info: iteration 25, average log likelihood -1.417414
[ Info: iteration 26, average log likelihood -1.417412
[ Info: iteration 27, average log likelihood -1.417411
[ Info: iteration 28, average log likelihood -1.417411
[ Info: iteration 29, average log likelihood -1.417411
[ Info: iteration 30, average log likelihood -1.417410
[ Info: iteration 31, average log likelihood -1.417410
[ Info: iteration 32, average log likelihood -1.417410
[ Info: iteration 33, average log likelihood -1.417410
[ Info: iteration 34, average log likelihood -1.417409
[ Info: iteration 35, average log likelihood -1.417409
[ Info: iteration 36, average log likelihood -1.417409
[ Info: iteration 37, average log likelihood -1.417409
[ Info: iteration 38, average log likelihood -1.417409
[ Info: iteration 39, average log likelihood -1.417409
[ Info: iteration 40, average log likelihood -1.417409
[ Info: iteration 41, average log likelihood -1.417409
[ Info: iteration 42, average log likelihood -1.417409
[ Info: iteration 43, average log likelihood -1.417409
[ Info: iteration 44, average log likelihood -1.417408
[ Info: iteration 45, average log likelihood -1.417408
[ Info: iteration 46, average log likelihood -1.417408
[ Info: iteration 47, average log likelihood -1.417408
[ Info: iteration 48, average log likelihood -1.417408
[ Info: iteration 49, average log likelihood -1.417408
[ Info: iteration 50, average log likelihood -1.417408
┌ Info: EM with 100000 data points 50 iterations avll -1.417408
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4229543283528212
│     -1.422851926417902
│      ⋮
└     -1.417408213968623
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417427
[ Info: iteration 2, average log likelihood -1.417322
[ Info: iteration 3, average log likelihood -1.417226
[ Info: iteration 4, average log likelihood -1.417110
[ Info: iteration 5, average log likelihood -1.416971
[ Info: iteration 6, average log likelihood -1.416826
[ Info: iteration 7, average log likelihood -1.416694
[ Info: iteration 8, average log likelihood -1.416591
[ Info: iteration 9, average log likelihood -1.416518
[ Info: iteration 10, average log likelihood -1.416468
[ Info: iteration 11, average log likelihood -1.416433
[ Info: iteration 12, average log likelihood -1.416406
[ Info: iteration 13, average log likelihood -1.416384
[ Info: iteration 14, average log likelihood -1.416364
[ Info: iteration 15, average log likelihood -1.416345
[ Info: iteration 16, average log likelihood -1.416327
[ Info: iteration 17, average log likelihood -1.416308
[ Info: iteration 18, average log likelihood -1.416288
[ Info: iteration 19, average log likelihood -1.416267
[ Info: iteration 20, average log likelihood -1.416246
[ Info: iteration 21, average log likelihood -1.416224
[ Info: iteration 22, average log likelihood -1.416202
[ Info: iteration 23, average log likelihood -1.416181
[ Info: iteration 24, average log likelihood -1.416161
[ Info: iteration 25, average log likelihood -1.416142
[ Info: iteration 26, average log likelihood -1.416125
[ Info: iteration 27, average log likelihood -1.416110
[ Info: iteration 28, average log likelihood -1.416098
[ Info: iteration 29, average log likelihood -1.416087
[ Info: iteration 30, average log likelihood -1.416078
[ Info: iteration 31, average log likelihood -1.416071
[ Info: iteration 32, average log likelihood -1.416065
[ Info: iteration 33, average log likelihood -1.416061
[ Info: iteration 34, average log likelihood -1.416057
[ Info: iteration 35, average log likelihood -1.416054
[ Info: iteration 36, average log likelihood -1.416051
[ Info: iteration 37, average log likelihood -1.416049
[ Info: iteration 38, average log likelihood -1.416047
[ Info: iteration 39, average log likelihood -1.416045
[ Info: iteration 40, average log likelihood -1.416044
[ Info: iteration 41, average log likelihood -1.416043
[ Info: iteration 42, average log likelihood -1.416042
[ Info: iteration 43, average log likelihood -1.416041
[ Info: iteration 44, average log likelihood -1.416040
[ Info: iteration 45, average log likelihood -1.416040
[ Info: iteration 46, average log likelihood -1.416039
[ Info: iteration 47, average log likelihood -1.416038
[ Info: iteration 48, average log likelihood -1.416038
[ Info: iteration 49, average log likelihood -1.416037
[ Info: iteration 50, average log likelihood -1.416037
┌ Info: EM with 100000 data points 50 iterations avll -1.416037
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4174272196633884
│     -1.4173218291283198
│      ⋮
└     -1.4160368830334524
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416048
[ Info: iteration 2, average log likelihood -1.415992
[ Info: iteration 3, average log likelihood -1.415941
[ Info: iteration 4, average log likelihood -1.415879
[ Info: iteration 5, average log likelihood -1.415799
[ Info: iteration 6, average log likelihood -1.415700
[ Info: iteration 7, average log likelihood -1.415587
[ Info: iteration 8, average log likelihood -1.415468
[ Info: iteration 9, average log likelihood -1.415356
[ Info: iteration 10, average log likelihood -1.415257
[ Info: iteration 11, average log likelihood -1.415175
[ Info: iteration 12, average log likelihood -1.415106
[ Info: iteration 13, average log likelihood -1.415047
[ Info: iteration 14, average log likelihood -1.414997
[ Info: iteration 15, average log likelihood -1.414954
[ Info: iteration 16, average log likelihood -1.414918
[ Info: iteration 17, average log likelihood -1.414887
[ Info: iteration 18, average log likelihood -1.414860
[ Info: iteration 19, average log likelihood -1.414837
[ Info: iteration 20, average log likelihood -1.414817
[ Info: iteration 21, average log likelihood -1.414799
[ Info: iteration 22, average log likelihood -1.414783
[ Info: iteration 23, average log likelihood -1.414768
[ Info: iteration 24, average log likelihood -1.414755
[ Info: iteration 25, average log likelihood -1.414742
[ Info: iteration 26, average log likelihood -1.414730
[ Info: iteration 27, average log likelihood -1.414719
[ Info: iteration 28, average log likelihood -1.414709
[ Info: iteration 29, average log likelihood -1.414699
[ Info: iteration 30, average log likelihood -1.414689
[ Info: iteration 31, average log likelihood -1.414680
[ Info: iteration 32, average log likelihood -1.414671
[ Info: iteration 33, average log likelihood -1.414663
[ Info: iteration 34, average log likelihood -1.414655
[ Info: iteration 35, average log likelihood -1.414647
[ Info: iteration 36, average log likelihood -1.414639
[ Info: iteration 37, average log likelihood -1.414632
[ Info: iteration 38, average log likelihood -1.414625
[ Info: iteration 39, average log likelihood -1.414618
[ Info: iteration 40, average log likelihood -1.414611
[ Info: iteration 41, average log likelihood -1.414604
[ Info: iteration 42, average log likelihood -1.414597
[ Info: iteration 43, average log likelihood -1.414590
[ Info: iteration 44, average log likelihood -1.414583
[ Info: iteration 45, average log likelihood -1.414577
[ Info: iteration 46, average log likelihood -1.414570
[ Info: iteration 47, average log likelihood -1.414564
[ Info: iteration 48, average log likelihood -1.414557
[ Info: iteration 49, average log likelihood -1.414550
[ Info: iteration 50, average log likelihood -1.414544
┌ Info: EM with 100000 data points 50 iterations avll -1.414544
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4160475948023994
│     -1.415992011232189
│      ⋮
└     -1.4145436229783956
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414546
[ Info: iteration 2, average log likelihood -1.414487
[ Info: iteration 3, average log likelihood -1.414434
[ Info: iteration 4, average log likelihood -1.414374
[ Info: iteration 5, average log likelihood -1.414304
[ Info: iteration 6, average log likelihood -1.414221
[ Info: iteration 7, average log likelihood -1.414126
[ Info: iteration 8, average log likelihood -1.414021
[ Info: iteration 9, average log likelihood -1.413913
[ Info: iteration 10, average log likelihood -1.413804
[ Info: iteration 11, average log likelihood -1.413699
[ Info: iteration 12, average log likelihood -1.413600
[ Info: iteration 13, average log likelihood -1.413509
[ Info: iteration 14, average log likelihood -1.413427
[ Info: iteration 15, average log likelihood -1.413353
[ Info: iteration 16, average log likelihood -1.413289
[ Info: iteration 17, average log likelihood -1.413232
[ Info: iteration 18, average log likelihood -1.413183
[ Info: iteration 19, average log likelihood -1.413141
[ Info: iteration 20, average log likelihood -1.413104
[ Info: iteration 21, average log likelihood -1.413071
[ Info: iteration 22, average log likelihood -1.413042
[ Info: iteration 23, average log likelihood -1.413016
[ Info: iteration 24, average log likelihood -1.412993
[ Info: iteration 25, average log likelihood -1.412971
[ Info: iteration 26, average log likelihood -1.412951
[ Info: iteration 27, average log likelihood -1.412933
[ Info: iteration 28, average log likelihood -1.412915
[ Info: iteration 29, average log likelihood -1.412899
[ Info: iteration 30, average log likelihood -1.412884
[ Info: iteration 31, average log likelihood -1.412869
[ Info: iteration 32, average log likelihood -1.412855
[ Info: iteration 33, average log likelihood -1.412842
[ Info: iteration 34, average log likelihood -1.412830
[ Info: iteration 35, average log likelihood -1.412818
[ Info: iteration 36, average log likelihood -1.412807
[ Info: iteration 37, average log likelihood -1.412796
[ Info: iteration 38, average log likelihood -1.412785
[ Info: iteration 39, average log likelihood -1.412775
[ Info: iteration 40, average log likelihood -1.412766
[ Info: iteration 41, average log likelihood -1.412757
[ Info: iteration 42, average log likelihood -1.412748
[ Info: iteration 43, average log likelihood -1.412739
[ Info: iteration 44, average log likelihood -1.412731
[ Info: iteration 45, average log likelihood -1.412723
[ Info: iteration 46, average log likelihood -1.412715
[ Info: iteration 47, average log likelihood -1.412707
[ Info: iteration 48, average log likelihood -1.412700
[ Info: iteration 49, average log likelihood -1.412692
[ Info: iteration 50, average log likelihood -1.412685
┌ Info: EM with 100000 data points 50 iterations avll -1.412685
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4145455708029606
│     -1.4144865085634435
│      ⋮
└     -1.4126852439340785
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412688
[ Info: iteration 2, average log likelihood -1.412624
[ Info: iteration 3, average log likelihood -1.412564
[ Info: iteration 4, average log likelihood -1.412494
[ Info: iteration 5, average log likelihood -1.412407
[ Info: iteration 6, average log likelihood -1.412300
[ Info: iteration 7, average log likelihood -1.412173
[ Info: iteration 8, average log likelihood -1.412029
[ Info: iteration 9, average log likelihood -1.411877
[ Info: iteration 10, average log likelihood -1.411723
[ Info: iteration 11, average log likelihood -1.411576
[ Info: iteration 12, average log likelihood -1.411439
[ Info: iteration 13, average log likelihood -1.411317
[ Info: iteration 14, average log likelihood -1.411208
[ Info: iteration 15, average log likelihood -1.411112
[ Info: iteration 16, average log likelihood -1.411027
[ Info: iteration 17, average log likelihood -1.410952
[ Info: iteration 18, average log likelihood -1.410886
[ Info: iteration 19, average log likelihood -1.410828
[ Info: iteration 20, average log likelihood -1.410777
[ Info: iteration 21, average log likelihood -1.410730
[ Info: iteration 22, average log likelihood -1.410689
[ Info: iteration 23, average log likelihood -1.410651
[ Info: iteration 24, average log likelihood -1.410616
[ Info: iteration 25, average log likelihood -1.410584
[ Info: iteration 26, average log likelihood -1.410555
[ Info: iteration 27, average log likelihood -1.410527
[ Info: iteration 28, average log likelihood -1.410501
[ Info: iteration 29, average log likelihood -1.410476
[ Info: iteration 30, average log likelihood -1.410453
[ Info: iteration 31, average log likelihood -1.410431
[ Info: iteration 32, average log likelihood -1.410410
[ Info: iteration 33, average log likelihood -1.410390
[ Info: iteration 34, average log likelihood -1.410371
[ Info: iteration 35, average log likelihood -1.410352
[ Info: iteration 36, average log likelihood -1.410335
[ Info: iteration 37, average log likelihood -1.410318
[ Info: iteration 38, average log likelihood -1.410303
[ Info: iteration 39, average log likelihood -1.410287
[ Info: iteration 40, average log likelihood -1.410273
[ Info: iteration 41, average log likelihood -1.410259
[ Info: iteration 42, average log likelihood -1.410246
[ Info: iteration 43, average log likelihood -1.410233
[ Info: iteration 44, average log likelihood -1.410221
[ Info: iteration 45, average log likelihood -1.410209
[ Info: iteration 46, average log likelihood -1.410198
[ Info: iteration 47, average log likelihood -1.410187
[ Info: iteration 48, average log likelihood -1.410177
[ Info: iteration 49, average log likelihood -1.410167
[ Info: iteration 50, average log likelihood -1.410157
┌ Info: EM with 100000 data points 50 iterations avll -1.410157
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412687731636469
│     -1.4126237160041275
│      ⋮
└     -1.410156933786859
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4229351172973659
│     -1.4229543283528212
│     -1.422851926417902
│     -1.4227604293020362
│      ⋮
│     -1.410176576485412
│     -1.4101665726460222
└     -1.410156933786859
32×26 Array{Float64,2}:
 -0.704612   -0.406122   -0.176003    -0.311289     -0.235605    -1.03756     -0.205382   -0.873804    0.277423    0.173758    -0.0131046     0.0624761   0.175507    -0.0411231   0.112846    -0.0892196    -0.103336   -0.179617    -0.502947     0.804968    -0.0933096  -0.259205    -0.312466    0.136328   -0.129441    0.130543
  0.437597    0.156614   -0.0552172    0.0417937    -0.283441    -0.123733    -0.495112   -0.867599   -0.193816    0.0391069    0.374892     -0.432262   -0.0781385   -0.180592    0.29165      0.216528      0.135762   -0.0150999    0.0912789    0.662114     0.280058   -0.295815     0.0258771  -0.278564    0.0110397   0.320473
 -0.0868921   0.327542    0.272774    -0.958015     -0.313577     0.220388    -0.171807   -0.489045   -0.0587953  -0.0396696   -0.343789      0.0199224   0.24704      0.209812    0.00353317   0.0375104    -0.169975   -0.0314829    0.205254     0.301398     0.286539    0.039618    -0.730205   -0.362542    0.294651   -0.0126788
 -0.191509    0.60105     0.285889    -0.000150009  -0.605683    -0.391923    -0.043529    0.0370977  -0.0641255  -0.00945523  -0.175089     -0.0423199   0.446664     0.0537819   0.0524138   -0.300844      0.215506    0.0540283   -0.0444758    0.178091     0.453879    0.167829    -0.436277    0.917493   -0.125158   -0.0651172
  0.256003   -0.24648    -0.0966179    0.235408      0.00371307   0.156368    -0.051192   -0.0852601  -0.736001   -0.0858503    0.0297828    -0.322991    0.594877    -0.0402332   0.631214     0.414337      0.350383    0.415732     0.348977    -0.142705    -0.207624   -0.00172687   0.0351412   0.333657    0.0895249  -0.736158
  0.181601   -0.0354815  -0.17556      0.14359      -0.390504    -0.205815    -0.0727018   0.232185   -0.45634     0.455696     0.44663       0.178616    0.319101     0.217033    0.632663    -0.169603      0.413168   -0.00825438   0.571454    -0.171071    -0.145634   -0.180977     0.130037    0.4854      0.199013    0.497873
  0.0401226  -0.133115   -0.435751     0.917088      0.313669    -0.0418697    0.0603532  -0.0184194  -0.487868   -0.316861     0.0631446     0.459896    0.0817046   -0.564035    0.76826     -0.323658      0.246624    0.546576    -0.115243    -0.504138     0.209422   -0.257045     0.121605    0.252107   -0.874506   -0.367819
  0.287294   -0.145851    0.413193     0.497905      0.0689733   -0.26699      0.360474   -0.0390352  -0.6388     -0.0945389    0.0404341     0.36841    -0.192975    -0.442437    0.138986     0.105374      0.0500049   0.456274    -0.292932    -0.108218     0.0819663   0.171044    -0.346031    0.141107    0.340569   -0.378343
 -0.0395908   0.166227   -0.59966     -0.290674      0.0540132    0.136828     0.632758    0.459398    0.0138448  -0.0131875   -0.000445822   0.273502    0.316159     0.0623573  -0.482983     0.249211      0.198168   -0.172003    -0.12316     -0.104721    -0.354328    0.487469    -0.395896    0.286793    0.230983   -0.242797
 -0.323426    0.211241   -0.29099     -0.182393      0.0524315    0.290788     0.169034   -0.0174793  -0.201914    0.0920906   -0.155949     -0.175268    0.00049035   0.148901   -0.0716321    0.000610812  -0.419464    0.0624906    0.262372     0.06656     -0.539915    0.261399     0.122205   -0.279112   -0.325244   -0.118855
 -0.317233    0.491851   -0.163548     0.589057     -0.00395807   0.252466     0.203022    0.411415    0.156118    0.0911042    0.398982     -0.115616    0.0170747   -0.0968064  -0.327342    -0.00055874    0.219163    0.429962    -0.0508556   -0.265309    -0.212171    0.110577     0.0239971  -0.0142136  -0.163374    0.373931
  0.362613    0.789389   -0.299985     0.188903      0.387154    -0.0280089    0.3256      0.195073   -0.0500933  -0.0872654    0.175183     -0.084373   -0.0121126   -0.132893   -0.41241     -0.290259     -0.451962    0.100053    -0.229883    -0.330294     0.60108    -0.332493     0.0075384  -0.36355    -0.301333    0.278141
  0.26853     0.0405039   0.0351639    0.00618664   -0.0991605   -0.0841611    0.0053731  -0.0832548  -0.352456    0.084384     0.0403519     0.07543     0.055931     0.012608    0.10247     -0.0106655     0.0793746   0.0264484    0.00936385   0.00268724   0.130871    0.0364532   -0.0330187   0.0691975   0.11393     7.56421e-5
 -0.0514419  -0.220939    0.0362281    0.0462612     0.0256633    0.0234878   -0.163056    0.161576    0.360974   -0.216805     0.0598224    -0.159875    0.132451    -0.0897389  -0.0778801    0.0584034     0.064173    0.10319     -0.0372935   -0.168349    -0.021394   -0.0839179   -0.104562    0.120619   -0.056894   -0.151978
  0.454147   -0.382723    0.156132     0.0163781     0.161884     0.200082    -0.398386   -0.0599959   0.187746   -0.0226232   -0.00809319    0.646238   -0.731787     0.157162    0.0471552   -0.120075      0.0852239   0.0316563    0.0156722   -0.188046     0.223167   -0.663485    -0.191446   -0.201213    0.296461    0.146276
  0.131071   -0.0327369   0.00340082  -0.0627496     0.154811     0.0272293   -0.12244    -0.0336274   0.599709    0.0810788   -0.358828      0.109737   -0.347677     0.0851846  -0.124193     0.0702857     0.0779846  -0.251535    -0.285587     0.181049     0.149034    0.413805     0.201726    0.0135853   0.238971    0.4811
 -0.27493     0.322172   -0.485336    -0.0481129    -0.463793    -0.303285     0.468309   -0.463728   -0.476525   -0.11897      0.113283      0.0467566  -0.424772     0.922722   -0.288852     0.327804      0.0884195   0.556223    -0.399089     0.153459    -0.531651    0.0374081   -0.0471886  -0.0605171  -0.0346153   0.439525
 -0.0379107   0.108389   -0.121807     0.141844     -0.91003     -0.506807     0.424502    0.0738907  -0.89892     0.409576     0.621477     -0.787009    0.10721     -0.489541   -0.0842816    0.395797     -0.455164    0.603021     0.448893     0.203961    -0.476132   -0.415981    -0.500368   -0.0868079  -0.0789466   0.0426853
 -0.750101   -0.155834   -0.0508094    0.0723092     0.233967     0.664364    -0.0881078  -0.236289    0.480871   -0.267405    -0.33072      -0.0951096  -0.06322     -0.0184368  -0.229376     0.34468       0.0256048   0.410381     0.215041    -0.454609    -0.407626    0.119435    -0.392018    0.468176   -0.474292    0.126402
 -0.475843   -0.113857   -0.0298044   -0.00467944    0.0584707    0.480616     0.320605   -0.160777    0.133218    0.112724     0.109676      0.0403368  -0.0936836   -0.575591    0.0416561   -0.0410024    -0.321937    0.348527     0.316421     0.307171    -0.476311    0.513047    -0.0140948  -0.824074   -0.0240354  -0.258183
 -0.250862    0.195965   -0.228054     0.354903      0.323629    -0.0395932    0.581736    0.346771   -0.0783063   0.0825857    0.195599     -0.0846605   0.16422     -0.302134   -0.292572     0.281969      0.0265117   0.360177    -0.199929    -0.187665    -0.0322819   0.294682     0.212893   -0.141053   -0.285452   -0.208932
  0.436843   -0.223513    0.232986    -0.272032     -0.145359    -0.431024    -0.541156   -0.30815    -0.135829    0.0759593   -0.0625648     0.015658    8.02293e-5   0.0024506   0.416327     0.0854391     0.149083    0.0135021   -0.114758     0.0843881    0.347215   -0.212725    -0.123352    0.204431    0.159337    0.101137
  0.351206    0.858706   -0.102267     0.278977     -0.328085     0.577718     0.106334    0.119397   -0.310034   -0.189706     0.0125031     0.245329   -0.149801     0.0993724   0.328924    -0.47968      -0.0748344   0.143683     0.653309    -0.343358    -0.126772    0.0777826   -0.415035    0.246061    0.501711    0.268584
  0.830962    0.368618    0.0133044    0.170389      0.339378     0.103777    -0.121427    0.219876   -0.630831    0.290119     0.288227     -0.152653    0.0557152    0.32876     0.00725037  -0.341281      0.16608    -0.302773     0.11537     -0.0345441    0.312272    0.0687449    1.00327    -0.344242    0.185521   -0.256097
 -0.066815   -0.21788     0.178832     0.260357      0.0335729   -0.497011    -0.444624    0.893283    0.201518    0.1901       0.000872148   0.164229    0.494807     0.511296   -0.794895    -0.481857      0.443777   -0.375288    -0.458152    -0.481538     0.174038   -0.619879    -0.355801    0.740777    0.384906    0.101158
 -0.134543   -0.407807    0.313002    -0.445632     -0.357811    -0.253931    -0.207834    0.0382172   0.198765    0.423338    -0.963222      0.537782   -0.560187     0.334037    0.226056    -0.285422      0.334159   -0.180002    -0.81553      0.274374     0.0640654   0.867195    -0.0990092   0.037247    0.114992   -0.109794
 -0.237329    0.243723   -0.511812    -1.03803      -0.164333     0.0945982   -0.380731    0.0795415   0.759352   -0.325959     0.0510864    -0.0429213  -0.197734     0.424252   -0.368618    -0.108423      0.050576   -0.668365     0.162704     0.396869     0.198365    0.203736     0.426849   -0.399513   -0.0446534   0.423822
  0.397167    0.387025    0.209565     0.756523      0.317945     0.514775     0.0299294   0.0684263   1.20481     0.231109    -0.287056      0.423064   -0.280979     0.288327   -0.344178    -0.249088     -0.172455   -0.518858    -0.219139     0.288705     0.285892    0.139802    -0.0360409   0.135667    0.272992    1.08611
 -0.0676029  -0.598205    0.0614159    0.0919308    -0.088899     0.00682091   0.089435    0.159804    0.183615    0.428201     0.0570533    -0.279859   -0.335793    -0.0182713  -0.646696     0.75735      -0.116677   -0.911102     0.0284821   -0.204511    -0.414883   -0.203908     0.948281    0.256492   -0.103718   -0.0801741
 -0.105793   -1.13174     0.147813    -0.387249      0.129326    -0.0917417   -0.74313     0.385204    0.282391    0.304654     0.162491     -0.190174   -0.0815315   -0.0412239  -0.111459     0.133572      0.204676   -0.0225602    0.311365     0.00329167  -0.86666     0.230118     0.19693    -0.0380928   0.171158   -0.0498142
  0.623363   -0.560295    0.223197    -0.0847812     0.0183672   -0.134234    -0.457213    0.258117    0.289904    0.241675    -0.0743371     0.271206    0.184467    -0.693854    0.0628227   -0.151176     -0.116866   -0.837264     0.0588421    0.0204495    0.634098    0.0674262    0.104744    0.0748592   0.152008   -0.334699
  0.0386144  -0.579891    0.597738    -0.166794      0.34514     -0.124313    -0.535333   -0.207932    0.602729   -0.4796      -0.256501     -0.381522   -0.145717    -0.445569   -0.0871996    0.45414      -0.0970767   0.07898     -0.289774    -0.0953617    0.694801   -0.32766      0.0188559  -0.311553   -0.118513   -0.0542019[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410148
[ Info: iteration 2, average log likelihood -1.410139
[ Info: iteration 3, average log likelihood -1.410130
[ Info: iteration 4, average log likelihood -1.410122
[ Info: iteration 5, average log likelihood -1.410113
[ Info: iteration 6, average log likelihood -1.410106
[ Info: iteration 7, average log likelihood -1.410098
[ Info: iteration 8, average log likelihood -1.410091
[ Info: iteration 9, average log likelihood -1.410083
[ Info: iteration 10, average log likelihood -1.410076
┌ Info: EM with 100000 data points 10 iterations avll -1.410076
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.070227e+05
      1       7.121642e+05      -1.948585e+05 |       32
      2       6.938085e+05      -1.835572e+04 |       32
      3       6.871574e+05      -6.651065e+03 |       32
      4       6.840493e+05      -3.108114e+03 |       32
      5       6.821493e+05      -1.899984e+03 |       32
      6       6.808569e+05      -1.292433e+03 |       32
      7       6.799164e+05      -9.404601e+02 |       32
      8       6.791513e+05      -7.650904e+02 |       32
      9       6.785369e+05      -6.144990e+02 |       32
     10       6.780370e+05      -4.998392e+02 |       32
     11       6.776276e+05      -4.094057e+02 |       32
     12       6.773074e+05      -3.201773e+02 |       32
     13       6.770258e+05      -2.816254e+02 |       32
     14       6.767768e+05      -2.489952e+02 |       32
     15       6.765529e+05      -2.239430e+02 |       32
     16       6.763564e+05      -1.964565e+02 |       32
     17       6.761827e+05      -1.737570e+02 |       32
     18       6.760318e+05      -1.508928e+02 |       32
     19       6.758759e+05      -1.558317e+02 |       32
     20       6.757305e+05      -1.454520e+02 |       32
     21       6.755951e+05      -1.353443e+02 |       32
     22       6.754593e+05      -1.358348e+02 |       32
     23       6.753449e+05      -1.143716e+02 |       32
     24       6.752393e+05      -1.056318e+02 |       32
     25       6.751470e+05      -9.231292e+01 |       32
     26       6.750676e+05      -7.941004e+01 |       32
     27       6.749865e+05      -8.108104e+01 |       32
     28       6.749058e+05      -8.068111e+01 |       32
     29       6.748279e+05      -7.794661e+01 |       32
     30       6.747605e+05      -6.732659e+01 |       32
     31       6.746946e+05      -6.592123e+01 |       32
     32       6.746316e+05      -6.299748e+01 |       32
     33       6.745718e+05      -5.980724e+01 |       32
     34       6.745197e+05      -5.212058e+01 |       32
     35       6.744679e+05      -5.182724e+01 |       32
     36       6.744111e+05      -5.678834e+01 |       32
     37       6.743501e+05      -6.099803e+01 |       32
     38       6.742973e+05      -5.276944e+01 |       32
     39       6.742492e+05      -4.807634e+01 |       32
     40       6.742042e+05      -4.506124e+01 |       32
     41       6.741637e+05      -4.048307e+01 |       32
     42       6.741281e+05      -3.557251e+01 |       32
     43       6.740936e+05      -3.447783e+01 |       32
     44       6.740629e+05      -3.072386e+01 |       32
     45       6.740357e+05      -2.725864e+01 |       32
     46       6.740131e+05      -2.254596e+01 |       32
     47       6.739929e+05      -2.019443e+01 |       32
     48       6.739736e+05      -1.926844e+01 |       32
     49       6.739557e+05      -1.796834e+01 |       32
     50       6.739348e+05      -2.087996e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 673934.7938458616)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421836
[ Info: iteration 2, average log likelihood -1.416885
[ Info: iteration 3, average log likelihood -1.415546
[ Info: iteration 4, average log likelihood -1.414524
[ Info: iteration 5, average log likelihood -1.413411
[ Info: iteration 6, average log likelihood -1.412371
[ Info: iteration 7, average log likelihood -1.411650
[ Info: iteration 8, average log likelihood -1.411241
[ Info: iteration 9, average log likelihood -1.411008
[ Info: iteration 10, average log likelihood -1.410859
[ Info: iteration 11, average log likelihood -1.410751
[ Info: iteration 12, average log likelihood -1.410666
[ Info: iteration 13, average log likelihood -1.410595
[ Info: iteration 14, average log likelihood -1.410535
[ Info: iteration 15, average log likelihood -1.410483
[ Info: iteration 16, average log likelihood -1.410438
[ Info: iteration 17, average log likelihood -1.410397
[ Info: iteration 18, average log likelihood -1.410360
[ Info: iteration 19, average log likelihood -1.410327
[ Info: iteration 20, average log likelihood -1.410297
[ Info: iteration 21, average log likelihood -1.410269
[ Info: iteration 22, average log likelihood -1.410243
[ Info: iteration 23, average log likelihood -1.410219
[ Info: iteration 24, average log likelihood -1.410197
[ Info: iteration 25, average log likelihood -1.410176
[ Info: iteration 26, average log likelihood -1.410156
[ Info: iteration 27, average log likelihood -1.410137
[ Info: iteration 28, average log likelihood -1.410118
[ Info: iteration 29, average log likelihood -1.410101
[ Info: iteration 30, average log likelihood -1.410084
[ Info: iteration 31, average log likelihood -1.410067
[ Info: iteration 32, average log likelihood -1.410051
[ Info: iteration 33, average log likelihood -1.410036
[ Info: iteration 34, average log likelihood -1.410021
[ Info: iteration 35, average log likelihood -1.410007
[ Info: iteration 36, average log likelihood -1.409993
[ Info: iteration 37, average log likelihood -1.409979
[ Info: iteration 38, average log likelihood -1.409966
[ Info: iteration 39, average log likelihood -1.409953
[ Info: iteration 40, average log likelihood -1.409941
[ Info: iteration 41, average log likelihood -1.409929
[ Info: iteration 42, average log likelihood -1.409917
[ Info: iteration 43, average log likelihood -1.409905
[ Info: iteration 44, average log likelihood -1.409894
[ Info: iteration 45, average log likelihood -1.409883
[ Info: iteration 46, average log likelihood -1.409873
[ Info: iteration 47, average log likelihood -1.409862
[ Info: iteration 48, average log likelihood -1.409852
[ Info: iteration 49, average log likelihood -1.409842
[ Info: iteration 50, average log likelihood -1.409832
┌ Info: EM with 100000 data points 50 iterations avll -1.409832
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.575285    -0.143125    0.194311     0.496101     0.686106    0.340262     0.0820359   0.248561   -0.298292    0.208751     0.0779161   -0.0224392   0.142031     -0.527245   -0.0265487   0.506517     0.522172     0.0230101  -0.240259    0.216017    0.31566      0.48913     0.288992   -0.485528     0.437658    -0.731629
 -0.836026     0.348262    0.0142669    0.0759951   -0.397213   -0.131294     0.266396   -0.330247    0.0958746   0.0202626   -0.0379738   -0.212311    0.26946      -0.224831   -0.360367    0.284443     0.38534      0.343256   -0.268472    0.379252   -0.0819839    0.24634    -0.524889    0.344141    -0.317646    -0.0374799
  0.523496     0.335684   -0.187844     0.341852    -0.17206    -0.00990201   0.409103    0.176618   -0.566068   -0.680472     0.233669    -0.256193   -0.0294936    -0.140373   -0.388614   -0.0626833   -0.106823     0.434717   -0.0757415  -0.865693    0.0343663    0.189722   -0.339585    0.171446     0.0827808   -0.44396
  0.00929581  -0.269333    0.342431    -0.532669     0.0759983   0.186299    -0.353602   -0.300334    0.447984   -0.468429    -0.254498     0.169077   -0.165356     -0.168016    0.175245    0.276607     0.117164     0.292509   -0.134622   -0.176776    0.531261    -0.359598   -0.924907   -0.217209     0.293599     0.0989518
 -0.0314712    0.231589   -0.0753771   -0.0384151   -0.0929308   0.102969     0.0943336   0.0233799  -0.0390231  -0.0240302   -0.0250251   -0.107026    0.10926       0.0344291  -0.0291817   0.0138971    0.00653154   0.108934    0.0325399   0.0107506  -0.00993126   0.151201   -0.0973714   0.0482249   -0.0644914    0.0212906
 -0.188667    -0.252565   -0.208243     0.502012     0.0371909  -0.0509386    0.0979817   0.350116    0.274834   -0.0369987    0.635017    -0.371379   -0.222208     -0.100934   -0.38639     0.232296     0.337734    -0.18853    -0.164968   -0.280573   -0.235028    -0.0347895   0.902309    0.0746803   -0.359362     0.00504642
 -0.850231    -0.113227   -0.0555732   -0.0182428    0.044946    0.364359     0.528635    0.43057     0.319975    0.0512034   -0.102175     0.0905655   0.000704078  -0.343832   -0.33043    -0.157604    -0.360799     0.423524    0.203948   -0.190029   -0.605333     0.613259   -0.0670314  -0.316698    -0.268732    -0.176157
  0.0570648    0.320768   -0.26692     -0.435656    -0.528484   -0.711917    -0.649069   -0.245364    0.197105    0.00862203  -0.389626    -0.0291968   0.465586     -0.0295246   0.281598   -0.108615    -0.276149     0.0770826  -0.0929264   0.0593612   0.271846    -0.0245478  -0.96863     0.719358    -0.104961     0.758884
 -0.246295    -0.707554   -0.606751    -0.837129     0.595412    0.501875    -0.273916    0.104188    0.196934    0.0574713    0.341617     0.484163    0.725129     -0.163022   -0.224132    0.174771     0.222065    -0.420182    0.479723   -0.142454   -0.578622     0.344501   -0.297642    0.460606    -0.0419738   -0.786631
  0.11344      1.20888    -0.943993     0.233832     0.57509     0.259973     0.512283    0.588246   -0.09505    -0.0200991    0.117756     0.177301    0.535711     -0.0216109  -0.0536126  -0.281819    -0.307941     0.480116   -0.333607   -0.196312    0.225811     0.134528   -0.146374   -0.313114    -0.236716     0.372897
 -0.226508     0.481546   -0.253338    -1.10012     -0.51695    -0.0238684   -0.233284   -0.567835    0.0602888  -0.614524     0.236286     0.0992351  -0.15024       0.788393   -0.412397   -0.240526    -0.0254792   -0.408846    0.253453    0.536195    0.181411     0.264807    0.0379519  -0.399194     0.191471     0.312571
 -0.0581664   -0.300821    0.0123174   -0.867983    -0.27804    -0.322419    -0.343266    0.34055     0.245774    0.918556    -0.359931     0.276349   -0.0550404     0.145054    0.388665   -0.0690869    0.466616    -0.530102   -0.30067     0.750533   -0.0729382    0.326325    0.208026   -0.256886     0.186472     0.312627
  0.249082     0.435026   -0.475954     0.349844    -0.24081     0.243106     0.0565764  -0.564352    0.142992   -0.206272     0.454563    -0.581493   -0.465974     -0.325452    0.331298    0.642634    -0.427036     0.239469    0.395457    1.18668    -0.169311     0.120238   -0.107182   -0.690488    -0.00423074   0.119101
 -0.402621    -0.441882   -0.192849    -0.199188    -0.167598   -0.961651    -0.29873    -0.904318    0.171311    0.0937034    0.174446    -0.0414584   0.178854     -0.0278876   0.175504   -0.0913006   -0.0856694   -0.120375   -0.47197     0.756518   -0.104266    -0.357361   -0.182737    0.122337    -0.131598     0.0723194
 -0.328584     0.1373     -0.342056     0.45002      0.287487    1.21885     -0.11233    -0.297938    0.316851   -0.065391    -0.0362148    0.115906   -0.684958      0.41679    -0.0379343   0.239456     0.330925     0.618746    0.171148   -0.34676    -0.678104    -0.216719   -0.450593   -0.0238893   -0.243817     0.494583
  0.513755     0.386094    0.232236     0.281823    -0.162521    0.828243    -0.152682    0.367959    0.206613    0.144457    -0.131776     0.26915    -0.119152      0.0137427   0.105408   -0.347517    -0.143986    -0.37421     0.917203   -0.245561   -0.0497245    0.0607477   0.0378042   0.198747     0.561062     0.219012
  0.209602    -0.447038    0.12332      0.151863     0.175817   -0.00553984  -0.210985    0.0787534   0.216145    0.0490896   -0.0533162    0.221618   -0.246706     -0.110683    0.010829    0.0835928   -0.00426313  -0.11309    -0.0735486  -0.0833447  -0.0475001   -0.0367052   0.147845   -0.0147792    0.188838     0.055076
  0.703679     0.391902   -0.142425     0.142657     0.167763   -0.183185    -0.264936    0.187849   -0.49308     0.33712      0.301986     0.15848    -0.318629      0.250805   -0.264721   -0.669859    -0.282451    -0.258507    0.0505508  -0.0890973   0.0864383   -0.266969    0.613561   -0.467582    -0.0614761    0.141743
 -0.0476659    0.0934983  -0.147994     0.396413    -0.485546   -0.0868139    0.19492     0.329116   -0.696617    0.291858     0.704696    -0.333336    0.504994     -0.130238    0.267331    0.133589     0.059513     0.47641     0.823431   -0.385827   -0.42863     -0.467655   -0.227725    0.484971    -0.0923247    0.260652
 -0.217004    -0.330364   -0.466611    -0.0859774   -0.19988     0.0804138    0.317742   -0.214536   -0.754801    0.83238     -0.0566662   -0.759959   -0.102313      0.128895   -0.391989    1.09306     -0.404746     0.297507   -0.0189714   0.178662   -0.573587     0.0725323   0.195111   -0.284981     0.117834     0.140999
  0.0884033    0.280954   -0.0598669    0.0540879   -0.393481   -0.206175     0.470488    0.129111   -0.41552     0.202805    -0.0211888    0.712283   -0.121712      0.152086    0.144163   -0.0560065    0.307291     0.125097   -0.0886955   0.0477566  -0.228785     0.531366   -0.45309     0.422478     0.450281     0.0877019
  0.219707    -1.14402     0.705108    -0.290387    -0.0566773  -0.504056    -0.728408   -0.0894357   0.385728   -0.0119734   -0.114233    -0.204378   -0.236569     -0.380248   -0.0771782   0.330123    -0.0932151   -0.377059   -0.125388    0.164345    0.242686    -0.158296    0.409244   -0.0522236   -0.0943508   -0.178626
 -0.0818053    0.13498    -0.18313     -0.0506819    0.141987   -0.16704     -0.0787984   0.544943    0.611377    0.319581     0.00125278  -0.321044    0.226449      0.449988   -1.14588     0.161767     0.103516    -0.31418    -0.096149   -0.370976   -0.0410375   -0.288836   -0.117502    0.202001     0.286755     0.366237
  0.273214     0.47372     0.386204     0.419427     0.44293     0.200588     0.176626    0.0563208   0.391879    0.0452773    0.129506     0.103634   -0.31343      -0.567776   -0.338738   -0.276843    -0.28834     -0.109713   -0.224088   -0.189339    0.863398    -0.369166    0.0274721  -0.282034    -0.363487     0.418463
  0.182033    -0.240123   -0.134096    -0.00262103   0.386186    0.336731    -0.195096    0.0307172   1.0809     -0.0971565   -0.57862      0.359506   -0.367881      0.206768   -0.282981   -0.016765     0.184521    -0.64715    -0.495452    0.104344    0.277702     0.448234    0.163677    0.168262     0.246685     0.325314
  0.0419279   -0.0861344  -0.00240854   0.0319318   -0.0515952  -0.288674     0.114125   -0.0383754  -0.336459    0.113077     0.18403     -0.111131    0.115554     -0.186228    0.0603485   0.134582     0.0960973    0.195174   -0.0604081  -0.0546131   0.101855    -0.0342236   0.100901   -0.0180446   -0.0797675   -0.243585
 -0.032688    -0.0638887   0.55161      0.323745    -0.214895   -0.447266    -0.328113    0.67202     0.0784567   0.0435161   -0.16004      0.262942    0.448352     -0.024306   -0.0145027  -0.639148     0.255941    -0.356859   -0.204313   -0.0961374   0.496       -0.17632    -0.265974    0.965079     0.0626659   -0.433476
 -0.162889     0.158785   -0.224571    -0.735868     0.332337    0.231639    -0.217407    0.102175    0.104779   -0.119728    -0.28514     -0.689486    0.366075      0.148953    0.437569    0.209711    -0.685799    -0.167241    0.338414   -0.138262   -0.161544    -0.132868    0.469168   -0.0768558   -0.615249    -0.278017
  0.153117    -0.222488   -0.0363841    0.569868     0.0990525  -0.0024886   -0.014744   -0.217171   -0.839797   -0.246811     0.0639685    0.180138    0.263077     -0.19116     0.727173   -0.00699337   0.295534     0.61971     0.109153   -0.201745   -0.130275    -0.0879566   0.0495739   0.228908    -0.149328    -0.569011
 -0.203673    -0.113367    0.319115    -0.417583    -0.243763    0.0572593   -0.172634   -0.780374   -0.39704     0.476301    -0.349093     0.199836    0.026615     -0.385912    0.143715   -0.335802    -0.554303     0.0301748   0.462008    0.35388    -0.0135533    0.102842   -0.165136   -0.701297     0.071004    -0.167474
 -0.144087     0.37106    -0.133447     0.140602    -0.285407   -0.527436     0.448321   -0.386452   -0.203006   -0.132077    -0.0873405    0.295283   -0.6261        0.955174   -0.331612    0.0744876    0.0773357    0.417203   -0.754117    0.145913   -0.218859    -0.0145652   0.0531035  -0.00253374   0.0448805    0.578178
  0.783857     0.150376    0.136194    -0.00415708  -0.297831   -0.177953    -0.348268   -0.324646   -0.330184    0.0183715    0.134722    -0.145334    0.0592255     0.112091    0.511615    0.0476156    0.514403    -0.182299    0.0870562   0.102285    0.622318    -0.158525    0.0698242   0.171124     0.421729     0.227407[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409823
[ Info: iteration 2, average log likelihood -1.409813
[ Info: iteration 3, average log likelihood -1.409804
[ Info: iteration 4, average log likelihood -1.409795
[ Info: iteration 5, average log likelihood -1.409787
[ Info: iteration 6, average log likelihood -1.409778
[ Info: iteration 7, average log likelihood -1.409770
[ Info: iteration 8, average log likelihood -1.409762
[ Info: iteration 9, average log likelihood -1.409754
[ Info: iteration 10, average log likelihood -1.409746
┌ Info: EM with 100000 data points 10 iterations avll -1.409746
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
