Julia Version 1.6.0-DEV.203
Commit 4e2fb5c72c (2020-06-09 12:13 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed ScikitLearnBase ─ v0.5.0
  Installed DecisionTree ──── v0.10.2
Updating `~/.julia/environments/v1.6/Project.toml`
  [7806a523] + DecisionTree v0.10.2
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [7806a523] + DecisionTree v0.10.2
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [2a0f44e3] + Base64
  [8bb1440f] + DelimitedFiles
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [9a3f8284] + Random
  [9e88b42a] + Serialization
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
    Testing DecisionTree
Status `/tmp/jl_QA6KBt/Project.toml`
  [7806a523] DecisionTree v0.10.2
  [6e75b9c4] ScikitLearnBase v0.5.0
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [37e2e46d] LinearAlgebra
  [9a3f8284] Random
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_QA6KBt/Manifest.toml`
  [7806a523] DecisionTree v0.10.2
  [6e75b9c4] ScikitLearnBase v0.5.0
  [2a0f44e3] Base64
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [9a3f8284] Random
  [9e88b42a] Serialization
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
Julia version: 1.6.0-DEV.203
TEST: classification/random.jl 

Feature 2, Threshold 0.6056544585515548
L-> Feature 5, Threshold 0.3519102249662106
    L-> Feature 4, Threshold 0.3964305172913062
        L-> 1 : 61/97
        R-> 1 : 93/136
    R-> Feature 4, Threshold 0.5443369813935621
        L-> 0 : 116/195
        R-> 1 : 123/168
R-> Feature 3, Threshold 0.40770541203275457
    L-> Feature 5, Threshold 0.5034714805111138
        L-> 0 : 71/88
        R-> 0 : 50/82
    R-> Feature 1, Threshold 0.5347975865461467
        L-> 0 : 80/123
        R-> 1 : 77/111
random.jl: Test Failed at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/classification/random.jl:107
  Expression: length.(m1.trees) == length.(m2.trees)
   Evaluated: [121, 105, 110, 123, 110] == [101, 119, 104, 104, 111]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/classification/random.jl:107
 [2] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/classification/random.jl:4
random.jl: Test Failed at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/classification/random.jl:108
  Expression: depth.(m1.trees) == depth.(m2.trees)
   Evaluated: [14, 11, 11, 14, 10] == [11, 12, 12, 13, 11]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/classification/random.jl:108
 [2] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/classification/random.jl:4

##### nfoldCV Classification Tree #####

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0  18    1  0
 0  81   34  0
 0  42  139  0
 0   0   18  0
Accuracy: 0.6606606606606606
Kappa:    0.37203364373685793

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   25    0  0
 0  121   35  0
 0   35  100  0
 0    0   17  0
Accuracy: 0.6636636636636637
Kappa:    0.39973926898749457

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   18    0  0
 0  115   33  0
 0   33  115  0
 0    0   19  0
Accuracy: 0.6906906906906907
Kappa:    0.4432432432432432

Mean Accuracy: 0.6716716716716716

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0  18    1  0
 0  81   34  0
 0  42  139  0
 0   0   18  0
Accuracy: 0.6606606606606606
Kappa:    0.37203364373685793

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   25    0  0
 0  121   35  0
 0   35  100  0
 0    0   17  0
Accuracy: 0.6636636636636637
Kappa:    0.39973926898749457

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   18    0  0
 0  115   33  0
 0   33  115  0
 0    0   19  0
Accuracy: 0.6906906906906907
Kappa:    0.4432432432432432

Mean Accuracy: 0.6716716716716716

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   21    0  0
 0  104   39  0
 0   36  111  0
 0    0   22  0
Accuracy: 0.6456456456456456
Kappa:    0.3721197788501486

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   19    0  0
 0  103   36  0
 0   30  127  0
 0    0   18  0
Accuracy: 0.6906906906906907
Kappa:    0.4408744131455398

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   21    1  0
 0  110   28  0
 0   44  115  0
 0    0   14  0
Accuracy: 0.6756756756756757
Kappa:    0.41632990895369776

Mean Accuracy: 0.6706706706706708

##### nfoldCV Classification Forest #####

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 16    3    0   0
  0  114    1   0
  0    2  179   0
  0    0    0  18
Accuracy: 0.9819819819819819
Kappa:    0.9687792987061691

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 22    3    0   0
  0  156    0   0
  0    2  133   0
  0    0    1  16
Accuracy: 0.9819819819819819
Kappa:    0.9701171086283483

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 15    3    0   0
  0  148    0   0
  0    7  141   0
  0    0    1  18
Accuracy: 0.9669669669669669
Kappa:    0.9443963750626166

Mean Accuracy: 0.9769769769769768

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 15    4    0   0
  0  115    0   0
  0    2  178   1
  0    0    2  16
Accuracy: 0.972972972972973
Kappa:    0.9530272871181606

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 23    2    0   0
  0  155    1   0
  0    3  132   0
  0    0    1  16
Accuracy: 0.978978978978979
Kappa:    0.9652048005732028

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 14    4    0   0
  0  147    1   0
  0    3  145   0
  0    0    2  17
Accuracy: 0.96996996996997
Kappa:    0.9492517297083117

Mean Accuracy: 0.973973973973974

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 15    6    0   0
  0  142    1   0
  0    7  140   0
  0    0    3  19
Accuracy: 0.948948948948949
Kappa:    0.9152836598177276

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 16    3    0   0
  0  138    1   0
  0    3  154   0
  0    0    3  15
Accuracy: 0.96996996996997
Kappa:    0.9491548715129862

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 21    1    0   0
  0  137    1   0
  0    2  157   0
  0    0    2  12
Accuracy: 0.9819819819819819
Kappa:    0.96949571749187

Mean Accuracy: 0.9669669669669668
random.jl: Test Failed at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/classification/random.jl:139
  Expression: accuracy == accuracy2
   Evaluated: [0.9819819819819819, 0.9819819819819819, 0.9669669669669669] == [0.972972972972973, 0.978978978978979, 0.96996996996997]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/classification/random.jl:139
 [2] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/classification/random.jl:4

##### nfoldCV Adaboosted Stumps #####

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0  19    0  0
 0  78   37  0
 0  10  171  0
 0   0   18  0
Accuracy: 0.7477477477477478
Kappa:    0.5150317278685115

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   25    0  0
 0  131   25  0
 0   21  108  6
 0    0   17  0
Accuracy: 0.7177177177177178
Kappa:    0.5025506555423124

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   18    0  0
 2  126   20  0
 0   22  126  0
 0    0   19  0
Accuracy: 0.7567567567567568
Kappa:    0.5640022629919987

Mean Accuracy: 0.7407407407407408

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0  19    0  0
 0  78   37  0
 0  10  171  0
 0   0   18  0
Accuracy: 0.7477477477477478
Kappa:    0.5150317278685115

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   25    0  0
 0  131   25  0
 0   21  108  6
 0    0   17  0
Accuracy: 0.7177177177177178
Kappa:    0.5025506555423124

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   18    0  0
 2  126   20  0
 0   22  126  0
 0    0   19  0
Accuracy: 0.7567567567567568
Kappa:    0.5640022629919987

Mean Accuracy: 0.7407407407407408

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   21    0  0
 2  115   26  0
 0   18  129  0
 0    0   22  0
Accuracy: 0.7327327327327328
Kappa:    0.528118332643378

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   19    0  0
 0  120   19  0
 0   26  131  0
 0    0   18  0
Accuracy: 0.7537537537537538
Kappa:    0.5565624086524408

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Array{Int64,2}:
 0   22    0  0
 0  120   18  0
 0   25  133  1
 0    0   14  0
Accuracy: 0.7597597597597597
Kappa:    0.5674903399681788

Mean Accuracy: 0.7487487487487487
==================================================
TEST: classification/low_precision.jl 


##### nfoldCV Classification Tree #####

Fold 1
Classes:  Int32[-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6]
Matrix:   12×12 Array{Int64,2}:
 6   0   0   0   0   0   0   0   0   0  0  0
 0  17   0   0   0   0   0   0   0   0  0  0
 0   0  25   0   0   0   0   0   0   0  0  0
 0   0   0  36   0   0   0   0   0   0  0  0
 0   0   0   0  56   0   0   0   0   0  0  0
 0   0   0   0   0  57   0   0   0   0  0  0
 0   0   0   0   0   0  65   0   0   0  0  0
 0   0   0   0   0   0   0  31   0   0  0  0
 0   0   0   0   0   0   0   0  22   0  0  0
 0   0   0   0   0   0   0   0   0  12  0  0
 0   0   0   0   0   0   0   0   0   0  2  0
 0   0   0   0   0   0   0   0   0   0  0  4
Accuracy: 1.0
Kappa:    1.0

Fold 2
Classes:  Int32[-6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6]
Matrix:   13×13 Array{Int64,2}:
 1  0   0   0   0   0   0   0   0   0   0  0  0
 0  4   0   0   0   0   0   0   0   0   0  0  0
 0  0  13   0   0   0   0   0   0   0   0  0  0
 0  0   0  31   0   0   0   0   0   0   0  0  0
 0  0   0   0  40   0   0   0   0   0   0  0  0
 0  0   0   0   0  37   0   0   0   0   0  0  0
 0  0   0   0   0   0  63   0   0   0   0  0  0
 0  0   0   0   0   0   0  51   0   0   0  0  0
 0  0   0   0   0   0   0   0  45   0   0  0  0
 0  0   0   0   0   0   0   0   0  29   0  0  0
 0  0   0   0   0   0   0   0   0   0  10  0  0
 0  0   0   0   0   0   0   0   0   0   0  8  0
 0  0   0   0   0   0   0   0   0   0   0  0  1
Accuracy: 1.0
Kappa:    1.0

Fold 3
Classes:  Int32[-7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 7]
Matrix:   14×14 Array{Int64,2}:
 1  0  0   0   0   0   0   0   0   0   0   0  0  0
 0  1  0   0   0   0   0   0   0   0   0   0  0  0
 0  0  2   0   0   0   0   0   0   0   0   0  0  0
 0  0  0  15   0   0   0   0   0   0   0   0  0  0
 0  0  0   0  18   0   0   0   0   0   0   0  0  0
 0  0  0   0   0  37   0   0   0   0   0   0  0  0
 0  0  0   0   0   0  52   0   0   0   0   0  0  0
 0  0  0   0   0   0   0  43   0   0   0   0  0  0
 0  0  0   0   0   0   0   0  63   0   0   0  0  0
 0  0  0   0   0   0   0   0   0  52   0   0  0  0
 0  0  0   0   0   0   0   0   0   0  25   0  0  0
 0  0  0   0   0   0   0   0   0   0   0  14  0  0
 0  0  0   0   0   0   0   0   0   0   0   0  9  0
 0  0  0   0   0   0   0   0   0   0   0   0  0  1
Accuracy: 1.0
Kappa:    1.0

Mean Accuracy: 1.0

##### nfoldCV Classification Forest #####

Fold 1
Classes:  Int32[-6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7]
Matrix:   14×14 Array{Int64,2}:
 0  0   0   1   0   0   0   0   0   0  0  0  0  0
 0  0   5   2   0   1   0   0   0   0  0  0  0  0
 0  0  12   2   2   0   0   0   0   0  0  0  0  0
 0  0   3  11   2   1   3   0   0   0  0  0  0  0
 0  0   1   2  21   5   3   1   0   0  0  0  0  0
 0  0   1   2   1  40   4   0   1   0  0  0  0  0
 0  0   1   0   3   4  40   1   2   0  0  0  0  0
 0  0   0   0   0   4  15  33   6   1  0  0  0  0
 0  0   0   0   0   0   5   6  41   0  0  0  0  0
 0  0   0   0   0   1   0   1   5  14  1  0  0  0
 0  0   0   0   0   0   1   1   5   3  3  0  1  0
 0  0   0   0   0   1   0   0   1   0  2  1  0  0
 0  0   0   0   0   0   0   0   0   0  0  0  2  0
 0  0   0   0   0   0   0   0   0   1  0  0  0  0
Accuracy: 0.6546546546546547
Kappa:    0.6032757334659373

Fold 2
Classes:  Int32[-7, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6]
Matrix:   13×13 Array{Int64,2}:
 0  0   0   0   0   0   1   0   0   0  0  0  0
 0  0   0   1   0   0   0   0   0   0  0  0  0
 0  1  13   2   1   1   0   0   0   0  0  0  0
 0  0   3  18   6   3   1   0   0   0  0  0  0
 0  0   0   1  26   9   1   0   0   0  0  0  0
 0  0   0   1   0  42   5   0   0   0  0  0  0
 0  0   0   0   2   9  35   3   2   0  0  0  0
 0  0   0   0   0   3  11  41   7   0  0  0  0
 0  0   0   0   0   1   4   3  27   1  0  0  0
 0  0   0   0   0   0   1   1  15  13  0  0  0
 0  0   0   0   0   0   0   1   5   3  1  0  0
 0  0   0   0   0   0   0   1   2   1  0  1  0
 0  0   0   0   0   0   0   0   0   2  0  0  1
Accuracy: 0.6546546546546547
Kappa:    0.6032140747878525

Fold 3
Classes:  Int32[-6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]
Matrix:   12×12 Array{Int64,2}:
 0  0  0   1   0   0   0   0   0   0  0  0
 0  1  1   0   1   0   0   0   0   0  0  0
 0  0  7   1   0   2   1   0   0   0  0  0
 0  0  4  15   1   3   0   0   0   0  0  0
 0  0  1   2  23  10   6   1   0   0  0  0
 0  0  0   0   3  40   5   0   0   0  0  0
 0  0  0   0   0   6  46   4   5   0  0  0
 0  0  0   0   3   2   8  40   5   0  0  0
 0  0  0   0   0   1   5   6  28   0  0  0
 0  0  0   0   0   0   2   2   8  12  0  0
 0  0  0   0   0   0   0   0   4   2  5  1
 0  0  0   0   0   0   0   0   1   2  4  2
Accuracy: 0.6576576576576577
Kappa:    0.6037989876324167

Mean Accuracy: 0.6556556556556558

##### nfoldCV Adaboosted Stumps #####

Fold 1
Classes:  Int32[-6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]
Matrix:   12×12 Array{Int64,2}:
 0  0  0  0   1  0  0   0   0  0  0  0
 0  0  0  1   4  0  0   0   0  0  0  0
 0  0  0  2   6  3  0   0   2  0  0  0
 0  0  1  8   7  9  0   0   3  0  0  0
 0  0  5  5  14  6  0   4   4  1  0  0
 0  0  6  3  11  6  0   7   5  2  0  0
 0  0  6  3   6  6  0  21   8  8  0  0
 0  0  6  3   3  2  0  26  20  5  0  0
 0  0  1  1   1  2  0  25  14  4  0  0
 0  0  0  1   0  0  0  11   5  2  0  0
 0  0  0  0   0  0  0   6   4  1  0  0
 0  0  0  0   0  0  0   5   1  0  0  0
Accuracy: 0.21021021021021022
Kappa:    0.08725286865170766

Fold 2
Classes:  Int32[-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7]
Matrix:   13×13 Array{Int64,2}:
 0  0  0  0  0   1  0  0  0  0  0  0  0
 0  0  3  2  0   7  0  0  1  0  0  0  0
 0  0  1  0  0  18  0  0  0  0  0  0  0
 0  0  3  1  0  35  0  0  0  2  0  0  0
 0  0  1  3  0  51  0  0  2  0  0  0  0
 0  0  2  1  2  49  0  2  1  0  0  0  0
 0  0  0  2  2  46  0  4  0  1  0  0  0
 0  0  0  0  0  34  0  3  0  0  0  0  0
 0  0  0  0  1  16  0  5  4  0  0  0  0
 0  0  0  0  0   8  0  4  2  0  0  0  0
 0  0  0  0  1   3  0  3  2  0  0  0  0
 0  0  0  0  0   2  0  0  1  0  0  0  0
 0  0  0  0  0   0  0  1  0  0  0  0  0
Accuracy: 0.17417417417417416
Kappa:    0.01958160250096354

Fold 3
Classes:  Int32[-7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6]
Matrix:   14×14 Array{Int64,2}:
 0  0  0  0  0   1  0  0   0  0   0  0  0  0
 0  0  0  0  0   1  0  0   0  0   0  0  0  0
 0  0  0  0  0   2  0  1   3  0   0  0  0  0
 0  0  0  0  3   5  0  0  10  0   1  0  0  0
 0  0  0  0  3  10  2  0  12  0   0  0  0  0
 0  0  0  0  2   6  2  1  22  0   0  0  0  0
 0  0  0  1  3   3  2  0  38  0   2  0  0  0
 0  0  0  1  3   4  1  0  35  2   2  0  0  0
 0  0  0  0  0   0  1  0  49  3   4  1  0  0
 0  0  0  0  1   0  1  0  28  5   8  0  0  0
 0  0  0  0  0   0  0  0  18  2  11  0  0  0
 0  0  0  0  0   1  0  0   6  2   2  0  0  0
 0  0  0  0  0   0  0  0   2  2   0  0  0  0
 0  0  0  0  0   0  0  0   0  2   0  0  0  0
Accuracy: 0.22822822822822822
Kappa:    0.09121704133969057

Mean Accuracy: 0.20420420420420418
==================================================
TEST: classification/heterogeneous.jl 

==================================================
TEST: classification/digits.jl 

==================================================
TEST: classification/iris.jl 

Feature 4, Threshold 0.8
L-> Iris-setosa : 50/50
R-> Feature 4, Threshold 1.75
    L-> Feature 3, Threshold 4.95
        L-> Feature 4, Threshold 1.65
            L-> Iris-versicolor : 47/47
            R-> Iris-virginica : 1/1
        R-> Feature 4, Threshold 1.55
            L-> Iris-virginica : 3/3
            R-> Feature 3, Threshold 5.449999999999999
                L-> Iris-versicolor : 2/2
                R-> Iris-virginica : 1/1
    R-> Feature 3, Threshold 4.85
        L-> Feature 2, Threshold 3.1
            L-> Iris-virginica : 2/2
            R-> Iris-versicolor : 1/1
        R-> Iris-virginica : 43/43

##### nfoldCV Classification Tree #####

Fold 1
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Array{Int64,2}:
 18   0   0
  0  15   0
  0   0  17
Accuracy: 1.0
Kappa:    1.0

Fold 2
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Array{Int64,2}:
 18   0   0
  0  18   0
  0   0  14
Accuracy: 1.0
Kappa:    1.0

Fold 3
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Array{Int64,2}:
 14   0   0
  0  17   0
  0   0  19
Accuracy: 1.0
Kappa:    1.0

Mean Accuracy: 1.0

##### nfoldCV Classification Forest #####

Fold 1
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Array{Int64,2}:
 18   0   0
  0  15   1
  0   0  16
Accuracy: 0.98
Kappa:    0.969951923076923

Fold 2
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Array{Int64,2}:
 16   0   0
  0  16   2
  0   1  15
Accuracy: 0.94
Kappa:    0.9099639855942376

Fold 3
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Array{Int64,2}:
 16   0   0
  0  16   0
  0   0  18
Accuracy: 1.0
Kappa:    1.0

Mean Accuracy: 0.9733333333333333

##### nfoldCV Classification Adaboosted Stumps #####

Fold 1
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Array{Int64,2}:
 19   0   0
  0  19   1
  0   0  11
Accuracy: 0.98
Kappa:    0.9692685925015365

Fold 2
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Array{Int64,2}:
 11   0   0
  0  18   1
  0   3  17
Accuracy: 0.92
Kappa:    0.8765432098765433

Fold 3
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Array{Int64,2}:
 20   0   0
  0  10   1
  0   2  17
Accuracy: 0.94
Kappa:    0.9077490774907748

Mean Accuracy: 0.9466666666666667
==================================================
TEST: classification/adult.jl 

==================================================
TEST: classification/scikitlearn.jl 

==================================================
TEST: regression/random.jl 

random.jl: Error During Test at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/regression/random.jl:1
  Got exception outside of a @test
  TaskFailedException:
  InexactError: trunc(UInt64, 7.309049930327262e121)
  Stacktrace:
   [1] trunc at ./float.jl:682 [inlined]
   [2] floor at ./float.jl:363 [inlined]
   [3] hypergeometric_hyp at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/src/util.jl:237 [inlined]
   [4] hypergeometric(::Int64, ::Int64, ::Int64, ::MersenneTwister) at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/src/util.jl:296
   [5] _split!(::Array{Any,2}, ::Array{Float64,1}, ::Array{Float64,1}, ::DecisionTree.treeregressor.NodeMeta{Any}, ::Int64, ::Int64, ::Int64, ::Int64, ::Float64, ::Array{Int64,1}, ::Array{Any,1}, ::Array{Float64,1}, ::Array{Float64,1}, ::MersenneTwister) at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/src/regression/tree.jl:109
   [6] _fit(::Array{Any,2}, ::Array{Float64,1}, ::Array{Float64,1}, ::Int64, ::Int64, ::Int64, ::Int64, ::Float64, ::MersenneTwister) at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/src/regression/tree.jl:282
   [7] fit(; X::Array{Any,2}, Y::Array{Float64,1}, W::Nothing, max_features::Int64, max_depth::Int64, min_samples_leaf::Int64, min_samples_split::Int64, min_purity_increase::Float64, rng::MersenneTwister) at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/src/regression/tree.jl:328
   [8] build_tree(::Array{Float64,1}, ::Array{Any,2}, ::Int64, ::Int64, ::Int64, ::Int64, ::Float64; rng::MersenneTwister) at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/src/regression/main.jl:35
   [9] macro expansion at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/src/regression/main.jl:81 [inlined]
   [10] (::DecisionTree.var"#123#threadsfor_fun#35"{Array{Float64,1},Array{Any,2},Int64,Int64,Int64,Float64,Int64,Int64,MersenneTwister,Array{Union{Leaf{Float64}, Node{Any,Float64}},1},UnitRange{Int64}})(::Bool) at ./threadingconstructs.jl:81
   [11] (::DecisionTree.var"#123#threadsfor_fun#35"{Array{Float64,1},Array{Any,2},Int64,Int64,Int64,Float64,Int64,Int64,MersenneTwister,Array{Union{Leaf{Float64}, Node{Any,Float64}},1},UnitRange{Int64}})() at ./threadingconstructs.jl:48
  Stacktrace:
   [1] wait at ./task.jl:269 [inlined]
   [2] threading_run(::Function) at ./threadingconstructs.jl:34
   [3] macro expansion at ./threadingconstructs.jl:93 [inlined]
   [4] build_forest(::Array{Float64,1}, ::Array{Any,2}, ::Int64, ::Int64, ::Float64, ::Int64, ::Int64, ::Int64, ::Float64; rng::Int64) at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/src/regression/main.jl:79
   [5] top-level scope at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/regression/random.jl:161
   [6] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/regression/random.jl:3
   [8] include(::String) at ./client.jl:444
   [9] run_tests(::Array{String,1}) at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/runtests.jl:13
   [10] macro expansion at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/runtests.jl:51 [inlined]
   [11] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
   [12] macro expansion at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/runtests.jl:51 [inlined]
   [13] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
   [14] top-level scope at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/runtests.jl:46
   [15] include(::String) at ./client.jl:444
   [16] top-level scope at none:6
   [17] eval(::Module, ::Any) at ./boot.jl:331
   [18] exec_options(::Base.JLOptions) at ./client.jl:260
   [19] _start() at ./client.jl:485
  
==================================================
TEST: regression/low_precision.jl 


##### nfoldCV Regression Tree #####

Fold 1
Mean Squared Error:     0.953998693124603
Correlation Coeff:      0.9618843907204211
Coeff of Determination: 0.9250446829669072

Fold 2
Mean Squared Error:     0.8208320849016333
Correlation Coeff:      0.9659857438323732
Coeff of Determination: 0.9328855953695734

Fold 3
Mean Squared Error:     0.8045528440841636
Correlation Coeff:      0.9680701151453298
Coeff of Determination: 0.9370790138925564

Mean Coeff of Determination: 0.9316697640763456

##### nfoldCV Regression Forest #####

Fold 1
Mean Squared Error:     1.0450938762762443
Correlation Coeff:      0.971536587037108
Coeff of Determination: 0.9240386101349993

Fold 2
Mean Squared Error:     0.9784316084407781
Correlation Coeff:      0.9608625224859421
Coeff of Determination: 0.9105335732187779

Fold 3
Mean Squared Error:     1.0688794221074236
Correlation Coeff:      0.9664790719129952
Coeff of Determination: 0.9175626798548581

Mean Coeff of Determination: 0.9173782877362117
==================================================
TEST: regression/digits.jl 

==================================================
TEST: regression/scikitlearn.jl 

scikitlearn.jl: Test Failed at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/regression/scikitlearn.jl:31
  Expression: fit_predict!(RandomForestRegressor(; rng = 10), X, y) == fit_predict!(RandomForestRegressor(; rng = 10), X, y)
   Evaluated: [-0.3882530521254678, -0.12870146882712993, -0.1590847361402003, 0.1912065509040446, -0.4582784927290907, -0.2608758003155016, 0.1216378700453095, 0.0189476933205302, -0.12025063128395878, -0.2618037601857205  …  -0.35314823489640096, -0.31550631908486243, -0.2877133540567613, -0.26895658113585386, 0.33539610223350685, -0.10094519893600536, -0.15973333101049478, -0.41609867755400953, -0.4944815971215021, -0.6730521370075909] == [-0.8433631224734339, -0.4606987408885928, -0.22626148571122787, 0.3433451738009274, -0.6673893729280549, -0.48195428240678756, 0.10982975355441452, -0.4068077627728409, -0.15303224282500272, -0.23492429831399225  …  -0.0038207905264018294, -0.1983400571432191, -0.33855174062148147, -0.36437674269385845, 0.15956358167628978, 0.13005628491771987, -0.3133519505643857, 0.01120108430313943, -0.3786551174776892, -0.8377696956637399]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/regression/scikitlearn.jl:31
 [2] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/regression/scikitlearn.jl:3
==================================================
Test Summary:        | Pass  Fail  Error  Total
Test Suites          |  123     4      1    128
  Classification     |   85     3            88
    random.jl        |   25     3            28
    low_precision.jl |   16                  16
    heterogeneous.jl |    3                   3
    digits.jl        |    9                   9
    iris.jl          |   24                  24
    adult.jl         |    3                   3
    scikitlearn.jl   |    5                   5
  Regression         |   38     1      1     40
    random.jl        |   16            1     17
    low_precision.jl |   10                  10
    digits.jl        |    7                   7
    scikitlearn.jl   |    5     1             6
  Miscellaneous      |                    No tests
ERROR: LoadError: Some tests did not pass: 123 passed, 4 failed, 1 errored, 0 broken.
in expression starting at /home/pkgeval/.julia/packages/DecisionTree/NyDlA/test/runtests.jl:45
ERROR: Package DecisionTree errored during testing
Stacktrace:
 [1] pkgerror(::String) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Types.jl:52
 [2] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1561
 [3] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:327
 [4] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:314
 [5] #test#61 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:67 [inlined]
 [6] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:67 [inlined]
 [7] #test#60 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:66 [inlined]
 [8] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:66 [inlined]
 [9] test(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:65
 [10] test(::String) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:65
 [11] top-level scope at none:16
