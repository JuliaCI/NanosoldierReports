Julia Version 1.5.0-DEV.627
Commit b46fc558d3 (2020-04-14 16:34 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed InvertedIndices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
  Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+3
  Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.7
  Installed FilePathsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.0
  Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.33.0
  Installed Memento â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
  Installed MLJBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.7
  Installed TimeZones â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.1
  Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
  Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.9+2
  Installed MLJModelInterface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.1
  Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.4
  Installed Syslogs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.0
  Installed Formatting â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.1
  Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.1
  Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
  Installed ExprTools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.1.1
  Installed CompilerSupportLibraries_jll â”€ v0.3.3+0
  Installed MbedTLS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.1
  Installed Tables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.4
  Installed LossFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
  Installed Mocking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.1
  Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
  Installed Zlib_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.2.11+9
  Installed FixedPointNumbers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.0
  Installed Crayons â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v4.0.1
  Installed SpecialFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.10.0
  Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.8.0
  Installed ComputationalResources â”€â”€â”€â”€â”€â”€â”€ v0.3.2
  Installed HTTP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.13
  Installed TableTraits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
  Installed TranscodingStreams â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.5
  Installed OrderedCollections â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
  Installed ProgressMeter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.2.0
  Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
  Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.3.1
  Installed OpenSpecFun_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.3+3
  Installed CodecZlib â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.0
  Installed IniFile â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.0
  Installed Parsers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.1
  Installed PrettyTables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.4
  Installed DataStructures â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.17.12
  Installed MbedTLS_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.16.0+1
  Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.12
  Installed Libiconv_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.16.0+2
  Installed ScientificTypes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.2
  Installed IteratorInterfaceExtensions â”€â”€ v1.0.0
  Installed LearnBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.0
  Installed EzXML â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
  Installed JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.21.0
  Installed Reexport â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.0
  Installed Rmath_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.2+0
  Installed DataValueInterfaces â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
  Installed XML2_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.9.9+4
  Installed ColorTypes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.10.0
  Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
  Installed MLJScientificTypes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.3
  Installed JLSO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.3.1
  Installed CategoricalArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.7
  Installed Distributions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.23.2
  Installed SortingAlgorithms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
  Installed BSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.5
Updating `~/.julia/environments/v1.5/Project.toml`
  [a7f614a8] + MLJBase v0.12.7
Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+3
  [fbb218c0] + BSON v0.2.5
  [324d7699] + CategoricalArrays v0.7.7
  [944b1d66] + CodecZlib v0.7.0
  [3da002f7] + ColorTypes v0.10.0
  [34da2185] + Compat v3.8.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [ed09eef8] + ComputationalResources v0.3.2
  [a8cc5b0e] + Crayons v4.0.1
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.12
  [e2d170a0] + DataValueInterfaces v1.0.0
  [31c24e10] + Distributions v0.23.2
  [e2ba6199] + ExprTools v0.1.1
  [8f5d6c58] + EzXML v1.1.0
  [48062228] + FilePathsBase v0.8.0
  [1a297f60] + FillArrays v0.8.7
  [53c48c17] + FixedPointNumbers v0.8.0
  [59287772] + Formatting v0.4.1
  [cd3eb016] + HTTP v0.8.13
  [83e8ac13] + IniFile v0.5.0
  [41ab1584] + InvertedIndices v1.0.0
  [82899510] + IteratorInterfaceExtensions v1.0.0
  [9da8a3cd] + JLSO v2.3.1
  [682c06a0] + JSON v0.21.0
  [7f8f8fb0] + LearnBase v0.3.0
  [94ce4f54] + Libiconv_jll v1.16.0+2
  [30fc2ffe] + LossFunctions v0.6.0
  [a7f614a8] + MLJBase v0.12.7
  [e80e1ace] + MLJModelInterface v0.2.1
  [2e2323e0] + MLJScientificTypes v0.2.3
  [739be429] + MbedTLS v1.0.1
  [c8ffd9c3] + MbedTLS_jll v2.16.0+1
  [f28f55f0] + Memento v1.0.0
  [e1d29d7a] + Missings v0.4.3
  [78c3b35d] + Mocking v0.7.1
  [4536629a] + OpenBLAS_jll v0.3.9+2
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.12
  [d96e819e] + Parameters v0.12.0
  [69de0a69] + Parsers v1.0.1
  [08abe8d2] + PrettyTables v0.8.4
  [92933f4c] + ProgressMeter v1.2.0
  [1fd47b50] + QuadGK v2.3.1
  [3cdcf5f2] + RecipesBase v1.0.0
  [189a3867] + Reexport v0.2.0
  [79098fc4] + Rmath v0.6.1
  [f50d1b31] + Rmath_jll v0.2.2+0
  [321657f4] + ScientificTypes v0.7.2
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.10.0
  [2913bbd2] + StatsBase v0.33.0
  [4c63d2b9] + StatsFuns v0.9.4
  [cea106d9] + Syslogs v0.3.0
  [3783bdb8] + TableTraits v1.0.0
  [bd369af6] + Tables v1.0.4
  [f269a46b] + TimeZones v1.0.1
  [3bb67fe8] + TranscodingStreams v0.9.5
  [02c8fc9c] + XML2_jll v2.9.9+4
  [83775a58] + Zlib_jll v1.2.11+9
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8bb1440f] + DelimitedFiles
  [8ba89e20] + Distributed
  [9fa8497b] + Future
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [1a1011a3] + SharedArrays
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [4607b0f0] + SuiteSparse
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
   Building TimeZones â†’ `~/.julia/packages/TimeZones/zymSN/deps/build.log`
    Testing MLJBase
Status `/tmp/jl_VdUaaP/Project.toml`
  [336ed68f] CSV v0.3.1
  [324d7699] CategoricalArrays v0.7.7
  [ed09eef8] ComputationalResources v0.3.2
  [a93c6f00] DataFrames v0.20.2
  [7806a523] DecisionTree v0.10.1
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.23.2
  [cd3eb016] HTTP v0.8.13
  [41ab1584] InvertedIndices v1.0.0
  [9da8a3cd] JLSO v2.3.1
  [682c06a0] JSON v0.21.0
  [30fc2ffe] LossFunctions v0.6.0
  [a7f614a8] MLJBase v0.12.7
  [e80e1ace] MLJModelInterface v0.2.1
  [2e2323e0] MLJScientificTypes v0.2.3
  [e1d29d7a] Missings v0.4.3
  [6f286f6a] MultivariateStats v0.7.0
  [b8a86587] NearestNeighbors v0.4.4
  [bac558e1] OrderedCollections v1.1.0
  [d96e819e] Parameters v0.12.0
  [08abe8d2] PrettyTables v0.8.4
  [92933f4c] ProgressMeter v1.2.0
  [321657f4] ScientificTypes v0.7.2
  [2913bbd2] StatsBase v0.33.0
  [bd369af6] Tables v1.0.4
  [9d95f2ec] TypedTables v1.2.0
  [ade2ca70] Dates
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [9a3f8284] Random
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_VdUaaP/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+3
  [fbb218c0] BSON v0.2.5
  [336ed68f] CSV v0.3.1
  [324d7699] CategoricalArrays v0.7.7
  [944b1d66] CodecZlib v0.7.0
  [3da002f7] ColorTypes v0.10.0
  [34da2185] Compat v3.8.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [ed09eef8] ComputationalResources v0.3.2
  [a8cc5b0e] Crayons v4.0.1
  [9a962f9c] DataAPI v1.1.0
  [a93c6f00] DataFrames v0.20.2
  [9a8bc11e] DataStreams v0.4.2
  [864edb3b] DataStructures v0.17.12
  [e2d170a0] DataValueInterfaces v1.0.0
  [7806a523] DecisionTree v0.10.1
  [85a47980] Dictionaries v0.2.1
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.23.2
  [e2ba6199] ExprTools v0.1.1
  [8f5d6c58] EzXML v1.1.0
  [48062228] FilePathsBase v0.8.0
  [1a297f60] FillArrays v0.8.7
  [53c48c17] FixedPointNumbers v0.8.0
  [59287772] Formatting v0.4.1
  [cd3eb016] HTTP v0.8.13
  [313cdc1a] Indexing v1.1.0
  [83e8ac13] IniFile v0.5.0
  [7d512f48] InternedStrings v0.7.0
  [41ab1584] InvertedIndices v1.0.0
  [82899510] IteratorInterfaceExtensions v1.0.0
  [9da8a3cd] JLSO v2.3.1
  [682c06a0] JSON v0.21.0
  [7f8f8fb0] LearnBase v0.3.0
  [94ce4f54] Libiconv_jll v1.16.0+2
  [30fc2ffe] LossFunctions v0.6.0
  [a7f614a8] MLJBase v0.12.7
  [e80e1ace] MLJModelInterface v0.2.1
  [2e2323e0] MLJScientificTypes v0.2.3
  [739be429] MbedTLS v1.0.1
  [c8ffd9c3] MbedTLS_jll v2.16.0+1
  [f28f55f0] Memento v1.0.0
  [e1d29d7a] Missings v0.4.3
  [78c3b35d] Mocking v0.7.1
  [6f286f6a] MultivariateStats v0.7.0
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.9+2
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.12
  [d96e819e] Parameters v0.12.0
  [69de0a69] Parsers v1.0.1
  [2dfb63ee] PooledArrays v0.5.3
  [08abe8d2] PrettyTables v0.8.4
  [92933f4c] ProgressMeter v1.2.0
  [1fd47b50] QuadGK v2.3.1
  [3cdcf5f2] RecipesBase v1.0.0
  [189a3867] Reexport v0.2.0
  [79098fc4] Rmath v0.6.1
  [f50d1b31] Rmath_jll v0.2.2+0
  [321657f4] ScientificTypes v0.7.2
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.10.0
  [03a91e81] SplitApplyCombine v1.0.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.33.0
  [4c63d2b9] StatsFuns v0.9.4
  [cea106d9] Syslogs v0.3.0
  [3783bdb8] TableTraits v1.0.0
  [bd369af6] Tables v1.0.4
  [f269a46b] TimeZones v1.0.1
  [3bb67fe8] TranscodingStreams v0.9.5
  [9d95f2ec] TypedTables v1.2.0
  [ea10d353] WeakRefStrings v0.5.8
  [02c8fc9c] XML2_jll v2.9.9+4
  [83775a58] Zlib_jll v1.2.11+9
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [9fa8497b] Future
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [1a1011a3] SharedArrays
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [4607b0f0] SuiteSparse
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
[ Info: nprocs() = 41
[ Info: nthreads() = 2
Loading some models for testing...                                           Test Summary: | Pass  Total
misc          |   94     94
Test Summary: | Pass  Total
interface     |   78     78
Test Summary: | Pass  Total
measures      |  211    211
Progress:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                  |  ETA: 0:00:03[KProgress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:00[K
Progress:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                  |  ETA: 0:00:18[KProgress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
Progress:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                  |  ETA: 0:00:02[KProgress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    |  ETA: 0:00:00[KProgress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             |  ETA: 0:00:00[KProgress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:00[K
[ Info: Updating [34mMachine{Resampler{Holdout,â€¦}} @ 4â€¦33[39m.
[ Info: Updating [34mMachine{Resampler{Holdout,â€¦}} @ 1â€¦90[39m.
[ Info: Updating [34mMachine{Resampler{Holdout,â€¦}} @ 1â€¦43[39m.
[ Info: Distributing evaluations among 40 workers.
[ Info: Creating subsamples from a subset of all rows. 
[ Info: Training [34mMachine{Resampler{CV,â€¦}} @ 1â€¦65[39m.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Training [34mMachine{Resampler{CV,â€¦}} @ 4â€¦25[39m.
[ Info: Creating subsamples from a subset of all rows. 
[ Info: Training [34mMachine{Resampler{CV,â€¦}} @ 6â€¦52[39m.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Training [34mMachine{Resampler{CV,â€¦}} @ 1â€¦89[39m.
[ Info: Creating subsamples from a subset of all rows. 
[ Info: Training [34mMachine{Resampler{CV,â€¦}} @ 1â€¦02[39m.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Training [34mMachine{Resampler{CV,â€¦}} @ 7â€¦88[39m.
Test Summary: | Pass  Total
resampling    |  125    125
Test Summary: | Pass  Total
data          |  121    121
[ Info: Training [34mMachine{ConstantClassifier} @ 3â€¦23[39m.
[ Info: Training [34mMachine{ConstantClassifier} @ 1â€¦09[39m.
[ Info: Training [34mNodalMachine{Scale} @ 1â€¦06[39m.
[ Info: Training [34mMachine{DecisionTreeRegressor} @ 1â€¦97[39m.
[ Info: Training [34mMachine{DecisionTreeRegressor} @ 1â€¦96[39m.
[ Info: Training [34mMachine{DecisionTreeRegressor} @ 1â€¦77[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 6â€¦15[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦69[39m.
[ Info: Training [34mNodalMachine{SimpleDeterministicCompositeModel{FooBarRegressor,â€¦}} @ 5â€¦60[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦64[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦97[39m.
[ Info: Updating [34mNodalMachine{SimpleDeterministicCompositeModel{FooBarRegressor,â€¦}} @ 5â€¦60[39m.
[ Info: Updating [34mNodalMachine{FeatureSelector} @ 1â€¦64[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦97[39m.
[ Info: Training [34mNodalMachine{SimpleDeterministicCompositeModel{FooBarRegressor,â€¦}} @ 5â€¦60[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦55[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦03[39m.
[ Info: Training [34mMachine{WrappedRidge} @ 2â€¦41[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 5â€¦62[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 7â€¦71[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦76[39m.
[ Info: Updating [34mMachine{WrappedRidge} @ 2â€¦41[39m.
â”Œ Info: Not retraining [34mNodalMachine{Standardizer} @ 5â€¦62[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateBoxCoxTransformer} @ 7â€¦71[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Updating [34mNodalMachine{FooBarRegressor} @ 1â€¦76[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 4â€¦20[39m.
[ Info: Spawning 3 sub-features to one-hot encode feature :x1.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 6â€¦25[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 5â€¦96[39m.
[ Info: Training [34mNodalMachine{DecisionTreeRegressor} @ 1â€¦95[39m.
train_args = Source{:input}[[34mSource{:input} @ 7â€¦44[39m]
mach.model = [34mOneHotEncoder @ 1â€¦83[39m
train_args = Node{Nothing}[[34mNode{Nothing} @ 1â€¦07[39m]
mach.model = UnivariateStandardizer @ 1â€¦30
train_args = Node[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦80[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 1â€¦08[39m]
mach.model = [34mKNNRegressor @ 2â€¦67[39m
train_args = Node[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦80[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 1â€¦08[39m]
mach.model = [34mDecisionTreeRegressor @ 7â€¦89[39m
train_args = Source{:input}[[34mSource{:input} @ 1â€¦40[39m]
mach.model = [34mOneHotEncoder @ 1â€¦83[39m
train_args = Node{Nothing}[[34mNode{Nothing} @ 4â€¦12[39m]
mach.model = UnivariateStandardizer @ 9â€¦73
train_args = Node[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦04[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 3â€¦09[39m]
mach.model = [34mKNNRegressor @ 2â€¦67[39m
train_args = Node[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦04[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 3â€¦09[39m]
mach.model = [34mDecisionTreeRegressor @ 1â€¦31[39m
train_args = Source{:input}[[34mSource{:input} @ 3â€¦71[39m]
mach.model = [34mOneHotEncoder @ 7â€¦33[39m
train_args = Node{Nothing}[[34mNode{Nothing} @ 3â€¦46[39m]
mach.model = UnivariateStandardizer @ 8â€¦90
train_args = Node[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦22[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 9â€¦16[39m]
mach.model = [34mKNNRegressor @ 1â€¦21[39m
train_args = Node[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦22[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 9â€¦16[39m]
mach.model = [34mDecisionTreeRegressor @ 4â€¦08[39m
train_args = Source{:input}[[34mSource{:input} @ 1â€¦06[39m]
mach.model = [34mOneHotEncoder @ 6â€¦90[39m
train_args = Node{NodalMachine{OneHotEncoder}}[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦20[39m]
mach.model = [34mStandardizer @ 1â€¦73[39m
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦59[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 7â€¦01[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦59[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 7â€¦01[39m.
[ Info: Training [34mMachine{Composite3} @ 1â€¦28[39m.
train_args = Source{:input}[[34mSource{:input} @ 8â€¦22[39m]
mach.model = [34mStandardizer @ 1â€¦24[39m
train_args = AbstractNode[[34mNode{NodalMachine{Standardizer}} @ 6â€¦15[39m, [34mSource{:target} @ 9â€¦95[39m, [34mSource{:weights} @ 1â€¦59[39m]
mach.model = ConstantClassifier @ 1â€¦32
[ Info: Training [34mNodalMachine{Standardizer} @ 3â€¦27[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦54[39m.
[ Info: Training [34mMachine{Composite3} @ 1â€¦89[39m.
train_args = Source{:input}[[34mSource{:input} @ 6â€¦79[39m]
mach.model = [34mStandardizer @ 1â€¦96[39m
train_args = AbstractNode[[34mNode{NodalMachine{Standardizer}} @ 1â€¦19[39m, [34mSource{:target} @ 5â€¦60[39m, [34mSource{:weights} @ 6â€¦05[39m]
mach.model = ConstantClassifier @ 1â€¦32
[ Info: Training [34mNodalMachine{Standardizer} @ 9â€¦16[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦01[39m.
[ Info: Training [34mMachine{CompositeWithNoFields} @ 2â€¦66[39m.
train_args = Source{:input}[[34mSource{:input} @ 1â€¦01[39m]
mach.model = [34mStandardizer @ 1â€¦87[39m
train_args = AbstractNode[[34mNode{NodalMachine{Standardizer}} @ 1â€¦21[39m, [34mSource{:target} @ 5â€¦62[39m, [34mSource{:weights} @ 1â€¦58[39m]
mach.model = ConstantClassifier @ 1â€¦32
[ Info: Training [34mNodalMachine{Standardizer} @ 7â€¦01[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 7â€¦78[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦49[39m.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 4â€¦41[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦82[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦72[39m.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 1â€¦95[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 3â€¦38[39m.
[ Info: Updating [34mNodalMachine{FeatureSelector} @ 1â€¦49[39m.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateStandardizer} @ 4â€¦41[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦82[39m.
[ Info: Updating [34mNodalMachine{FeatureSelector} @ 1â€¦72[39m.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateStandardizer} @ 1â€¦95[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 3â€¦38[39m.
[ Info: Training [34mMachine{Pipe} @ 5â€¦69[39m.
train_args = Source{:input}[[34mSource{:input} @ 1â€¦16[39m]
mach.model = [34mFeatureSelector @ 1â€¦60[39m
train_args = Source{:target}[[34mSource{:target} @ 2â€¦49[39m]
mach.model = UnivariateStandardizer @ 7â€¦49
train_args = AbstractNode[[34mNode{NodalMachine{FeatureSelector}} @ 1â€¦65[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 6â€¦17[39m, [34mSource{:weights} @ 1â€¦28[39m]
mach.model = [34mKNNRegressor @ 1â€¦85[39m
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦05[39m.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 8â€¦36[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 3â€¦36[39m.
[ Info: Training [34mMachine{Pipe21} @ 3â€¦66[39m.
train_args = Source{:input}[[34mSource{:input} @ 4â€¦00[39m]
mach.model = [34mOneHotEncoder @ 1â€¦54[39m
train_args = AbstractNode[[34mNode{NodalMachine{OneHotEncoder}} @ 5â€¦51[39m, [34mSource{:target} @ 7â€¦98[39m, [34mSource{:weights} @ 1â€¦28[39m]
mach.model = ConstantClassifier @ 1â€¦32
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 2â€¦33[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 5â€¦42[39m.
[ Info: Training [34mMachine{Piper3} @ 7â€¦18[39m.
train_args = Source{:input}[[34mSource{:input} @ 1â€¦93[39m]
mach.model = [34mOneHotEncoder @ 8â€¦05[39m
train_args = AbstractNode[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦52[39m, [34mSource{:target} @ 1â€¦29[39m, [34mSource{:weights} @ 7â€¦68[39m]
mach.model = ConstantClassifier @ 1â€¦32
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 2â€¦05[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦31[39m.
[ Info: Training [34mMachine{Piper3} @ 1â€¦56[39m.
train_args = Source{:input}[[34mSource{:input} @ 1â€¦59[39m]
mach.model = [34mOneHotEncoder @ 8â€¦05[39m
train_args = AbstractNode[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦56[39m, [34mSource{:target} @ 1â€¦14[39m, [34mSource{:weights} @ 5â€¦30[39m]
mach.model = ConstantClassifier @ 1â€¦32
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦18[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦30[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦96[39m.
[ Info: Spawning 3 sub-features to one-hot encode feature :x3.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦36[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 5â€¦43[39m.
[ Info: Training [34mMachine{Pipe4} @ 6â€¦15[39m.
train_args = Source{:input}[[34mSource{:input} @ 1â€¦73[39m]
mach.model = [34mOneHotEncoder @ 6â€¦60[39m
train_args = Node{NodalMachine{OneHotEncoder}}[[34mNode{NodalMachine{OneHotEncoder}} @ 2â€¦69[39m]
mach.model = [34mFeatureSelector @ 1â€¦94[39m
train_args = Source{:target}[[34mSource{:target} @ 1â€¦06[39m]
mach.model = [34mStaticTransformer @ 5â€¦09[39m
train_args = AbstractNode[[34mNode{NodalMachine{FeatureSelector}} @ 1â€¦73[39m, [34mNode{NodalMachine{StaticTransformer}} @ 1â€¦87[39m, [34mSource{:weights} @ 1â€¦25[39m]
mach.model = [34mKNNRegressor @ 1â€¦13[39m
train_args = Node{NodalMachine{KNNRegressor}}[[34mNode{NodalMachine{KNNRegressor}} @ 1â€¦58[39m]
mach.model = [34mStaticTransformer @ 1â€¦41[39m
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦04[39m.
[ Info: Spawning 3 sub-features to one-hot encode feature :x3.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 3â€¦14[39m.
[ Info: Training [34mNodalMachine{StaticTransformer} @ 1â€¦07[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 9â€¦43[39m.
[ Info: Training [34mNodalMachine{StaticTransformer} @ 1â€¦58[39m.
[ Info: Training [34mMachine{Pipe9} @ 1â€¦54[39m.
train_args = Node{Nothing}[[34mNode{Nothing} @ 1â€¦95[39m]
mach.model = [34mOneHotEncoder @ 9â€¦16[39m
train_args = Source{:target}[[34mSource{:target} @ 1â€¦92[39m]
mach.model = UnivariateStandardizer @ 2â€¦34
train_args = AbstractNode[[34mNode{NodalMachine{OneHotEncoder}} @ 2â€¦40[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 4â€¦99[39m, [34mSource{:weights} @ 1â€¦58[39m]
mach.model = [34mKNNRegressor @ 3â€¦84[39m
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦51[39m.
[ Info: Spawning 2 sub-features to one-hot encode feature :gender.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 1â€¦43[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦56[39m.
[ Info: Training [34mMachine{Pipe99} @ 1â€¦88[39m.
train_args = Node{Nothing}[[34mNode{Nothing} @ 1â€¦18[39m]
mach.model = [34mOneHotEncoder @ 1â€¦74[39m
train_args = Node{NodalMachine{OneHotEncoder}}[[34mNode{NodalMachine{OneHotEncoder}} @ 5â€¦32[39m]
mach.model = [34mMyTransformer @ 3â€¦14[39m
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 6â€¦72[39m.
[ Info: Spawning 2 sub-features to one-hot encode feature :gender.
[ Info: Training [34mNodalMachine{MyTransformer} @ 4â€¦96[39m.
â”Œ Info: Not retraining [34mNodalMachine{KNNRegressor} @ 4â€¦55[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mMachine{KNNRegressor} @ 1â€¦60[39m.
[ Info: Training [34mNodalMachine{MyTransformer1} @ 1â€¦74[39m.
train_args = Node{Nothing}[[34mNode{Nothing} @ 3â€¦84[39m]
mach.model = [34mStandardizer @ 1â€¦73[39m
train_args = Source{:target}[[34mSource{:target} @ 3â€¦13[39m]
mach.model = [34mUnivariateBoxCoxTransformer @ 1â€¦74[39m
train_args = AbstractNode[[34mNode{NodalMachine{Standardizer}} @ 7â€¦12[39m, [34mNode{NodalMachine{UnivariateBoxCoxTransformer}} @ 1â€¦88[39m, [34mSource{:weights} @ 4â€¦18[39m]
mach.model = [34mKNNRegressor @ 1â€¦43[39m
train_args = Source{:input}[[34mSource{:input} @ 1â€¦83[39m]
mach.model = [34mMyTransformer @ 5â€¦16[39m
train_args = Node{NodalMachine{Main.TestLearningNetworks.MyTransformer}}[[34mNode{NodalMachine{MyTransformer}} @ 2â€¦11[39m]
mach.model = [34mStandardizer @ 2â€¦14[39m
train_args = Source{:target}[[34mSource{:target} @ 8â€¦77[39m]
mach.model = [34mUnivariateBoxCoxTransformer @ 6â€¦00[39m
train_args = AbstractNode[[34mNode{NodalMachine{Standardizer}} @ 1â€¦69[39m, [34mNode{NodalMachine{UnivariateBoxCoxTransformer}} @ 6â€¦88[39m, [34mSource{:weights} @ 1â€¦76[39m]
mach.model = [34mKNNRegressor @ 1â€¦30[39m
train_args = Node{Nothing}[[34mNode{Nothing} @ 1â€¦01[39m]
mach.model = [34mStandardizer @ 1â€¦76[39m
train_args = Source{:target}[[34mSource{:target} @ 1â€¦68[39m]
mach.model = [34mUnivariateBoxCoxTransformer @ 1â€¦73[39m
train_args = Node[[34mNode{NodalMachine{Standardizer}} @ 1â€¦43[39m, [34mNode{NodalMachine{UnivariateBoxCoxTransformer}} @ 1â€¦75[39m]
mach.model = [34mKNNRegressor @ 5â€¦75[39m
train_args = Union{}[]
mach.model = [34mMyTransformer @ 8â€¦90[39m
train_args = Node{NodalMachine{Main.TestLearningNetworks.MyTransformer}}[[34mNode{NodalMachine{MyTransformer}} @ 3â€¦92[39m]
mach.model = [34mStandardizer @ 2â€¦92[39m
train_args = Source{:target}[[34mSource{:target} @ 5â€¦76[39m]
mach.model = [34mUnivariateBoxCoxTransformer @ 8â€¦26[39m
train_args = Node[[34mNode{NodalMachine{Standardizer}} @ 1â€¦88[39m, [34mNode{NodalMachine{UnivariateBoxCoxTransformer}} @ 9â€¦44[39m]
mach.model = [34mKNNRegressor @ 1â€¦63[39m
[ Info: Training [34mNodalMachine{KNNRegressor} @ 7â€¦33[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 5â€¦31[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 8â€¦73[39m.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 1â€¦44[39m.
â”Œ Info: Not retraining [34mNodalMachine{Standardizer} @ 5â€¦31[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateBoxCoxTransformer} @ 8â€¦73[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Updating [34mNodalMachine{RidgeRegressor} @ 1â€¦44[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 4â€¦84[39m.
[ Info: Training [34mNodalMachine{PCA} @ 3â€¦49[39m.
â”Œ Info: Not retraining [34mNodalMachine{Standardizer} @ 4â€¦84[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
â”Œ Info: Not retraining [34mNodalMachine{PCA} @ 3â€¦49[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 1â€¦20[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦29[39m.
[ Info: Training [34mNodalMachine{PCA} @ 4â€¦76[39m.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 7â€¦80[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦50[39m.
[ Info: Training [34mNodalMachine{PCA} @ 1â€¦86[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 1â€¦67[39m.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 3â€¦53[39m.
[ Info: Training [34mNodalMachine{DecisionTreeRegressor} @ 1â€¦58[39m.
[ Info: Training [34mNodalMachine{DecisionTreeRegressor} @ 9â€¦87[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦69[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 1â€¦76[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 5â€¦40[39m.
[ Info: Training [34mNodalMachine{MyTransformer} @ 8â€¦22[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 4â€¦63[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 1â€¦74[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 8â€¦43[39m.
Test Summary:        | Pass  Total
machines+composition |  293    293
Test Summary: | Pass  Total
hyperparam    |  118    118
Test Summary: | Pass  Total
openml        |   15     15
â”Œ Warning: Forcibly interrupting busy workers
â”‚   exception = rmprocs: pids [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41] not terminated after 5.0 seconds.
â”” @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1234
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
    Testing MLJBase tests passed 
