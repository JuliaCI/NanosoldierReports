Julia Version 1.5.0-DEV.701
Commit 5cb3f3fbc1 (2020-04-28 13:13 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed CEnum ────────────── v0.2.0
  Installed Adapt ────────────── v1.0.1
  Installed Cthulhu ──────────── v1.0.2
  Installed OrderedCollections ─ v1.1.0
  Installed TimerOutputs ─────── v0.5.5
  Installed ExprTools ────────── v0.1.1
  Installed DataStructures ───── v0.17.14
  Installed CUDAnative ───────── v3.0.4
  Installed CodeTracking ─────── v0.5.9
  Installed CUDAapi ──────────── v4.0.0
  Installed BinaryProvider ───── v0.5.8
  Installed CUDAdrv ──────────── v6.2.3
  Installed LLVM ─────────────── v1.3.4
Updating `~/.julia/environments/v1.5/Project.toml`
  [be33ccc6] + CUDAnative v3.0.4
Updating `~/.julia/environments/v1.5/Manifest.toml`
  [79e6a3ab] + Adapt v1.0.1
  [b99e7846] + BinaryProvider v0.5.8
  [fa961155] + CEnum v0.2.0
  [3895d2a7] + CUDAapi v4.0.0
  [c5f51814] + CUDAdrv v6.2.3
  [be33ccc6] + CUDAnative v3.0.4
  [da1fd8a2] + CodeTracking v0.5.9
  [f68482b8] + Cthulhu v1.0.2
  [864edb3b] + DataStructures v0.17.14
  [e2ba6199] + ExprTools v0.1.1
  [929cbde3] + LLVM v1.3.4
  [bac558e1] + OrderedCollections v1.1.0
  [a759f4b9] + TimerOutputs v0.5.5
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [6462fe0b] + Sockets
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
    Testing CUDAnative
Status `/tmp/jl_LVO3Km/Project.toml`
  [79e6a3ab] Adapt v1.0.1
  [b99e7846] BinaryProvider v0.5.8
  [fa961155] CEnum v0.2.0
  [3895d2a7] CUDAapi v4.0.0
  [c5f51814] CUDAdrv v6.2.3
  [be33ccc6] CUDAnative v3.0.4
  [f68482b8] Cthulhu v1.0.2
  [864edb3b] DataStructures v0.17.14
  [e2ba6199] ExprTools v0.1.1
  [929cbde3] LLVM v1.3.4
  [a759f4b9] TimerOutputs v0.5.5
  [b77e0a4c] InteractiveUtils
  [8f399da3] Libdl
  [44cfe95a] Pkg
  [de0858da] Printf
  [8dfed614] Test
Status `/tmp/jl_LVO3Km/Manifest.toml`
  [79e6a3ab] Adapt v1.0.1
  [b99e7846] BinaryProvider v0.5.8
  [fa961155] CEnum v0.2.0
  [3895d2a7] CUDAapi v4.0.0
  [c5f51814] CUDAdrv v6.2.3
  [be33ccc6] CUDAnative v3.0.4
  [da1fd8a2] CodeTracking v0.5.9
  [f68482b8] Cthulhu v1.0.2
  [864edb3b] DataStructures v0.17.14
  [e2ba6199] ExprTools v0.1.1
  [929cbde3] LLVM v1.3.4
  [bac558e1] OrderedCollections v1.1.0
  [a759f4b9] TimerOutputs v0.5.5
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [6462fe0b] Sockets
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
WARNING: Method definition deque(Type{T}) where {T} in module DataStructures at /home/pkgeval/.julia/packages/DataStructures/w35Mo/src/deque.jl:89 overwritten at deprecated.jl:70.
  ** incremental compilation may be fatally broken for this module **

[ Info: Testing using device Tesla T4 (compute capability 7.5.0, 14.558 GiB available memory) on CUDA driver 10.2.0 and toolkit 10.2.89
non-isbits arguments: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:353
  Got exception outside of a @test
  GPU compilation of kernel1(Type{Int64}, Int64) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#kernel1#304",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#kernel1#304", ::Type{Tuple{Type{Int64},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157 [inlined]
   [16] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:358 [inlined]
   [17] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [18] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:354 [inlined]
   [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:169 [inlined]
   [21] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:5
   [23] include(::String) at ./client.jl:457
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:164 [inlined]
   [25] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [26] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [27] include(::String) at ./client.jl:457
   [28] top-level scope at none:6
   [29] eval(::Module, ::Any) at ./boot.jl:331
   [30] exec_options(::Base.JLOptions) at ./client.jl:272
   [31] _start() at ./client.jl:506
  
stack traces at different debug levels: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:558
  Got exception outside of a @test
  TypeError: non-boolean (Nothing) used in boolean context
  Stacktrace:
   [1] julia_script(::String, ::Cmd) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:80
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:573 [inlined]
   [3] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:560 [inlined]
   [5] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:558 [inlined]
   [7] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [8] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:5
   [9] include(::String) at ./client.jl:457
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:164 [inlined]
   [11] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [12] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [13] include(::String) at ./client.jl:457
   [14] top-level scope at none:6
   [15] eval(::Module, ::Any) at ./boot.jl:331
   [16] exec_options(::Base.JLOptions) at ./client.jl:272
   [17] _start() at ./client.jl:506
  
#329: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:600
  Got exception outside of a @test
  TypeError: non-boolean (Nothing) used in boolean context
  Stacktrace:
   [1] julia_script(::String, ::Cmd) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:80
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:613 [inlined]
   [3] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:602 [inlined]
   [5] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:558 [inlined]
   [7] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [8] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:5
   [9] include(::String) at ./client.jl:457
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:164 [inlined]
   [11] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [12] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [13] include(::String) at ./client.jl:457
   [14] top-level scope at none:6
   [15] eval(::Module, ::Any) at ./boot.jl:331
   [16] exec_options(::Base.JLOptions) at ./client.jl:272
   [17] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
  Got exception outside of a @test
  GPU compilation of #2462#kernel(CuDeviceArray{Int32,1,CUDAnative.AS.Global}, Type{Int32}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2462#kernel#611",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2462#kernel#611", ::Type{Tuple{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Type{Int32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:994
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
  Got exception outside of a @test
  GPU compilation of #2462#kernel(CuDeviceArray{Int64,1,CUDAnative.AS.Global}, Type{Int64}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2462#kernel#611",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2462#kernel#611", ::Type{Tuple{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Type{Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:994
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
  Got exception outside of a @test
  GPU compilation of #2462#kernel(CuDeviceArray{UInt32,1,CUDAnative.AS.Global}, Type{UInt32}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2462#kernel#611",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2462#kernel#611", ::Type{Tuple{CuDeviceArray{UInt32,1,CUDAnative.AS.Global},Type{UInt32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:994
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
  Got exception outside of a @test
  GPU compilation of #2462#kernel(CuDeviceArray{UInt64,1,CUDAnative.AS.Global}, Type{UInt64}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2462#kernel#611",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2462#kernel#611", ::Type{Tuple{CuDeviceArray{UInt64,1,CUDAnative.AS.Global},Type{UInt64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:994
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
  Got exception outside of a @test
  GPU compilation of #2466#kernel(CuDeviceArray{Int32,1,CUDAnative.AS.Global}, Type{Int32}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2466#kernel#612",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2466#kernel#612", ::Type{Tuple{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Type{Int32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1014
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
  Got exception outside of a @test
  GPU compilation of #2466#kernel(CuDeviceArray{Int64,1,CUDAnative.AS.Global}, Type{Int64}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2466#kernel#612",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2466#kernel#612", ::Type{Tuple{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Type{Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1014
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
  Got exception outside of a @test
  GPU compilation of #2466#kernel(CuDeviceArray{UInt64,1,CUDAnative.AS.Global}, Type{UInt64}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2466#kernel#612",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2466#kernel#612", ::Type{Tuple{CuDeviceArray{UInt64,1,CUDAnative.AS.Global},Type{UInt64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1014
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
  Got exception outside of a @test
  GPU compilation of #2470#kernel(CuDeviceArray{Int32,1,CUDAnative.AS.Global}, Type{Int32}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2470#kernel#613",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2470#kernel#613", ::Type{Tuple{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Type{Int32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1034
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
  Got exception outside of a @test
  GPU compilation of #2470#kernel(CuDeviceArray{Int64,1,CUDAnative.AS.Global}, Type{Int64}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2470#kernel#613",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2470#kernel#613", ::Type{Tuple{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Type{Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1034
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
  Got exception outside of a @test
  GPU compilation of #2470#kernel(CuDeviceArray{UInt32,1,CUDAnative.AS.Global}, Type{UInt32}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2470#kernel#613",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2470#kernel#613", ::Type{Tuple{CuDeviceArray{UInt32,1,CUDAnative.AS.Global},Type{UInt32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1034
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
  Got exception outside of a @test
  GPU compilation of #2470#kernel(CuDeviceArray{UInt64,1,CUDAnative.AS.Global}, Type{UInt64}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2470#kernel#613",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2470#kernel#613", ::Type{Tuple{CuDeviceArray{UInt64,1,CUDAnative.AS.Global},Type{UInt64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1034
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
  Got exception outside of a @test
  GPU compilation of #2478#kernel(CuDeviceArray{Int32,1,CUDAnative.AS.Global}, Type{Int32}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2478#kernel#615",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2478#kernel#615", ::Type{Tuple{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Type{Int32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1070
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1058
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
  Got exception outside of a @test
  GPU compilation of #2478#kernel(CuDeviceArray{Int64,1,CUDAnative.AS.Global}, Type{Int64}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2478#kernel#615",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2478#kernel#615", ::Type{Tuple{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Type{Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1070
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1058
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
  Got exception outside of a @test
  GPU compilation of #2478#kernel(CuDeviceArray{UInt32,1,CUDAnative.AS.Global}, Type{UInt32}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2478#kernel#615",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2478#kernel#615", ::Type{Tuple{CuDeviceArray{UInt32,1,CUDAnative.AS.Global},Type{UInt32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1070
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1058
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
  Got exception outside of a @test
  GPU compilation of #2478#kernel(CuDeviceArray{UInt64,1,CUDAnative.AS.Global}, Type{UInt64}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2478#kernel#615",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2478#kernel#615", ::Type{Tuple{CuDeviceArray{UInt64,1,CUDAnative.AS.Global},Type{UInt64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1070
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1058
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
  Got exception outside of a @test
  GPU compilation of #2478#kernel(CuDeviceArray{Float32,1,CUDAnative.AS.Global}, Type{Float32}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Float32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2478#kernel#615",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2478#kernel#615", ::Type{Tuple{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Type{Float32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1070
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1058
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Float64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
  Got exception outside of a @test
  GPU compilation of #2478#kernel(CuDeviceArray{Float64,1,CUDAnative.AS.Global}, Type{Float64}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Float64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2478#kernel#615",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2478#kernel#615", ::Type{Tuple{CuDeviceArray{Float64,1,CUDAnative.AS.Global},Type{Float64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1070
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1058
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
  Got exception outside of a @test
  GPU compilation of #2482#kernel(CuDeviceArray{Int32,1,CUDAnative.AS.Global}, Type{Int32}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2482#kernel#616",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2482#kernel#616", ::Type{Tuple{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Type{Int32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1088
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1076
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
  Got exception outside of a @test
  GPU compilation of #2482#kernel(CuDeviceArray{Int64,1,CUDAnative.AS.Global}, Type{Int64}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2482#kernel#616",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2482#kernel#616", ::Type{Tuple{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Type{Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1088
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1076
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
  Got exception outside of a @test
  GPU compilation of #2482#kernel(CuDeviceArray{UInt32,1,CUDAnative.AS.Global}, Type{UInt32}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2482#kernel#616",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2482#kernel#616", ::Type{Tuple{CuDeviceArray{UInt32,1,CUDAnative.AS.Global},Type{UInt32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1088
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1076
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
  Got exception outside of a @test
  GPU compilation of #2482#kernel(CuDeviceArray{UInt64,1,CUDAnative.AS.Global}, Type{UInt64}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2482#kernel#616",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2482#kernel#616", ::Type{Tuple{CuDeviceArray{UInt64,1,CUDAnative.AS.Global},Type{UInt64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1088
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1076
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
  Got exception outside of a @test
  GPU compilation of #2482#kernel(CuDeviceArray{Float32,1,CUDAnative.AS.Global}, Type{Float32}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Float32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2482#kernel#616",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2482#kernel#616", ::Type{Tuple{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Type{Float32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1088
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1076
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Float64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
  Got exception outside of a @test
  GPU compilation of #2482#kernel(CuDeviceArray{Float64,1,CUDAnative.AS.Global}, Type{Float64}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 3 to your kernel function is of type Type{Float64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2482#kernel#616",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2482#kernel#616", ::Type{Tuple{CuDeviceArray{Float64,1,CUDAnative.AS.Global},Type{Float64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1088
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1076
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
  Got exception outside of a @test
  GPU compilation of #2492#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2492#kernel#619",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2492#kernel#619", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1142
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1130
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
  Got exception outside of a @test
  GPU compilation of #2492#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2492#kernel#619",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2492#kernel#619", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1142
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1130
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
  Got exception outside of a @test
  GPU compilation of #2492#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2492#kernel#619",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2492#kernel#619", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1142
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1130
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
  Got exception outside of a @test
  GPU compilation of #2492#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2492#kernel#619",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2492#kernel#619", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1142
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1130
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
  Got exception outside of a @test
  GPU compilation of #2492#kernel(Type{Float32}, CuDeviceArray{Float32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Float32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2492#kernel#619",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2492#kernel#619", ::Type{Tuple{Type{Float32},CuDeviceArray{Float32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1142
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1130
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Float64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
  Got exception outside of a @test
  GPU compilation of #2492#kernel(Type{Float64}, CuDeviceArray{Float64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Float64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2492#kernel#619",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2492#kernel#619", ::Type{Tuple{Type{Float64},CuDeviceArray{Float64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1142
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1130
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
  Got exception outside of a @test
  GPU compilation of #2495#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2495#kernel#620",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2495#kernel#620", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1157
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
  Got exception outside of a @test
  GPU compilation of #2495#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2495#kernel#620",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2495#kernel#620", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1157
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
  Got exception outside of a @test
  GPU compilation of #2495#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2495#kernel#620",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2495#kernel#620", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1157
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
  Got exception outside of a @test
  GPU compilation of #2495#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2495#kernel#620",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2495#kernel#620", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1157
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
  Got exception outside of a @test
  GPU compilation of #2498#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2498#kernel#621",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2498#kernel#621", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1174
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
  Got exception outside of a @test
  GPU compilation of #2498#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2498#kernel#621",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2498#kernel#621", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1174
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
  Got exception outside of a @test
  GPU compilation of #2498#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2498#kernel#621",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2498#kernel#621", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1174
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
  Got exception outside of a @test
  GPU compilation of #2498#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2498#kernel#621",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2498#kernel#621", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1174
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
  Got exception outside of a @test
  GPU compilation of #2501#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2501#kernel#622",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2501#kernel#622", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1192
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
  Got exception outside of a @test
  GPU compilation of #2501#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2501#kernel#622",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2501#kernel#622", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1192
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
  Got exception outside of a @test
  GPU compilation of #2501#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2501#kernel#622",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2501#kernel#622", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1192
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
  Got exception outside of a @test
  GPU compilation of #2501#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2501#kernel#622",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2501#kernel#622", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1192
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
  Got exception outside of a @test
  GPU compilation of #2504#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2504#kernel#623",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2504#kernel#623", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1211
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
  Got exception outside of a @test
  GPU compilation of #2504#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2504#kernel#623",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2504#kernel#623", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1211
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
  Got exception outside of a @test
  GPU compilation of #2504#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2504#kernel#623",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2504#kernel#623", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1211
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
  Got exception outside of a @test
  GPU compilation of #2504#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2504#kernel#623",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2504#kernel#623", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1211
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
  Got exception outside of a @test
  GPU compilation of #2507#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2507#kernel#624",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2507#kernel#624", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1227
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
  Got exception outside of a @test
  GPU compilation of #2507#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2507#kernel#624",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2507#kernel#624", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1227
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
  Got exception outside of a @test
  GPU compilation of #2507#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2507#kernel#624",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2507#kernel#624", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1227
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
  Got exception outside of a @test
  GPU compilation of #2507#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2507#kernel#624",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2507#kernel#624", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1227
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
  Got exception outside of a @test
  GPU compilation of #2510#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2510#kernel#625",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2510#kernel#625", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1242
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
  Got exception outside of a @test
  GPU compilation of #2510#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2510#kernel#625",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2510#kernel#625", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1242
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
  Got exception outside of a @test
  GPU compilation of #2510#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2510#kernel#625",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2510#kernel#625", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1242
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
  Got exception outside of a @test
  GPU compilation of #2510#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2510#kernel#625",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2510#kernel#625", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1242
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
 ──────────────────────────────────────────────────────────────────────────────
                                       Time                   Allocations      
                               ──────────────────────   ───────────────────────
       Tot / % measured:             628s / 9.71%           13.6GiB / 15.7%    

 Section               ncalls     time   %tot     avg     alloc   %tot      avg
 ──────────────────────────────────────────────────────────────────────────────
 LLVM middle-end          631    38.9s  63.8%  61.7ms    753MiB  34.5%  1.19MiB
   IR generation          631    21.1s  34.5%  33.4ms    705MiB  32.3%  1.12MiB
     emission             631    9.49s  15.5%  15.0ms    466MiB  21.4%   757KiB
     rewrite              631    8.78s  14.4%  13.9ms    176MiB  8.08%   286KiB
       hide unreach...  7.86k    4.28s  7.01%   544μs   32.7MiB  1.50%  4.26KiB
         find           7.86k    3.52s  5.77%   448μs   2.36MiB  0.11%     315B
         predecessors   7.86k    483ms  0.79%  61.4μs   11.7MiB  0.54%  1.53KiB
         replace        7.86k    184ms  0.30%  23.4μs   2.50MiB  0.11%     333B
       lower throw        631    1.70s  2.78%  2.69ms   59.9MiB  2.74%  97.2KiB
       hide trap          631    234ms  0.38%   371μs   4.52MiB  0.21%  7.34KiB
     clean-up             631    110ms  0.18%   174μs   6.82MiB  0.31%  11.1KiB
   optimization           625    11.6s  19.0%  18.5ms   38.4MiB  1.76%  63.0KiB
   device library          37    5.46s  8.95%   148ms    505KiB  0.02%  13.6KiB
   runtime library        248    657ms  1.08%  2.65ms    688KiB  0.03%  2.77KiB
 validation             1.16k    19.0s  31.1%  16.3ms   1.38GiB  64.9%  1.22MiB
 LLVM back-end            362    2.09s  3.42%  5.77ms   4.34MiB  0.20%  12.3KiB
   machine-code gen...    362    1.88s  3.07%  5.18ms   1.36MiB  0.06%  3.85KiB
   preparation            362    210ms  0.34%   581μs   2.98MiB  0.14%  8.42KiB
 device runtime lib...      9    948ms  1.55%   105ms   9.01MiB  0.41%  1.00MiB
 Julia front-end          632   74.7ms  0.12%   118μs    208KiB  0.01%     338B
 strip debug info          30    219μs  0.00%  7.31μs     0.00B  0.00%    0.00B
 ──────────────────────────────────────────────────────────────────────────────
Test Summary:                                                  | Pass  Error  Broken  Total
CUDAnative                                                     |  540     56     128    724
  base interface                                               |                      No tests
  pointer                                                      |   20                    20
  code generation                                              |   84                    84
  code generation (relying on a device)                        |    8                     8
  execution                                                    |   73      3             76
    @cuda                                                      |   14                    14
    argument passing                                           |   30      1             31
      manually allocated                                       |    1                     1
      scalar through single-value array                        |    1                     1
      scalar through single-value array, using device function |    1                     1
      tuples                                                   |    1                     1
      ghost function parameters                                |    2                     2
      immutables                                               |    1                     1
      automatic recompilation                                  |    2                     2
      automatic recompilation (bis)                            |    2                     2
      non-isbits arguments                                     |           1              1
      splatting                                                |    3                     3
      object invoke                                            |    1                     1
      closures                                                 |    1                     1
      conversions                                              |    8                     8
      argument count                                           |    4                     4
      keyword arguments                                        |                      No tests
      captured values                                          |    2                     2
    exceptions                                                 |           2              2
      stack traces at different debug levels                   |           1              1
      #329                                                     |           1              1
    shmem divergence bug                                       |    7                     7
    dynamic parallelism                                        |   11                    11
    cooperative groups                                         |    1                     1
    threading                                                  |   10                    10
  pointer                                                      |   37                    37
  device arrays                                                |   20                    20
  CUDA functionality                                           |  199     53            252
    indexing                                                   |    1                     1
    math                                                       |   71                    71
    formatted output                                           |    6                     6
    @cuprint                                                   |   27                    27
    assertion                                                  |                      No tests
    shared memory                                              |   14                    14
    data movement and conversion                               |   17                    17
    clock and nanosleep                                        |                      No tests
    parallel synchronization and communication                 |   16                    16
    libcudadevrt                                               |                      No tests
    atomics (low-level)                                        |   27     23             50
      atomic_add                                               |    6                     6
      atomic_sub                                               |    6                     6
      atomic_inc                                               |    1                     1
      atomic_dec                                               |    1                     1
      atomic_xchg                                              |    4                     4
      atomic_and                                               |           4              4
        T = Int32                                              |           1              1
        T = Int64                                              |           1              1
        T = UInt32                                             |           1              1
        T = UInt64                                             |           1              1
      atomic_or                                                |    1      3              4
        T = Int32                                              |           1              1
        T = Int64                                              |           1              1
        T = UInt32                                             |    1                     1
        T = UInt64                                             |           1              1
      atomic_xor                                               |           4              4
        T = Int32                                              |           1              1
        T = Int64                                              |           1              1
        T = UInt32                                             |           1              1
        T = UInt64                                             |           1              1
      atomic_cas                                               |    4                     4
      atomic_max                                               |           6              6
        T = Int32                                              |           1              1
        T = Int64                                              |           1              1
        T = UInt32                                             |           1              1
        T = UInt64                                             |           1              1
        T = Float32                                            |           1              1
        T = Float64                                            |           1              1
      atomic_min                                               |           6              6
        T = Int32                                              |           1              1
        T = Int64                                              |           1              1
        T = UInt32                                             |           1              1
        T = UInt64                                             |           1              1
        T = Float32                                            |           1              1
        T = Float64                                            |           1              1
      atomic_mul                                               |    2                     2
      atomic_div                                               |    2                     2
    atomics (high-level)                                       |   20     30             50
      add                                                      |           6              6
        T = Int32                                              |           1              1
        T = Int64                                              |           1              1
        T = UInt32                                             |           1              1
        T = UInt64                                             |           1              1
        T = Float32                                            |           1              1
        T = Float64                                            |           1              1
      sub                                                      |           4              4
        T = Int32                                              |           1              1
        T = Int64                                              |           1              1
        T = UInt32                                             |           1              1
        T = UInt64                                             |           1              1
      and                                                      |           4              4
        T = Int32                                              |           1              1
        T = Int64                                              |           1              1
        T = UInt32                                             |           1              1
        T = UInt64                                             |           1              1
      or                                                       |           4              4
        T = Int32                                              |           1              1
        T = Int64                                              |           1              1
        T = UInt32                                             |           1              1
        T = UInt64                                             |           1              1
      xor                                                      |           4              4
        T = Int32                                              |           1              1
        T = Int64                                              |           1              1
        T = UInt32                                             |           1              1
        T = UInt64                                             |           1              1
      max                                                      |           4              4
        T = Int32                                              |           1              1
        T = Int64                                              |           1              1
        T = UInt32                                             |           1              1
        T = UInt64                                             |           1              1
      min                                                      |           4              4
        T = Int32                                              |           1              1
        T = Int64                                              |           1              1
        T = UInt32                                             |           1              1
        T = UInt64                                             |           1              1
      macro                                                    |   20                    20
  WMMA                                                         |   82            128    210
  NVTX                                                         |                      No tests
  examples                                                     |    6                     6
ERROR: LoadError: Some tests did not pass: 540 passed, 0 failed, 56 errored, 128 broken.
in expression starting at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:12
ERROR: Package CUDAnative errored during testing
Stacktrace:
 [1] pkgerror(::String, ::Vararg{String,N} where N) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/Types.jl:52
 [2] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/Operations.jl:1515
 [3] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:316
 [4] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:303
 [5] #test#68 at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:297 [inlined]
 [6] test at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:297 [inlined]
 [7] #test#67 at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:296 [inlined]
 [8] test at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:296 [inlined]
 [9] test(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:295
 [10] test(::String) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:295
 [11] top-level scope at none:16
