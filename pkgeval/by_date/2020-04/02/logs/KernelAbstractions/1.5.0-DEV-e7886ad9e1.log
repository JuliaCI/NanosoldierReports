Julia Version 1.5.0-DEV.565
Commit e7886ad9e1 (2020-04-02 17:34 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed Adapt ────────────── v1.0.1
  Installed CEnum ────────────── v0.2.0
  Installed StaticArrays ─────── v0.12.1
  Installed BinaryProvider ───── v0.5.8
  Installed Cassette ─────────── v0.3.1
  Installed KernelAbstractions ─ v0.2.1
  Installed CUDAdrv ──────────── v6.2.2
  Installed LLVM ─────────────── v1.3.4
  Installed Cthulhu ──────────── v1.0.0
  Installed CUDAapi ──────────── v4.0.0
  Installed TerminalMenus ────── v0.1.0
  Installed Requires ─────────── v1.0.1
  Installed TimerOutputs ─────── v0.5.3
  Installed Compat ───────────── v2.2.0
  Installed MacroTools ───────── v0.5.5
  Installed CodeTracking ─────── v0.5.8
  Installed CUDAnative ───────── v3.0.2
  Installed OrderedCollections ─ v1.1.0
  Installed DataStructures ───── v0.17.11
   Updating `~/.julia/environments/v1.5/Project.toml`
   63c18a36 + KernelAbstractions v0.2.1
   Updating `~/.julia/environments/v1.5/Manifest.toml`
   79e6a3ab + Adapt v1.0.1
   b99e7846 + BinaryProvider v0.5.8
   fa961155 + CEnum v0.2.0
   3895d2a7 + CUDAapi v4.0.0
   c5f51814 + CUDAdrv v6.2.2
   be33ccc6 + CUDAnative v3.0.2
   7057c7e9 + Cassette v0.3.1
   da1fd8a2 + CodeTracking v0.5.8
   34da2185 + Compat v2.2.0
   f68482b8 + Cthulhu v1.0.0
   864edb3b + DataStructures v0.17.11
   63c18a36 + KernelAbstractions v0.2.1
   929cbde3 + LLVM v1.3.4
   1914dd2f + MacroTools v0.5.5
   bac558e1 + OrderedCollections v1.1.0
   ae029012 + Requires v1.0.1
   90137ffa + StaticArrays v0.12.1
   dc548174 + TerminalMenus v0.1.0
   a759f4b9 + TimerOutputs v0.5.3
   2a0f44e3 + Base64
   ade2ca70 + Dates
   8bb1440f + DelimitedFiles
   8ba89e20 + Distributed
   b77e0a4c + InteractiveUtils
   76f85450 + LibGit2
   8f399da3 + Libdl
   37e2e46d + LinearAlgebra
   56ddb016 + Logging
   d6f4376e + Markdown
   a63ad114 + Mmap
   44cfe95a + Pkg
   de0858da + Printf
   3fa0cd96 + REPL
   9a3f8284 + Random
   ea8e919c + SHA
   9e88b42a + Serialization
   1a1011a3 + SharedArrays
   6462fe0b + Sockets
   2f01184e + SparseArrays
   10745b16 + Statistics
   8dfed614 + Test
   cf7118a7 + UUIDs
   4ec0a83e + Unicode
    Testing KernelAbstractions
┌ Error: Error building `MPI`: 
│ ERROR: LoadError: No MPI library found.
│ Ensure an MPI implementation is loaded, or set the `JULIA_MPI_PATH` variable.
│ Stacktrace:
│  [1] error(::String) at ./error.jl:33
│  [2] (::var"#9#10")() at /home/pkgeval/.julia/packages/MPI/lqZRM/deps/build.jl:33
│  [3] #477 at ./env.jl:81 [inlined]
│  [4] access_env at ./env.jl:43 [inlined]
│  [5] get(::var"#9#10", ::Base.EnvDict, ::String) at ./env.jl:81
│  [6] top-level scope at /home/pkgeval/.julia/packages/MPI/lqZRM/deps/build.jl:29
│  [7] include(::String) at ./client.jl:441
│  [8] top-level scope at none:5
│ in expression starting at /home/pkgeval/.julia/packages/MPI/lqZRM/deps/build.jl:29
└ @ Pkg.Operations /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/Operations.jl:912
     Status `/tmp/jl_Ev3R0h/Project.toml`
   3895d2a7 CUDAapi v4.0.0
   c5f51814 CUDAdrv v6.2.2
   be33ccc6 CUDAnative v3.0.2
   3a865a2d CuArrays v2.0.1
   63c18a36 KernelAbstractions v0.2.1
   da04e1cc MPI v0.12.0
   90137ffa StaticArrays v0.12.1
   b77e0a4c InteractiveUtils
   8dfed614 Test
     Status `/tmp/jl_Ev3R0h/Manifest.toml`
   621f4979 AbstractFFTs v0.5.0
   79e6a3ab Adapt v1.0.1
   b99e7846 BinaryProvider v0.5.8
   fa961155 CEnum v0.2.0
   3895d2a7 CUDAapi v4.0.0
   c5f51814 CUDAdrv v6.2.2
   be33ccc6 CUDAnative v3.0.2
   7057c7e9 Cassette v0.3.1
   da1fd8a2 CodeTracking v0.5.8
   34da2185 Compat v2.2.0
   f68482b8 Cthulhu v1.0.0
   3a865a2d CuArrays v2.0.1
   864edb3b DataStructures v0.17.11
   ffbed154 DocStringExtensions v0.8.1
   0c68f7d7 GPUArrays v3.1.0
   63c18a36 KernelAbstractions v0.2.1
   929cbde3 LLVM v1.3.4
   da04e1cc MPI v0.12.0
   1914dd2f MacroTools v0.5.5
   872c559c NNlib v0.6.6
   bac558e1 OrderedCollections v1.1.0
   189a3867 Reexport v0.2.0
   ae029012 Requires v1.0.1
   90137ffa StaticArrays v0.12.1
   dc548174 TerminalMenus v0.1.0
   a759f4b9 TimerOutputs v0.5.3
   2a0f44e3 Base64
   ade2ca70 Dates
   8bb1440f DelimitedFiles
   8ba89e20 Distributed
   b77e0a4c InteractiveUtils
   76f85450 LibGit2
   8f399da3 Libdl
   37e2e46d LinearAlgebra
   56ddb016 Logging
   d6f4376e Markdown
   a63ad114 Mmap
   44cfe95a Pkg
   de0858da Printf
   3fa0cd96 REPL
   9a3f8284 Random
   ea8e919c SHA
   9e88b42a Serialization
   1a1011a3 SharedArrays
   6462fe0b Sockets
   2f01184e SparseArrays
   10745b16 Statistics
   8dfed614 Test
   cf7118a7 UUIDs
   4ec0a83e Unicode
indextest: Error During Test at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/test/test.jl:108
  Got exception outside of a @test
  InvalidIRError: compiling gpu_index_linear_global(Cassette.Context{nametype(CUDACtx),KernelAbstractions.CompilerMetadata{DynamicSize,DynamicCheck(),Nothing,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},NDRange{1,DynamicSize,StaticSize{(8,)},CartesianIndices{1,Tuple{Base.OneTo{Int64}}},Nothing}},Nothing,KernelAbstractions.var"##PassType#254",Nothing,Cassette.DisableHooks}, typeof(gpu_index_linear_global), CuDeviceArray{Int64,2,CUDAnative.AS.Global}) resulted in invalid LLVM IR
  Reason: unsupported call to an unknown function (call to jfptr_throw_boundserror_1414)
  Stacktrace:
   [1] check_ir(::CUDAnative.CompilerJob, ::LLVM.Module) at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/compiler/validation.jl:116
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/compiler/driver.jl:186 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/compiler/driver.jl:45
   [6] #compile#175 at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:maxthreads,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/execution.jl:326
   [8] #223 at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#223#224"{String,Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:maxthreads,),Tuple{Int64}}},typeof(Cassette.overdub),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:maxthreads,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/execution.jl:391
   [13] convert at ./essentials.jl:309 [inlined]
   [14] Pairs at ./iterators.jl:169 [inlined]
   [15] pairs at ./iterators.jl:226 [inlined]
   [16] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/execution.jl:157 [inlined]
   [17] (::KernelAbstractions.Kernel{CUDA,StaticSize{(8,)},DynamicSize,typeof(gpu_index_linear_global)})(::CuArray{Int64,2,Nothing}; ndrange::Int64, dependencies::Nothing, workgroupsize::Nothing, progress::Function) at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/src/backends/cuda.jl:211
   [18] indextest(::CUDA, ::Type{T} where T) at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/test/test.jl:73
   [19] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/test/test.jl:111
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/test/test.jl:109
   [22] include(::String) at ./client.jl:441
   [23] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/test/runtests.jl:5
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/test/runtests.jl:5
   [26] include(::String) at ./client.jl:441
   [27] top-level scope at none:6
   [28] eval(::Module, ::Any) at ./boot.jl:331
   [29] exec_options(::Base.JLOptions) at ./client.jl:264
   [30] _start() at ./client.jl:490
  
Unittests: Error During Test at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/test/runtests.jl:4
  Got exception outside of a @test
  LoadError: InvalidIRError: compiling gpu_kernel_val!(Cassette.Context{nametype(CUDACtx),KernelAbstractions.CompilerMetadata{DynamicSize,DynamicCheck(),Nothing,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},NDRange{1,DynamicSize,DynamicSize,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},CartesianIndices{1,Tuple{Base.OneTo{Int64}}}}},Nothing,KernelAbstractions.var"##PassType#254",Nothing,Cassette.DisableHooks}, typeof(gpu_kernel_val!), CuDeviceArray{Int64,1,CUDAnative.AS.Global}, Val{3}) resulted in invalid LLVM IR
  Reason: unsupported call to an unknown function (call to jfptr_throw_boundserror_1414)
  Stacktrace:
   [1] check_ir(::CUDAnative.CompilerJob, ::LLVM.Module) at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/compiler/validation.jl:116
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/compiler/driver.jl:186 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/compiler/driver.jl:45
   [6] #compile#175 at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:maxthreads,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/execution.jl:326
   [8] #223 at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#223#224"{String,Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:maxthreads,),Tuple{Nothing}}},typeof(Cassette.overdub),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:maxthreads,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/execution.jl:391
   [13] getproperty at ./Base.jl:33 [inlined]
   [14] merge at ./namedtuple.jl:253 [inlined]
   [15] cufunction(::typeof(Cassette.overdub), ::Type{Tuple{Cassette.Context{nametype(CUDACtx),KernelAbstractions.CompilerMetadata{DynamicSize,DynamicCheck(),Nothing,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},NDRange{1,DynamicSize,DynamicSize,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},CartesianIndices{1,Tuple{Base.OneTo{Int64}}}}},Nothing,KernelAbstractions.var"##PassType#254",Nothing,Cassette.DisableHooks},typeof(gpu_kernel_val!),CuDeviceArray{Int64,1,CUDAnative.AS.Global},Val{3}}}; kwargs::Base.Iterators.Pairs{Symbol,Union{Nothing, String},Tuple{Symbol,Symbol},NamedTuple{(:name, :maxthreads),Tuple{String,Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/execution.jl:0
   [16] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/cnQli/src/execution.jl:157 [inlined]
   [17] (::KernelAbstractions.Kernel{CUDA,DynamicSize,DynamicSize,typeof(gpu_kernel_val!)})(::CuArray{Int64,1,Nothing}, ::Vararg{Any,N} where N; ndrange::Tuple{Int64}, dependencies::Nothing, workgroupsize::Nothing, progress::Function) at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/src/backends/cuda.jl:211
   [18] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/test/test.jl:161
   [19] include(::String) at ./client.jl:441
   [20] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/test/runtests.jl:5
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/test/runtests.jl:5
   [23] include(::String) at ./client.jl:441
   [24] top-level scope at none:6
   [25] eval(::Module, ::Any) at ./boot.jl:331
   [26] exec_options(::Base.JLOptions) at ./client.jl:264
   [27] _start() at ./client.jl:490
  in expression starting at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/test/test.jl:159
  
Test Summary: | Pass  Error  Total
Unittests     |   26      2     28
  partition   |   12            12
  indextest   |   10      1     11
  Const       |    3             3
ERROR: LoadError: Some tests did not pass: 26 passed, 0 failed, 2 errored, 0 broken.
in expression starting at /home/pkgeval/.julia/packages/KernelAbstractions/hdDNq/test/runtests.jl:4
ERROR: Package KernelAbstractions errored during testing
Stacktrace:
 [1] pkgerror(::String, ::Vararg{String,N} where N) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/Types.jl:53
 [2] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/Operations.jl:1523
 [3] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:316
 [4] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:303
 [5] #test#68 at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:297 [inlined]
 [6] test at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:297 [inlined]
 [7] #test#67 at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:296 [inlined]
 [8] test at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:296 [inlined]
 [9] test(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:295
 [10] test(::String) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:295
 [11] top-level scope at none:16
