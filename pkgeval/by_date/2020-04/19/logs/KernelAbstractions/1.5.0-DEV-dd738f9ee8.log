Julia Version 1.5.0-DEV.650
Commit dd738f9ee8 (2020-04-19 16:28 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed Adapt ────────────── v1.0.1
  Installed CodeTracking ─────── v0.5.9
  Installed CUDAapi ──────────── v4.0.0
  Installed MacroTools ───────── v0.5.5
  Installed StaticArrays ─────── v0.12.1
  Installed ExprTools ────────── v0.1.1
  Installed Cassette ─────────── v0.3.1
  Installed KernelAbstractions ─ v0.2.2
  Installed CEnum ────────────── v0.2.0
  Installed Requires ─────────── v1.0.1
  Installed TimerOutputs ─────── v0.5.4
  Installed OrderedCollections ─ v1.1.0
  Installed BinaryProvider ───── v0.5.8
  Installed Cthulhu ──────────── v1.0.2
  Installed DataStructures ───── v0.17.12
  Installed CUDAdrv ──────────── v6.2.2
  Installed CUDAnative ───────── v3.0.4
  Installed LLVM ─────────────── v1.3.4
Updating `~/.julia/environments/v1.5/Project.toml`
  [63c18a36] + KernelAbstractions v0.2.2
Updating `~/.julia/environments/v1.5/Manifest.toml`
  [79e6a3ab] + Adapt v1.0.1
  [b99e7846] + BinaryProvider v0.5.8
  [fa961155] + CEnum v0.2.0
  [3895d2a7] + CUDAapi v4.0.0
  [c5f51814] + CUDAdrv v6.2.2
  [be33ccc6] + CUDAnative v3.0.4
  [7057c7e9] + Cassette v0.3.1
  [da1fd8a2] + CodeTracking v0.5.9
  [f68482b8] + Cthulhu v1.0.2
  [864edb3b] + DataStructures v0.17.12
  [e2ba6199] + ExprTools v0.1.1
  [63c18a36] + KernelAbstractions v0.2.2
  [929cbde3] + LLVM v1.3.4
  [1914dd2f] + MacroTools v0.5.5
  [bac558e1] + OrderedCollections v1.1.0
  [ae029012] + Requires v1.0.1
  [90137ffa] + StaticArrays v0.12.1
  [a759f4b9] + TimerOutputs v0.5.4
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
    Testing KernelAbstractions
┌ Error: Error building `MPI`: 
│ ERROR: LoadError: LoadError: No MPI library found.
│ Ensure an MPI implementation is loaded, or set the `JULIA_MPI_PATH` variable.
│ Stacktrace:
│  [1] error(::String) at ./error.jl:33
│  [2] find_lib() at /home/pkgeval/.julia/packages/MPI/O0dMQ/src/paths.jl:19
│  [3] top-level scope at /home/pkgeval/.julia/packages/MPI/O0dMQ/src/paths.jl:25
│  [4] include(::String) at ./client.jl:442
│  [5] top-level scope at /home/pkgeval/.julia/packages/MPI/O0dMQ/deps/build.jl:3
│  [6] include(::String) at ./client.jl:442
│  [7] top-level scope at none:5
│ in expression starting at /home/pkgeval/.julia/packages/MPI/O0dMQ/src/paths.jl:25
│ in expression starting at /home/pkgeval/.julia/packages/MPI/O0dMQ/deps/build.jl:3
└ @ Pkg.Operations /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/Operations.jl:905
Status `/tmp/jl_g8QYCP/Project.toml`
  [3895d2a7] CUDAapi v4.0.0
  [c5f51814] CUDAdrv v6.2.2
  [be33ccc6] CUDAnative v3.0.4
  [3a865a2d] CuArrays v2.0.1
  [63c18a36] KernelAbstractions v0.2.2
  [da04e1cc] MPI v0.13.0
  [90137ffa] StaticArrays v0.12.1
  [b77e0a4c] InteractiveUtils
  [8dfed614] Test
Status `/tmp/jl_g8QYCP/Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [79e6a3ab] Adapt v1.0.1
  [b99e7846] BinaryProvider v0.5.8
  [fa961155] CEnum v0.2.0
  [3895d2a7] CUDAapi v4.0.0
  [c5f51814] CUDAdrv v6.2.2
  [be33ccc6] CUDAnative v3.0.4
  [7057c7e9] Cassette v0.3.1
  [da1fd8a2] CodeTracking v0.5.9
  [f68482b8] Cthulhu v1.0.2
  [3a865a2d] CuArrays v2.0.1
  [864edb3b] DataStructures v0.17.12
  [ffbed154] DocStringExtensions v0.8.1
  [e2ba6199] ExprTools v0.1.1
  [0c68f7d7] GPUArrays v3.1.0
  [63c18a36] KernelAbstractions v0.2.2
  [929cbde3] LLVM v1.3.4
  [da04e1cc] MPI v0.13.0
  [1914dd2f] MacroTools v0.5.5
  [872c559c] NNlib v0.6.6
  [bac558e1] OrderedCollections v1.1.0
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [90137ffa] StaticArrays v0.12.1
  [a759f4b9] TimerOutputs v0.5.4
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
indextest: Error During Test at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/test/test.jl:108
  Got exception outside of a @test
  InvalidIRError: compiling gpu_index_linear_global(Cassette.Context{nametype(CUDACtx),KernelAbstractions.CompilerMetadata{DynamicSize,DynamicCheck,Nothing,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},NDRange{1,DynamicSize,StaticSize{(8,)},CartesianIndices{1,Tuple{Base.OneTo{Int64}}},Nothing}},Nothing,KernelAbstractions.var"##PassType#254",Nothing,Cassette.DisableHooks}, typeof(gpu_index_linear_global), CuDeviceArray{Int64,2,CUDAnative.AS.Global}) resulted in invalid LLVM IR
  Reason: unsupported call to an unknown function (call to jfptr_throw_boundserror_1427)
  Stacktrace:
   [1] check_ir(::CUDAnative.CompilerJob, ::LLVM.Module) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:116
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:186 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/kJdxU/src/TimerOutput.jl:245 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:maxthreads,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{String,Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:maxthreads,),Tuple{Int64}}},typeof(Cassette.overdub),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:maxthreads,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] convert at ./essentials.jl:309 [inlined]
   [14] Pairs at ./iterators.jl:169 [inlined]
   [15] pairs at ./iterators.jl:226 [inlined]
   [16] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157 [inlined]
   [17] (::KernelAbstractions.Kernel{CUDA,StaticSize{(8,)},DynamicSize,typeof(gpu_index_linear_global)})(::CuArray{Int64,2,Nothing}; ndrange::Int64, dependencies::Nothing, workgroupsize::Nothing, progress::Function) at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/src/backends/cuda.jl:215
   [18] indextest(::CUDA, ::Type{T} where T) at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/test/test.jl:73
   [19] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/test/test.jl:111
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/test/test.jl:109
   [22] include(::String) at ./client.jl:442
   [23] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/test/runtests.jl:5
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/test/runtests.jl:5
   [26] include(::String) at ./client.jl:442
   [27] top-level scope at none:6
   [28] eval(::Module, ::Any) at ./boot.jl:331
   [29] exec_options(::Base.JLOptions) at ./client.jl:265
   [30] _start() at ./client.jl:491
  
Unittests: Error During Test at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/test/runtests.jl:4
  Got exception outside of a @test
  LoadError: InvalidIRError: compiling gpu_kernel_val!(Cassette.Context{nametype(CUDACtx),KernelAbstractions.CompilerMetadata{DynamicSize,DynamicCheck,Nothing,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},NDRange{1,DynamicSize,DynamicSize,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},CartesianIndices{1,Tuple{Base.OneTo{Int64}}}}},Nothing,KernelAbstractions.var"##PassType#254",Nothing,Cassette.DisableHooks}, typeof(gpu_kernel_val!), CuDeviceArray{Int64,1,CUDAnative.AS.Global}, Val{3}) resulted in invalid LLVM IR
  Reason: unsupported call to an unknown function (call to jfptr_throw_boundserror_1427)
  Stacktrace:
   [1] check_ir(::CUDAnative.CompilerJob, ::LLVM.Module) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:116
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:186 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/kJdxU/src/TimerOutput.jl:245 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:maxthreads,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{String,Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:maxthreads,),Tuple{Nothing}}},typeof(Cassette.overdub),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:maxthreads,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] getproperty at ./Base.jl:33 [inlined]
   [14] merge at ./namedtuple.jl:253 [inlined]
   [15] cufunction(::typeof(Cassette.overdub), ::Type{Tuple{Cassette.Context{nametype(CUDACtx),KernelAbstractions.CompilerMetadata{DynamicSize,DynamicCheck,Nothing,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},NDRange{1,DynamicSize,DynamicSize,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},CartesianIndices{1,Tuple{Base.OneTo{Int64}}}}},Nothing,KernelAbstractions.var"##PassType#254",Nothing,Cassette.DisableHooks},typeof(gpu_kernel_val!),CuDeviceArray{Int64,1,CUDAnative.AS.Global},Val{3}}}; kwargs::Base.Iterators.Pairs{Symbol,Union{Nothing, String},Tuple{Symbol,Symbol},NamedTuple{(:name, :maxthreads),Tuple{String,Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:0
   [16] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157 [inlined]
   [17] (::KernelAbstractions.Kernel{CUDA,DynamicSize,DynamicSize,typeof(gpu_kernel_val!)})(::CuArray{Int64,1,Nothing}, ::Vararg{Any,N} where N; ndrange::Tuple{Int64}, dependencies::Nothing, workgroupsize::Nothing, progress::Function) at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/src/backends/cuda.jl:215
   [18] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/test/test.jl:161
   [19] include(::String) at ./client.jl:442
   [20] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/test/runtests.jl:5
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/test/runtests.jl:5
   [23] include(::String) at ./client.jl:442
   [24] top-level scope at none:6
   [25] eval(::Module, ::Any) at ./boot.jl:331
   [26] exec_options(::Base.JLOptions) at ./client.jl:265
   [27] _start() at ./client.jl:491
  in expression starting at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/test/test.jl:159
  
Test Summary: | Pass  Error  Total
Unittests     |   26      2     28
  partition   |   12            12
  indextest   |   10      1     11
  Const       |    3             3
ERROR: LoadError: Some tests did not pass: 26 passed, 0 failed, 2 errored, 0 broken.
in expression starting at /home/pkgeval/.julia/packages/KernelAbstractions/cpaX2/test/runtests.jl:4
ERROR: Package KernelAbstractions errored during testing
Stacktrace:
 [1] pkgerror(::String, ::Vararg{String,N} where N) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/Types.jl:52
 [2] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/Operations.jl:1516
 [3] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:316
 [4] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:303
 [5] #test#68 at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:297 [inlined]
 [6] test at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:297 [inlined]
 [7] #test#67 at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:296 [inlined]
 [8] test at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:296 [inlined]
 [9] test(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:295
 [10] test(::String) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:295
 [11] top-level scope at none:16
