Julia Version 1.6.0-DEV.1117
Commit 36effbe10a (2020-10-02 17:38 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: AMD EPYC 7502 32-Core Processor
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-10.0.1 (ORCJIT, znver2)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed HDF5_jll ───────────────────── v1.10.5+6
  Installed Zstd_jll ───────────────────── v1.4.5+1
  Installed IntelOpenMP_jll ────────────── v2018.0.3+0
  Installed BinDeps ────────────────────── v1.0.1
  Installed SpecialFunctions ───────────── v0.10.3
  Installed FFTW ───────────────────────── v1.2.4
  Installed PyCall ─────────────────────── v1.92.1
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed Reexport ───────────────────── v0.2.0
  Installed VersionParsing ─────────────── v1.2.0
  Installed HDF5 ───────────────────────── v0.13.6
  Installed JSON ───────────────────────── v0.21.1
  Installed TranscodingStreams ─────────── v0.9.5
  Installed MAT ────────────────────────── v0.8.1
  Installed Lz4_jll ────────────────────── v1.9.2+2
  Installed FFTW_jll ───────────────────── v3.3.9+5
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed Zlib_jll ───────────────────── v1.2.11+16
  Installed Blosc_jll ──────────────────── v1.14.3+1
  Installed CMake ──────────────────────── v1.2.0
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed Conda ──────────────────────── v1.4.1
  Installed CodecZlib ──────────────────── v0.7.0
  Installed Blosc ──────────────────────── v0.7.0
  Installed MKL_jll ────────────────────── v2020.2.254+0
  Installed MacroTools ─────────────────── v0.5.5
  Installed URIParser ──────────────────── v0.4.1
  Installed BufferedStreams ────────────── v1.0.0
  Installed Parsers ────────────────────── v1.0.10
  Installed Compat ─────────────────────── v3.18.0
  Installed ADCME ──────────────────────── v0.5.12
Updating `~/.julia/environments/v1.6/Project.toml`
  [07b341a0] + ADCME v0.5.12
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [07b341a0] + ADCME v0.5.12
  [621f4979] + AbstractFFTs v0.5.0
  [9e28174c] + BinDeps v1.0.1
  [a74b3585] + Blosc v0.7.0
  [0b7ba130] + Blosc_jll v1.14.3+1
  [e1450e63] + BufferedStreams v1.0.0
  [631607c0] + CMake v1.2.0
  [944b1d66] + CodecZlib v0.7.0
  [34da2185] + Compat v3.18.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [8f4d0f93] + Conda v1.4.1
  [7a1cc6ca] + FFTW v1.2.4
  [f5851436] + FFTW_jll v3.3.9+5
  [f67ccb44] + HDF5 v0.13.6
  [0234f1f7] + HDF5_jll v1.10.5+6
  [1d5cc7b8] + IntelOpenMP_jll v2018.0.3+0
  [682c06a0] + JSON v0.21.1
  [5ced341a] + Lz4_jll v1.9.2+2
  [23992714] + MAT v0.8.1
  [856f044c] + MKL_jll v2020.2.254+0
  [1914dd2f] + MacroTools v0.5.5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [69de0a69] + Parsers v1.0.10
  [438e738f] + PyCall v1.92.1
  [189a3867] + Reexport v0.2.0
  [276daf66] + SpecialFunctions v0.10.3
  [3bb67fe8] + TranscodingStreams v0.9.5
  [30578b45] + URIParser v0.4.1
  [81def892] + VersionParsing v1.2.0
  [83775a58] + Zlib_jll v1.2.11+16
  [3161d3a3] + Zstd_jll v1.4.5+1
  [56f22d72] + Artifacts
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8bb1440f] + DelimitedFiles
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [1a1011a3] + SharedArrays
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [fa267f1f] + TOML
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
   Building Conda ─→ `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/7a58bb32ce5d85f8bf7559aa7c2842f9aecf52fc/build.log`
   Building PyCall → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/b6dff5fa725eff4f775f472acd86756d6e31fb02/build.log`
   Building CMake ─→ `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/50a8b41d2c562fccd9ab841085fc7d1e2706da82/build.log`
   Building HDF5 ──→ `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/0713cbabdf855852dfab3ce6447c87145f3d9ea8/build.log`
   Building FFTW ──→ `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/8b7c16b56936047ca41bf25effa137ae0b381ae8/build.log`
   Building ADCME ─→ `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/75cced9fa2823c1212528caf9c0eed055ccb734a/build.log`
    Testing ADCME
Status `/tmp/jl_J4kkOZ/Project.toml`
  [07b341a0] ADCME v0.5.12
  [631607c0] CMake v1.2.0
  [7a1cc6ca] FFTW v1.2.4
  [23992714] MAT v0.8.1
  [76087f3c] NLopt v0.6.0
  [429524aa] Optim v1.2.0
  [438e738f] PyCall v1.92.1
  [d330b81b] PyPlot v2.9.0
  [276daf66] SpecialFunctions v0.10.3
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [44cfe95a] Pkg
  [9a3f8284] Random
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_J4kkOZ/Manifest.toml`
  [07b341a0] ADCME v0.5.12
  [621f4979] AbstractFFTs v0.5.0
  [4fba245c] ArrayInterface v2.13.3
  [9e28174c] BinDeps v1.0.1
  [a74b3585] Blosc v0.7.0
  [0b7ba130] Blosc_jll v1.14.3+1
  [e1450e63] BufferedStreams v1.0.0
  [631607c0] CMake v1.2.0
  [944b1d66] CodecZlib v0.7.0
  [3da002f7] ColorTypes v0.10.9
  [5ae59095] Colors v0.12.4
  [bbf7d656] CommonSubexpressions v0.3.0
  [34da2185] Compat v3.18.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [8f4d0f93] Conda v1.4.1
  [9a962f9c] DataAPI v1.3.0
  [864edb3b] DataStructures v0.18.6
  [163ba53b] DiffResults v1.0.2
  [b552c78f] DiffRules v1.0.1
  [7a1cc6ca] FFTW v1.2.4
  [f5851436] FFTW_jll v3.3.9+5
  [1a297f60] FillArrays v0.9.6
  [6a86dc24] FiniteDiff v2.7.0
  [53c48c17] FixedPointNumbers v0.8.4
  [f6369f11] ForwardDiff v0.10.12
  [f67ccb44] HDF5 v0.13.6
  [0234f1f7] HDF5_jll v1.10.5+6
  [1d5cc7b8] IntelOpenMP_jll v2018.0.3+0
  [682c06a0] JSON v0.21.1
  [b964fa9f] LaTeXStrings v1.2.0
  [d3d80556] LineSearches v7.1.0
  [5ced341a] Lz4_jll v1.9.2+2
  [23992714] MAT v0.8.1
  [856f044c] MKL_jll v2020.2.254+0
  [1914dd2f] MacroTools v0.5.5
  [fdba3010] MathProgBase v0.7.8
  [e1d29d7a] Missings v0.4.4
  [d41bc354] NLSolversBase v7.7.1
  [76087f3c] NLopt v0.6.0
  [079eb43e] NLopt_jll v2.6.2+0
  [77ba4419] NaNMath v0.3.4
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [429524aa] Optim v1.2.0
  [bac558e1] OrderedCollections v1.3.1
  [d96e819e] Parameters v0.12.1
  [69de0a69] Parsers v1.0.10
  [85a6dd25] PositiveFactorizations v0.2.3
  [438e738f] PyCall v1.92.1
  [d330b81b] PyPlot v2.9.0
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.1.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.10.3
  [90137ffa] StaticArrays v0.12.4
  [2913bbd2] StatsBase v0.33.1
  [3bb67fe8] TranscodingStreams v0.9.5
  [30578b45] URIParser v0.4.1
  [3a884ed6] UnPack v1.0.2
  [81def892] VersionParsing v1.2.0
  [83775a58] Zlib_jll v1.2.11+16
  [3161d3a3] Zstd_jll v1.4.5+1
  [56f22d72] Artifacts
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [1a1011a3] SharedArrays
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [fa267f1f] TOML
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
    Testing Running tests...
WARNING: Method definition size(PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/BcTLp/src/PyCall.jl:809 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/PJIHk/src/variable.jl:212.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition length(PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/BcTLp/src/PyCall.jl:808 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/PJIHk/src/variable.jl:236.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition lastindex(PyCall.PyObject) in module PyCall at deprecated.jl:70 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/PJIHk/src/variable.jl:424.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition *(PyCall.PyObject, PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/BcTLp/src/pyoperators.jl:11 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/PJIHk/src/ops.jl:102.
  ** incremental compilation may be fatally broken for this module **

OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-127
OMP: Info #156: KMP_AFFINITY: 128 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 2 packages x 32 cores/pkg x 2 threads/core (64 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 64 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 65 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 66 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 67 maps to package 0 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 4 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 68 maps to package 0 core 4 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 5 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 69 maps to package 0 core 5 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 6 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 70 maps to package 0 core 6 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 7 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 71 maps to package 0 core 7 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 8 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 72 maps to package 0 core 8 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 0 core 9 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 73 maps to package 0 core 9 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 0 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 74 maps to package 0 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 0 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 75 maps to package 0 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 0 core 12 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 76 maps to package 0 core 12 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 0 core 13 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 77 maps to package 0 core 13 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 0 core 14 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 78 maps to package 0 core 14 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 0 core 15 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 79 maps to package 0 core 15 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 0 core 16 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 80 maps to package 0 core 16 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 0 core 17 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 81 maps to package 0 core 17 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 0 core 18 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 82 maps to package 0 core 18 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 0 core 19 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 83 maps to package 0 core 19 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 20 maps to package 0 core 20 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 84 maps to package 0 core 20 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 21 maps to package 0 core 21 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 85 maps to package 0 core 21 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 22 maps to package 0 core 22 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 86 maps to package 0 core 22 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 23 maps to package 0 core 23 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 87 maps to package 0 core 23 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 24 maps to package 0 core 24 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 88 maps to package 0 core 24 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 25 maps to package 0 core 25 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 89 maps to package 0 core 25 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 26 maps to package 0 core 26 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 90 maps to package 0 core 26 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 27 maps to package 0 core 27 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 91 maps to package 0 core 27 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 28 maps to package 0 core 28 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 92 maps to package 0 core 28 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 29 maps to package 0 core 29 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 93 maps to package 0 core 29 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 30 maps to package 0 core 30 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 94 maps to package 0 core 30 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 31 maps to package 0 core 31 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 95 maps to package 0 core 31 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 32 maps to package 1 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 96 maps to package 1 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 33 maps to package 1 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 97 maps to package 1 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 34 maps to package 1 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 98 maps to package 1 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 35 maps to package 1 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 99 maps to package 1 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 36 maps to package 1 core 4 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 100 maps to package 1 core 4 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 37 maps to package 1 core 5 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 101 maps to package 1 core 5 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 38 maps to package 1 core 6 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 102 maps to package 1 core 6 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 39 maps to package 1 core 7 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 103 maps to package 1 core 7 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 40 maps to package 1 core 8 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 104 maps to package 1 core 8 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 41 maps to package 1 core 9 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 105 maps to package 1 core 9 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 42 maps to package 1 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 106 maps to package 1 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 43 maps to package 1 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 107 maps to package 1 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 44 maps to package 1 core 12 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 108 maps to package 1 core 12 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 45 maps to package 1 core 13 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 109 maps to package 1 core 13 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 46 maps to package 1 core 14 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 110 maps to package 1 core 14 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 47 maps to package 1 core 15 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 111 maps to package 1 core 15 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 48 maps to package 1 core 16 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 112 maps to package 1 core 16 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 49 maps to package 1 core 17 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 113 maps to package 1 core 17 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 50 maps to package 1 core 18 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 114 maps to package 1 core 18 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 51 maps to package 1 core 19 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 115 maps to package 1 core 19 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 52 maps to package 1 core 20 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 116 maps to package 1 core 20 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 53 maps to package 1 core 21 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 117 maps to package 1 core 21 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 54 maps to package 1 core 22 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 118 maps to package 1 core 22 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 55 maps to package 1 core 23 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 119 maps to package 1 core 23 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 56 maps to package 1 core 24 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 120 maps to package 1 core 24 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 57 maps to package 1 core 25 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 121 maps to package 1 core 25 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 58 maps to package 1 core 26 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 122 maps to package 1 core 26 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 59 maps to package 1 core 27 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 123 maps to package 1 core 27 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 60 maps to package 1 core 28 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 124 maps to package 1 core 28 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 61 maps to package 1 core 29 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 125 maps to package 1 core 29 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 62 maps to package 1 core 30 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 126 maps to package 1 core 30 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 63 maps to package 1 core 31 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 127 maps to package 1 core 31 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 4316 thread 0 bound to OS proc set 0
[ Info: You are using ADCME for the first time. Precompiling built-in custom operators may take some time...
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /home/pkgeval/.julia/adcme/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /home/pkgeval/.julia/adcme/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0
OMP: Info #156: KMP_AFFINITY: 1 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #159: KMP_AFFINITY: 1 packages x 1 cores/pkg x 1 threads/core (1 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 
OMP: Info #250: KMP_AFFINITY: pid 4830 tid 4830 thread 0 bound to OS proc set 0
┌ Warning: Cannot load /home/pkgeval/.julia/packages/ADCME/PJIHk/deps/CustomOps/build/libadcme.so. Please recompile the shared library by `ADCME.precompile()` for using custom operators.
└ @ ADCME ~/.julia/packages/ADCME/PJIHk/src/ADCME.jl:95
Python path=/home/pkgeval/.julia/adcme/bin/python
PREFIXDIR=/home/pkgeval/.julia/adcme/lib/Libraries
TF_INC=/home/pkgeval/.julia/adcme/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/adcme/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
MPI_INCLUDE_PATH and/or MPI_C_LIBRARIES is not set. MPI operators are not compiled.
-- Found OpenMP_C: -fopenmp (found version "4.0") 
-- Found OpenMP_CXX: -fopenmp (found version "4.0") 
-- Found OpenMP: TRUE (found version "4.0")  
OPENMP Found
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/packages/ADCME/PJIHk/deps/CustomOps/build
[1/19] Building CXX object CMakeFiles/adcme.dir/OT/src/sinkhorn.cpp.o
[2/19] Building CXX object CMakeFiles/adcme.dir/TriSolve/TriSolve.cpp.o
[3/19] Building CXX object CMakeFiles/adcme.dir/PrintTensor/PrintTensor.cpp.o
[4/19] Building CXX object CMakeFiles/adcme.dir/SparseAccumulate/Impl.cpp.o
[5/19] Building CXX object CMakeFiles/adcme.dir/SparseToDense/SparseToDense.cpp.o
[6/19] Building CXX object CMakeFiles/adcme.dir/TriLu/TriLu.cpp.o
[7/19] Building CXX object CMakeFiles/adcme.dir/SparseAccumulate/SparseAccumulator.cpp.o
[8/19] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/lru_cache.cpp.o
[9/19] Building CXX object CMakeFiles/adcme.dir/SparseConcate/SparseConcate.cpp.o
[10/19] Building CXX object CMakeFiles/adcme.dir/SparseScatterUpdate/SparseScatterUpdate.cpp.o
[11/19] Building CXX object CMakeFiles/adcme.dir/OT/SinkhornKnopp/SinkhornKnopp.cpp.o
[12/19] Building CXX object CMakeFiles/adcme.dir/SparseIndexing/SparseIndexing.cpp.o
[13/19] Building CXX object CMakeFiles/adcme.dir/SparseMatMul/SparseMatMul.cpp.o
[14/19] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/Solve/Solve.cpp.o
[15/19] Building CXX object CMakeFiles/adcme.dir/SolveBatchedRhs/SolveBatchedRhs.cpp.o
[16/19] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/Factorization/SparseFactorization.cpp.o
[17/19] Building CXX object CMakeFiles/adcme.dir/SparseLeastSquare/SparseLeastSquare.cpp.o
[18/19] Building CXX object CMakeFiles/adcme.dir/SparseSolver/SparseSolver.cpp.o
[19/19] Linking CXX shared library libadcme.so
Collecting package metadata (current_repodata.json): ...working... done
Solving environment: ...working... done

## Package Plan ##

  environment location: /home/pkgeval/.julia/adcme

  added / updated specs:
    - matplotlib


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    ca-certificates-2020.7.22  |                0         132 KB  anaconda
    certifi-2020.6.20          |           py37_0         159 KB  anaconda
    conda-4.8.5                |           py37_0         3.1 MB  anaconda
    matplotlib-3.3.1           |                0          24 KB  anaconda
    openssl-1.1.1h             |       h7b6447c_0         3.8 MB  anaconda
    ------------------------------------------------------------
                                           Total:         7.2 MB

The following packages will be UPDATED:

  ca-certificates    conda-forge::ca-certificates-2020.6.2~ --> anaconda::ca-certificates-2020.7.22-0
  conda              conda-forge::conda-4.8.4-py37hc8dfbb8~ --> anaconda::conda-4.8.5-py37_0
  openssl            conda-forge::openssl-1.1.1g-h516909a_1 --> anaconda::openssl-1.1.1h-h7b6447c_0

The following packages will be SUPERSEDED by a higher-priority channel:

  certifi            conda-forge::certifi-2020.6.20-py37hc~ --> anaconda::certifi-2020.6.20-py37_0
  matplotlib                                      pkgs/main --> anaconda



Downloading and Extracting Packages
matplotlib-3.3.1     | 24 KB     |            |   0% matplotlib-3.3.1     | 24 KB     | ######7    |  68% matplotlib-3.3.1     | 24 KB     | ########## | 100% 
openssl-1.1.1h       | 3.8 MB    |            |   0% openssl-1.1.1h       | 3.8 MB    | ########## | 100% openssl-1.1.1h       | 3.8 MB    | ########## | 100% 
conda-4.8.5          | 3.1 MB    |            |   0% conda-4.8.5          | 3.1 MB    | ########## | 100% conda-4.8.5          | 3.1 MB    | ########## | 100% 
ca-certificates-2020 | 132 KB    |            |   0% ca-certificates-2020 | 132 KB    | ########## | 100% 
certifi-2020.6.20    | 159 KB    |            |   0% certifi-2020.6.20    | 159 KB    | ########## | 100% 
Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
2020-10-02 20:53:41.266674: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-02 20:53:41.274028: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499765000 Hz
2020-10-02 20:53:41.274189: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6368cd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-02 20:53:41.274202: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[✔️] Julia version
[✔️] TensorFlow version
[✔️] TensorFlow-Probability version
[✔️] Python executable file
[✘] Julia path (Optional)

[Reason]
`julia` outputs nothing. This will break custom operator compilation.


[Instruction]
Add your julia binary path to your environment path, e.g. (Unix systems) 

export PATH=/opt/julia/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] Dynamic library path (Optional)

[Reason]
/home/pkgeval/.julia/adcme/lib is not in LD_LIBRARY_PATH. This MAY break custom operator compilation. However, in most cases, ADCME automatic fixes this problem for you.


[Instruction]
Add your dynamic library path path to your environment path, e.g. (Unix systems) 

export LD_LIBRARY_PATH=/home/pkgeval/.julia/adcme/lib:$LD_LIBRARY_PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux or Apple).
For Windows, you need to add it to PATH instead of LD_LIBRARY_PATH.

[✔️] Memory Address Length =  64
[✘] Binaries path

[Reason]
/home/pkgeval/.julia/adcme/bin is not in PATH. This path contains compatible tools such as a GCC compiler, `cmake`, `make`, or any other tools you want to use directly from terminal.
However, setting the path is NOT a requirement, and ADCME works totally fine without any action.


[Instruction]
(Optional) Add your binary path to your environment path, e.g. (Unix systems) 

export PATH=/home/pkgeval/.julia/adcme/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] GPU Support (Optional)

[Reason]
ADCME is not compiled against GPU.


[Instruction]
If you intend to use GPU, set ENV["GPU"] = 1 and then rebuild ADCME.

Dependency file is located at: /home/pkgeval/.julia/packages/ADCME/PJIHk/src/../deps/deps.jl
2020-10-02 20:53:41.700030: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Test Summary:               | Pass  Total
indexing for rank 3 tensors |    3      3
[ Info: Copy "/home/pkgeval/.julia/packages/ADCME/PJIHk/src/../deps/AdeptCMakeLists.txt" to "/home/pkgeval/.julia/adcme/lib/Adept-2/adept/CMakeLists.txt" ... 
[ Info: Remove /home/pkgeval/.julia/adcme/lib/Adept-2/adept/build ... 
[ Info: Make /home/pkgeval/.julia/adcme/lib/Adept-2/adept/build ... 
[ Info: Change directory into /home/pkgeval/.julia/adcme/lib/Adept-2/adept/build ... 
[ Info: Cmake ... 
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /home/pkgeval/.julia/adcme/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /home/pkgeval/.julia/adcme/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0
OMP: Info #156: KMP_AFFINITY: 1 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #159: KMP_AFFINITY: 1 packages x 1 cores/pkg x 1 threads/core (1 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 
OMP: Info #250: KMP_AFFINITY: pid 6288 tid 6288 thread 0 bound to OS proc set 0
Python path=/home/pkgeval/.julia/adcme/bin/python
PREFIXDIR=/home/pkgeval/.julia/adcme/lib/Libraries
TF_INC=/home/pkgeval/.julia/adcme/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/adcme/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
Use openblas library /home/pkgeval/.julia/adcme/lib/libopenblas.so
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/adcme/lib/Adept-2/adept/build
[ Info: Make ... 
[1/12] Building CXX object CMakeFiles/adept.dir/StackStorageOrig.cpp.o
[2/12] Building CXX object CMakeFiles/adept.dir/cppblas.cpp.o
[3/12] Building CXX object CMakeFiles/adept.dir/settings.cpp.o
[4/12] Building CXX object CMakeFiles/adept.dir/Storage.cpp.o
[5/12] Building CXX object CMakeFiles/adept.dir/index.cpp.o
[6/12] Building CXX object CMakeFiles/adept.dir/Array.cpp.o
[7/12] Building CXX object CMakeFiles/adept.dir/Stack.cpp.o
[8/12] Building CXX object CMakeFiles/adept.dir/inv.cpp.o
[9/12] Building CXX object CMakeFiles/adept.dir/vector_utilities.cpp.o
[10/12] Building CXX object CMakeFiles/adept.dir/jacobian.cpp.o
[11/12] Building CXX object CMakeFiles/adept.dir/solve.cpp.o
[12/12] Linking CXX shared library /home/pkgeval/.julia/adcme/lib/libadept.so
∘ Add the following lines to CMakeLists.txt 

include_directories(${LIBDIR}/Adept-2/include)
find_library(ADEPT_LIB_FILE adept HINTS ${LIBDIR})
find_library(LIBOPENBLAS openblas HINTS ${LIBDIR})
message("ADEPT_LIB_FILE=${ADEPT_LIB_FILE}")
message("LIBOPENBLAS=${LIBOPENBLAS}")

∘ Add `${ADEPT_LIB_FILE}` and `${LIBOPENBLAS}` to `target_link_libraries`
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /home/pkgeval/.julia/adcme/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /home/pkgeval/.julia/adcme/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0
OMP: Info #156: KMP_AFFINITY: 1 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #159: KMP_AFFINITY: 1 packages x 1 cores/pkg x 1 threads/core (1 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 
OMP: Info #250: KMP_AFFINITY: pid 6390 tid 6390 thread 0 bound to OS proc set 0
Python path=/home/pkgeval/.julia/adcme/bin/python
PREFIXDIR=/home/pkgeval/.julia/adcme/lib/Libraries
TF_INC=/home/pkgeval/.julia/adcme/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/adcme/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
ADEPT_LIB_FILE=/home/pkgeval/.julia/adcme/lib/libadept.so
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/packages/ADCME/PJIHk/deps/Plugin/ExtendedNN/build
[1/2] Building CXX object CMakeFiles/ExtendedNn.dir/ExtendedNn.cpp.o
[2/2] Linking CXX shared library libExtendedNn.so
Load library operator (with gradient, multiple outputs = true): /home/pkgeval/.julia/packages/ADCME/PJIHk/deps/Plugin/ExtendedNN/build/libExtendedNn.so ==> extended_nn
Test Summary: | Pass  Total
fcx           |    4      4
Test Summary: | Pass  Total
dropout       |    2      2
Test Summary:      | Pass  Total
sparse_constructor |    7      7
Test Summary:     | Pass  Total
sparse_arithmetic |    4      4
Test Summary:  | Pass  Total
sparse_adjoint |    1      1
Test Summary: | Pass  Total
sparse_mul    |    6      6
Test Summary:    | Pass  Total
sparse_vcat_hcat |    2      2
Test Summary:   | Pass  Total
sparse_indexing |    3      3
Test Summary: | Pass  Total
sparse_solve  |    1      1
k = 1
k = 2
k = 3
k = 4
k = 5
k = 6
k = 7
k = 8
k = 9
k = 10
v = [0.5258647462577528, 0.04255608586744697, 0.7612460736766686, 0.6402243436586623, 0.8623962725632033, 0.5445712130943885, 0.6770633584917491, 0.06662772329459687, 0.7996736588496887, 0.6654007935634196]
2020-10-02 20:54:45.310686: I ../SparseAccumulate/Impl.cpp:68] Create a new sparse assembler [Handle ID = 100] with 20 rows and tolerance 0.

2020-10-02 20:54:45.310877: I ../SparseAccumulate/Impl.cpp:69] Current sparse assembler:
2020-10-02 20:54:45.310900: I ../SparseAccumulate/Impl.cpp:74]  100 |
2020-10-02 20:54:45.310929: I ../SparseAccumulate/Impl.cpp:82] destroy_sparse_assembler
2020-10-02 20:54:45.404691: I ../SparseAccumulate/Impl.cpp:68] Create a new sparse assembler [Handle ID = 100] with 5 rows and tolerance 1.

2020-10-02 20:54:45.404782: I ../SparseAccumulate/Impl.cpp:69] Current sparse assembler:
2020-10-02 20:54:45.404792: I ../SparseAccumulate/Impl.cpp:74]  100 |
2020-10-02 20:54:45.404813: I ../SparseAccumulate/Impl.cpp:82] destroy_sparse_assembler
2020-10-02 20:54:45.550772: I ../SparseAccumulate/Impl.cpp:68] Create a new sparse assembler [Handle ID = 100] with 5 rows and tolerance 0.

2020-10-02 20:54:45.550945: I ../SparseAccumulate/Impl.cpp:69] Current sparse assembler:
2020-10-02 20:54:45.550966: I ../SparseAccumulate/Impl.cpp:74]  100 |
2020-10-02 20:54:45.551001: I ../SparseAccumulate/Impl.cpp:82] destroy_sparse_assembler
Test Summary:    | Pass  Total
sparse_assembler |    3      3
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = \(s::SparseTensor, o::PyObject, method::String) at sparse.jl:426
└ @ ADCME ~/.julia/packages/ADCME/PJIHk/src/sparse.jl:426
Test Summary:       | Pass  Total
sparse_least_square |    1      1
Test Summary:  | Pass  Total
sparse mat mul |    3      3
Test Summary: | Pass  Total
spdiag        |    3      3
Test Summary: | Pass  Total
spzero        |    2      2
Test Summary:   | Pass  Total
sparse indexing |    1      1
Test Summary: | Pass  Total
sum           |    3      3
Test Summary:   | Pass  Total
dense_to_sparse |    2      2
Test Summary: | Pass  Total
spdiagm       |    4      4
Test Summary: | Pass  Total
hvcat         |    1      1
Test Summary: | Pass  Total
find          |    6      6
Test Summary:             | Pass  Total
sparse scatter update add |    2      2
Test Summary:   | Pass  Total
constant sparse |    1      1
Test Summary: | Pass  Total
get index     |    1      1
2020-10-02 20:54:57.789073: I ../SparseFactorizationSolve/Factorization/SparseFactorization.h:32] Factorization: current matrix id= 1, maximum cache size = 999999

2020-10-02 20:54:57.832883: I ../SparseFactorizationSolve/Factorization/SparseFactorization.h:32] Factorization: current matrix id= 2, maximum cache size = 999999

Test Summary:                  | Pass  Total
sparse_factorization_and_solve |    2      2
2020-10-02 20:54:57.964582: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at SparseSolver.cpp:139 : Internal: Sparse solver factorization failed.
2020-10-02 20:54:57.965167: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at SparseSolver.cpp:139 : Internal: Sparse solver factorization failed.
Test Summary:         | Pass  Total
sparse solver warning |    1      1
Test Summary:  | Pass  Total
sparse promote |    6      6
Test Summary: | Pass  Total
trisolve      |    1      1
Test Summary: | Broken  Total
random        |     47     47
Test Summary: | Pass  Total
save and load |    1      1
Test Summary:   | Pass  Total
psave and pload |    1      1
tensorboard --logdir="/tmp/jl_Lb4ouA" --port 0
tensorboard --logdir="/tmp/jl_w2Y7Hw" --port 0
Test Summary: |
diary         | No tests
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = macro expansion at variable.jl:17 [inlined]
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/variable.jl:17
Test Summary: | Pass  Total
indexing      |   28     28
Test Summary: | Pass  Total
Variables     |    4      4
Test Summary: | Pass  Total
tensor        |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/variable.jl:64
Test Summary: | Pass  Total
Hessian       |    2      2
Test Summary: | Pass  Total
Jacobian      |    1      1
Test Summary: | Pass  Total
gradients_v   |    1      1
Test Summary:   | Pass  Total
size and length |    9      9
Test Summary: | Pass  Total
copy          |    1      1
Test Summary: | Pass  Total
getindex      |    1      1
Test Summary:     | Pass  Total
convert_to_tensor |    5      5
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:131
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/variable.jl:131
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:132
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/variable.jl:132
Test Summary: | Pass  Total
cell          |    2      2
Test Summary:    | Pass  Total
special matrices |    2      2
Test Summary:   | Pass  Total
ones/zeros like |    2      2
Test Summary:      | Pass  Total
gradient_magnitude |    1      1
Test Summary:        | Pass  Total
indexing with tensor |    6      6
Test Summary: | Pass  Total
ndims         |    4      4
Test Summary:      | Pass  Total
gradients_colocate |    1      1
Test Summary: | Pass  Total
*             |   27     27
Test Summary: | Pass  Total
reshape       |    6      6
Test Summary:  | Pass  Total
scatter_update |    9      9
Test Summary: | Pass  Total
adjoint       |    4      4
Test Summary:           | Pass  Total
scatter_update_pyobject |    9      9
Test Summary: | Pass  Total
Operators     |   14     14
Test Summary:   | Pass  Total
Other Operators |    1      1
Test Summary:    | Pass  Total
Concat and stack |    6      6
Test Summary: | Pass  Total
Vectorize     |    5      5
Test Summary: | Pass  Total
Solve         |    3      3
Test Summary: | Pass  Total
diff          |    3      3
Test Summary: | Pass  Total
clip          |    1      1
Test Summary: | Pass  Total
map           |    1      1
Test Summary: | Pass  Total
diag          |    2      2
Test Summary: | Pass  Total
dot           |    3      3
Test Summary: | Pass  Total
prod          |    1      1
Test Summary: | Pass  Total
findall       |    2      2
Test Summary: | Pass  Total
svd           |    1      1
Test Summary: | Pass  Total
vector        |    1      1
Test Summary: | Pass  Total
repeat        |    6      6
Test Summary: | Pass  Total
pmap          |    3      3
Test Summary: | Pass  Total
reshape       |    1      1
Test Summary: | Pass  Total
batch mul     |    1      1
Test Summary: | Pass  Total
sort          |    2      2
Test Summary: | Pass  Total
set_shape     |    3      3
Test Summary: | Pass  Total
activation    |    8      8
Test Summary: | Pass  Total
trace         |    1      1
Test Summary: | Pass  Total
trilu         |   22     22
Test Summary: | Pass  Total
reverse       |    3      3
Test Summary: | Pass  Total
solve batch   |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = (::var"#45#46"{PyObject, Int64})() at core.jl:18
└ @ Main ~/.julia/packages/ADCME/PJIHk/test/core.jl:18
Test Summary:      | Pass  Total
control_dependency |    2      2
WARNING: Method definition body(Any, Any) in module Main at /home/pkgeval/.julia/packages/ADCME/PJIHk/test/core.jl:40 overwritten at /home/pkgeval/.julia/packages/ADCME/PJIHk/test/core.jl:73.
Test Summary: | Pass  Total
while loop    |    3      3
Test Summary: | Pass  Total
if_clause     |    1      1
Test Summary:     | Pass  Total
if_else: tf.where |    2      2
Test Summary:          | Pass  Total
get and add collection |    1      1
Test Summary: | Pass  Total
has_gpu       |    1      1
2020-10-02 20:56:04.652436: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6240 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6594 thread 2 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6596 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6597 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6604 thread 12 bound to OS proc set 12
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6605 thread 13 bound to OS proc set 13
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6602 thread 10 bound to OS proc set 10
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6608 thread 16 bound to OS proc set 16
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6607 thread 15 bound to OS proc set 15
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6610 thread 18 bound to OS proc set 18
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6609 thread 17 bound to OS proc set 17
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6611 thread 19 bound to OS proc set 19
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6606 thread 14 bound to OS proc set 14
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6612 thread 20 bound to OS proc set 20
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6599 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6601 thread 9 bound to OS proc set 9
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6600 thread 8 bound to OS proc set 8
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6613 thread 21 bound to OS proc set 21
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6595 thread 3 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6603 thread 11 bound to OS proc set 11
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6598 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6614 thread 22 bound to OS proc set 22
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6615 thread 23 bound to OS proc set 23
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6616 thread 24 bound to OS proc set 24
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6618 thread 26 bound to OS proc set 26
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6617 thread 25 bound to OS proc set 25
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6620 thread 28 bound to OS proc set 28
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6619 thread 27 bound to OS proc set 27
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6621 thread 29 bound to OS proc set 29
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6623 thread 31 bound to OS proc set 31
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6622 thread 30 bound to OS proc set 30
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6624 thread 32 bound to OS proc set 32
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6625 thread 33 bound to OS proc set 33
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6628 thread 36 bound to OS proc set 36
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6626 thread 34 bound to OS proc set 34
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6629 thread 37 bound to OS proc set 37
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6630 thread 38 bound to OS proc set 38
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6632 thread 40 bound to OS proc set 40
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6627 thread 35 bound to OS proc set 35
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6631 thread 39 bound to OS proc set 39
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6638 thread 46 bound to OS proc set 46
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6633 thread 41 bound to OS proc set 41
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6636 thread 44 bound to OS proc set 44
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6637 thread 45 bound to OS proc set 45
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6635 thread 43 bound to OS proc set 43
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6634 thread 42 bound to OS proc set 42
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6639 thread 47 bound to OS proc set 47
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6641 thread 49 bound to OS proc set 49
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6642 thread 50 bound to OS proc set 50
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6640 thread 48 bound to OS proc set 48
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6645 thread 53 bound to OS proc set 53
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6654 thread 62 bound to OS proc set 62
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6652 thread 60 bound to OS proc set 60
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6647 thread 55 bound to OS proc set 55
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6643 thread 51 bound to OS proc set 51
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6649 thread 57 bound to OS proc set 57
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6656 thread 64 bound to OS proc set 64
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6650 thread 58 bound to OS proc set 58
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6653 thread 61 bound to OS proc set 61
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6655 thread 63 bound to OS proc set 63
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6646 thread 54 bound to OS proc set 54
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6648 thread 56 bound to OS proc set 56
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6644 thread 52 bound to OS proc set 52
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6651 thread 59 bound to OS proc set 59
┌ Info: Timeline information saved in test.json
│ - Open Chrome and navigate to chrome://tracing
└ - Load the timeline file
Test Summary: |
timeline      | No tests
Test Summary: | Pass  Total
independent   |    1      1
Test Summary:    | Pass  Total
run corner cases |    1      1
Test Summary: | Pass  Total
@cpu @gpu     |    4      4
Test Summary: | Pass  Total
xavier_init   |    1      1
Load library operator: /home/pkgeval/.julia/packages/ADCME/PJIHk/deps/CustomOps/build/libadcme.so ==> sparse_solver
Load library operator (with gradient, multiple outputs = false): /home/pkgeval/.julia/packages/ADCME/PJIHk/deps/CustomOps/build/libadcme.so ==> sparse_solver
Test Summary: | Pass  Total
load_op       |    2      2
Test Summary: | Pass  Total
ae            |    1      1
[ Info: (1/4)Intializing TensorArray...
[ Info: (2/4)Parsing Condition...
[ Info: (3/4)Parsing Main Loop...
[ Info: (4/4)Postprocessing Results...
Newton-Raphson with absolute tolerance = 1.0e-12 and relative tolerance = 1.0e-12
ITER  2 >>> Error = 15.652475842498529 | Relative Error = 15.652475842498529
ITER  3 >>> Error = 64.928788679993914 | Relative Error = 15.652475842498529
ITER  4 >>> Error = 15.489950495968388 | Relative Error = 64.928788679993914
ITER  5 >>> Error = 2.2725864326069174 | Relative Error = 15.489950495968388
ITER  6 >>> Error = 0.084320075161598992 | Relative Error = 2.2725864326069174
ITER  7 >>> Error = 0.00013179440739372649 | Relative Error = 0.084320075161598992
ITER  8 >>> Error = 3.2366684481841166e-10 | Relative Error = 0.00013179440739372649
ITER  9 >>> Error = 0 | Relative Error = 3.2366684481841166e-10
Test Summary: | Pass  Total
register      |    4      4
Test Summary:         | Pass  Total
list_physical_devices |    1      1
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.0], 5, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([2.0945514815423265], 10, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9708700202758002], 10, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.7390849323725236], 21, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9999996172052663], 19, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.299999999999848], 42, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.45840750163141003], 22, true)
Test Summary:                  | Pass  Total
newton raphson with linesearch |    7      7
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:50
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/optim.jl:50
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:51
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/optim.jl:51
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:51
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/optim.jl:51
[CustomOptimizer] Number of inequalities constraints = 1, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 4
Test Summary: | Pass  Total
NLopt         |    1      1
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:71
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/optim.jl:71
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:71
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/optim.jl:71
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:71
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/optim.jl:71
[CustomOptimizer] Number of inequalities constraints = 0, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 2
[CustomOptimizer] No bounds provided, use (-∞, +∞) as default; or you need to provide bounds in the function CustomOptimizer
(f, df, c, dc, x0) = (ADCME.var"#f#494"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7f33801a13b0>), ADCME.var"#df#495"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7f33801a13b0>), ADCME.var"#c#496"{Vector{Float64}, Vector{Any}, Vector{Any}, Int64, Int64}([0.5258647462577528, 0.04255608586744697], Any[], Any[], 0, 0), ADCME.var"#dc#499"{Vector{Float64}, Vector{Any}, Vector{Any}, Int64, Int64, Int64, Int64}([0.5258647462577528, 0.04255608586744697], Any[], Any[], 0, 2, 0, 0), [0.5258647462577528, 0.04255608586744697])
Test Summary: | Pass  Total
Optim         |    1      1
Test Summary:  | Broken  Total
newton raphson |      1      1
Test Summary:               | Broken  Total
NonlinearConstrainedProblem |      1      1
[ Info: Optimization starts...
iter 1, current loss = 9786.982357426994
[ Info: (0, 9786.982357426994)
================== STEP 0 ==================
iter 2, current loss = 8.663985265017026e11
iter 3, current loss = 3446.0505536097544
[ Info: (1, 3446.0505536097544)
================== STEP 1 ==================
iter 4, current loss = 3166.472396052265
iter 5, current loss = 2350.77327189119
iter 6, current loss = 5535.001796739056
iter 7, current loss = 2010.9973516802402
[ Info: (2, 2010.9973516802402)
================== STEP 2 ==================
iter 8, current loss = 2004.456759627545
iter 9, current loss = 1978.4009282407205
iter 10, current loss = 1850.678655081477
iter 11, current loss = 1275.9893836574174
iter 12, current loss = 0.5953858409883743
iter 13, current loss = 8.489235140170597e-21
[ Info: (3, 8.489235140170597e-21)
================== STEP 3 ==================
iter 14, current loss = 4.4761857056128304e-18
iter 15, current loss = 8.432460324274025e-21
[ Info: (4, 8.432460324274025e-21)
================== STEP 4 ==================
Test Summary: | Pass  Total
Custom BFGS!  |    1      1
[ Info: Optimization starts...
iter 0, current loss=4.0
iter 1, current loss=1.0
================ STEP 0 ===============
Test Summary: | Pass  Total
var_to_bounds |    1      1
┌ Warning: θ is not a PyObject, no gradients is available
└ @ ADCME ~/.julia/packages/ADCME/PJIHk/src/optim.jl:591
Test Summary:            | Pass  Total
newton_raphson_with_grad |    3      3
Test Summary:   | Pass  Total
pack and unpack |    2      2
Test Summary:    | Pass  Total
search direction |    1      1
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:300
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/optim.jl:300
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:300
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/optim.jl:300
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:300
└ @ Core ~/.julia/packages/ADCME/PJIHk/test/optim.jl:300
[ Info: Optimization starts...
iter 1, current loss = 29.77495433488601
[ Info: (0, 29.77495433488601)
================== STEP 0 ==================
iter 2, current loss = 8.921619452579999e10
iter 3, current loss = 29.77000824372986
iter 4, current loss = 2.1183865832467097
[ Info: (1, 2.1183865832467097)
================== STEP 1 ==================
iter 5, current loss = 0.387896917131637
iter 6, current loss = 9.376409938093095
iter 7, current loss = 0.23426630924727576
[ Info: (2, 0.23426630924727576)
================== STEP 2 ==================
iter 8, current loss = 0.21906941314478418
iter 9, current loss = 0.40384592658705154
iter 10, current loss = 0.21885046568046868
[ Info: (3, 0.21885046568046868)
================== STEP 3 ==================
iter 11, current loss = 0.21788966709086485
iter 12, current loss = 0.2140905212868193
iter 13, current loss = 0.1963715574425575
iter 14, current loss = 0.19087538585512115
iter 15, current loss = 0.17147233619904378
[ Info: (4, 0.17147233619904378)
================== STEP 4 ==================
iter 16, current loss = 0.1439391003017846
iter 17, current loss = 0.141359201798127
[ Info: (5, 0.141359201798127)
================== STEP 5 ==================
iter 18, current loss = 0.09169384095791405
iter 19, current loss = 0.09208904701389839
iter 20, current loss = 0.05470314041836701
[ Info: (6, 0.05470314041836701)
================== STEP 6 ==================
iter 21, current loss = 0.03806405617478366
iter 22, current loss = 0.06889950960747757
iter 23, current loss = 0.04187996437507287
[ Info: (7, 0.04187996437507287)
================== STEP 7 ==================
iter 24, current loss = 1.3627045291275706
iter 25, current loss = 0.03584740938662851
iter 26, current loss = 0.0818504895879941
iter 27, current loss = 0.019150670311634546
[ Info: (8, 0.019150670311634546)
================== STEP 8 ==================
iter 28, current loss = 249.73082833593827
iter 29, current loss = 0.01884254276467317
iter 30, current loss = 0.1874862663646858
iter 31, current loss = 0.01199435146479711
[ Info: (9, 0.01199435146479711)
================== STEP 9 ==================
iter 32, current loss = 0.05473468781624296
iter 33, current loss = 0.006313919063226883
[ Info: (10, 0.006313919063226883)
================== STEP 10 ==================
iter 34, current loss = 0.005910728585056849
iter 35, current loss = 0.0032868272924792023
[ Info: (11, 0.0032868272924792023)
================== STEP 11 ==================
iter 36, current loss = 0.0029244460761973677
iter 37, current loss = 0.010979075223758199
iter 38, current loss = 0.0029244328584018316
[ Info: (12, 0.0029244328584018316)
================== STEP 12 ==================
iter 39, current loss = 0.0026668284210614444
iter 40, current loss = 0.0017886299932553466
iter 41, current loss = 0.00023784893268331042
iter 42, current loss = 0.00020355009029267396
[ Info: (13, 0.00020355009029267396)
================== STEP 13 ==================
iter 43, current loss = 9.655507465638792e-5
iter 44, current loss = 2.1788363223012735e-5
[ Info: (14, 2.1788363223012735e-5)
================== STEP 14 ==================
iter 45, current loss = 3.2800735680266968e-6
iter 46, current loss = 8.954145027924338e-5
iter 47, current loss = 2.8348553062245507e-9
[ Info: (15, 2.8348553062245507e-9)
================== STEP 15 ==================
iter 48, current loss = 5.669669934638837e-12
iter 49, current loss = 3.6453716949822266e-14
[ Info: (16, 3.6453716949822266e-14)
================== STEP 16 ==================
iter 50, current loss = 8.326136928337045e-17
iter 51, current loss = 5.156614745502032e-13
iter 52, current loss = 1.1055339054420316e-20
[ Info: (17, 1.1055339054420316e-20)
================== STEP 17 ==================
iter 53, current loss = 3.605291552086329e-27
iter 54, current loss = 1.7664073670911203e-19
iter 55, current loss = 1.4914401489334754e-30
[ Info: (18, 1.4914401489334754e-30)
================== STEP 18 ==================
[ Info: Optimization starts...
iter 1, current loss = 29.77495433488601
[ Info: (0, 29.77495433488601)
================== STEP 0 ==================
iter 2, current loss = 1.2844869331838623e8
iter 3, current loss = 29.64133570492479
iter 4, current loss = 2.1124875131812697
[ Info: (1, 2.1124875131812697)
================== STEP 1 ==================
iter 5, current loss = 1.709569217321523
iter 6, current loss = 0.23488638051194455
[ Info: (2, 0.23488638051194455)
================== STEP 2 ==================
iter 7, current loss = 0.2306357538703295
iter 8, current loss = 0.22050005506074866
[ Info: (3, 0.22050005506074866)
================== STEP 3 ==================
iter 9, current loss = 0.22029733788919997
iter 10, current loss = 0.21421328789430247
iter 11, current loss = 0.16546346229148923
[ Info: (4, 0.16546346229148923)
================== STEP 4 ==================
iter 12, current loss = 0.1641988658751954
iter 13, current loss = 0.15196615388312282
[ Info: (5, 0.15196615388312282)
================== STEP 5 ==================
iter 14, current loss = 0.13075280787713467
iter 15, current loss = 0.12506110105130103
[ Info: (6, 0.12506110105130103)
================== STEP 6 ==================
iter 16, current loss = 0.051349319904529525
iter 17, current loss = 0.04393203849998187
[ Info: (7, 0.04393203849998187)
================== STEP 7 ==================
iter 18, current loss = 0.0427672593830864
iter 19, current loss = 0.036068091092936995
[ Info: (8, 0.036068091092936995)
================== STEP 8 ==================
iter 20, current loss = 0.018095090909760955
iter 21, current loss = 6.2809566153349
iter 22, current loss = 0.03491076855996107
iter 23, current loss = 0.32633855408625456
iter 24, current loss = 0.030030958900218535
iter 25, current loss = 0.0125609693972702
iter 26, current loss = 0.012565273161596115
[ Info: (9, 0.012565273161596115)
================== STEP 9 ==================
iter 27, current loss = 0.04092806313514242
iter 28, current loss = 0.008076514132794607
[ Info: (10, 0.008076514132794607)
================== STEP 10 ==================
iter 29, current loss = 0.008035003679960762
iter 30, current loss = 0.006558254030956571
[ Info: (11, 0.006558254030956571)
================== STEP 11 ==================
iter 31, current loss = 0.006161698340370341
iter 32, current loss = 0.0013738346184259008
[ Info: (12, 0.0013738346184259008)
================== STEP 12 ==================
iter 33, current loss = 0.0010662208122001625
iter 34, current loss = 0.0004883506864680672
[ Info: (13, 0.0004883506864680672)
================== STEP 13 ==================
iter 35, current loss = 0.00014612528134885317
iter 36, current loss = 2.9483167631992663e-5
[ Info: (14, 2.9483167631992663e-5)
================== STEP 14 ==================
iter 37, current loss = 1.4393198543993001e-5
iter 38, current loss = 2.757078613907403e-6
[ Info: (15, 2.757078613907403e-6)
================== STEP 15 ==================
iter 39, current loss = 2.7264036784646423e-6
iter 40, current loss = 2.66148197559796e-6
[ Info: (16, 2.66148197559796e-6)
================== STEP 16 ==================
iter 41, current loss = 2.66009846606302e-6
iter 42, current loss = 2.9733385607933556e-10
[ Info: (17, 2.9733385607933556e-10)
================== STEP 17 ==================
iter 43, current loss = 1.096585541000353e-5
iter 44, current loss = 2.7383156501230922e-11
[ Info: (18, 2.7383156501230922e-11)
================== STEP 18 ==================
iter 45, current loss = 2.736678765549519e-11
iter 46, current loss = 1.534849045885187e-11
[ Info: (19, 1.534849045885187e-11)
================== STEP 19 ==================
iter 47, current loss = 1.0790440080747527e-8
iter 48, current loss = 1.8219268353576354e-17
[ Info: (20, 1.8219268353576354e-17)
================== STEP 20 ==================
iter 49, current loss = 1.2344973638285523e-17
iter 50, current loss = 9.434005485778136e-18
[ Info: (21, 9.434005485778136e-18)
================== STEP 21 ==================
iter 51, current loss = 9.432096990881305e-18
iter 52, current loss = 4.788873268375007e-19
[ Info: (22, 4.788873268375007e-19)
================== STEP 22 ==================
iter 53, current loss = 9.336377516324669e-18
iter 54, current loss = 4.781559102808935e-19
[ Info: (23, 4.781559102808935e-19)
================== STEP 23 ==================
iter 55, current loss = 4.776185892321144e-19
iter 56, current loss = 6.339451976053694e-21
[ Info: (24, 6.339451976053694e-21)
================== STEP 24 ==================
iter 57, current loss = 2.801605034493508e-19
iter 58, current loss = 6.329569289730077e-21
[ Info: (25, 6.329569289730077e-21)
================== STEP 25 ==================
Test Summary: | Pass  Total
Optim         |    2      2
[ Info: 3.900395188869995e-8
[2.6873403110589567, 2.2848777584058286, 1.9594851778940718, 1.6954024050853085, 1.4802634931976848, 1.304318508155104, 1.1598475045894157, 1.0407152651051805, 0.9420302552703155, 0.8598815076342154]
[2.6873403110589567, 2.284877740310942, 1.9594851486009872, 1.6954023693861155, 1.4802634543798445, 1.3043184684311484, 1.1598474654062376, 1.0407152273674067, 0.9420302195019175, 0.8598814740954398]
[ Info: 1.7492351763217855e-6
[2.6873403110589567, 2.51968033219294, 2.3591800737664697, 2.205947431997972, 2.0600573213745235, 1.9215424113722332, 1.7903868796137, 1.6665331065514712, 1.5498999348193685, 1.4403938823398201]
[2.6873403110589567, 2.5196803722971524, 2.3591806721463433, 2.2059490607905317, 2.0600593252906663, 1.9215446484117815, 1.7903894445161121, 1.6665356793266155, 1.5499024452536934, 1.4403964019318742]
[ Info: 0.009280891261506266
[2.6873403110589567, 2.519680334828145, 2.407655825231478, 2.319781537411425, 2.246150283167248, 2.182163783773478, 2.1252505434992806, 2.073802233315023, 2.0267344163791177, 1.9832752878804247]
[2.6873403110589567, 2.5289466959494193, 2.4204906422698946, 2.3345738165870635, 2.2621849805281444, 2.1990517443624444, 2.1427536022001736, 2.0917631683139026, 2.045043876227474, 2.001854279772373]
[ Info: 0.00026401080077454944
[2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567]
[2.6873403110589567, 2.687263777750499, 2.687186271558512, 2.687108108244675, 2.6870294441458276, 2.686950372370638, 2.6868709546007836, 2.6867912346415768, 2.686711245167153, 2.686631011454237]
ADCME.Optimizer.RMSProp: 
[2.6873403110589567, 2.1809229506849572, 1.876707980129773, 1.6546592408302834, 1.479244033062772, 1.3346961766756142, 1.2124398515964887, 1.1071870862263171, 1.015408944687647, 0.9346163191023285]
ADCME.Optimizer.AMSGrad: 
[2.6873403110589567, 2.180931270734745, 1.6124928714759128, 1.1086151780363889, 0.7379095523937294, 0.526063739275981, 0.4585161239500091, 0.4877499962958967, 0.5512317022689825, 0.5952183172262842]
ADCME.Optimizer.NADAM: 
[2.6873403110589567, 2.4425702565335135, 2.2636223209469, 2.1059931830955145, 1.9611223452288684, 1.8261560639124625, 1.699821585350836, 1.5814319739611473, 1.470562155887079, 1.3669096060903072]
ADCME.Optimizer.Momentum: 
[2.6873403110589567, 0.5561138694752266, 1.9019191744859019, 1.5251751312785737, 0.04201579412822935, 1.1070655728753587, 0.9972859136071752, 0.09250596740575295, 0.8373703084967707, 0.9155307151492693]
ADCME.Optimizer.Nesterov: 
[2.6873403110589567, 1.9593498023002809, 1.2701537117986894, 0.7838060906690361, 0.5406336834135215, 0.48898653622901833, 0.5361697434507273, 0.593802848884102, 0.6052577936273842, 0.553136858054489]
ADCME.Optimizer.RADAM: 
[2.6873403110589567, 2.284877758405829, 1.9432397781298896, 1.655285612561695, 1.4144226819237642, 1.4126078826685304, 1.409924914461023, 1.4065453158264798, 1.4025672017224886, 1.3980581649489405]
ADCME.Optimizer.AdaMax: 
[2.6873403110589567, 2.51968033219294, 2.362208211311266, 2.2144819560814186, 2.076059233397677, 1.9464997124427987, 1.8253670164593165, 1.7122304206311472, 1.6066663584779954, 1.5082598767767745]
Test Summary: | Pass  Total
Optimizers    |    4      4
Test Summary: | Pass  Total
sinkhorn      |    1      1
Test Summary: | Pass  Total
dist          |    5      5
WARNING: Method definition f(Any, Any, Any) in module Main at /home/pkgeval/.julia/packages/ADCME/PJIHk/test/ode.jl:2 overwritten at /home/pkgeval/.julia/packages/ADCME/PJIHk/test/ode.jl:13.
Test Summary: | Pass  Total
runge_kutta   |    6      6
Test Summary: | Pass  Total
alpha scheme  |    2      2
Test Summary: | Pass  Total
LinearFlow    |    2      2
Test Summary:      | Pass  Total
AffineConstantFlow |    2      2
ActNorm: initializing s and t...
Test Summary: | Pass  Total
ActNorm       |    2      2
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6239 thread 65 bound to OS proc set 65
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6675 thread 66 bound to OS proc set 66
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6678 thread 69 bound to OS proc set 69
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6676 thread 67 bound to OS proc set 67
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6679 thread 70 bound to OS proc set 70
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6680 thread 71 bound to OS proc set 71
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6683 thread 74 bound to OS proc set 74
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6682 thread 73 bound to OS proc set 73
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6684 thread 75 bound to OS proc set 75
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6677 thread 68 bound to OS proc set 68
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6681 thread 72 bound to OS proc set 72
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6685 thread 76 bound to OS proc set 76
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6686 thread 77 bound to OS proc set 77
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6687 thread 78 bound to OS proc set 78
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6688 thread 79 bound to OS proc set 79
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6689 thread 80 bound to OS proc set 80
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6690 thread 81 bound to OS proc set 81
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6693 thread 84 bound to OS proc set 84
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6691 thread 82 bound to OS proc set 82
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6698 thread 89 bound to OS proc set 89
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6692 thread 83 bound to OS proc set 83
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6694 thread 85 bound to OS proc set 85
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6702 thread 93 bound to OS proc set 93
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6700 thread 91 bound to OS proc set 91
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6703 thread 94 bound to OS proc set 94
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6699 thread 90 bound to OS proc set 90
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6697 thread 88 bound to OS proc set 88
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6711 thread 102 bound to OS proc set 102
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6701 thread 92 bound to OS proc set 92
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6723 thread 114 bound to OS proc set 114
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6716 thread 107 bound to OS proc set 107
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6696 thread 87 bound to OS proc set 87
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6695 thread 86 bound to OS proc set 86
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6704 thread 95 bound to OS proc set 95
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6724 thread 115 bound to OS proc set 115
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6725 thread 116 bound to OS proc set 116
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6726 thread 117 bound to OS proc set 117
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6727 thread 118 bound to OS proc set 118
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6728 thread 119 bound to OS proc set 119
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6714 thread 105 bound to OS proc set 105
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6708 thread 99 bound to OS proc set 99
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6730 thread 121 bound to OS proc set 121
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6732 thread 123 bound to OS proc set 123
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6719 thread 110 bound to OS proc set 110
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6729 thread 120 bound to OS proc set 120
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6735 thread 126 bound to OS proc set 126
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6720 thread 111 bound to OS proc set 111
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6718 thread 109 bound to OS proc set 109
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6733 thread 124 bound to OS proc set 124
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6721 thread 112 bound to OS proc set 112
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6736 thread 127 bound to OS proc set 127
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6709 thread 100 bound to OS proc set 100
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6722 thread 113 bound to OS proc set 113
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6717 thread 108 bound to OS proc set 108
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6737 thread 128 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6715 thread 106 bound to OS proc set 106
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6713 thread 104 bound to OS proc set 104
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6712 thread 103 bound to OS proc set 103
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6705 thread 96 bound to OS proc set 96
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6706 thread 97 bound to OS proc set 97
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6707 thread 98 bound to OS proc set 98
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6710 thread 101 bound to OS proc set 101
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6731 thread 122 bound to OS proc set 122
OMP: Info #250: KMP_AFFINITY: pid 4316 tid 6734 thread 125 bound to OS proc set 125
Test Summary: | Pass  Total
SlowMAF       |    2      2
Test Summary: | Pass  Total
MAF           |    2      2
Test Summary: | Pass  Total
IAF           |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = tril(o::PyObject, num::Int64) at ops.jl:1136
└ @ ADCME ~/.julia/packages/ADCME/PJIHk/src/ops.jl:1136
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = triu(o::PyObject, num::Int64) at ops.jl:1152
└ @ ADCME ~/.julia/packages/ADCME/PJIHk/src/ops.jl:1152
Test Summary:     | Pass  Total
Invertible1x1Conv |    2      2
Test Summary:  | Pass  Total
AffineHalfFlow |    2      2
Test Summary:      | Broken  Total
NeuralCouplingFlow |      1      1
Test Summary: | Pass  Total
Permute       |    2      2
Test Summary: | Pass  Total
composite     |    2      2
QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-pkgeval'
Finite difference: [0.4718287747474043, 0.04330434936179065, 0.004293001322023458, 0.00042892713796974035, 4.28889851956403e-5]
Automatic differentiation: [0.04406251847654709, 0.0004263396450686727, 4.249208240564365e-6, 4.247790432831929e-8, 4.247648831235372e-10]
Test Summary: | Pass  Total
test_jacobian |    1      1
[ Info: (1, 10)
[ Info: (2, 10)
[ Info: (3, 10)
[ Info: (4, 10)
[ Info: (5, 10)
[ Info: (6, 10)
[ Info: (7, 10)
[ Info: (8, 10)
[ Info: (9, 10)
[ Info: (10, 10)
Test Summary: | Pass  Total
lineview      |    1      1
[ Info: (1, 9)
[ Info: (2, 9)
[ Info: (3, 9)
[ Info: (4, 9)
[ Info: (5, 9)
[ Info: (6, 9)
[ Info: (7, 9)
[ Info: (8, 9)
[ Info: (9, 9)
[ Info: (1, 9)
[ Info: (2, 9)
[ Info: (3, 9)
[ Info: (4, 9)
[ Info: (5, 9)
[ Info: (6, 9)
[ Info: (7, 9)
[ Info: (8, 9)
[ Info: (9, 9)
Test Summary: | Pass  Total
meshview      |    2      2
[ Info: 1
[ Info: 2
[ Info: 3
[ Info: 4
[ Info: 5
Test Summary: | Pass  Total
gradview      |    1      1
Test Summary: | Pass  Total
jacview       |    1      1
Test Summary: |
PCLview       | No tests
sys:1: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.
sys:1: UserWarning: Attempted to set non-positive left xlim on a log-scaled axis.
Invalid limit will be ignored.
sys:1: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.
Invalid limit will be ignored.
MovieWriter imagemagick unavailable; using Pillow instead.
Test Summary: | Pass  Total
animate       |    1      1
    Testing ADCME tests passed 
