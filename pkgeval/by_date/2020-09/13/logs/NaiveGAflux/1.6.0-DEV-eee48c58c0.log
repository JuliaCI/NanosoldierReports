Julia Version 1.6.0-DEV.898
Commit eee48c58c0 (2020-09-12 15:01 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake-avx512)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
[ Info: LEGAL NOTICE: package operations send anonymous data about your system to https://pkg.julialang.org (your current package server), including the operating system and Julia versions you are using, and a random client UUID. Running `Pkg.telemetryinfo()` will show exactly what data is sent. See https://julialang.org/legal/data/ for more details about what this data is used for, how long it is retained, and how to opt out of sending it.
  Installed DataAPI ────────────────────── v1.3.0
  Installed CodecZlib ──────────────────── v0.7.0
  Installed Bzip2_jll ──────────────────── v1.0.6+4
  Installed FillArrays ─────────────────── v0.9.6
  Installed CUDA ───────────────────────── v1.3.3
  Installed IniFile ────────────────────── v0.5.0
  Installed Inflate ────────────────────── v0.1.2
  Installed DataStructures ─────────────── v0.17.20
  Installed JSONSchema ─────────────────── v0.3.2
  Installed ExprTools ──────────────────── v0.1.2
  Installed IterTools ──────────────────── v1.3.0
  Installed ColorTypes ─────────────────── v0.10.9
  Installed MuladdMacro ────────────────── v0.2.2
  Installed Cbc_jll ────────────────────── v2.10.3+4
  Installed OrderedCollections ─────────── v1.3.0
  Installed Adapt ──────────────────────── v2.0.2
  Installed Osi_jll ────────────────────── v0.108.5+3
  Installed BenchmarkTools ─────────────── v0.5.0
  Installed Missings ───────────────────── v0.4.4
  Installed Cgl_jll ────────────────────── v0.60.2+5
  Installed Juno ───────────────────────── v0.8.3
  Installed Media ──────────────────────── v0.5.0
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed SortingAlgorithms ──────────── v0.3.1
  Installed MacroTools ─────────────────── v0.5.5
  Installed CodecBzip2 ─────────────────── v0.7.2
  Installed Calculus ───────────────────── v0.5.1
  Installed SpecialFunctions ───────────── v0.10.3
  Installed MetaGraphs ─────────────────── v0.6.5
  Installed IRTools ────────────────────── v0.4.1
  Installed SimpleTraits ───────────────── v0.9.3
  Installed NaiveNASlib ────────────────── v1.3.0
  Installed ZygoteRules ────────────────── v0.2.0
  Installed MbedTLS_jll ────────────────── v2.16.8+0
  Installed Zygote ─────────────────────── v0.5.6
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed NaiveGAflux ────────────────── v0.7.0
  Installed MbedTLS ────────────────────── v1.0.2
  Installed OpenBLAS32_jll ─────────────── v0.3.9+4
  Installed Parsers ────────────────────── v1.0.10
  Installed TranscodingStreams ─────────── v0.9.5
  Installed NaiveNASflux ───────────────── v1.5.0
  Installed Functors ───────────────────── v0.1.0
  Installed Requires ───────────────────── v1.0.2
  Installed CpuId ──────────────────────── v0.2.2
  Installed Reexport ───────────────────── v0.2.0
  Installed CommonSubexpressions ───────── v0.3.0
  Installed SLEEFPirates ───────────────── v0.5.5
  Installed ChainRulesCore ─────────────── v0.9.9
  Installed JSON ───────────────────────── v0.21.1
  Installed Zlib_jll ───────────────────── v1.2.11+16
  Installed NaNMath ────────────────────── v0.3.4
  Installed TimerOutputs ───────────────── v0.5.6
  Installed MemPool ────────────────────── v0.3.1
  Installed SIMDPirates ────────────────── v0.8.25
  Installed AbstractTrees ──────────────── v0.3.3
  Installed ZipFile ────────────────────── v0.9.2
  Installed LoopVectorization ──────────── v0.8.26
  Installed JuMP ───────────────────────── v0.21.3
  Installed CEnum ──────────────────────── v0.3.0
  Installed BinaryProvider ─────────────── v0.5.10
  Installed Cbc ────────────────────────── v0.7.0
  Installed FileIO ─────────────────────── v1.4.3
  Installed Colors ─────────────────────── v0.12.4
  Installed DocStringExtensions ────────── v0.8.3
  Installed UnPack ─────────────────────── v1.0.2
  Installed VectorizationBase ──────────── v0.12.33
  Installed JLD2 ───────────────────────── v0.1.14
  Installed ForwardDiff ────────────────── v0.10.12
  Installed GPUArrays ──────────────────── v5.1.0
  Installed ChainRules ─────────────────── v0.7.18
  Installed DiffRules ──────────────────── v1.0.1
  Installed Flux ───────────────────────── v0.11.1
  Installed Clp_jll ────────────────────── v1.17.6+6
  Installed LLVM ───────────────────────── v2.0.0
  Installed Setfield ───────────────────── v0.7.0
  Installed CoinUtils_jll ──────────────── v2.11.3+3
  Installed DiffResults ────────────────── v1.0.2
  Installed NNlib ──────────────────────── v0.7.4
  Installed ConstructionBase ───────────── v1.0.0
  Installed OffsetArrays ───────────────── v1.1.3
  Installed MutableArithmetics ─────────── v0.2.10
  Installed StaticArrays ───────────────── v0.12.4
  Installed StatsBase ──────────────────── v0.33.1
  Installed GPUCompiler ────────────────── v0.6.1
  Installed MathOptInterface ───────────── v0.9.14
  Installed LightGraphs ────────────────── v1.3.3
  Installed FixedPointNumbers ──────────── v0.8.4
  Installed ArrayLayouts ───────────────── v0.4.7
  Installed ArnoldiMethod ──────────────── v0.0.4
  Installed HTTP ───────────────────────── v0.8.17
Updating `~/.julia/environments/v1.6/Project.toml`
  [81ede08e] + NaiveGAflux v0.7.0
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [1520ce14] + AbstractTrees v0.3.3
  [79e6a3ab] + Adapt v2.0.2
  [ec485272] + ArnoldiMethod v0.0.4
  [4c555306] + ArrayLayouts v0.4.7
  [6e4b80f9] + BenchmarkTools v0.5.0
  [b99e7846] + BinaryProvider v0.5.10
  [6e34b625] + Bzip2_jll v1.0.6+4
  [fa961155] + CEnum v0.3.0
  [052768ef] + CUDA v1.3.3
  [49dc2e85] + Calculus v0.5.1
  [9961bab8] + Cbc v0.7.0
  [38041ee0] + Cbc_jll v2.10.3+4
  [3830e938] + Cgl_jll v0.60.2+5
  [082447d4] + ChainRules v0.7.18
  [d360d2e6] + ChainRulesCore v0.9.9
  [06985876] + Clp_jll v1.17.6+6
  [523fee87] + CodecBzip2 v0.7.2
  [944b1d66] + CodecZlib v0.7.0
  [be027038] + CoinUtils_jll v2.11.3+3
  [3da002f7] + ColorTypes v0.10.9
  [5ae59095] + Colors v0.12.4
  [bbf7d656] + CommonSubexpressions v0.3.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [187b0558] + ConstructionBase v1.0.0
  [adafc99b] + CpuId v0.2.2
  [9a962f9c] + DataAPI v1.3.0
  [864edb3b] + DataStructures v0.17.20
  [163ba53b] + DiffResults v1.0.2
  [b552c78f] + DiffRules v1.0.1
  [ffbed154] + DocStringExtensions v0.8.3
  [e2ba6199] + ExprTools v0.1.2
  [5789e2e9] + FileIO v1.4.3
  [1a297f60] + FillArrays v0.9.6
  [53c48c17] + FixedPointNumbers v0.8.4
  [587475ba] + Flux v0.11.1
  [f6369f11] + ForwardDiff v0.10.12
  [d9f16b24] + Functors v0.1.0
  [0c68f7d7] + GPUArrays v5.1.0
  [61eb1bfa] + GPUCompiler v0.6.1
  [cd3eb016] + HTTP v0.8.17
  [7869d1d1] + IRTools v0.4.1
  [d25df0c9] + Inflate v0.1.2
  [83e8ac13] + IniFile v0.5.0
  [c8e1da08] + IterTools v1.3.0
  [033835bb] + JLD2 v0.1.14
  [682c06a0] + JSON v0.21.1
  [7d188eb4] + JSONSchema v0.3.2
  [4076af6c] + JuMP v0.21.3
  [e5e0dc1b] + Juno v0.8.3
  [929cbde3] + LLVM v2.0.0
  [093fc24a] + LightGraphs v1.3.3
  [bdcacae8] + LoopVectorization v0.8.26
  [1914dd2f] + MacroTools v0.5.5
  [b8f27783] + MathOptInterface v0.9.14
  [739be429] + MbedTLS v1.0.2
  [c8ffd9c3] + MbedTLS_jll v2.16.8+0
  [e89f7d12] + Media v0.5.0
  [f9f48841] + MemPool v0.3.1
  [626554b9] + MetaGraphs v0.6.5
  [e1d29d7a] + Missings v0.4.4
  [46d2c3a1] + MuladdMacro v0.2.2
  [d8a4904e] + MutableArithmetics v0.2.10
  [872c559c] + NNlib v0.7.4
  [77ba4419] + NaNMath v0.3.4
  [81ede08e] + NaiveGAflux v0.7.0
  [85610aed] + NaiveNASflux v1.5.0
  [bd45eb3e] + NaiveNASlib v1.3.0
  [6fe1bfb0] + OffsetArrays v1.1.3
  [656ef2d0] + OpenBLAS32_jll v0.3.9+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [bac558e1] + OrderedCollections v1.3.0
  [7da25872] + Osi_jll v0.108.5+3
  [69de0a69] + Parsers v1.0.10
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v1.0.2
  [21efa798] + SIMDPirates v0.8.25
  [476501e8] + SLEEFPirates v0.5.5
  [efcf1570] + Setfield v0.7.0
  [699a6c99] + SimpleTraits v0.9.3
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.10.3
  [90137ffa] + StaticArrays v0.12.4
  [2913bbd2] + StatsBase v0.33.1
  [a759f4b9] + TimerOutputs v0.5.6
  [3bb67fe8] + TranscodingStreams v0.9.5
  [3a884ed6] + UnPack v1.0.2
  [3d5dd08c] + VectorizationBase v0.12.33
  [a5390f91] + ZipFile v0.9.2
  [83775a58] + Zlib_jll v1.2.11+16
  [e88e6eb3] + Zygote v0.5.6
  [700de1a5] + ZygoteRules v0.2.0
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8bb1440f] + DelimitedFiles
  [8ba89e20] + Distributed
  [9fa8497b] + Future
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [9abbd945] + Profile
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [1a1011a3] + SharedArrays
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [fa267f1f] + TOML
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
   Building SLEEFPirates → `~/.julia/packages/SLEEFPirates/jGsib/deps/build.log`
   Building Cbc ─────────→ `~/.julia/packages/Cbc/f5sSt/deps/build.log`
    Testing NaiveGAflux
Status `/tmp/jl_0D9M5T/Project.toml`
  [052768ef] CUDA v1.3.3
  [c8e1da08] IterTools v1.3.0
  [f9f48841] MemPool v0.3.1
  [81ede08e] NaiveGAflux v0.7.0
  [85610aed] NaiveNASflux v1.5.0
  [189a3867] Reexport v0.2.0
  [efcf1570] Setfield v0.7.0
  [56ddb016] Logging
  [44cfe95a] Pkg
  [9a3f8284] Random
  [9e88b42a] Serialization
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_0D9M5T/Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [1520ce14] AbstractTrees v0.3.3
  [79e6a3ab] Adapt v2.0.2
  [ec485272] ArnoldiMethod v0.0.4
  [4c555306] ArrayLayouts v0.4.7
  [6e4b80f9] BenchmarkTools v0.5.0
  [b99e7846] BinaryProvider v0.5.10
  [6e34b625] Bzip2_jll v1.0.6+4
  [fa961155] CEnum v0.3.0
  [052768ef] CUDA v1.3.3
  [49dc2e85] Calculus v0.5.1
  [9961bab8] Cbc v0.7.0
  [38041ee0] Cbc_jll v2.10.3+4
  [3830e938] Cgl_jll v0.60.2+5
  [082447d4] ChainRules v0.7.18
  [d360d2e6] ChainRulesCore v0.9.9
  [06985876] Clp_jll v1.17.6+6
  [523fee87] CodecBzip2 v0.7.2
  [944b1d66] CodecZlib v0.7.0
  [be027038] CoinUtils_jll v2.11.3+3
  [3da002f7] ColorTypes v0.10.9
  [5ae59095] Colors v0.12.4
  [bbf7d656] CommonSubexpressions v0.3.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [187b0558] ConstructionBase v1.0.0
  [adafc99b] CpuId v0.2.2
  [9a962f9c] DataAPI v1.3.0
  [864edb3b] DataStructures v0.17.20
  [163ba53b] DiffResults v1.0.2
  [b552c78f] DiffRules v1.0.1
  [ffbed154] DocStringExtensions v0.8.3
  [e2ba6199] ExprTools v0.1.2
  [5789e2e9] FileIO v1.4.3
  [1a297f60] FillArrays v0.9.6
  [53c48c17] FixedPointNumbers v0.8.4
  [587475ba] Flux v0.11.1
  [f6369f11] ForwardDiff v0.10.12
  [d9f16b24] Functors v0.1.0
  [0c68f7d7] GPUArrays v5.1.0
  [61eb1bfa] GPUCompiler v0.6.1
  [cd3eb016] HTTP v0.8.17
  [7869d1d1] IRTools v0.4.1
  [d25df0c9] Inflate v0.1.2
  [83e8ac13] IniFile v0.5.0
  [c8e1da08] IterTools v1.3.0
  [033835bb] JLD2 v0.1.14
  [682c06a0] JSON v0.21.1
  [7d188eb4] JSONSchema v0.3.2
  [4076af6c] JuMP v0.21.3
  [e5e0dc1b] Juno v0.8.3
  [929cbde3] LLVM v2.0.0
  [093fc24a] LightGraphs v1.3.3
  [bdcacae8] LoopVectorization v0.8.26
  [1914dd2f] MacroTools v0.5.5
  [b8f27783] MathOptInterface v0.9.14
  [739be429] MbedTLS v1.0.2
  [c8ffd9c3] MbedTLS_jll v2.16.8+0
  [e89f7d12] Media v0.5.0
  [f9f48841] MemPool v0.3.1
  [626554b9] MetaGraphs v0.6.5
  [e1d29d7a] Missings v0.4.4
  [46d2c3a1] MuladdMacro v0.2.2
  [d8a4904e] MutableArithmetics v0.2.10
  [872c559c] NNlib v0.7.4
  [77ba4419] NaNMath v0.3.4
  [81ede08e] NaiveGAflux v0.7.0
  [85610aed] NaiveNASflux v1.5.0
  [bd45eb3e] NaiveNASlib v1.3.0
  [6fe1bfb0] OffsetArrays v1.1.3
  [656ef2d0] OpenBLAS32_jll v0.3.9+4
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [bac558e1] OrderedCollections v1.3.0
  [7da25872] Osi_jll v0.108.5+3
  [69de0a69] Parsers v1.0.10
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.2
  [21efa798] SIMDPirates v0.8.25
  [476501e8] SLEEFPirates v0.5.5
  [efcf1570] Setfield v0.7.0
  [699a6c99] SimpleTraits v0.9.3
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.10.3
  [90137ffa] StaticArrays v0.12.4
  [2913bbd2] StatsBase v0.33.1
  [a759f4b9] TimerOutputs v0.5.6
  [3bb67fe8] TranscodingStreams v0.9.5
  [3a884ed6] UnPack v1.0.2
  [3d5dd08c] VectorizationBase v0.12.33
  [a5390f91] ZipFile v0.9.2
  [83775a58] Zlib_jll v1.2.11+16
  [e88e6eb3] Zygote v0.5.6
  [700de1a5] ZygoteRules v0.2.0
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [9fa8497b] Future
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [9abbd945] Profile
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [1a1011a3] SharedArrays
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [fa267f1f] TOML
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
    Testing Running tests...
[ Info: Testing util
[ Info: Testing shape
WARNING: both Flux and NaiveNASlib export "flatten"; uses of it in module NaiveNASflux must be qualified
[ Info: Testing archspace
[ Info: Testing mutation
[ Info: Testing crossover
[ Info: Testing fitness
[ Info: Testing candidate
CandidateModel identity: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:6
  Got exception outside of a @test
  MethodError: no method matching Core.Compiler.IRCode(::Vector{Any}, ::Vector{Any}, ::Vector{Int32}, ::Vector{UInt8}, ::Core.Compiler.CFG, ::Vector{Core.LineInfoNode}, ::Vector{Any}, ::Vector{Any}, ::Vector{Any})
  Stacktrace:
    [1] Core.Compiler.IRCode(ir::IRTools.Inner.IR)
      @ IRTools.Inner.Wrap ~/.julia/packages/IRTools/GVPoj/src/ir/wrap.jl:55
    [2] update!(ci::Core.CodeInfo, ir::IRTools.Inner.IR)
      @ IRTools.Inner ~/.julia/packages/IRTools/GVPoj/src/reflection/utils.jl:143
    [3] #s2778#1234
      @ ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:34 [inlined]
    [4] #s2778#1234(::Any, ctx::Any, f::Any, args::Any)
      @ Zygote ./none:0
    [5] (::Core.GeneratedFunctionStub)(::Any, ::Vararg{Any, N} where N)
      @ Core ./boot.jl:556
    [6] pullback(f::Function, ps::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:172
    [7] gradient(f::Function, args::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:53
    [8] macro expansion
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:82 [inlined]
    [9] macro expansion
      @ ~/.julia/packages/Juno/hEPx8/src/progress.jl:134 [inlined]
   [10] train!(loss::Function, ps::Zygote.Params, data::Vector{Tuple{Matrix{Float32}, Matrix{Float32}}}, opt::Descent; cb::Flux.Optimise.var"#16#22")
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:80
   [11] train!
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:78 [inlined]
   [12] train!(model::CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, data::Vector{Tuple{Matrix{Float32}, Matrix{Float32}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:42
   [13] train!(model::CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, data::Tuple{Matrix{Float32}, Matrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:45
   [14] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:37
   [15] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [16] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:6
   [17] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [18] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:3
   [19] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [20] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:48
   [21] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [22] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:8
   [23] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [24] top-level scope
      @ none:6
   [25] eval(m::Module, e::Any)
      @ Core ./boot.jl:345
   [26] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:261
   [27] _start()
      @ Base ./client.jl:485
CandidateModel HostCandidate: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:6
  Got exception outside of a @test
  MethodError: no method matching Core.Compiler.IRCode(::Vector{Any}, ::Vector{Any}, ::Vector{Int32}, ::Vector{UInt8}, ::Core.Compiler.CFG, ::Vector{Core.LineInfoNode}, ::Vector{Any}, ::Vector{Any}, ::Vector{Any})
  Stacktrace:
    [1] Core.Compiler.IRCode(ir::IRTools.Inner.IR)
      @ IRTools.Inner.Wrap ~/.julia/packages/IRTools/GVPoj/src/ir/wrap.jl:55
    [2] update!(ci::Core.CodeInfo, ir::IRTools.Inner.IR)
      @ IRTools.Inner ~/.julia/packages/IRTools/GVPoj/src/reflection/utils.jl:143
    [3] #s2778#1234
      @ ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:34 [inlined]
    [4] #s2778#1234(::Any, ctx::Any, f::Any, args::Any)
      @ Zygote ./none:0
    [5] (::Core.GeneratedFunctionStub)(::Any, ::Vararg{Any, N} where N)
      @ Core ./boot.jl:556
    [6] pullback(f::Function, ps::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:172
    [7] gradient(f::Function, args::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:53
    [8] macro expansion
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:82 [inlined]
    [9] macro expansion
      @ ~/.julia/packages/Juno/hEPx8/src/progress.jl:134 [inlined]
   [10] train!(loss::Function, ps::Zygote.Params, data::Vector{Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}}}, opt::Descent; cb::Flux.Optimise.var"#16#22")
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:80
   [11] train!
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:78 [inlined]
   [12] train!(model::CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, data::Vector{Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:42
   [13] train!(model::CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, data::Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:45
   [14] train!(c::HostCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}}, data::Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:72
   [15] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:37
   [16] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [17] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:6
   [18] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [19] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:3
   [20] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [21] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:48
   [22] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [23] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:8
   [24] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [25] top-level scope
      @ none:6
   [26] eval(m::Module, e::Any)
      @ Core ./boot.jl:345
   [27] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:261
   [28] _start()
      @ Base ./client.jl:485
CandidateModel CacheCandidate: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:6
  Got exception outside of a @test
  MethodError: no method matching Core.Compiler.IRCode(::Vector{Any}, ::Vector{Any}, ::Vector{Int32}, ::Vector{UInt8}, ::Core.Compiler.CFG, ::Vector{Core.LineInfoNode}, ::Vector{Any}, ::Vector{Any}, ::Vector{Any})
  Stacktrace:
    [1] Core.Compiler.IRCode(ir::IRTools.Inner.IR)
      @ IRTools.Inner.Wrap ~/.julia/packages/IRTools/GVPoj/src/ir/wrap.jl:55
    [2] update!(ci::Core.CodeInfo, ir::IRTools.Inner.IR)
      @ IRTools.Inner ~/.julia/packages/IRTools/GVPoj/src/reflection/utils.jl:143
    [3] #s2778#1234
      @ ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:34 [inlined]
    [4] #s2778#1234(::Any, ctx::Any, f::Any, args::Any)
      @ Zygote ./none:0
    [5] (::Core.GeneratedFunctionStub)(::Any, ::Vararg{Any, N} where N)
      @ Core ./boot.jl:556
    [6] pullback(f::Function, ps::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:172
    [7] gradient(f::Function, args::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:53
    [8] macro expansion
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:82 [inlined]
    [9] macro expansion
      @ ~/.julia/packages/Juno/hEPx8/src/progress.jl:134 [inlined]
   [10] train!(loss::Function, ps::Zygote.Params, data::Vector{Tuple{Matrix{Float32}, Matrix{Float32}}}, opt::Descent; cb::Flux.Optimise.var"#16#22")
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:80
   [11] train!
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:78 [inlined]
   [12] train!(model::CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, data::Vector{Tuple{Matrix{Float32}, Matrix{Float32}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:42
   [13] train!
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:45 [inlined]
   [14] train!(c::CacheCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}}, data::Tuple{Matrix{Float32}, Matrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:187
   [15] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:37
   [16] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [17] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:6
   [18] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [19] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:3
   [20] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [21] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:48
   [22] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [23] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:8
   [24] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [25] top-level scope
      @ none:6
   [26] eval(m::Module, e::Any)
      @ Core ./boot.jl:345
   [27] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:261
   [28] _start()
      @ Base ./client.jl:485
CandidateModel FileCandidate: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:6
  Got exception outside of a @test
  MethodError: no method matching Core.Compiler.IRCode(::Vector{Any}, ::Vector{Any}, ::Vector{Int32}, ::Vector{UInt8}, ::Core.Compiler.CFG, ::Vector{Core.LineInfoNode}, ::Vector{Any}, ::Vector{Any}, ::Vector{Any})
  Stacktrace:
    [1] Core.Compiler.IRCode(ir::IRTools.Inner.IR)
      @ IRTools.Inner.Wrap ~/.julia/packages/IRTools/GVPoj/src/ir/wrap.jl:55
    [2] update!(ci::Core.CodeInfo, ir::IRTools.Inner.IR)
      @ IRTools.Inner ~/.julia/packages/IRTools/GVPoj/src/reflection/utils.jl:143
    [3] #s2778#1234
      @ ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:34 [inlined]
    [4] #s2778#1234(::Any, ctx::Any, f::Any, args::Any)
      @ Zygote ./none:0
    [5] (::Core.GeneratedFunctionStub)(::Any, ::Vararg{Any, N} where N)
      @ Core ./boot.jl:556
    [6] pullback(f::Function, ps::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:172
    [7] gradient(f::Function, args::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:53
    [8] macro expansion
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:82 [inlined]
    [9] macro expansion
      @ ~/.julia/packages/Juno/hEPx8/src/progress.jl:134 [inlined]
   [10] train!(loss::Function, ps::Zygote.Params, data::Vector{Tuple{Matrix{Float32}, Matrix{Float32}}}, opt::Descent; cb::Flux.Optimise.var"#16#22")
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:80
   [11] train!
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:78 [inlined]
   [12] train!(model::CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, data::Vector{Tuple{Matrix{Float32}, Matrix{Float32}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:42
   [13] train!(model::CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, data::Tuple{Matrix{Float32}, Matrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:45
   [14] (::NaiveGAflux.var"#384#385"{typeof(train!), FileCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, Float64, ReentrantLock}, Tuple{Tuple{Matrix{Float32}, Matrix{Float32}}}})()
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:124
   [15] lock(f::NaiveGAflux.var"#384#385"{typeof(train!), FileCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, Float64, ReentrantLock}, Tuple{Tuple{Matrix{Float32}, Matrix{Float32}}}}, l::ReentrantLock)
      @ Base ./lock.jl:168
   [16] callcand(f::Function, c::FileCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, Float64, ReentrantLock}, args::Tuple{Matrix{Float32}, Matrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:123
   [17] train!(c::FileCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, Float64, ReentrantLock}, data::Tuple{Matrix{Float32}, Matrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:165
   [18] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:37
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [20] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:6
   [21] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [22] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:3
   [23] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [24] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:48
   [25] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [26] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:8
   [27] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [28] top-level scope
      @ none:6
   [29] eval(m::Module, e::Any)
      @ Core ./boot.jl:345
   [30] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:261
   [31] _start()
      @ Base ./client.jl:485
CandidateModel Base.ComposedFunction{Type{CacheCandidate}, Type{HostCandidate}}(CacheCandidate, HostCandidate): Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:6
  Got exception outside of a @test
  MethodError: no method matching Core.Compiler.IRCode(::Vector{Any}, ::Vector{Any}, ::Vector{Int32}, ::Vector{UInt8}, ::Core.Compiler.CFG, ::Vector{Core.LineInfoNode}, ::Vector{Any}, ::Vector{Any}, ::Vector{Any})
  Stacktrace:
    [1] Core.Compiler.IRCode(ir::IRTools.Inner.IR)
      @ IRTools.Inner.Wrap ~/.julia/packages/IRTools/GVPoj/src/ir/wrap.jl:55
    [2] update!(ci::Core.CodeInfo, ir::IRTools.Inner.IR)
      @ IRTools.Inner ~/.julia/packages/IRTools/GVPoj/src/reflection/utils.jl:143
    [3] #s2778#1234
      @ ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:34 [inlined]
    [4] #s2778#1234(::Any, ctx::Any, f::Any, args::Any)
      @ Zygote ./none:0
    [5] (::Core.GeneratedFunctionStub)(::Any, ::Vararg{Any, N} where N)
      @ Core ./boot.jl:556
    [6] pullback(f::Function, ps::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:172
    [7] gradient(f::Function, args::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:53
    [8] macro expansion
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:82 [inlined]
    [9] macro expansion
      @ ~/.julia/packages/Juno/hEPx8/src/progress.jl:134 [inlined]
   [10] train!(loss::Function, ps::Zygote.Params, data::Vector{Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}}}, opt::Descent; cb::Flux.Optimise.var"#16#22")
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:80
   [11] train!
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:78 [inlined]
   [12] train!(model::CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, data::Vector{Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:42
   [13] train!(model::CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, data::Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:45
   [14] train!(c::HostCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}}, data::Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:72
   [15] train!(c::CacheCandidate{HostCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}}}, data::Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:187
   [16] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:37
   [17] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [18] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:6
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [20] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:3
   [21] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [22] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:48
   [23] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [24] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:8
   [25] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [26] top-level scope
      @ none:6
   [27] eval(m::Module, e::Any)
      @ Core ./boot.jl:345
   [28] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:261
   [29] _start()
      @ Base ./client.jl:485
CandidateModel Base.ComposedFunction{Base.ComposedFunction{Type{CacheCandidate}, Type{FileCandidate}}, Type{HostCandidate}}(CacheCandidate ∘ FileCandidate, HostCandidate): Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:6
  Got exception outside of a @test
  MethodError: no method matching Core.Compiler.IRCode(::Vector{Any}, ::Vector{Any}, ::Vector{Int32}, ::Vector{UInt8}, ::Core.Compiler.CFG, ::Vector{Core.LineInfoNode}, ::Vector{Any}, ::Vector{Any}, ::Vector{Any})
  Stacktrace:
    [1] Core.Compiler.IRCode(ir::IRTools.Inner.IR)
      @ IRTools.Inner.Wrap ~/.julia/packages/IRTools/GVPoj/src/ir/wrap.jl:55
    [2] update!(ci::Core.CodeInfo, ir::IRTools.Inner.IR)
      @ IRTools.Inner ~/.julia/packages/IRTools/GVPoj/src/reflection/utils.jl:143
    [3] #s2778#1234
      @ ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:34 [inlined]
    [4] #s2778#1234(::Any, ctx::Any, f::Any, args::Any)
      @ Zygote ./none:0
    [5] (::Core.GeneratedFunctionStub)(::Any, ::Vararg{Any, N} where N)
      @ Core ./boot.jl:556
    [6] pullback(f::Function, ps::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:172
    [7] gradient(f::Function, args::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:53
    [8] macro expansion
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:82 [inlined]
    [9] macro expansion
      @ ~/.julia/packages/Juno/hEPx8/src/progress.jl:134 [inlined]
   [10] train!(loss::Function, ps::Zygote.Params, data::Vector{Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}}}, opt::Descent; cb::Flux.Optimise.var"#16#22")
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:80
   [11] train!
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:78 [inlined]
   [12] train!(model::CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, data::Vector{Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:42
   [13] train!(model::CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}, data::Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:45
   [14] train!(c::HostCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}}, data::Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:72
   [15] (::NaiveGAflux.var"#384#385"{typeof(train!), FileCandidate{HostCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}}, Float64, ReentrantLock}, Tuple{Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}}}})()
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:124
   [16] lock(f::NaiveGAflux.var"#384#385"{typeof(train!), FileCandidate{HostCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}}, Float64, ReentrantLock}, Tuple{Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}}}}, l::ReentrantLock)
      @ Base ./lock.jl:168
   [17] callcand(f::Function, c::FileCandidate{HostCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}}, Float64, ReentrantLock}, args::Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:123
   [18] train!
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:165 [inlined]
   [19] train!(c::CacheCandidate{FileCandidate{HostCandidate{CandidateModel{CompGraph, Descent, var"#294#306", DummyFitness}}, Float64, ReentrantLock}}, data::Tuple{CUDA.CuMatrix{Float32}, CUDA.CuMatrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:187
   [20] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:37
   [21] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [22] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:6
   [23] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [24] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/candidate.jl:3
   [25] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [26] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:48
   [27] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [28] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:8
   [29] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [30] top-level scope
      @ none:6
   [31] eval(m::Module, e::Any)
      @ Core ./boot.jl:345
   [32] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:261
   [33] _start()
      @ Base ./client.jl:485
[ Info: Testing evolve
[ Info: Testing population
[ Info: Testing iterators
[ Info: Testing visualization
[ Info: Testing README examples
Basic example: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:1
  Got exception outside of a @test
  MethodError: no method matching Core.Compiler.IRCode(::Vector{Any}, ::Vector{Any}, ::Vector{Int32}, ::Vector{UInt8}, ::Core.Compiler.CFG, ::Vector{Core.LineInfoNode}, ::Vector{Any}, ::Vector{Any}, ::Vector{Any})
  Stacktrace:
    [1] Core.Compiler.IRCode(ir::IRTools.Inner.IR)
      @ IRTools.Inner.Wrap ~/.julia/packages/IRTools/GVPoj/src/ir/wrap.jl:55
    [2] update!(ci::Core.CodeInfo, ir::IRTools.Inner.IR)
      @ IRTools.Inner ~/.julia/packages/IRTools/GVPoj/src/reflection/utils.jl:143
    [3] #s2778#1234
      @ ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:34 [inlined]
    [4] #s2778#1234(::Any, ctx::Any, f::Any, args::Any)
      @ Zygote ./none:0
    [5] (::Core.GeneratedFunctionStub)(::Any, ::Vararg{Any, N} where N)
      @ Core ./boot.jl:556
    [6] pullback(f::Function, ps::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:172
    [7] gradient(f::Function, args::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:53
    [8] macro expansion
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:82 [inlined]
    [9] macro expansion
      @ ~/.julia/packages/Juno/hEPx8/src/progress.jl:134 [inlined]
   [10] train!(loss::Function, ps::Zygote.Params, data::Vector{Tuple{Matrix{Float64}, Matrix{Float32}}}, opt::Descent; cb::Flux.Optimise.var"#16#22")
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:80
   [11] train!
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:78 [inlined]
   [12] train!
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:42 [inlined]
   [13] train!(model::CandidateModel{CompGraph, Descent, typeof(Flux.Losses.logitcrossentropy), AccuracyFitness}, data::Tuple{Matrix{Float64}, Matrix{Float32}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:45
   [14] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:37
   [15] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [16] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:2
   [17] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [18] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:63
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [20] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:8
   [21] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [22] top-level scope
      @ none:6
   [23] eval(m::Module, e::Any)
      @ Core ./boot.jl:345
   [24] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:261
   [25] _start()
      @ Base ./client.jl:485
Candidate handling: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:438
  Got exception outside of a @test
  MethodError: no method matching Core.Compiler.IRCode(::Vector{Any}, ::Vector{Any}, ::Vector{Int32}, ::Vector{UInt8}, ::Core.Compiler.CFG, ::Vector{Core.LineInfoNode}, ::Vector{Any}, ::Vector{Any}, ::Vector{Any})
  Stacktrace:
    [1] Core.Compiler.IRCode(ir::IRTools.Inner.IR)
      @ IRTools.Inner.Wrap ~/.julia/packages/IRTools/GVPoj/src/ir/wrap.jl:55
    [2] update!(ci::Core.CodeInfo, ir::IRTools.Inner.IR)
      @ IRTools.Inner ~/.julia/packages/IRTools/GVPoj/src/reflection/utils.jl:143
    [3] #s2778#1234
      @ ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:34 [inlined]
    [4] #s2778#1234(::Any, ctx::Any, f::Any, args::Any)
      @ Zygote ./none:0
    [5] (::Core.GeneratedFunctionStub)(::Any, ::Vararg{Any, N} where N)
      @ Core ./boot.jl:556
    [6] pullback(f::Function, ps::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:172
    [7] gradient(f::Function, args::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:53
    [8] macro expansion
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:82 [inlined]
    [9] macro expansion
      @ ~/.julia/packages/Juno/hEPx8/src/progress.jl:134 [inlined]
   [10] train!(loss::Function, ps::Zygote.Params, data::Base.Iterators.Take{Base.Iterators.Repeated{Tuple{Matrix{Float32}, Vector{Float32}}}}, opt::ADAM; cb::Flux.Optimise.var"#16#22")
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:80
   [11] train!(loss::Function, ps::Zygote.Params, data::Base.Iterators.Take{Base.Iterators.Repeated{Tuple{Matrix{Float32}, Vector{Float32}}}}, opt::ADAM)
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:78
   [12] train!(model::CandidateModel{CompGraph, ADAM, typeof(Flux.Losses.logitcrossentropy), NanGuard{Validate}}, data::Base.Iterators.Take{Base.Iterators.Repeated{Tuple{Matrix{Float32}, Vector{Float32}}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:42
   [13] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:454
   [14] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [15] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:439
   [16] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [17] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:63
   [18] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [19] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:8
   [20] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [21] top-level scope
      @ none:6
   [22] eval(m::Module, e::Any)
      @ Core ./boot.jl:345
   [23] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:261
   [24] _start()
      @ Base ./client.jl:485
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4539
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3978
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4220 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6778
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7140
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7174
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1895
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:2162 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2155 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
unknown function (ip: 0x7fa772dc266f)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
#mapreducedim!#889 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
mapreducedim!##kw at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:145
unknown function (ip: 0x7fa772dbf9e3)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
#_mapreduce#23 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
_mapreduce##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:34 [inlined]
#mapreduce#21 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
mapreduce at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
== at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
eval_test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
unknown function (ip: 0x7fa89dc3d6ff)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1682 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:434
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:669
macro expansion at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:558 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113 [inlined]
top-level scope at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:540
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:837
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:785
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:880
eval at ./boot.jl:345 [inlined]
include_string at ./loading.jl:1004
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
_include at ./loading.jl:1058
include at ./client.jl:444
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1682 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:155 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:561
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:669
macro expansion at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:63 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113 [inlined]
top-level scope at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:8
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:837
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:785
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:880
eval at ./boot.jl:345 [inlined]
include_string at ./loading.jl:1004
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
_include at ./loading.jl:1058
include at ./client.jl:444
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1682 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:155 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:561
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:669
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:837
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:785
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:880
eval at ./boot.jl:345
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
exec_options at ./client.jl:261
_start at ./client.jl:485
jfptr__start_17019.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1682 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4539
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3978
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4220 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6778
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7140
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7174
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:351
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1901
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:2162 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2155 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
unknown function (ip: 0x7fa772dc266f)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
#mapreducedim!#889 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
mapreducedim!##kw at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:145
unknown function (ip: 0x7fa772dbf9e3)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
#_mapreduce#23 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
_mapreduce##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:34 [inlined]
#mapreduce#21 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
mapreduce at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
== at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
eval_test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
unknown function (ip: 0x7fa89dc3d6ff)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1682 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:434
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:669
macro expansion at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:558 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113 [inlined]
top-level scope at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:540
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:837
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:785
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:880
eval at ./boot.jl:345 [inlined]
include_string at ./loading.jl:1004
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
_include at ./loading.jl:1058
include at ./client.jl:444
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1682 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:155 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:561
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:669
macro expansion at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:63 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113 [inlined]
top-level scope at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:8
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:837
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:785
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:880
eval at ./boot.jl:345 [inlined]
include_string at ./loading.jl:1004
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
_include at ./loading.jl:1058
include at ./client.jl:444
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1682 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:155 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:561
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:669
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:837
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:785
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:880
eval at ./boot.jl:345
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
exec_options at ./client.jl:261
_start at ./client.jl:485
jfptr__start_17019.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1682 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Iterators: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:558
  Test threw exception
  Expression: first(giter) == first(miter) |> gpu
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, CartesianIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 3, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{2}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceMatrix{Int64, CUDA.AS.Global}, CUDA.CuDeviceMatrix{Int64, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, CartesianIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 3, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{2}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceMatrix{Int64, CUDA.AS.Global}, CUDA.CuDeviceMatrix{Int64, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, CartesianIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 3, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{2}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceMatrix{Int64, CUDA.AS.Global}, CUDA.CuDeviceMatrix{Int64, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, CartesianIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 3, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{2}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceMatrix{Int64, CUDA.AS.Global}, CUDA.CuDeviceMatrix{Int64, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, CartesianIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 3, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{2}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceMatrix{Int64, CUDA.AS.Global}, CUDA.CuDeviceMatrix{Int64, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, CartesianIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 3, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{2}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceMatrix{Int64, CUDA.AS.Global}, CUDA.CuDeviceMatrix{Int64, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuMatrix{Bool}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{2}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuMatrix{Int64}, CUDA.CuMatrix{Int64}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuMatrix{Int64}, ::CUDA.CuMatrix{Int64}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuMatrix{Int64}, B::CUDA.CuMatrix{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [30] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:558
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [32] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/examples.jl:540
[ Info: Testing AutoFlux
[ Info: 	Smoke test with TrainSplitAccuracy and EliteAndSusSelection
ImageClassifier smoketest: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:23
  Test threw exception
  Expression: fit(c, x, y, fitnesstrategy = f, trainstrategy = t, evolutionstrategy = GlobalOptimizerMutation(EliteAndSusSelection(popsize = c.popsize, nelites = 1)), mdir = dummydir)
  MethodError: no method matching Core.Compiler.IRCode(::Vector{Any}, ::Vector{Any}, ::Vector{Int32}, ::Vector{UInt8}, ::Core.Compiler.CFG, ::Vector{Core.LineInfoNode}, ::Vector{Any}, ::Vector{Any}, ::Vector{Any})
  Stacktrace:
    [1] Core.Compiler.IRCode(ir::IRTools.Inner.IR)
      @ IRTools.Inner.Wrap ~/.julia/packages/IRTools/GVPoj/src/ir/wrap.jl:55
    [2] update!(ci::Core.CodeInfo, ir::IRTools.Inner.IR)
      @ IRTools.Inner ~/.julia/packages/IRTools/GVPoj/src/reflection/utils.jl:143
    [3] #s2778#1234
      @ ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:34 [inlined]
    [4] #s2778#1234(::Any, ctx::Any, f::Any, args::Any)
      @ Zygote ./none:0
    [5] (::Core.GeneratedFunctionStub)(::Any, ::Vararg{Any, N} where N)
      @ Core ./boot.jl:556
    [6] pullback(f::Function, ps::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:172
    [7] gradient(f::Function, args::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:53
    [8] macro expansion
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:82 [inlined]
    [9] macro expansion
      @ ~/.julia/packages/Juno/hEPx8/src/progress.jl:134 [inlined]
   [10] train!(loss::Function, ps::Zygote.Params, data::Base.Iterators.Take{NaiveGAflux.RepeatStatefulIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}}, opt::ADAGrad; cb::Flux.Optimise.var"#16#22")
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:80
   [11] train!(loss::Function, ps::Zygote.Params, data::Base.Iterators.Take{NaiveGAflux.RepeatStatefulIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}}, opt::ADAGrad)
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:78
   [12] train!(model::CandidateModel{CompGraph, ADAGrad, typeof(Flux.Losses.logitcrossentropy), NanGuard{Validate}}, data::Base.Iterators.Take{NaiveGAflux.RepeatStatefulIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:42
   [13] train!(c::HostCandidate{CandidateModel{CompGraph, ADAGrad, typeof(Flux.Losses.logitcrossentropy), NanGuard{Validate}}}, data::Base.Iterators.Take{NaiveGAflux.RepeatStatefulIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:72
   [14] train!(c::CacheCandidate{HostCandidate{CandidateModel{CompGraph, ADAGrad, typeof(Flux.Losses.logitcrossentropy), NanGuard{Validate}}}}, data::Base.Iterators.Take{NaiveGAflux.RepeatStatefulIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:187
   [15] evolutionloop(population::Population{Int64, PersistentArray{CacheCandidate, 1}}, evostrategy::AfterEvolution{typeof(NaiveGAflux.resetandreturn), AfterEvolution{NaiveGAflux.AutoFlux.ImageClassification.var"#22#23"{GlobalOptimizerMutation{EliteAndSusSelection{NaiveGAflux.AutoFlux.ImageClassification.var"#27#28"{Float64, Float64}}, NaiveGAflux.var"#414#416"{BoundedRandomWalk{Float64, NaiveGAflux.var"#22#23"}}}}, AfterEvolution{Base.ComposedFunction{typeof(NaiveGAflux.AutoFlux.ImageClassification.rename_models), typeof(NaiveGAflux.AutoFlux.ImageClassification.clear_redundant_vertices)}, CombinedEvolution{Vector{AbstractEvolution}}}}}, trainingiter::RepeatPartitionIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}, cb::typeof(identity))
      @ NaiveGAflux.AutoFlux.ImageClassification ~/.julia/packages/NaiveGAflux/BOZ0I/src/app/imageclassification/ImageClassification.jl:118
   [16] fit(c::ImageClassifier{NaiveGAflux.AutoFlux.ImageClassification.var"#97#98"{Int64, Bool}}, fit_iter::RepeatPartitionIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}, fitnessgen::Function, evostrategy::AfterEvolution{typeof(NaiveGAflux.resetandreturn), AfterEvolution{NaiveGAflux.AutoFlux.ImageClassification.var"#22#23"{GlobalOptimizerMutation{EliteAndSusSelection{NaiveGAflux.AutoFlux.ImageClassification.var"#27#28"{Float64, Float64}}, NaiveGAflux.var"#414#416"{BoundedRandomWalk{Float64, NaiveGAflux.var"#22#23"}}}}, AfterEvolution{Base.ComposedFunction{typeof(NaiveGAflux.AutoFlux.ImageClassification.rename_models), typeof(NaiveGAflux.AutoFlux.ImageClassification.clear_redundant_vertices)}, CombinedEvolution{Vector{AbstractEvolution}}}}}; cb::Function, mdir::String)
      @ NaiveGAflux.AutoFlux.ImageClassification ~/.julia/packages/NaiveGAflux/BOZ0I/src/app/imageclassification/ImageClassification.jl:105
   [17] fit(c::ImageClassifier{NaiveGAflux.AutoFlux.ImageClassification.var"#97#98"{Int64, Bool}}, x::Array{Float32, 4}, y::Matrix{Float32}; cb::Function, fitnesstrategy::TrainSplitAccuracy{NaiveGAflux.AutoFlux.ImageClassification.var"#3#5", typeof(identity)}, trainstrategy::TrainStrategy{typeof(identity)}, evolutionstrategy::GlobalOptimizerMutation{EliteAndSusSelection{NaiveGAflux.AutoFlux.ImageClassification.var"#27#28"{Float64, Float64}}, NaiveGAflux.var"#414#416"{BoundedRandomWalk{Float64, NaiveGAflux.var"#22#23"}}}, mdir::String)
      @ NaiveGAflux.AutoFlux.ImageClassification ~/.julia/packages/NaiveGAflux/BOZ0I/src/app/imageclassification/ImageClassification.jl:71
   [18] (::var"#422#432"{String, TrainStrategy{typeof(identity)}, TrainSplitAccuracy{NaiveGAflux.AutoFlux.ImageClassification.var"#3#5", typeof(identity)}, ImageClassifier{NaiveGAflux.AutoFlux.ImageClassification.var"#97#98"{Int64, Bool}}, Matrix{Float32}, Array{Float32, 4}})()
      @ Main ./none:0
   [19] with_logstate(f::Function, logstate::Any)
      @ Base.CoreLogging ./logging.jl:430
   [20] with_logger
      @ ./logging.jl:542 [inlined]
   [21] #collect_test_logs#45
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/logging.jl:51 [inlined]
   [22] collect_test_logs
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/logging.jl:50 [inlined]
   [23] match_logs(::Function, ::Tuple{Symbol, String}, ::Vararg{Any, N} where N; match_mode::Symbol, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/logging.jl:186
   [24] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:23
   [25] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [26] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:4
   [27] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [28] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
ImageClassifier smoketest: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:25
  Test threw exception
  Expression: length(pop) == c.popsize
  MethodError: no method matching length(::Nothing)
  Closest candidates are:
    length(!Matched::Union{Base.KeySet, Base.ValueIterator}) at abstractdict.jl:54
    length(!Matched::Union{DataStructures.SortedDict, DataStructures.SortedMultiDict, DataStructures.SortedSet}) at /home/pkgeval/.julia/packages/DataStructures/DLSxi/src/container_loops.jl:331
    length(!Matched::Union{NNlib.BatchedAdjoint{T, S}, NNlib.BatchedTranspose{T, S}} where S where T) at /home/pkgeval/.julia/packages/NNlib/PI8Xh/src/batched/batchedadjtrans.jl:49
    ...
  Stacktrace:
   [1] top-level scope
     @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:25
   [2] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [3] top-level scope
     @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:4
   [4] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [5] top-level scope
     @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
ImageClassifier smoketest: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:26
  Test threw exception
  Expression: modelname.(pop) == ["model$(i)" for i = 1:length(pop)]
  MethodError: no method matching modelname(::Nothing)
  Closest candidates are:
    modelname(!Matched::AbstractCandidate) at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/src/app/imageclassification/ImageClassification.jl:17
    modelname(!Matched::CompGraph) at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/src/app/imageclassification/ImageClassification.jl:18
  Stacktrace:
    [1] _broadcast_getindex_evalf(f::typeof(modelname), args::Nothing)
      @ Base.Broadcast ./broadcast.jl:648
    [2] _broadcast_getindex(bc::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0}, Nothing, typeof(modelname), Tuple{Base.RefValue{Nothing}}}, I::CartesianIndex{0})
      @ Base.Broadcast ./broadcast.jl:621
    [3] getindex(bc::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0}, Nothing, typeof(modelname), Tuple{Base.RefValue{Nothing}}}, I::CartesianIndex{0})
      @ Base.Broadcast ./broadcast.jl:575
    [4] copy(bc::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0}, Nothing, typeof(modelname), Tuple{Base.RefValue{Nothing}}})
      @ Base.Broadcast ./broadcast.jl:852
    [5] materialize(bc::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0}, Nothing, typeof(modelname), Tuple{Base.RefValue{Nothing}}})
      @ Base.Broadcast ./broadcast.jl:837
    [6] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:26
    [7] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
    [8] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:4
    [9] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [10] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
ImageClassifier smoketest: Test Failed at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:34
  Expression: unique(globallearningrate.(pop)) != [1]
   Evaluated: [1] != [1]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:34
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
 [3] top-level scope
   @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:4
 [4] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
 [5] top-level scope
   @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
[ Info: 	Smoke test with TrainAccuracyVsSize and EliteAndTournamentSelection
ImageClassifier smoketest: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:39
  Test threw exception
  Expression: fit(c, x, y, fitnesstrategy = TrainAccuracyVsSize(), trainstrategy = t, evolutionstrategy = GlobalOptimizerMutation(EliteAndTournamentSelection(popsize = c.popsize, nelites = 1, k = 2)), mdir = dummydir)
  MethodError: no method matching Core.Compiler.IRCode(::Vector{Any}, ::Vector{Any}, ::Vector{Int32}, ::Vector{UInt8}, ::Core.Compiler.CFG, ::Vector{Core.LineInfoNode}, ::Vector{Any}, ::Vector{Any}, ::Vector{Any})
  Stacktrace:
    [1] Core.Compiler.IRCode(ir::IRTools.Inner.IR)
      @ IRTools.Inner.Wrap ~/.julia/packages/IRTools/GVPoj/src/ir/wrap.jl:55
    [2] update!(ci::Core.CodeInfo, ir::IRTools.Inner.IR)
      @ IRTools.Inner ~/.julia/packages/IRTools/GVPoj/src/reflection/utils.jl:143
    [3] #s2778#1234
      @ ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:34 [inlined]
    [4] #s2778#1234(::Any, ctx::Any, f::Any, args::Any)
      @ Zygote ./none:0
    [5] (::Core.GeneratedFunctionStub)(::Any, ::Vararg{Any, N} where N)
      @ Core ./boot.jl:556
    [6] pullback(f::Function, ps::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:172
    [7] gradient(f::Function, args::Zygote.Params)
      @ Zygote ~/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:53
    [8] macro expansion
      @ ~/.julia/packages/Flux/05b38/src/optimise/train.jl:82 [inlined]
    [9] macro expansion
      @ ~/.julia/packages/Juno/hEPx8/src/progress.jl:134 [inlined]
   [10] train!(loss::Function, ps::Zygote.Params, data::Base.Iterators.Take{NaiveGAflux.RepeatStatefulIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}}, opt::ADAGrad; cb::Flux.Optimise.var"#16#22")
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:80
   [11] train!(loss::Function, ps::Zygote.Params, data::Base.Iterators.Take{NaiveGAflux.RepeatStatefulIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}}, opt::ADAGrad)
      @ Flux.Optimise ~/.julia/packages/Flux/05b38/src/optimise/train.jl:78
   [12] train!(model::CandidateModel{CompGraph, ADAGrad, typeof(Flux.Losses.logitcrossentropy), NanGuard{Validate}}, data::Base.Iterators.Take{NaiveGAflux.RepeatStatefulIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:42
   [13] train!(c::HostCandidate{CandidateModel{CompGraph, ADAGrad, typeof(Flux.Losses.logitcrossentropy), NanGuard{Validate}}}, data::Base.Iterators.Take{NaiveGAflux.RepeatStatefulIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:72
   [14] train!(c::CacheCandidate{HostCandidate{CandidateModel{CompGraph, ADAGrad, typeof(Flux.Losses.logitcrossentropy), NanGuard{Validate}}}}, data::Base.Iterators.Take{NaiveGAflux.RepeatStatefulIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}})
      @ NaiveGAflux ~/.julia/packages/NaiveGAflux/BOZ0I/src/candidate.jl:187
   [15] evolutionloop(population::Population{Int64, PersistentArray{CacheCandidate, 1}}, evostrategy::AfterEvolution{typeof(NaiveGAflux.resetandreturn), AfterEvolution{NaiveGAflux.AutoFlux.ImageClassification.var"#22#23"{GlobalOptimizerMutation{EliteAndTournamentSelection{Float64, NaiveGAflux.AutoFlux.ImageClassification.var"#27#28"{Float64, Float64}}, NaiveGAflux.var"#414#416"{BoundedRandomWalk{Float64, NaiveGAflux.var"#22#23"}}}}, AfterEvolution{Base.ComposedFunction{typeof(NaiveGAflux.AutoFlux.ImageClassification.rename_models), typeof(NaiveGAflux.AutoFlux.ImageClassification.clear_redundant_vertices)}, CombinedEvolution{Vector{AbstractEvolution}}}}}, trainingiter::RepeatPartitionIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}, cb::typeof(identity))
      @ NaiveGAflux.AutoFlux.ImageClassification ~/.julia/packages/NaiveGAflux/BOZ0I/src/app/imageclassification/ImageClassification.jl:118
   [16] fit(c::ImageClassifier{NaiveGAflux.AutoFlux.ImageClassification.var"#97#98"{Int64, Bool}}, fit_iter::RepeatPartitionIterator{MapIterator{typeof(NaiveGAflux.gpuitr), SeedIterator{MersenneTwister, SeedIterator{MersenneTwister, IterTools.NCycle{Base.Iterators.Zip{Tuple{ShuffleIterator{Singleton{Array{Float32, 4}}, MersenneTwister}, ShuffleIterator{Singleton{Matrix{Float32}}, MersenneTwister}}}}}}}, Union{Nothing, Tuple{Tuple{Any, Any}, Tuple{Int64, Tuple{Int64, Tuple{Int64, Tuple{Tuple{BatchIterator{Vector{Int64}}, Int64}, Tuple{BatchIterator{Vector{Int64}}, Int64}}}}}}}}, fitnessgen::Function, evostrategy::AfterEvolution{typeof(NaiveGAflux.resetandreturn), AfterEvolution{NaiveGAflux.AutoFlux.ImageClassification.var"#22#23"{GlobalOptimizerMutation{EliteAndTournamentSelection{Float64, NaiveGAflux.AutoFlux.ImageClassification.var"#27#28"{Float64, Float64}}, NaiveGAflux.var"#414#416"{BoundedRandomWalk{Float64, NaiveGAflux.var"#22#23"}}}}, AfterEvolution{Base.ComposedFunction{typeof(NaiveGAflux.AutoFlux.ImageClassification.rename_models), typeof(NaiveGAflux.AutoFlux.ImageClassification.clear_redundant_vertices)}, CombinedEvolution{Vector{AbstractEvolution}}}}}; cb::Function, mdir::String)
      @ NaiveGAflux.AutoFlux.ImageClassification ~/.julia/packages/NaiveGAflux/BOZ0I/src/app/imageclassification/ImageClassification.jl:105
   [17] fit(c::ImageClassifier{NaiveGAflux.AutoFlux.ImageClassification.var"#97#98"{Int64, Bool}}, x::Array{Float32, 4}, y::Matrix{Float32}; cb::Function, fitnesstrategy::TrainAccuracyVsSize{typeof(identity)}, trainstrategy::TrainStrategy{typeof(identity)}, evolutionstrategy::GlobalOptimizerMutation{EliteAndTournamentSelection{Float64, NaiveGAflux.AutoFlux.ImageClassification.var"#27#28"{Float64, Float64}}, NaiveGAflux.var"#414#416"{BoundedRandomWalk{Float64, NaiveGAflux.var"#22#23"}}}, mdir::String)
      @ NaiveGAflux.AutoFlux.ImageClassification ~/.julia/packages/NaiveGAflux/BOZ0I/src/app/imageclassification/ImageClassification.jl:71
   [18] (::var"#424#435"{String, TrainStrategy{typeof(identity)}, ImageClassifier{NaiveGAflux.AutoFlux.ImageClassification.var"#97#98"{Int64, Bool}}, Matrix{Float32}, Array{Float32, 4}})()
      @ Main ./none:0
   [19] with_logstate(f::Function, logstate::Any)
      @ Base.CoreLogging ./logging.jl:430
   [20] with_logger
      @ ./logging.jl:542 [inlined]
   [21] #collect_test_logs#45
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/logging.jl:51 [inlined]
   [22] collect_test_logs
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/logging.jl:50 [inlined]
   [23] match_logs(::Function, ::Tuple{Symbol, String}, ::Vararg{Any, N} where N; match_mode::Symbol, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/logging.jl:186
   [24] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:39
   [25] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [26] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:4
   [27] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [28] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
ImageClassifier smoketest: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:41
  Test threw exception
  Expression: length(pop) == c.popsize
  MethodError: no method matching length(::Nothing)
  Closest candidates are:
    length(!Matched::Union{Base.KeySet, Base.ValueIterator}) at abstractdict.jl:54
    length(!Matched::Union{DataStructures.SortedDict, DataStructures.SortedMultiDict, DataStructures.SortedSet}) at /home/pkgeval/.julia/packages/DataStructures/DLSxi/src/container_loops.jl:331
    length(!Matched::Union{NNlib.BatchedAdjoint{T, S}, NNlib.BatchedTranspose{T, S}} where S where T) at /home/pkgeval/.julia/packages/NNlib/PI8Xh/src/batched/batchedadjtrans.jl:49
    ...
  Stacktrace:
   [1] top-level scope
     @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:41
   [2] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [3] top-level scope
     @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:4
   [4] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [5] top-level scope
     @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
ImageClassifier smoketest: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:42
  Test threw exception
  Expression: modelname.(pop) == ["model$(i)" for i = 1:length(pop)]
  MethodError: no method matching modelname(::Nothing)
  Closest candidates are:
    modelname(!Matched::AbstractCandidate) at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/src/app/imageclassification/ImageClassification.jl:17
    modelname(!Matched::CompGraph) at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/src/app/imageclassification/ImageClassification.jl:18
  Stacktrace:
    [1] _broadcast_getindex_evalf(f::typeof(modelname), args::Nothing)
      @ Base.Broadcast ./broadcast.jl:648
    [2] _broadcast_getindex(bc::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0}, Nothing, typeof(modelname), Tuple{Base.RefValue{Nothing}}}, I::CartesianIndex{0})
      @ Base.Broadcast ./broadcast.jl:621
    [3] getindex(bc::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0}, Nothing, typeof(modelname), Tuple{Base.RefValue{Nothing}}}, I::CartesianIndex{0})
      @ Base.Broadcast ./broadcast.jl:575
    [4] copy(bc::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0}, Nothing, typeof(modelname), Tuple{Base.RefValue{Nothing}}})
      @ Base.Broadcast ./broadcast.jl:852
    [5] materialize(bc::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0}, Nothing, typeof(modelname), Tuple{Base.RefValue{Nothing}}})
      @ Base.Broadcast ./broadcast.jl:837
    [6] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:42
    [7] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
    [8] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:4
    [9] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [10] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
ImageClassifier smoketest: Test Failed at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:44
  Expression: unique(globallearningrate.(pop)) != [1]
   Evaluated: [1] != [1]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:44
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
 [3] top-level scope
   @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:4
 [4] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
 [5] top-level scope
   @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4539
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3978
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4220 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6778
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7140
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7174
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1895
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:2162 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2155 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
unknown function (ip: 0x7fa772caa16f)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
#mapreducedim!#889 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
mapreducedim!##kw at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:145
unknown function (ip: 0x7fa772ca6d73)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
#_mapreduce#23 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
_mapreduce##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:34 [inlined]
#mapreduce#21 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
mapreduce at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
== at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
_eq at ./tuple.jl:332
== at ./tuple.jl:328
unknown function (ip: 0x7fa772ca49f8)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
== at ./abstractarray.jl:1936
unknown function (ip: 0x7fa89dc6140b)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
eval_test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
unknown function (ip: 0x7fa89dc3d6ff)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1682 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:434
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:669
macro expansion at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188 [inlined]
macro expansion at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113 [inlined]
macro expansion at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113 [inlined]
top-level scope at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:837
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:785
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:880
eval at ./boot.jl:345 [inlined]
include_string at ./loading.jl:1004
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
_include at ./loading.jl:1058
include at ./client.jl:444
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1682 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:155 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:561
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:669
macro expansion at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:66 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113 [inlined]
top-level scope at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:8
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:837
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:785
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:880
eval at ./boot.jl:345 [inlined]
include_string at ./loading.jl:1004
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
_include at ./loading.jl:1058
include at ./client.jl:444
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1682 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:155 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:561
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:669
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:837
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:785
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:880
eval at ./boot.jl:345
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
exec_options at ./client.jl:261
_start at ./client.jl:485
jfptr__start_17019.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1682 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4539
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3978
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4220 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6778
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7140
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7174
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:351
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1901
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:2162 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2155 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
unknown function (ip: 0x7fa772caa16f)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
#mapreducedim!#889 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
mapreducedim!##kw at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:145
unknown function (ip: 0x7fa772ca6d73)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
#_mapreduce#23 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
_mapreduce##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:34 [inlined]
#mapreduce#21 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
mapreduce at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
== at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
_eq at ./tuple.jl:332
== at ./tuple.jl:328
unknown function (ip: 0x7fa772ca49f8)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
== at ./abstractarray.jl:1936
unknown function (ip: 0x7fa89dc6140b)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
eval_test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
unknown function (ip: 0x7fa89dc3d6ff)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1682 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:434
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:669
macro expansion at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188 [inlined]
macro expansion at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113 [inlined]
macro expansion at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113 [inlined]
top-level scope at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:837
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:785
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:880
eval at ./boot.jl:345 [inlined]
include_string at ./loading.jl:1004
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
_include at ./loading.jl:1058
include at ./client.jl:444
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1682 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:155 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:561
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:489
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:669
macro expansion at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:66 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113 [inlined]
top-level scope at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:8
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:837
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:785
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:880
eval at ./boot.jl:345 [inlined]
include_string at ./loading.jl:1004
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
_include at ./loading.jl:1058
include at ./client.jl:444
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1682 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:155 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:561
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:669
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:837
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:785
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:880
eval at ./boot.jl:345
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
exec_options at ./client.jl:261
_start at ./client.jl:485
jfptr__start_17019.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2163 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2345
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1682 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Test 1 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 1 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 1 epochs and 10 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 2 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 2 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 2 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 2 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 2 epochs and 10 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 2 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 10 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 10 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 10 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test 10 epochs and 10 batches per generation: Error During Test at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
  Test threw exception
  Expression: collect(iitr) == collect(iitr)
  MethodError: no method matching Base.CodegenParams(; track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, emit_function=GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), emitted_function=GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}(GPUCompiler.MethodCompileTracer(PTX CompilerJob of function unbox_uint64(Any) for sm_75, Core.MethodInstance[MethodInstance for unbox_uint64(::Any)], #undef)), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, prefer_specsig, gnu_pubnames, debug_info_kind, lookup, generic_context) at reflection.jl:972 got unsupported keyword arguments "static_alloc", "emit_function", "emitted_function"
  Stacktrace:
    [1] kwerr(kw::NamedTuple{(:track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind), Tuple{Bool, Bool, Bool, Bool, GPUCompiler.var"#hook_emit_function#36"{GPUCompiler.MethodCompileTracer}, GPUCompiler.var"#hook_emitted_function#37"{GPUCompiler.MethodCompileTracer}, Bool, Int32}}, args::Type)
      @ Base ./error.jl:157
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:119
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, String, String}, h::Dict{String, LLVM.Module}, key::String)
      @ Base ./dict.jl:465
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/GKp4B/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ GPUCompiler ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:93
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(CUDA.partial_mapreduce_grid), Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/GKp4B/src/cache.jl:40
   [22] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(CUDA.partial_mapreduce_grid), tt::Type{Tuple{typeof(identity), typeof(&), Bool, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, CartesianIndices{4, NTuple{4, Base.OneTo{Int64}}}, Val{true}, CUDA.CuDeviceArray{Bool, 5, CUDA.AS.Global}, Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}, CUDA.CuDeviceArray{Float32, 4, CUDA.AS.Global}}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] mapreducedim!(f::typeof(identity), op::typeof(&), R::CUDA.CuArray{Bool, 4}, A::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{4}, NTuple{4, Base.OneTo{Int64}}, typeof(==), Tuple{CUDA.CuArray{Float32, 4}, CUDA.CuArray{Float32, 4}}}; init::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/mapreduce.jl:196
   [25] _mapreduce(::typeof(==), ::typeof(&), ::CUDA.CuArray{Float32, 4}, ::CUDA.CuArray{Float32, 4}; dims::Colon, init::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:62
   [26] #mapreduce#21
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [27] mapreduce
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:28 [inlined]
   [28] ==(A::CUDA.CuArray{Float32, 4}, B::CUDA.CuArray{Float32, 4})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/mapreduce.jl:78
   [29] _eq(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:332
   [30] ==(t1::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}}, t2::Tuple{CUDA.CuArray{Float32, 4}, Flux.OneHotMatrix{CUDA.CuVector{Flux.OneHotVector}}})
      @ Base ./tuple.jl:328
   [31] ==(A::Vector{Any}, B::Vector{Any})
      @ Base ./abstractarray.jl:1936
   [32] eval_test(evaluated::Expr, quoted::Expr, source::LineNumberNode, negate::Bool)
      @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:245
   [33] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:138
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1188
   [35] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:126
   [36] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [37] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:121
   [38] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1113
   [39] top-level scope
      @ ~/.julia/packages/NaiveGAflux/BOZ0I/test/app/autoflux.jl:3
Test Summary:                                                                                                                                                                  | Pass  Fail  Error  Total
NaiveGAflux.jl                                                                                                                                                                 | 1699     2     47   1748
  Probability                                                                                                                                                                  |   12                  12
  MutationShield                                                                                                                                                               |    6                   6
  VertexSelection                                                                                                                                                              |    2                   2
  MutationShield allowed list                                                                                                                                                  |   49                  49
  MutationShield abstract allowed list                                                                                                                                         |    4                   4
  SelectWithMutation                                                                                                                                                           |    6                   6
  remove_redundant_vertices                                                                                                                                                    |    3                   3
  Clone ApplyIf                                                                                                                                                                |    1                   1
  PersistentArray                                                                                                                                                              |    9                   9
  Bounded Random Walk                                                                                                                                                          |    3                   3
  Mergeopts                                                                                                                                                                    |    4                   4
  Optimizer trait                                                                                                                                                              |    7                   7
  Singleton                                                                                                                                                                    |    6                   6
  PrefixLogger                                                                                                                                                                 |    2                   2
  Shape                                                                                                                                                                        |  454                 454
  Architecture Spaces                                                                                                                                                          |  164                 164
  Mutation                                                                                                                                                                     |  349                 349
  Crossover                                                                                                                                                                    |  206                 206
  Fitness                                                                                                                                                                      |   95                  95
  Candidate                                                                                                                                                                    |   13            6     19
    CandidateModel identity                                                                                                                                                    |                 1      1
    CandidateModel HostCandidate                                                                                                                                               |                 1      1
    CandidateModel CacheCandidate                                                                                                                                              |                 1      1
    CandidateModel FileCandidate                                                                                                                                               |                 1      1
    CandidateModel Base.ComposedFunction{Type{CacheCandidate}, Type{HostCandidate}}(CacheCandidate, HostCandidate)                                                             |                 1      1
    CandidateModel Base.ComposedFunction{Base.ComposedFunction{Type{CacheCandidate}, Type{FileCandidate}}, Type{HostCandidate}}(CacheCandidate ∘ FileCandidate, HostCandidate) |                 1      1
    FileCandidate                                                                                                                                                              |    5                   5
    Global optimizer mutation                                                                                                                                                  |    8                   8
  Evolution                                                                                                                                                                    |   21                  21
  Population                                                                                                                                                                   |   12                  12
  RepeatPartitionIterator                                                                                                                                                      |   36                  36
  SeedIterator                                                                                                                                                                 |    2                   2
  MapIterator                                                                                                                                                                  |    1                   1
  GpuIterator                                                                                                                                                                  |    3                   3
  BatchIterator                                                                                                                                                                |    4                   4
  BatchIterator singleton                                                                                                                                                      |    3                   3
  ShuffleIterator basic                                                                                                                                                        |    2                   2
  ShuffleIterator ndims 1                                                                                                                                                      |    7                   7
  ShuffleIterator ndims 2                                                                                                                                                      |    5                   5
  ShuffleIterator ndims 3                                                                                                                                                      |    5                   5
  ShuffleIterator ndims 4                                                                                                                                                      |    7                   7
  ShuffleIterator ndims 5                                                                                                                                                      |    7                   7
  ShuffleIterator ndims 6                                                                                                                                                      |    9                   9
  ShuffleIterator singleton                                                                                                                                                    |    4                   4
  RepeatPartitionIterator and ShuffleIterator                                                                                                                                  |    9                   9
  visualization                                                                                                                                                                |   34                  34
  Basic example                                                                                                                                                                |    1            1      2
  ParSpace example                                                                                                                                                             |    6                   6
  ConvSpace example                                                                                                                                                            |    1                   1
  ArchSpace example                                                                                                                                                            |    2                   2
  Mutation examples                                                                                                                                                            |   17                  17
  Crossover examples                                                                                                                                                           |   13                  13
  Fitness functions                                                                                                                                                            |   32                  32
  Candidate handling                                                                                                                                                           |                 1      1
  Evolution strategies                                                                                                                                                         |    7                   7
  Iterators                                                                                                                                                                    |   18            1     19
  AutoFlux                                                                                                                                                                     |   36     2     38     76
    ImageClassifier smoketest                                                                                                                                                  |    2     2      6     10
    PruneLongRunning                                                                                                                                                           |   10                  10
    sizevs                                                                                                                                                                     |    6                   6
    TrainStrategy                                                                                                                                                              |   18           32     50
      Test 1 epochs and 2 batches per generation                                                                                                                               |    3            2      5
      Test 1 epochs and 10 batches per generation                                                                                                                              |    3            1      4
      Test 2 epochs and 2 batches per generation                                                                                                                               |    3            4      7
      Test 2 epochs and 10 batches per generation                                                                                                                              |    3            1      4
      Test 10 epochs and 2 batches per generation                                                                                                                              |    3           20     23
      Test 10 epochs and 10 batches per generation                                                                                                                             |    3            4      7
ERROR: LoadError: Some tests did not pass: 1699 passed, 2 failed, 47 errored, 0 broken.
in expression starting at /home/pkgeval/.julia/packages/NaiveGAflux/BOZ0I/test/runtests.jl:6
ERROR: Package NaiveGAflux errored during testing
Stacktrace:
  [1] pkgerror(::String, ::Vararg{String, N} where N)
    @ Pkg.Types /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Types.jl:52
  [2] test(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing)
    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1580
  [3] test(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:328
  [4] test(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec})
    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:315
  [5] #test#62
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:67 [inlined]
  [6] test
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:67 [inlined]
  [7] #test#61
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:66 [inlined]
  [8] test
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:66 [inlined]
  [9] test(pkg::String; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:65
 [10] test(pkg::String)
    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:65
 [11] top-level scope
    @ none:19
