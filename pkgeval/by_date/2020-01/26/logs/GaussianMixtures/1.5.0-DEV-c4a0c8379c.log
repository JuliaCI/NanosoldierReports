Julia Version 1.5.0-DEV.152
Commit c4a0c8379c (2020-01-26 14:50 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed CMakeWrapper ─────── v0.2.3
 Installed LegacyStrings ────── v0.4.1
 Installed StatsFuns ────────── v0.9.3
 Installed BinDeps ──────────── v1.0.0
 Installed DataStructures ───── v0.17.9
 Installed StatsBase ────────── v0.32.0
 Installed Missings ─────────── v0.4.3
 Installed Parameters ───────── v0.12.0
 Installed CMake ────────────── v1.1.2
 Installed Blosc ────────────── v0.5.1
 Installed Compat ───────────── v2.2.0
 Installed Arpack ───────────── v0.4.0
 Installed OrderedCollections ─ v1.1.0
 Installed JLD ──────────────── v0.9.1
 Installed SortingAlgorithms ── v0.3.1
 Installed NearestNeighbors ─── v0.4.4
 Installed ScikitLearnBase ──── v0.5.0
 Installed Clustering ───────── v0.13.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed StaticArrays ─────── v0.12.1
 Installed Distances ────────── v0.8.2
 Installed PDMats ───────────── v0.9.11
 Installed QuadGK ───────────── v2.3.1
 Installed BinaryProvider ───── v0.5.8
 Installed FileIO ───────────── v1.2.1
 Installed URIParser ────────── v0.4.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed Rmath ────────────── v0.6.0
 Installed FillArrays ───────── v0.8.4
 Installed SpecialFunctions ─── v0.9.0
 Installed Distributions ────── v0.22.3
 Installed HDF5 ─────────────── v0.12.5
 Installed DataAPI ──────────── v1.1.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_A1huFg/Project.toml`
 [no changes]
  Updating `/tmp/jl_A1huFg/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_zbsHHA/Project.toml`
 [no changes]
  Updating `/tmp/jl_zbsHHA/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_0Y8aRQ/Project.toml`
 [no changes]
  Updating `/tmp/jl_0Y8aRQ/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_TvlVCr/Project.toml`
 [no changes]
  Updating `/tmp/jl_TvlVCr/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_o1mmen/Project.toml`
 [no changes]
  Updating `/tmp/jl_o1mmen/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_o1mmen/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.8221385657898101e6, [65631.68167406761, 34368.31832593239], [-33173.99491447746 14553.304275367553 5637.028375448921; 33185.79539553002 -14868.320509774054 -5933.055481333258], [[54204.39087642719 6549.4434283474175 3153.4114718765723; 6549.4434283474175 64584.40344703714 1607.6533431723833; 3153.4114718765723 1607.6533431723835 66026.230656154], [46235.61417234418 -6329.99150042869 -3245.6433057355175; -6329.99150042869 35775.036512613755 -1321.1233854977136; -3245.6433057355175 -1321.1233854977136 34826.00070188639]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.299685e+03
      1       1.029721e+03      -2.699640e+02 |        4
      2       1.008869e+03      -2.085127e+01 |        4
      3       9.909491e+02      -1.792012e+01 |        0
      4       9.909491e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 990.9491202604868)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.060149
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.684282
[ Info: iteration 2, lowerbound -3.528716
[ Info: iteration 3, lowerbound -3.387207
[ Info: iteration 4, lowerbound -3.258745
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.148710
[ Info: iteration 6, lowerbound -3.063364
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.996718
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.932568
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.843287
[ Info: iteration 10, lowerbound -2.735445
[ Info: iteration 11, lowerbound -2.620720
[ Info: iteration 12, lowerbound -2.515663
[ Info: iteration 13, lowerbound -2.436555
[ Info: iteration 14, lowerbound -2.387596
[ Info: dropping number of Gaussions to 3
[ Info: iteration 15, lowerbound -2.348025
[ Info: iteration 16, lowerbound -2.319990
[ Info: iteration 17, lowerbound -2.308183
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.303084
[ Info: iteration 19, lowerbound -2.299264
[ Info: iteration 20, lowerbound -2.299258
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Jan 27 10:54:46 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Jan 27 10:54:54 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Mon Jan 27 10:54:56 2020: EM with 272 data points 0 iterations avll -2.060149
5.8 data points per parameter
, Mon Jan 27 10:54:58 2020: GMM converted to Variational GMM
, Mon Jan 27 10:55:06 2020: iteration 1, lowerbound -3.684282
, Mon Jan 27 10:55:06 2020: iteration 2, lowerbound -3.528716
, Mon Jan 27 10:55:06 2020: iteration 3, lowerbound -3.387207
, Mon Jan 27 10:55:06 2020: iteration 4, lowerbound -3.258745
, Mon Jan 27 10:55:07 2020: dropping number of Gaussions to 7
, Mon Jan 27 10:55:07 2020: iteration 5, lowerbound -3.148710
, Mon Jan 27 10:55:07 2020: iteration 6, lowerbound -3.063364
, Mon Jan 27 10:55:07 2020: dropping number of Gaussions to 6
, Mon Jan 27 10:55:07 2020: iteration 7, lowerbound -2.996718
, Mon Jan 27 10:55:07 2020: dropping number of Gaussions to 5
, Mon Jan 27 10:55:07 2020: iteration 8, lowerbound -2.932568
, Mon Jan 27 10:55:07 2020: dropping number of Gaussions to 4
, Mon Jan 27 10:55:07 2020: iteration 9, lowerbound -2.843287
, Mon Jan 27 10:55:07 2020: iteration 10, lowerbound -2.735445
, Mon Jan 27 10:55:07 2020: iteration 11, lowerbound -2.620720
, Mon Jan 27 10:55:07 2020: iteration 12, lowerbound -2.515663
, Mon Jan 27 10:55:07 2020: iteration 13, lowerbound -2.436555
, Mon Jan 27 10:55:07 2020: iteration 14, lowerbound -2.387596
, Mon Jan 27 10:55:07 2020: dropping number of Gaussions to 3
, Mon Jan 27 10:55:07 2020: iteration 15, lowerbound -2.348025
, Mon Jan 27 10:55:07 2020: iteration 16, lowerbound -2.319990
, Mon Jan 27 10:55:07 2020: iteration 17, lowerbound -2.308183
, Mon Jan 27 10:55:07 2020: dropping number of Gaussions to 2
, Mon Jan 27 10:55:07 2020: iteration 18, lowerbound -2.303084
, Mon Jan 27 10:55:07 2020: iteration 19, lowerbound -2.299264
, Mon Jan 27 10:55:07 2020: iteration 20, lowerbound -2.299258
, Mon Jan 27 10:55:07 2020: iteration 21, lowerbound -2.299255
, Mon Jan 27 10:55:07 2020: iteration 22, lowerbound -2.299254
, Mon Jan 27 10:55:07 2020: iteration 23, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 24, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 25, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 26, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 27, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 28, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 29, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 30, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 31, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 32, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 33, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 34, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 35, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 36, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 37, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 38, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 39, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 40, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 41, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 42, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 43, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 44, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 45, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 46, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 47, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 48, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 49, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: iteration 50, lowerbound -2.299253
, Mon Jan 27 10:55:07 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398608, 178.04509222601396]
β = [95.95490777398608, 178.04509222601396]
m = [2.00022925777537 53.85198717246128; 4.250300733269908 79.2868669443618]
ν = [97.95490777398608, 180.04509222601396]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948432 -0.008953123827346126; 0.0 0.012748664777409342], [0.1840415554748469 -0.007644049042327514; 0.0 0.008581705166333357]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9968615165475709
avll from llpg:  -0.9968615165475709
avll direct:     -0.996861516547571
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9996929103085224
avll from llpg:  -0.9996929103085224
avll direct:     -0.9996929103085223
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.150624      0.0383684   -0.0883721    0.156237     0.015939    -0.062534     0.0125362   -0.0482681   -0.0328002    0.0106037  -0.0778536    0.114193    -0.0732766    0.171451     0.0441671   -0.0827223    0.233946    -0.120204     0.0740504    -0.262835    -0.0368761   -0.00506199  -0.0908809    0.0306459    -0.151803     0.0661435
 -0.142272     -0.0397186   -0.13033      0.0779954   -0.272082    -0.098831     0.0493452   -0.00906842  -0.00999081   0.0899924   0.0614655   -0.0360337    0.16008      0.180369     0.0148737   -0.0123699   -0.0201645   -0.100564    -0.0330178    -0.00167376   0.0319682   -0.0931661   -0.129965     0.044421      0.10075     -0.160618
  0.0942151     0.0478812    0.088687     0.155084     0.0614485    0.0994833    0.062784    -0.00158585  -0.00760128   0.137351   -0.156576     0.1889      -0.0376195    0.0674611   -0.0763788   -0.125761    -0.00981105  -0.0152871   -0.0875683    -0.078547    -0.0165556    0.0722634    0.0626709    0.0468198     0.187591    -0.0110333
 -0.0815684    -0.0456816    0.0595765    0.0140702    0.0817099   -0.108652     0.160625     0.0274917   -0.00637025  -0.115      -0.0219359   -0.0440032    0.0199441   -0.155036    -0.213574     0.0606109    0.0210389    0.0103675    0.0377016    -0.0386092    0.00977531  -0.251173    -0.105621     0.228082     -0.0238977    0.0130177
 -0.058672     -0.173175    -0.0249731   -0.0610239    0.0751414    0.085746    -0.0538619    0.0547899    0.159828     0.168525    0.115477     0.00156127   0.0728004    0.0233551    0.136717    -0.00221399  -0.0122552   -0.0497457    0.0281892     0.0241658    0.0281035   -0.160846     0.0241568    0.0176829    -0.0628795   -0.0648182
  0.149285     -0.197793     0.132834    -0.130204     0.112956    -0.0930941    0.0936777    0.0866779   -0.0268214    0.0446222  -0.0453671   -0.157905    -0.0708383    0.0171228    0.0646274    0.167612     0.116996    -0.0482378   -0.0744478    -0.151969     0.0323075    0.117771     0.0565732    0.0741319    -0.00168199  -0.0683926
  0.0256343     0.170324     0.004601    -0.0725701   -0.0366547   -0.0739592   -0.113985    -0.0625865   -0.0217541   -0.0615892   0.246336     0.00202235  -0.108829     0.0724052   -0.00124493   0.0895315    0.121047     0.034926     0.00660024   -0.0790812   -0.178859    -0.143341    -0.116778    -0.0622867     0.210341    -0.108146
  0.0232048    -0.143767    -0.167079     0.00647502   0.0077585   -0.0344813   -0.0304516   -0.0303145   -0.174415    -0.0991529  -0.0940415   -0.122545    -0.00778334   0.0216612   -0.0140925   -0.0956598    0.184453     0.0176557    0.034579     -0.0785477    0.0829437   -0.0610425   -0.0999238    0.0619734     0.0981323   -0.0146851
 -0.015304     -0.0202115    0.0855044   -0.0725927   -0.18673      0.163945    -0.0194649   -0.0827464   -0.0665317    0.0888411   0.203646     0.0273677   -0.12124     -0.0337203    0.199076    -0.0107919   -0.0179856    0.0314131    0.0578141    -0.0106281    0.0166232    0.142348     0.0149247   -0.151249     -0.00601951   0.0568245
  0.0861682    -0.0427558   -0.0598602    0.00837242  -0.104452     0.0497497   -0.0599984   -0.0381493   -0.229066    -0.302815    0.122981     0.00173567   0.00759535  -0.155756     0.0381915    0.0493396    0.100809    -0.0552337   -0.0732209    -0.170489    -0.061169    -0.0698513    0.145374     0.013256      0.0748189    0.185703
  0.132108     -0.0197618   -0.0143431   -0.128129    -0.0922798   -0.00579885  -0.00975342  -0.0690179   -0.0997614   -0.0073812  -0.00454831  -0.0955537   -0.0583533   -0.0159708    0.0394973   -0.016914    -0.103043    -0.174945     0.0181113    -0.0730201   -0.0755406   -0.0843748    0.0268417   -0.133262      0.0120825   -0.0901858
  0.0171998    -0.0482066   -0.0655905    0.0668074    0.146225     0.144897    -0.0592264   -0.056884     0.0978559   -0.0475814  -0.0852852    0.117332    -0.232006    -0.0441131    0.207912    -0.0853509    0.126347    -0.12122      0.000187317  -0.0397077    0.0960953   -0.103673     0.0112055   -0.0408927    -0.0297468    0.139973
 -0.120783      0.211166     0.0703409   -0.0668005    0.157586     0.00868076  -0.127259     0.0155229    0.0912421    0.107759   -0.00333628  -0.0367269    0.0586758    0.00133062   0.149567    -0.176712     0.0916447    0.0755844   -0.116953      0.21192     -0.00841347   0.0652805    0.00799446  -0.100144     -0.0121481    0.00113495
 -0.0475269     0.0630845   -0.159335     0.0458712    0.0791021   -0.11087     -0.18764     -0.0725934    0.0655095    0.120018    0.127234     0.00280741  -0.113376     0.114331     0.0178719    0.0424258    0.00747028  -0.0722755    0.0177935    -0.0399366    0.0637105   -0.0963259   -0.157857    -0.0420075     0.209636     0.10159
 -0.0502279    -0.00565724  -0.197548    -0.0736704    0.0124024   -0.15903      0.142597     0.111514     0.158639    -0.0628727   0.0649449   -0.0333317    0.0373258   -0.121       -0.106308    -0.066165    -0.0293429    0.208538    -0.314352     -0.0921597   -0.05699      0.281882    -0.0170826   -0.0784985    -0.0519633   -0.123271
 -0.0904544     0.104372     0.16464      0.00041629   0.11606     -0.0327909   -0.036382     0.100611    -0.0162186   -0.0246837  -0.0763051    0.0421593   -0.0269607    0.110132     0.231907     0.0579658    0.053525    -0.0682326   -0.0306743    -0.0784559    0.0614712    0.0380587    0.131933     0.167374      0.028701     0.007818
  0.0778261     0.0641277    0.267475    -0.0892676    0.0223429    0.101374     0.0860379   -0.0141656   -0.214493     0.156333   -0.0296478   -0.146076     0.0470465   -0.143792    -0.0972072    0.0770673   -0.256828    -0.0976348    0.04057       0.109144    -0.0834059    0.0664155    0.153041     0.0849509     0.161164     0.0231194
 -0.0358836    -0.172956     0.0194636   -0.0925046   -0.0462428   -0.0833077    0.0235932    0.0966937    0.0905358    0.0156989   0.0674184   -0.0839375    0.354135     0.0888291    0.19116      0.102056     0.0854627   -0.103523     0.118883     -0.0258028    0.0479869    0.141723     0.142374     0.00297285   -0.0908327    0.0330951
  0.000145907   0.0582372    0.0489665   -0.142231    -0.0538932    0.205614     0.0384289    0.121143     0.0797339   -0.0664803   0.0810645   -0.140356     0.0961343   -0.0110268    0.037205    -0.12342     -0.0953882    0.0204707   -0.0278967    -0.0311431   -0.0707981    0.0794958    0.111885    -0.0731774    -0.104146    -0.102031
 -0.121341     -0.131472    -0.0801747    0.00995767  -0.0154261    0.114303     0.0743418    0.0196684   -0.045317    -0.0820889   0.155787     0.0143298   -0.0828743    0.00737451   0.020251     0.0686867   -0.0126745    0.0311698   -0.0394067    -0.00845306  -0.0928226   -0.0240084   -0.0129744   -0.000243403   0.0395613   -0.0764273
  0.0271246    -0.149097     0.151429     0.0719397   -0.0113764   -0.179193    -0.0371711    0.0661242    0.105306     0.12546    -0.0489174   -0.00567022   0.0514346    0.0106923    0.060914     0.169795     0.131064     0.0469504   -0.0547763    -0.0170435   -0.108795     0.0227711   -0.0339753   -0.0449362    -0.0765136   -0.0451794
 -0.0324186    -0.185924    -0.0259721    0.0451278    0.0230756   -0.0825108   -0.00526313   0.0664614    0.0371309   -0.0450013   0.18685     -0.0172653   -0.114846    -0.137125    -0.1264       0.0194615    0.0929204    0.264812    -0.0425439    -0.219376    -0.0320067   -0.098569    -0.158185    -0.0784997     0.131695    -0.0480214
 -0.0603779    -0.113668    -0.0967723   -0.0621966    0.0581151   -0.0219025    0.0167489    0.0897051   -0.0438365    0.044503    0.0287931    0.00184352  -0.113242     0.00499441   0.0698539    0.109763     0.0259874   -0.123897    -0.00860662    0.0337392    0.0738424   -0.237831     0.0891107    0.215709     -0.0973612    0.116051
  0.0452647     0.0575436   -0.167837    -0.102444     0.00306439   0.0952859   -0.115939    -0.178859    -0.107708     0.0133363   0.054706    -0.0392671    0.063337    -0.221075    -0.0867443   -0.0296758    0.0189079   -0.0116295   -0.0756717    -0.0150355   -0.0175216    0.0915061    0.0576652    0.102902     -0.00642166  -0.126509
 -0.0314411    -0.00585457   0.213177     0.222413    -0.0727515    0.114973    -0.0509327    0.0726132    0.0250815   -0.0968418   0.00337071  -0.120859    -0.0166594   -0.209878     0.130224     0.131996     0.140064    -0.161203    -0.0993869    -0.0843541   -0.0756551    0.0162384    0.183131    -0.0484735     0.0726772   -0.0790815
 -0.0356753    -0.0474548   -0.0122072    0.0812553    0.0640108    0.0591662    0.03539     -0.147331     0.049827     0.0416158   0.0880584    0.00665346  -0.00323262  -0.087832     0.0292964    0.0874661   -0.0399711    0.0996941    0.108403      0.0224272    0.111329    -0.189873    -0.0110128    0.0256236     0.0996539    0.0342867
 -0.216314      0.0498939    0.117606    -0.062764     0.0689538   -0.0129741   -0.105184    -0.00300068   0.138928     0.194427   -0.104851     0.131434    -0.0521572   -0.237329     0.126241     0.0464303    0.0294235    0.00501176  -0.129581      0.081922    -0.00394718   0.0487476    0.0642082   -0.0221763    -0.0408132   -0.18077
 -0.0714439    -0.138506    -0.0558078    0.0933803   -0.0250471   -0.0497798    0.0877829   -0.0172129   -0.0111744   -0.0858694  -0.153306    -0.0164363   -0.0475202   -0.0102393    0.0413196   -0.0583758    0.0106775    0.0174351   -0.0682726     0.0171978   -0.00922011   0.0294125    0.0629915    0.0893992    -0.0873126    0.0576071
  0.182115     -0.190773     0.0223318   -0.0279135   -0.0581757    0.0310866   -0.0440115   -0.0488514   -0.0112595    0.0197673   0.128761    -0.211191     0.0658829    0.00824956   0.0805939    0.00275064  -0.0599852    0.00401089   0.00869946   -0.0855549    0.0605015   -0.00452425   0.00160279  -0.00235776    0.107274    -0.10929
  0.0289519     0.09909      0.00287217   0.104487    -0.0479602   -0.126506    -0.00936002  -0.0195779    0.0363093    0.0167097   0.0583128   -0.043708     0.165061    -0.137947     0.11346     -0.0745911    0.0254521    0.140348    -0.098543      0.102716    -0.0138921   -0.100241    -0.126766     0.0585437     0.0495355    0.118964
 -0.123047      0.0763094    0.119979     0.0358788   -0.0149468    0.0869853   -0.0285788   -0.0181083    0.00147279  -0.237199   -0.125814    -0.0408039    0.0171852   -0.0530842    0.0508015   -0.118335     0.0368639    0.124622    -0.0666472    -0.157584    -0.0494175    0.0883221   -0.15317     -0.0544191     0.132174     0.0550146
 -0.092835      0.00830564  -0.0988601   -0.0639057    0.0128282    0.0582505    0.0510268   -0.15091     -0.0473257    0.130813   -0.0284402    0.202912    -0.0268147   -0.0366067    0.0114296    0.00557349  -0.0413156    0.0154015    0.138046     -0.00250317   0.100353    -0.00200412   0.196537     0.0297963    -0.307989     0.0221614kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4416784462162615
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.441784
[ Info: iteration 2, average log likelihood -1.441678
[ Info: iteration 3, average log likelihood -1.440835
[ Info: iteration 4, average log likelihood -1.434034
[ Info: iteration 5, average log likelihood -1.419284
[ Info: iteration 6, average log likelihood -1.412671
[ Info: iteration 7, average log likelihood -1.410646
[ Info: iteration 8, average log likelihood -1.409145
[ Info: iteration 9, average log likelihood -1.408008
[ Info: iteration 10, average log likelihood -1.407260
[ Info: iteration 11, average log likelihood -1.406786
[ Info: iteration 12, average log likelihood -1.406473
[ Info: iteration 13, average log likelihood -1.406258
[ Info: iteration 14, average log likelihood -1.406105
[ Info: iteration 15, average log likelihood -1.405993
[ Info: iteration 16, average log likelihood -1.405910
[ Info: iteration 17, average log likelihood -1.405847
[ Info: iteration 18, average log likelihood -1.405796
[ Info: iteration 19, average log likelihood -1.405756
[ Info: iteration 20, average log likelihood -1.405725
[ Info: iteration 21, average log likelihood -1.405701
[ Info: iteration 22, average log likelihood -1.405683
[ Info: iteration 23, average log likelihood -1.405670
[ Info: iteration 24, average log likelihood -1.405659
[ Info: iteration 25, average log likelihood -1.405650
[ Info: iteration 26, average log likelihood -1.405642
[ Info: iteration 27, average log likelihood -1.405636
[ Info: iteration 28, average log likelihood -1.405630
[ Info: iteration 29, average log likelihood -1.405624
[ Info: iteration 30, average log likelihood -1.405619
[ Info: iteration 31, average log likelihood -1.405615
[ Info: iteration 32, average log likelihood -1.405610
[ Info: iteration 33, average log likelihood -1.405605
[ Info: iteration 34, average log likelihood -1.405601
[ Info: iteration 35, average log likelihood -1.405597
[ Info: iteration 36, average log likelihood -1.405592
[ Info: iteration 37, average log likelihood -1.405588
[ Info: iteration 38, average log likelihood -1.405585
[ Info: iteration 39, average log likelihood -1.405581
[ Info: iteration 40, average log likelihood -1.405578
[ Info: iteration 41, average log likelihood -1.405575
[ Info: iteration 42, average log likelihood -1.405573
[ Info: iteration 43, average log likelihood -1.405571
[ Info: iteration 44, average log likelihood -1.405569
[ Info: iteration 45, average log likelihood -1.405567
[ Info: iteration 46, average log likelihood -1.405566
[ Info: iteration 47, average log likelihood -1.405564
[ Info: iteration 48, average log likelihood -1.405563
[ Info: iteration 49, average log likelihood -1.405562
[ Info: iteration 50, average log likelihood -1.405561
┌ Info: EM with 100000 data points 50 iterations avll -1.405561
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4417837782315728
│     -1.441677907047099
│      ⋮
└     -1.4055613429526301
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405712
[ Info: iteration 2, average log likelihood -1.405559
[ Info: iteration 3, average log likelihood -1.404620
[ Info: iteration 4, average log likelihood -1.397535
[ Info: iteration 5, average log likelihood -1.382705
[ Info: iteration 6, average log likelihood -1.373966
[ Info: iteration 7, average log likelihood -1.370687
[ Info: iteration 8, average log likelihood -1.369234
[ Info: iteration 9, average log likelihood -1.368457
[ Info: iteration 10, average log likelihood -1.367914
[ Info: iteration 11, average log likelihood -1.367458
[ Info: iteration 12, average log likelihood -1.367005
[ Info: iteration 13, average log likelihood -1.366497
[ Info: iteration 14, average log likelihood -1.365945
[ Info: iteration 15, average log likelihood -1.365379
[ Info: iteration 16, average log likelihood -1.364779
[ Info: iteration 17, average log likelihood -1.364086
[ Info: iteration 18, average log likelihood -1.363307
[ Info: iteration 19, average log likelihood -1.362488
[ Info: iteration 20, average log likelihood -1.361664
[ Info: iteration 21, average log likelihood -1.360875
[ Info: iteration 22, average log likelihood -1.360151
[ Info: iteration 23, average log likelihood -1.359489
[ Info: iteration 24, average log likelihood -1.358882
[ Info: iteration 25, average log likelihood -1.358353
[ Info: iteration 26, average log likelihood -1.357914
[ Info: iteration 27, average log likelihood -1.357574
[ Info: iteration 28, average log likelihood -1.357339
[ Info: iteration 29, average log likelihood -1.357190
[ Info: iteration 30, average log likelihood -1.357088
[ Info: iteration 31, average log likelihood -1.357009
[ Info: iteration 32, average log likelihood -1.356945
[ Info: iteration 33, average log likelihood -1.356895
[ Info: iteration 34, average log likelihood -1.356855
[ Info: iteration 35, average log likelihood -1.356825
[ Info: iteration 36, average log likelihood -1.356801
[ Info: iteration 37, average log likelihood -1.356783
[ Info: iteration 38, average log likelihood -1.356770
[ Info: iteration 39, average log likelihood -1.356760
[ Info: iteration 40, average log likelihood -1.356752
[ Info: iteration 41, average log likelihood -1.356747
[ Info: iteration 42, average log likelihood -1.356743
[ Info: iteration 43, average log likelihood -1.356741
[ Info: iteration 44, average log likelihood -1.356739
[ Info: iteration 45, average log likelihood -1.356738
[ Info: iteration 46, average log likelihood -1.356737
[ Info: iteration 47, average log likelihood -1.356736
[ Info: iteration 48, average log likelihood -1.356736
[ Info: iteration 49, average log likelihood -1.356736
[ Info: iteration 50, average log likelihood -1.356736
┌ Info: EM with 100000 data points 50 iterations avll -1.356736
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4057120984765445
│     -1.4055586038255068
│      ⋮
└     -1.3567355166533972
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.356930
[ Info: iteration 2, average log likelihood -1.356739
[ Info: iteration 3, average log likelihood -1.356025
[ Info: iteration 4, average log likelihood -1.348075
[ Info: iteration 5, average log likelihood -1.327670
[ Info: iteration 6, average log likelihood -1.315925
[ Info: iteration 7, average log likelihood -1.311147
[ Info: iteration 8, average log likelihood -1.308683
[ Info: iteration 9, average log likelihood -1.306923
[ Info: iteration 10, average log likelihood -1.305365
[ Info: iteration 11, average log likelihood -1.304064
[ Info: iteration 12, average log likelihood -1.302997
[ Info: iteration 13, average log likelihood -1.302049
[ Info: iteration 14, average log likelihood -1.301114
[ Info: iteration 15, average log likelihood -1.300109
[ Info: iteration 16, average log likelihood -1.299054
[ Info: iteration 17, average log likelihood -1.298122
[ Info: iteration 18, average log likelihood -1.297439
[ Info: iteration 19, average log likelihood -1.296958
[ Info: iteration 20, average log likelihood -1.296594
[ Info: iteration 21, average log likelihood -1.296287
[ Info: iteration 22, average log likelihood -1.296004
[ Info: iteration 23, average log likelihood -1.295730
[ Info: iteration 24, average log likelihood -1.295453
[ Info: iteration 25, average log likelihood -1.295171
[ Info: iteration 26, average log likelihood -1.294883
[ Info: iteration 27, average log likelihood -1.294580
[ Info: iteration 28, average log likelihood -1.294274
[ Info: iteration 29, average log likelihood -1.293975
[ Info: iteration 30, average log likelihood -1.293696
[ Info: iteration 31, average log likelihood -1.293435
[ Info: iteration 32, average log likelihood -1.293191
[ Info: iteration 33, average log likelihood -1.292969
[ Info: iteration 34, average log likelihood -1.292766
[ Info: iteration 35, average log likelihood -1.292582
[ Info: iteration 36, average log likelihood -1.292412
[ Info: iteration 37, average log likelihood -1.292241
[ Info: iteration 38, average log likelihood -1.292071
[ Info: iteration 39, average log likelihood -1.291913
[ Info: iteration 40, average log likelihood -1.291795
[ Info: iteration 41, average log likelihood -1.291722
[ Info: iteration 42, average log likelihood -1.291681
[ Info: iteration 43, average log likelihood -1.291659
[ Info: iteration 44, average log likelihood -1.291647
[ Info: iteration 45, average log likelihood -1.291639
[ Info: iteration 46, average log likelihood -1.291633
[ Info: iteration 47, average log likelihood -1.291628
[ Info: iteration 48, average log likelihood -1.291625
[ Info: iteration 49, average log likelihood -1.291622
[ Info: iteration 50, average log likelihood -1.291619
┌ Info: EM with 100000 data points 50 iterations avll -1.291619
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3569298687311173
│     -1.356739248708371
│      ⋮
└     -1.291619161636904
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.291858
[ Info: iteration 2, average log likelihood -1.291575
[ Info: iteration 3, average log likelihood -1.290455
[ Info: iteration 4, average log likelihood -1.280332
[ Info: iteration 5, average log likelihood -1.260785
[ Info: iteration 6, average log likelihood -1.250785
[ Info: iteration 7, average log likelihood -1.246960
[ Info: iteration 8, average log likelihood -1.244918
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.243729
[ Info: iteration 10, average log likelihood -1.242879
[ Info: iteration 11, average log likelihood -1.242200
[ Info: iteration 12, average log likelihood -1.241647
[ Info: iteration 13, average log likelihood -1.240968
[ Info: iteration 14, average log likelihood -1.239819
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.237790
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.234165
[ Info: iteration 17, average log likelihood -1.240125
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.232505
[ Info: iteration 19, average log likelihood -1.229623
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.226731
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.223921
[ Info: iteration 22, average log likelihood -1.231667
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.224182
[ Info: iteration 24, average log likelihood -1.220921
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.218016
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.229953
[ Info: iteration 27, average log likelihood -1.235319
[ Info: iteration 28, average log likelihood -1.227056
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.223354
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.220655
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.228395
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.221454
[ Info: iteration 33, average log likelihood -1.232747
[ Info: iteration 34, average log likelihood -1.226189
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.222384
[ Info: iteration 36, average log likelihood -1.230970
[ Info: iteration 37, average log likelihood -1.223606
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.220054
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.217337
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.240781
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.238774
[ Info: iteration 42, average log likelihood -1.229433
[ Info: iteration 43, average log likelihood -1.225349
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.221978
[ Info: iteration 45, average log likelihood -1.219156
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.216084
[ Info: iteration 47, average log likelihood -1.238824
[ Info: iteration 48, average log likelihood -1.228371
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.224328
[ Info: iteration 50, average log likelihood -1.233746
┌ Info: EM with 100000 data points 50 iterations avll -1.233746
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2918581286387159
│     -1.2915748269209437
│      ⋮
└     -1.2337463644301143
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.225778
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.220996
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.219011
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.208007
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.172273
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     18
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.142349
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     12
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.144967
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.141580
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│      8
│     15
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.118964
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.130242
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     12
│     17
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.124524
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│      5
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.126610
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     15
│     18
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.126894
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     12
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.140385
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.123839
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.124279
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     12
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.121087
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     18
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.119998
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│     17
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.112782
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.143089
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.126878
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      5
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.110878
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     12
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.127103
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     15
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.122352
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│     17
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.114126
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.141194
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.124297
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      5
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.113936
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     12
│     16
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.124746
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     25
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.133581
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│     18
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.111023
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     12
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.132538
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.123135
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      5
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.117817
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     12
│     16
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.129306
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.129391
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      7
│      8
│     17
│     23
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.107100
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     12
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.136664
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.127455
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      5
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.114492
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     12
│     16
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.126023
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.133390
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      7
│      8
│     18
│     23
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.111202
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     12
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.133113
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.123036
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      5
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.117918
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     12
│     16
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.129537
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.129371
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│     17
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.107142
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     12
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.136749
┌ Info: EM with 100000 data points 50 iterations avll -1.136749
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2257775833176368
│     -1.2209963597528815
│      ⋮
└     -1.1367491891174388
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4416784462162615
│     -1.4417837782315728
│     -1.441677907047099
│     -1.44083521400136
│      ⋮
│     -1.129370957955961
│     -1.1071415718075057
└     -1.1367491891174388
32×26 Array{Float64,2}:
 -0.031645     0.00850134  -0.826526    0.204513    -0.0718334    0.110433    -0.0465702    0.0955277    0.244979     -0.128569     0.00161612   -0.111252    -0.0163886    -0.178675     0.144291    0.0769402    0.089512     -0.133068    -0.336689    -0.0839857   -0.0756708    0.00213887   0.0829679    -0.0377141     0.274544    -0.25172
 -0.0507011   -0.00642732   0.774552    0.291349    -0.0650111    0.117246    -0.00454468   0.0699617   -0.0928236    -0.10193      0.00326565   -0.118404    -0.0136041    -0.220765     0.132259    0.15347      0.18491      -0.154364     0.0958095   -0.0836452   -0.0754652   -0.048899     0.222977     -0.0432758    -0.0151269   -0.0363812
 -0.0221643   -0.00154862  -0.170425   -0.0664241    0.00318471  -0.152687     0.152335     0.109749     0.180389     -0.0633612    0.0659607    -0.0249159    0.0221152    -0.127813    -0.11965    -0.107432    -0.0289988     0.252667    -0.319087    -0.0921857   -0.0429054    0.279357    -0.0165938    -0.0807616    -0.0654403   -0.140941
 -0.0443492   -0.0633114   -0.0256045  -0.00378155   0.0157118   -0.00233265  -0.0206487   -0.00750782   0.0586025     0.0110458    0.0497165     0.00734142  -0.0299052     0.0235613    0.0677532  -0.00093371   0.0457404     0.00498404  -0.0185411   -0.00793602  -0.0382546   -0.0973164   -0.0022547     0.010275      0.0095729   -0.00594819
 -0.0507972    0.110703     0.0643093   0.0425455    0.102404    -0.0848883   -0.0679263    0.0637201    0.000307131  -0.0116704   -0.0231631     0.00259314  -0.0328814     0.105686     0.201621    0.0533581    0.0226825    -0.0638233   -0.0229361   -0.0546696    0.0496345   -0.0117515    0.0592186     0.0572621     0.0437593    0.0332737
  0.00168096  -0.128254    -0.0404375   0.074308     0.0793183    0.0885343   -0.0364382    0.0224464    0.0519189    -0.0485362    0.0487149     0.0350564   -0.171781     -0.0833526    0.0150816  -0.0311703    0.0838086     0.0891353   -0.0146668   -0.133794     0.0277737   -0.101118    -0.0890884    -0.0580522     0.0581353    0.0385921
  0.0225032    0.121943     0.0557448  -0.213555     0.0201608    0.156128     0.0324533   -0.976502     0.135556     -0.102955     0.0303574    -0.131257     0.0699348     0.0514127    0.0342709  -0.118027    -0.123123      0.0133376   -0.0108414   -0.03625      0.0417932    0.0717354    0.097057      0.27969      -0.157525    -0.0547091
 -0.00994364   0.0231687    0.022436   -0.0184877   -0.0720836    0.183844     0.0272358    0.667324     0.0647113    -0.0561879    0.162892     -0.133395     0.0999205    -0.0397435    0.0335853  -0.110149    -0.0483317     0.0189253   -0.0179495   -0.0338292   -0.080014     0.0581891    0.100189     -0.279705     -0.00711315  -0.10628
  0.11471     -0.0818674   -0.139157    0.0301184   -0.124237     0.0577971   -0.0931489   -0.0704744   -0.482216     -0.37379      0.0318976     0.0105529    0.0287671    -0.258025     0.0994881   0.137175     0.237877     -0.00306313  -0.0690606   -0.1609      -0.0596663   -0.0463917    0.173208      0.0135875     0.0234247    0.189488
  0.0454721    0.0123966   -0.0494314  -0.0148821   -0.0751096   -0.0138033   -0.0201926   -0.102822     0.0571605    -0.209063     0.270157     -0.0268513   -0.0319852    -0.00158461   0.104305   -0.0333523   -0.0951636    -0.0781046   -0.0691201   -0.162875    -0.0617724   -0.121688     0.0711984     0.0111759     0.161734     0.180952
  0.0873483    0.0384616    0.110155    0.159824     0.0472161    0.087615     0.0621022    0.00312945  -0.0130277     0.137434    -0.154941      0.184305    -0.0434114     0.0603316   -0.117744   -0.128425    -0.00696871    0.00401882  -0.0591896   -0.0663057   -0.00695338   0.0598167    0.050583      0.0477491     0.215196    -0.0187924
 -0.164258     0.0364198   -0.0812996   0.147933     0.0177328   -0.062293     0.00410017  -0.0278224   -0.0316902     0.00299931  -0.0909515     0.112733    -0.0929625     0.161713     0.032632   -0.0986399    0.231329     -0.126928     0.0571082   -0.252054    -0.0368121   -0.005389    -0.0737732     0.0249916    -0.155692     0.0646191
 -0.0411175   -0.0538989   -0.0732921  -0.0573645   -0.0744115    0.0815156   -0.00756336  -0.00475013  -0.0382176     0.0614684    0.114216      0.00361666  -0.111812     -0.00875932   0.129919    0.0321504    0.000529073  -0.0453398    0.0303227    0.00851915   0.0449286   -0.0302096    0.0383167     0.0292198    -0.0432913    0.0839381
  0.183311    -0.190976     0.0418011  -0.0519291   -0.00286865   0.0503277   -0.049693    -0.0378786   -0.0170224     0.00658059   0.128353     -0.224141     0.0639267     0.0142227    0.10077     0.0411307   -0.0355365     0.0147852    0.00486069  -0.0861989    0.0657328    0.0135912    0.00253164   -0.0377818     0.105998    -0.107636
 -0.168799     0.0087808    0.0120697  -0.00216634  -0.0883326   -0.050928    -0.0306743   -0.0229465    0.0894279     0.150515    -0.0188069     0.0535266    0.0276607    -0.0401266    0.074057    0.0478951   -0.00652663   -0.0512823   -0.0904543    0.0523252    0.00747768  -0.0165511    0.00499454    0.00751521    0.0344816   -0.171465
 -0.125674     0.0699175    0.0756992   0.0427558   -0.0226137    0.0725465   -0.0318541   -0.0256777    0.00140712   -0.234686    -0.120454     -0.0422625    0.0193871    -0.0387026    0.0508121  -0.116623     0.0207376     0.124166    -0.0649618   -0.14608     -0.0401978    0.0810918   -0.148476     -0.0493928     0.130678     0.0531146
  0.125618     0.0199774   -0.0213859  -0.117444    -0.077001    -0.0277735   -0.012698    -0.0861305   -0.0881364    -0.00639606   0.0256829    -0.102931    -0.0161497    -0.0259901    0.0527988  -0.00684748  -0.165303     -0.165303     0.00499371  -0.0667113   -0.0732333   -0.110754     0.0353624    -0.126835      0.0413588   -0.0670725
  0.0304357    0.0778025   -0.0116003   0.0858718   -0.0484133   -0.139485    -0.00579598  -0.0157843    0.0359829     0.0371372    0.058883     -0.0343172    0.146472     -0.134495     0.116762   -0.0913427    0.0263851     0.12997     -0.110204     0.101822     0.00211448  -0.117808    -0.123296      0.0580374     0.0513896    0.103368
 -0.013209    -0.156026    -0.0101497  -0.10031     -0.0383236   -0.126127     0.0234794    0.0956255    0.0768437    -0.0638557    0.0728098    -0.0542092    0.335503      0.0895809    0.179753    0.106732     0.085155     -0.0752357    0.113941    -0.0343189    0.0246541    0.143827     0.152592     -0.000650431  -0.0741877    0.0498751
  0.148193    -0.196801     0.120029   -0.126092     0.10244     -0.098294     0.0820642    0.082826    -0.0277558     0.0617017   -0.06125      -0.156582    -0.066929     -0.00756796   0.0624211   0.155014     0.153342     -0.0464189   -0.0773892   -0.179418     0.0509219    0.110309     0.0569376     0.0718368    -0.00724288  -0.0450909
 -0.0369829    0.0178612   -0.0729865  -0.0272384    0.067663    -0.0121258   -0.0799829   -0.00830234  -0.0448734     0.0113344   -0.0699682    -0.0783775   -0.00301807    0.0129302    0.0515785  -0.133663     0.149538     -0.00105748  -0.0264876    0.0341053    0.042572    -0.00824548  -0.0398134    -0.0247079     0.0431081   -0.00688817
 -0.038197    -0.0348618   -0.0995797  -0.0198955    0.0236541    0.0914638   -0.0324122   -0.100711    -0.042453      0.015249     0.10624       0.0116769   -0.0147472    -0.0807578   -0.0148671   0.027119     0.00816324    0.0395528   -0.0205531   -0.0113184   -0.00366867  -0.0452207    0.000839597   0.0384221     0.0722458   -0.0631671
 -0.0946131   -0.00120851  -0.0594454  -0.057848     0.0213479    0.0532975    0.0710379   -0.147632    -0.0106818     0.125441    -0.0146904     0.181544    -0.0201016    -0.0353038    0.0127428   0.0177208   -0.0920504     0.0166439    0.172879     0.0412891    0.122285    -0.0212189    0.171464      0.0547742    -0.286168    -0.00178574
  0.0700485    0.0630733    0.195985   -0.0815869    0.0250379    0.109931     0.0986575   -0.014676    -0.199884      0.160959    -0.056431     -0.137374    -0.0163494    -0.131607    -0.0901767   0.0869142   -0.239591     -0.096177     0.042982     0.108709    -0.0586731    0.0687782    0.132203      0.0878914     0.177182     0.0151047
  0.487477     0.0175964    0.531659   -0.174063    -0.0548083   -0.142148    -0.185193    -0.0178598    0.106145     -0.330793    -0.000985069  -0.0929277   -0.158916     -0.338078     0.0278819  -0.0228752   -0.0284112    -0.176957    -0.116423    -0.713789    -0.00886431  -0.184917    -0.425246      0.0947689    -0.0584207   -0.0527454
  0.619096     0.156112     0.220117    0.219626    -0.105567    -0.10468      0.201432     0.0623845    0.0150943     0.336387    -0.00998382   -0.0246581    0.0964591     0.0301758    0.172118    0.144282     0.0719375     0.0786909    0.00662238   0.723431     0.0425113   -0.104488    -0.0880464     0.0166692    -0.592136     0.14741
 -0.0676149    0.0157903    0.103178    0.00822977   0.0598658   -0.101868     0.157682     0.0309859   -0.0171079    -0.152264    -0.0239918    -0.0349345   -0.0500225    -0.088568    -0.261105    0.0712021    0.120211      0.0162686   -0.0116919   -0.568222    -0.00679465  -0.278201    -0.125762      0.286485      0.0694333    0.0187231
 -0.157602    -0.0718915   -0.0282079   0.0867402    0.12039     -0.109834     0.181686     0.0212008    0.00398253   -0.0770405   -0.0227724    -0.0598442    0.129987     -0.20884     -0.23693     0.0543052   -0.0809753     0.00856456   0.0819       0.597446     0.0279344   -0.240798     0.000903134   0.183627     -0.0702651    0.00855242
 -0.404965    -0.146876     0.166044    0.554792     0.135015    -0.175117    -0.0437206    0.0346929    0.042726      0.247155    -0.0375462     0.00918996   0.0434014     0.044608     0.0059946   0.171118     0.518489      0.0458324   -0.0897731    0.151687    -0.1691       0.0768399   -1.24655      -0.0477896    -0.160357    -0.0812445
  0.188841    -0.13193      0.318439   -0.00975303  -0.0190896   -0.176558    -0.00330188   0.317272     0.335626      0.420405     0.0592163     0.00957607   0.063131      0.154401     0.138666    0.154506     0.019572      0.0561745   -0.253042    -0.148021    -0.151898     0.0337363    0.575435     -0.0289825    -0.125124     0.0390825
  0.108512    -0.162877    -0.0296298  -0.392137    -0.0207705   -0.186394    -0.0392145    0.120179     0.162555     -0.00324779  -0.119132     -0.0267341    0.0821064    -0.278004     0.0940322   0.176783    -0.0562112     0.0446522   -0.047147    -0.1809       0.00458879  -0.0262369   -0.50709      -0.0447595    -0.0180693   -0.0130719
  0.212817    -0.153831     0.0409478   0.606416    -0.055437    -0.176791    -0.0814429   -0.206187     0.0126781    -0.0747817   -0.119375     -0.00875526  -0.000408683   0.171892     0.023051    0.17327      0.0198664     0.0382422    0.0612179    0.166845    -0.112329     0.0621427    1.45862      -0.0569545     0.036203    -0.160666[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.127440
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.105931
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     12
│     16
│     17
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.110597
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.117035
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.115892
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.100368
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     18
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.127264
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.105602
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     12
│     16
│     17
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.110561
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.117027
┌ Info: EM with 100000 data points 10 iterations avll -1.117027
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.327249e+05
      1       7.294804e+05      -2.032445e+05 |       32
      2       6.919490e+05      -3.753142e+04 |       32
      3       6.728477e+05      -1.910133e+04 |       32
      4       6.628214e+05      -1.002631e+04 |       32
      5       6.584369e+05      -4.384517e+03 |       32
      6       6.555595e+05      -2.877357e+03 |       32
      7       6.539200e+05      -1.639478e+03 |       32
      8       6.529643e+05      -9.557757e+02 |       32
      9       6.522280e+05      -7.362299e+02 |       32
     10       6.516087e+05      -6.192825e+02 |       32
     11       6.510565e+05      -5.522183e+02 |       32
     12       6.505464e+05      -5.100863e+02 |       32
     13       6.499849e+05      -5.615736e+02 |       32
     14       6.493314e+05      -6.534376e+02 |       32
     15       6.485114e+05      -8.200130e+02 |       32
     16       6.476853e+05      -8.260937e+02 |       32
     17       6.470928e+05      -5.925479e+02 |       32
     18       6.465938e+05      -4.989920e+02 |       32
     19       6.460298e+05      -5.640052e+02 |       32
     20       6.452008e+05      -8.290159e+02 |       32
     21       6.441859e+05      -1.014875e+03 |       32
     22       6.434474e+05      -7.384347e+02 |       32
     23       6.429393e+05      -5.081940e+02 |       32
     24       6.423256e+05      -6.136631e+02 |       32
     25       6.417795e+05      -5.461005e+02 |       32
     26       6.414852e+05      -2.942436e+02 |       32
     27       6.413949e+05      -9.038479e+01 |       31
     28       6.413625e+05      -3.233983e+01 |       31
     29       6.413482e+05      -1.436623e+01 |       30
     30       6.413416e+05      -6.569919e+00 |       29
     31       6.413352e+05      -6.343322e+00 |       30
     32       6.413292e+05      -6.087037e+00 |       27
     33       6.413247e+05      -4.427000e+00 |       26
     34       6.413210e+05      -3.731636e+00 |       24
     35       6.413176e+05      -3.382029e+00 |       23
     36       6.413156e+05      -2.000490e+00 |       19
     37       6.413137e+05      -1.945789e+00 |       20
     38       6.413116e+05      -2.078851e+00 |       18
     39       6.413103e+05      -1.260002e+00 |       21
     40       6.413094e+05      -8.972557e-01 |       15
     41       6.413087e+05      -7.353495e-01 |       12
     42       6.413080e+05      -7.189309e-01 |       12
     43       6.413071e+05      -8.708492e-01 |       12
     44       6.413062e+05      -8.959257e-01 |       13
     45       6.413051e+05      -1.068068e+00 |       15
     46       6.413038e+05      -1.365852e+00 |       22
     47       6.413019e+05      -1.863810e+00 |       17
     48       6.413001e+05      -1.763515e+00 |       18
     49       6.412984e+05      -1.761555e+00 |       23
     50       6.412968e+05      -1.585827e+00 |       17
K-means terminated without convergence after 50 iterations (objv = 641296.7994580833)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.364044
[ Info: iteration 2, average log likelihood -1.334655
[ Info: iteration 3, average log likelihood -1.300236
[ Info: iteration 4, average log likelihood -1.259384
[ Info: iteration 5, average log likelihood -1.216777
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.164788
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.154938
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.108309
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│      9
│     10
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.057857
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     12
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.099464
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.132277
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.108756
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.074255
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│      9
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.070024
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.126134
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.112143
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     12
│     14
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.088728
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.102021
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     18
│     19
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.080910
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.101218
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.113809
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.093847
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     10
│     19
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.075720
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     12
│     14
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.100341
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.128413
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.098744
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     19
│     25
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.074951
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     12
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.087322
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     14
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.102773
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.096253
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│     19
│     21
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.070825
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     12
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.111812
[ Info: iteration 33, average log likelihood -1.121975
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     14
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.059441
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     10
│     12
│     19
│     21
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.065311
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      5
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.134005
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.133587
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.090893
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      7
│      9
│     12
│      ⋮
│     21
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.033959
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.148948
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.135845
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.100274
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│     12
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.054328
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     14
│     18
│     21
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.091394
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.133846
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.106932
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│     12
│     19
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.064674
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.111432
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     14
│     18
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.089499
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      9
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.104741
┌ Info: EM with 100000 data points 50 iterations avll -1.104741
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.183894    -0.190812      0.0428479   -0.0504899   -0.00620685   0.0489125   -0.0497008   -0.0374044   -0.0162143    0.00838303   0.129411    -0.228218     0.0657379    0.0149414    0.101312     0.0427509   -0.0310693    0.0154287    0.00458918   -0.0860628   0.0672861    0.0153428    0.00184239  -0.0374631     0.107347    -0.107901
  0.15029      0.206684      0.0139379   -0.0386994   -0.0490334   -0.023641    -0.130435    -0.0910776   -0.017198    -0.0689705    0.298925     0.00473431  -0.115812     0.11843      0.00175849   0.121409     0.143626     0.170005    -0.00509792   -0.104171   -0.193731    -0.130348    -0.118996    -0.0412053     0.383597    -0.0367474
 -0.042106    -0.0714425    -0.0229439    0.063769     0.0656954    0.0523646    0.0436787   -0.146624     0.0527117    0.10736      0.107633     0.00653772  -0.00295361  -0.0761705    0.0302364    0.0805456   -0.0451983    0.0922737    0.118616      0.0420955   0.122121    -0.191704    -0.00939233   0.0268976     0.0909167    0.0323568
 -0.0229805   -0.00214278   -0.170621    -0.0709655    0.00194767  -0.155019     0.150955     0.109585     0.182576    -0.0635435    0.0658145   -0.0251149    0.0216907   -0.125268    -0.119648    -0.103686    -0.0286026    0.251273    -0.318497     -0.0926162  -0.0454802    0.279279    -0.0176199   -0.0800808    -0.0650124   -0.134971
 -0.0502454    0.0769071    -0.134378     0.0451435    0.0784998   -0.102518    -0.185332    -0.0730628    0.077964     0.107474     0.117294    -0.00305012  -0.10151      0.116757     0.0361638    0.04212      0.0453537   -0.0733222    0.0176226    -0.0454165   0.0635225   -0.0937282   -0.151349    -0.042493      0.197574     0.0980912
 -0.0588121   -0.171813     -0.0239432    0.00358133   0.119688     0.0859424   -0.0505544    0.0613707    0.183953     0.168984     0.118908     0.0140029    0.0715941   -0.0210788    0.13167     -0.00446475  -0.00787714  -0.0484208    0.0233667     0.0253312   0.0484333   -0.168586     0.0279703    0.0263105    -0.0800428   -0.0498431
 -0.0410857    0.000453513   0.166822     0.253173    -0.0722862    0.113057    -0.0221699    0.0802787    0.030837    -0.111735     0.00541865  -0.108939    -0.0154818   -0.198702     0.135882     0.126305     0.148805    -0.14544     -0.0723342    -0.0845224  -0.0757569   -0.0346979    0.170375    -0.0421677     0.0990033   -0.115302
  0.0897786    0.0417729     0.121018     0.16026      0.0452692    0.0843198    0.0640223    0.00423373  -0.0140316    0.138203    -0.155509     0.185953    -0.0399124    0.0601099   -0.123617    -0.130358    -0.00667341   0.0047233   -0.0644856    -0.0721128  -0.0108992    0.0707617    0.053803     0.0497875     0.22588     -0.0250077
 -0.0632064   -0.113613     -0.115529    -0.0200704    0.0600453    0.00360238   0.0303317    0.0949367   -0.0411116    0.0373658    0.0263633   -0.00789873  -0.108807     0.00777741   0.0674124    0.0968983    0.0302635   -0.128063     0.00446656    0.0331908   0.0603371   -0.237322     0.0833189    0.192101     -0.0966832    0.121046
 -0.241267     0.0371793     0.0900693   -0.0386731    0.0915494   -0.0524596   -0.10354      0.00946143   0.230716     0.172444    -0.0623983    0.105407    -0.0563394   -0.23163      0.110522     0.133755     0.122709     0.0216314   -0.13566       0.133937    0.00701885   0.0638074    0.0646596   -0.0110118    -0.0342188   -0.169644
  0.0881316   -0.0407507    -0.0979848    0.00838278  -0.105388     0.0274506   -0.0539613   -0.0827494   -0.224844    -0.291917     0.144559    -0.00528589   0.00261469  -0.136294     0.10495      0.0469909    0.0764364   -0.0386388   -0.0722895    -0.166269   -0.0600185   -0.0848768    0.127216     0.0129039     0.0766618    0.18595
 -0.0942103    0.109994      0.159423     0.0290562    0.113912    -0.0545867   -0.0296673    0.105271    -0.0137398   -0.0299547   -0.0449722    0.0137551    0.00799738   0.111168     0.230971     0.0576041    0.0099065   -0.0400157   -0.0403983    -0.0665893   0.0504725    0.0362664    0.140134     0.124163      0.0203091   -0.00628597
 -0.0137089   -0.158022     -0.00905384  -0.102142    -0.0435961   -0.128878     0.024472     0.0962558    0.076137    -0.0653209    0.0729096   -0.0529449    0.340681     0.0891862    0.180337     0.105507     0.0847062   -0.07557      0.115134     -0.0348589   0.0223522    0.148908     0.154924    -0.000655771  -0.0768009    0.0478463
 -0.0803223   -0.041678     -0.119724    -0.0280966    0.0147617    0.0231263    0.0913581   -0.105893    -0.0653129    0.0958462   -0.0139308    0.095921    -0.0371195   -0.057078     0.00760503   0.00491249  -0.0179733    0.0148745    0.21885       0.0406951   0.121178    -0.0170574    0.107244     0.043902     -0.253978    -0.0101712
 -0.0560383   -0.0196374     0.0673438    0.0442461    0.076687    -0.107168     0.156578     0.026343    -0.00155204  -0.108692    -0.0219211   -0.0481257    0.0302463   -0.142415    -0.223525     0.0627136    0.0280755    0.00798555   0.0254701    -0.015278    0.0101777   -0.250448    -0.0827968    0.224774     -0.0256547    0.0166615
 -0.0922755   -0.131372     -0.0492324    0.0434498   -0.0304739   -0.0567891    0.0845969   -0.0328803   -0.0125079   -0.0929995   -0.131017    -0.0120753   -0.0539741    0.00805439   0.060805    -0.0594952    0.0358128    0.00227398  -0.0655986     0.0128776  -0.0144028    0.0181867    0.0486805    0.0447953    -0.0677406    0.05367
  0.144795    -0.198443      0.121718    -0.127278     0.106442    -0.103196     0.0832579    0.0889257   -0.0275104    0.0550145   -0.0599484   -0.151479    -0.0668632    0.00290719   0.0598572    0.166377     0.160393    -0.0433194   -0.0833534    -0.189904    0.0413306    0.117375     0.0588848    0.0721773    -0.0147073   -0.0431109
  0.0304104   -0.199904     -0.173208    -0.0188716    0.0592769   -0.00832953  -0.0164806   -0.0605939   -0.218124    -0.0645119   -0.226772    -0.00414059  -0.0408753   -0.0222829    0.00282365  -0.0869894    0.172402     0.0310399    0.0357431    -0.0607172   0.0770865   -0.0764983   -0.043567     0.0478811     0.0809461    0.00978011
 -0.12622      0.0637654     0.0687283    0.0407263   -0.0234598    0.0619907   -0.0308886   -0.0226815   -0.00445385  -0.212936    -0.11269     -0.0443935    0.0255468   -0.0202741    0.0410407   -0.113538     0.0255712    0.120292    -0.0664144    -0.143205   -0.0384746    0.06804     -0.149773    -0.0385089     0.128542     0.0412512
  0.0238752   -0.0424544    -0.0656677    0.0720817    0.146478     0.24357     -0.0740258   -0.0630313    0.110644    -0.0487766   -0.112125     0.106891    -0.231397    -0.0429777    0.219701    -0.0897558    0.121116    -0.11563      0.000917976  -0.0307421   0.0956327   -0.103247     0.00485196  -0.0372362    -0.0281523    0.119099
 -0.195519     0.062531     -0.0826706    0.121485     0.0448992   -0.0637161   -0.00741155  -0.0204805   -0.0461731   -0.0176409   -0.132695     0.0752312   -0.0931553    0.189968     0.0300072   -0.150611     0.225207    -0.126758     0.0737567    -0.249153   -0.0449239   -0.00716071  -0.0830494    0.0245318    -0.239646     0.0771474
 -0.0175123   -0.188758     -0.0219832    0.0796616    0.0235732   -0.041689     0.00248525   0.109632     0.00130924  -0.0544678    0.186312    -0.0208666   -0.117087    -0.12116     -0.151842     0.0192813    0.0459155    0.284671    -0.0317328    -0.227694   -0.0300149   -0.0988891   -0.16035     -0.0707965     0.131124    -0.0460431
  0.0445598    0.064787     -0.168828    -0.108423     0.00780085   0.0984133   -0.112701    -0.177698    -0.134977     0.00882856   0.0148745   -0.0119024    0.0600853   -0.203369    -0.0977779   -0.041344     0.019912     0.0441933   -0.0787706    -0.0143933  -0.0217507    0.0826561    0.0575458    0.115185      0.00217524  -0.128453
  0.0318399    0.0868174    -0.00627495   0.0945198   -0.0512687   -0.138016    -0.00801686  -0.0175194    0.036063     0.0315618    0.0597361   -0.0346872    0.159581    -0.138696     0.124436    -0.105996     0.0259491    0.13386     -0.127069      0.100862   -0.0054592   -0.111333    -0.126859     0.0577361     0.052569     0.103385
 -0.17046      0.0546142     0.0769495   -0.0399227    0.107735    -0.00549103   0.00993436  -0.0386006    0.0665186    0.131985     0.00797368   0.0696282   -0.0411622   -0.112229     0.0909456   -0.0193445   -0.0506935   -2.52234e-6  -0.101066      0.0117055  -0.0800941   -0.0548653    0.156572    -0.00140102   -0.0672689   -0.140647
  0.0759941    0.0670841     0.210855    -0.0900126    0.0233082    0.108334     0.111353    -0.0110099   -0.207956     0.161718    -0.073066    -0.13491     -0.0143374   -0.149638    -0.0933495    0.0838836   -0.241087    -0.100069     0.0456128     0.119923   -0.0645623    0.0751071    0.147873     0.0901121     0.155706     0.00907269
  0.0320624   -0.149245      0.118063     0.148285     0.0083083   -0.179114    -0.0406065    0.0761516    0.144433     0.146038    -0.0553148   -0.00546471   0.0502723    0.00724377   0.0686292    0.16914      0.113807     0.0463723   -0.0842402    -0.0179528  -0.101679     0.0326837    0.0335772   -0.0442283    -0.0654709   -0.0485978
 -0.0236011   -0.0189082    -0.0422249   -0.0493158   -0.238298     0.127595    -0.0260527   -0.0791909   -0.0329162    0.0830095    0.177049     0.0319189   -0.101731    -0.0281569    0.160187    -0.0195397   -0.0283252    0.0219649    0.0458184    -0.0116254   0.0392539    0.118038    -0.0079107   -0.0929149    -0.00732703   0.0457731
  0.0917116    0.0136119     0.00762709  -0.104537    -0.0696393    0.00564792  -0.0202205   -0.073463    -0.0890681    0.0213401   -0.00887301  -0.0349268   -0.0577545   -0.0334208    0.0638122   -0.0453003   -0.137492    -0.154427    -0.0138102    -0.066487   -0.0642058   -0.0810617    0.0370796   -0.109102      0.0103659   -0.103595
  0.00123508   0.0641624     0.0348597   -0.0917491   -0.046225     0.177492     0.0385806    0.0942926    0.0804137   -0.0723597    0.10292     -0.125712     0.104559    -0.00765473   0.0360894   -0.118544    -0.0797289    0.0218059   -0.0178653    -0.0403319  -0.0465755    0.0756784    0.110955    -0.0762888    -0.0833769   -0.10418
 -0.120713     0.0411767    -0.00943009  -0.0467458    0.0872297    0.0824732   -0.0641802    0.0170295    0.0225964   -0.00206763   0.0664331   -0.0223142   -0.0176177    0.00892171   0.0850081   -0.0714329    0.0915191    0.0142163   -0.1007        0.0656171  -0.0411656    0.0210436    0.0141125   -0.0632319     0.0204495   -0.035938
 -0.111723    -0.00953037   -0.11587      0.0326061   -0.324778    -0.0909118    0.0285586   -0.0370469    0.00363519   0.0758769    0.103299    -0.0246845    0.14019      0.212508    -0.0221598    0.00456153  -0.0172843   -0.141049    -0.0488532    -0.0204787  -0.00479611  -0.105546    -0.114965     0.0312362     0.186573    -0.168053[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     12
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.095618
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     10
│     12
│     19
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.057289
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      7
│     12
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.033420
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     12
│     14
│     19
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.057265
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     12
│     19
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.053127
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      7
│     10
│     12
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.031938
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│     12
│     14
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.062152
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     12
│     19
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.044978
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      7
│      9
│     12
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.033237
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│     10
│     12
│     14
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.063219
┌ Info: EM with 100000 data points 10 iterations avll -1.063219
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0136852    0.162765    -0.118555    -0.0874337   -0.0759701   -0.0486765    -0.092272    -0.0106137   -0.0509661     0.155648    -0.16261      0.0679132     0.0336845   -0.0885873   -0.106369   -0.0716739    0.157925    -0.0155972   -0.195589     0.152311     -0.200182     0.016097    -0.069474    -0.0237922    0.0463027     0.0469104
 -0.119427     0.022032    -0.0481987   -0.0212902   -0.00355049  -0.0707877     0.163322     0.0138392    0.0790026     0.0266455   -0.0144583   -0.0204374    -0.226663    -0.136227     0.0102891  -0.0601434    0.122508    -0.0882619    0.155553     0.00774238    0.0489557    0.0400919    0.0896433   -0.0488185   -0.00103348    0.110466
 -0.0492819    0.0575782    0.0975704   -0.165538     0.0144757   -0.0168423     0.0784475   -0.217965     0.126147     -0.0646004   -0.0758056    0.0277111    -0.00787282   0.0238591    0.125985    0.052424     0.0773097    0.00400011  -0.08631     -0.0223914     0.0272145    0.219854    -0.0930841   -0.0778349   -0.0294684    -0.0128067
  0.00182638   0.00328672  -0.147564    -0.250462     0.0484711    0.234266     -0.00986148  -0.018239     0.101886      0.0112052   -0.0684611    0.0331607     0.055114     0.00236759   0.0185755  -0.191961     0.00821813   0.0343201    0.0535347   -0.0253839     0.0247184    0.224977     0.104972     0.0713496   -0.109141      0.00369012
 -0.307753    -0.0636672    0.0697094    0.100975    -0.092878     0.0391462    -0.125329     0.00601421   0.050836     -0.0164977    0.038456    -0.079331      0.0968687    0.20869      0.0291656  -0.0567614   -0.0645003    0.100114     0.0650314   -0.0126319     0.0288027   -0.0875519    0.193534     0.0100085    0.195173     -0.0685366
  0.0751907    0.0098131   -0.106221    -0.128019    -0.163219    -0.0381262    -0.116129    -0.184469     0.032554      0.187789     0.0511766   -0.0276612    -0.226929    -0.16828      0.14104     0.152945     0.0827736    0.0515106   -0.20111      0.167534     -0.0707011    0.0581863    0.118439     0.115784     0.0781343    -0.143458
 -0.117161    -0.0341258   -0.169001    -0.228094    -0.228919    -0.0737867     0.0125165    0.107313    -0.227552     -0.0399594    0.133039     0.0739637    -0.0755784   -0.0696646    0.0655561   0.0722967    0.214058     0.0715245    0.0657196   -0.023768     -0.114474     0.0133143   -0.0121958   -0.132339    -0.00370143   -0.216936
  0.0578356    0.028022    -0.029329    -0.0102074    0.109928     0.028787     -0.026569    -0.239686     0.065953     -0.0133419   -0.25348     -0.0629476    -0.0148569   -0.058398    -0.026537    0.0810729   -0.00630199  -0.0478362   -0.164397    -0.0328995     0.00604063   0.0566267   -0.0625046    0.041125     0.0994675     0.116273
 -0.198684     0.0122315    0.164369     0.230958    -0.0826702    0.115864     -0.0205491   -0.00444872  -0.0328573    -0.0588548    0.130308     0.0509393     0.0177191   -0.00904183  -0.0598135  -0.0462707   -0.0531474   -0.0422064   -0.178399    -0.141267      0.115155    -0.0301309   -0.0456657    0.0101232    0.0285763    -0.0564595
  0.11405      0.0107791    0.166158     0.00406223  -0.0368157    0.203092      0.0958641    0.0498099    0.0117844    -0.0742908    0.108529     0.0502629     0.00627277  -0.0328916   -0.0376422   0.128309    -0.0927109    0.00350442  -0.0202687   -0.248262      0.0161335   -0.201081    -0.0380053   -0.182855    -0.0732105    -0.033521
  0.078756     0.0075188    0.043354    -0.132056     0.1218       0.0775986    -0.0654599    0.131569    -0.242046     -0.106243     0.194834    -0.0400363    -0.00822662   0.126932    -0.127919   -0.110465     0.0341221    0.0129124    0.138479    -0.0623502    -0.0294959    0.0447278    0.135346     0.0263523    0.025657     -0.00326222
  0.0716086   -0.0813894   -0.0249137    0.0356883    0.0218269    0.138837      0.12335      0.0937796   -0.236182      0.0445653    0.0926925   -0.00349439    0.0884958   -0.0488456    0.0129      0.00627215   0.0132723    0.0819887   -0.0177193   -0.118685     -0.00701061  -0.12876      0.148032     0.136829     0.0668626     0.0463856
 -0.113906    -0.192435    -0.0713635   -0.0365458   -0.0882504   -0.0769513     0.108828     0.0776258   -0.126154      0.0924849   -0.0323068    0.00054541    0.00699815  -0.046775    -0.0400184   0.00886343   0.132545    -0.0962012    0.176427    -0.0217451    -0.0731597   -0.0640257    0.158386    -0.224987     0.0202303    -0.022866
  0.180712    -0.234057    -0.0690477    0.123238    -0.0183048   -0.0156085     0.0503846    0.0514077    0.15276      -0.105517    -0.026648     0.229884      0.058096     0.00961566  -0.0558123   0.164521    -0.0377421   -0.229501     0.0620258   -0.0969381     0.0509385   -0.0319097    0.0175922   -0.109937     0.0704462     0.221893
  0.0743965    0.144448    -0.204421    -0.0755315    0.00161193  -0.0612788    -0.0549805    0.109477    -0.00142876   -0.104036     0.283162    -0.0754382     0.0758272   -0.226455    -0.0565764   0.0177282   -0.0060964    0.0682359    0.0795664    0.0346668     0.136325    -0.0466791    0.0294537   -0.0653256   -0.0108947    -0.188021
 -0.0516862   -0.106424     0.0676195    0.202169     0.210077    -0.000789059   0.0861263    0.0978247    0.0726755    -0.00441919   0.0851885    0.000221059   0.0747242   -0.0437021   -0.0856987   0.0150078   -0.0540856    0.121303     0.0200597   -0.174128     -0.120279     0.254883    -0.01391     -0.0777768   -0.0205814     0.105473
 -0.0655126   -0.245508    -0.0776647   -0.00543538   0.179631     0.00698692   -0.151492    -0.180406    -0.205106      0.0286871    0.13843      0.0221709    -0.159178     0.0456994   -0.0843788   0.241921    -0.267096     0.0516435   -0.0852478    0.119493      0.0969308    0.0689428    0.0606986    0.0104428    0.0238437     0.0385216
  0.101869    -0.0853082   -0.0146162    0.0305711   -0.0822989   -0.0525343    -0.0598047    0.0533979   -0.0665604    -0.142364     0.125835     0.0691597     0.050284    -0.0772808    0.0505039   0.00725891  -0.102818    -0.0878421    0.0905414    0.0271221    -0.0642206   -0.0569091    0.0160356    0.116785    -0.192985      0.0175911
  0.168891    -0.15094      0.0118974   -0.102529     0.0373511   -0.0229826    -0.111716     0.0914719    0.020971      0.10138     -0.0843945   -0.095276      0.259853    -0.0789878   -0.164366    0.0562198    0.115995    -0.00999653   0.0481723    0.000145704   0.0563669   -0.0668605   -0.0854558    0.0459041    0.0945812     0.0180705
 -0.0239757   -0.228567    -0.0440032   -0.152035     0.0647386   -0.151848     -0.0565077    0.0321155    0.000776663   0.146293    -0.23027     -0.103504     -0.0351657    0.0230453   -0.0127561   0.260684     0.0685301   -0.0611692    0.0748192    0.129646     -0.103399    -0.0468156    0.095413    -0.0666605    0.0606747     0.114002
  0.0798776    0.0256573   -0.202703    -0.101657    -0.332403     0.186196     -0.179682     0.0135602   -0.0301721    -0.100362     0.107469    -0.0635636    -0.0710678   -0.00636916  -0.0868994   0.145938     0.0812326    0.0968307   -0.0166381   -0.125637      0.0195266    0.244117    -0.170926    -0.0393344   -0.000327386  -0.00284792
 -0.0811038    0.0279752   -0.180184     0.0174472   -0.0231439    0.134597      0.180472     0.154973    -0.052936     -0.0705347    0.0262452    0.0781129    -0.0782529   -0.0229984    0.0144364  -0.132066    -0.043486    -0.133483    -0.0831171    0.0684661    -0.152431     0.202396     0.147862    -0.00513565  -0.151048     -0.117909
  0.00515764  -0.145969    -0.0510907   -0.101816     0.0911862   -0.225518     -0.13784      0.163581    -0.0715033    -0.164317    -0.141106    -0.115725      0.0203487    0.0516461   -0.085905    0.00940745  -0.0731149   -0.0905806   -0.175877    -0.0833932     0.0492812    0.116596     0.0259108    0.154108     0.135204      0.0498666
 -0.0440019   -0.216939    -0.011118    -0.167815    -0.0857102    0.0687902    -0.104566     0.0818701   -0.152355      0.0952177   -0.0531862    0.0361776    -0.0122889    0.0333575    0.173494   -0.0221609   -0.0818589    0.1403       0.00466138   0.0121643    -0.09839     -0.0339284    0.142911     0.0536254    0.0365257     0.192477
  0.0117809    0.164121    -0.0660747   -0.0537213    0.0448765    0.110534     -0.104016     0.121473    -0.19788       0.129965     0.0931801    0.0758705    -0.028405     0.170706     0.0128211   0.105095     0.0871329   -0.0799172   -0.0492571    0.0524324     0.168107    -0.0137182   -0.00265871  -0.0547346    0.0139028     0.051656
 -0.0828127    0.103162    -0.197304    -0.0272465    0.0420293   -0.00914193   -0.0579264   -0.0671584   -0.0720886    -0.0949985   -0.0980932    0.120472      0.0396395    0.0313269   -0.166397   -0.0293969    0.0673024    0.0557937   -0.13611     -0.0267286    -0.089504    -0.0659504   -0.0810998   -0.0634924    0.0450197     0.0628758
 -0.00504003   0.0959104   -0.0323828   -0.0247242   -0.0858536    0.0184566     0.152712    -0.0232472   -0.0696006     0.112288     0.00973106   0.0732115    -0.0167943   -0.0890016   -0.142802   -0.00960612  -0.105839     0.0215041    0.123212     0.0110517     0.0199249    0.00747024  -0.0453499    0.0828459   -0.0677379    -0.0364398
  0.0134242   -0.00284535  -0.0328663   -0.080139    -0.12451     -0.0203229    -0.281983     0.0365046   -0.0747217    -0.0876666   -0.0341154    0.0544911    -0.109226    -0.0372651   -0.0165458  -0.173181     0.00568559   0.226648    -0.121218     0.053459     -0.0336683   -0.0801529    0.122217     0.107875    -0.0217446    -0.0288632
  0.142554     0.10249     -0.0601942   -0.0266205   -0.0981787   -0.032799      0.209111     0.154234     0.0178701     0.0967172    0.155843    -0.0378578     0.0111368   -0.0934906    0.0209907  -0.0361058   -0.0193287   -0.0346379   -0.0566149   -0.0749144     0.0908703   -0.0871113   -0.0349278    0.104456     0.0764096    -0.130051
  0.0486577    0.068438     0.0559526    0.012768     0.0940041   -0.0172076     0.0843352   -0.0584474   -0.185516     -0.028181     0.0746883    0.135016     -0.149616    -0.0420012   -0.0229565   0.095888    -0.00423802   0.202441    -0.0664699    0.113325     -0.0290056   -0.178812    -0.108919    -0.0542397    0.114854     -0.01402
 -0.00929666  -0.0174354   -0.00440974  -0.100994    -0.152969     0.01122      -0.106022    -0.111577    -0.203153      0.0123696    0.0862128    0.0960362    -0.0579709   -0.0297487   -0.0518754   0.0904413    0.0628709    0.0646209    0.00235624  -0.0387084     0.122057    -0.022938    -0.097138    -0.116385     0.000473923   0.0689439
 -0.137786    -0.0612095   -0.0876932   -0.0470453   -0.111372     0.160954     -0.148253    -0.0200638   -0.0477866    -0.0193951   -0.0218364    0.0951989     0.129609    -0.188129     0.0123326   0.0235226   -0.14178      0.169976    -0.0806644    0.0058322     0.046435     0.0375045    0.0148695    0.0263156   -0.0963717     0.0234976kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4219581998920459
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421977
[ Info: iteration 2, average log likelihood -1.421920
[ Info: iteration 3, average log likelihood -1.421885
[ Info: iteration 4, average log likelihood -1.421851
[ Info: iteration 5, average log likelihood -1.421813
[ Info: iteration 6, average log likelihood -1.421768
[ Info: iteration 7, average log likelihood -1.421706
[ Info: iteration 8, average log likelihood -1.421594
[ Info: iteration 9, average log likelihood -1.421356
[ Info: iteration 10, average log likelihood -1.420837
[ Info: iteration 11, average log likelihood -1.419887
[ Info: iteration 12, average log likelihood -1.418643
[ Info: iteration 13, average log likelihood -1.417616
[ Info: iteration 14, average log likelihood -1.417077
[ Info: iteration 15, average log likelihood -1.416867
[ Info: iteration 16, average log likelihood -1.416793
[ Info: iteration 17, average log likelihood -1.416767
[ Info: iteration 18, average log likelihood -1.416757
[ Info: iteration 19, average log likelihood -1.416754
[ Info: iteration 20, average log likelihood -1.416752
[ Info: iteration 21, average log likelihood -1.416752
[ Info: iteration 22, average log likelihood -1.416751
[ Info: iteration 23, average log likelihood -1.416751
[ Info: iteration 24, average log likelihood -1.416751
[ Info: iteration 25, average log likelihood -1.416751
[ Info: iteration 26, average log likelihood -1.416751
[ Info: iteration 27, average log likelihood -1.416751
[ Info: iteration 28, average log likelihood -1.416751
[ Info: iteration 29, average log likelihood -1.416751
[ Info: iteration 30, average log likelihood -1.416750
[ Info: iteration 31, average log likelihood -1.416750
[ Info: iteration 32, average log likelihood -1.416750
[ Info: iteration 33, average log likelihood -1.416750
[ Info: iteration 34, average log likelihood -1.416750
[ Info: iteration 35, average log likelihood -1.416750
[ Info: iteration 36, average log likelihood -1.416750
[ Info: iteration 37, average log likelihood -1.416750
[ Info: iteration 38, average log likelihood -1.416750
[ Info: iteration 39, average log likelihood -1.416750
[ Info: iteration 40, average log likelihood -1.416750
[ Info: iteration 41, average log likelihood -1.416750
[ Info: iteration 42, average log likelihood -1.416750
[ Info: iteration 43, average log likelihood -1.416750
[ Info: iteration 44, average log likelihood -1.416750
[ Info: iteration 45, average log likelihood -1.416750
[ Info: iteration 46, average log likelihood -1.416750
[ Info: iteration 47, average log likelihood -1.416750
[ Info: iteration 48, average log likelihood -1.416750
[ Info: iteration 49, average log likelihood -1.416750
[ Info: iteration 50, average log likelihood -1.416750
┌ Info: EM with 100000 data points 50 iterations avll -1.416750
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4219766644828782
│     -1.4219200976847604
│      ⋮
└     -1.4167500556259833
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416765
[ Info: iteration 2, average log likelihood -1.416716
[ Info: iteration 3, average log likelihood -1.416680
[ Info: iteration 4, average log likelihood -1.416639
[ Info: iteration 5, average log likelihood -1.416591
[ Info: iteration 6, average log likelihood -1.416532
[ Info: iteration 7, average log likelihood -1.416463
[ Info: iteration 8, average log likelihood -1.416386
[ Info: iteration 9, average log likelihood -1.416306
[ Info: iteration 10, average log likelihood -1.416228
[ Info: iteration 11, average log likelihood -1.416157
[ Info: iteration 12, average log likelihood -1.416095
[ Info: iteration 13, average log likelihood -1.416042
[ Info: iteration 14, average log likelihood -1.415995
[ Info: iteration 15, average log likelihood -1.415951
[ Info: iteration 16, average log likelihood -1.415907
[ Info: iteration 17, average log likelihood -1.415862
[ Info: iteration 18, average log likelihood -1.415815
[ Info: iteration 19, average log likelihood -1.415764
[ Info: iteration 20, average log likelihood -1.415712
[ Info: iteration 21, average log likelihood -1.415659
[ Info: iteration 22, average log likelihood -1.415607
[ Info: iteration 23, average log likelihood -1.415558
[ Info: iteration 24, average log likelihood -1.415515
[ Info: iteration 25, average log likelihood -1.415477
[ Info: iteration 26, average log likelihood -1.415446
[ Info: iteration 27, average log likelihood -1.415419
[ Info: iteration 28, average log likelihood -1.415398
[ Info: iteration 29, average log likelihood -1.415380
[ Info: iteration 30, average log likelihood -1.415366
[ Info: iteration 31, average log likelihood -1.415354
[ Info: iteration 32, average log likelihood -1.415344
[ Info: iteration 33, average log likelihood -1.415335
[ Info: iteration 34, average log likelihood -1.415327
[ Info: iteration 35, average log likelihood -1.415320
[ Info: iteration 36, average log likelihood -1.415314
[ Info: iteration 37, average log likelihood -1.415308
[ Info: iteration 38, average log likelihood -1.415303
[ Info: iteration 39, average log likelihood -1.415298
[ Info: iteration 40, average log likelihood -1.415293
[ Info: iteration 41, average log likelihood -1.415288
[ Info: iteration 42, average log likelihood -1.415284
[ Info: iteration 43, average log likelihood -1.415280
[ Info: iteration 44, average log likelihood -1.415276
[ Info: iteration 45, average log likelihood -1.415273
[ Info: iteration 46, average log likelihood -1.415269
[ Info: iteration 47, average log likelihood -1.415266
[ Info: iteration 48, average log likelihood -1.415263
[ Info: iteration 49, average log likelihood -1.415260
[ Info: iteration 50, average log likelihood -1.415257
┌ Info: EM with 100000 data points 50 iterations avll -1.415257
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4167646697313465
│     -1.4167156662838798
│      ⋮
└     -1.4152571032750865
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415266
[ Info: iteration 2, average log likelihood -1.415206
[ Info: iteration 3, average log likelihood -1.415151
[ Info: iteration 4, average log likelihood -1.415083
[ Info: iteration 5, average log likelihood -1.414995
[ Info: iteration 6, average log likelihood -1.414886
[ Info: iteration 7, average log likelihood -1.414762
[ Info: iteration 8, average log likelihood -1.414635
[ Info: iteration 9, average log likelihood -1.414520
[ Info: iteration 10, average log likelihood -1.414425
[ Info: iteration 11, average log likelihood -1.414350
[ Info: iteration 12, average log likelihood -1.414292
[ Info: iteration 13, average log likelihood -1.414247
[ Info: iteration 14, average log likelihood -1.414210
[ Info: iteration 15, average log likelihood -1.414181
[ Info: iteration 16, average log likelihood -1.414156
[ Info: iteration 17, average log likelihood -1.414134
[ Info: iteration 18, average log likelihood -1.414116
[ Info: iteration 19, average log likelihood -1.414100
[ Info: iteration 20, average log likelihood -1.414086
[ Info: iteration 21, average log likelihood -1.414073
[ Info: iteration 22, average log likelihood -1.414062
[ Info: iteration 23, average log likelihood -1.414052
[ Info: iteration 24, average log likelihood -1.414042
[ Info: iteration 25, average log likelihood -1.414033
[ Info: iteration 26, average log likelihood -1.414025
[ Info: iteration 27, average log likelihood -1.414016
[ Info: iteration 28, average log likelihood -1.414009
[ Info: iteration 29, average log likelihood -1.414001
[ Info: iteration 30, average log likelihood -1.413994
[ Info: iteration 31, average log likelihood -1.413988
[ Info: iteration 32, average log likelihood -1.413981
[ Info: iteration 33, average log likelihood -1.413975
[ Info: iteration 34, average log likelihood -1.413968
[ Info: iteration 35, average log likelihood -1.413962
[ Info: iteration 36, average log likelihood -1.413956
[ Info: iteration 37, average log likelihood -1.413950
[ Info: iteration 38, average log likelihood -1.413944
[ Info: iteration 39, average log likelihood -1.413938
[ Info: iteration 40, average log likelihood -1.413932
[ Info: iteration 41, average log likelihood -1.413926
[ Info: iteration 42, average log likelihood -1.413921
[ Info: iteration 43, average log likelihood -1.413915
[ Info: iteration 44, average log likelihood -1.413909
[ Info: iteration 45, average log likelihood -1.413903
[ Info: iteration 46, average log likelihood -1.413898
[ Info: iteration 47, average log likelihood -1.413892
[ Info: iteration 48, average log likelihood -1.413886
[ Info: iteration 49, average log likelihood -1.413881
[ Info: iteration 50, average log likelihood -1.413875
┌ Info: EM with 100000 data points 50 iterations avll -1.413875
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4152658649548677
│     -1.4152061963305598
│      ⋮
└     -1.4138751139644392
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413880
[ Info: iteration 2, average log likelihood -1.413820
[ Info: iteration 3, average log likelihood -1.413767
[ Info: iteration 4, average log likelihood -1.413708
[ Info: iteration 5, average log likelihood -1.413636
[ Info: iteration 6, average log likelihood -1.413552
[ Info: iteration 7, average log likelihood -1.413454
[ Info: iteration 8, average log likelihood -1.413348
[ Info: iteration 9, average log likelihood -1.413239
[ Info: iteration 10, average log likelihood -1.413134
[ Info: iteration 11, average log likelihood -1.413037
[ Info: iteration 12, average log likelihood -1.412949
[ Info: iteration 13, average log likelihood -1.412872
[ Info: iteration 14, average log likelihood -1.412804
[ Info: iteration 15, average log likelihood -1.412744
[ Info: iteration 16, average log likelihood -1.412693
[ Info: iteration 17, average log likelihood -1.412648
[ Info: iteration 18, average log likelihood -1.412608
[ Info: iteration 19, average log likelihood -1.412574
[ Info: iteration 20, average log likelihood -1.412543
[ Info: iteration 21, average log likelihood -1.412515
[ Info: iteration 22, average log likelihood -1.412489
[ Info: iteration 23, average log likelihood -1.412466
[ Info: iteration 24, average log likelihood -1.412444
[ Info: iteration 25, average log likelihood -1.412424
[ Info: iteration 26, average log likelihood -1.412406
[ Info: iteration 27, average log likelihood -1.412388
[ Info: iteration 28, average log likelihood -1.412371
[ Info: iteration 29, average log likelihood -1.412356
[ Info: iteration 30, average log likelihood -1.412341
[ Info: iteration 31, average log likelihood -1.412326
[ Info: iteration 32, average log likelihood -1.412312
[ Info: iteration 33, average log likelihood -1.412299
[ Info: iteration 34, average log likelihood -1.412286
[ Info: iteration 35, average log likelihood -1.412273
[ Info: iteration 36, average log likelihood -1.412260
[ Info: iteration 37, average log likelihood -1.412247
[ Info: iteration 38, average log likelihood -1.412235
[ Info: iteration 39, average log likelihood -1.412222
[ Info: iteration 40, average log likelihood -1.412210
[ Info: iteration 41, average log likelihood -1.412198
[ Info: iteration 42, average log likelihood -1.412185
[ Info: iteration 43, average log likelihood -1.412173
[ Info: iteration 44, average log likelihood -1.412161
[ Info: iteration 45, average log likelihood -1.412149
[ Info: iteration 46, average log likelihood -1.412136
[ Info: iteration 47, average log likelihood -1.412124
[ Info: iteration 48, average log likelihood -1.412112
[ Info: iteration 49, average log likelihood -1.412100
[ Info: iteration 50, average log likelihood -1.412087
┌ Info: EM with 100000 data points 50 iterations avll -1.412087
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4138803455074527
│     -1.4138201468625653
│      ⋮
└     -1.4120874328860125
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412083
[ Info: iteration 2, average log likelihood -1.412022
[ Info: iteration 3, average log likelihood -1.411964
[ Info: iteration 4, average log likelihood -1.411899
[ Info: iteration 5, average log likelihood -1.411822
[ Info: iteration 6, average log likelihood -1.411728
[ Info: iteration 7, average log likelihood -1.411618
[ Info: iteration 8, average log likelihood -1.411491
[ Info: iteration 9, average log likelihood -1.411351
[ Info: iteration 10, average log likelihood -1.411206
[ Info: iteration 11, average log likelihood -1.411061
[ Info: iteration 12, average log likelihood -1.410922
[ Info: iteration 13, average log likelihood -1.410794
[ Info: iteration 14, average log likelihood -1.410679
[ Info: iteration 15, average log likelihood -1.410578
[ Info: iteration 16, average log likelihood -1.410488
[ Info: iteration 17, average log likelihood -1.410411
[ Info: iteration 18, average log likelihood -1.410343
[ Info: iteration 19, average log likelihood -1.410284
[ Info: iteration 20, average log likelihood -1.410231
[ Info: iteration 21, average log likelihood -1.410184
[ Info: iteration 22, average log likelihood -1.410142
[ Info: iteration 23, average log likelihood -1.410104
[ Info: iteration 24, average log likelihood -1.410069
[ Info: iteration 25, average log likelihood -1.410036
[ Info: iteration 26, average log likelihood -1.410006
[ Info: iteration 27, average log likelihood -1.409977
[ Info: iteration 28, average log likelihood -1.409949
[ Info: iteration 29, average log likelihood -1.409923
[ Info: iteration 30, average log likelihood -1.409898
[ Info: iteration 31, average log likelihood -1.409874
[ Info: iteration 32, average log likelihood -1.409850
[ Info: iteration 33, average log likelihood -1.409827
[ Info: iteration 34, average log likelihood -1.409805
[ Info: iteration 35, average log likelihood -1.409783
[ Info: iteration 36, average log likelihood -1.409762
[ Info: iteration 37, average log likelihood -1.409741
[ Info: iteration 38, average log likelihood -1.409720
[ Info: iteration 39, average log likelihood -1.409700
[ Info: iteration 40, average log likelihood -1.409680
[ Info: iteration 41, average log likelihood -1.409660
[ Info: iteration 42, average log likelihood -1.409641
[ Info: iteration 43, average log likelihood -1.409622
[ Info: iteration 44, average log likelihood -1.409603
[ Info: iteration 45, average log likelihood -1.409585
[ Info: iteration 46, average log likelihood -1.409567
[ Info: iteration 47, average log likelihood -1.409550
[ Info: iteration 48, average log likelihood -1.409533
[ Info: iteration 49, average log likelihood -1.409517
[ Info: iteration 50, average log likelihood -1.409501
┌ Info: EM with 100000 data points 50 iterations avll -1.409501
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4120832495575122
│     -1.4120222275223286
│      ⋮
└     -1.4095009148482136
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4219581998920459
│     -1.4219766644828782
│     -1.4219200976847604
│     -1.4218853978770007
│      ⋮
│     -1.4095332534437182
│     -1.4095168490465013
└     -1.4095009148482136
32×26 Array{Float64,2}:
 -0.426341    -0.546231     0.112125    0.285603     0.187395     0.0611274    0.120267   -0.300402    0.00515527  -0.101688    0.412332    -0.46805     0.424908    -0.756261     0.254835      0.740063     0.648385   -0.3332        0.114222    0.283212    0.88028     -0.0126954   0.0864979   -0.139331      0.192028    0.105831
 -0.0332534   -0.281383     0.193839    0.0511674    0.674189    -0.384366     0.267541    0.214303    0.340831    -0.506383    0.382917    -0.484486    0.632725    -0.14576      0.102142      0.136937     0.131583    0.493155     -0.0745857  -0.429079    0.780352     0.2242     -0.0944819    0.0688461     0.32801     0.245989
  0.480802     0.149451     0.240889    0.338965     0.0926167   -0.599828    -0.175235    0.279171    0.641498    -0.294737    0.261076    -0.0184492   0.101631     0.402336    -0.0971564     0.304017    -0.228658    0.121898      0.0780189   0.19919     0.357805    -0.362944    0.0641969    0.259793     -0.446146   -0.586483
 -0.578807    -0.3913      -0.0950272   0.116851     0.0758746   -0.130168     0.0555367   0.0222969   0.353171    -0.121049    0.340561     0.206526   -0.00683621   0.311217     0.171361     -0.172991    -0.0850193   0.228209      0.0699811  -0.869078   -0.270313     0.365242    0.035426    -0.111125     -0.50916    -0.178416
 -0.00664604  -0.111138    -1.31043     0.0481647    0.343152     0.056879    -0.259811    0.547347   -0.223716     0.016809    0.28423     -0.216787    0.386138     0.0950943   -0.155971     -0.0118599   -0.261335   -0.0665202    -0.33387     0.234341    0.1886       0.479339    0.149108     0.868027     -0.0084668   0.516744
  0.00616832  -0.311786    -0.214387   -0.584147    -0.00982921  -0.420915    -0.632088    0.210384   -0.286167    -0.829686   -0.153618     0.431951    0.277104     0.372025    -0.196581      0.53947     -0.0356569   0.150382      0.13055     0.507529    0.505678     0.555968    0.225823     0.000786508  -0.255098    0.50644
 -0.0632362   -0.119754    -0.0979712  -0.497085     0.07161     -0.00826245   0.810027    0.151852    0.200056    -0.0757577   0.0876045    0.721149    0.00578005  -0.161213     0.846294     -0.111639    -0.0374459   0.153214      0.126189   -0.0996682   0.299453     0.0305189   0.10893      0.258572     -0.476027    0.64714
  0.349806    -0.131373    -0.225023    0.488389    -0.547377    -0.239055     0.704825    0.490296   -0.0863599    0.0527206   0.202356     0.19213    -0.152789     0.0122137    0.0359793     0.253249     0.285823    0.307983      0.386654    0.0555248  -0.07531     -0.152232    0.73979      0.183234      0.124664    0.631644
  0.150011     0.0588695   -0.0842096  -0.192698    -0.0562242    0.231406    -0.0416063  -0.0518881  -0.139639     0.067441   -0.0761314    0.0256598   0.00296333  -0.277281     0.000757099   0.115737     0.0897295  -0.10493      -0.0819973   0.383726    0.067611    -0.042383    0.0742693   -0.080511      0.121672    0.0730147
  0.239013     0.417769     0.484024   -0.852038    -0.320216     0.560719    -0.0196094  -0.431074   -0.491038     0.83223    -0.21237      0.14043    -0.563516     0.149221    -0.0339673     0.202012     0.548371   -0.398707      0.256295    0.150672    0.00564824  -0.336348   -0.131824    -0.513907      0.158117   -0.160972
 -0.0888437    0.342657     0.456533    0.633271    -0.135085    -0.0573022   -0.164138   -0.393666   -0.960804     0.753114   -0.22518     -0.645581   -0.246394    -0.396987     0.589599     -0.515826    -0.233457   -0.302123     -0.659219   -0.880195   -0.768825    -0.268562    0.419462     0.234793      0.344603   -0.252416
  0.0269181    0.435707    -0.110593    0.213283    -0.233308     0.307164     0.0677604   0.264836   -0.594114     0.20867    -0.728874     0.666468   -0.593234    -0.00118424  -0.275237     -0.300051    -0.925114   -0.168584     -0.194878   -0.0150813  -0.378658    -0.0913495  -0.0239641    0.167432      0.176024    0.113334
  0.227008     0.495778    -0.38664    -0.415646     0.26834     -0.186022    -0.0780338  -0.0671283   0.349414     0.143849   -0.293634     0.299119    0.231488    -0.436831    -0.193387     -0.4317      -0.206776   -0.24387      -0.411695    0.219287   -0.302653    -0.23127    -0.628848    -0.346098     -0.367726   -0.670473
  0.345257     0.153981    -0.337244   -0.31935      0.12284      0.122995    -0.196379   -0.0206886   0.497318     0.125479   -0.0173986    1.04831    -0.0514712    0.317376    -0.742392     -0.76704     -0.147428    0.0813954     0.321082   -0.712466   -0.945453     0.167692   -0.376257    -0.100603     -0.144532    0.0175223
 -0.341786    -0.369054     0.303639    0.0673101   -0.0628688    0.346666    -0.339485   -0.0301116  -0.466129    -0.2429      0.0645034   -0.50056    -0.217027     0.294214    -0.525176      0.100962     0.142333    0.0032139     0.0766409  -0.406556   -0.703605    -0.417852   -0.592147     0.0302656     0.624155   -0.079813
  0.043013    -0.130664     0.0332056   0.329903     0.202218    -0.00442964   0.432897    0.307623    0.214177     0.391758   -0.0207825   -0.349806   -0.311039    -0.659771    -0.267536     -0.642589     0.052487    0.0925133    -0.107794   -0.544627   -0.104243    -0.55767    -0.583554     0.225101      0.817017   -0.223
 -0.36584     -0.350467     0.299303   -0.192011     0.395698     0.643471    -0.394942   -0.967265   -0.111917    -0.0760838  -0.159584     0.183085   -0.0350919   -0.625167     0.216866      0.170702     0.0549392  -0.151939     -0.402348   -0.123252   -0.373767     0.167778    0.0628996   -0.292225     -0.179388   -0.194922
 -0.831759    -0.0464161    0.28306     0.0335226   -0.151286     0.325663    -0.479431   -0.207142   -0.0723748    0.16782     0.0618678   -0.720808    0.272512     0.399065     0.233858     -0.00583494  -0.0125925   0.22524       0.316192   -0.346075    0.20593      0.603446    0.122615    -0.164877     -0.122422   -0.0832261
  0.192777     0.18051      0.349956    0.217031    -0.0443553    0.778674     0.521844   -0.538099   -0.507584    -0.343058   -0.151046    -0.157906    0.114388    -0.345746     0.351477     -0.256989     0.222586   -0.156977      0.302746    0.173221   -0.134237    -0.332783    0.0444938   -0.00391781    0.126958    0.291441
 -0.192711     0.427366    -0.259815   -0.00638365   0.125692     0.462243     0.379103   -0.424618   -0.51403     -0.0556525  -0.276838     0.321358    0.00997073  -0.294977     0.312601     -0.282495     0.183694   -0.197845     -0.0699573  -0.150316    0.218005     1.04266    -0.0133096   -0.317813      0.393727    0.648024
  0.129633     0.287329     0.0465609   0.139752    -0.612235    -0.0247746   -0.658178    0.380971   -0.292502     0.17411     0.0138836   -0.417068   -0.770811    -0.0294161   -0.394343      0.168127     0.0852499  -0.263026     -0.35584     0.832609   -0.0541476   -0.363686    0.0606722   -0.160725      0.421781   -0.133521
  0.306786     0.0786729   -0.187714   -0.173811     0.252291    -0.175162    -0.36906     0.14941    -0.329934    -0.0291831  -0.386781     0.159568   -0.116081    -0.637579     0.0955855     0.128157     0.295505    0.0969559    -0.160181    0.36563     0.180705    -0.168643    0.0613366    0.551047      0.653387    0.0548278
  0.0875103   -0.0457781   -0.0822332  -0.330998     0.0201646    0.212473     0.117878    0.0385172  -0.23829      0.0695018  -0.06173      0.0540915  -0.022689    -0.0890114   -0.0248037     0.0627314    0.296499   -0.0594328     0.199076   -0.113255   -0.15809      0.0061057   0.0476248   -0.22219       0.182304    0.194895
 -0.134705     0.00698045   0.211291    0.504393    -0.0815223    0.128062     0.17421    -0.0305286  -0.126222     0.0735352   0.0909019   -0.220468   -0.141718    -0.1763      -0.116332      0.0024582   -0.0749971  -0.196145     -0.0690168  -0.113767    0.107715    -0.125186   -0.0127665    0.0996654     0.401079    0.100986
 -0.0420471   -0.194998    -0.20817    -0.791568     0.34748     -0.173631    -0.237443    0.82618     0.260497     0.360802    0.364542     0.0786772   0.293376     0.349065    -0.541757      0.367304    -0.155713    0.296661     -0.0744496  -0.0985857   0.0565223   -0.0546435  -0.454437    -0.158637     -0.010404   -0.00179418
 -0.341923    -0.431913    -0.0472686   0.328249     0.128151    -0.209987    -0.0991787   0.154571    0.0406535   -0.217581    0.308847     0.107491    0.279858     0.0793518   -0.385357      0.0724499   -0.405563    0.235681     -0.0221073  -0.565639   -0.211856    -0.27882    -0.0596651    0.169884      0.0113705  -0.183748
 -0.00205245  -0.227869    -0.226962    0.048646    -0.426272    -0.155476     0.318229    0.444672    0.46123      0.640014    0.313302    -0.252636   -0.187526     0.280971    -0.689025     -0.206996     0.532676   -0.144994      0.461473    0.0296774  -0.391299    -0.394672    0.352943    -0.283803      0.0340066  -0.399782
  0.205        0.233989    -0.146777   -0.221971    -0.596348    -0.156619     0.318407    0.183437    0.0288685   -0.0313344   0.357466    -0.391053   -0.311997     0.89258     -0.263054     -0.466614    -0.406114    0.0346989    -0.222017   -0.127239   -0.310199     0.0223462  -0.00220829   0.0220444    -0.195148    0.046074
  0.189305     0.271301    -0.289059   -0.237526    -0.52221      0.141314    -0.263977   -0.412423   -0.418212     0.243763    0.138994     0.538366   -0.0347062    0.190945     0.0910215     0.344094    -0.10617     0.174616     -0.208824    0.379904   -0.238883     0.347358    0.578359    -0.372261     -0.800374   -0.335595
  0.160642    -0.318741     0.0714177  -0.233126    -0.423483    -0.105965    -0.249023   -0.492464    0.68103     -0.0829671  -0.0727797    0.128106   -0.00773512   0.265583     0.185372      0.463921     0.380456   -0.0370884     0.169255    0.201844    0.269641     0.242339    0.174984    -0.576391     -0.578155   -0.333636
  0.0209603   -0.139329    -0.168144   -0.182579    -0.107505    -0.203601    -0.215939   -0.145899    0.117485    -0.0903261  -0.0331211    0.110688   -0.275672     0.162537     0.174631     -0.0359271   -0.0873543   0.170974     -0.266828    0.142803   -0.11495      0.168194   -0.0581614    0.0631416    -0.35884    -0.0934709
  0.15593      0.130198    -0.124106    0.112114     0.167865    -0.163585    -0.0239454   0.0934584  -0.0261625   -0.211223   -0.00574248   0.100697    0.451859    -0.196542     0.259841      0.0854174   -0.178784   -0.000380392  -0.0170431   0.239485    0.500501     0.213322    0.290944     0.0854246    -0.370815   -0.0753968[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409485
[ Info: iteration 2, average log likelihood -1.409470
[ Info: iteration 3, average log likelihood -1.409456
[ Info: iteration 4, average log likelihood -1.409442
[ Info: iteration 5, average log likelihood -1.409428
[ Info: iteration 6, average log likelihood -1.409415
[ Info: iteration 7, average log likelihood -1.409402
[ Info: iteration 8, average log likelihood -1.409390
[ Info: iteration 9, average log likelihood -1.409378
[ Info: iteration 10, average log likelihood -1.409366
┌ Info: EM with 100000 data points 10 iterations avll -1.409366
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.117267e+05
      1       7.076226e+05      -2.041041e+05 |       32
      2       6.916519e+05      -1.597070e+04 |       32
      3       6.852307e+05      -6.421189e+03 |       32
      4       6.820816e+05      -3.149108e+03 |       32
      5       6.802155e+05      -1.866152e+03 |       32
      6       6.789263e+05      -1.289198e+03 |       32
      7       6.779561e+05      -9.701993e+02 |       32
      8       6.772152e+05      -7.408367e+02 |       32
      9       6.766374e+05      -5.778035e+02 |       32
     10       6.761540e+05      -4.834431e+02 |       32
     11       6.757614e+05      -3.925372e+02 |       32
     12       6.754114e+05      -3.500545e+02 |       32
     13       6.750895e+05      -3.218930e+02 |       32
     14       6.748170e+05      -2.724987e+02 |       32
     15       6.745569e+05      -2.600936e+02 |       32
     16       6.742978e+05      -2.591280e+02 |       32
     17       6.740641e+05      -2.337004e+02 |       32
     18       6.738609e+05      -2.031775e+02 |       32
     19       6.736941e+05      -1.668275e+02 |       32
     20       6.735538e+05      -1.402852e+02 |       32
     21       6.734175e+05      -1.362818e+02 |       32
     22       6.732787e+05      -1.387920e+02 |       32
     23       6.731549e+05      -1.238129e+02 |       32
     24       6.730433e+05      -1.116341e+02 |       32
     25       6.729383e+05      -1.049583e+02 |       32
     26       6.728397e+05      -9.864526e+01 |       32
     27       6.727517e+05      -8.799002e+01 |       32
     28       6.726661e+05      -8.554484e+01 |       32
     29       6.725866e+05      -7.950547e+01 |       32
     30       6.725164e+05      -7.021174e+01 |       32
     31       6.724521e+05      -6.430416e+01 |       32
     32       6.723885e+05      -6.356611e+01 |       32
     33       6.723300e+05      -5.852266e+01 |       32
     34       6.722748e+05      -5.526267e+01 |       32
     35       6.722231e+05      -5.167963e+01 |       32
     36       6.721739e+05      -4.917018e+01 |       32
     37       6.721243e+05      -4.959151e+01 |       32
     38       6.720713e+05      -5.297474e+01 |       32
     39       6.720134e+05      -5.790578e+01 |       32
     40       6.719600e+05      -5.340379e+01 |       32
     41       6.719061e+05      -5.393138e+01 |       32
     42       6.718604e+05      -4.573230e+01 |       32
     43       6.718185e+05      -4.185709e+01 |       32
     44       6.717777e+05      -4.082546e+01 |       32
     45       6.717422e+05      -3.546792e+01 |       32
     46       6.717076e+05      -3.459875e+01 |       32
     47       6.716771e+05      -3.049011e+01 |       32
     48       6.716535e+05      -2.363906e+01 |       32
     49       6.716275e+05      -2.599763e+01 |       32
     50       6.716007e+05      -2.678566e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 671600.7050368753)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421029
[ Info: iteration 2, average log likelihood -1.415979
[ Info: iteration 3, average log likelihood -1.414602
[ Info: iteration 4, average log likelihood -1.413567
[ Info: iteration 5, average log likelihood -1.412480
[ Info: iteration 6, average log likelihood -1.411490
[ Info: iteration 7, average log likelihood -1.410832
[ Info: iteration 8, average log likelihood -1.410485
[ Info: iteration 9, average log likelihood -1.410299
[ Info: iteration 10, average log likelihood -1.410182
[ Info: iteration 11, average log likelihood -1.410096
[ Info: iteration 12, average log likelihood -1.410028
[ Info: iteration 13, average log likelihood -1.409970
[ Info: iteration 14, average log likelihood -1.409920
[ Info: iteration 15, average log likelihood -1.409876
[ Info: iteration 16, average log likelihood -1.409837
[ Info: iteration 17, average log likelihood -1.409801
[ Info: iteration 18, average log likelihood -1.409769
[ Info: iteration 19, average log likelihood -1.409739
[ Info: iteration 20, average log likelihood -1.409711
[ Info: iteration 21, average log likelihood -1.409686
[ Info: iteration 22, average log likelihood -1.409662
[ Info: iteration 23, average log likelihood -1.409640
[ Info: iteration 24, average log likelihood -1.409620
[ Info: iteration 25, average log likelihood -1.409600
[ Info: iteration 26, average log likelihood -1.409582
[ Info: iteration 27, average log likelihood -1.409564
[ Info: iteration 28, average log likelihood -1.409547
[ Info: iteration 29, average log likelihood -1.409531
[ Info: iteration 30, average log likelihood -1.409516
[ Info: iteration 31, average log likelihood -1.409501
[ Info: iteration 32, average log likelihood -1.409487
[ Info: iteration 33, average log likelihood -1.409473
[ Info: iteration 34, average log likelihood -1.409459
[ Info: iteration 35, average log likelihood -1.409445
[ Info: iteration 36, average log likelihood -1.409432
[ Info: iteration 37, average log likelihood -1.409419
[ Info: iteration 38, average log likelihood -1.409406
[ Info: iteration 39, average log likelihood -1.409392
[ Info: iteration 40, average log likelihood -1.409379
[ Info: iteration 41, average log likelihood -1.409366
[ Info: iteration 42, average log likelihood -1.409353
[ Info: iteration 43, average log likelihood -1.409340
[ Info: iteration 44, average log likelihood -1.409327
[ Info: iteration 45, average log likelihood -1.409314
[ Info: iteration 46, average log likelihood -1.409301
[ Info: iteration 47, average log likelihood -1.409287
[ Info: iteration 48, average log likelihood -1.409274
[ Info: iteration 49, average log likelihood -1.409261
[ Info: iteration 50, average log likelihood -1.409248
┌ Info: EM with 100000 data points 50 iterations avll -1.409248
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.133475     -0.120299    -0.40502      0.394074    0.248514    -0.426661   -0.0432645   0.315378     0.687797   -0.446267     0.432389      0.0951029    0.424419    0.433976    0.161274    0.369848    -0.122284   -0.0347266    0.129141     0.0751634    0.430087     0.0121233   0.259178     0.603521    -0.801242    -0.0324388
 -0.204644     -0.324622    -0.09012     -0.494394    0.493698     0.966053    0.0359158  -0.0281512   -0.316723    0.317191     0.0979706    -0.0660594   -0.0168759  -0.388475   -0.174642   -0.0342088    0.259849   -0.349149    -0.0599541   -0.39734     -0.266759    -0.11276    -0.116095    -0.214542     0.731793     0.693912
  0.000804341  -0.337602    -0.107745    -0.386898    0.0987048   -0.326675   -0.0315679   0.215438     0.36167    -0.192758     0.23297      -0.00818181   0.305048    0.210317   -0.075419    0.242842     0.116286    0.226216     0.0598121    0.0420309    0.238199     0.278476    0.0139482   -0.204601    -0.228936     0.0765762
 -0.116685     -0.169053    -0.263498    -0.384552    0.180899    -0.187344    0.69838    -0.0331198    0.113921   -0.151274     0.0920352     0.753616     0.297996   -0.22924     0.669336   -0.179036    -0.106917    0.18603      0.151361    -0.533009     0.304792     0.467082    0.196848     0.0440892   -0.481682     0.55769
  0.0616198     0.244356     0.236531     0.721379   -0.0135838   -0.192902    0.127151   -0.164026    -0.281744    1.37448     -0.0608499    -0.727505    -0.187791   -0.702456    0.346838   -0.784128    -0.131594   -0.219499    -0.469067    -0.880614    -0.619465    -0.439823   -0.0363462    0.434256     0.428163    -0.552123
 -0.0913142     0.456249     0.292929    -0.0692506  -0.0898789    0.488886    0.0483239  -0.142184    -0.540168    0.0264846   -0.413129      0.36751     -0.690811   -0.27573     0.649754   -0.354669    -0.230765   -0.173758    -0.201772    -0.189557    -0.65691     -0.0250962   0.212714    -0.298148     0.124978    -0.204209
 -0.0537613    -0.349969     0.0245597   -0.179736    0.0220066    0.015848   -0.253345   -0.685021     0.255748   -0.352805    -0.0177255     0.162347    -0.140772    0.044428    0.508965    0.0703736    0.0798136   0.159019    -0.256088     0.0495767   -0.115369     0.380429    0.00848168  -0.128465    -0.764271    -0.168514
  0.295244      0.605959    -0.28652      0.241735   -0.414173     0.704223    0.649325   -0.93845     -0.224807    0.125293    -0.290719      0.135283    -0.275216    0.191772   -0.0567852  -0.810676     0.051425   -0.419629     0.54254     -0.145266    -0.00101418  -0.0203273   0.0185408   -0.247245    -0.367616    -0.0450495
  0.131729     -0.217467    -0.22378      0.250996   -0.414732    -0.209082    0.845834    0.719113     0.389573    0.50347      0.28469       0.118799    -0.126383    0.130907   -0.173979   -0.196535     0.635082    0.210841     0.772942    -0.087222    -0.413115    -0.348289    0.443399    -0.130791    -0.129027     0.117494
 -0.156474      0.120457    -0.450134    -0.0811181  -0.0323959    0.503309    0.0246838  -0.140312    -0.867852    0.109231    -0.295598      0.253195     0.113022   -0.0754088   0.205181    0.0145284   -0.237556    0.00198935  -0.392999     0.45819      0.306048     0.489448    0.0465106    0.467793     0.0803445    0.69696
 -0.164903      0.420399     0.0967551    0.478665    0.400416     0.177102    0.0228085   0.0215133   -0.20061    -0.58394      0.0320493    -0.0695985    0.347614   -0.387035    0.475004   -0.0573835   -0.432358   -0.102165    -0.0233358   -0.136018     0.468562     0.20641    -0.165645     0.385232     0.24122      0.312208
  0.101904      0.152537    -0.595383    -0.0703384   0.134071     0.148391   -0.181386   -0.77451      0.18136    -0.422381    -0.187326      0.44076      0.0052577  -1.61513     0.338648    0.187507     0.564809   -0.563849    -0.70555      0.275763    -0.140852    -0.260513   -0.326428    -0.196757     0.155693    -0.141175
 -0.101945      0.157905    -0.0910542   -0.0419392   0.0646804   -0.0333208  -0.276675   -0.0344128    0.175411    0.283884    -0.143556     -0.0611502   -0.110582   -0.107312   -0.191526   -0.077956    -0.114391   -0.243176    -0.255168     0.195141     0.0635913    0.118139   -0.221196    -0.232187    -0.13869     -0.398633
 -0.570244     -0.245645    -0.229372    -0.0538806   0.308102     0.0264     -0.61408     0.191307    -0.198391   -0.491657     0.00339295   -0.470324    -0.0584575   0.18094    -0.160877    0.104204     0.174671    0.686535     0.293838    -0.641518    -0.268244     0.657027   -0.450703     0.671916     0.480899     0.063087
 -0.438479     -0.495814     0.351845     0.287603    0.0491506   -0.0680587   0.108358   -0.0471823   -0.327079   -0.234058     0.164479     -0.58907      0.154982   -0.467308    0.500905    0.63277      0.553049   -0.187503     0.145108     0.376831     0.807744     0.0949796   0.273716    -0.0384577    0.248738     0.245231
 -0.0113066    -0.03736      0.0288581   -0.0140362  -0.695168     0.434986   -0.500782   -0.111398    -0.274713    0.496488    -0.000858804  -0.26954     -0.7187      0.208338   -0.703851    0.228379     0.185936   -0.284443    -0.110049     0.370846    -0.803712    -0.585624   -0.0943924   -0.274507     0.129562    -0.623637
  0.057509     -0.109336    -0.283632    -0.304033   -0.0968373   -0.447487   -0.779408   -0.0776304   -0.480601   -0.565751    -0.24111       0.244579     0.422154    0.272997   -0.315747    0.399741    -0.215737    0.0500759    0.103387     0.277319     0.278467     0.481881    0.472005    -0.0746071   -0.433124     0.154594
  0.258717     -0.315515     0.581414     0.160878    0.613055    -0.394257    0.472616    0.0252824    0.342812   -0.416765    -0.00540194   -0.361223     0.28756    -0.449097   -0.120251   -0.569404     0.0965543   0.730957    -0.420655    -0.54355      0.534996    -0.269717   -0.546447    -0.144799     0.706354     0.101172
 -0.434112     -0.337269     0.405383    -0.16172     0.488466     0.0888755  -0.25047    -0.00485798   0.0948243  -0.0293312    0.229834     -0.06294      0.454877   -0.160394   -0.37965     0.14572     -0.351468    0.0782944   -0.12454     -0.456467    -0.241548    -0.650413   -0.33865     -0.100217    -0.218218    -0.75801
  0.2742        0.285054    -0.190648    -0.0963379  -0.485285    -0.50911     0.0329989   0.387279    -0.0281651  -0.0524043    0.0939506    -0.106678    -0.370446    0.679735   -0.168526   -0.476318    -0.558506    0.16182     -0.319614     0.179924    -0.230273     0.0175779   0.0535678    0.170951    -0.252456    -0.122405
  0.313603      0.405085    -0.00169812   0.209197    0.102162    -0.0232417  -0.0955605   0.802264    -0.14567     0.0656724    0.0109527    -0.200726    -0.482186   -0.0985309  -0.527829   -0.0575877   -0.254193   -0.230743     0.0975295    0.233346     0.3583      -0.541653   -0.272872     0.414747     0.833016    -0.126801
 -0.748099     -0.00713597   0.319068    -0.088903   -0.226935     0.518021   -0.397447   -0.326418     0.316156    0.723192     0.220952     -0.772311     0.481208    0.305322    0.352916    0.0381346    0.185196    0.413077     0.303964    -0.372143     0.383064     0.534516    0.361588    -0.55629     -0.324219    -0.228317
 -0.0245018    -0.26337     -0.160465    -0.199245   -0.0146049   -0.214021    0.0977009   0.347298     0.254385   -0.0358049    0.358718      0.0514559    0.185076    0.323093   -0.172605    0.18349     -0.0176506   0.234541     0.054924    -0.0854376    0.0441665   -0.0645086  -0.0745758   -0.0566023   -0.217405    -0.000850819
  0.0775336    -0.00758814  -0.205146     0.115133   -0.0370324   -0.220156    0.0280497   0.263703    -0.0400827   0.152954     0.107671     -0.497451     0.206437   -0.0916509  -0.874172   -0.0613669    0.184134   -0.250778     0.102603    -0.172477     0.111126    -0.208888   -0.0267046   -0.00239513   0.825742    -0.0161456
  0.583493      0.112714     0.107094     0.365727   -0.190046     0.0292338   0.392845   -0.380743     0.336373    0.245444     0.100094      0.399477     0.377996   -0.508446   -0.0492483   0.458087     0.0133545  -0.127739    -0.0913876    0.41331      0.628159     0.0527001   0.613531    -0.415932    -0.166552    -0.197801
  0.0253182    -0.0324825    0.111709     0.0553508  -0.00117015   0.234779    0.0928571  -0.138931    -0.303684   -0.00977956  -0.0897508    -0.0323578   -0.129723   -0.226559    0.230403   -0.00299162   0.139043   -0.0889555    0.0771652    0.00204418  -0.0232461   -0.015712    0.160531     0.00988602   0.185755     0.144084
  0.190963     -0.0267125   -0.0382625   -0.803695   -0.772994    -0.0118309  -0.34025     0.00968534   0.0364006   0.385124    -0.0749453     0.468918    -0.843139    0.664843    0.282306    0.80141      0.356201   -0.149348    -0.16633      0.458383     0.128571     0.144191    0.0679425   -0.591783    -0.356335    -0.0641621
 -0.293465      0.0655157   -0.0366278    0.0572092  -0.395749     0.526363    0.224171   -0.0291694   -0.49963     0.102439    -0.126632      0.0872078   -0.140953    0.197862   -0.270355   -0.128626    -0.193406   -0.0520321    0.0204573   -0.368623    -0.37693      0.0586062  -0.0459893   -0.226162     0.138324     0.361228
 -0.127854     -0.534294     0.832371     1.00011    -0.485961    -0.118892    0.0388325  -0.528951    -0.0661758  -0.491648     0.412395     -0.259453    -0.474025    0.270173   -0.195677    0.136023     0.0713923   0.0688521   -0.026455    -0.362269    -0.462415    -0.354444   -0.022729     0.170094     0.526515     0.149496
  0.325276      0.158693    -0.440376    -0.481651    0.227503    -0.0630196  -0.155374    0.133105     0.49913     0.211733    -0.0433555     0.715986     0.016584    0.177868   -0.80158    -0.609989    -0.261066    0.00696571  -0.00177792  -0.441303    -0.874616    -0.0185614  -0.596508    -0.147134    -0.198284    -0.211028
  0.512919      0.602174     0.260373    -0.790195    0.581353     0.337722   -0.05981    -0.204049    -0.484049   -0.154229    -0.257424      0.238504     0.291514   -0.319373    0.131776    0.227814     0.522839    0.00210238   0.460116     0.615999    -0.0151791   -0.011056   -0.0620806   -0.110036     0.00401254   0.0159732
  0.305762     -0.0466887   -0.449654    -0.107505   -0.0670584   -0.324734   -0.209846    0.518509    -0.12248     0.177462    -0.152349      0.172433    -0.176246   -0.390536    0.110125    0.0682613    0.0896606   0.3122      -0.305589     0.438497     0.118405    -0.187777    0.177443     0.616874     0.453729     0.125025[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409235
[ Info: iteration 2, average log likelihood -1.409223
[ Info: iteration 3, average log likelihood -1.409210
[ Info: iteration 4, average log likelihood -1.409198
[ Info: iteration 5, average log likelihood -1.409186
[ Info: iteration 6, average log likelihood -1.409174
[ Info: iteration 7, average log likelihood -1.409163
[ Info: iteration 8, average log likelihood -1.409152
[ Info: iteration 9, average log likelihood -1.409141
[ Info: iteration 10, average log likelihood -1.409130
┌ Info: EM with 100000 data points 10 iterations avll -1.409130
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
