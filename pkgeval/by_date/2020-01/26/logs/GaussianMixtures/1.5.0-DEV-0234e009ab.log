Julia Version 1.5.0-DEV.150
Commit 0234e009ab (2020-01-25 18:06 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed URIParser ────────── v0.4.0
 Installed Blosc ────────────── v0.5.1
 Installed Parameters ───────── v0.12.0
 Installed BinDeps ──────────── v1.0.0
 Installed StaticArrays ─────── v0.12.1
 Installed Clustering ───────── v0.13.3
 Installed Compat ───────────── v2.2.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed HDF5 ─────────────── v0.12.5
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed QuadGK ───────────── v2.3.1
 Installed FileIO ───────────── v1.2.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed DataStructures ───── v0.17.9
 Installed NearestNeighbors ─── v0.4.4
 Installed Rmath ────────────── v0.6.0
 Installed Missings ─────────── v0.4.3
 Installed CMake ────────────── v1.1.2
 Installed StatsFuns ────────── v0.9.3
 Installed OrderedCollections ─ v1.1.0
 Installed JLD ──────────────── v0.9.1
 Installed Arpack ───────────── v0.4.0
 Installed SpecialFunctions ─── v0.9.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed DataAPI ──────────── v1.1.0
 Installed FillArrays ───────── v0.8.4
 Installed LegacyStrings ────── v0.4.1
 Installed BinaryProvider ───── v0.5.8
 Installed StatsBase ────────── v0.32.0
 Installed SortingAlgorithms ── v0.3.1
 Installed PDMats ───────────── v0.9.11
 Installed Distances ────────── v0.8.2
 Installed Distributions ────── v0.22.3
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_qr6iek/Project.toml`
 [no changes]
  Updating `/tmp/jl_qr6iek/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_Xu4C6F/Project.toml`
 [no changes]
  Updating `/tmp/jl_Xu4C6F/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_IJPJr0/Project.toml`
 [no changes]
  Updating `/tmp/jl_IJPJr0/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_ZZzDgE/Project.toml`
 [no changes]
  Updating `/tmp/jl_ZZzDgE/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_YMNwTB/Project.toml`
 [no changes]
  Updating `/tmp/jl_YMNwTB/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_YMNwTB/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -5.251777233985686e6, [30076.202436346997, 69923.797563653], [-13022.436091611598 11685.584063522836 -5142.639979159901; 13333.57209393931 -11639.110881573451 5324.336950305186], [[10210.037093606701 -7477.244331512154 -3624.2538926577813; -7477.244331512154 25210.267925025168 -1636.6381455434057; -3624.2538926577813 -1636.6381455434057 30478.69389368675], [89738.62015111843 7732.453147374597 3924.098365912868; 7732.453147374597 74015.92704207417 1785.7510339755415; 3924.098365912868 1785.7510339755413 69756.88919611524]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.076518e+03
      1       8.502788e+02      -2.262390e+02 |        7
      2       8.175371e+02      -3.274167e+01 |        2
      3       8.136883e+02      -3.848798e+00 |        2
      4       7.972853e+02      -1.640299e+01 |        0
      5       7.972853e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 797.2853036418956)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.054830
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.808658
[ Info: iteration 2, lowerbound -3.689993
[ Info: iteration 3, lowerbound -3.557616
[ Info: iteration 4, lowerbound -3.400950
[ Info: iteration 5, lowerbound -3.236448
[ Info: iteration 6, lowerbound -3.084259
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.952876
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.843437
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.749415
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.658172
[ Info: iteration 11, lowerbound -2.577859
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.504898
[ Info: iteration 13, lowerbound -2.438422
[ Info: iteration 14, lowerbound -2.388401
[ Info: iteration 15, lowerbound -2.350943
[ Info: iteration 16, lowerbound -2.324193
[ Info: iteration 17, lowerbound -2.309489
[ Info: iteration 18, lowerbound -2.308596
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302915
[ Info: iteration 20, lowerbound -2.299259
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Jan 27 10:19:49 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Jan 27 10:19:57 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Mon Jan 27 10:20:00 2020: EM with 272 data points 0 iterations avll -2.054830
5.8 data points per parameter
, Mon Jan 27 10:20:01 2020: GMM converted to Variational GMM
, Mon Jan 27 10:20:10 2020: iteration 1, lowerbound -3.808658
, Mon Jan 27 10:20:10 2020: iteration 2, lowerbound -3.689993
, Mon Jan 27 10:20:10 2020: iteration 3, lowerbound -3.557616
, Mon Jan 27 10:20:10 2020: iteration 4, lowerbound -3.400950
, Mon Jan 27 10:20:10 2020: iteration 5, lowerbound -3.236448
, Mon Jan 27 10:20:10 2020: iteration 6, lowerbound -3.084259
, Mon Jan 27 10:20:10 2020: dropping number of Gaussions to 7
, Mon Jan 27 10:20:10 2020: iteration 7, lowerbound -2.952876
, Mon Jan 27 10:20:10 2020: dropping number of Gaussions to 6
, Mon Jan 27 10:20:10 2020: iteration 8, lowerbound -2.843437
, Mon Jan 27 10:20:10 2020: dropping number of Gaussions to 5
, Mon Jan 27 10:20:10 2020: iteration 9, lowerbound -2.749415
, Mon Jan 27 10:20:10 2020: dropping number of Gaussions to 4
, Mon Jan 27 10:20:10 2020: iteration 10, lowerbound -2.658172
, Mon Jan 27 10:20:10 2020: iteration 11, lowerbound -2.577859
, Mon Jan 27 10:20:10 2020: dropping number of Gaussions to 3
, Mon Jan 27 10:20:10 2020: iteration 12, lowerbound -2.504898
, Mon Jan 27 10:20:10 2020: iteration 13, lowerbound -2.438422
, Mon Jan 27 10:20:10 2020: iteration 14, lowerbound -2.388401
, Mon Jan 27 10:20:10 2020: iteration 15, lowerbound -2.350943
, Mon Jan 27 10:20:10 2020: iteration 16, lowerbound -2.324193
, Mon Jan 27 10:20:10 2020: iteration 17, lowerbound -2.309489
, Mon Jan 27 10:20:10 2020: iteration 18, lowerbound -2.308596
, Mon Jan 27 10:20:10 2020: dropping number of Gaussions to 2
, Mon Jan 27 10:20:10 2020: iteration 19, lowerbound -2.302915
, Mon Jan 27 10:20:10 2020: iteration 20, lowerbound -2.299259
, Mon Jan 27 10:20:10 2020: iteration 21, lowerbound -2.299256
, Mon Jan 27 10:20:10 2020: iteration 22, lowerbound -2.299254
, Mon Jan 27 10:20:10 2020: iteration 23, lowerbound -2.299254
, Mon Jan 27 10:20:10 2020: iteration 24, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 25, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 26, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 27, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 28, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 29, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 30, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 31, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 32, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 33, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 34, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 35, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 36, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 37, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 38, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 39, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 40, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 41, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 42, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 43, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 44, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 45, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 46, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 47, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 48, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 49, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: iteration 50, lowerbound -2.299253
, Mon Jan 27 10:20:10 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260141, 95.95490777398591]
β = [178.0450922260141, 95.95490777398591]
m = [4.250300733269907 79.28686694436182; 2.0002292577753686 53.851987172461286]
ν = [180.0450922260141, 97.95490777398591]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484394 -0.007644049042327432; 0.0 0.008581705166333458], [0.37587636119484585 -0.008953123827346187; 0.0 0.012748664777409349]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999988
avll from stats: -0.9722955222680604
avll from llpg:  -0.9722955222680606
avll direct:     -0.9722955222680606
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9690304311893865
avll from llpg:  -0.9690304311893863
avll direct:     -0.9690304311893863
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.117251    -0.000479512  -0.0482748    0.0210267   -0.0345856    0.0181415   -0.225443     -0.15137      0.0527726   -0.215958     -0.014556    -0.110624     0.0678487   -0.0229175   -0.0479942   -0.119581     0.172737    -0.0711734   -0.100433    -0.0366991    -0.0768468    0.134468    -0.0908958     0.0298959   -0.0884619   -0.096044
  0.0972861    0.0894287    -0.205754     0.0706675   -0.0498626   -0.166443     0.0166287    -0.0284092    0.0325608    0.000235417  -0.101996    -0.0369589   -0.0634063   -0.18498      0.113638    -0.0993778    0.148519     0.288834     0.0894517    0.0296833     0.129413    -0.038596    -0.136984     -0.249597    -0.218326     0.029714
  0.205662    -0.184278      0.00723792  -0.0195774    0.120707    -0.0471161    0.147446     -0.0345719    0.0288513    0.234577     -0.0606251   -0.00649629  -0.0604904   -0.0447431    0.190099    -0.0219946    0.0516891    0.0478211   -0.0459088   -0.0657003    -0.0374806   -0.0965478    0.142985     -0.0863295    0.0442379   -0.224535
  0.14473      0.0772645     0.0829968   -0.132514     0.0747534    0.1297       0.0741461     0.0663386   -0.053473    -0.0121157    -0.140561     0.0951703   -0.00549063  -0.0964825    0.107312    -0.00699452   0.175479     0.12491      0.00433461   0.037699     -0.0594813    0.0304158    0.090729     -0.0318883    0.02988     -0.00865445
  0.02803     -0.0920029    -0.0942733    0.18618      0.119265    -0.126603    -0.0445374    -0.0512841    0.0507773   -0.144723      0.117226     0.0728745   -0.0579637    0.00975735   0.0943133   -0.0801953    0.100617    -0.0263456    0.0936249   -0.0479577     0.0876017   -0.0233546    0.0122135    -0.00148413  -0.14713     -0.0408565
  0.0362303    0.0413669    -0.107279    -0.0423423    0.0720926    0.0390447   -0.11656       0.112595    -0.210304    -0.0299186     0.150314    -0.0114258    0.199694     0.0814388    0.0864627   -0.178169    -0.0119783   -0.0681069   -0.0314573    0.0794322    -0.0379752    0.0464319   -0.117315     -0.0652494   -0.0959179    0.0652304
 -0.0112271    0.0518054    -0.0457829   -0.0248866    0.00270347   0.0470223   -0.125887     -0.0523723   -0.00109076  -0.0129123     0.141244    -0.215636    -0.12221      0.15436     -0.067973     0.0499147   -0.122678    -0.0519869    0.0721723   -0.120034     -0.0486465   -0.0866753   -0.0373246     0.0321194    0.068822     0.0504602
 -0.0425114    0.00853763    0.107559    -0.147579    -0.0486139   -0.140067    -0.0396774    -0.0219643    0.0714694    0.23854       0.0841309   -0.090711    -0.0330358   -0.00454782  -0.0116727    0.00169556  -0.0189956   -0.0908564    0.0276041   -0.0991904     0.0255687   -0.0360145   -0.067175     -0.0912609   -0.0491114   -0.0275899
 -0.0322288    0.0877482     0.0516793    0.00551142  -0.163725    -0.00428667  -0.189582     -0.127573     0.0951959    0.226682     -0.161317     0.018651     0.168251     0.129709    -0.0268992    0.0372537    0.00837046  -0.0833504    0.0786799   -0.0137761    -0.0743964   -0.0117899   -0.203228     -0.0394901    0.101956     0.0499248
  0.0293691   -0.029021      0.079669     0.025898    -0.00242295   0.156962     0.0277078    -0.0582284   -0.10373     -0.0185153    -0.0493432   -0.0291508   -0.0366532   -0.0213054    0.00869029  -0.109078    -0.0391941   -0.138839    -0.0291234    0.0737401    -0.0376315    0.116647     0.0515745    -0.0915478    0.0898903    0.168938
  0.0521978    0.077014      0.176148    -0.158129    -0.28855      0.0148168    0.0883321     0.265904    -0.0939166    0.0406116     0.0747072    0.0787703    0.0125993   -0.146352    -0.0876666   -0.0129187    0.135323    -0.0272688   -0.161542    -0.0921058    -0.0053175   -0.00975324  -0.131923      0.0762978   -0.108191     0.058145
 -0.0441212    0.0161954    -0.0542968    0.0274951   -0.0277459    0.0764794    0.00154352   -0.0238996    0.139014     0.0114763    -0.0632909    0.0716476   -0.0326649    0.0701494    0.111198     0.0537524    0.0505525   -0.115226     0.0982686    0.0227469     0.104495    -0.0539964   -0.104145      0.123301    -0.0444247    0.153535
 -0.155408    -0.0132495     0.207226     0.309498     0.0445443    0.027147     0.082189      0.0252981   -0.00509935  -0.0190517     0.0279109    0.0100628    0.0987159   -0.0251476   -0.0497778    0.177905     0.0517181    0.0224608    0.154886     0.064913     -0.00503615   0.00650317   0.0853317     0.130397    -0.0607048   -0.148466
  0.0785575    0.0467756     0.0227449   -0.0152902   -0.0338824   -0.167845     0.0751735     0.0439948   -0.0420658    0.0704814    -0.0230897    0.0240934   -0.0560528   -0.0474915    0.0767559   -0.0671041   -0.0871073    0.00726863  -0.0220246    0.0522594     0.167813    -0.037897     0.187023      0.197991    -0.159434    -0.106256
  0.0701274    0.191109     -0.216841    -0.0494362    0.161321    -0.0691348   -0.0736075     0.153079    -0.069035    -0.248778     -0.252939     0.159452     0.131214    -0.0828159   -0.136662    -0.059185    -0.00924896   0.0575134   -0.0148548   -0.167125     -0.0688235    0.0464462   -0.110995      0.0399099    0.0269666   -0.0402834
 -0.00253652   0.0704505     0.0294738   -0.172738     0.0115893    0.0827349   -0.00125651   -0.0615654    0.0927549    0.122376     -0.00328866   0.0236628   -0.099024    -0.00185454   0.0828955    0.0553053    0.0274114    0.194119    -0.104252    -0.128923      0.109945     0.0700321   -0.0900539    -0.0972522   -0.102842     0.0469358
  0.0916136   -0.0532677     0.07748      0.0885703    0.0285849   -0.0592691   -0.0557938    -0.0452604   -0.0816724    0.0618129     0.0823542    0.00284653   0.0610823   -0.0914752    0.164424     0.0224765    0.122043     0.0119209    0.205275     0.000343177  -0.0287281    0.00944494  -0.0361093     0.0141375    0.0580368   -0.049011
 -0.104426    -0.146562      0.0610816   -0.0365084    0.0245162   -0.00958813   0.0996096    -0.160455    -0.0638425   -0.0219916    -0.0073268    0.0314478    0.228578    -0.0656285    0.0298797    0.0071835   -0.0835256    0.0221426    0.102363    -0.113304     -0.0323941   -0.112237    -0.0599899     0.0473515   -0.196563     0.0603145
 -0.142481     0.0659486    -0.137293     0.0947866    0.35361      0.00337622  -0.0552766    -0.194953    -0.0817911   -0.034702     -0.0556269   -0.0102409   -0.0651909    0.195683    -0.016242    -0.0251857   -0.0829304    0.0284217   -0.0989215   -0.0548324    -0.0443362    0.0381675   -0.134665      0.0559061    0.158907    -0.000661793
 -0.0259139    0.0146328     0.133547     0.0195032   -0.022492    -0.0886338   -0.00420966    0.189083    -0.0117241   -0.0272852     0.190143    -0.0821861   -0.188948    -0.146803    -0.0553472   -0.0419359   -0.141351     0.0341058   -0.0903243    0.0274145    -0.0986156   -0.029512    -0.00586492    0.243072    -0.0566268   -0.0783862
 -0.0719934    0.205111     -0.0387743    0.0403073   -0.0453039   -0.0248779    0.0576112    -0.0718089   -0.139313     0.119821     -0.0741752   -0.0423451   -0.053515    -0.103312     0.123872     0.00736618  -0.0938003   -0.00239149  -0.0359323    0.0632069    -0.0612543    0.203038     0.0456694     0.0320625   -0.0937008   -0.0040268
  0.0110309    0.0781789    -0.10373     -0.0397027    0.0401203   -0.0585015    0.0520021     0.00660679   0.0594777    0.0236115     0.0745661   -0.0599236    0.0716549    0.00173375   0.10445     -0.00322898  -0.0628331    0.170924     0.01954      0.0859225     0.0808237    0.175149    -0.0747577     0.140688    -0.0859747   -0.0386826
 -0.0427499    0.106182      0.202847    -0.113555    -0.0077296   -0.198354    -0.00741047    0.0857542   -0.119553    -0.0343202     0.0188879    0.0860506   -0.0280349   -0.00277445   0.0139122   -0.0671285    0.268172     0.0670019    0.130252    -0.0568778    -0.13433     -0.257434     0.0660233    -0.0950201   -0.0174175   -0.0678289
 -0.0379082    0.0454348    -0.146837     0.0205558    0.111924    -0.0247661   -0.0807343    -0.0248509    0.247609    -0.0255082     0.0682699    0.178649    -0.116128     0.0303527   -0.208836     0.00935128   0.0513446    0.0669201   -0.219944    -0.0406799    -0.00485076  -0.0228458    0.0625803     0.0692644    0.196181     0.0657863
 -0.0223338   -0.0240957     0.0901415    0.0699021   -0.0482185    0.00879684   0.0378571     0.0963923   -0.0904365    0.0955388     0.087504    -0.0417018   -0.0872587   -0.0394064    0.0914005   -0.0618412   -0.161494     0.14816     -0.110099     0.117751      0.0498629   -0.039176     0.000624876  -0.0188142    0.0861329   -0.0728355
 -0.0111334   -0.0193484     0.00737462  -0.0539679   -0.164811     0.0112939   -0.0498553     0.0201925   -0.00478461   0.0135567    -0.18961      0.0277244   -0.09312     -0.150986    -0.135753     0.0936757    0.250869     0.102915    -0.0522258   -0.163603     -0.121223    -0.0941042   -0.132669      0.0700136   -0.15173      0.0803007
 -0.0676596   -0.0787499     0.156559     0.0141346   -0.0824878    0.273952    -0.000799343  -0.00910162   0.116254     0.15974       0.0231308   -0.0644784   -0.0742119    0.00044986   0.0568798    0.0882491   -0.0662851   -0.0307448    0.127136     0.0641015    -0.0587612   -0.045646    -0.0614891     0.0271884    0.0902429    0.0753013
  0.118048     0.0320564     0.130855    -0.0122205   -0.00603633   0.0560018    0.175745      0.112266     0.050556     0.156069     -0.0948212   -0.018049     0.0802802    0.179535    -0.0980948    0.20319     -0.0972607    0.00637907  -0.1685      -0.123069     -0.0634348   -0.077806     0.0617356    -0.0179365    0.0617501   -0.120286
  0.0486007    0.1223        0.0375459   -0.0763965   -0.156141     0.045525     0.163159     -0.0101066    0.018759     0.0651122     0.210931     0.0222248    0.00786457   0.0488602   -0.091082    -0.00186014  -0.18948      0.111474    -0.104969    -0.0474501    -0.066629     0.131883     0.0506775     0.0028707    0.00931558  -0.0586395
  0.0379712   -0.067566      0.00712692  -0.0403521   -0.0372367   -0.224871    -0.0199772    -0.0853478    0.00991136   0.0677448    -0.0811803    0.0218225    0.0264031   -0.0383431   -0.0685155   -0.199673    -0.127553     0.0848221   -0.0805945    0.101091      0.117358     0.192606    -0.000227335   0.0456399   -0.117572     0.134646
  0.00953369   0.0573085    -0.0437905    0.0168744    0.0982067    0.00155957  -0.0772846    -0.236891     0.190218     0.0374782     0.0620183   -0.0745383   -0.0546061   -0.0320347    0.0465402    0.0238494    0.0334471    0.0758389   -0.020111     0.0920784    -0.0464096    0.0582878    0.131484     -0.0863192    0.103687    -0.0311228
  0.0853308   -0.0124478     0.189414     0.0887081    0.0666613   -0.129431     0.114183      0.00814949   0.0665938   -0.00171602   -0.122953     0.0095659   -0.0763942   -0.0569158   -0.024005     0.0547018    0.00601884  -0.0172491   -0.00337817  -0.143333      0.200552    -0.109378    -0.0752799     0.0517425   -0.0783304   -0.00222565kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4152169699657065
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415278
[ Info: iteration 2, average log likelihood -1.415206
[ Info: iteration 3, average log likelihood -1.414647
[ Info: iteration 4, average log likelihood -1.407576
[ Info: iteration 5, average log likelihood -1.385739
[ Info: iteration 6, average log likelihood -1.376161
[ Info: iteration 7, average log likelihood -1.374337
[ Info: iteration 8, average log likelihood -1.373566
[ Info: iteration 9, average log likelihood -1.373194
[ Info: iteration 10, average log likelihood -1.372986
[ Info: iteration 11, average log likelihood -1.372838
[ Info: iteration 12, average log likelihood -1.372709
[ Info: iteration 13, average log likelihood -1.372585
[ Info: iteration 14, average log likelihood -1.372464
[ Info: iteration 15, average log likelihood -1.372349
[ Info: iteration 16, average log likelihood -1.372245
[ Info: iteration 17, average log likelihood -1.372154
[ Info: iteration 18, average log likelihood -1.372077
[ Info: iteration 19, average log likelihood -1.372009
[ Info: iteration 20, average log likelihood -1.371949
[ Info: iteration 21, average log likelihood -1.371895
[ Info: iteration 22, average log likelihood -1.371848
[ Info: iteration 23, average log likelihood -1.371807
[ Info: iteration 24, average log likelihood -1.371770
[ Info: iteration 25, average log likelihood -1.371737
[ Info: iteration 26, average log likelihood -1.371707
[ Info: iteration 27, average log likelihood -1.371680
[ Info: iteration 28, average log likelihood -1.371655
[ Info: iteration 29, average log likelihood -1.371633
[ Info: iteration 30, average log likelihood -1.371612
[ Info: iteration 31, average log likelihood -1.371592
[ Info: iteration 32, average log likelihood -1.371574
[ Info: iteration 33, average log likelihood -1.371557
[ Info: iteration 34, average log likelihood -1.371541
[ Info: iteration 35, average log likelihood -1.371526
[ Info: iteration 36, average log likelihood -1.371512
[ Info: iteration 37, average log likelihood -1.371499
[ Info: iteration 38, average log likelihood -1.371488
[ Info: iteration 39, average log likelihood -1.371478
[ Info: iteration 40, average log likelihood -1.371469
[ Info: iteration 41, average log likelihood -1.371462
[ Info: iteration 42, average log likelihood -1.371456
[ Info: iteration 43, average log likelihood -1.371450
[ Info: iteration 44, average log likelihood -1.371446
[ Info: iteration 45, average log likelihood -1.371442
[ Info: iteration 46, average log likelihood -1.371439
[ Info: iteration 47, average log likelihood -1.371437
[ Info: iteration 48, average log likelihood -1.371435
[ Info: iteration 49, average log likelihood -1.371433
[ Info: iteration 50, average log likelihood -1.371431
┌ Info: EM with 100000 data points 50 iterations avll -1.371431
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4152775910324373
│     -1.4152063205936458
│      ⋮
└     -1.3714312947668388
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.371541
[ Info: iteration 2, average log likelihood -1.371449
[ Info: iteration 3, average log likelihood -1.371182
[ Info: iteration 4, average log likelihood -1.368240
[ Info: iteration 5, average log likelihood -1.355176
[ Info: iteration 6, average log likelihood -1.341873
[ Info: iteration 7, average log likelihood -1.337608
[ Info: iteration 8, average log likelihood -1.336502
[ Info: iteration 9, average log likelihood -1.336014
[ Info: iteration 10, average log likelihood -1.335687
[ Info: iteration 11, average log likelihood -1.335417
[ Info: iteration 12, average log likelihood -1.335170
[ Info: iteration 13, average log likelihood -1.334932
[ Info: iteration 14, average log likelihood -1.334693
[ Info: iteration 15, average log likelihood -1.334444
[ Info: iteration 16, average log likelihood -1.334183
[ Info: iteration 17, average log likelihood -1.333915
[ Info: iteration 18, average log likelihood -1.333650
[ Info: iteration 19, average log likelihood -1.333392
[ Info: iteration 20, average log likelihood -1.333147
[ Info: iteration 21, average log likelihood -1.332918
[ Info: iteration 22, average log likelihood -1.332699
[ Info: iteration 23, average log likelihood -1.332478
[ Info: iteration 24, average log likelihood -1.332233
[ Info: iteration 25, average log likelihood -1.331926
[ Info: iteration 26, average log likelihood -1.331519
[ Info: iteration 27, average log likelihood -1.331043
[ Info: iteration 28, average log likelihood -1.330564
[ Info: iteration 29, average log likelihood -1.330147
[ Info: iteration 30, average log likelihood -1.329802
[ Info: iteration 31, average log likelihood -1.329522
[ Info: iteration 32, average log likelihood -1.329307
[ Info: iteration 33, average log likelihood -1.329150
[ Info: iteration 34, average log likelihood -1.329042
[ Info: iteration 35, average log likelihood -1.328968
[ Info: iteration 36, average log likelihood -1.328918
[ Info: iteration 37, average log likelihood -1.328882
[ Info: iteration 38, average log likelihood -1.328853
[ Info: iteration 39, average log likelihood -1.328829
[ Info: iteration 40, average log likelihood -1.328806
[ Info: iteration 41, average log likelihood -1.328783
[ Info: iteration 42, average log likelihood -1.328759
[ Info: iteration 43, average log likelihood -1.328733
[ Info: iteration 44, average log likelihood -1.328706
[ Info: iteration 45, average log likelihood -1.328677
[ Info: iteration 46, average log likelihood -1.328647
[ Info: iteration 47, average log likelihood -1.328616
[ Info: iteration 48, average log likelihood -1.328585
[ Info: iteration 49, average log likelihood -1.328556
[ Info: iteration 50, average log likelihood -1.328527
┌ Info: EM with 100000 data points 50 iterations avll -1.328527
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3715410265541876
│     -1.3714493831553474
│      ⋮
└     -1.3285274827360007
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.328681
[ Info: iteration 2, average log likelihood -1.328437
[ Info: iteration 3, average log likelihood -1.327203
[ Info: iteration 4, average log likelihood -1.317657
[ Info: iteration 5, average log likelihood -1.299058
[ Info: iteration 6, average log likelihood -1.285972
[ Info: iteration 7, average log likelihood -1.279826
[ Info: iteration 8, average log likelihood -1.275774
[ Info: iteration 9, average log likelihood -1.272735
[ Info: iteration 10, average log likelihood -1.270319
[ Info: iteration 11, average log likelihood -1.268013
[ Info: iteration 12, average log likelihood -1.265881
[ Info: iteration 13, average log likelihood -1.264974
[ Info: iteration 14, average log likelihood -1.264798
[ Info: iteration 15, average log likelihood -1.264726
[ Info: iteration 16, average log likelihood -1.264691
[ Info: iteration 17, average log likelihood -1.264672
[ Info: iteration 18, average log likelihood -1.264660
[ Info: iteration 19, average log likelihood -1.264653
[ Info: iteration 20, average log likelihood -1.264647
[ Info: iteration 21, average log likelihood -1.264643
[ Info: iteration 22, average log likelihood -1.264640
[ Info: iteration 23, average log likelihood -1.264638
[ Info: iteration 24, average log likelihood -1.264636
[ Info: iteration 25, average log likelihood -1.264635
[ Info: iteration 26, average log likelihood -1.264634
[ Info: iteration 27, average log likelihood -1.264633
[ Info: iteration 28, average log likelihood -1.264633
[ Info: iteration 29, average log likelihood -1.264632
[ Info: iteration 30, average log likelihood -1.264632
[ Info: iteration 31, average log likelihood -1.264632
[ Info: iteration 32, average log likelihood -1.264631
[ Info: iteration 33, average log likelihood -1.264631
[ Info: iteration 34, average log likelihood -1.264631
[ Info: iteration 35, average log likelihood -1.264631
[ Info: iteration 36, average log likelihood -1.264631
[ Info: iteration 37, average log likelihood -1.264631
[ Info: iteration 38, average log likelihood -1.264631
[ Info: iteration 39, average log likelihood -1.264631
[ Info: iteration 40, average log likelihood -1.264630
[ Info: iteration 41, average log likelihood -1.264630
[ Info: iteration 42, average log likelihood -1.264630
[ Info: iteration 43, average log likelihood -1.264630
[ Info: iteration 44, average log likelihood -1.264630
[ Info: iteration 45, average log likelihood -1.264630
[ Info: iteration 46, average log likelihood -1.264630
[ Info: iteration 47, average log likelihood -1.264630
[ Info: iteration 48, average log likelihood -1.264630
[ Info: iteration 49, average log likelihood -1.264630
[ Info: iteration 50, average log likelihood -1.264630
┌ Info: EM with 100000 data points 50 iterations avll -1.264630
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3286813870100553
│     -1.32843749027341
│      ⋮
└     -1.2646302891092749
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.264867
[ Info: iteration 2, average log likelihood -1.264581
[ Info: iteration 3, average log likelihood -1.263269
[ Info: iteration 4, average log likelihood -1.250727
[ Info: iteration 5, average log likelihood -1.221935
[ Info: iteration 6, average log likelihood -1.202194
[ Info: iteration 7, average log likelihood -1.194004
[ Info: iteration 8, average log likelihood -1.189330
[ Info: iteration 9, average log likelihood -1.185644
[ Info: iteration 10, average log likelihood -1.183232
[ Info: iteration 11, average log likelihood -1.181417
[ Info: iteration 12, average log likelihood -1.180202
[ Info: iteration 13, average log likelihood -1.179182
[ Info: iteration 14, average log likelihood -1.177748
[ Info: iteration 15, average log likelihood -1.175577
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.173603
[ Info: iteration 17, average log likelihood -1.187393
[ Info: iteration 18, average log likelihood -1.181960
[ Info: iteration 19, average log likelihood -1.179798
[ Info: iteration 20, average log likelihood -1.178499
[ Info: iteration 21, average log likelihood -1.176765
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.174483
[ Info: iteration 23, average log likelihood -1.187143
[ Info: iteration 24, average log likelihood -1.181876
[ Info: iteration 25, average log likelihood -1.179665
[ Info: iteration 26, average log likelihood -1.178281
[ Info: iteration 27, average log likelihood -1.176449
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.174159
[ Info: iteration 29, average log likelihood -1.187115
[ Info: iteration 30, average log likelihood -1.181905
[ Info: iteration 31, average log likelihood -1.179615
[ Info: iteration 32, average log likelihood -1.178159
[ Info: iteration 33, average log likelihood -1.176275
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.173994
[ Info: iteration 35, average log likelihood -1.187110
[ Info: iteration 36, average log likelihood -1.181931
[ Info: iteration 37, average log likelihood -1.179600
[ Info: iteration 38, average log likelihood -1.178118
[ Info: iteration 39, average log likelihood -1.176223
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.173947
[ Info: iteration 41, average log likelihood -1.187108
[ Info: iteration 42, average log likelihood -1.181944
[ Info: iteration 43, average log likelihood -1.179597
[ Info: iteration 44, average log likelihood -1.178106
[ Info: iteration 45, average log likelihood -1.176209
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.173935
[ Info: iteration 47, average log likelihood -1.187106
[ Info: iteration 48, average log likelihood -1.181949
[ Info: iteration 49, average log likelihood -1.179596
[ Info: iteration 50, average log likelihood -1.178102
┌ Info: EM with 100000 data points 50 iterations avll -1.178102
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2648671023538944
│     -1.2645814795168766
│      ⋮
└     -1.1781016522919543
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.176513
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.173879
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.174991
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.159263
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.126498
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.105473
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.099345
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     15
│     16
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.097185
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     10
│     17
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.091950
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.099004
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.100125
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     10
│     14
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.093738
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.091371
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      9
│     13
│     15
│     16
│     19
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.082175
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     10
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.094292
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     15
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.079250
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.090091
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      9
│     10
│     13
│     15
│     16
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.080589
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.095193
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     14
│     15
│     16
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.084072
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.081155
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     13
│     15
│     16
│     19
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.076237
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     17
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.098800
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.086324
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     17
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.075750
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     13
│     15
│     16
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.082546
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.089043
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     14
│     15
│     16
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.093683
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     17
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.083639
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     13
│     15
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.078060
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     17
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.082992
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     14
│     15
│     16
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.086539
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     10
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.090757
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     13
│     15
│     16
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.082671
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     17
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.090818
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.081925
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     17
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.071920
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     13
│     15
│     16
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.092083
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.094662
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     14
│     15
│     16
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.086034
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     17
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.079347
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│      ⋮
│     16
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.074491
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     17
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.092658
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     14
│     15
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.092387
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.082963
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     13
│     15
│     16
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.078389
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     17
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.087261
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.091704
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     17
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.077721
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     13
│     15
│     16
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.084242
┌ Info: EM with 100000 data points 50 iterations avll -1.084242
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1765130235664316
│     -1.1738785944451438
│      ⋮
└     -1.0842423395416334
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4152169699657065
│     -1.4152775910324373
│     -1.4152063205936458
│     -1.4146472006769744
│      ⋮
│     -1.0917041925819735
│     -1.0777210963704382
└     -1.0842423395416334
32×26 Array{Float64,2}:
 -0.289932     0.114071    -0.160933    0.0820912    0.369314     -0.00292219   0.0143413    -0.243548    -0.109018    -0.0711282   -0.120519     0.120158    -0.427199     0.255165     -0.0670463   -0.03094     -0.0939727    0.0269088   -0.109168    -0.04439    -0.0414439    0.0552105   -0.190107     0.0204294     0.172605    0.0153283
  0.0685254    0.0444948   -0.110042    0.100845     0.331127     -0.0205422   -0.169151     -0.113456    -0.0547687   -0.0602417    0.0246739   -0.117481     0.287002     0.0918841     0.0724885   -0.0269791   -0.0194186    0.0313181   -0.11802     -0.0166388  -0.0508289   -0.0392632   -0.089581     0.0959239     0.181664   -0.0367957
  0.00491277   0.0426019   -0.0418738  -0.117906     0.056454      0.0324149   -0.141692     -0.102081     0.268331     0.0552225   -0.0720346   -0.098413    -0.432816    -0.0526272    -0.107566     0.0319231    0.0182141    0.0819612   -0.0167687    0.140904   -0.111304     0.0672       0.142083    -0.104342      0.0543336   0.00551778
  0.0128494    0.0758075   -0.0432395   0.113734     0.123787      0.00477498  -0.102411     -0.385347     0.159351     0.0224574    0.187161    -0.0114943    0.280076    -0.0104354     0.275543     0.0282236    0.0338087    0.0678825   -0.0232533    0.090852    0.0232858    0.0598385    0.0474179   -0.0825067     0.142707   -0.0386918
  0.271297     0.0479161   -0.414331    0.0358699   -0.385153      0.0488451   -0.034049      0.108767    -0.206567     0.290889    -0.0313816   -0.0169895   -0.716018    -0.0057029    -0.279628     0.146139    -0.0894744    0.00875655  -0.165951    -0.171623   -0.0631684    0.102146     0.265942    -0.00130853    0.0809372  -0.133676
  0.204718     0.291797     0.36669     0.15321      0.121726      0.0515996    0.131311      0.102481    -0.317798     0.129739    -0.0402016   -0.00970917   0.562598    -0.157504      0.0253053    0.198606    -0.029183    -0.00455128  -0.15526     -0.125719   -0.0650156   -0.100196    -0.0613651   -0.0371738     0.14531    -0.126353
 -0.0176287   -0.0648964    0.221555   -0.0519882    0.0364152     0.067144     0.327399      0.119113     0.0289236    0.119436    -0.104805    -0.0251642   -0.308025     0.503401      0.312895     0.252891    -0.164328     0.00685411  -0.163551    -0.092403   -0.0642669   -0.295575    -0.0362731   -0.0404649    -0.0274717  -0.113843
  0.210796    -0.0850241    0.149324    0.0341657    0.0246086     0.0558532    0.16861       0.120226     0.45959      0.218205    -0.163675    -0.0155315    0.713573     0.32018      -0.440572     0.231077    -0.109387     0.0101703   -0.178817    -0.0966047  -0.0533145   -0.0193259    0.0992329   -0.00470105    0.145644   -0.111999
  0.0189862    0.0694966    0.029394   -0.166629     0.0114598     0.0910393   -0.000767615  -0.0735894    0.0944653    0.145304    -0.00260477   0.0256894   -0.12949     -0.0218857     0.0783941    0.0582791    0.0183253    0.197067    -0.0827095   -0.13668     0.137327     0.0696402   -0.0521866   -0.133511     -0.105339    0.0531143
 -0.126016    -9.515e-5    -0.0491986   0.0349013   -0.0324431     0.00755097  -0.213962     -0.166333     0.0528346   -0.200815    -0.0242675   -0.116718     0.0901945   -0.0214992    -0.0415478   -0.102952     0.184656    -0.0686262   -0.094893    -0.0313835  -0.0776756    0.134445    -0.0903071   -0.0434808    -0.0735885  -0.0888315
  0.0820844    0.0207682    0.20205    -0.426002    -0.316669      0.00678632   0.0639843     0.257889    -0.129176     0.100468     0.11045      0.0948788    0.0659446   -0.208574     -0.0835297   -0.0112176    0.143207    -0.0536227   -0.169122    -0.148844    0.00119988  -0.00937231  -0.115867     0.020202     -0.105982    0.053166
  0.0293813    0.139235     0.188648    0.151241    -0.251985      0.0213807    0.128322      0.259779    -0.0777053    0.0130214    0.0488567    0.0525455   -0.06579     -0.0879935    -0.0606853   -0.00726972   0.128533    -0.0207378   -0.168642    -0.0409782  -0.00362958  -0.0102738   -0.148106     0.109901     -0.109981    0.0589054
 -0.0437314    0.10713      0.253306   -0.0847124   -0.000992493  -0.24643     -0.014891      0.0737891   -0.119704    -0.0376208    0.0224964    0.061854    -0.0323153   -0.00188941    0.0139029   -0.065308     0.28951      0.0769565    0.135909    -0.0565602  -0.156795    -0.261773     0.0963302   -0.139886     -0.0152539  -0.0651375
  0.00305325   0.0453787   -0.0599955  -0.00625266   0.00411785    0.0130544   -0.0973695    -0.0529008   -0.0216241   -0.00918323   0.15111     -0.218131    -0.119745     0.158812     -0.0891414    0.0455313   -0.138181    -0.0479835    0.0822854   -0.121033   -0.0127668   -0.0772845   -0.0330811    0.0285643     0.0650877   0.058213
  0.0334301    0.0350955   -0.0955132  -0.0427772    0.059642     -0.263874    -0.0926485     0.113374    -0.230567     0.118497     0.151343     0.0643946    0.199606     0.0878221    -0.00522487  -0.190589    -0.0969099   -0.0684138   -0.0471244    0.0757533  -0.0527127    0.0731427   -0.112207    -0.47505      -0.0476327   0.0805618
  0.022681     0.0637867   -0.129713   -0.0438836    0.0796341     0.410308    -0.125167      0.102445    -0.194726    -0.194784     0.151       -0.156097     0.200527     0.077673      0.148473    -0.16837      0.0776195   -0.0694281   -0.010614     0.0772555  -0.0203998    0.0313096   -0.117665     0.38601      -0.107913    0.0380526
 -0.154352    -0.135396     0.0833667  -0.0307134    0.0180084    -0.0106325    0.101939     -0.155588    -0.0758001   -0.108435    -0.0200766   -0.0539525    0.237998    -0.0796168     0.0287558    0.0399005   -0.0931287    0.100149     0.100085    -0.0994181  -0.0143485   -0.099995    -0.059934     0.0371357    -0.195437    0.0630849
 -0.0394332    0.00451425   0.140938    0.0169709   -0.0344118    -0.0818746    0.0352864     0.192623    -0.001209    -0.0240378    0.185447    -0.0860176   -0.181706    -0.14736      -0.0720077   -0.0593363   -0.144411     0.0570955   -0.0895328    0.0296637  -0.0758155    0.0335026   -0.00925231   0.239236     -0.056851   -0.0809151
 -0.156756    -0.0138088    0.164937    0.305837     0.031225      0.0262805    0.0752722     0.0132697   -0.0175601    0.0473843    0.0103335    0.0100568    0.0876099   -0.0294603    -0.0486898    0.177661     0.0579272    0.0303071    0.177473     0.0322754  -0.0375845   -0.0137066    0.0810211    0.0922269    -0.0789737  -0.181059
 -0.00705841   0.0630319   -0.0154978   0.0154291   -0.0371928    -0.121116     0.023485     -0.0750775   -0.0769337    0.0917759   -0.081382     0.00117325  -0.00951351  -0.0598201     0.0388853   -0.0780362   -0.099906     0.0447808   -0.0473578    0.0839365   0.0333554    0.195857     0.0232264    0.0356145    -0.0951506   0.061515
  0.0861524   -0.00710338   0.190652    0.0667821    0.0678491    -0.132213     0.157882      0.0115018    0.0578937    0.00423562  -0.121453     0.010675    -0.0861497   -0.0526511    -0.0178629    0.0579745    0.016973    -0.0342909    7.38258e-5  -0.12467     0.206241    -0.101551    -0.0705426    0.0865966    -0.0799051  -0.0013171
  0.0630858    0.0319733    0.0245834  -0.0115501   -0.0366925    -0.152861     0.0702155     0.0418759    0.0694628    0.0707322   -0.0308823    0.0258332   -0.0603873   -0.0884388     0.0768627   -0.0728454   -0.0865919    0.0187618   -0.0426839    0.0505072   0.174255    -0.0170822    0.167113     0.190992     -0.160103   -0.100369
  0.0376405   -0.0197999    0.0732117  -0.031112    -0.00174747    0.178338     0.00557233   -0.0497481   -0.103129    -0.0651525   -0.0521146   -0.0469105   -0.0744791   -0.0276066    -0.016498    -0.107615    -0.0432893   -0.125093     0.0336746    0.0899007  -0.0366602    0.109013     0.0534268   -0.0892363     0.0822642   0.172706
  0.00551017   0.0812067   -0.102559   -0.0309558    0.0334793    -0.10971      0.065578      0.0172862    0.0693762    0.0266376    0.0860661   -0.0604322    0.064888     0.00690648    0.111952     0.0394142   -0.0655324    0.179765     0.00577589   0.0627693   0.0841783    0.293538    -0.0783261    0.141515     -0.0974684  -0.0347877
  0.106415    -0.0455104    0.0391726   0.0146432    0.0107315    -0.0395791   -0.0221304    -0.025092     0.016121     0.170005    -0.042674     0.0166549    0.0474358    0.00291076    0.120777     0.00189564   0.0852764   -0.00503752   0.0728138   -0.0244306  -0.0479133   -0.0354124    0.00420844  -0.0413666     0.0573191  -0.0867386
 -0.0365761   -0.0119614   -0.0567453   0.00749513  -0.027388      0.0622557   -0.0118128    -0.0441184    0.106059     0.0326924   -0.0526375    0.0706837   -0.0404096    0.0758645     0.107899     0.0245955    0.0301426   -0.109701     0.108247     0.0117522   0.0890163   -0.0532379   -0.118754     0.106334     -0.0423355   0.12113
  0.065598     0.165878    -0.252465   -0.0532981    0.161107     -0.0621396   -0.0755455     0.150404    -0.0644709   -0.234567    -0.268377     0.162232     0.1152      -0.0804059    -0.139161    -0.0563319   -0.00219347   0.0632692   -0.0312889   -0.162645   -0.068074     0.0544705   -0.11169      0.0374969     0.0168922  -0.0590809
 -0.0445562    0.0276745    0.0722155  -0.122688    -0.0472183    -0.145311    -0.0375265    -0.0131881    0.0717762    0.232405     0.112281    -0.0910943   -0.032839    -0.0260233    -0.0116498    0.0031699   -0.0153259   -0.0601452    0.00517546  -0.109487    0.0267638   -0.0232225   -0.0811472   -0.100245     -0.0471428  -0.0251272
 -0.0302717    0.0426145   -0.176233    0.0180914    0.13056      -0.0254185   -0.0360713    -0.0113922    0.250251    -0.0166747    0.100945     0.179697    -0.106475     0.0653583    -0.205124    -0.0347627    0.0549331    0.0906632   -0.185057    -0.0447727  -0.00340355  -0.0250074    0.102257     0.0685674     0.167074    0.0671453
 -0.0589899   -0.0202082    0.0182178  -0.0418338   -0.222387      0.0109616   -0.0880841    -0.0100741    0.00658829  -0.00661954  -0.188222     0.025025    -0.0901925   -0.155716     -0.131641     0.0982262    0.250656     0.127706    -0.0225802   -0.184376   -0.13024     -0.0977238   -0.170312     0.0681354    -0.124197    0.061259
  0.045726     0.0478214    0.0574353  -0.0604736   -0.0693016     0.146915     0.0804536     0.0216164    0.0321026    0.0665312    0.0482056    0.00141578  -0.0392032    0.000579232   0.0262945    0.0298701   -0.0213008    0.0854888    0.00587555   0.0503154  -0.0553311    0.0455276    0.0173976   -0.000260508   0.0104829   0.0115464
  0.0308911   -0.0229086   -0.0248707   0.0966486    0.00245429   -0.085813     8.27934e-5   -0.00147912   0.00183815  -0.0299944    0.0400641    0.00109392  -0.0616293   -0.0678545     0.101851    -0.0808886    0.0426348    0.132868     0.0148207    0.0401094   0.0797723   -0.028644    -0.0525329   -0.0734542    -0.0820473  -0.0334014[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.090335
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.064083
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.074887
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.056593
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.084859
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.068014
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.071033
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.060396
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.086358
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.068026
┌ Info: EM with 100000 data points 10 iterations avll -1.068026
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.451728e+05
      1       6.935443e+05      -1.516285e+05 |       32
      2       6.635828e+05      -2.996148e+04 |       32
      3       6.470761e+05      -1.650672e+04 |       32
      4       6.349161e+05      -1.215997e+04 |       32
      5       6.260514e+05      -8.864719e+03 |       32
      6       6.199884e+05      -6.063012e+03 |       32
      7       6.167028e+05      -3.285544e+03 |       32
      8       6.145297e+05      -2.173117e+03 |       32
      9       6.130665e+05      -1.463231e+03 |       32
     10       6.120251e+05      -1.041324e+03 |       32
     11       6.113564e+05      -6.687089e+02 |       32
     12       6.109638e+05      -3.926765e+02 |       32
     13       6.107136e+05      -2.501239e+02 |       32
     14       6.104856e+05      -2.280066e+02 |       32
     15       6.102111e+05      -2.744872e+02 |       32
     16       6.099337e+05      -2.774026e+02 |       32
     17       6.096765e+05      -2.572771e+02 |       32
     18       6.094880e+05      -1.884587e+02 |       32
     19       6.093565e+05      -1.315371e+02 |       32
     20       6.092411e+05      -1.153591e+02 |       32
     21       6.091240e+05      -1.171143e+02 |       32
     22       6.090033e+05      -1.206861e+02 |       32
     23       6.088798e+05      -1.234864e+02 |       31
     24       6.087796e+05      -1.002266e+02 |       32
     25       6.086896e+05      -9.004362e+01 |       31
     26       6.086184e+05      -7.118508e+01 |       31
     27       6.085563e+05      -6.206285e+01 |       30
     28       6.085123e+05      -4.398255e+01 |       31
     29       6.084758e+05      -3.647940e+01 |       30
     30       6.084414e+05      -3.441359e+01 |       31
     31       6.084078e+05      -3.362376e+01 |       30
     32       6.083681e+05      -3.972998e+01 |       31
     33       6.083208e+05      -4.730724e+01 |       30
     34       6.082456e+05      -7.519254e+01 |       31
     35       6.081455e+05      -1.000716e+02 |       32
     36       6.079637e+05      -1.817748e+02 |       32
     37       6.076917e+05      -2.720155e+02 |       32
     38       6.074118e+05      -2.798982e+02 |       32
     39       6.072491e+05      -1.627128e+02 |       30
     40       6.071769e+05      -7.218876e+01 |       32
     41       6.071335e+05      -4.337178e+01 |       31
     42       6.071102e+05      -2.330497e+01 |       31
     43       6.070895e+05      -2.072177e+01 |       30
     44       6.070731e+05      -1.639507e+01 |       31
     45       6.070582e+05      -1.488601e+01 |       31
     46       6.070441e+05      -1.415798e+01 |       29
     47       6.070233e+05      -2.079822e+01 |       28
     48       6.069992e+05      -2.407542e+01 |       31
     49       6.069735e+05      -2.569747e+01 |       32
     50       6.069454e+05      -2.811261e+01 |       30
K-means terminated without convergence after 50 iterations (objv = 606945.3906096742)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.316287
[ Info: iteration 2, average log likelihood -1.281584
[ Info: iteration 3, average log likelihood -1.254084
[ Info: iteration 4, average log likelihood -1.225464
[ Info: iteration 5, average log likelihood -1.187011
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.129017
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.105531
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.079731
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     11
│     21
│     23
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.064682
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.102602
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     10
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.101732
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.085821
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     22
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.060463
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.097197
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.060816
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     10
│     11
│     12
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.046302
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.096618
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.077372
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     10
│     16
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.048014
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.084013
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     21
│     22
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.083210
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.079272
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.070572
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      7
│     11
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.036781
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     22
│     26
│     27
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.083220
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.106075
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.095696
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.073135
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│      7
│     12
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.035622
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.114035
[ Info: iteration 31, average log likelihood -1.110707
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.070367
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     10
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.058023
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     12
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.066020
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     11
│     17
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.064745
[ Info: iteration 36, average log likelihood -1.092021
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     10
│     16
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.051619
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.097749
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.076945
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     12
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.057689
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.066801
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     21
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.079270
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     17
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.079134
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.088436
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     10
│     11
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.069302
[ Info: iteration 46, average log likelihood -1.109700
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.062703
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.058046
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│     17
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.055679
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     16
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.093463
┌ Info: EM with 100000 data points 50 iterations avll -1.093463
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0635809    0.159136    -0.247532     -0.0556151    0.160186    -0.0643727   -0.0754286    0.153407    -0.0615552    -0.219253    -0.265759      0.155764     0.111193    -0.081532    -0.135806    -0.0556418   -0.00224929    0.0579568  -0.0291521    -0.160492    -0.0673699    0.0488789   -0.112982     0.0363743    0.0187149   -0.0571782
 -0.0553061    0.0198765   -0.0788171    -0.00577687   0.0125659    0.0364739   -0.172929    -0.043314    -0.0661161    -0.131173     0.0595746    -0.089734     0.1412       0.0207789    0.0131948   -0.140121     0.0934383    -0.0704185  -0.0707251     0.0198665   -0.0635588    0.101902    -0.103573    -0.0462169   -0.0772839   -0.0220642
 -0.146703    -0.0141191    0.183256      0.296847     0.0476136    0.0370094    0.0532571    0.0227169   -0.000328329   0.0394993    0.0209732     0.0105617    0.0804169   -0.0226232   -0.0515831    0.145012     0.0732838     0.0212282   0.181687      0.025152    -0.0508236   -0.0575546    0.0815441    0.100177    -0.0386233   -0.203367
  0.00554952   0.0823432   -0.10226      -0.0313064    0.0332719   -0.107348     0.0653946    0.0192665    0.0673031     0.0270429    0.084981     -0.0605357    0.0652707    0.0078118    0.112333     0.0380043   -0.0692196     0.180838    0.0077682     0.0637635    0.0846278    0.293424    -0.0773536    0.140623    -0.0957315   -0.0336865
 -0.0511721    0.211205    -0.0386973    -0.0330318   -0.0455464   -0.0183901    0.0694198   -0.0589508   -0.199665      0.215023    -0.0912117    -0.0459135   -0.0401428   -0.0969594    0.223205    -0.0977477   -0.184977     -0.0548343  -0.0620703     0.0648695   -0.0444719    0.522899     0.0473208    0.00765091  -0.0524212    0.0137162
  0.055334     0.0761017    0.195426     -0.150702    -0.285104     0.0135928    0.0947632    0.256448    -0.102927      0.0594319    0.0823919     0.0756668    0.00298237  -0.149078    -0.0745667   -0.00950123   0.135972     -0.0375861  -0.167606     -0.0981645   -0.00175583  -0.00935857  -0.130594     0.0614822   -0.107797     0.0557752
  0.0190511    0.0714997    0.00812916   -0.154242     0.0105422    0.0966776   -0.00213641  -0.0871544    0.0787917     0.216204     0.0156714    -0.00128596  -0.167697    -0.0201553    0.0794008    0.0484082    0.000652766   0.218741   -0.129587     -0.130838     0.154268     0.0642141   -0.0703027   -0.168782    -0.0954056    0.0553137
 -0.0642119   -0.0884362    0.154497      0.0187649   -0.088702     0.273286     0.0108358   -0.00496936   0.125209      0.133403     0.0233787    -0.0668596   -0.110915     0.00207505   0.0597931    0.0870818   -0.0594126    -0.0189075   0.12945       0.11573     -0.051757    -0.0362601   -0.0743892    0.0318893    0.0831325    0.0682891
  0.198971    -0.15972      0.000431963  -0.0379452    0.119896    -0.0597534    0.151812     0.0418904    0.0507579     0.216403    -0.040416     -0.0086983   -0.0682175   -0.0237293    0.191435    -0.00955225   0.0778889     0.0445925  -0.0453525    -0.0630918   -0.0398091   -0.0950417    0.166724    -0.0763105    0.0396838   -0.219852
 -0.0215594    0.0564075    0.0509467    -0.150931    -0.0207806   -0.0612987   -0.0420911   -0.0105992    0.0567622     0.235486     0.000445989  -0.0609396   -0.029375    -0.049694     0.0246747   -0.0168249    0.0476219    -0.0252155   0.00535505   -0.0941525    0.0211873   -0.0106336   -0.0430417   -0.0733061   -0.0580973   -0.0191962
 -0.0416924    0.0992503    0.217472     -0.0857598    0.00227298  -0.19259     -0.0162972    0.0607715   -0.0970791    -0.0371668    0.0287814     0.0548013   -0.0307126    0.00302101   0.0274404   -0.0607885    0.260193      0.0785095   0.118571     -0.0503894   -0.129463    -0.207116     0.0729714   -0.144758    -0.0192698   -0.0499746
  0.0269729   -0.0139047    0.160004      0.0671837   -0.00819552   0.0394576    0.0831556    0.089249    -0.120495      0.0854306    0.0750631    -0.0357902   -0.0810235   -0.0371936    0.0418239   -0.0629383   -0.0453306     0.165997   -0.133083      0.137266     0.0415792   -0.0249907   -0.0277795   -0.0235543    0.0842556   -0.0315143
  0.0865589    0.0764054   -0.200931      0.0753515   -0.0548207   -0.173249     0.0174354   -0.0314333    0.0374987    -0.0362272   -0.10521      -0.0405759   -0.0675921   -0.190534     0.110524    -0.10373      0.16567       0.293093    0.0841703     0.0630672    0.120351    -0.0137486   -0.127147    -0.218335    -0.216831     0.0199643
 -0.062648     0.0764463   -0.0948244     0.0474666    0.236408     0.00827413  -0.0834291   -0.208609     0.0510833    -0.0255382   -0.00595363   -0.0154312   -0.0932479    0.0856167    0.034874    -0.00290008  -0.0149127     0.0471347  -0.0690358     0.0365557   -0.0415949    0.0370405   -0.032051    -0.0139429    0.133499    -0.0143423
  0.0528868   -0.0551866    0.0113085     0.00827363  -0.0375618   -0.221329    -0.0196641   -0.0826143   -0.0120966     0.0228585   -0.0802735     0.042537     0.0383708   -0.029036    -0.0606515   -0.192544    -0.114392      0.128031   -0.0705386     0.101105     0.117456     0.196037     0.0073959    0.0449871   -0.138995     0.138291
 -0.15212     -0.133109     0.081704     -0.035696     0.020089    -0.00798047   0.0971156   -0.147849    -0.0689458    -0.0954677   -0.0254284    -0.0395067    0.221372    -0.0702623    0.0242228    0.0556912   -0.0910346     0.0878624   0.0990301    -0.0959605   -0.0172926   -0.10793     -0.0601082    0.0360321   -0.194928     0.0560835
 -0.0463744   -0.0146273    0.16032       0.0400375   -0.026704     0.0510849    0.0624279    0.0956358   -0.121314      0.091016     0.0733661    -0.0591053   -0.0708281   -0.0608352    0.199369    -0.0645028   -0.160345      0.158448   -0.124905      0.0964149    0.0374241   -0.06096     -0.0119638   -0.0194476    0.077336    -0.0438408
  0.159522     0.0356546    0.107706      0.0387867   -0.030427     0.0565479    0.162783     0.113506     0.0262254     0.184967    -0.0917427    -0.0170318    0.110219     0.19451     -0.0925312    0.211788    -0.100997      0.0055766  -0.167002     -0.117076    -0.0609884   -0.0890926    0.05694     -0.0210257    0.0850407   -0.120431
  0.0865003   -0.00516262   0.186423      0.0622466    0.0695533   -0.130473     0.153483     0.0123151    0.0542621     0.00296483  -0.114793      0.0126616   -0.0823717   -0.0482774   -0.0205139    0.0553307    0.0160625    -0.0304     -0.000770551  -0.125885     0.203863    -0.103782    -0.0652939    0.0845132   -0.0814232   -0.00524053
  0.0413829    0.111637     0.0355161    -0.0700905   -0.153107     0.0404215    0.153504    -0.00709138   0.0165926     0.0687991    0.339838     -0.00272674  -0.023666     0.0596239   -0.0801896    0.0298489   -0.179167      0.108607   -0.107649     -0.0406857   -0.0607929    0.120262     0.0350085    0.00150441  -0.00962913  -0.0395599
  0.223799    -0.0540081    0.0669463    -0.0457659    0.0532782    0.0716444   -0.084168     0.00404123  -0.0621277     0.0300517   -0.0732072     0.0691602    0.0182503   -0.0757526    0.154681    -0.0115042    0.142951      0.100835    0.0877139     0.0620383   -0.0516991    0.016572     0.0142652   -0.0195754    0.113726    -0.0286258
  0.274378     0.124557     0.0369768    -0.185751     0.0581559    0.166905     0.109175     0.118831    -0.0047379    -0.143543    -0.17817       0.115959    -0.00567322  -0.0693996    0.123658     0.00767278   0.161679      0.152308    0.00878359    0.0267083   -0.0189675    0.0252373    0.17357     -0.0491815   -0.0438888    0.00869767
 -0.0151766   -0.0573629   -0.0335191     0.0559106   -0.0445845   -0.0625687   -0.0730224   -0.0276196    0.0309958    -0.0734822   -0.0175347     0.0531506   -0.0649145   -0.0665568   -0.0169917    0.00112047   0.163063      0.057178    0.021952     -0.0959378   -0.0128406   -0.0569701   -0.0696854    0.0321618   -0.140406    -0.00253849
 -0.0390309    0.00344777   0.140918      0.0160098   -0.0347217   -0.0798333    0.0337266    0.190618    -0.00224854   -0.0222445    0.184984     -0.0854123   -0.180594    -0.143858    -0.0715402   -0.0551609   -0.144413      0.0555667  -0.0895036     0.0296246   -0.0732872    0.0294104   -0.0094606    0.238197    -0.056901    -0.0801082
  0.0375389   -0.0138695    0.0663352    -0.0353594   -0.00185925   0.175373     0.00238678  -0.0515012   -0.102272     -0.0478627   -0.0510236    -0.0486335   -0.0636812   -0.0270568   -0.00171053  -0.100086    -0.041546     -0.115933    0.0223756     0.0866776   -0.0347534    0.108874     0.0524948   -0.0894293    0.0777222    0.174893
  0.096573    -0.0421511    0.0734078     0.0660394    0.0337909   -0.0506496   -0.0527002   -0.0388972   -0.089906      0.0669608    0.0922008     0.00443781   0.05027     -0.0750407    0.167385     0.00529226   0.0945838     0.0129534   0.180332      0.00102953  -0.0300534    0.0111132   -0.00437443   0.00221719   0.0652799   -0.0606694
 -0.166851     0.0376839    0.0349727     0.199233    -0.00756     -0.00879114   0.0806066   -0.0347167   -0.0374735     0.0299998   -0.0234798    -0.00807832   0.0050151   -0.0439803   -0.0580236    0.324201     0.0893498     0.0159478   0.0950691     0.0539246   -0.0428826   -0.224764     0.0608936    0.0745364   -0.100208    -0.0964984
 -0.0376367    0.00889205  -0.0490119    -0.00611965  -0.0199699    0.0817329   -0.0097327   -0.0619262    0.147355      0.0187156   -0.0605655     0.0717358   -0.0360084    0.0894271    0.11899      0.0324488    0.0333383    -0.0954063   0.116376      0.0180096    0.0993149   -0.0456556   -0.148352     0.107103    -0.0482478    0.142152
  0.0662882    0.0353388    0.0224196    -0.0133083   -0.0352728   -0.155365     0.0703598    0.0433779    0.0618803     0.0700071   -0.0311454     0.0255571   -0.0546859   -0.0867221    0.0784554   -0.0758619   -0.0876293     0.0200019  -0.0491013     0.0467466    0.17658     -0.0121399    0.169208     0.188999    -0.164786    -0.101901
 -0.0391675    0.0456858   -0.1802        0.0199984    0.126303    -0.0251023   -0.0376199   -0.0149222    0.251742     -0.0223686    0.0875105     0.173579    -0.117186     0.0585222   -0.206161    -0.0369069    0.0571489     0.107448   -0.179709     -0.0721144   -0.00920114  -0.0220857    0.0891401    0.0713513    0.196611     0.0615525
  0.0108024    0.0489883   -0.0670037    -0.0139001    0.00443889  -0.00477522  -0.0982868   -0.0589389   -0.0216415    -0.0119666    0.15278      -0.226933    -0.134363     0.165737    -0.0952606    0.047602    -0.139022     -0.0535606   0.0857951    -0.123329    -0.0158969   -0.0860971   -0.033368     0.0318932    0.0711448    0.0611321
 -0.0122318    0.0754904    0.0336816     0.0163191   -0.170256     0.00986418  -0.179971    -0.0862161    0.0960818     0.232142    -0.186692      0.0680084    0.168345     0.127163    -0.0260285    0.0190695    0.041855     -0.092903    0.0729204    -0.00820936  -0.0768671   -0.0125202   -0.178211    -0.0505154    0.0831138    0.054676[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.096804
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     11
│     12
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.048255
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│     10
│     16
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.030095
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.068125
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.055623
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│     10
│     11
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.021484
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.075037
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     10
│     11
│     12
│      ⋮
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.036554
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      7
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.049424
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     10
│     11
│     12
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.050502
┌ Info: EM with 100000 data points 10 iterations avll -1.050502
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.146943      0.0991474    0.0196202    -0.00809539   0.0331203    0.0637061    0.109512    -0.0353615    0.0541777   0.00180577   0.156059     0.0884681    0.0516005    -0.0225525    -0.0499374    0.159574     -0.0917902   -0.0473913    -0.168512     -0.110446    -0.0250485    0.00543405  -0.0675707  -0.0949064    0.0100439   -0.0680538
 -0.123297      0.0411945   -0.0400986    -0.00709758   0.287465     0.121977     0.0380733    0.0166839    0.0313423  -0.0107002    0.131347    -0.0482185   -0.0431108    -0.173072      0.0942752    0.0370339     0.0893412   -0.0451075    -0.086354      0.0602538    0.250349     0.00645423  -0.0925223   0.0707375   -0.24824      0.114395
 -0.0582518     0.0976692   -0.00843929   -0.121761    -0.0707085   -0.0948366   -0.198447     0.255683    -0.0439319   0.0342592   -0.0644227   -0.00589063  -0.0787235    -0.126035     -0.068765    -0.0496572    -0.195191     0.0330695    -0.22199       0.131707     0.040433    -0.0323777    0.0636051  -0.115338     0.00715742  -0.0721605
 -0.0588315     0.0452747   -0.048101      0.220061     0.155641    -0.269194    -0.105171    -0.0497041   -0.118499    0.0101983   -0.0692002    0.171373    -0.0137356    -0.0182041     0.158661    -0.119726     -0.114126     0.394387     -0.0136372     0.00177433  -0.00434592  -0.20043     -0.22481     0.0128206   -0.0927556    0.0968159
  0.116572     -0.0558735   -0.0146709     0.0224166    0.0570185    0.0613745    0.0239187    0.163601     0.0118876  -0.231598    -0.00576685  -0.0599721    0.00591241   -0.194862      0.0566498    0.0560387     0.132433    -0.0649272    -0.0926567    -0.0538744    0.0117306    0.0348354   -0.0658967   0.0810481    0.0260365   -0.0204357
  0.029588      0.0646916    0.195418      0.18464     -0.160484    -0.109321    -0.076598    -0.0163587   -0.247003    0.0272198   -0.118376     0.0535943   -0.000575852  -0.167684     -0.0359487   -0.0460196    -0.0818518    0.0132059     0.0567678    -0.159093    -0.0511532    0.0848313    0.206031   -0.164181    -0.126837    -0.205993
  0.105902     -0.0816542    0.0960617     0.0870884    0.021503     0.0563529    0.0740004   -0.00176157  -0.0759862   0.0166771   -0.103679    -0.0867607   -0.0445574     0.00266127    0.145545     0.165006     -0.0142715   -0.137795      0.143456      0.0796051   -0.110699     0.136259     0.0398581   0.210879    -0.181056     0.0493235
  0.113469     -0.0523899    0.0477765     0.181078     0.084535    -0.127981     0.0914701    0.120661    -0.0707697   0.0117864   -0.0256161    0.176916    -0.0441876    -0.0353565     0.0337905   -0.105486     -0.115493     0.032072      0.00553814    0.0528415   -0.0148203    0.0489954   -0.0168372   0.193022    -0.217914    -0.0503085
  0.020607      0.0722955    0.0539127     0.0687096    0.0439847    0.211257    -0.0195768    0.148287    -0.132192    0.00359216   0.0724403   -0.154301    -0.0557962    -0.0382881    -0.0388396   -0.178897     -0.0323411   -0.137526     -0.146547     -0.169332     0.0993574    0.0260001   -0.106386    0.00911065   0.0906122   -0.0389093
  0.0877032     0.0910781    0.171075     -0.0752263    0.0054176    0.0663126    0.0622969    0.0352196    0.0868896  -0.289119    -0.0805699   -0.109958     0.0732512    -0.0267692     0.0146149    0.110898      0.0153597   -0.0353425    -0.0365609    -0.0946078   -0.0275559   -0.0383889   -0.0326545   0.00959066  -0.147816    -0.105781
  0.103937     -0.156945    -0.0815401    -0.00109545  -0.0427738   -0.0448474    0.0848929    0.152386    -0.0116065   0.0431394   -0.0115827    0.0864611    0.110151      0.121933     -0.016825    -0.00581148    0.00510308   0.154469     -0.0987483    -0.226893     0.233078    -0.0125171    0.0428462  -0.0490537    0.0406156    0.0976585
 -0.109965      0.0147022   -0.0188842     0.0973131    0.0114634   -0.142258     0.0888396   -0.099502     0.0969566   0.0797828    0.00543591  -0.0144235    0.0100268    -0.0575139    -0.00586035   0.120415      0.00563331   0.133644      0.118385     -0.186535     0.0884424   -0.0397817   -0.108203   -0.0341595    0.0382336    0.159079
  0.025409     -0.0263063   -0.117355      0.025905    -0.0278591    0.0169975    0.0368923   -0.160088    -0.0341373   0.0481264    0.190363     0.0202855    0.129036      0.0383196     0.0498837   -0.0570611     0.169073    -0.0833025    -0.054066      0.0794212   -0.0921594    0.0544869   -0.0416137   0.0498194    0.113466     0.0630167
  0.0168741     0.0345362   -0.0371362     0.0997815    0.222709    -0.0437412   -0.0450921   -0.0064643   -0.0834781   0.0488336   -0.0582924    0.0062697    0.111326     -0.241794     -0.0585716    0.033974     -0.180416     0.0621057    -0.0231999    -0.103501     0.0514466    0.16013     -0.125956    0.102786     0.0474031    0.143545
 -0.0227608    -0.0425424   -0.0790535     0.238491    -0.25679      0.0541971   -0.0157032   -0.0919603    0.13775     0.126788     0.111074    -0.128865    -0.0578199     0.0810931    -0.113027     0.0258706     0.0131587    0.104324      0.0133914     0.0887483    0.118304    -0.178205     0.0310056   0.0477123   -0.0538596   -0.0730332
  0.046215      0.0115118    0.0225294    -0.0442491    0.144211    -0.0774224   -0.0341316   -0.119673    -0.196183   -0.0322084   -0.0347917    0.0376345   -0.045681      0.113778      0.0665927    0.126709      0.179269    -0.0421453    -0.100511      0.0360236   -0.0529937    0.0118274    0.0631514  -0.0860754   -0.117617     0.0597464
 -0.0847483     0.018055     0.027949     -0.115089    -0.15481     -0.118148     0.0486907   -0.0412477   -0.0310755  -0.0156209    0.114963     0.177953     0.102642     -0.0600239    -0.0890977   -0.132403     -0.0479719   -0.0343129     0.0140702    -0.0516882   -0.0334642   -0.136361     0.0732917  -0.030494    -0.0797559   -0.0710065
  0.0136872     0.037152     0.061579     -0.0680875    0.129918     0.172135    -0.0159739    0.0898027   -0.206256    0.0765595   -0.122685     0.0950288    0.0107993    -0.100153     -0.00695866  -0.231704      0.0463725    0.0522705     0.0129012     0.188119     0.00829009  -0.119888    -0.0895195   0.126175    -0.136999     0.0426417
 -0.0313228    -0.0938805   -0.0120602    -0.0136895   -0.158087    -0.123307    -0.00542378  -0.119413    -0.0906183   0.0914366    0.0709527    0.0403523   -0.0558842     0.109004      0.0522366    0.11272       0.262016     0.0830898     0.1016       -0.0395767   -0.171907     0.0783039   -0.0171452   0.0101471    0.0329823   -0.044045
 -0.0351033    -0.0776214   -0.0519872     0.00212388   0.144163    -0.00931758  -0.0419966    0.0655897   -0.0585958  -0.0868314    0.0215954   -0.15379      0.0124517    -0.143097      0.108758     0.0430379     0.0973423   -0.21623       0.115796     -0.0673853   -0.0109642    0.12236     -0.0206092   0.180678    -0.0793281    0.278106
  0.250435      0.0105426   -0.0208268    -0.0451469    0.0545985   -0.0537664   -0.0882845   -0.14806      0.0184188   0.0859442   -0.0267129    0.037114     0.0410496    -0.134261      0.185229    -0.000234159   0.0792109    0.000351784   0.072285     -0.0897309    0.0799122   -0.00991294  -0.136862   -0.0331368    0.0899622    0.0159545
  0.149827     -0.00428517   0.0960291    -0.069874     0.0748529   -0.0497771   -0.0318507    0.0322309    0.101506   -0.0603905    0.0664144    0.0786377    0.0453754    -0.0549932     0.0694621   -0.0250094    -0.0880822   -0.0633694     0.0507961     0.121718    -0.173033     0.126785     0.013998    0.0161274   -0.0597942   -0.11706
 -0.222125      0.0124641   -0.0698415    -0.00655691  -0.00569918   0.256336     0.283113     0.097153    -0.0800153   0.107098    -0.0218271   -0.0624498   -0.0966712     0.0585531    -0.0418627    0.0486896    -0.127366     0.172378     -0.0328267     0.0270091    0.117186    -0.165742     0.125774    0.0424911   -0.0490589   -0.016863
 -0.0178236     0.0222175    0.147053     -0.250219     0.0610119    0.14272     -0.181149     0.00482582  -0.107507    0.0820214    0.0691106    0.187198     0.0544279    -0.0672255    -0.00678131  -0.124562      0.0916111   -0.0132814    -0.0482574    -0.0420228   -0.247037     0.0640986   -0.0287073  -0.191707     0.0371627   -0.086991
 -0.0100056     0.162496     0.0335805     0.0315327    0.106968    -0.00219498  -0.0740516   -0.0939466   -0.034406   -0.0526987   -0.119943    -0.0458944    0.0739532     0.0197543     0.131709     0.113144      0.0718802   -0.0781751    -0.135662     -0.153858    -0.177839     0.0528002   -0.0552368  -0.0494389    0.107848     0.019722
 -0.218381     -0.095417    -0.138404      0.10356      0.0889059   -0.13055     -0.0387197   -0.0570938    0.179614   -0.115686     0.0135004   -0.0165263    0.0885668    -0.000679971   0.00828583  -0.0984547     0.0634868    0.0445876    -0.0223333    -0.0397377   -0.0208113   -0.0522484    0.199203    0.149411    -0.112893     0.111593
 -0.0112103     0.0985091    0.0439894     0.096734    -0.00963084   0.0407238   -0.027496    -0.0771693   -0.0814497  -0.0379455    0.00177563   0.00342582  -0.0792671     0.115613     -0.00660209   0.145015     -0.0612634    0.0374717     0.0219331     0.00915835  -0.0464951    0.0633496   -0.0350735   0.0388149   -0.00785329   0.131491
  0.0304778     0.0668512    0.0180693     0.158913    -0.0368389    0.0751554    0.0766085   -0.181975     0.0533789  -0.0358379   -0.187309     0.0435645    0.0799245     0.0791212     0.0590174    0.0236443    -0.0659579   -0.0137666    -0.0209292     0.0318844   -0.137689    -0.00818311  -0.0266075   0.111921     0.00927685   0.131977
  0.0483539    -0.0772905   -0.0672597     0.0630683    0.0576138   -0.0838492    0.133791     0.00943758   0.0532452   0.0716065    0.049337     0.183633     0.0619648     0.130148      0.0417931    0.0298217     0.227312    -0.0141147    -0.000661928  -0.089417     0.0257649   -0.0668765    0.0615602  -0.147384     0.112125    -0.0570413
  0.0685969    -0.244234     0.00392668   -0.0552365    0.0113846   -0.0423633   -0.121795    -0.0227595    0.0423559   0.134193    -0.0205295    0.129112     0.0535911     0.093288     -0.0285953    0.0557816     0.0579722   -0.0313604     0.0128181    -0.00325461   0.0965294   -0.100373    -0.203984    0.00606672  -0.0197866   -0.0161006
  0.0436607     0.0529981    0.0662727     0.0885127    0.112947    -0.0259758    0.0506075    0.0638388    0.0104759   0.00874857  -0.0881596    0.0647449   -0.173398     -0.0901638     0.0481886    0.181248     -0.0286204    0.017989     -0.103311      0.00950225  -0.0389797   -0.102581     0.0246477  -0.0548943   -0.0635645    0.10219
  0.000495027  -0.155898    -0.000195808   0.0479018   -0.142345    -0.00860042  -0.0853254    0.00154911   0.157325    0.0364908    0.0429378   -0.01375      0.0570654     0.211437     -0.186831     0.247363     -0.172184    -0.117569     -0.0771133    -0.266764    -0.0439659    0.02691      0.0769256   0.0596738   -0.022568    -0.14828kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4214820732374764
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421504
[ Info: iteration 2, average log likelihood -1.421433
[ Info: iteration 3, average log likelihood -1.421378
[ Info: iteration 4, average log likelihood -1.421313
[ Info: iteration 5, average log likelihood -1.421231
[ Info: iteration 6, average log likelihood -1.421119
[ Info: iteration 7, average log likelihood -1.420942
[ Info: iteration 8, average log likelihood -1.420619
[ Info: iteration 9, average log likelihood -1.420016
[ Info: iteration 10, average log likelihood -1.419050
[ Info: iteration 11, average log likelihood -1.417918
[ Info: iteration 12, average log likelihood -1.417035
[ Info: iteration 13, average log likelihood -1.416566
[ Info: iteration 14, average log likelihood -1.416369
[ Info: iteration 15, average log likelihood -1.416294
[ Info: iteration 16, average log likelihood -1.416265
[ Info: iteration 17, average log likelihood -1.416254
[ Info: iteration 18, average log likelihood -1.416249
[ Info: iteration 19, average log likelihood -1.416247
[ Info: iteration 20, average log likelihood -1.416246
[ Info: iteration 21, average log likelihood -1.416246
[ Info: iteration 22, average log likelihood -1.416245
[ Info: iteration 23, average log likelihood -1.416245
[ Info: iteration 24, average log likelihood -1.416244
[ Info: iteration 25, average log likelihood -1.416244
[ Info: iteration 26, average log likelihood -1.416244
[ Info: iteration 27, average log likelihood -1.416244
[ Info: iteration 28, average log likelihood -1.416244
[ Info: iteration 29, average log likelihood -1.416243
[ Info: iteration 30, average log likelihood -1.416243
[ Info: iteration 31, average log likelihood -1.416243
[ Info: iteration 32, average log likelihood -1.416243
[ Info: iteration 33, average log likelihood -1.416243
[ Info: iteration 34, average log likelihood -1.416243
[ Info: iteration 35, average log likelihood -1.416243
[ Info: iteration 36, average log likelihood -1.416242
[ Info: iteration 37, average log likelihood -1.416242
[ Info: iteration 38, average log likelihood -1.416242
[ Info: iteration 39, average log likelihood -1.416242
[ Info: iteration 40, average log likelihood -1.416242
[ Info: iteration 41, average log likelihood -1.416242
[ Info: iteration 42, average log likelihood -1.416242
[ Info: iteration 43, average log likelihood -1.416242
[ Info: iteration 44, average log likelihood -1.416242
[ Info: iteration 45, average log likelihood -1.416242
[ Info: iteration 46, average log likelihood -1.416242
[ Info: iteration 47, average log likelihood -1.416242
[ Info: iteration 48, average log likelihood -1.416242
[ Info: iteration 49, average log likelihood -1.416242
[ Info: iteration 50, average log likelihood -1.416242
┌ Info: EM with 100000 data points 50 iterations avll -1.416242
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4215036463306512
│     -1.4214325583009837
│      ⋮
└     -1.4162418212465446
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416263
[ Info: iteration 2, average log likelihood -1.416190
[ Info: iteration 3, average log likelihood -1.416134
[ Info: iteration 4, average log likelihood -1.416069
[ Info: iteration 5, average log likelihood -1.415996
[ Info: iteration 6, average log likelihood -1.415918
[ Info: iteration 7, average log likelihood -1.415844
[ Info: iteration 8, average log likelihood -1.415779
[ Info: iteration 9, average log likelihood -1.415728
[ Info: iteration 10, average log likelihood -1.415690
[ Info: iteration 11, average log likelihood -1.415662
[ Info: iteration 12, average log likelihood -1.415641
[ Info: iteration 13, average log likelihood -1.415623
[ Info: iteration 14, average log likelihood -1.415609
[ Info: iteration 15, average log likelihood -1.415595
[ Info: iteration 16, average log likelihood -1.415582
[ Info: iteration 17, average log likelihood -1.415570
[ Info: iteration 18, average log likelihood -1.415558
[ Info: iteration 19, average log likelihood -1.415546
[ Info: iteration 20, average log likelihood -1.415535
[ Info: iteration 21, average log likelihood -1.415523
[ Info: iteration 22, average log likelihood -1.415512
[ Info: iteration 23, average log likelihood -1.415501
[ Info: iteration 24, average log likelihood -1.415491
[ Info: iteration 25, average log likelihood -1.415481
[ Info: iteration 26, average log likelihood -1.415472
[ Info: iteration 27, average log likelihood -1.415463
[ Info: iteration 28, average log likelihood -1.415455
[ Info: iteration 29, average log likelihood -1.415448
[ Info: iteration 30, average log likelihood -1.415441
[ Info: iteration 31, average log likelihood -1.415435
[ Info: iteration 32, average log likelihood -1.415430
[ Info: iteration 33, average log likelihood -1.415425
[ Info: iteration 34, average log likelihood -1.415420
[ Info: iteration 35, average log likelihood -1.415416
[ Info: iteration 36, average log likelihood -1.415412
[ Info: iteration 37, average log likelihood -1.415409
[ Info: iteration 38, average log likelihood -1.415405
[ Info: iteration 39, average log likelihood -1.415402
[ Info: iteration 40, average log likelihood -1.415400
[ Info: iteration 41, average log likelihood -1.415397
[ Info: iteration 42, average log likelihood -1.415394
[ Info: iteration 43, average log likelihood -1.415392
[ Info: iteration 44, average log likelihood -1.415389
[ Info: iteration 45, average log likelihood -1.415387
[ Info: iteration 46, average log likelihood -1.415384
[ Info: iteration 47, average log likelihood -1.415382
[ Info: iteration 48, average log likelihood -1.415380
[ Info: iteration 49, average log likelihood -1.415377
[ Info: iteration 50, average log likelihood -1.415375
┌ Info: EM with 100000 data points 50 iterations avll -1.415375
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4162631223624924
│     -1.416189727307831
│      ⋮
└     -1.4153751331584767
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415383
[ Info: iteration 2, average log likelihood -1.415339
[ Info: iteration 3, average log likelihood -1.415300
[ Info: iteration 4, average log likelihood -1.415253
[ Info: iteration 5, average log likelihood -1.415193
[ Info: iteration 6, average log likelihood -1.415117
[ Info: iteration 7, average log likelihood -1.415024
[ Info: iteration 8, average log likelihood -1.414917
[ Info: iteration 9, average log likelihood -1.414802
[ Info: iteration 10, average log likelihood -1.414688
[ Info: iteration 11, average log likelihood -1.414579
[ Info: iteration 12, average log likelihood -1.414481
[ Info: iteration 13, average log likelihood -1.414394
[ Info: iteration 14, average log likelihood -1.414320
[ Info: iteration 15, average log likelihood -1.414258
[ Info: iteration 16, average log likelihood -1.414207
[ Info: iteration 17, average log likelihood -1.414165
[ Info: iteration 18, average log likelihood -1.414131
[ Info: iteration 19, average log likelihood -1.414104
[ Info: iteration 20, average log likelihood -1.414080
[ Info: iteration 21, average log likelihood -1.414060
[ Info: iteration 22, average log likelihood -1.414043
[ Info: iteration 23, average log likelihood -1.414028
[ Info: iteration 24, average log likelihood -1.414014
[ Info: iteration 25, average log likelihood -1.414002
[ Info: iteration 26, average log likelihood -1.413990
[ Info: iteration 27, average log likelihood -1.413979
[ Info: iteration 28, average log likelihood -1.413969
[ Info: iteration 29, average log likelihood -1.413959
[ Info: iteration 30, average log likelihood -1.413950
[ Info: iteration 31, average log likelihood -1.413941
[ Info: iteration 32, average log likelihood -1.413933
[ Info: iteration 33, average log likelihood -1.413925
[ Info: iteration 34, average log likelihood -1.413917
[ Info: iteration 35, average log likelihood -1.413910
[ Info: iteration 36, average log likelihood -1.413903
[ Info: iteration 37, average log likelihood -1.413896
[ Info: iteration 38, average log likelihood -1.413889
[ Info: iteration 39, average log likelihood -1.413883
[ Info: iteration 40, average log likelihood -1.413877
[ Info: iteration 41, average log likelihood -1.413872
[ Info: iteration 42, average log likelihood -1.413867
[ Info: iteration 43, average log likelihood -1.413861
[ Info: iteration 44, average log likelihood -1.413857
[ Info: iteration 45, average log likelihood -1.413852
[ Info: iteration 46, average log likelihood -1.413847
[ Info: iteration 47, average log likelihood -1.413843
[ Info: iteration 48, average log likelihood -1.413839
[ Info: iteration 49, average log likelihood -1.413834
[ Info: iteration 50, average log likelihood -1.413830
┌ Info: EM with 100000 data points 50 iterations avll -1.413830
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4153827308491769
│     -1.4153389985283085
│      ⋮
└     -1.4138302245175245
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413835
[ Info: iteration 2, average log likelihood -1.413781
[ Info: iteration 3, average log likelihood -1.413731
[ Info: iteration 4, average log likelihood -1.413674
[ Info: iteration 5, average log likelihood -1.413602
[ Info: iteration 6, average log likelihood -1.413511
[ Info: iteration 7, average log likelihood -1.413403
[ Info: iteration 8, average log likelihood -1.413279
[ Info: iteration 9, average log likelihood -1.413147
[ Info: iteration 10, average log likelihood -1.413015
[ Info: iteration 11, average log likelihood -1.412891
[ Info: iteration 12, average log likelihood -1.412778
[ Info: iteration 13, average log likelihood -1.412678
[ Info: iteration 14, average log likelihood -1.412592
[ Info: iteration 15, average log likelihood -1.412517
[ Info: iteration 16, average log likelihood -1.412453
[ Info: iteration 17, average log likelihood -1.412397
[ Info: iteration 18, average log likelihood -1.412348
[ Info: iteration 19, average log likelihood -1.412304
[ Info: iteration 20, average log likelihood -1.412266
[ Info: iteration 21, average log likelihood -1.412232
[ Info: iteration 22, average log likelihood -1.412201
[ Info: iteration 23, average log likelihood -1.412173
[ Info: iteration 24, average log likelihood -1.412147
[ Info: iteration 25, average log likelihood -1.412123
[ Info: iteration 26, average log likelihood -1.412100
[ Info: iteration 27, average log likelihood -1.412080
[ Info: iteration 28, average log likelihood -1.412060
[ Info: iteration 29, average log likelihood -1.412042
[ Info: iteration 30, average log likelihood -1.412024
[ Info: iteration 31, average log likelihood -1.412008
[ Info: iteration 32, average log likelihood -1.411992
[ Info: iteration 33, average log likelihood -1.411977
[ Info: iteration 34, average log likelihood -1.411963
[ Info: iteration 35, average log likelihood -1.411949
[ Info: iteration 36, average log likelihood -1.411936
[ Info: iteration 37, average log likelihood -1.411923
[ Info: iteration 38, average log likelihood -1.411910
[ Info: iteration 39, average log likelihood -1.411898
[ Info: iteration 40, average log likelihood -1.411886
[ Info: iteration 41, average log likelihood -1.411875
[ Info: iteration 42, average log likelihood -1.411863
[ Info: iteration 43, average log likelihood -1.411852
[ Info: iteration 44, average log likelihood -1.411841
[ Info: iteration 45, average log likelihood -1.411830
[ Info: iteration 46, average log likelihood -1.411819
[ Info: iteration 47, average log likelihood -1.411808
[ Info: iteration 48, average log likelihood -1.411798
[ Info: iteration 49, average log likelihood -1.411787
[ Info: iteration 50, average log likelihood -1.411776
┌ Info: EM with 100000 data points 50 iterations avll -1.411776
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4138347916897727
│     -1.4137809162044277
│      ⋮
└     -1.4117764277008367
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411775
[ Info: iteration 2, average log likelihood -1.411707
[ Info: iteration 3, average log likelihood -1.411641
[ Info: iteration 4, average log likelihood -1.411562
[ Info: iteration 5, average log likelihood -1.411464
[ Info: iteration 6, average log likelihood -1.411342
[ Info: iteration 7, average log likelihood -1.411198
[ Info: iteration 8, average log likelihood -1.411041
[ Info: iteration 9, average log likelihood -1.410880
[ Info: iteration 10, average log likelihood -1.410721
[ Info: iteration 11, average log likelihood -1.410571
[ Info: iteration 12, average log likelihood -1.410432
[ Info: iteration 13, average log likelihood -1.410306
[ Info: iteration 14, average log likelihood -1.410191
[ Info: iteration 15, average log likelihood -1.410088
[ Info: iteration 16, average log likelihood -1.409994
[ Info: iteration 17, average log likelihood -1.409908
[ Info: iteration 18, average log likelihood -1.409830
[ Info: iteration 19, average log likelihood -1.409758
[ Info: iteration 20, average log likelihood -1.409691
[ Info: iteration 21, average log likelihood -1.409629
[ Info: iteration 22, average log likelihood -1.409571
[ Info: iteration 23, average log likelihood -1.409517
[ Info: iteration 24, average log likelihood -1.409465
[ Info: iteration 25, average log likelihood -1.409417
[ Info: iteration 26, average log likelihood -1.409371
[ Info: iteration 27, average log likelihood -1.409327
[ Info: iteration 28, average log likelihood -1.409286
[ Info: iteration 29, average log likelihood -1.409246
[ Info: iteration 30, average log likelihood -1.409208
[ Info: iteration 31, average log likelihood -1.409173
[ Info: iteration 32, average log likelihood -1.409139
[ Info: iteration 33, average log likelihood -1.409107
[ Info: iteration 34, average log likelihood -1.409077
[ Info: iteration 35, average log likelihood -1.409049
[ Info: iteration 36, average log likelihood -1.409022
[ Info: iteration 37, average log likelihood -1.408998
[ Info: iteration 38, average log likelihood -1.408974
[ Info: iteration 39, average log likelihood -1.408953
[ Info: iteration 40, average log likelihood -1.408932
[ Info: iteration 41, average log likelihood -1.408913
[ Info: iteration 42, average log likelihood -1.408895
[ Info: iteration 43, average log likelihood -1.408877
[ Info: iteration 44, average log likelihood -1.408861
[ Info: iteration 45, average log likelihood -1.408845
[ Info: iteration 46, average log likelihood -1.408830
[ Info: iteration 47, average log likelihood -1.408816
[ Info: iteration 48, average log likelihood -1.408802
[ Info: iteration 49, average log likelihood -1.408789
[ Info: iteration 50, average log likelihood -1.408777
┌ Info: EM with 100000 data points 50 iterations avll -1.408777
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4117748566813846
│     -1.4117065828081705
│      ⋮
└     -1.4087766069762933
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4214820732374764
│     -1.4215036463306512
│     -1.4214325583009837
│     -1.4213778099875243
│      ⋮
│     -1.4088023900162003
│     -1.4087892539550022
└     -1.4087766069762933
32×26 Array{Float64,2}:
 -0.0209989  -0.775982    0.195327    0.155151   -0.397293    -0.57772    -0.438904     0.488374   -0.239034    -0.658752    -0.106393    -0.868101    -0.262969    -0.115644     0.144393    0.479599     0.0554544   0.0493447    0.118887    -0.109665     0.0651918   0.11242     -0.724282   -0.0229505   -0.160788    0.623169
 -0.255533   -0.19161     0.232104    0.755836   -0.602767     0.217936   -0.17956      0.588968   -0.288429    -0.422358    -0.0570405   -0.022365    -0.409953    -0.618319    -0.183943   -0.7852       0.661459   -0.473948     1.1823      -1.09148      0.2356      0.910754     0.873037   -0.350601    -0.246867   -0.4994
  0.388126   -1.18268     0.334057   -0.312099    0.356631     0.235116    0.330619     0.206456   -0.189503    -0.00749878  -0.229072     0.166595    -0.725239    -0.462641     0.660173    0.302472     0.0303294  -0.498938     0.205175     0.00378314  -0.825557    0.125311     0.452798    0.170768     0.113091    0.486026
  0.210595   -0.198594    0.603448   -0.113304    0.476124    -0.252057   -0.641581    -0.243308   -0.144116     0.182181     0.244835    -0.122794    -0.0552047    0.0825273    0.554938   -0.0700304   -0.019972   -0.47001      0.0611408   -0.0102428   -0.217589    0.71927      0.337177    0.372822    -0.255178    0.33419
  0.305278   -0.471752    0.199773    0.639887    0.109211    -0.451519    0.142442    -0.636393    0.483938    -0.0684755   -0.875664     0.197238     0.0484429   -0.33958     -0.665704    0.137185    -0.0983678  -0.40435     -0.548699    -0.212529    -0.351983    0.270493    -0.0503597  -0.339013     0.150699   -0.0700554
 -0.789641    0.199597    0.231698    0.430293   -0.156522    -0.104185   -0.25325     -0.0844848  -0.0588157    0.377504    -0.336979    -0.399738     0.150024    -0.542071    -0.215632   -0.0951154   -0.0991421   0.53961     -0.211397    -0.130046    -0.298408   -0.564489    -0.153849    0.276982     0.069923    0.249769
 -0.272761    0.479844   -0.0387398   0.200742   -0.0621452    0.131285    0.516334     0.39775     0.0721857   -0.931078    -0.215371    -0.136103     0.18282     -0.076411    -0.656379    0.174897    -0.244826    0.461457     0.0878574    0.353208    -0.379843   -0.145327    -0.159255    0.436563     0.0196108   0.292043
 -0.28917    -0.21108     0.728411   -0.563842   -0.231949     0.169863    0.612753    -0.38489    -0.207112    -0.482264    -0.544579    -0.0616763    0.125255     0.387161    -0.222363    0.641063     0.583301   -0.0717234    0.312841    -0.428382    -0.669072    0.459642    -0.152692    0.540867    -0.0558259  -0.381459
 -0.0851899   0.705592    0.248257    0.538117    0.350916    -0.0829489  -0.00196566  -1.07011    -1.2938       0.100289     0.256993    -0.471823    -0.785781     0.359738     0.198121    0.0241087   -0.249423   -0.723908    -0.302654     0.03304      0.142109    0.324442     0.0720197  -1.05615      0.185755    0.703263
 -0.037302    0.479541    0.346912   -0.398581    0.38402     -0.0343916   0.0848203   -0.127232    0.0285964   -0.192736     0.310096    -0.435349    -0.110483     0.219094     0.0855187   0.492078    -0.133864    0.180187    -0.518936     0.103103    -0.107159   -0.194197    -0.431627   -0.626989     0.0879573  -0.415299
 -0.166693   -0.0215171   0.165409    0.206674    0.0881696    0.0485568   0.161774    -0.357086   -0.660087    -0.319597     0.337012    -0.112941     0.179861     0.523697    -0.0513297  -0.671677    -0.570146   -0.775883     0.15366      0.384175    -0.643549   -0.342692    -0.120879    0.712575    -0.736079    0.354514
 -0.475602    0.0359903  -0.509573   -0.136499   -0.764497     0.156771    0.131756     0.773703   -0.41683      0.0792157    0.38146      0.0496917   -0.574863     0.22106      0.869875    0.0724782    0.135574    0.663233     0.438439     0.31789      0.243309   -0.394842    -0.0128363   0.223688    -0.428502    0.068253
  0.428097   -0.204341   -0.358009   -0.0326368   0.00189452  -0.219166   -0.148828    -0.0889667  -0.0659552    0.422032     0.305009    -0.0060247    0.00178223   0.0156799    0.40659    -0.377965     0.480937   -0.57994     -0.299079    -0.23633      0.228197   -0.0639794   -0.379981   -0.286778    -0.0959819  -0.0963943
  0.0444179  -0.116931    0.0863104  -0.196859    0.0990892    0.101352   -0.327349    -0.0160047   0.0937337    0.0365444    0.00374917   0.0540809   -0.0575247   -0.00456745   0.120863    0.335079    -0.0861382   0.272446     0.158159    -0.137724     0.169181    0.233718     0.514073    0.00686956   0.15233    -0.037539
  0.0441543   0.536127   -0.617847    0.487879    0.4584       0.555036    0.949717    -0.494669    0.00760658   0.274576    -0.166651     0.252207     0.21952     -0.0648892   -0.013278   -0.274767     0.170318    0.551645    -0.261329    -0.0825449    0.23864     0.0177389   -0.333714    0.0771299   -0.0459028   0.348408
  0.500502    0.760488   -0.14921     0.0840758   0.249403     0.492715    0.713853    -0.315876    0.417734     0.30322      0.314644     0.673557     0.178048     0.0225305   -0.256967   -0.0732997   -0.220936   -0.503071    -0.160262     0.137982    -0.0063004   0.288487     0.738039   -0.136482     0.540101   -0.591905
  0.484353   -0.296937   -0.0239129   0.15199    -0.366426     0.182657    0.111613    -0.0969529  -0.471908    -0.675173     0.04916      0.496125    -0.597551     0.213557    -0.168247    0.0201747   -0.549851   -0.45928     -0.17928     -0.113657     0.130296    0.305859    -0.167641   -0.42616     -0.375935   -0.290915
 -0.13167     0.150548   -0.655703    0.197866   -0.641643    -0.0834477  -0.343643    -0.522586   -0.0179402   -0.116027     0.117829     0.290929     0.445467     0.581313    -0.203273   -0.22937     -0.0301329   0.107894     0.159516    -0.492793     0.349099    0.494581    -0.106866   -0.321232    -0.18343    -0.131992
  0.444988    0.0220149   0.0434335   0.0331316  -0.110736    -0.0243802   0.374472     0.378108   -0.656401     0.00279453  -0.436022     0.877197     0.17043     -0.231057    -0.327043   -0.751999     0.100545   -0.582358     0.013598    -0.137192     0.327243   -0.0734918   -0.184131    0.497993    -0.624759    0.520491
 -0.0273797  -0.281423    0.310854    0.172727   -0.303105    -0.681694   -0.239155     0.143353   -0.138391     0.790373    -0.285432     1.05439     -0.089723    -0.346889    -0.376149   -0.309525    -0.69171    -0.162517     0.0712343    0.504673     0.515619   -0.334895     0.247086    0.42611     -0.0293794  -0.145302
  0.231848   -0.12236    -0.346897    0.439254    0.382624     0.122216   -0.406766    -0.140638    0.0303719    0.395874     0.142468     0.0947326    0.139017    -0.475463     0.365463   -0.196764    -0.104539   -0.0423786   -0.227357    -0.082872     0.212074   -0.0720462   -0.152987   -0.0990744   -0.624796    0.137334
  0.353029    0.132124   -0.0258907   0.0465871   0.467661    -0.266673    0.0326584    0.0533209  -0.00779449   0.254627     0.311765    -0.243741     0.211971    -0.450268     0.3955      0.128206     0.60449    -0.00155055   0.128277    -0.0796686   -0.13315    -0.0767305    0.0664682   0.0726091    0.694038    0.318242
  0.0338158  -0.162533   -0.068412   -0.0789106   0.108377     0.0455772   0.1725      -0.353658   -0.0876615    0.0418506   -0.0831189   -0.140814    -0.104809     0.0762018    0.199772    0.173223     0.255685   -0.0502209   -0.285903    -0.105203    -0.0732073   0.0800784   -0.213371   -0.198944    -0.120662    0.0721599
  0.0531176  -0.0113516  -0.0273395   0.0605467  -0.0863246   -0.128356   -0.07082      0.220207    0.0544001    0.0951498    0.0666691    0.131346     0.0910023   -0.0771804   -0.0140469   0.007032    -0.0418293   0.00238627   0.102213    -0.0945892    0.156525   -0.141647    -0.0720415  -0.121434     0.0543906  -0.156898
 -0.114843   -0.507701   -0.48572    -0.213939    0.0148193    0.0686702   0.0618126    0.55869     0.79664      0.234291    -0.507433     0.207836     0.330367    -0.606523     0.0838915   0.468059     0.809596    0.753039    -0.0675691   -0.241908     0.313468   -0.17398     -0.0828582   0.202455    -0.0611758  -0.156714
 -0.200852   -0.537604    0.0591659  -0.688226    0.0432401   -0.339115   -0.0562079    0.328091    0.192549     0.242569    -0.321574    -0.00392151  -0.262927     0.354035     0.0388682   0.00565349   0.786338   -0.130332     0.130336    -0.144911     0.422108    0.00504659  -0.153823   -0.216115     0.084475   -0.103653
 -0.178903   -0.216063    0.368654   -0.59017    -0.310926    -0.295253   -0.91115      0.741403    0.478706    -0.356465     0.658396     0.373672     0.305962     0.246594     0.179024    0.0105431   -0.579227   -0.225532     0.261112     0.380317    -0.206671   -0.298745     0.23894    -0.21505      0.0518854  -0.335404
  0.0958685   0.409461   -0.510952   -0.0486845  -0.141299     0.269994   -0.159246     0.563237    0.282069     0.254258     0.724417    -0.208483     0.440718     0.129423    -0.105367    0.0989268    0.0423993   0.202951    -0.11394     -0.164153     0.291587   -0.557509    -0.384553   -0.182396    -0.0790126  -0.434939
 -0.164045   -0.0678779   0.0809605   0.377301   -0.102394     0.0475563   0.0476584    0.0834848  -0.0327456   -0.451279    -0.251863    -0.0823137    0.0515124   -0.13815     -0.224663   -0.0759727   -0.28312     0.0447773    0.105019     0.0801673   -0.380681    0.116817     0.039328    0.434058    -0.226675    0.37233
 -0.0468183   0.482071    0.0229999  -0.138273    0.219096     0.139314    0.270144    -0.19931     0.0161252   -0.140392     0.188378    -0.0321371    0.167536     0.274258    -0.16194    -0.304672    -0.160554    0.0475108    0.00669738   0.254092    -0.325401   -0.0675073   -0.0157164   0.324163     0.120937    0.29519
 -0.207375    0.313147    0.288099   -0.222369   -0.0586543    0.297818   -0.0579187    0.0645571  -0.0778837    0.333421    -0.142389     0.20933      0.160535     0.0905403    0.107629   -0.224748     0.127439    0.477198     0.0306881    0.0105283    0.272811    0.0426915    0.72227     0.0320702    0.165438   -0.529794
 -0.203954    0.200338    0.234521    0.0288924   0.032234     0.203335    0.071583     0.0422576   0.00423615  -0.228509    -0.374326     0.049062    -0.400897     0.0653998   -0.359526    0.756884    -0.354866    0.428169     0.335816     0.0458815    0.106376    0.0437625    0.4423      0.25232      0.439742    0.132696[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408764
[ Info: iteration 2, average log likelihood -1.408753
[ Info: iteration 3, average log likelihood -1.408741
[ Info: iteration 4, average log likelihood -1.408730
[ Info: iteration 5, average log likelihood -1.408719
[ Info: iteration 6, average log likelihood -1.408709
[ Info: iteration 7, average log likelihood -1.408699
[ Info: iteration 8, average log likelihood -1.408689
[ Info: iteration 9, average log likelihood -1.408679
[ Info: iteration 10, average log likelihood -1.408669
┌ Info: EM with 100000 data points 10 iterations avll -1.408669
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.969506e+05
      1       7.107929e+05      -1.861577e+05 |       31
      2       6.934962e+05      -1.729675e+04 |       31
      3       6.871720e+05      -6.324174e+03 |       31
      4       6.840705e+05      -3.101488e+03 |       31
      5       6.821814e+05      -1.889110e+03 |       31
      6       6.808643e+05      -1.317127e+03 |       31
      7       6.799206e+05      -9.436560e+02 |       31
      8       6.792075e+05      -7.131156e+02 |       31
      9       6.786473e+05      -5.602297e+02 |       31
     10       6.781697e+05      -4.775501e+02 |       31
     11       6.778068e+05      -3.629716e+02 |       31
     12       6.775186e+05      -2.881865e+02 |       31
     13       6.772775e+05      -2.410839e+02 |       31
     14       6.770652e+05      -2.123089e+02 |       31
     15       6.768891e+05      -1.760339e+02 |       31
     16       6.767470e+05      -1.421085e+02 |       31
     17       6.766169e+05      -1.301424e+02 |       31
     18       6.765037e+05      -1.131719e+02 |       31
     19       6.763912e+05      -1.125057e+02 |       31
     20       6.762975e+05      -9.366691e+01 |       31
     21       6.762149e+05      -8.267868e+01 |       31
     22       6.761369e+05      -7.794265e+01 |       31
     23       6.760587e+05      -7.818073e+01 |       31
     24       6.759885e+05      -7.025157e+01 |       31
     25       6.759278e+05      -6.070683e+01 |       31
     26       6.758693e+05      -5.852435e+01 |       31
     27       6.758160e+05      -5.326145e+01 |       31
     28       6.757628e+05      -5.322057e+01 |       31
     29       6.757047e+05      -5.808401e+01 |       31
     30       6.756515e+05      -5.317389e+01 |       31
     31       6.755964e+05      -5.513122e+01 |       31
     32       6.755417e+05      -5.470120e+01 |       31
     33       6.754875e+05      -5.416753e+01 |       31
     34       6.754298e+05      -5.771192e+01 |       31
     35       6.753701e+05      -5.966199e+01 |       31
     36       6.753101e+05      -6.000717e+01 |       31
     37       6.752569e+05      -5.327804e+01 |       31
     38       6.752090e+05      -4.784938e+01 |       31
     39       6.751618e+05      -4.718081e+01 |       31
     40       6.751067e+05      -5.511079e+01 |       31
     41       6.750521e+05      -5.461870e+01 |       31
     42       6.749992e+05      -5.286241e+01 |       31
     43       6.749509e+05      -4.834519e+01 |       31
     44       6.749031e+05      -4.775541e+01 |       31
     45       6.748602e+05      -4.291732e+01 |       31
     46       6.748222e+05      -3.798157e+01 |       31
     47       6.747880e+05      -3.425296e+01 |       31
     48       6.747600e+05      -2.796172e+01 |       31
     49       6.747317e+05      -2.831545e+01 |       31
     50       6.747019e+05      -2.983908e+01 |       31
K-means terminated without convergence after 50 iterations (objv = 674701.8675716659)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
ERROR: LoadError: LoadError: UndefVarError: ind2sub not defined
Stacktrace:
 [1] sanitycheck!(::GMM{Float64,Array{Float64,2}}) at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:54
 [2] GMMk(::Int64, ::Array{Float64,2}; kind::Symbol, nInit::Int64, nIter::Int64, sparse::Int64) at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:140
 [3] #GMM#7 at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:36 [inlined]
 [4] top-level scope at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:29
 [5] include(::String) at ./client.jl:439
 [6] top-level scope at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/test/runtests.jl:7
 [7] include(::String) at ./client.jl:439
 [8] top-level scope at none:6
in expression starting at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:22
in expression starting at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/test/runtests.jl:7
err = ProcessFailedException(Base.Process[Process(`/opt/julia/bin/julia -Cnative -J/opt/julia/lib/julia/sys.so -g1 --code-coverage=none --color=no --compiled-modules=yes --check-bounds=yes --inline=yes --startup-file=no --track-allocation=none --eval 'append!(empty!(Base.DEPOT_PATH), ["/home/pkgeval/.julia", "/opt/julia/local/share/julia", "/opt/julia/share/julia", "/usr/local/share/julia"])
append!(empty!(Base.DL_LOAD_PATH), String[])

cd("/home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/test")
append!(empty!(ARGS), String[])
include("/home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/test/runtests.jl")
'`, ProcessExited(1))])
ERROR: Package GaussianMixtures errored during testing
Stacktrace:
 [1] pkgerror(::String, ::Vararg{String,N} where N) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Types.jl:54
 [2] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Operations.jl:1471
 [3] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:313
 [4] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:300
 [5] #test#66 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:294 [inlined]
 [6] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:294 [inlined]
 [7] #test#65 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:293 [inlined]
 [8] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:293 [inlined]
 [9] test(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:292
 [10] test(::String) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:292
 [11] top-level scope at none:13
