Julia Version 1.5.0-DEV.17
Commit 9b7ea2f0b3 (2020-01-07 01:14 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed URIParser ────────── v0.4.0
 Installed PDMats ───────────── v0.9.10
 Installed Arpack_jll ───────── v3.5.0+2
 Installed ScikitLearnBase ──── v0.5.0
 Installed Parameters ───────── v0.12.0
 Installed StaticArrays ─────── v0.12.1
 Installed DataStructures ───── v0.17.7
 Installed SortingAlgorithms ── v0.3.1
 Installed SpecialFunctions ─── v0.9.0
 Installed CMake ────────────── v1.1.2
 Installed LegacyStrings ────── v0.4.1
 Installed BinaryProvider ───── v0.5.8
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed JLD ──────────────── v0.9.1
 Installed FileIO ───────────── v1.2.1
 Installed OpenBLAS_jll ─────── v0.3.7+3
 Installed FillArrays ───────── v0.8.2
 Installed Rmath ────────────── v0.6.0
 Installed QuadGK ───────────── v2.3.1
 Installed DataAPI ──────────── v1.1.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed Distances ────────── v0.8.2
 Installed Distributions ────── v0.22.0
 Installed OrderedCollections ─ v1.1.0
 Installed Missings ─────────── v0.4.3
 Installed StatsFuns ────────── v0.9.3
 Installed Compat ───────────── v2.2.0
 Installed BinDeps ──────────── v1.0.0
 Installed Blosc ────────────── v0.5.1
 Installed Clustering ───────── v0.13.3
 Installed StatsBase ────────── v0.32.0
 Installed NearestNeighbors ─── v0.4.4
 Installed HDF5 ─────────────── v0.12.5
 Installed Arpack ───────────── v0.4.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.0
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+3
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_CthJ6X/Project.toml`
 [no changes]
  Updating `/tmp/jl_CthJ6X/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_dPrrhI/Project.toml`
 [no changes]
  Updating `/tmp/jl_dPrrhI/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_IV0EsV/Project.toml`
 [no changes]
  Updating `/tmp/jl_IV0EsV/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_LufFDL/Project.toml`
 [no changes]
  Updating `/tmp/jl_LufFDL/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_2EfXt3/Project.toml`
 [no changes]
  Updating `/tmp/jl_2EfXt3/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_2EfXt3/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.0
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.477751619789889e6, [13506.246178751084, 86493.75382124892], [-2903.524688239064 19754.76690763127 -8665.321170028408; 2819.500268291941 -19461.594009034303 8757.010146666988], [[13133.815993421502 -3296.670693273467 991.5811109270969; -3296.670693273467 33279.64548347302 -9046.166140982048; 991.5811109270969 -9046.166140982048 16444.18118913962], [87120.19047055008 2902.1508880473307 -1268.2195436730724; 2902.1508880473307 67262.09046667759 9406.027811651344; -1268.2195436730726 9406.027811651344 82908.24576517384]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.427228e+03
      1       9.850214e+02      -4.422066e+02 |        6
      2       9.076696e+02      -7.735180e+01 |        4
      3       8.720276e+02      -3.564204e+01 |        0
      4       8.720276e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 872.0275941801347)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.062840
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.765115
[ Info: iteration 2, lowerbound -3.606636
[ Info: iteration 3, lowerbound -3.436949
[ Info: iteration 4, lowerbound -3.257174
[ Info: iteration 5, lowerbound -3.092693
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.957736
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.844955
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.761120
[ Info: iteration 9, lowerbound -2.701387
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.645811
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.572874
[ Info: iteration 12, lowerbound -2.500407
[ Info: iteration 13, lowerbound -2.437721
[ Info: iteration 14, lowerbound -2.387825
[ Info: iteration 15, lowerbound -2.350495
[ Info: iteration 16, lowerbound -2.323889
[ Info: iteration 17, lowerbound -2.309379
[ Info: iteration 18, lowerbound -2.308668
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302915
[ Info: iteration 20, lowerbound -2.299259
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Jan  7 09:33:45 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Jan  7 09:33:53 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Tue Jan  7 09:33:55 2020: EM with 272 data points 0 iterations avll -2.062840
5.8 data points per parameter
, Tue Jan  7 09:33:57 2020: GMM converted to Variational GMM
, Tue Jan  7 09:34:05 2020: iteration 1, lowerbound -3.765115
, Tue Jan  7 09:34:05 2020: iteration 2, lowerbound -3.606636
, Tue Jan  7 09:34:05 2020: iteration 3, lowerbound -3.436949
, Tue Jan  7 09:34:05 2020: iteration 4, lowerbound -3.257174
, Tue Jan  7 09:34:05 2020: iteration 5, lowerbound -3.092693
, Tue Jan  7 09:34:05 2020: dropping number of Gaussions to 7
, Tue Jan  7 09:34:05 2020: iteration 6, lowerbound -2.957736
, Tue Jan  7 09:34:05 2020: dropping number of Gaussions to 6
, Tue Jan  7 09:34:05 2020: iteration 7, lowerbound -2.844955
, Tue Jan  7 09:34:05 2020: dropping number of Gaussions to 5
, Tue Jan  7 09:34:05 2020: iteration 8, lowerbound -2.761120
, Tue Jan  7 09:34:05 2020: iteration 9, lowerbound -2.701387
, Tue Jan  7 09:34:05 2020: dropping number of Gaussions to 4
, Tue Jan  7 09:34:05 2020: iteration 10, lowerbound -2.645811
, Tue Jan  7 09:34:05 2020: dropping number of Gaussions to 3
, Tue Jan  7 09:34:05 2020: iteration 11, lowerbound -2.572874
, Tue Jan  7 09:34:05 2020: iteration 12, lowerbound -2.500407
, Tue Jan  7 09:34:05 2020: iteration 13, lowerbound -2.437721
, Tue Jan  7 09:34:05 2020: iteration 14, lowerbound -2.387825
, Tue Jan  7 09:34:05 2020: iteration 15, lowerbound -2.350495
, Tue Jan  7 09:34:05 2020: iteration 16, lowerbound -2.323889
, Tue Jan  7 09:34:05 2020: iteration 17, lowerbound -2.309379
, Tue Jan  7 09:34:05 2020: iteration 18, lowerbound -2.308668
, Tue Jan  7 09:34:05 2020: dropping number of Gaussions to 2
, Tue Jan  7 09:34:05 2020: iteration 19, lowerbound -2.302915
, Tue Jan  7 09:34:05 2020: iteration 20, lowerbound -2.299259
, Tue Jan  7 09:34:05 2020: iteration 21, lowerbound -2.299256
, Tue Jan  7 09:34:05 2020: iteration 22, lowerbound -2.299254
, Tue Jan  7 09:34:05 2020: iteration 23, lowerbound -2.299254
, Tue Jan  7 09:34:05 2020: iteration 24, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 25, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 26, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 27, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 28, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 29, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 30, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 31, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 32, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 33, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 34, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 35, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 36, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 37, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 38, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 39, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 40, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 41, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 42, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 43, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 44, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 45, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 46, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 47, lowerbound -2.299253
, Tue Jan  7 09:34:05 2020: iteration 48, lowerbound -2.299253
, Tue Jan  7 09:34:06 2020: iteration 49, lowerbound -2.299253
, Tue Jan  7 09:34:06 2020: iteration 50, lowerbound -2.299253
, Tue Jan  7 09:34:06 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398587, 178.0450922260141]
β = [95.95490777398587, 178.0450922260141]
m = [2.000229257775368 53.85198717246127; 4.250300733269908 79.28686694436182]
ν = [97.95490777398587, 180.0450922260141]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119484225 -0.008953123827345831; 0.0 0.012748664777409217], [0.1840415554748479 -0.007644049042327596; 0.0 0.008581705166333458]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9746295342121458
avll from llpg:  -0.9746295342111598
avll direct:     -0.9746295342111598
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9773085656764154
avll from llpg:  -0.9773085656764156
avll direct:     -0.9773085656764156
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.13009       0.102626    -0.123797    -0.0110244    0.113682    -0.266197     0.0378258   -0.00638057   0.0863746    0.00680244  -0.0496004   -0.0188938   -0.00339706  -0.0602523    0.113081     0.25576       0.0567194    0.126213     0.134352     0.210083     0.0283994    0.0757831    0.0502136    0.0706427   -0.0190006   -0.0539551
  0.134999      0.0168291    0.0813304   -0.034798     0.141291     0.0549792   -0.0735702   -0.0430592   -0.118229    -0.103289     0.137547     0.026099     0.10992     -0.0892784    0.128236    -0.0112206    -0.0520832   -0.125669    -0.0401569   -0.00764803  -0.00734339  -0.0473983    0.0861669   -0.0211072    0.0515414    0.0877172
  0.108263      0.038393     0.00784457   0.0645095    0.0806227   -0.157725     0.053268    -0.0242025   -0.0385296    0.116662    -0.0869204    0.155938     0.0945354    0.0388921    0.00711825  -0.0773257    -0.0582416    0.160961    -0.158926    -0.105657    -0.0160378   -0.12181      0.0614485   -0.0160617   -0.0365311   -0.00298741
  0.0236135    -0.159712    -0.0534123   -0.0576082    0.0532885   -0.0565463    0.12922      0.0456436   -0.00683725  -0.127214     0.133848     0.120167    -0.131332     0.216421    -0.039101     0.00491258    0.108448    -0.0435139   -0.103494    -0.00467889   0.0527281   -0.0247138    0.183272     0.0213432   -0.0626282    0.0765415
  0.100841     -0.0522308    0.106232     0.0619322   -0.234664     0.0464296    0.13336      0.148887    -0.0983753   -0.00729929   0.105357     0.0302166    0.00273088   0.0721474    0.090753     0.0280168    -0.101556     0.206835    -0.126578     0.0176056   -0.0729804   -0.0814532    0.0723347    0.0342369    0.0785963    0.0290556
 -0.0531444    -0.101466    -0.0946777    0.0454302   -0.0295656    0.121368     0.0690555    0.0403945    0.178579     0.166627     0.034698     0.0232688    0.0424839   -0.039775     0.0321391   -0.0252891    -0.0870555    0.0188848    0.214591    -0.0657692    0.151147    -0.00370693   0.159518    -0.041492    -0.124448    -0.10761
  0.200996     -0.0804028    0.0399913   -0.0144588   -0.0906191   -0.0893453    0.0961281   -0.00603528  -0.0708883   -0.0393485   -0.123145     0.161031     0.0602722    0.0171585   -0.0885978    0.0580195    -0.106612    -0.0475467    0.182168    -0.106655    -0.0444218   -0.0894093    0.0131475    0.00909756   0.00297294  -0.0290769
 -0.111337     -0.052986     0.0225806    0.155956     0.0913284   -0.220602    -0.11478     -0.022207     0.192502    -0.120184     0.0208297   -0.0749508    0.0313393    0.0495032   -0.029227     0.0821492    -0.156703    -0.0714524   -0.16522      0.15499      0.00220548   0.140097    -0.132961    -0.0937917    0.0129094    0.00563269
  0.0812306    -0.0491836   -0.054616    -0.0181586   -0.142569    -0.0342467    0.0998515   -0.00369545  -0.0767003   -0.139479     0.0247586   -0.00512007  -0.196468    -0.079355     0.047862    -0.0377206    -0.0655143    0.00646408   0.117684     0.101637     0.127994     0.0685187   -0.123999    -0.141509    -0.0926851   -0.0421037
  0.185661     -0.0790252    0.038253     0.0881335   -0.0134719    0.0436158    0.139355     0.0903742   -0.171044     0.0121964   -0.118154     0.222399     0.106151    -0.209751    -0.181091    -0.113223     -0.0255093   -0.0712211   -0.0860294    0.0168426   -0.0389428   -0.0293533    0.182577     0.0673455   -0.163193     0.0814126
 -0.0651937    -0.0893188    0.0434038    0.183167     0.0158796   -0.048238    -0.0964803   -0.113112     0.0863594    0.120566     0.0928809    0.00761749   0.0318885    0.207767    -0.194627    -0.0278743    -0.152946    -0.0656578    0.0187834    0.107827     0.00932787  -0.0605143   -0.183813    -0.0455028    0.00963695  -0.116615
  0.168473     -0.0360793    0.0727279   -0.0276385    0.00735451   0.0759924   -0.0685381    0.0264084   -0.103877     0.0712004    0.0195207    0.00209189   0.0499737   -0.0653976   -0.258951     0.00358925    0.0133242    0.114768     0.0404894    0.0397594   -0.0616354    0.0136345    0.0926925   -0.0570658   -0.00861742  -0.124422
 -0.0571807    -0.0622531    0.0507351   -0.115668     0.0247401   -0.0426312   -0.118499     0.12404     -0.144104     0.104455     0.0665931   -0.0320881    0.0628839   -0.0856797   -0.00513173   0.069515      0.0915869   -0.0767219    0.218815    -0.0201815    0.0504788   -0.0795445   -0.0605396   -0.180891    -0.0574263    0.178396
 -0.0741378     0.098826     0.01716      0.0627038    0.067259     0.138462     0.0148539   -0.00807987  -0.0652072    0.149709     0.0107924    0.258528     0.0340814    0.00692339  -0.152102    -0.119288      0.0285328   -0.0678674   -0.0698202    0.0104517    0.00403866  -0.0265598   -0.0173962   -0.0885817   -0.0502186   -0.0886888
  0.0419936     0.0600417   -0.0708506   -0.132921     0.0172569    0.0606424    0.143103     0.0463661   -0.2545      -0.118164     0.0167944   -0.0498574    0.070832    -0.123706     0.113286     0.0320863     0.0636188   -0.120554    -0.0550689   -0.0724239    0.093128     0.0527718   -0.00477146   0.0094124   -0.0881545    0.201847
  0.229461     -0.0142336    0.0941016   -0.179144    -0.182386    -0.0465276    0.0150692    0.0653795   -0.0139191    0.023845     0.172427    -0.00675654  -0.0334894   -0.065487     0.0587449    0.123485      0.0276417    0.0011207   -0.0457001   -0.00896997  -0.147748     0.174867     0.0533709   -0.00931917   0.0628754   -0.155717
 -0.166252     -0.131105    -0.0683431   -0.0372671    0.162142     0.113279     0.0547455    0.00480978  -0.00359933  -0.167254    -0.0211491    0.100571    -0.141484     0.0605503   -0.0137352    0.0747884     0.00439661   0.0224995    0.314391     0.0363368   -0.0326528    0.0895892    0.110888     0.167732    -0.0629507   -0.0319909
  0.0736484     0.00236767  -0.14181     -0.0722999    0.0167029    0.0433681    0.0107193    0.0576656    0.0192531   -0.0487749    0.0658451    0.0466258    0.166795     0.0280131    0.0550579   -0.222038     -0.0284073    0.0335377   -0.00656551  -0.0162251    0.168697     0.0488961    0.0587215    0.256766     0.0858182   -0.087071
 -0.0568275    -0.140517     0.0489645   -0.00725675   0.170908     0.164112    -0.0381316    0.106734    -0.0632581    0.0226101   -0.0466212   -0.108785     0.0201372    0.155344    -0.118231    -0.0214846     0.00245073   0.158401    -0.0806494    0.0450458   -0.107851    -0.086272    -0.0432099    0.0942577    0.132628    -0.0879617
 -0.039805      0.104154     0.0203831   -0.147172     0.127189     0.115911    -0.251424    -0.11034      0.215907    -0.0523977   -0.019274     0.0651665    0.082905     0.119        0.0690849    0.0209192     0.135781    -0.0192286    0.0116786    0.0244206   -0.0165034   -0.0772775    0.0515148    0.0415789    0.0128329    0.00761683
  0.0634848     0.0490497   -0.0132708   -0.00910122   0.063548    -0.0992081   -0.124293    -0.157557    -0.0896457   -0.0508341    0.0197495    0.0805322   -0.0898179   -0.00334202   0.0828251   -0.00139347    0.0816434   -0.0917466   -0.0343395   -0.321664     0.0224419    0.0869179    0.0796146   -0.0698558   -0.164485     0.122
  0.0215749    -0.133354    -0.0298294   -0.207037    -0.0750312   -0.0556648   -0.00272375  -0.0222499    0.0107166   -0.180483    -0.227045     0.0641912   -0.0292031   -0.073835    -0.0490158   -0.0574442    -0.0368525   -0.127591    -0.0975009   -0.0792893   -0.0642484    0.0564313   -0.108982     0.0615634    0.0473042    0.0536777
  0.0104643     0.0431716   -0.127753     0.00611992  -0.0868887   -0.0236613   -0.156255    -0.0214198    0.0121656    0.106416    -0.0209519    0.00214986  -0.0121702   -0.0466827   -0.0366718   -0.0123617     0.0489475   -0.0546522   -0.159934    -0.172993     0.198732    -0.0641539   -0.0425228    0.00370693   0.0460102   -0.0359272
  0.149638      0.0672845   -0.0455795    0.00879913  -0.0892219   -0.161001     0.0270321    0.052088    -0.0121612    0.0615504    0.053112     0.0208945    0.0610175    0.0157687   -0.0374437    0.104277      0.0767096   -0.0285032   -0.0537256   -0.117623    -0.0191311   -0.0813482   -0.0141432   -0.152291     0.0196817   -0.115244
 -0.0803143     0.121663    -0.0323249   -0.120698    -0.131614     0.0619686   -0.27526     -0.0362217   -0.0972689    0.0987672   -0.0877935    0.0808434   -0.0256763   -0.0222098   -0.0468076    0.014484     -0.0634429    0.0919702    0.0996185   -0.104       -0.156941     0.177764     0.0666628   -0.118358     0.0829042   -0.21201
  0.0839618     0.126629     0.11707     -0.0796455    0.159347    -0.0244404    0.0854656   -0.166645    -0.0794473   -0.100652     0.0849376   -0.13189     -0.0189299   -0.114733    -0.085738    -0.0255628     0.0013508    0.0676582    0.188021    -0.005412     0.0408583    0.0736824    0.0379576   -0.0554098    0.0265089   -0.0458434
  0.175449      0.0973965    0.0624103   -0.0906       0.102106    -0.00868701   0.033214     0.00895873  -0.0115792   -0.10597     -0.0942376    0.278657    -0.0685576   -0.107594     0.0313193    0.0341321     0.0228449    0.141215    -0.149691     0.0310346    0.339176     0.0837203   -0.050722    -0.0259145   -0.0494916    0.0891882
  0.103922      0.19568     -0.0240704    0.00818374  -0.0507055   -0.088316     0.0368848   -0.0408469   -0.0291756    0.0244614    0.146353     0.0194172   -0.097039     0.144226     0.0461133    0.000465652  -0.106901     0.0325812   -0.0273618   -0.0356495    0.0552787   -0.0205513    0.148466    -0.27506     -0.00809776  -0.0954738
 -0.000147128   0.0283401    0.0296202    0.0423443    0.0798616   -0.0268215    0.0129627    0.00914367  -0.0562891   -0.0745401    0.0858264    0.0745582    0.103708     0.129921     0.111046    -0.0558488    -0.0424701   -0.163973     0.0390233    0.0631761   -0.0522541    0.0610614    0.0794121   -0.0765542    0.0615866   -0.00598491
  0.136801     -0.0533411    0.0476403   -0.0620302    0.07142     -0.0441736   -0.0754483   -0.0234863    0.1712       0.0208097    0.0180237    0.151441     0.0743116    0.00578888   0.011274     0.103925      0.079379    -0.175971     0.03617     -0.217422    -0.0383147    0.0989221   -0.0816245    0.0702209   -0.00568324  -0.0239437
 -0.0619425    -0.175213    -0.204937     0.0290917   -0.125135    -0.0822768   -0.03565      0.128562     0.078897     0.129899    -0.0647322    0.0669511   -0.00265644  -0.00722871   0.048991     0.146477      0.00316562  -0.186058    -0.081506     0.113326    -0.0979548    0.0235279   -0.00839188   0.134573     0.0943953    0.0536582
  0.0398433     0.130411     0.191664    -0.00185997   0.145842     0.0704787   -0.0147751    0.153972     0.0431107    0.0672672   -0.00143351   0.13552      0.0955251   -0.0536308    0.0653784   -0.0254945     0.0325851    0.109633     0.240468     0.0917496    0.100485    -0.0321803    0.0105931    0.0457137    0.132431     0.00885002kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3888263165569035
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.388911
[ Info: iteration 2, average log likelihood -1.388823
[ Info: iteration 3, average log likelihood -1.388118
[ Info: iteration 4, average log likelihood -1.382127
[ Info: iteration 5, average log likelihood -1.369336
[ Info: iteration 6, average log likelihood -1.362169
[ Info: iteration 7, average log likelihood -1.360021
[ Info: iteration 8, average log likelihood -1.359023
[ Info: iteration 9, average log likelihood -1.358390
[ Info: iteration 10, average log likelihood -1.357980
[ Info: iteration 11, average log likelihood -1.357727
[ Info: iteration 12, average log likelihood -1.357568
[ Info: iteration 13, average log likelihood -1.357460
[ Info: iteration 14, average log likelihood -1.357385
[ Info: iteration 15, average log likelihood -1.357331
[ Info: iteration 16, average log likelihood -1.357291
[ Info: iteration 17, average log likelihood -1.357261
[ Info: iteration 18, average log likelihood -1.357236
[ Info: iteration 19, average log likelihood -1.357216
[ Info: iteration 20, average log likelihood -1.357198
[ Info: iteration 21, average log likelihood -1.357182
[ Info: iteration 22, average log likelihood -1.357166
[ Info: iteration 23, average log likelihood -1.357151
[ Info: iteration 24, average log likelihood -1.357137
[ Info: iteration 25, average log likelihood -1.357123
[ Info: iteration 26, average log likelihood -1.357109
[ Info: iteration 27, average log likelihood -1.357094
[ Info: iteration 28, average log likelihood -1.357079
[ Info: iteration 29, average log likelihood -1.357062
[ Info: iteration 30, average log likelihood -1.357043
[ Info: iteration 31, average log likelihood -1.357021
[ Info: iteration 32, average log likelihood -1.356992
[ Info: iteration 33, average log likelihood -1.356956
[ Info: iteration 34, average log likelihood -1.356916
[ Info: iteration 35, average log likelihood -1.356878
[ Info: iteration 36, average log likelihood -1.356845
[ Info: iteration 37, average log likelihood -1.356817
[ Info: iteration 38, average log likelihood -1.356795
[ Info: iteration 39, average log likelihood -1.356777
[ Info: iteration 40, average log likelihood -1.356761
[ Info: iteration 41, average log likelihood -1.356748
[ Info: iteration 42, average log likelihood -1.356737
[ Info: iteration 43, average log likelihood -1.356728
[ Info: iteration 44, average log likelihood -1.356720
[ Info: iteration 45, average log likelihood -1.356713
[ Info: iteration 46, average log likelihood -1.356706
[ Info: iteration 47, average log likelihood -1.356700
[ Info: iteration 48, average log likelihood -1.356693
[ Info: iteration 49, average log likelihood -1.356687
[ Info: iteration 50, average log likelihood -1.356680
┌ Info: EM with 100000 data points 50 iterations avll -1.356680
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3889110963110134
│     -1.3888226602999967
│      ⋮
└     -1.35668020280952
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.356807
[ Info: iteration 2, average log likelihood -1.356678
[ Info: iteration 3, average log likelihood -1.356274
[ Info: iteration 4, average log likelihood -1.352861
[ Info: iteration 5, average log likelihood -1.341534
[ Info: iteration 6, average log likelihood -1.330113
[ Info: iteration 7, average log likelihood -1.324747
[ Info: iteration 8, average log likelihood -1.321691
[ Info: iteration 9, average log likelihood -1.319496
[ Info: iteration 10, average log likelihood -1.317826
[ Info: iteration 11, average log likelihood -1.316523
[ Info: iteration 12, average log likelihood -1.315416
[ Info: iteration 13, average log likelihood -1.314390
[ Info: iteration 14, average log likelihood -1.313396
[ Info: iteration 15, average log likelihood -1.312434
[ Info: iteration 16, average log likelihood -1.311507
[ Info: iteration 17, average log likelihood -1.310588
[ Info: iteration 18, average log likelihood -1.309652
[ Info: iteration 19, average log likelihood -1.308658
[ Info: iteration 20, average log likelihood -1.307786
[ Info: iteration 21, average log likelihood -1.307304
[ Info: iteration 22, average log likelihood -1.307073
[ Info: iteration 23, average log likelihood -1.306950
[ Info: iteration 24, average log likelihood -1.306876
[ Info: iteration 25, average log likelihood -1.306829
[ Info: iteration 26, average log likelihood -1.306797
[ Info: iteration 27, average log likelihood -1.306776
[ Info: iteration 28, average log likelihood -1.306762
[ Info: iteration 29, average log likelihood -1.306752
[ Info: iteration 30, average log likelihood -1.306745
[ Info: iteration 31, average log likelihood -1.306740
[ Info: iteration 32, average log likelihood -1.306736
[ Info: iteration 33, average log likelihood -1.306732
[ Info: iteration 34, average log likelihood -1.306730
[ Info: iteration 35, average log likelihood -1.306728
[ Info: iteration 36, average log likelihood -1.306726
[ Info: iteration 37, average log likelihood -1.306725
[ Info: iteration 38, average log likelihood -1.306723
[ Info: iteration 39, average log likelihood -1.306723
[ Info: iteration 40, average log likelihood -1.306722
[ Info: iteration 41, average log likelihood -1.306721
[ Info: iteration 42, average log likelihood -1.306721
[ Info: iteration 43, average log likelihood -1.306720
[ Info: iteration 44, average log likelihood -1.306720
[ Info: iteration 45, average log likelihood -1.306720
[ Info: iteration 46, average log likelihood -1.306720
[ Info: iteration 47, average log likelihood -1.306719
[ Info: iteration 48, average log likelihood -1.306719
[ Info: iteration 49, average log likelihood -1.306719
[ Info: iteration 50, average log likelihood -1.306719
┌ Info: EM with 100000 data points 50 iterations avll -1.306719
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.356806759200318
│     -1.356678089384558
│      ⋮
└     -1.3067191146955106
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.306858
[ Info: iteration 2, average log likelihood -1.306706
[ Info: iteration 3, average log likelihood -1.305876
[ Info: iteration 4, average log likelihood -1.297792
[ Info: iteration 5, average log likelihood -1.276857
[ Info: iteration 6, average log likelihood -1.264770
[ Info: iteration 7, average log likelihood -1.260234
[ Info: iteration 8, average log likelihood -1.257841
[ Info: iteration 9, average log likelihood -1.256412
[ Info: iteration 10, average log likelihood -1.255366
[ Info: iteration 11, average log likelihood -1.254435
[ Info: iteration 12, average log likelihood -1.253587
[ Info: iteration 13, average log likelihood -1.252829
[ Info: iteration 14, average log likelihood -1.252177
[ Info: iteration 15, average log likelihood -1.251657
[ Info: iteration 16, average log likelihood -1.251205
[ Info: iteration 17, average log likelihood -1.250743
[ Info: iteration 18, average log likelihood -1.250228
[ Info: iteration 19, average log likelihood -1.249660
[ Info: iteration 20, average log likelihood -1.249038
[ Info: iteration 21, average log likelihood -1.248326
[ Info: iteration 22, average log likelihood -1.247561
[ Info: iteration 23, average log likelihood -1.246836
[ Info: iteration 24, average log likelihood -1.246137
[ Info: iteration 25, average log likelihood -1.245412
[ Info: iteration 26, average log likelihood -1.244550
[ Info: iteration 27, average log likelihood -1.243464
[ Info: iteration 28, average log likelihood -1.242199
[ Info: iteration 29, average log likelihood -1.240815
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.239305
[ Info: iteration 31, average log likelihood -1.256032
[ Info: iteration 32, average log likelihood -1.247659
[ Info: iteration 33, average log likelihood -1.244646
[ Info: iteration 34, average log likelihood -1.243449
[ Info: iteration 35, average log likelihood -1.243012
[ Info: iteration 36, average log likelihood -1.242794
[ Info: iteration 37, average log likelihood -1.242591
[ Info: iteration 38, average log likelihood -1.242301
[ Info: iteration 39, average log likelihood -1.241819
[ Info: iteration 40, average log likelihood -1.241118
[ Info: iteration 41, average log likelihood -1.240166
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.238944
[ Info: iteration 43, average log likelihood -1.255636
[ Info: iteration 44, average log likelihood -1.247297
[ Info: iteration 45, average log likelihood -1.244419
[ Info: iteration 46, average log likelihood -1.243250
[ Info: iteration 47, average log likelihood -1.242806
[ Info: iteration 48, average log likelihood -1.242610
[ Info: iteration 49, average log likelihood -1.242463
[ Info: iteration 50, average log likelihood -1.242293
┌ Info: EM with 100000 data points 50 iterations avll -1.242293
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3068578976535417
│     -1.3067063966538937
│      ⋮
└     -1.242292578724489
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.242220
[ Info: iteration 2, average log likelihood -1.241550
[ Info: iteration 3, average log likelihood -1.239650
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.223985
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.194409
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.177507
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.170284
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.164229
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.161085
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.152791
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.158854
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.158212
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.159233
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.151539
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.157797
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.165587
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.152719
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.148085
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.154091
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.164645
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.151843
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.157160
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.156297
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.157197
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.148522
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.154583
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.155340
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.155576
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.155841
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.154662
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.145791
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.151146
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.153393
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.154582
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.145824
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.160834
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.155920
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.147493
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.142940
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.158803
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.155774
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.147265
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.152608
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.161331
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.148840
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.144522
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.150702
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.161200
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.148633
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.144295
┌ Info: EM with 100000 data points 50 iterations avll -1.144295
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2422202343993547
│     -1.2415503325382375
│      ⋮
└     -1.1442952964860242
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     19
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.150880
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     19
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.144636
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     19
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.142030
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.132137
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.101330
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.084674
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│     15
│     16
│     17
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.096327
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      9
│     15
│     16
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.093642
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│     15
│     16
│     17
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.072188
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      9
│     15
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.074121
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│     15
│     16
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.073447
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      9
│     15
│     16
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.077821
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│     15
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.069128
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.089090
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.073481
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      9
│     15
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.063176
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.068522
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      9
│     15
│     16
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.088576
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     15
│     16
│     17
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.072518
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      9
│     15
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.072853
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.076154
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      9
│     15
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.070660
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│     15
│     16
│     17
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.072714
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      4
│      7
│      9
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.073646
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│     15
│     16
│     17
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.083254
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.076647
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.057567
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.093271
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     15
│     16
│     17
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.074340
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      9
│     15
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.071554
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│     15
│     16
│     17
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.074921
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      5
│      9
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.073096
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.082715
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.069423
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.082897
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.076874
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      5
│      7
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.056887
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      9
│     15
│     16
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.091076
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│     15
│     16
│     17
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.076006
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      9
│     15
│     16
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.074313
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│     15
│     16
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.066891
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      9
│     15
│     16
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.078318
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      7
│     15
│     16
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.075579
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      9
│     15
│     16
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.079719
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│     15
│     16
│     17
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.071867
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      9
│     15
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.073488
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│     15
│     16
│     17
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.072724
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      9
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.073530
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.082941
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      9
│     15
│     16
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.076671
┌ Info: EM with 100000 data points 50 iterations avll -1.076671
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1508797132432385
│     -1.1446363251860117
│      ⋮
└     -1.0766708123326365
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3888263165569035
│     -1.3889110963110134
│     -1.3888226602999967
│     -1.3881177800419406
│      ⋮
│     -1.0735296526510067
│     -1.08294122804443
└     -1.0766708123326365
32×26 Array{Float64,2}:
  0.179502     0.111927      0.0681481   -0.0924546    0.112194   -0.0165275    0.00110922   0.0294022   -0.0359909    -0.079023    -0.113327     0.279585    -0.0562574   -0.104971     0.0278074    0.0433369    0.0503666     0.0850001   -0.132642    0.0531426    0.360858      0.0995394   -0.0273938   -0.0130475    -0.0522649    0.106196
  0.0570395    0.048285      0.0618257   -0.00873229   0.0177349   0.0415713    0.0415885    0.0548931   -0.0468403     0.0124489    0.00463743   0.0726391   -0.0502423   -0.0696394    0.0558804   -0.0439118   -0.0347563     0.0527756    0.168105    0.105663     0.128921      0.0108081   -0.0515305   -0.0431931     0.020822    -0.0177316
  0.139036    -0.075068      0.0217183   -0.0150041    0.0699603  -0.0328647   -0.0463556   -0.0086486    0.171753      0.028683     0.0204098    0.151198     0.0890323    0.0315407    0.0162325    0.102921     0.080285     -0.1756       0.0357141  -0.211551    -0.0400099     0.0587876   -0.0552908    0.0750299     0.00159571  -0.0250231
  0.0635238    0.0379134    -0.0195537   -0.0233337    0.0659071  -0.0950188   -0.117372    -0.165779    -0.0924382    -0.0642855    0.0223995    0.0882153   -0.102224    -0.00522481   0.0832876   -0.00789317   0.117289     -0.0892898   -0.0350734  -0.321419     0.0204537     0.043016     0.0789195   -0.0662873    -0.160212     0.11864
 -0.0976049    0.109632     -0.0902919   -0.0357909    0.107161   -0.243743     0.0416686   -0.0183637    0.077466      0.0262646   -0.0362333   -0.0191557   -0.00770763  -0.0792202    0.123289     0.223156     0.0266211     0.129701     0.124327    0.188244     0.0578176     0.0682014    0.0390994   -0.00350977   -0.0182844   -0.0609545
  0.0568768    0.0117312    -0.0202586   -0.105358    -0.0671614  -0.0694389   -0.00927781  -0.0405707    0.000672448  -0.115854    -0.074328     0.042359    -0.0958667    0.0350779   -0.00593457  -0.0348264   -0.0620019    -0.0395471   -0.0705604  -0.0694809   -0.000640323   0.0222532    0.00195298  -0.0810554     0.0226754   -0.0163282
  0.108134    -0.0509753     0.125822     0.0581722   -0.223187    0.0429562    0.121369     0.120588    -0.0905594    -0.00474162   0.101836     0.0223144   -0.0254788    0.0242141    0.0957935    0.0522681   -0.153379      0.195623    -0.109869    0.0327555   -0.0687621    -0.0835162    0.058215     0.0370562     0.0713917    0.0341897
  0.00451856   0.0647063     0.0175429   -0.0455155    0.0989948   0.0341551   -0.108887    -0.0421377    0.0744463    -0.0755043    0.0486797    0.0699061    0.0960114    0.135096     0.0986337   -0.041003     0.0373198    -0.0870328    0.0261727   0.0288596   -0.0570489     0.0114452    0.0800738   -0.0235996     0.0381042    0.00458957
 -0.0639074   -0.0940217     0.0566014    0.20012      0.0241371  -0.0483642   -0.0986682   -0.0997861    0.0923064     0.106754     0.102566    -0.0178769    0.0297627    0.210907    -0.197062    -0.0292365   -0.168843     -0.064327     0.0777016   0.104054    -0.0291778    -0.0922925   -0.137155    -0.0503342    -0.00354993  -0.122381
  0.197369    -0.082504     -0.00309165   0.0369614   -0.105138   -0.0777402    0.0963458    0.00889581  -0.0879033    -0.0617314   -0.111099     0.180714     0.0583281    0.0387347   -0.0875806    0.0556377   -0.104077     -0.0416458    0.182277   -0.118349    -0.0461554    -0.0636646    0.0159319    0.00747785    0.00233856   0.0513765
  0.0115301   -0.243048     -0.10056     -0.0822943    0.0566936  -0.0305326    0.133162     0.0491135   -0.107522     -0.095209     0.0773193    0.156212    -0.150122     0.247657    -0.15498      0.00716918   0.053529     -0.0290778   -0.0657052  -0.0354336   -0.405241     -0.0289463    0.0826074   -0.0128499    -0.117047     0.0282867
  0.0413017   -0.0749107    -0.00146112   0.0406986    0.0582608  -0.0625757    0.235323     0.00889058   0.0976584    -0.161718     0.174366     0.0671295   -0.111593     0.254506     0.0706844   -0.00285435   0.27027      -0.0783935   -0.153337    0.0340668    0.558794     -0.0210996    0.278384     0.0166531    -0.035418     0.112257
  0.0796034    0.00573055   -0.108712    -0.0705899   -0.28827     0.10284     -0.305931     0.0560246    0.0124243    -0.0886309    0.0569426   -0.0909737    0.184311     0.0978927    0.0406895   -0.226229    -0.000570499  -0.00695611   0.0438138  -0.0252254    0.153909      0.099803     0.121414     0.292626      0.146398    -0.100823
  0.0700319    0.000568436  -0.179519    -0.0650057    0.277241    0.0693422    0.294347     0.0532411    0.030827     -0.0395003    0.065704     0.16124      0.150799    -0.0397892    0.0773131   -0.211486    -0.148225      0.0739172   -0.0215744  -0.00632894   0.163155     -0.0391272    0.0152252    0.223105     -0.0805026   -0.0623095
  0.030532     0.060646     -0.0977512   -0.253771     0.0773357   0.0667843    0.267466     0.046461    -0.281452     -0.127151     0.0143167    0.319058     0.0826092   -0.184876     0.0971175    0.0338613    0.0651894    -0.227338    -0.0544406  -0.0597062    0.0172528    -0.236103    -0.0717899    0.00532393   -0.375168     0.135237
  0.0673893    0.0605679    -0.108837     0.0212019   -0.0414919   0.0583273   -0.0699742    0.0462195   -0.256989     -0.117841     0.0156868   -0.41307      0.0623455   -0.0490154    0.118326     0.0327477    0.0664072    -0.0548241   -0.0543169  -0.0722607    0.189045      0.273855     0.0531885   -0.000616179   0.217647     0.289105
 -0.0112368    0.0287214    -0.104027     0.0159097    0.25823    -0.0655693   -0.15823     -0.0214444    0.0447168     0.0885179   -0.00948066  -0.182635     0.0250087    0.0744689   -0.0370106    0.0213179    0.0483728    -0.0791616   -0.0407049   0.00723171   0.169579     -0.00758323  -0.0576761   -0.0227607     0.0218278   -0.0313781
  0.00922117   0.0363709    -0.118551     0.0532794   -0.645591   -0.0109033   -0.153842    -0.0212268   -0.0497414     0.11184     -0.0250088    0.0241277   -0.0438847   -0.227792    -0.036835     0.00848764   0.0468284    -0.0717016   -0.358085   -0.398329     0.226193     -0.107429    -0.0277685   -0.00597404    0.0412766   -0.028776
 -0.155602     0.223227     -1.15712      0.0574929   -0.020688    0.1162       0.0625193    0.0391445    0.196465      0.158564    -0.0221819   -0.0463141    0.03744     -0.034468     0.0333792   -0.020578    -0.0885553    -0.00426452   0.194266   -0.0506732    0.163978      0.0120395    0.135064    -0.0358044    -0.152672    -0.121942
 -0.0125251   -0.349151      0.957804     0.0663188   -0.0184688   0.111983     0.0647291    0.0380576    0.191765      0.139026     0.113737     0.0142713    0.0407694   -0.0366985    0.0315981    0.00211258  -0.089452      0.016319     0.15877    -0.0452644    0.111311      0.0168513    0.124156    -0.00582173   -0.074773    -0.0955443
  0.197472    -0.709727      0.0350771    0.135206    -0.0480754   0.0467342    0.159093     0.112583    -0.174668      0.0114875   -0.116593     0.258983     0.176039    -0.15876     -0.187006     0.020688    -0.0471073    -0.0757752    0.0307543   0.00705653  -0.0897292    -0.0333597    0.191311     0.0755624    -0.201912     0.113566
  0.19243      0.635116      0.0415232    0.0340926   -0.0310039   0.035601     0.108663     0.105578    -0.165484      0.00403593  -0.116654     0.18013      0.0411463   -0.234085    -0.170429    -0.248844    -0.0181911    -0.0702421   -0.183344   -0.0165632    0.0382357    -0.0231994    0.228758     0.0809944    -0.144899     0.042692
  0.0589077   -0.0457144     0.0477193    0.0189464    0.0833167  -0.0104147   -0.0392798    0.0267137   -0.0114155     0.0166253   -0.0278543   -0.00967367   0.0634041    0.043148    -0.117       -0.00780949  -0.0207757     0.117098    -0.0905491   0.0229665   -0.0524011    -0.0280797    0.00415568  -0.0193652     0.0292121   -0.0660735
  0.0341906   -0.0457703     0.0702147   -0.0756006    0.0787818   0.00412074  -0.0942198    0.0441256   -0.129993      0.00212579   0.103       -0.0104662    0.0787886   -0.0805884    0.0301949    0.0248964    0.0142571    -0.086139     0.0943351  -0.00814212   0.0596971    -0.0602337    0.0545198   -0.112403     -0.00792836   0.145227
 -0.0805766    0.109965     -0.019732    -0.127594    -0.174912    0.0207293   -0.256696     0.0767515    0.0150362     0.0958306   -0.0825084   -0.00117914  -0.0257745    0.261774    -0.0646552    0.0377781   -0.0467379     0.167385    -0.156214   -0.569075    -0.157042      0.392561     0.0496981   -0.109228      0.251857    -0.214517
 -0.0816266    0.135495     -0.047356    -0.148225    -0.0950483   0.057897    -0.292333    -0.116935    -0.189031      0.123671    -0.10333      0.0784724   -0.0257948   -0.251697     0.14534      0.0618355   -0.0515515     0.0192251    0.396674    0.382385    -0.157429     -0.054486     0.134742    -0.130072     -0.0987738   -0.185956
  0.227725    -0.00248236    0.0989288   -0.172161    -0.179681   -0.0533741    0.0311057    0.11862      0.00449342    0.0178194    0.159637    -0.0157764   -0.0316169   -0.0566925    0.0815551    0.17122      0.0301724     0.00240055  -0.0390315   0.00289011  -0.146775      0.177911     0.0600038   -0.00993136    0.0586958   -0.154392
  0.145251     0.061817     -0.0357548    0.00926882  -0.0896254  -0.168815     0.0272561    0.0474688   -0.000961592   0.0516468    0.068556     0.0285196    0.0686945    0.0144705   -0.0435133    0.107822     0.0673574    -0.0329527   -0.042952   -0.0674786   -0.0169477    -0.147376    -0.0266746   -0.135642      0.0246264   -0.118239
 -0.12301     -0.13051      -0.136323    -0.00283024   0.0404187   0.0199562    0.00536021   0.0793806    0.0349933    -0.0148428   -0.0439862    0.0870826   -0.0671496    0.0392687    0.00927659   0.0976568    0.00347857   -0.0544332    0.118397    0.0662782   -0.063115      0.0572703    0.0484598    0.143903      0.0187337    0.0536374
 -0.0655884    0.0976101     0.0131165    0.0766992    0.0754378   0.136998     0.025511    -0.0195653   -0.10214       0.145355     0.019595     0.249847     0.0284198    0.00466032  -0.165166    -0.107417     0.0441349    -0.0579684   -0.106554    0.0301762    0.0109477    -0.00793132  -0.0147509   -0.0872718    -0.0594574   -0.0946382
 -0.210515     0.125435      0.153461    -0.0294795    0.261026   -0.0214824    0.083916    -0.190975    -0.0392026    -0.0947276    0.124508    -0.101764     0.0551966   -0.148994    -0.223316    -0.0427285    0.00400284    0.09501      0.151281    0.224168     0.017513      0.0771421    0.024147    -0.0624704     0.0309354   -0.049183
  0.60672      0.128725      0.070601    -0.0991911    0.116027    0.0308216    0.084103    -0.165296    -0.106665     -0.107938    -0.0196621   -0.152649    -0.0442044   -0.0634711   -0.0584283   -0.0032246   -0.00353963   -0.00968472   0.177832   -0.259593     0.0602503     0.0604884    0.0375245   -0.0475484     0.0117118   -0.038676[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│     15
│     16
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.066160
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.053593
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│     15
│     16
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.060697
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.051707
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│     15
│     16
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.059738
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.050118
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│     15
│     16
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.066069
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.052887
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│     15
│     16
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.060649
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.051503
┌ Info: EM with 100000 data points 10 iterations avll -1.051503
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.123896e+05
      1       6.606987e+05      -1.516909e+05 |       32
      2       6.318890e+05      -2.880971e+04 |       32
      3       6.137005e+05      -1.818850e+04 |       32
      4       6.020278e+05      -1.167272e+04 |       32
      5       5.954473e+05      -6.580511e+03 |       32
      6       5.922053e+05      -3.242002e+03 |       32
      7       5.903157e+05      -1.889541e+03 |       32
      8       5.888989e+05      -1.416836e+03 |       32
      9       5.879027e+05      -9.962070e+02 |       32
     10       5.870425e+05      -8.602129e+02 |       32
     11       5.861001e+05      -9.424193e+02 |       32
     12       5.849343e+05      -1.165709e+03 |       32
     13       5.837216e+05      -1.212713e+03 |       32
     14       5.829139e+05      -8.076861e+02 |       32
     15       5.822691e+05      -6.448502e+02 |       32
     16       5.816787e+05      -5.904095e+02 |       32
     17       5.811484e+05      -5.303294e+02 |       32
     18       5.807430e+05      -4.053402e+02 |       32
     19       5.805122e+05      -2.307764e+02 |       32
     20       5.803780e+05      -1.342186e+02 |       32
     21       5.802984e+05      -7.958936e+01 |       32
     22       5.802661e+05      -3.235641e+01 |       32
     23       5.802514e+05      -1.469953e+01 |       31
     24       5.802415e+05      -9.843273e+00 |       31
     25       5.802351e+05      -6.394791e+00 |       30
     26       5.802279e+05      -7.234559e+00 |       31
     27       5.802190e+05      -8.908418e+00 |       27
     28       5.802120e+05      -6.988272e+00 |       27
     29       5.802064e+05      -5.587955e+00 |       27
     30       5.802001e+05      -6.364612e+00 |       28
     31       5.801926e+05      -7.437784e+00 |       28
     32       5.801868e+05      -5.785100e+00 |       27
     33       5.801823e+05      -4.500653e+00 |       24
     34       5.801775e+05      -4.793767e+00 |       29
     35       5.801713e+05      -6.199651e+00 |       27
     36       5.801651e+05      -6.281611e+00 |       27
     37       5.801541e+05      -1.099856e+01 |       31
     38       5.801385e+05      -1.556960e+01 |       32
     39       5.801197e+05      -1.877229e+01 |       29
     40       5.800996e+05      -2.009821e+01 |       32
     41       5.800778e+05      -2.177033e+01 |       30
     42       5.800473e+05      -3.051163e+01 |       31
     43       5.800102e+05      -3.712367e+01 |       31
     44       5.799592e+05      -5.099473e+01 |       32
     45       5.798896e+05      -6.958385e+01 |       32
     46       5.797893e+05      -1.003268e+02 |       32
     47       5.797075e+05      -8.176022e+01 |       32
     48       5.796654e+05      -4.209731e+01 |       32
     49       5.796430e+05      -2.248357e+01 |       32
     50       5.796281e+05      -1.488241e+01 |       31
K-means terminated without convergence after 50 iterations (objv = 579628.0799593579)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.308416
[ Info: iteration 2, average log likelihood -1.276941
[ Info: iteration 3, average log likelihood -1.240603
[ Info: iteration 4, average log likelihood -1.188322
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.136566
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     23
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.103568
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.110967
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      9
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.062697
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     13
│     18
│     22
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.047332
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     14
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.089109
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.085501
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.067601
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     18
│     20
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.045241
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     12
│     13
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.056165
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      9
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.063578
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.089839
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.062165
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     22
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.068617
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      9
│     12
│     20
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.055864
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     14
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.074986
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.071571
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.072531
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      9
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.064598
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     14
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.048162
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.078851
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.071123
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      9
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.052275
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     14
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.069325
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.090930
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.058786
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      6
│      9
│     12
│     22
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.029155
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.089476
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     18
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.061268
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.076466
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.061140
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     12
│     14
│     18
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.020525
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.099640
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     13
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.057774
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     18
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.030781
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     12
│     20
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.041254
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.103483
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.067496
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     13
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.020529
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.077003
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     14
│     18
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.064230
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.078608
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.086593
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     18
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.042446
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     13
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.050816
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.064017
┌ Info: EM with 100000 data points 50 iterations avll -1.064017
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.140005    0.0100795    0.0834254    -0.0395487    0.137407     0.0422083   -0.0734584    -0.0557837   -0.116619    -0.111028     0.151913     0.0170614    0.107719     -0.0959325    0.0747285   -0.0113322    -0.0479268    -0.121573      0.00883339  -0.00754398   0.026186    -0.0676331    0.0907666   -0.013532     0.0465525    0.0873785
  0.195427    0.127224     0.112235     -0.0640998    0.18684      0.00594478   0.0840556    -0.177838    -0.0728484   -0.101038     0.0507488   -0.126623     0.00604044   -0.107729    -0.142531    -0.02332       0.000474682   0.0417684     0.168854    -0.0186823    0.0386607    0.0693546    0.0313797   -0.0551527    0.0222332   -0.0438946
  0.0715031   0.0611767   -0.0428783     0.0403294    0.0861543   -0.0598649   -0.142803     -0.175205    -0.141608    -0.0819661    0.0263274    0.0936882   -0.083016     -0.0203891    0.112929    -0.0424608     0.130215     -0.0779611    -0.0437618   -0.355213     0.0261324    0.0125879    0.0761264   -0.0645374   -0.161593     0.120589
 -0.0265708   0.0891926   -0.0105645    -0.120217    -0.0513316   -0.0132278   -0.109071      0.00154709  -0.136613     0.0233435    0.0182908    0.0477618    0.0442282     0.00285226   0.0896877   -0.0134948    -0.0345475    -0.0607181     0.0247489   -0.0640006   -0.0869903    0.160452     0.111314    -0.0693519    0.0588522   -0.0432032
  0.154994    0.0520287   -0.000502976   0.0648798    0.0771514   -0.180395     0.0496596    -0.0208617    0.00689061   0.101657    -0.0870185    0.156214     0.0937534     0.0430756    0.0139241   -0.0579103    -0.0590488     0.175183     -0.156163    -0.105407    -0.0123852   -0.136044     0.0613252   -0.0219446   -0.0564945   -0.00283567
  0.0955697  -0.0481036    0.0334317     0.0276891   -0.189224     0.00551149   0.115263      0.0754454   -0.111166    -0.0619728    0.0617001    0.00787418  -0.112622     -0.011341     0.0698598    0.01011      -0.11838       0.0964582    -0.0140203    0.059038     0.0176885   -0.010173    -0.0133092   -0.0410058   -0.00242309  -0.00386585
 -0.0181528   0.103348     0.0192763    -0.138121     0.12088      0.103438    -0.237524     -0.108838     0.207354    -0.0455713   -0.00789463   0.0774947    0.073954      0.125265     0.0862275   -0.0188286     0.133215      0.000272338   0.00971268   0.0258574   -0.0649528   -0.0579409    0.0135755    0.0365264    0.0144689    0.00648206
  0.025938   -0.164905    -0.0581571    -0.0180075    0.0569687   -0.0470103    0.181342      0.027023    -0.00874925  -0.130048     0.122634     0.114239    -0.132805      0.243945    -0.0518634    0.00266645    0.165347     -0.0508796    -0.106813    -0.00147691   0.0525344   -0.0253144    0.176565     0.00681428  -0.0770217    0.069753
  0.0160188   0.0394737   -0.12793       0.0153306   -0.0985984   -0.0241427   -0.157659     -0.0214394   -0.00757234   0.107974    -0.0207956   -0.104019    -0.00669067   -0.0512514   -0.0365311    0.0077223     0.0470524    -0.0656481    -0.150589    -0.180268     0.204716    -0.0634703   -0.0265871   -0.00281523   0.0290539   -0.0356868
 -0.0612852   0.0965792    0.0136389     0.072418     0.0719106    0.133688     0.0312143    -0.0182163   -0.106926     0.141052     0.0214765    0.246702     0.0295429     0.00483639  -0.158638    -0.102         0.0447527    -0.0640251    -0.10641      0.0240532    0.0126154    0.00644857  -0.0187272   -0.0867818   -0.0566248   -0.0887652
  0.0743514   0.00388335  -0.146867     -0.0685915   -0.00484585   0.0849801   -0.00264031    0.0548374    0.0194163   -0.0665643    0.0622517    0.0279401    0.165949      0.0284887    0.0595364   -0.213897     -0.0737637     0.0297496     0.0108418   -0.0168836    0.15835      0.0329108    0.0661619    0.252447     0.0324428   -0.0762648
  0.113777   -0.0601279    0.00279249   -0.0196932    0.0717307   -0.0322967   -0.0426029    -0.0258756    0.080068    -0.00594525   0.0189394    0.133711     0.056254      0.0109774    0.0424227    0.0809098     0.0970618    -0.154916      0.0153598   -0.231267    -0.00786871   0.0739182   -0.0258231    0.0397841   -0.0405931    0.0099612
  0.0653502   0.0152252    0.021223      0.117591     0.167434    -0.0387073    0.000629064   0.0106092   -0.063391    -0.125081     0.17939      0.0718889    0.0598757     0.248205     0.143888    -0.0752174    -0.0416157    -0.13571       0.0265917    0.0712268   -0.0324571    0.0603509    0.138172    -0.0776454    0.0292289    0.0114265
 -0.0547125  -0.0896298    0.0374384     0.187859     0.0283561   -0.0510945   -0.102021     -0.10408      0.0758819    0.0864879    0.0972913   -0.0167245    0.028463      0.193402    -0.175874    -0.0262416    -0.173426     -0.0658764     0.0659816    0.0885862   -0.0242234   -0.0869192   -0.121614    -0.0512502   -0.0159434   -0.0953308
 -0.130327   -0.0944934   -0.0652292    -0.0305737    0.19568      0.122007     0.0222433     0.0163345   -0.030291    -0.158146    -0.0156207    0.0855353   -0.130019      0.0638414   -0.0180711    0.0610893     0.00952498    0.0242347     0.282872     0.014591    -0.0223529    0.108943     0.113009     0.156371    -0.0520843    0.0565105
  0.168255   -0.0427361    0.0712805    -0.0253017    0.00466579   0.0491501   -0.0672055     0.0206706   -0.0980927    0.015376     0.0199189    0.00508208   0.0633016    -0.0596413   -0.256861    -0.000618672   0.0388299     0.092704      0.00951781   0.0533625   -0.0355317    0.0217117    0.0821852   -0.0579891   -0.00727385  -0.10935
 -0.103903   -0.0536527   -0.0438567     0.101366     0.0261581   -0.0326501   -0.0124369     0.0137564    0.185863     0.0548076    0.0292649   -0.0452903    0.0434315     0.00248916   0.00495032   0.0357864    -0.113333     -0.0255169     0.0392875    0.0343819    0.0899896    0.0679652    0.0148084   -0.0600959   -0.056432    -0.0623068
  0.0287981  -0.112046    -0.0145698    -0.206228    -0.0729056   -0.0515132   -0.0324593    -0.0317453   -0.0021498   -0.176355    -0.215275     0.0734359   -0.0876552    -0.033321    -0.00341438  -0.0532393    -0.0292925    -0.122441     -0.0989244   -0.0938893   -0.0305926    0.0546628   -0.0978445    0.0574273    0.034939     0.0585023
  0.144993    0.0615479   -0.0408181    -0.0059378   -0.0937395   -0.159632     0.037921      0.0487087   -0.00926055   0.0392817    0.0663331    0.0310133    0.0675982     0.0137145   -0.0347751    0.105373      0.0716583    -0.0294271    -0.0477209   -0.0803907   -0.0146693   -0.153354    -0.0201466   -0.130715     0.0215112   -0.111087
  0.0393103   0.119957     0.190414     -0.00442071   0.142053     0.112295     0.000909728   0.10729      0.00828805   0.114636    -0.00652184   0.141707     0.0940762    -0.0658461    0.064534    -0.0515158     0.00833383    0.105309      0.244086     0.107649     0.138366    -0.0403287    0.0028676    0.0449064    0.122954     0.0107392
 -0.102148   -0.17135     -0.209987      0.0249039   -0.115813    -0.0273675    0.00675379    0.146877     0.0793093    0.124863    -0.0623047    0.0559804   -0.000205765  -0.0118817    0.0468711    0.132747      0.00920346   -0.153664     -0.062691     0.111848    -0.0972329    0.0170529   -0.00812272   0.136876     0.0816805    0.0725863
 -0.117987    0.100894    -0.107619     -0.0324177    0.114959    -0.212376     0.0398566    -0.0127909    0.080222     0.0154731   -0.052793    -0.0359584    0.00255296   -0.100879     0.134602     0.246029      0.0416622     0.121803      0.131796     0.208976     0.0552623    0.0814633    0.0223239    0.0175095   -0.00437214  -0.0515148
 -0.20258     0.109896    -0.0762908    -0.0085619    0.142547    -0.517074     0.00741317   -0.0150207    0.0922353   -0.05509     -0.06354      0.0136025   -0.000864472   0.00458352   0.103306     0.154632      0.0531838     0.0528055     0.0957027    0.200416     0.0448242    0.0619421    0.020045     0.0170151   -0.0175103   -0.0257017
  0.173302    0.120172     0.0639748    -0.103408     0.114791    -0.0198166    0.0120524     0.00950428  -0.0416548   -0.0832709   -0.0902178    0.267078    -0.0499834    -0.0878337    0.0319174    0.0337664     0.0503672     0.0590442    -0.118969     0.036747     0.326842     0.0963201   -0.0148313   -0.0138474   -0.0490511    0.0973875
 -0.0456666  -0.118468     0.043969     -0.0563542    0.162663     0.184801    -0.0425175     0.108629    -0.0766403    0.00738879  -0.0505102   -0.153424     0.0569153     0.148015    -0.125247    -0.0249762     0.044586      0.142405     -0.0967264    0.0493981   -0.145802    -0.0903913   -0.0639457    0.0597101    0.142263    -0.0710397
  0.292172   -0.0561001    0.162514     -0.178389    -0.172088    -0.0641761    0.033841      0.158858     0.0418529   -0.015593     0.214464    -0.00993335  -0.028022     -0.0567384    0.113368     0.204958      0.0404783    -0.0138755    -0.0371239    0.0386132   -0.1136       0.18431      0.0539831   -0.0125295    0.0446362   -0.110469
  0.194368   -0.0687473    0.0380381     0.0882762   -0.0404021    0.0417457    0.135164      0.109606    -0.169457     0.00686742  -0.11663      0.222153     0.113615     -0.19798     -0.179496    -0.110472     -0.0364415    -0.0739521    -0.06818     -0.00917028  -0.0275142   -0.0278745    0.21416      0.077458    -0.176668     0.0802061
  0.0627477   0.0614563   -0.168974     -0.126659     0.0363834    0.0316876    0.25669       0.0323663   -0.287779    -0.166988     0.0286332   -0.0988729    0.042961     -0.174381     0.136955     0.0138483     0.0548474    -0.184517     -0.0349926   -0.0772314    0.117566    -0.0446637   -0.0326496   -0.00937771  -0.116127     0.284962
 -0.0778911  -0.0969935    0.0542274    -0.11331      0.0247793   -0.0365566   -0.117007      0.13679     -0.147002     0.100938     0.0604131   -0.0331077    0.0499277    -0.0730064   -0.00687475   0.0643584     0.0876264    -0.0577703     0.194438    -0.0215729    0.0938843   -0.065511     0.0230784   -0.186494    -0.059754     0.207256
 -0.0678058   0.110104    -0.0262878    -0.142139    -0.140201     0.0287504   -0.243794     -0.00784872  -0.0769268    0.0898797   -0.0857781    0.0336397   -0.0245107     0.0040294    0.0465133    0.0511113    -0.0429409     0.0701065     0.10046     -0.0417807   -0.153982     0.152816     0.0961312   -0.107879     0.0679449   -0.185796
  0.106482    0.196574    -0.0142387     0.0113515   -0.0432398   -0.0842382    0.0553145    -0.0440537   -0.0192969    0.0106183    0.134581     0.00434675  -0.0948347     0.115379     0.0215461    0.00735268   -0.102225      0.0751277    -0.0301766   -0.0391582    0.0608878   -0.0211776    0.146728    -0.265085    -0.00205719  -0.114993
  0.196279   -0.0804422   -0.00145099    0.0498664   -0.104317    -0.0748303    0.0983786     0.00753435  -0.0954716   -0.0653223   -0.104445     0.183324     0.0582015     0.0350094   -0.0862974    0.0541994    -0.0986351    -0.041085      0.175735    -0.119321    -0.0477126   -0.0702275    0.0150662    0.00814498   0.00354604   0.0538513[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.056169
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│     12
│     14
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.000235
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      9
│     13
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.994538
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     14
│     22
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.033111
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     14
│     18
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.013940
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      3
│      9
│     12
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.976495
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.042407
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│     12
│     14
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.994851
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      9
│     14
│     18
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.009547
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     12
│     14
│     20
│     22
│     25
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.017553
┌ Info: EM with 100000 data points 10 iterations avll -1.017553
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0930393    -0.0885826   -0.0387718   -0.101962     0.138071    -0.0863726    0.060943    -0.144396   -0.00198467   0.0847831    0.12334      0.174312     0.0349272   0.15929      0.0234098    0.0239109   -0.0151002   -0.09119     -0.0567864    0.080834      0.0819973   -0.0365895   -0.203491    -0.0494875   -0.10941      0.0132104
 -0.0308355     0.151448    -0.0707148    0.123417    -0.0764782    0.0234917   -0.00549501   0.0330638   0.0286218   -0.0492429    0.119524    -0.0488028   -0.25831    -0.0686088   -0.134327    -0.136602     0.0209681    0.147792     0.146471    -0.183125     -0.0721876    0.129825    -0.163315    -0.0921409    0.147615     0.0246534
 -0.0566445     0.0894608   -0.169028     0.129869    -0.0154163   -0.0406174    0.00498672   0.0293758  -0.0525031    0.00940826   0.00295416  -0.0832173    0.0935775  -0.150409    -0.0082278    0.0357592    0.164359    -0.0706268   -0.0232635   -0.00323835    0.163122     0.115937    -0.019449    -0.0630823    0.0831906   -0.0218147
  0.118185      0.0264735   -0.0292054    0.0491595    0.232674     0.173496    -0.0559332   -0.120497    0.15453      0.133789     0.120385    -0.222012     0.0722957   0.0256941    0.0535817   -0.109314     0.100155     0.0468761   -0.0653003   -0.0954777     0.0275098   -0.0253579    0.0519212    0.0453623   -0.125745    -0.0523451
  0.0515238    -0.023223    -0.021666     0.0268863   -0.0775411    0.152358    -0.0690012    0.123435   -0.0455973   -0.127364    -0.0319906   -0.0307547   -0.113997   -0.0344786    0.196368     0.0618231    0.0613768    0.0417046   -0.111443    -0.094882     -0.0255983   -0.025293    -0.131647    -0.122602    -0.12402      0.0153104
 -0.0621359     0.148628     0.0987061    0.0310483   -0.147713     0.156467     0.01787      0.0955969  -0.066182    -0.103059     0.0799878   -0.00272367  -0.0309485   0.193289    -0.10403     -0.0969425   -0.075795    -0.00418361  -0.103305     0.177061      0.0367465    0.155531    -0.0116658   -0.0724122    0.178573    -0.0138851
 -0.0822015    -0.190802     0.0578578   -0.00710967  -0.0993982   -0.114202    -0.136953     0.142036    0.0510406   -0.035275     0.0356598    0.0441453   -0.0292666   0.0762809   -0.100674    -0.129886     0.0271092    0.0424475   -0.084654    -0.186697     -0.0853435    0.0743375    0.0550543    0.141515     0.0205493   -0.179946
 -0.00277065    0.0938528   -0.0494397    0.0139397    0.0441057   -0.170603    -0.0543999    0.0254997   0.214353    -0.09448      0.0654699   -0.1842       0.0406612   0.0300781    0.00106238   0.0474486    0.00238334  -0.0308214   -0.195861     0.0449935     0.0641067   -0.070918     0.117439     0.0172849    0.088528    -0.015759
  0.00200234    0.0237719   -0.0681723    0.0656665   -0.175435    -0.0872642    0.00209831  -0.0922807   0.0128718    0.00859178   0.0322699    0.0397333   -0.0363384   0.118866     0.0447903    0.101121    -0.125434    -0.0358282    0.0827111   -0.0401838    -0.10846      0.185268     0.157167    -0.0224936    0.00543943  -0.0704186
  0.0587069     0.0640201   -0.132275     0.159928    -0.0994578    0.0996126   -0.168279    -0.0426008  -0.0139876   -0.0490605   -0.129047     0.104295     0.12268     0.0624521    0.00197175   0.114325     0.0257294   -0.131967    -0.0446998   -0.0276813    -0.149824     0.00669329  -0.0282246    0.00321715   0.136915     0.0778231
 -0.0388949    -0.0312322   -0.063402    -0.0729366    0.0292342   -0.144912     0.0678273   -0.0326765   0.103008     0.0586406   -0.0161706    0.0987041    0.0391502   0.155974    -0.10003      0.0146006   -0.0907321    0.0910259   -0.0730213   -0.00170799    0.113422    -0.114615     0.151865    -0.0180935   -0.0310066    0.0453973
  0.0352247    -0.0402264   -0.0367762    0.228562    -0.0764216   -0.0389206   -0.143515     0.175656    0.134608    -0.026908     0.0111229   -0.104231     0.0113075  -0.0510212    0.056564    -0.0566791   -0.168638    -0.0876273   -0.0737728    0.1817        0.0555395    0.0552134    0.224645     0.142858    -0.190645     0.0884279
 -0.0103234     0.124324    -0.0654707   -0.0240552   -0.108324     0.174199     0.0678732   -0.0311805  -0.201749     0.0613839    0.0668003   -0.0459525   -0.0224639  -0.0542496    0.0898882   -0.00150366  -0.00604246  -0.160797     0.121207    -0.0807433    -0.00570508   0.0813427   -0.00866095   0.057246    -0.0756096    0.0642132
  0.117329      0.0623339    0.0545533   -0.0883576    0.163052    -0.0774267    0.119873     0.18105    -0.123766     0.00728302   0.252206    -0.0372951    0.166393   -0.109607    -0.116178     0.0138868    0.0959576   -0.0722275   -0.0766432   -0.139294     -0.20359     -0.0627532    0.00543882   0.0663421    0.0170981    0.0345181
  0.0283039    -0.0444522   -0.0715717    0.183299    -0.00985875  -0.0129965   -0.0583275    0.11388     0.0227543    0.132383    -0.0128879    0.0523184   -0.078876    0.00719726  -0.243914     0.194218    -0.0505754    0.0548593   -0.0847754    0.0157372    -0.00486075   0.00630632   0.0893331    0.05177      0.17399     -0.0613186
  0.144483     -0.0213314   -0.155265    -0.0130998    0.0804739    0.0212923   -0.0364475    0.179626    0.0317938   -0.0977707   -0.0401697    0.140822    -0.173183    0.155854     0.0582268   -0.057547    -0.0307956    0.175745    -0.119529     0.0918414     0.10144      0.0154518   -0.127539    -0.0692681   -0.0952547   -0.136249
  0.099949     -0.0829631   -0.0357835    0.204612    -0.115448     0.0256964    0.0896943    0.0184188   0.00337354  -0.128141    -0.0285688    0.0776763    0.0457573   0.12148     -0.0809404   -0.0632182    0.0913042    0.0770628    0.19648      0.0628432     0.0892004   -0.00177198   0.039204     0.140542     0.0621991   -0.0635117
 -0.0130024    -0.056682     0.156632    -0.0219938    0.0370438   -0.00766104  -0.16728      0.166676   -0.0476919   -0.0793655   -0.0527177   -0.105307     0.124766   -0.0545822   -0.104336    -0.0327394   -0.144276     0.157194    -0.0977425   -0.267945     -0.0264798    0.092559    -0.0101068   -0.127136     0.041431    -0.0665611
  0.146975      0.0010254   -0.071655     0.0954442   -0.11265     -0.0108308    0.00616933   0.064319   -0.0691874   -0.149826    -0.0221993    0.0645123    0.0560632  -0.0605198   -0.261567     0.166468     0.0786057   -0.0496905   -0.100564     0.066298      0.0427472    0.0437392    0.166486    -0.129111     0.0236661    0.0406516
  0.275523      0.0604446    0.0834844    0.00137896   0.082791     0.144887     0.1136       0.144452    0.0536152   -0.143403    -0.0296262   -0.112925    -0.15684     0.0197318    0.123262    -0.140812    -0.107768    -0.0469984   -0.021883    -0.0727644     0.0468999   -0.055224    -0.0684643    0.0684144   -0.0952035    0.0919254
  0.207575      0.157025     0.0122901   -0.00807247  -0.116801    -0.0380216    0.074163    -0.172728   -0.0284604    0.0225935    0.027362    -0.0202856    0.107315    0.0109176   -0.0435208    0.0483763   -0.0691459    0.0227165   -0.0417429   -0.0662501    -0.0958035    0.0471643   -0.129241    -0.0437383    0.0877366    0.0738468
  0.000246171  -0.00993704   0.00640317  -0.134792     0.122914     0.0177866    0.156137    -0.0725892  -0.0169262    0.152364    -0.0254724    0.117039    -0.0558734   0.0432725    0.0504201    0.153341    -0.0782028    0.0342979   -0.0373167    0.0208808     0.00930331  -0.0295668    0.00301897  -0.167711    -0.0734421    0.0333254
 -0.168183     -0.128149    -0.0486906   -0.117228    -0.0114456   -0.137445     0.17039      0.0316785   0.0734062   -0.162648     0.0511783   -0.0489526   -0.0130305   0.0453401   -0.0908663    0.00242287   0.10208     -0.111111     0.0601362    0.200641      0.0111235    0.104909     0.0275418   -0.0398878    0.0478092    0.0743946
 -0.000646474  -0.11502     -0.192184    -0.00265804   0.0595477   -0.0125516   -0.0437651   -0.0193395   0.0106987    0.110978     0.0337779    0.0246138   -0.116627    0.145547     0.0246911    0.0160529   -0.0236865   -0.0925234    0.100134     0.0814172    -0.0226496   -0.057437     0.0370358    0.216598     0.147307     0.0381578
  0.00143358   -0.0553134    0.131124    -0.0354618   -0.0561599    0.0619495   -0.0317364    0.170233   -0.0312231    0.0418678    0.0334281   -0.0132154   -0.0186233  -0.0714408    0.174709    -0.1338      -0.171502     0.249301    -0.00501838   0.172542     -0.14023      0.0148922    0.040253    -0.359082    -0.0570917   -0.13574
  0.0173931    -0.00177094  -0.0485648   -0.217678    -0.131218    -0.0570156   -0.221537     0.0287272  -0.143467     0.137207     0.0348128    0.0678448   -0.0680747  -0.00199019   0.185678     0.00691852  -0.0131679   -0.00429855  -0.0307635    0.0709539    -0.0524546    0.0743451   -0.0173655    0.0662694   -0.0735063    0.0686727
  0.0259714     0.0553559    0.0115186    0.141688     0.0352012    0.174029     0.183752    -0.195634   -0.0388254   -0.0955018    0.107172     0.0681866   -0.0562235  -0.0996334    0.0468629    0.139156     0.0302266    0.12274     -0.0505044    0.155799      0.0393612    0.083017    -0.107889    -0.169603     0.191048    -0.0925
 -0.0384033    -0.045724    -0.189591     0.102263     0.102258    -0.105764    -0.0626264   -0.0616947  -0.0948686    0.0307249   -0.299923    -0.109377     0.13533    -0.0598074   -0.0751766    0.0851786   -0.0336666    0.0314595    0.0649215    0.0982858    -0.132225    -0.11736      0.0511209   -0.104528    -0.00672737   0.0153525
 -0.0344224     0.0463956   -0.0795994   -0.0481006    0.172143     0.0102196   -0.107208    -0.155553   -0.0950829   -0.0281784    0.255552     0.146533     0.0201993  -0.0529426   -0.0119213   -0.0882377   -0.120489     0.050549    -0.0895008   -0.240396     -0.0495027    0.0228244    0.0117013    0.126455     0.0328029   -0.0585557
 -0.0171416    -0.0791515    0.0285172   -0.0913034   -0.0687008   -0.18895     -0.0845565    0.200658   -0.0147137    0.0191861   -0.177822    -0.0541135    0.0339179   0.151097     0.0168408   -0.151248     0.0464312   -0.0950404    0.0770473    0.0909957    -0.0992218   -0.0196746   -0.0341455   -0.155435     0.143327    -0.120401
  0.000804251  -0.0329102    0.0126365    0.0145232    0.00242376   0.142769     0.12182     -0.0795728   0.128982     0.276441     0.0122771   -0.102156     0.0852477   0.101593    -0.0527168    0.116922     0.00303656  -0.0754604   -0.0498907   -0.231545      0.0300582   -0.00263594  -0.0123379    0.216844    -0.104087     0.0251572
 -0.0532685     0.033213    -0.0322971   -0.16732      0.0159255   -0.0929594    0.0476805    0.0320353   0.102342    -0.102876    -0.0530703    0.303807    -0.0223463   0.130053    -0.0753995    0.194309    -0.0459671    0.132791    -0.0528051   -0.000497506  -0.208306     0.052445    -0.099996    -0.0764095    0.117224     0.0304751kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4240045454120656
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424024
[ Info: iteration 2, average log likelihood -1.423976
[ Info: iteration 3, average log likelihood -1.423947
[ Info: iteration 4, average log likelihood -1.423912
[ Info: iteration 5, average log likelihood -1.423866
[ Info: iteration 6, average log likelihood -1.423794
[ Info: iteration 7, average log likelihood -1.423656
[ Info: iteration 8, average log likelihood -1.423345
[ Info: iteration 9, average log likelihood -1.422645
[ Info: iteration 10, average log likelihood -1.421394
[ Info: iteration 11, average log likelihood -1.419956
[ Info: iteration 12, average log likelihood -1.419000
[ Info: iteration 13, average log likelihood -1.418595
[ Info: iteration 14, average log likelihood -1.418453
[ Info: iteration 15, average log likelihood -1.418403
[ Info: iteration 16, average log likelihood -1.418385
[ Info: iteration 17, average log likelihood -1.418378
[ Info: iteration 18, average log likelihood -1.418375
[ Info: iteration 19, average log likelihood -1.418374
[ Info: iteration 20, average log likelihood -1.418373
[ Info: iteration 21, average log likelihood -1.418373
[ Info: iteration 22, average log likelihood -1.418373
[ Info: iteration 23, average log likelihood -1.418373
[ Info: iteration 24, average log likelihood -1.418373
[ Info: iteration 25, average log likelihood -1.418373
[ Info: iteration 26, average log likelihood -1.418372
[ Info: iteration 27, average log likelihood -1.418372
[ Info: iteration 28, average log likelihood -1.418372
[ Info: iteration 29, average log likelihood -1.418372
[ Info: iteration 30, average log likelihood -1.418372
[ Info: iteration 31, average log likelihood -1.418372
[ Info: iteration 32, average log likelihood -1.418372
[ Info: iteration 33, average log likelihood -1.418372
[ Info: iteration 34, average log likelihood -1.418372
[ Info: iteration 35, average log likelihood -1.418372
[ Info: iteration 36, average log likelihood -1.418372
[ Info: iteration 37, average log likelihood -1.418372
[ Info: iteration 38, average log likelihood -1.418372
[ Info: iteration 39, average log likelihood -1.418372
[ Info: iteration 40, average log likelihood -1.418372
[ Info: iteration 41, average log likelihood -1.418372
[ Info: iteration 42, average log likelihood -1.418372
[ Info: iteration 43, average log likelihood -1.418372
[ Info: iteration 44, average log likelihood -1.418372
[ Info: iteration 45, average log likelihood -1.418372
[ Info: iteration 46, average log likelihood -1.418372
[ Info: iteration 47, average log likelihood -1.418372
[ Info: iteration 48, average log likelihood -1.418372
[ Info: iteration 49, average log likelihood -1.418372
[ Info: iteration 50, average log likelihood -1.418372
┌ Info: EM with 100000 data points 50 iterations avll -1.418372
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.424023654335837
│     -1.4239763601074729
│      ⋮
└     -1.4183715695573276
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418387
[ Info: iteration 2, average log likelihood -1.418326
[ Info: iteration 3, average log likelihood -1.418278
[ Info: iteration 4, average log likelihood -1.418222
[ Info: iteration 5, average log likelihood -1.418152
[ Info: iteration 6, average log likelihood -1.418065
[ Info: iteration 7, average log likelihood -1.417964
[ Info: iteration 8, average log likelihood -1.417855
[ Info: iteration 9, average log likelihood -1.417747
[ Info: iteration 10, average log likelihood -1.417650
[ Info: iteration 11, average log likelihood -1.417568
[ Info: iteration 12, average log likelihood -1.417504
[ Info: iteration 13, average log likelihood -1.417453
[ Info: iteration 14, average log likelihood -1.417414
[ Info: iteration 15, average log likelihood -1.417382
[ Info: iteration 16, average log likelihood -1.417355
[ Info: iteration 17, average log likelihood -1.417331
[ Info: iteration 18, average log likelihood -1.417311
[ Info: iteration 19, average log likelihood -1.417292
[ Info: iteration 20, average log likelihood -1.417275
[ Info: iteration 21, average log likelihood -1.417259
[ Info: iteration 22, average log likelihood -1.417244
[ Info: iteration 23, average log likelihood -1.417231
[ Info: iteration 24, average log likelihood -1.417219
[ Info: iteration 25, average log likelihood -1.417207
[ Info: iteration 26, average log likelihood -1.417197
[ Info: iteration 27, average log likelihood -1.417187
[ Info: iteration 28, average log likelihood -1.417179
[ Info: iteration 29, average log likelihood -1.417171
[ Info: iteration 30, average log likelihood -1.417163
[ Info: iteration 31, average log likelihood -1.417157
[ Info: iteration 32, average log likelihood -1.417151
[ Info: iteration 33, average log likelihood -1.417146
[ Info: iteration 34, average log likelihood -1.417141
[ Info: iteration 35, average log likelihood -1.417137
[ Info: iteration 36, average log likelihood -1.417134
[ Info: iteration 37, average log likelihood -1.417131
[ Info: iteration 38, average log likelihood -1.417128
[ Info: iteration 39, average log likelihood -1.417126
[ Info: iteration 40, average log likelihood -1.417124
[ Info: iteration 41, average log likelihood -1.417122
[ Info: iteration 42, average log likelihood -1.417120
[ Info: iteration 43, average log likelihood -1.417119
[ Info: iteration 44, average log likelihood -1.417118
[ Info: iteration 45, average log likelihood -1.417117
[ Info: iteration 46, average log likelihood -1.417116
[ Info: iteration 47, average log likelihood -1.417115
[ Info: iteration 48, average log likelihood -1.417115
[ Info: iteration 49, average log likelihood -1.417114
[ Info: iteration 50, average log likelihood -1.417114
┌ Info: EM with 100000 data points 50 iterations avll -1.417114
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4183867091297357
│     -1.41832591480716
│      ⋮
└     -1.4171135052906645
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417127
[ Info: iteration 2, average log likelihood -1.417076
[ Info: iteration 3, average log likelihood -1.417036
[ Info: iteration 4, average log likelihood -1.416991
[ Info: iteration 5, average log likelihood -1.416934
[ Info: iteration 6, average log likelihood -1.416864
[ Info: iteration 7, average log likelihood -1.416780
[ Info: iteration 8, average log likelihood -1.416683
[ Info: iteration 9, average log likelihood -1.416577
[ Info: iteration 10, average log likelihood -1.416468
[ Info: iteration 11, average log likelihood -1.416366
[ Info: iteration 12, average log likelihood -1.416275
[ Info: iteration 13, average log likelihood -1.416200
[ Info: iteration 14, average log likelihood -1.416140
[ Info: iteration 15, average log likelihood -1.416094
[ Info: iteration 16, average log likelihood -1.416057
[ Info: iteration 17, average log likelihood -1.416027
[ Info: iteration 18, average log likelihood -1.416002
[ Info: iteration 19, average log likelihood -1.415979
[ Info: iteration 20, average log likelihood -1.415957
[ Info: iteration 21, average log likelihood -1.415936
[ Info: iteration 22, average log likelihood -1.415915
[ Info: iteration 23, average log likelihood -1.415894
[ Info: iteration 24, average log likelihood -1.415872
[ Info: iteration 25, average log likelihood -1.415850
[ Info: iteration 26, average log likelihood -1.415827
[ Info: iteration 27, average log likelihood -1.415803
[ Info: iteration 28, average log likelihood -1.415779
[ Info: iteration 29, average log likelihood -1.415754
[ Info: iteration 30, average log likelihood -1.415728
[ Info: iteration 31, average log likelihood -1.415702
[ Info: iteration 32, average log likelihood -1.415677
[ Info: iteration 33, average log likelihood -1.415651
[ Info: iteration 34, average log likelihood -1.415627
[ Info: iteration 35, average log likelihood -1.415603
[ Info: iteration 36, average log likelihood -1.415580
[ Info: iteration 37, average log likelihood -1.415559
[ Info: iteration 38, average log likelihood -1.415539
[ Info: iteration 39, average log likelihood -1.415520
[ Info: iteration 40, average log likelihood -1.415502
[ Info: iteration 41, average log likelihood -1.415485
[ Info: iteration 42, average log likelihood -1.415469
[ Info: iteration 43, average log likelihood -1.415455
[ Info: iteration 44, average log likelihood -1.415441
[ Info: iteration 45, average log likelihood -1.415429
[ Info: iteration 46, average log likelihood -1.415417
[ Info: iteration 47, average log likelihood -1.415405
[ Info: iteration 48, average log likelihood -1.415395
[ Info: iteration 49, average log likelihood -1.415385
[ Info: iteration 50, average log likelihood -1.415375
┌ Info: EM with 100000 data points 50 iterations avll -1.415375
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4171268400648234
│     -1.4170762701489485
│      ⋮
└     -1.4153749258292574
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415375
[ Info: iteration 2, average log likelihood -1.415307
[ Info: iteration 3, average log likelihood -1.415243
[ Info: iteration 4, average log likelihood -1.415169
[ Info: iteration 5, average log likelihood -1.415079
[ Info: iteration 6, average log likelihood -1.414970
[ Info: iteration 7, average log likelihood -1.414845
[ Info: iteration 8, average log likelihood -1.414711
[ Info: iteration 9, average log likelihood -1.414575
[ Info: iteration 10, average log likelihood -1.414445
[ Info: iteration 11, average log likelihood -1.414324
[ Info: iteration 12, average log likelihood -1.414216
[ Info: iteration 13, average log likelihood -1.414120
[ Info: iteration 14, average log likelihood -1.414036
[ Info: iteration 15, average log likelihood -1.413963
[ Info: iteration 16, average log likelihood -1.413900
[ Info: iteration 17, average log likelihood -1.413845
[ Info: iteration 18, average log likelihood -1.413797
[ Info: iteration 19, average log likelihood -1.413755
[ Info: iteration 20, average log likelihood -1.413718
[ Info: iteration 21, average log likelihood -1.413684
[ Info: iteration 22, average log likelihood -1.413653
[ Info: iteration 23, average log likelihood -1.413625
[ Info: iteration 24, average log likelihood -1.413598
[ Info: iteration 25, average log likelihood -1.413573
[ Info: iteration 26, average log likelihood -1.413549
[ Info: iteration 27, average log likelihood -1.413526
[ Info: iteration 28, average log likelihood -1.413504
[ Info: iteration 29, average log likelihood -1.413483
[ Info: iteration 30, average log likelihood -1.413462
[ Info: iteration 31, average log likelihood -1.413442
[ Info: iteration 32, average log likelihood -1.413423
[ Info: iteration 33, average log likelihood -1.413405
[ Info: iteration 34, average log likelihood -1.413387
[ Info: iteration 35, average log likelihood -1.413369
[ Info: iteration 36, average log likelihood -1.413352
[ Info: iteration 37, average log likelihood -1.413336
[ Info: iteration 38, average log likelihood -1.413320
[ Info: iteration 39, average log likelihood -1.413305
[ Info: iteration 40, average log likelihood -1.413291
[ Info: iteration 41, average log likelihood -1.413276
[ Info: iteration 42, average log likelihood -1.413263
[ Info: iteration 43, average log likelihood -1.413249
[ Info: iteration 44, average log likelihood -1.413236
[ Info: iteration 45, average log likelihood -1.413224
[ Info: iteration 46, average log likelihood -1.413212
[ Info: iteration 47, average log likelihood -1.413200
[ Info: iteration 48, average log likelihood -1.413188
[ Info: iteration 49, average log likelihood -1.413176
[ Info: iteration 50, average log likelihood -1.413165
┌ Info: EM with 100000 data points 50 iterations avll -1.413165
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4153748137132776
│     -1.4153072768385704
│      ⋮
└     -1.4131652789870968
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413163
[ Info: iteration 2, average log likelihood -1.413084
[ Info: iteration 3, average log likelihood -1.413006
[ Info: iteration 4, average log likelihood -1.412911
[ Info: iteration 5, average log likelihood -1.412791
[ Info: iteration 6, average log likelihood -1.412639
[ Info: iteration 7, average log likelihood -1.412457
[ Info: iteration 8, average log likelihood -1.412257
[ Info: iteration 9, average log likelihood -1.412052
[ Info: iteration 10, average log likelihood -1.411857
[ Info: iteration 11, average log likelihood -1.411679
[ Info: iteration 12, average log likelihood -1.411520
[ Info: iteration 13, average log likelihood -1.411380
[ Info: iteration 14, average log likelihood -1.411256
[ Info: iteration 15, average log likelihood -1.411147
[ Info: iteration 16, average log likelihood -1.411051
[ Info: iteration 17, average log likelihood -1.410966
[ Info: iteration 18, average log likelihood -1.410890
[ Info: iteration 19, average log likelihood -1.410823
[ Info: iteration 20, average log likelihood -1.410763
[ Info: iteration 21, average log likelihood -1.410708
[ Info: iteration 22, average log likelihood -1.410659
[ Info: iteration 23, average log likelihood -1.410613
[ Info: iteration 24, average log likelihood -1.410571
[ Info: iteration 25, average log likelihood -1.410532
[ Info: iteration 26, average log likelihood -1.410496
[ Info: iteration 27, average log likelihood -1.410461
[ Info: iteration 28, average log likelihood -1.410429
[ Info: iteration 29, average log likelihood -1.410399
[ Info: iteration 30, average log likelihood -1.410370
[ Info: iteration 31, average log likelihood -1.410342
[ Info: iteration 32, average log likelihood -1.410316
[ Info: iteration 33, average log likelihood -1.410292
[ Info: iteration 34, average log likelihood -1.410268
[ Info: iteration 35, average log likelihood -1.410245
[ Info: iteration 36, average log likelihood -1.410224
[ Info: iteration 37, average log likelihood -1.410203
[ Info: iteration 38, average log likelihood -1.410183
[ Info: iteration 39, average log likelihood -1.410164
[ Info: iteration 40, average log likelihood -1.410146
[ Info: iteration 41, average log likelihood -1.410129
[ Info: iteration 42, average log likelihood -1.410112
[ Info: iteration 43, average log likelihood -1.410097
[ Info: iteration 44, average log likelihood -1.410081
[ Info: iteration 45, average log likelihood -1.410067
[ Info: iteration 46, average log likelihood -1.410053
[ Info: iteration 47, average log likelihood -1.410039
[ Info: iteration 48, average log likelihood -1.410026
[ Info: iteration 49, average log likelihood -1.410014
[ Info: iteration 50, average log likelihood -1.410001
┌ Info: EM with 100000 data points 50 iterations avll -1.410001
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4131633715821632
│     -1.4130837730015993
│      ⋮
└     -1.4100014964792689
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4240045454120656
│     -1.424023654335837
│     -1.4239763601074729
│     -1.423946531132433
│      ⋮
│     -1.4100261846792637
│     -1.4100136295151098
└     -1.4100014964792689
32×26 Array{Float64,2}:
  0.32216     -0.181725    -0.0751842  -0.0654229    0.0351505   -0.0171127   -0.227183     -0.284588   -0.533499    -0.156308    -0.31868     -0.4071     -0.251201    -0.0297388    0.0213445    -0.464126    -0.0205763   0.486907   -0.0147701   0.126183     0.118086   -0.0598947  -0.141946    0.233116     0.191518   -0.0366502
  0.19033      0.0820291   -0.209775   -0.121221     0.437223    -0.502796    -0.174425     -0.225927   -0.381484    -0.0618482    0.139408    -0.281923    0.268345    -0.0724708   -0.177051      0.374031     0.171488    0.211449    0.195906   -0.158071    -0.196205    0.100378    0.238445   -0.00917884  -0.729688    0.133847
  0.0684197   -0.0478135   -0.221361   -0.0400068   -0.364832    -0.0433534   -0.183897      0.120185    0.0574721    0.0639096   -0.099256    -0.0635476   0.137835     0.0726456    0.0337437     0.221281     0.0171647  -0.182316   -0.0280674   0.0142491    0.103213    0.180965    0.0514395   0.257068    -0.0338222   0.00727724
 -0.0453998    0.0839223    0.182939    0.0467869    0.133662     0.065784     0.117102      0.0204084   0.0903145   -0.00921503   0.115113     0.0772468  -0.113325    -0.0427364    0.0147957    -0.0169685   -0.0951354   0.040858   -0.145638   -0.0208081   -0.02464    -0.055758   -0.0176428  -0.202325     0.0931419  -0.0163818
 -0.200247     0.00927472   0.285353   -0.370617    -0.123955    -0.662394    -0.809932      0.612712    0.320035    -0.160762    -0.345133    -0.797824   -0.358325    -0.396558     0.239954      0.103174     0.669782   -0.451831   -0.0141924   0.894535    -0.534681   -0.115082   -0.724261    0.00260841   0.0608943  -0.40551
 -0.26076     -0.0972764   -0.0858144  -0.691332     0.228833    -0.0643211   -0.38616      -0.172503    0.0346543    0.711275    -0.141063     0.924863    0.23759     -0.332319    -0.186471      0.0772154    0.216575   -0.145668    0.290279    0.618115    -0.554113    0.0344403  -0.0443927   0.0970513    0.453281   -0.199804
 -0.0211645    0.596004    -0.109571   -0.285549    -0.106268    -0.442481     0.0975588     0.243948   -0.0262345   -0.0938649   -0.294793     0.0317723   0.743965    -0.804888     0.633614      0.126861    -0.361276    0.139427    0.100746    0.0617629    0.110754   -0.170908    0.0999312   0.160914     0.260724   -0.00012552
 -0.10462      0.438613     0.270295   -0.191269     0.0279646   -0.271006     0.516617      0.076005    0.201958     0.0367529   -0.245032     0.389356    0.530156     0.00559585   0.34959       0.509064     0.799445   -0.579305   -0.404416    0.306021    -0.0221232   0.503691    0.0566228  -0.141603    -0.0454555  -0.0403286
  0.483492    -0.299075    -0.318604    0.434356    -0.195789     0.646844    -0.633061     -0.455112    0.505386    -0.0845125    0.582244     0.0606496  -0.0623361   -0.209557    -0.150752     -0.297838    -0.939892    0.517494    0.411843   -0.612085     0.0463739  -0.218586   -0.0588983  -0.0676242    0.430639    0.0441388
 -0.0693321   -0.0262458   -0.103536    0.585047     0.172924     0.481013     0.480084     -0.127917   -0.33656      0.0410675    0.281899     0.326561    0.237127     0.254013    -0.115663     -0.317407    -0.444331    0.664504    0.333363   -0.549501     0.223993   -0.0503433   0.0872441  -0.0639376   -0.131386    0.043892
 -0.476752     0.192625    -0.378468   -0.143423    -0.605682     0.0581735   -0.487984      0.201934    0.0169883    0.297019    -0.097934    -0.0111803  -0.603479    -0.0326419   -0.283736     -0.11768     -0.615504    0.0123966  -0.50034     0.00203248  -0.174384   -0.393096    0.227822    0.354796     0.413512    0.188232
 -0.889269    -0.289889     0.315641    0.0759695   -0.00127993  -0.0420686   -0.281152      0.224805   -0.34493     -0.170518     0.507434     0.0885336  -0.430498    -0.0809979   -0.310053     -0.00297653  -0.464258    0.531646   -0.302661    0.313807    -0.0397812   0.0298818  -0.5576      0.305986     0.0751222  -0.283978
  0.116955    -0.00290073  -0.43402     0.299064     0.0148416   -0.0296786    0.293464      0.472829    0.135853     0.164942    -0.00886378   0.360536    0.150662     0.148765     0.190813     -0.379454     0.512859   -0.0956737   0.604905   -0.190057    -0.151052   -0.0105867  -0.235462   -0.302166     0.390286   -0.429652
 -0.0371031   -0.0931687   -0.4298      0.0487235   -0.318701    -0.49754      0.0286901     0.93102     0.672495    -0.0742954    0.53756      0.307187   -0.142693    -0.161526    -0.373352      0.191123     0.329232   -0.265381    0.665155   -0.134436    -0.309271   -0.0758686  -0.389345   -0.538952    -0.18653     0.56838
 -0.00391636  -0.472691     0.0943733   0.119486     0.11695      0.273083    -0.00774341   -0.255284   -0.0286863    0.138104     0.399371     0.267479   -0.505298     0.865209    -0.605445      0.20664      0.223342   -0.338585   -0.099735   -0.0598823   -0.232225    0.207832   -0.158915   -0.254408    -0.289888   -0.260579
 -0.476774    -0.0875841    0.527888    0.0992373   -0.313842     0.633734     0.570724      0.531372    0.319815     0.381279    -0.067079     0.536874    0.062524     0.240208    -0.15141       0.00032378  -0.432782   -0.55812    -0.323107    0.410863    -0.058959   -0.358833   -0.242404   -0.27369      0.047245    0.447034
  0.257472    -0.468542    -0.807287    0.00690945   0.0467285    0.00669671  -0.0254663    -0.621476   -0.0585007    0.504512    -0.725706     0.337252    0.876894     0.807815    -0.149987     -0.0837234    0.149025   -0.25756     0.807281   -0.174739     0.263673    0.167809    0.0990735   0.679213     0.143481   -0.398158
 -0.0474011   -0.444644     0.317583    0.00241406  -0.0252502    0.45318      0.380464     -0.143251   -0.00185218   0.0340019   -0.00432095  -0.283627    0.535499     0.93464      0.48511       0.157987     0.0927405  -0.0131873  -0.0500646   0.209463     0.409938    0.494787   -0.434375    0.399714    -0.3861     -0.418955
  0.0533122    0.375288     0.466105   -0.13824      0.366266     0.456084     0.309316     -0.905288   -0.663512    -0.174681    -0.446235     0.264042    0.072548     0.410786     0.294548     -0.208066    -0.340823   -0.0448949  -0.998979   -0.318807     0.29384     0.402111    0.37302     0.155721     0.332817   -0.526946
  0.0034305   -0.388341     0.498137    0.0220287    0.304647     0.385712    -0.192064     -0.718155   -0.691554     0.00577648  -0.485797    -0.356742   -0.189729    -0.462357     0.116678     -0.142113    -0.704158    0.663222   -0.0511712   1.00514      0.379713    0.0785528   0.241744    0.468386     0.027942    0.459153
  0.291098     0.338903    -0.489427   -0.116426     0.0521032   -0.575737    -0.595786     -0.412099    0.0374496    0.163859     0.490214    -0.399754    0.606951    -0.422992     0.417558      0.161223     0.624093    0.69909     0.521545   -0.346787    -0.0602221   0.423753   -0.124849    0.0120757    0.121192   -0.554694
  0.394558     0.835496     0.0697691   0.126041     0.0143625   -0.171587     0.0335379    -0.347374    0.323579     0.3823      -0.0952436   -0.632932    0.536787     0.406719     0.0438884    -0.102666     0.715527    0.182786    0.17209     0.392973     0.257292   -0.0346432   0.113416   -0.111362     0.24839     0.725701
  0.228424     0.236989    -0.406585   -0.388262     0.199261     0.789151    -0.000906178  -0.18292     0.515352     0.0570122    0.370177     0.228421    0.380555     0.214585    -0.127706      0.41118      0.109478   -0.291079   -0.43827    -0.669392     0.528826    0.71747     0.57036     0.0744514   -0.578638    0.381186
  0.13471     -0.212116    -0.271887    0.244272    -0.750507     1.16243      0.0278558     0.557148    0.409612     0.0808245   -0.414574    -0.356504   -0.00297802   0.0134773   -0.298619     -0.817388    -0.164813   -0.573494    0.227893   -0.334774     0.634284   -0.0678102   0.668005    0.841579    -0.0390889   0.35131
  0.312643    -0.495809    -0.196824   -0.811791    -0.0657794   -0.586116    -0.127848      0.029411   -0.529929    -0.240906    -0.363997     0.223977   -0.321417    -0.353489    -0.385533      0.431056    -0.0626447  -0.38902    -0.148359   -0.136324    -0.513477    0.225041    0.540509   -0.291069    -0.283312   -0.531672
  0.287453     0.387313    -1.01821     0.530119    -0.110564    -0.358047     0.190798     -0.0495865  -0.539216    -0.233241    -0.581734    -0.0172823  -0.450161    -0.134678    -0.219877      0.0589456   -0.099162    0.272643    0.784125   -0.105437    -0.366333   -0.023216    0.689454   -0.0925564    0.059894    0.121282
 -0.116317     0.0909661    0.0149989  -0.0290214   -0.0547287   -0.254416     0.0738394     0.266991    0.12474     -0.275758     0.0219806    0.223047   -0.0443406   -0.219052     0.0304295     0.273877     0.0319095  -0.275523   -0.209492   -0.0381985   -0.0490172   0.133239    0.0761212  -0.118245     0.0357243   0.0614551
  0.0249721   -0.423581    -0.145954    0.21858      0.117794     0.220769     0.183804      0.0407385  -0.223389     0.339694     0.242115    -0.185865   -0.0401012    0.646582    -0.44662      -0.480901    -0.0309752   0.35451     0.400332   -0.0572115   -0.28596    -0.607523   -0.315514    0.0287662    0.0406702  -0.157172
  0.0846542   -0.264347     0.964381   -0.233764     0.783228     0.112236    -0.00516426    0.129415    0.540872    -0.197286     0.203349    -0.623902    0.0347513   -0.365798     0.407397     -0.152002    -0.0704714  -0.0230659  -0.612773    0.0782349    0.121127   -0.0242271   0.124529   -0.172784    -0.558802    0.00106696
  0.261591     0.521012     0.279571    0.0205135    0.325554    -0.100379    -0.152929      0.134592    0.0309094   -0.299607     0.454376    -0.0674389  -0.756461    -0.512309     0.000127543  -0.455965    -0.0657772   0.280046   -0.539016    0.137708    -0.409291   -0.307112    0.0625113  -0.893828     0.452551    0.374247
 -0.139512     0.727315     0.0934418   0.708832    -0.438048    -0.385065     0.239028      0.132794    0.251602    -0.639095     0.464249    -0.225747   -0.394638    -0.0637613    0.182857      0.436896    -0.160689    0.171633   -0.571653   -0.639602     0.495692    0.175822   -0.191368    0.0496741    0.15611     0.195246
  0.760139    -0.372121     0.198681    0.376806    -0.23834     -0.142782     0.087263      0.209933    0.116833    -0.842096    -0.200437    -0.454334   -0.589256     0.0790635   -0.0512713     0.267718    -0.0983438  -0.62493    -0.5563     -0.0623732   -0.16623    -0.0979041   0.263021   -0.373776    -0.144846    0.191674[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409990
[ Info: iteration 2, average log likelihood -1.409978
[ Info: iteration 3, average log likelihood -1.409967
[ Info: iteration 4, average log likelihood -1.409957
[ Info: iteration 5, average log likelihood -1.409946
[ Info: iteration 6, average log likelihood -1.409936
[ Info: iteration 7, average log likelihood -1.409926
[ Info: iteration 8, average log likelihood -1.409916
[ Info: iteration 9, average log likelihood -1.409907
[ Info: iteration 10, average log likelihood -1.409898
┌ Info: EM with 100000 data points 10 iterations avll -1.409898
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.007388e+05
      1       7.074611e+05      -1.932777e+05 |       32
      2       6.926657e+05      -1.479541e+04 |       32
      3       6.873174e+05      -5.348220e+03 |       32
      4       6.846031e+05      -2.714301e+03 |       32
      5       6.828503e+05      -1.752825e+03 |       32
      6       6.815445e+05      -1.305804e+03 |       32
      7       6.805441e+05      -1.000394e+03 |       32
      8       6.797146e+05      -8.294969e+02 |       32
      9       6.790314e+05      -6.831789e+02 |       32
     10       6.784254e+05      -6.060212e+02 |       32
     11       6.779230e+05      -5.024238e+02 |       32
     12       6.775260e+05      -3.969920e+02 |       32
     13       6.771855e+05      -3.405209e+02 |       32
     14       6.768515e+05      -3.339792e+02 |       32
     15       6.765652e+05      -2.862861e+02 |       32
     16       6.763240e+05      -2.412324e+02 |       32
     17       6.761083e+05      -2.156535e+02 |       32
     18       6.759197e+05      -1.886442e+02 |       32
     19       6.757521e+05      -1.676066e+02 |       32
     20       6.755833e+05      -1.688013e+02 |       32
     21       6.754348e+05      -1.484488e+02 |       32
     22       6.752963e+05      -1.385545e+02 |       32
     23       6.751652e+05      -1.310999e+02 |       32
     24       6.750557e+05      -1.094664e+02 |       32
     25       6.749359e+05      -1.198023e+02 |       32
     26       6.748127e+05      -1.232302e+02 |       32
     27       6.747066e+05      -1.060528e+02 |       32
     28       6.746040e+05      -1.026107e+02 |       32
     29       6.745178e+05      -8.622596e+01 |       32
     30       6.744378e+05      -8.002729e+01 |       32
     31       6.743587e+05      -7.905678e+01 |       32
     32       6.742889e+05      -6.982282e+01 |       32
     33       6.742325e+05      -5.638594e+01 |       32
     34       6.741861e+05      -4.641067e+01 |       32
     35       6.741453e+05      -4.083425e+01 |       32
     36       6.741063e+05      -3.893407e+01 |       32
     37       6.740715e+05      -3.479309e+01 |       32
     38       6.740326e+05      -3.896534e+01 |       32
     39       6.739885e+05      -4.410839e+01 |       32
     40       6.739450e+05      -4.349684e+01 |       32
     41       6.739074e+05      -3.757137e+01 |       32
     42       6.738743e+05      -3.313018e+01 |       32
     43       6.738447e+05      -2.956646e+01 |       32
     44       6.738180e+05      -2.672131e+01 |       32
     45       6.737942e+05      -2.372330e+01 |       32
     46       6.737701e+05      -2.418183e+01 |       32
     47       6.737480e+05      -2.205648e+01 |       32
     48       6.737266e+05      -2.140403e+01 |       32
     49       6.737059e+05      -2.068630e+01 |       32
     50       6.736878e+05      -1.810173e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 673687.8164633731)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421505
[ Info: iteration 2, average log likelihood -1.416746
[ Info: iteration 3, average log likelihood -1.415517
[ Info: iteration 4, average log likelihood -1.414632
[ Info: iteration 5, average log likelihood -1.413670
[ Info: iteration 6, average log likelihood -1.412677
[ Info: iteration 7, average log likelihood -1.411891
[ Info: iteration 8, average log likelihood -1.411409
[ Info: iteration 9, average log likelihood -1.411141
[ Info: iteration 10, average log likelihood -1.410979
[ Info: iteration 11, average log likelihood -1.410867
[ Info: iteration 12, average log likelihood -1.410783
[ Info: iteration 13, average log likelihood -1.410714
[ Info: iteration 14, average log likelihood -1.410656
[ Info: iteration 15, average log likelihood -1.410606
[ Info: iteration 16, average log likelihood -1.410562
[ Info: iteration 17, average log likelihood -1.410523
[ Info: iteration 18, average log likelihood -1.410487
[ Info: iteration 19, average log likelihood -1.410454
[ Info: iteration 20, average log likelihood -1.410424
[ Info: iteration 21, average log likelihood -1.410396
[ Info: iteration 22, average log likelihood -1.410370
[ Info: iteration 23, average log likelihood -1.410346
[ Info: iteration 24, average log likelihood -1.410324
[ Info: iteration 25, average log likelihood -1.410303
[ Info: iteration 26, average log likelihood -1.410284
[ Info: iteration 27, average log likelihood -1.410265
[ Info: iteration 28, average log likelihood -1.410248
[ Info: iteration 29, average log likelihood -1.410232
[ Info: iteration 30, average log likelihood -1.410216
[ Info: iteration 31, average log likelihood -1.410201
[ Info: iteration 32, average log likelihood -1.410187
[ Info: iteration 33, average log likelihood -1.410174
[ Info: iteration 34, average log likelihood -1.410161
[ Info: iteration 35, average log likelihood -1.410148
[ Info: iteration 36, average log likelihood -1.410136
[ Info: iteration 37, average log likelihood -1.410125
[ Info: iteration 38, average log likelihood -1.410113
[ Info: iteration 39, average log likelihood -1.410103
[ Info: iteration 40, average log likelihood -1.410092
[ Info: iteration 41, average log likelihood -1.410082
[ Info: iteration 42, average log likelihood -1.410072
[ Info: iteration 43, average log likelihood -1.410062
[ Info: iteration 44, average log likelihood -1.410052
[ Info: iteration 45, average log likelihood -1.410043
[ Info: iteration 46, average log likelihood -1.410034
[ Info: iteration 47, average log likelihood -1.410025
[ Info: iteration 48, average log likelihood -1.410016
[ Info: iteration 49, average log likelihood -1.410007
[ Info: iteration 50, average log likelihood -1.409998
┌ Info: EM with 100000 data points 50 iterations avll -1.409998
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.19699      0.0369128    0.132687   -0.153888   -0.0324177   -0.0616865   0.086307     0.0631843   0.18081      0.21227    -0.0937497  -0.0482457    0.298761    0.0542755    0.0899379   0.223472    0.19066    -0.236459    -0.087039    0.0942495  -0.0345458   0.0321921     0.136801    -0.131661    -0.177909     0.10766
 -0.33536     -0.0789311    0.582139    0.363385   -0.375845     0.668099    0.494869     0.460011    0.485583     0.257104   -0.0923217   0.32378      0.0711749   0.139406     0.125434   -0.242039   -0.408569   -0.3894      -0.296749    0.358145    0.234705   -0.381681     -0.335791    -0.229133     0.411868     0.558797
  0.0232398    0.714958     0.489472    0.0963523   0.124496    -0.654015   -0.0242493    0.123152    0.476713    -0.187323    0.0993562  -0.285505     0.0347212  -0.0797136    0.558539    0.73363     0.642713   -0.00895633  -0.201816    0.809118   -0.318862    0.251533     -0.27255     -0.251395     0.457601    -0.459175
 -0.073502     0.350835    -0.665681   -0.0836866  -0.293047    -0.328582    0.328492     0.369615   -0.301423     0.277883   -1.0049      0.0961162    0.344367   -0.429842     0.320578   -0.144554    0.051568   -0.242658     0.236956    0.100841   -0.237361   -0.244868      0.479702     0.247023     0.0519659    0.0153754
 -0.132429    -0.523212     0.193791    0.0312807   0.0405621    0.204565   -0.0395588   -0.134493   -0.135634     0.0944971   0.430571    0.322366    -0.363397    0.553825    -0.546429    0.319384    0.0660771  -0.229531    -0.0856938   0.0979166  -0.304273    0.244904     -0.207162    -0.151153    -0.356262    -0.0940915
  0.376993     0.646354    -0.167252   -0.156855   -0.12829     -0.287127   -0.267199    -0.388361    0.0141025    0.270156   -0.0464383  -0.523714     0.677796   -0.102542     0.561222   -0.14887     0.348951    0.457269     0.123361   -0.250682    0.326164    0.219829      0.0088956    0.0861212    0.221447     0.160566
 -0.18632      0.380768     0.60889    -0.399226    0.00889373  -0.0665643   0.478425    -0.34954    -0.275696    -0.30141    -0.568937    0.774126     0.418099   -0.0172749    0.223045    0.575766    0.309818   -0.713095    -0.669832   -0.0650554  -0.0399748   0.56449       0.00114116  -0.194166    -0.183644    -0.148747
  0.577932    -0.488341    -0.263592    0.510406    0.227183     0.595409   -0.381074    -0.404616    0.333053     0.152673    0.549741   -0.0998695   -0.0191988   0.277991    -0.370081   -0.437624   -0.388543    0.471529     0.598187   -0.64347     0.0978587  -0.25015      -0.157323    -0.0990039    0.241565    -0.173593
  0.129332    -0.153153    -0.254125   -0.283025    0.130215     0.677673   -0.00590859   0.0266378   0.787231     0.1834      0.173876   -0.21132      0.628745    0.183267     0.147436    0.251602    0.322019   -0.439365    -0.145702   -0.264811    0.737338    0.563653      0.195104     0.40385     -0.571743     0.0557661
 -0.0590864   -0.50368     -0.370895   -0.651355    0.239464     0.131196   -0.180112    -0.159599   -0.0519998    0.766154   -0.315332    0.725495     0.385312    0.221943    -0.176693   -0.38882     0.373237   -0.243122     0.555617    0.458292   -0.384664    0.0255656    -0.0368549    0.0267622    0.475699    -0.592684
  0.151621     0.0932814   -0.877469    0.497047   -0.660662     0.200248   -0.0460936   -0.214199   -0.309412     0.299742   -0.207956    0.316336     0.169564    1.03687     -0.0584264   0.46606    -0.0194133  -0.101546     0.593214   -0.112635    0.107656    0.313929      0.0115673    0.34838      0.219706    -0.108617
 -0.393704    -0.459787    -0.386541    0.252822   -0.214537    -0.0130474   0.219868     0.370132   -0.38272     -0.943013   -0.0711209   0.22767     -0.298914   -0.486465     0.131438   -0.0268886  -0.452127    0.224174    -0.0844736  -0.149913    0.1179      0.184039     -0.160203     0.358281    -0.0249593   -0.380956
  0.276215    -0.416877     0.353145    0.129288    0.295509     0.303047   -0.112215    -0.672002   -0.731606    -0.205705   -0.281558   -0.318029     0.2607     -0.898666     0.426715   -0.125955   -0.459932    0.842623     0.525667    0.972134    0.291686    0.160835      0.0718529    0.312375     0.24495      0.575575
 -0.754832     0.194863     0.108251    0.0200772   0.182196     0.27498     0.0432666    0.0213998  -0.177205     0.589041    0.315373    0.354546     0.239162   -0.0142012    0.0846356  -0.183218   -0.118122    0.796082     0.134382    0.102573    0.163312    0.000199657  -0.397437     0.405746    -0.00374833  -0.0968641
 -0.416876     0.143703    -0.432638   -0.0619677  -0.0572845    0.136228    0.256049     0.782894    0.760063     0.232824    0.296995    0.325338    -0.48345     0.755478    -0.475787    0.139283    0.17412    -0.844554    -0.437896   -0.299425   -0.279743   -0.0951536    -0.101464    -0.437214    -0.254847    -0.271879
 -0.0899948    0.349311     0.0256976  -0.5104     -0.0196669   -0.716239   -0.573123     0.0886481   0.0429107    0.120822   -0.0904711   0.436357     0.118508   -0.823096    -0.129309    0.510544   -0.0323678  -0.240621    -0.237213    0.343348   -0.280134   -0.0211201    -0.0389811    0.207296     0.260577     0.0993597
  0.0486039   -0.0910067   -0.280162    0.334618   -0.0874459   -0.548382    0.256558     0.665632    0.431251    -0.0098083   0.398221    0.246944     0.269201    0.114804     0.11069     0.0521397   0.725544   -0.0578771    0.88569    -0.0680275  -0.36949     0.0854197    -0.619479    -0.406979    -0.28563      0.172436
  0.115737     0.476563    -0.685258    0.321186   -0.346185     0.0881396   0.0984862    0.248101    0.649369    -0.191157    0.259853    0.326702     0.167461   -0.496023    -0.128151   -0.0739086  -0.258564    0.150095     0.463955   -0.580832    0.0587159   0.0418675     0.18499     -0.0997031    0.570063     0.157717
 -0.480133    -0.0771703    0.17907     0.260735   -0.265879    -0.179323   -0.487788     0.123185   -0.246854    -0.0386937   0.478764    0.095459    -0.750063   -0.153926    -0.570241   -0.0112977  -0.989839    0.447183    -0.115217    0.124157   -0.482161   -0.571567     -0.20435     -0.0312763    0.399518     0.0694703
  0.00526895   0.536412     0.226341    0.715301   -0.257286    -0.306297    0.102831     0.0446002   0.00126075  -0.619936    0.421252   -0.642486    -0.519532    0.0452861   -0.0278766   0.570044   -0.237123    0.189085    -0.616358   -0.341017    0.493349    0.137261     -0.136861    -0.0430449   -0.254587     0.456154
 -0.0400966   -0.374813     0.493623    0.0399127   0.186614     0.453463    0.340999    -0.528864   -0.359586     0.0125991  -0.154508   -0.296072     0.244384    1.11257      0.272552    0.0288298  -0.0621727   0.0667516   -0.3507      0.329614    0.25855     0.390988     -0.305066     0.499646    -0.130656    -0.639102
  0.059232     0.00877874  -0.182227    0.0236811  -0.0622474   -0.0198528   0.021296     0.0574743   0.0808714    0.0835182   0.0384003  -0.00332488   0.0936615   0.00723291  -0.129056   -0.0426945   0.102685    0.031806     0.16063    -0.0312467  -0.030094   -0.0335214     0.0290733    0.0587724    0.0604716    0.0353358
  0.418781    -0.210115    -0.0438832   0.118298   -0.0229909   -0.327173   -0.256999    -0.208297   -0.57328     -0.0527598  -0.447835   -0.431294    -0.372861    0.24232     -0.170712   -0.393345    0.109487    0.251054     0.134607    0.0613918  -0.173757   -0.217658     -0.0933005    0.00425462   0.129294    -0.195815
  0.21969      0.338178     0.120214   -0.06699     0.197718    -0.013317   -0.0937326    0.295888    0.14912     -0.137326    0.358492    0.10906     -0.757825   -0.520723    -0.0813322  -0.608536    0.0616423   0.283947    -0.336842    0.148844   -0.458688   -0.239529     -0.00777935  -0.770467     0.498952     0.340075
  0.29171      0.0340717   -0.618595   -0.291235    0.454219    -0.918139   -0.278977    -0.202449   -0.392587    -0.155917    0.110985   -0.346699     0.060067   -0.305441    -0.179696    0.54722     0.138181    0.34773      0.257696   -0.30745    -0.338481    0.204661      0.636678    -0.163677    -0.70449     -0.379943
  0.128672    -0.132242    -0.219903    0.321222    0.271662     0.365437    0.876596    -0.163224   -0.84083      0.0400176  -0.0340765   0.066613     0.395184    0.693642    -0.354105   -0.570137   -0.396725    0.349222     0.211762   -0.528782    0.172874   -0.442976      0.495315    -0.160942    -0.446552     0.224171
 -0.237091     0.226396    -0.167963   -0.0627328   0.356288     0.46565     0.186422    -0.32846    -0.306023    -0.0833341   0.170242    1.03094     -0.341916    0.0037017   -0.0838422   0.226439   -0.361069    0.210008    -0.869258   -0.598498    0.280963    0.902227      1.0511      -0.292165     0.319964     0.254389
 -0.0336481    0.0466472   -0.0498274   0.114094   -0.00482906   0.0300596   0.0204119    0.0328145  -0.0611898   -0.170268    0.0756459   0.00335731  -0.0830204  -0.00853607   0.0604079  -0.0558622  -0.157183    0.0851811   -0.0398732  -0.0883704   0.0761073   0.0312202    -0.0524777    0.0279322    0.138702    -0.101805
  0.325919     0.0903626    0.734073   -0.116904    0.789834     0.698999    0.197317    -0.312364    0.219917    -0.642547    0.0307467  -0.518786    -0.106379   -0.131985     0.361212   -0.60141    -0.148789    0.180558    -0.595026   -0.251864    0.238288   -0.00249863    0.484743    -0.0730199   -0.70267      0.0665939
 -0.544252    -0.438157     0.708735   -0.547967    0.604458    -0.456622   -0.440524     0.542807    0.0172059   -0.169305    0.0258226  -0.81249     -0.270386   -0.449923     0.060616   -0.223981    0.160931   -0.156041    -0.585411    0.514972   -0.211917   -0.273554     -0.38722     -0.0207711   -0.244388    -0.154167
 -0.0959231   -0.0754563   -0.0620304  -0.349295   -0.618242     0.471631   -0.582346    -0.0795148  -0.222661     0.202975   -0.254948   -0.439422    -0.578906    0.0319646   -0.262813   -0.315529   -0.720651    0.0627299   -0.64222     0.165199    0.284557   -0.234329      0.422596     0.573869     0.212875     0.317021
  0.990405    -0.45893      0.144426    0.0588886  -0.195287    -0.221086    0.0711233    0.180574    0.215266    -0.92015    -0.167591   -0.311642    -0.452536   -0.195491    -0.0691722   0.341971    0.0965666  -0.822373    -0.211858   -0.0994439  -0.362747   -0.039481      0.438945    -0.671055    -0.101666     0.24426[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409989
[ Info: iteration 2, average log likelihood -1.409981
[ Info: iteration 3, average log likelihood -1.409972
[ Info: iteration 4, average log likelihood -1.409964
[ Info: iteration 5, average log likelihood -1.409955
[ Info: iteration 6, average log likelihood -1.409947
[ Info: iteration 7, average log likelihood -1.409938
[ Info: iteration 8, average log likelihood -1.409930
[ Info: iteration 9, average log likelihood -1.409922
[ Info: iteration 10, average log likelihood -1.409914
┌ Info: EM with 100000 data points 10 iterations avll -1.409914
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
