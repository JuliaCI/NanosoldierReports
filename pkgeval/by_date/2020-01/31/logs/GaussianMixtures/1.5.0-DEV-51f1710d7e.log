Julia Version 1.5.0-DEV.212
Commit 51f1710d7e (2020-01-31 07:16 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed GaussianMixtures ─── v0.3.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed Missings ─────────── v0.4.3
  Installed DataAPI ──────────── v1.1.0
  Installed Rmath ────────────── v0.6.0
  Installed JLD ──────────────── v0.9.2
  Installed Blosc ────────────── v0.5.1
  Installed PDMats ───────────── v0.9.11
  Installed SortingAlgorithms ── v0.3.1
  Installed CMake ────────────── v1.1.2
  Installed Compat ───────────── v2.2.0
  Installed SpecialFunctions ─── v0.9.0
  Installed StatsBase ────────── v0.32.0
  Installed StaticArrays ─────── v0.12.1
  Installed Clustering ───────── v0.13.3
  Installed BinaryProvider ───── v0.5.8
  Installed OrderedCollections ─ v1.1.0
  Installed URIParser ────────── v0.4.0
  Installed StatsFuns ────────── v0.9.3
  Installed FillArrays ───────── v0.8.4
  Installed Distances ────────── v0.8.2
  Installed Arpack ───────────── v0.4.0
  Installed Parameters ───────── v0.12.0
  Installed DataStructures ───── v0.17.9
  Installed HDF5 ─────────────── v0.12.5
  Installed CMakeWrapper ─────── v0.2.3
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed QuadGK ───────────── v2.3.1
  Installed ScikitLearnBase ──── v0.5.0
  Installed FileIO ───────────── v1.2.1
  Installed NearestNeighbors ─── v0.4.4
  Installed BinDeps ──────────── v1.0.0
  Installed LegacyStrings ────── v0.4.1
  Installed Distributions ────── v0.22.4
#=#=#                                                                         ######                                                                     8.7%######################                                                    31.0%##########################################                                58.6%#######################################################################   99.9%######################################################################## 100.0%
#=#=#                                                                         ##O#- #                                                                       ######################################################################## 100.0%
#####                                                                      7.0%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_cNuPxT/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -583797.790101707, [363.7442210808136, 99636.25577891922], [-51.20859625179456 -690.3354403830026 -738.6528576092448; 80.66648109724156 928.164091816237 648.5340981264455], [[332.44636472014145 91.36038626627963 69.26548622676788; 91.36038626627963 1403.5862878892417 1382.5223194672976; 69.26548622676788 1382.5223194672976 1545.314641074986], [100295.25047611652 282.1303502349184 134.04534500493605; 282.1303502349183 98887.81772239004 -1550.8667923582225; 134.04534500493602 -1550.8667923582225 97900.87252655276]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.310824e+03
      1       9.134523e+02      -3.973721e+02 |        7
      2       8.634752e+02      -4.997711e+01 |        0
      3       8.634752e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 863.4751617408856)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.083795
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.895333
[ Info: iteration 2, lowerbound -3.788448
[ Info: iteration 3, lowerbound -3.670616
[ Info: iteration 4, lowerbound -3.522038
[ Info: iteration 5, lowerbound -3.353394
[ Info: iteration 6, lowerbound -3.189225
[ Info: iteration 7, lowerbound -3.057545
[ Info: dropping number of Gaussions to 7
[ Info: iteration 8, lowerbound -2.964667
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.877416
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.787021
[ Info: iteration 11, lowerbound -2.697075
[ Info: iteration 12, lowerbound -2.610297
[ Info: iteration 13, lowerbound -2.530964
[ Info: iteration 14, lowerbound -2.467361
[ Info: iteration 15, lowerbound -2.423790
[ Info: dropping number of Gaussions to 3
[ Info: iteration 16, lowerbound -2.383748
[ Info: iteration 17, lowerbound -2.349081
[ Info: iteration 18, lowerbound -2.324043
[ Info: iteration 19, lowerbound -2.309503
[ Info: iteration 20, lowerbound -2.308627
[ Info: dropping number of Gaussions to 2
[ Info: iteration 21, lowerbound -2.302914
[ Info: iteration 22, lowerbound -2.299258
[ Info: iteration 23, lowerbound -2.299255
[ Info: iteration 24, lowerbound -2.299254
[ Info: iteration 25, lowerbound -2.299254
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan 31 22:14:40 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan 31 22:14:48 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Fri Jan 31 22:14:51 2020: EM with 272 data points 0 iterations avll -2.083795
5.8 data points per parameter
, Fri Jan 31 22:14:53 2020: GMM converted to Variational GMM
, Fri Jan 31 22:15:03 2020: iteration 1, lowerbound -3.895333
, Fri Jan 31 22:15:03 2020: iteration 2, lowerbound -3.788448
, Fri Jan 31 22:15:03 2020: iteration 3, lowerbound -3.670616
, Fri Jan 31 22:15:03 2020: iteration 4, lowerbound -3.522038
, Fri Jan 31 22:15:03 2020: iteration 5, lowerbound -3.353394
, Fri Jan 31 22:15:03 2020: iteration 6, lowerbound -3.189225
, Fri Jan 31 22:15:03 2020: iteration 7, lowerbound -3.057545
, Fri Jan 31 22:15:03 2020: dropping number of Gaussions to 7
, Fri Jan 31 22:15:03 2020: iteration 8, lowerbound -2.964667
, Fri Jan 31 22:15:03 2020: dropping number of Gaussions to 5
, Fri Jan 31 22:15:03 2020: iteration 9, lowerbound -2.877416
, Fri Jan 31 22:15:03 2020: dropping number of Gaussions to 4
, Fri Jan 31 22:15:03 2020: iteration 10, lowerbound -2.787021
, Fri Jan 31 22:15:03 2020: iteration 11, lowerbound -2.697075
, Fri Jan 31 22:15:03 2020: iteration 12, lowerbound -2.610297
, Fri Jan 31 22:15:03 2020: iteration 13, lowerbound -2.530964
, Fri Jan 31 22:15:03 2020: iteration 14, lowerbound -2.467361
, Fri Jan 31 22:15:03 2020: iteration 15, lowerbound -2.423790
, Fri Jan 31 22:15:03 2020: dropping number of Gaussions to 3
, Fri Jan 31 22:15:03 2020: iteration 16, lowerbound -2.383748
, Fri Jan 31 22:15:03 2020: iteration 17, lowerbound -2.349081
, Fri Jan 31 22:15:03 2020: iteration 18, lowerbound -2.324043
, Fri Jan 31 22:15:03 2020: iteration 19, lowerbound -2.309503
, Fri Jan 31 22:15:03 2020: iteration 20, lowerbound -2.308627
, Fri Jan 31 22:15:03 2020: dropping number of Gaussions to 2
, Fri Jan 31 22:15:03 2020: iteration 21, lowerbound -2.302914
, Fri Jan 31 22:15:03 2020: iteration 22, lowerbound -2.299258
, Fri Jan 31 22:15:03 2020: iteration 23, lowerbound -2.299255
, Fri Jan 31 22:15:03 2020: iteration 24, lowerbound -2.299254
, Fri Jan 31 22:15:03 2020: iteration 25, lowerbound -2.299254
, Fri Jan 31 22:15:03 2020: iteration 26, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 27, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 28, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 29, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 30, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 31, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 32, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 33, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 34, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 35, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 36, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 37, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 38, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 39, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 40, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 41, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 42, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 43, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 44, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 45, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 46, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 47, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 48, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 49, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: iteration 50, lowerbound -2.299253
, Fri Jan 31 22:15:03 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601456, 95.95490777398548]
β = [178.04509222601456, 95.95490777398548]
m = [4.250300733269904 79.28686694436175; 2.0002292577753646 53.85198717246126]
ν = [180.04509222601456, 97.95490777398548]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484463 -0.007644049042327408; 0.0 0.008581705166333355], [0.3758763611948488 -0.00895312382734607; 0.0 0.012748664777409411]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9645686013352294
avll from llpg:  -0.9645686013352298
avll direct:     -0.9645686013352299
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9671720661657341
avll from llpg:  -0.9671720661657341
avll direct:     -0.967172066165734
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.0326971   -0.0263692   -0.0655789    0.0527049    0.105153     0.125792      0.0627454    -0.161582   -0.0755302   0.158053     0.0427413   -0.243615     0.0216224  -0.148533    -0.0552152    0.0637186    0.00908023   0.176019   -0.0381289   -0.239129     -0.0558035   -0.0436321   -0.152029     -0.041427     0.028114    -0.0226241
  0.0232106    0.0485782   -0.167182     0.0914381    0.0688677   -0.0540124    -0.00983721   -0.0661276   0.0390601   0.121709    -0.334326    -0.0885763   -0.101527   -0.192593    -0.092264     0.0143095    0.113436    -0.223215    0.0616013   -0.129595     -0.111647    -0.0318585   -0.0673743    -0.0593757   -0.126922    -0.0179584
 -0.0638947   -0.0339323   -0.111587     0.231407     0.0580784   -0.0753632    -0.0132365     0.0653402   0.0337235   0.293674    -0.118538    -0.203033    -0.0396276  -0.0513944   -0.0695634   -0.0386348    0.060577     0.0622888  -0.0913777    0.10322      -0.116535    -0.078913    -0.0458151    -0.00431312   0.0715276   -0.0930856
  0.00358556  -0.0387798    0.115515    -0.135879    -0.138728    -0.0388079     0.0928874    -0.135275   -0.182089    0.199907     0.0320189   -0.014618     0.0106446   0.0532235    0.10684     -0.189191     0.236815    -0.129258   -0.225049    -0.175856      0.0149849    0.00829429  -0.0175646     0.0269926    0.197048     0.0551865
  0.0733324   -0.012448    -0.100259     0.0237181    0.00372133   0.0063655    -0.0319433     0.159457   -0.072346   -0.120292     0.181648     0.048841     0.0148175   0.0351383    0.25        -0.0609796   -0.101231    -0.0603068   0.00372007  -0.111982     -0.0810027    0.0647711    0.122813      0.0566651    8.76937e-5   0.204659
  0.0130131   -0.12911      0.0994412    0.0855576    0.216942    -0.00270638    0.0478686     0.190557    0.203819   -0.0141818   -0.0645618   -0.168808     0.0678091   0.00752355   0.0197959    0.00539188   0.148213     0.0268964   0.153371     0.00589979   -0.0853579   -0.143343    -0.0393016     0.0031623   -0.131845    -0.124045
  0.074105     0.058892    -0.0634667    0.0170027    0.0983451    0.0698777    -0.137485      0.184441    0.048246    0.0575705   -0.187994     0.142294     0.0485914   0.0879539    0.218757    -0.0237351    0.149094    -0.0212145  -0.0554505   -0.02564      -0.0681336    0.0349046   -0.0325291    -0.0644478    0.152835    -0.165685
  0.0248774    0.015471     0.0760156    0.00933088   0.224581    -0.000280722  -0.177778     -0.209617   -0.0910837  -0.0976274    0.0349464    0.0497927   -0.0869863  -0.126174     0.133669    -0.0559618   -0.174359     0.0854936  -0.0770713   -0.0375371     0.0776821   -0.0598984   -0.0838552     0.0759229   -0.189273    -0.00199848
  0.011098     0.116496     0.0453386   -0.21545     -0.0541363    0.0305614     0.191342      0.0344978   0.0785942  -0.108582    -0.0721187    0.283292    -0.0421281  -0.0566946   -0.0261501   -0.034611    -0.0948942   -0.128205   -0.116991    -0.0450833    -0.221097     0.0787929   -0.00434123   -0.0854777   -0.0308168   -0.149812
 -0.0816414   -0.0274581    0.100836     0.101977    -0.0675888   -0.155046      0.236889      0.100103    0.131518    0.0427492   -0.0196708    0.0440673    0.0368682  -0.0286343   -0.0829701   -0.0671218   -0.0283801   -0.158437   -0.081209     0.245581     -0.0498331   -0.0605244    0.0532641    -0.0140222    0.0873431    0.0242807
 -0.0843784    0.283298    -0.0660234    0.00485718   0.0529628    0.153897      0.0859374     0.0401377   0.0855296  -0.189881     0.115994     0.150486     0.124829   -0.0343912   -0.0594693    0.0589944    0.0234776    0.0893183  -0.0787526    0.0242471    -0.0182626   -0.00669883   0.0860824     0.136456    -0.0618813    0.0459742
 -0.0677114    0.00330046   0.00514328   0.0622385   -0.0590935    0.0384134     0.00271285    0.0940971  -0.0461765   0.105248    -0.109667    -0.0432312    0.05029    -0.149189     0.00329764  -0.056727     0.00703696   0.0649266   0.182921    -0.0332734    -0.080476    -0.0655037    0.214154     -0.0442349   -0.121918     0.020372
 -0.207008     0.106362    -0.0417707   -0.0294528   -0.0228828    0.125415     -0.180641     -0.0644607  -0.0263317   0.105573     0.0673436   -0.0144707    0.0462967   0.00780619   0.00105172  -0.0185069    0.00313492  -0.0219449  -0.0803667   -0.0746475     0.0597713    0.0491742   -0.0908464    -0.125219    -0.0636074   -0.00669857
  0.0606344    0.0579534    0.0333672    0.055837    -0.0113859    0.149353      0.0308988    -0.11282     0.0780277  -0.0529241   -0.0267721    0.0966525    0.0801982   0.0391969    0.00225121   0.0343569    0.0469129    0.100789   -0.0808086    0.0478561    -0.0933764   -0.0529979   -0.12497      -0.174122     0.0178146   -0.0614256
  0.141392    -0.120384     0.134366     0.0471095    0.0785201    0.0504946     0.0259763     0.0121786  -0.0441947  -0.124477     0.127195    -0.158661    -0.135586    0.0978344    0.118594     0.16379      0.0233156   -0.0538819  -0.0747086    0.168933     -0.1265       0.050647    -0.226493      0.170458     0.018354    -0.00575858
  0.0239934   -0.0906841   -0.11805      0.205459    -0.0365978   -0.14503      -0.00396274   -0.075816   -0.0130124  -0.0104283   -0.0234476    0.12117     -0.0079773  -0.0190636   -0.0516603    0.0127056   -0.0761709    0.0575377   0.0832648    0.115054     -0.200891    -0.0972228   -0.0364733    -0.0686568   -0.00834698  -0.0399844
 -0.115388     0.00622557   0.0131504    0.0101155    0.0163373    0.106347     -0.174562      0.138986    0.0518349  -0.108534     0.0734649   -0.188407     0.0291654   0.0438825    0.0791214    0.0780772   -0.0698642    0.151637    0.0543625    0.0451053     0.0812761   -0.0266028    0.0345629    -0.00349837  -0.0950252   -0.0817798
 -0.0146518    0.0534502   -0.152008     0.0448918   -0.0504366    0.0933226    -0.0113952     0.112716   -0.178332    0.0828416   -0.0481085   -0.203689     0.110998    0.193926    -0.152027     0.013655    -0.00506602  -0.0273246   0.128976    -0.170878      0.00752435   0.0235734    0.0359915     0.0525252   -0.12651     -0.0908685
  0.0548368   -0.0693693    0.0451615    0.0740898   -0.0601854   -0.0418474     0.181158     -0.228709    0.0444536  -0.00162537  -0.04651     -0.0130624   -0.0578013  -0.0602984    0.0223517   -0.0344809    0.157757    -0.083164   -0.144691    -0.0142435     0.0618429   -0.0310099    0.0337421     0.0227003    0.106969     0.200676
 -0.0366683   -0.124856    -0.056109     0.0121302   -0.180739    -0.122498     -0.00836169    0.176311   -0.184575    0.0619889    0.15212     -0.00073385  -0.0591892   0.161264     0.0369833    0.0694445    0.104379     0.0640359  -0.120389    -0.115194     -0.00291265   0.150944    -0.0317796    -0.0611878    0.136575    -0.0266025
 -0.0690479    0.161773     0.0461063    0.221546     0.0285172    0.0649931     0.0247885     0.0264874  -0.243044    0.0184284    0.230818     0.175049    -0.0430233  -0.0147093    0.06391     -0.158582     0.105833     0.0770848   0.0278813    0.148872      0.031079    -0.0686885    0.0555967    -0.182623    -0.127994    -0.167595
  0.102373    -0.057011     0.0353962   -0.02535     -0.160009     0.0104886    -0.0281656    -0.0304854   0.0801931   0.0684981   -0.00241088   0.147729     0.0480051   0.0727058    0.0328631    0.0279678   -0.0875661   -0.152986   -0.0316325    0.0315765    -0.139385    -0.213227    -0.000998805   0.0204603    0.0722214   -0.159534
 -0.139448    -0.16478     -0.103066     0.040092    -0.0505244    0.0675298     0.117122     -0.155129    0.193299   -0.0352183   -0.0474283    0.140668     0.107193   -0.0720012    0.0619567    0.0346969   -0.132065     0.148546   -0.0873819    0.00746633    0.0852351    0.0928852    0.0908832     0.174372     0.0785877   -0.0234602
 -0.162444    -0.00431853   0.0355482    0.00223938  -0.00290997  -0.197568     -0.000728879  -0.0406431  -0.050546    0.0903043    0.125478    -0.0232487   -0.0409104   0.228908    -0.036214    -0.0986408    0.00398577  -0.05569     0.098335     0.0240013    -0.123287     0.178314     0.10584      -0.0824276   -0.101668     0.202915
 -0.101943     0.0102931    0.103824    -0.0581609   -0.178321     0.179001      0.048632     -0.135681   -0.10221    -2.6362e-5    0.0212647   -0.129958     0.0200774  -0.00616886   0.0175059   -0.00508041  -0.0400179    0.0193705  -0.0539528   -0.0687288    -0.209482     0.114862    -0.0219421     0.154514    -0.146449    -0.00832023
 -0.048437    -0.0088222   -0.0705682    0.177298     0.0774287    0.0587462    -0.187743     -0.0825605  -0.129571    0.0895317    0.159919     0.00666071  -0.0665199  -0.10841      0.0441984    0.0746804   -0.0842576    0.165643   -0.0582832    0.0391081     0.0238573   -0.0630771   -0.0372857    -0.202357     0.112266    -0.0889701
  0.10885      0.114829     0.0630858    0.03144     -0.0240639    0.216251      0.148966     -0.0989264   0.017991    0.0568117    0.0142711   -0.0974282   -0.0253393  -0.0546789    0.0446501   -0.0165588   -0.0155066   -0.0306293   0.099333    -0.0741031    -0.00363259   0.0367737    0.00727416   -0.180836    -0.00029845  -0.138967
 -0.0207766    0.194467    -0.0618499   -0.0329097    0.0761348   -0.0623764     0.168667     -0.136309    0.0348861   0.050586     0.0189762    0.0100497    0.0975183   0.0753338   -0.0220655   -0.146587    -0.0541721    0.0845243   0.0575277   -0.000849112  -0.113525    -0.0369812   -0.261109     -0.115756    -0.0460994    0.111768
  0.0676879    0.0635633    0.0230104    0.0454387    0.152342     0.071251     -0.0806808     0.153104   -0.0947971   0.134649    -0.0224203    0.0065142   -0.180982   -0.0456806   -0.0959458   -0.0114828    0.0735349   -0.122325   -0.0338388    0.0877395     0.224006    -0.192212    -0.161134     -0.26213      0.0389951    0.299545
 -0.174141     0.0386933   -0.0377548    0.0896646    0.00308194  -0.244006      0.0798537    -0.0565534  -0.100512   -0.0647297    0.089408     0.0147761   -0.150598   -0.00718893  -0.022175     0.0442762   -0.10952      0.0570055   0.0417971   -0.168704     -0.108041     0.0800463   -0.215669     -0.0887818   -0.0109284    0.0626231
 -0.0225228   -0.133595     0.190479    -0.197392    -0.199627    -0.0675592    -0.0395347    -0.0489678  -0.0240148   0.0338209   -0.144032     0.0749363   -0.137918    0.036629     0.0200301   -0.277609     0.0576784   -0.0158483  -0.143896    -0.0401116    -0.129128     0.126044     0.0898405    -0.019704    -0.213505     0.137503
 -0.157065     0.0998308   -0.130318    -0.138879     0.00412806   0.0562208     0.14715       0.0553928   0.172839    0.00923259  -0.0552599   -0.108864     0.185028   -0.045082    -0.025443    -0.13919     -0.018897    -0.0149334   0.0512557   -0.0933817    -0.078445     0.0473344   -0.0372097    -0.00992399   0.0447455    0.153074kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4132668852070616
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413324
[ Info: iteration 2, average log likelihood -1.413276
[ Info: iteration 3, average log likelihood -1.412999
[ Info: iteration 4, average log likelihood -1.409200
[ Info: iteration 5, average log likelihood -1.394765
[ Info: iteration 6, average log likelihood -1.383596
[ Info: iteration 7, average log likelihood -1.380206
[ Info: iteration 8, average log likelihood -1.378407
[ Info: iteration 9, average log likelihood -1.377479
[ Info: iteration 10, average log likelihood -1.376979
[ Info: iteration 11, average log likelihood -1.376647
[ Info: iteration 12, average log likelihood -1.376411
[ Info: iteration 13, average log likelihood -1.376238
[ Info: iteration 14, average log likelihood -1.376104
[ Info: iteration 15, average log likelihood -1.375995
[ Info: iteration 16, average log likelihood -1.375899
[ Info: iteration 17, average log likelihood -1.375811
[ Info: iteration 18, average log likelihood -1.375732
[ Info: iteration 19, average log likelihood -1.375671
[ Info: iteration 20, average log likelihood -1.375628
[ Info: iteration 21, average log likelihood -1.375599
[ Info: iteration 22, average log likelihood -1.375581
[ Info: iteration 23, average log likelihood -1.375569
[ Info: iteration 24, average log likelihood -1.375561
[ Info: iteration 25, average log likelihood -1.375556
[ Info: iteration 26, average log likelihood -1.375553
[ Info: iteration 27, average log likelihood -1.375551
[ Info: iteration 28, average log likelihood -1.375550
[ Info: iteration 29, average log likelihood -1.375549
[ Info: iteration 30, average log likelihood -1.375548
[ Info: iteration 31, average log likelihood -1.375548
[ Info: iteration 32, average log likelihood -1.375548
[ Info: iteration 33, average log likelihood -1.375547
[ Info: iteration 34, average log likelihood -1.375547
[ Info: iteration 35, average log likelihood -1.375547
[ Info: iteration 36, average log likelihood -1.375547
[ Info: iteration 37, average log likelihood -1.375547
[ Info: iteration 38, average log likelihood -1.375547
[ Info: iteration 39, average log likelihood -1.375547
[ Info: iteration 40, average log likelihood -1.375547
[ Info: iteration 41, average log likelihood -1.375547
[ Info: iteration 42, average log likelihood -1.375547
[ Info: iteration 43, average log likelihood -1.375547
[ Info: iteration 44, average log likelihood -1.375547
[ Info: iteration 45, average log likelihood -1.375547
[ Info: iteration 46, average log likelihood -1.375547
[ Info: iteration 47, average log likelihood -1.375547
[ Info: iteration 48, average log likelihood -1.375547
[ Info: iteration 49, average log likelihood -1.375547
[ Info: iteration 50, average log likelihood -1.375547
┌ Info: EM with 100000 data points 50 iterations avll -1.375547
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4133242454358435
│     -1.41327583161307
│      ⋮
└     -1.3755470880002163
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.375667
[ Info: iteration 2, average log likelihood -1.375532
[ Info: iteration 3, average log likelihood -1.374694
[ Info: iteration 4, average log likelihood -1.367884
[ Info: iteration 5, average log likelihood -1.351304
[ Info: iteration 6, average log likelihood -1.340446
[ Info: iteration 7, average log likelihood -1.337208
[ Info: iteration 8, average log likelihood -1.335854
[ Info: iteration 9, average log likelihood -1.334968
[ Info: iteration 10, average log likelihood -1.334312
[ Info: iteration 11, average log likelihood -1.333783
[ Info: iteration 12, average log likelihood -1.333300
[ Info: iteration 13, average log likelihood -1.332849
[ Info: iteration 14, average log likelihood -1.332414
[ Info: iteration 15, average log likelihood -1.331997
[ Info: iteration 16, average log likelihood -1.331606
[ Info: iteration 17, average log likelihood -1.331223
[ Info: iteration 18, average log likelihood -1.330853
[ Info: iteration 19, average log likelihood -1.330510
[ Info: iteration 20, average log likelihood -1.330210
[ Info: iteration 21, average log likelihood -1.329963
[ Info: iteration 22, average log likelihood -1.329776
[ Info: iteration 23, average log likelihood -1.329645
[ Info: iteration 24, average log likelihood -1.329559
[ Info: iteration 25, average log likelihood -1.329503
[ Info: iteration 26, average log likelihood -1.329466
[ Info: iteration 27, average log likelihood -1.329441
[ Info: iteration 28, average log likelihood -1.329424
[ Info: iteration 29, average log likelihood -1.329413
[ Info: iteration 30, average log likelihood -1.329404
[ Info: iteration 31, average log likelihood -1.329398
[ Info: iteration 32, average log likelihood -1.329393
[ Info: iteration 33, average log likelihood -1.329390
[ Info: iteration 34, average log likelihood -1.329387
[ Info: iteration 35, average log likelihood -1.329384
[ Info: iteration 36, average log likelihood -1.329382
[ Info: iteration 37, average log likelihood -1.329381
[ Info: iteration 38, average log likelihood -1.329379
[ Info: iteration 39, average log likelihood -1.329378
[ Info: iteration 40, average log likelihood -1.329377
[ Info: iteration 41, average log likelihood -1.329375
[ Info: iteration 42, average log likelihood -1.329374
[ Info: iteration 43, average log likelihood -1.329373
[ Info: iteration 44, average log likelihood -1.329371
[ Info: iteration 45, average log likelihood -1.329369
[ Info: iteration 46, average log likelihood -1.329367
[ Info: iteration 47, average log likelihood -1.329364
[ Info: iteration 48, average log likelihood -1.329361
[ Info: iteration 49, average log likelihood -1.329356
[ Info: iteration 50, average log likelihood -1.329351
┌ Info: EM with 100000 data points 50 iterations avll -1.329351
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3756671725415408
│     -1.3755320424676203
│      ⋮
└     -1.3293506061443583
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.329509
[ Info: iteration 2, average log likelihood -1.329332
[ Info: iteration 3, average log likelihood -1.328716
[ Info: iteration 4, average log likelihood -1.323681
[ Info: iteration 5, average log likelihood -1.307747
[ Info: iteration 6, average log likelihood -1.291315
[ Info: iteration 7, average log likelihood -1.282650
[ Info: iteration 8, average log likelihood -1.278539
[ Info: iteration 9, average log likelihood -1.276460
[ Info: iteration 10, average log likelihood -1.275086
[ Info: iteration 11, average log likelihood -1.273949
[ Info: iteration 12, average log likelihood -1.273117
[ Info: iteration 13, average log likelihood -1.272689
[ Info: iteration 14, average log likelihood -1.272467
[ Info: iteration 15, average log likelihood -1.272313
[ Info: iteration 16, average log likelihood -1.272177
[ Info: iteration 17, average log likelihood -1.272038
[ Info: iteration 18, average log likelihood -1.271889
[ Info: iteration 19, average log likelihood -1.271735
[ Info: iteration 20, average log likelihood -1.271583
[ Info: iteration 21, average log likelihood -1.271438
[ Info: iteration 22, average log likelihood -1.271305
[ Info: iteration 23, average log likelihood -1.271185
[ Info: iteration 24, average log likelihood -1.271076
[ Info: iteration 25, average log likelihood -1.270975
[ Info: iteration 26, average log likelihood -1.270878
[ Info: iteration 27, average log likelihood -1.270780
[ Info: iteration 28, average log likelihood -1.270676
[ Info: iteration 29, average log likelihood -1.270555
[ Info: iteration 30, average log likelihood -1.270411
[ Info: iteration 31, average log likelihood -1.270243
[ Info: iteration 32, average log likelihood -1.270058
[ Info: iteration 33, average log likelihood -1.269866
[ Info: iteration 34, average log likelihood -1.269691
[ Info: iteration 35, average log likelihood -1.269558
[ Info: iteration 36, average log likelihood -1.269467
[ Info: iteration 37, average log likelihood -1.269409
[ Info: iteration 38, average log likelihood -1.269379
[ Info: iteration 39, average log likelihood -1.269365
[ Info: iteration 40, average log likelihood -1.269359
[ Info: iteration 41, average log likelihood -1.269356
[ Info: iteration 42, average log likelihood -1.269355
[ Info: iteration 43, average log likelihood -1.269354
[ Info: iteration 44, average log likelihood -1.269353
[ Info: iteration 45, average log likelihood -1.269353
[ Info: iteration 46, average log likelihood -1.269353
[ Info: iteration 47, average log likelihood -1.269353
[ Info: iteration 48, average log likelihood -1.269352
[ Info: iteration 49, average log likelihood -1.269352
[ Info: iteration 50, average log likelihood -1.269352
┌ Info: EM with 100000 data points 50 iterations avll -1.269352
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3295093782558633
│     -1.3293319207271923
│      ⋮
└     -1.2693521868059652
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.269574
[ Info: iteration 2, average log likelihood -1.269318
[ Info: iteration 3, average log likelihood -1.268003
[ Info: iteration 4, average log likelihood -1.258042
[ Info: iteration 5, average log likelihood -1.236617
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.211164
[ Info: iteration 7, average log likelihood -1.207724
[ Info: iteration 8, average log likelihood -1.194234
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.185443
[ Info: iteration 10, average log likelihood -1.200794
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.185324
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.191001
[ Info: iteration 13, average log likelihood -1.194559
[ Info: iteration 14, average log likelihood -1.184700
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.176315
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.191368
[ Info: iteration 17, average log likelihood -1.192908
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.182724
[ Info: iteration 19, average log likelihood -1.187931
[ Info: iteration 20, average log likelihood -1.178410
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.171155
[ Info: iteration 22, average log likelihood -1.194842
[ Info: iteration 23, average log likelihood -1.183440
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.177040
[ Info: iteration 25, average log likelihood -1.183404
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.173795
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.185177
[ Info: iteration 28, average log likelihood -1.189474
[ Info: iteration 29, average log likelihood -1.180435
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.173989
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.179991
[ Info: iteration 32, average log likelihood -1.188364
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.179970
[ Info: iteration 34, average log likelihood -1.186513
[ Info: iteration 35, average log likelihood -1.177451
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.170551
[ Info: iteration 37, average log likelihood -1.194327
[ Info: iteration 38, average log likelihood -1.182861
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.176493
[ Info: iteration 40, average log likelihood -1.182871
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.173017
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.184014
[ Info: iteration 43, average log likelihood -1.188118
[ Info: iteration 44, average log likelihood -1.178887
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.172447
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.178362
[ Info: iteration 47, average log likelihood -1.186561
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.177899
[ Info: iteration 49, average log likelihood -1.184071
[ Info: iteration 50, average log likelihood -1.174428
┌ Info: EM with 100000 data points 50 iterations avll -1.174428
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2695738104969303
│     -1.2693180410686578
│      ⋮
└     -1.1744280376784153
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.167412
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.166718
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.164978
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.148407
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.106832
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.091929
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     13
│     15
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.065690
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.094102
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.073888
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.074883
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     13
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.078662
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.087270
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     15
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.059793
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      9
│     10
│     12
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.077811
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.086284
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     13
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.070675
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.086941
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.082676
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│     15
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.058120
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     13
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.089439
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.083127
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.069882
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.077103
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.077617
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│     15
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.064490
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.092018
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.074247
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     13
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.064493
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.083693
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.079019
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     10
│     15
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.064110
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     13
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.087571
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.076201
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      9
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.064380
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.082745
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│      9
│     13
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.068228
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     15
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.086456
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.083771
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.063493
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     13
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.075894
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.080366
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│      9
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.065514
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     15
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.078604
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     13
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.079252
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.070543
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.079152
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.072559
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      9
│     13
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.078215
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     15
│     19
│     20
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.076602
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.076662
┌ Info: EM with 100000 data points 50 iterations avll -1.076662
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.167411567653942
│     -1.1667177482571705
│      ⋮
└     -1.076662163967277
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4132668852070616
│     -1.4133242454358435
│     -1.41327583161307
│     -1.4129990839183209
│      ⋮
│     -1.0782147769448762
│     -1.076602368362307
└     -1.076662163967277
32×26 Array{Float64,2}:
 -0.0181313   -0.0441569    -0.0521399    0.0435916   -0.0217789    0.0470696    0.0662988  -0.0509061   -0.0305587    0.090547     0.0533839   -0.0742376    0.0178778   -0.0350895    0.0190926    0.0672981   -0.00673171   0.108118     -0.0590233  -0.108773     -0.00173024   0.0588531   -0.0357436   -0.0386663    0.0830751    -0.0475132
 -0.0986286    0.100087     -0.0827752   -0.103052     0.00019043   0.121531     0.139004    0.00652551   0.118017    -0.00649289  -0.0523733   -0.0820011    0.107594    -0.0554       0.00337602  -0.0892277   -0.0181694   -0.0167465     0.0783518  -0.0692741    -0.0594836    0.0388901   -0.0233348   -0.126772     0.0258924     0.0450591
 -0.232953     0.118798     -0.0442555   -0.0337447   -0.0205757    0.174385    -0.17992    -0.0641943    0.00886428   0.0842833    0.0621823   -0.128253     0.0327561    0.00854535   0.014542    -0.0345959    0.00235005  -0.0229383    -0.0706238  -0.102158      0.0543504    0.0434755   -0.0985902   -0.146181    -0.0766023    -0.0077823
 -0.0705289    0.277677     -0.0666651    0.00793323   0.0779325    0.149286     0.0781497   0.0314906    0.0876477   -0.234519     0.12504      0.207047     0.118711    -0.0349394   -0.0589494   -0.00475014  -0.00193894   0.0787051    -0.0842842   0.0145029    -0.0165933   -0.0208313    0.099073     0.0902389   -0.0370459     0.045408
  0.0329782    0.0155221     0.0379528    0.0433749    0.212171     0.00839727  -0.149361   -0.21026     -0.091729    -0.0910343    0.03524      0.102733    -0.0852018   -0.0923388    0.0387416   -0.0500812   -0.170926     0.0562896    -0.0773041  -0.0379808     0.0761008   -0.0850179   -0.080442     0.0448234   -0.194893     -0.0020723
  0.0560666   -0.0708975     0.0418651    0.0818673   -0.056452    -0.0355123    0.178718   -0.22004      0.0499074    0.0005916   -0.0577554   -0.0151735   -0.102002    -0.022656     0.0173119   -0.0352023    0.159349    -0.0842358    -0.142549   -0.0435948     0.0471994   -0.0114129    0.0327766    0.0293589    0.105951      0.20143
  0.135372    -0.114593      0.0328516    0.0200592    0.076897     0.0942921   -0.0658633   0.0308956   -0.0110771   -0.0883631    0.133051    -0.154018    -0.347254     0.0353862    0.114487     0.0702907    0.0498342   -0.0750411    -0.0627359   0.104199     -0.0886575    0.0277117   -0.227349     0.168067    -0.0617419     0.0439278
  0.150991    -0.106199      0.224939     0.100463     0.0862306   -0.0297357    0.0701351  -0.0155945   -0.108714    -0.115289     0.132885    -0.171545     0.0862209    0.188079     0.121428     0.167401     0.0190799   -0.0497372    -0.0830774   0.213584     -0.157907     0.0809291   -0.222916     0.153656     0.0317164    -0.0743921
  0.106496    -0.0204968     0.0353413   -0.0308933   -0.212174     0.0116004   -0.0346436  -0.02105      0.0955098    0.0630816   -0.00269182   0.154698     0.0452587    0.0690646    0.0329137    0.0286083   -0.126189    -0.174419     -0.0308775   0.0229578    -0.14227     -0.241431     0.00977183   0.0212141    0.0430616    -0.172352
 -0.0301299    0.198174     -0.0637599    0.0294116    0.0716583   -0.0622056    0.162085   -0.143828     0.0284508    0.0526349    0.0204892   -0.00604347   0.102414     0.0674735   -0.0208437   -0.129799    -0.0765338    0.0891878     0.0347931  -0.000131714  -0.129801    -0.0566914   -0.274912    -0.127542     0.000285229   0.136204
 -0.0203435   -0.00606645   -0.0691098    0.125244     0.0139004   -0.0406626   -0.0071043   0.053818     0.00497749   0.167757    -0.160484    -0.124206    -0.0210082   -0.128315    -0.0594822   -0.0476936    0.0467452   -0.0226695     0.0612906  -0.0280325    -0.0985851   -0.0559538    0.0467073   -0.0301518   -0.064304     -0.0307873
 -0.112681     0.0792536     0.0694388    0.0700565   -0.068634     0.127109     0.0471684  -0.0519128   -0.137117     0.00936463   0.109653     0.0596417   -0.00318872  -0.0272374    0.033996    -0.0858891    0.010801     0.0502056    -0.023336    0.033345     -0.0358388    0.027293     0.0057229   -0.00427929  -0.111207     -0.0732207
 -0.0195745   -0.121361      0.184769    -0.177927    -0.245532    -0.0646687   -0.0300884  -0.0397913   -0.0120969    0.0136754   -0.138673     0.126542    -0.11336      0.0366949    0.0280665   -0.260196     0.0678114    0.000542603  -0.139162   -0.0340417    -0.162879     0.136084     0.0883887   -0.0226329   -0.218055      0.118921
 -0.0101602    0.0518414    -0.0359281   -0.07034     -0.0490212    0.0603926    0.0793713   0.0816132   -0.066171     0.00124426  -0.0488966    0.0125798    0.0379201    0.0811608   -0.0823263    0.00307015  -0.0556686   -0.101205      0.013205   -0.121074     -0.0885458    0.0401763    0.0217341   -0.0161891   -0.0800263    -0.122719
  0.00477854  -0.0383056     0.0910784   -0.165039    -0.115897    -0.0419478    0.0370221  -0.116984    -0.17282      0.185242     0.00609908  -0.0252913    0.0171929    0.0096409    0.100678    -0.169016     0.230601    -0.114354     -0.239691   -0.175392      0.00775047   0.0141021   -0.0138282    0.00550646   0.160718      0.0566441
 -0.198391     0.0395223    -0.0388698    0.0903914    3.12094e-5  -0.260481     0.0882597  -0.0619406   -0.0926358   -0.0653677    0.0995211    0.0149084   -0.156192     0.0290694   -0.0303934    0.0517152   -0.1022       0.0854087     0.0417353  -0.171708     -0.106572     0.10691     -0.194286    -0.104975    -0.0150766     0.0339629
  0.0570456    0.0578251     0.0642868    0.0253003    0.00526878   0.17249      0.0455321  -0.0588818    0.103918    -0.0436411   -0.0251366    0.0933502    0.0804243    0.0391555    0.00781072   0.0373377    0.0469694    0.116249     -0.104312    0.0543037    -0.0958907   -0.042903    -0.132875    -0.173902     0.00986685   -0.0694426
  0.0105368   -0.117257      0.0995219    0.105142     0.233115    -0.011514     0.0332974   0.190154     0.199991    -0.0191807   -0.0659924   -0.148047     0.0485651    0.0152461    0.00788217   0.00591078   0.144407     0.026579      0.149524    0.0299812    -0.0828932   -0.147603    -0.0387303   -0.0103224   -0.134127     -0.125559
 -0.117194    -0.0629231    -0.0163449   -0.221143     0.0309444    0.0979113   -0.177058    0.121099    -0.208228    -0.126746     0.0280367   -0.185245     0.0821682    0.0494615    0.0787503    0.106814    -0.0641567    0.247082      0.145755    0.0425714     0.078761    -0.0268089    0.0340574   -0.00131299  -0.0984337     0.00177739
 -0.117157     0.06451       0.0527781    0.328644     0.0464874    0.11017     -0.177662    0.147193     0.29803     -0.0479762    0.116051    -0.17437     -0.00836743   0.0490507    0.0782989    0.0374568   -0.111876     0.036436     -0.0380397   0.0459909     0.085514    -0.0268791    0.0344811   -0.0141516   -0.0860177    -0.131238
 -0.0854085    0.0149688    -0.370552     0.039435    -0.112078    -0.223334    -0.0752291   0.077885    -0.0487438    0.0911613    0.0765426   -0.0486183   -0.178598     0.211617     0.0355462   -0.184743     0.0269424   -0.0687593     0.0920135   0.000484357  -0.131103     0.172753     0.0976906   -0.0631813   -0.0998861     0.216269
 -0.205902    -0.0923022     0.469942    -0.0553036    0.0797832   -0.123963     0.0739034  -0.182567    -0.0443454    0.074913     0.222583    -0.00637368   0.101415     0.172712    -0.050876     0.0241002   -0.0297781   -0.0428851     0.0983152   0.0451091    -0.107174     0.228062     0.123266    -0.0884859   -0.0886156     0.189651
 -0.0475931   -0.000405306   0.100498     0.122745    -0.221299    -0.1634      -0.20181    -0.12366      0.0764786    0.137364     0.0836292   -0.0288267   -0.0317881    0.138293    -0.102097    -0.0644716   -0.00208474  -0.158068     -0.0813607   0.245727     -0.0494434   -0.0618814   -0.0105273    0.0127107    0.0833493     0.115279
 -0.0983402   -0.0391158     0.100956     0.0791456    0.0372825   -0.150073     0.855855    0.309476     0.140724     0.0108475   -0.10711      0.110737     0.0800386   -0.1273      -0.0716216   -0.0700038   -0.0285027   -0.160744     -0.080449    0.24568      -0.0485735   -0.0203538    0.0769479   -0.0388527    0.103983     -0.0883654
  0.0661449    0.0636609    -0.00887806  -0.0102469    0.0852814    0.0163446   -0.377533    0.157125    -0.0380465    0.0995177    0.0653489    0.00159868  -0.238953    -0.0148372   -0.122269     0.0320392    0.156924    -0.11757      -0.0717956   0.100725      0.19405     -0.185314     0.0513369   -0.296323     0.0255461     0.23229
  0.0665004    0.0588        0.0478788    0.0666152    0.20966      0.132137     0.301473    0.149863    -0.152195     0.214601    -0.0930523    0.00989427  -0.16736     -0.0673815   -0.110599    -0.0601934    0.0498886   -0.182162      0.0285714   0.0704341     0.273092    -0.20595     -0.307175    -0.230189     0.0488372     0.372391
  0.0128208   -0.115653     -0.100013     0.177953     0.017146    -0.155179    -0.0406722  -0.0843044   -0.383803    -0.0129093   -0.0767752    0.128104    -0.0243742   -0.0662261   -0.0889849    0.0116157   -0.0765301    0.0757478     0.0942802   0.0978715    -0.210057    -0.0435132    0.0190282    0.00549561  -0.167255     -0.0419569
  0.0297913   -0.0694004    -0.135144     0.238628    -0.0591017   -0.166471     0.123407   -0.0721021    0.325107     0.0618554    0.0115672    0.106924     0.00537949   0.0647372    0.0489609    0.0178833   -0.070896     0.0441532     0.091665    0.135946     -0.190513    -0.0786338   -0.088622    -0.143529     0.0970493    -0.0407401
  0.085697    -0.00783068   -0.106701     0.0303306    0.00304234  -0.0019576   -0.0290641   0.173083    -0.0629102   -0.101791     0.162734     0.0588567    0.036197     0.0318697    0.259512    -0.0590693   -0.0791537   -0.0857361    -0.0075351  -0.11045      -0.0778046    0.055581     0.113242     0.0563683    0.0419407     0.187287
  0.0449792    0.0638796    -0.0551441    0.00138999   0.10159      0.0728398   -0.181823    0.175006     0.0536487    0.071224    -0.237418     0.145213     0.0473194    0.0522003    0.236372    -0.0169201    0.177456     0.00965423   -0.0519316  -0.0213191    -0.0817649    0.0348824   -0.0761628   -0.066837     0.144971     -0.203199
 -0.139603    -0.0260247    -0.137049     0.211287     0.0854922    0.0566089   -0.209736   -0.0789507   -0.144246     0.143613     0.102544    -0.0109792   -0.0401061   -0.176111     0.0401054    0.0760267   -0.102037    -0.524067     -0.0740598  -0.0188973     0.010723    -0.00642736   0.0652836   -0.370813     0.162773     -0.0900045
  0.0398387    0.00892187   -0.0578158    0.132461     0.0409003    0.0573912   -0.0917495  -0.101956    -0.128578    -0.0136808    0.234216     0.0531969   -0.110622    -0.0905137    0.0510911    0.0732683   -0.0297492    0.781746     -0.0345294   0.070844      0.0647849   -0.115649    -0.0872914   -0.132273     0.0932849    -0.0859067[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.077683
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      9
│     10
│     13
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.054822
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.077203
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      9
│     10
│     13
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.053912
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.075873
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      9
│     10
│     13
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.051983
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.074839
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      9
│     10
│     13
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.051644
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.074772
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      9
│     10
│     13
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.051673
┌ Info: EM with 100000 data points 10 iterations avll -1.051673
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.085883e+05
      1       6.811715e+05      -2.274169e+05 |       32
      2       6.518994e+05      -2.927201e+04 |       32
      3       6.398976e+05      -1.200187e+04 |       32
      4       6.323275e+05      -7.570099e+03 |       32
      5       6.253462e+05      -6.981275e+03 |       32
      6       6.200282e+05      -5.318011e+03 |       32
      7       6.174245e+05      -2.603730e+03 |       32
      8       6.164162e+05      -1.008276e+03 |       32
      9       6.158182e+05      -5.979509e+02 |       32
     10       6.154000e+05      -4.181838e+02 |       32
     11       6.151240e+05      -2.760018e+02 |       32
     12       6.148939e+05      -2.301599e+02 |       32
     13       6.146923e+05      -2.016325e+02 |       32
     14       6.144796e+05      -2.126287e+02 |       32
     15       6.142594e+05      -2.201964e+02 |       32
     16       6.139726e+05      -2.868311e+02 |       32
     17       6.136013e+05      -3.712750e+02 |       32
     18       6.130458e+05      -5.555403e+02 |       32
     19       6.123744e+05      -6.714028e+02 |       32
     20       6.119948e+05      -3.795479e+02 |       32
     21       6.118169e+05      -1.779594e+02 |       32
     22       6.116929e+05      -1.239798e+02 |       32
     23       6.115754e+05      -1.174688e+02 |       32
     24       6.114572e+05      -1.182657e+02 |       32
     25       6.113555e+05      -1.016997e+02 |       31
     26       6.112703e+05      -8.519390e+01 |       31
     27       6.112239e+05      -4.639757e+01 |       31
     28       6.112013e+05      -2.253150e+01 |       31
     29       6.111888e+05      -1.257230e+01 |       27
     30       6.111794e+05      -9.331302e+00 |       23
     31       6.111683e+05      -1.114171e+01 |       28
     32       6.111550e+05      -1.328492e+01 |       31
     33       6.111410e+05      -1.396995e+01 |       28
     34       6.111256e+05      -1.544585e+01 |       28
     35       6.111071e+05      -1.848064e+01 |       28
     36       6.110843e+05      -2.279809e+01 |       31
     37       6.110558e+05      -2.854575e+01 |       30
     38       6.110155e+05      -4.026731e+01 |       31
     39       6.109640e+05      -5.152722e+01 |       30
     40       6.109122e+05      -5.175479e+01 |       32
     41       6.108646e+05      -4.761256e+01 |       29
     42       6.108171e+05      -4.745899e+01 |       32
     43       6.107701e+05      -4.701639e+01 |       32
     44       6.107362e+05      -3.396656e+01 |       30
     45       6.107122e+05      -2.399157e+01 |       30
     46       6.106877e+05      -2.443341e+01 |       29
     47       6.106596e+05      -2.814264e+01 |       31
     48       6.106258e+05      -3.375524e+01 |       26
     49       6.105928e+05      -3.305381e+01 |       31
     50       6.105554e+05      -3.742085e+01 |       30
K-means terminated without convergence after 50 iterations (objv = 610555.3607485527)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.323683
[ Info: iteration 2, average log likelihood -1.288480
[ Info: iteration 3, average log likelihood -1.250761
[ Info: iteration 4, average log likelihood -1.211043
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.160742
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      7
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.115687
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.082926
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.067685
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     12
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.033450
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│      7
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.029097
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.062221
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.039849
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│     12
│     13
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -0.992407
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     21
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.040997
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.063356
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.023793
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     12
│     13
│     16
│     21
│     23
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -0.982247
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.084673
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.047264
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.016569
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      6
│     12
│     13
│     16
│     21
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -0.982951
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.079910
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.055585
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.012835
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│     12
│     13
│     16
│     21
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -0.977130
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.087909
[ Info: iteration 27, average log likelihood -1.055184
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      7
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -0.993030
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     12
│     13
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.023992
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.077637
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.039259
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│      7
│     12
│     16
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -0.994260
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.060927
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.047591
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.030767
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      7
│     12
│     13
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -0.992112
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.052686
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.050487
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.019317
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│     12
│     13
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -0.994005
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.054402
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.046439
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.034552
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      7
│     12
│     13
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -0.988615
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.043716
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.055116
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.029558
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      6
│      7
│     12
│      ⋮
│     21
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -0.973663
[ Info: iteration 49, average log likelihood -1.094865
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.048502
┌ Info: EM with 100000 data points 50 iterations avll -1.048502
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0648453    0.0616578    0.0199836    0.0230892     0.150063      0.0759612   -0.0388639     0.15343      -0.0937926    0.153671    -0.0138912    0.0051889   -0.202606    -0.0401951   -0.115169    -0.0146195    0.102563    -0.146389    -0.0218441    0.085616    0.234021    -0.194872   -0.127204    -0.258145     0.0355702    0.299335
  0.0522079   -0.0714148    0.044254     0.103626     -0.0538145    -0.0301183    0.167837     -0.233685      0.0559565   -0.00204468  -0.0419498   -0.019105    -0.0955346   -0.0196159    0.0174342    0.0239613    0.159353    -0.075574    -0.144152    -0.0476112   0.0865145   -0.0200567   0.0346876    0.0328402    0.101585     0.201435
 -0.144995    -0.0361115    0.0363106   -0.00464561   -0.0237012    -0.183776    -0.00954809   -0.0505226    -0.0476906    0.0873568    0.149925    -0.0298632   -0.0433663    0.208455    -0.0095033   -0.0884248    0.00567471  -0.0569242    0.0958816    0.0251415  -0.118358     0.194804    0.112167    -0.0773662   -0.0959397    0.206211
 -0.0680902   -0.0311601   -0.0705511    0.234061      0.051795     -0.0649063   -0.0201714     0.108436      0.0165257    0.288579    -0.104747    -0.212652    -0.0413282   -0.0502917   -0.108926    -0.100809     0.033404     0.0593533   -0.124078     0.100717   -0.106926    -0.0908942  -0.0485322   -0.00641401   0.0706484   -0.0781459
  0.0120184    0.110704     0.069009    -0.216082     -0.0552507     0.0303246    0.199793      0.0271184     0.0749438   -0.111659    -0.0473171    0.300145    -0.0451451   -0.0574505   -0.0344811   -0.0393368   -0.11037     -0.132258    -0.11733     -0.0281814  -0.222156     0.0751073  -0.0170919   -0.0863273   -0.0272471   -0.132435
 -0.0778041   -0.015781     0.0953486    0.131566     -0.066994     -0.0922287    0.225833      0.107758      0.0932138    0.045088     0.00901833  -0.00430514   0.0362454    0.0068168   -0.0379655   -0.0523603   -0.0221197   -0.0993608   -0.0744214    0.180507   -0.017039    -0.0412792   0.0319247   -0.00864051   0.0501617   -0.00858497
 -0.0136605   -0.120665     0.193507    -0.175919     -0.251166     -0.0623239   -0.0386153    -0.0627578    -0.0210318    0.0283154   -0.1478       0.0952017   -0.117656     0.0316819    0.0225381   -0.296039     0.101275     0.00360627  -0.135632    -0.0430719  -0.194527     0.135846    0.104942    -0.0148187   -0.245795     0.136983
  0.0899864    0.106623     0.0655878   -0.000911864  -0.0195901     0.175054     0.14654      -0.0985399    -0.00218524   0.044487    -0.0133147   -0.0995653    0.00734415  -0.0526668    0.0531875   -0.00874438  -0.0251819   -0.031051     0.0994849   -0.0553658  -0.00331252   0.0612003   0.00696816  -0.256381     0.0110645   -0.135968
 -0.0698959    0.273221    -0.0665043    0.00522491    0.0744279     0.147939     0.0762629     0.0354517     0.0912033   -0.233197     0.127921     0.20146      0.118888    -0.0345757   -0.0579095   -0.008776    -0.00231418   0.0820726   -0.0834543    0.0137988  -0.0164118   -0.0226639   0.099979     0.0918104   -0.0421391    0.0445372
 -0.0352197    0.184978    -0.011782     0.0907121     0.0475846    -0.0162727    0.0982225    -0.07108      -0.0790253    0.0479368    0.0934002    0.106865     0.0412128    0.0302162    0.0262743   -0.133751     0.00536428   0.0820847    0.0261116    0.0636075  -0.0256709   -0.0686447  -0.127838    -0.163325    -0.0581873   -0.0146155
 -0.191352     0.0375211   -0.0374333    0.0917508    -0.000126427  -0.251286     0.0846459    -0.0600925    -0.0949455   -0.0662694    0.102808     0.0152796   -0.155077     0.0315331   -0.0242373    0.0483888   -0.0938595    0.0775447    0.0360876   -0.171898   -0.103204     0.0980538  -0.186707    -0.101482    -0.0210551    0.0421003
 -0.124616     0.00401008   0.00355038   0.175341      0.0394494     0.110941    -0.141125      0.206382     -0.0211049   -0.217274     0.0853294   -0.207603     0.0333287    0.0514153    0.0744707    0.115475    -0.100447     0.244263     0.105438     0.0247785   0.0616025   -0.0132213   0.0315599   -0.0123059   -0.0783125   -0.105855
 -0.140334     0.00759334   0.123602    -0.0565789    -0.184393      0.188467     0.0520477    -0.112694     -0.103182     0.0184401    0.0461809   -0.117292     0.00742684  -0.00593464  -0.0389937   -0.0492194   -0.0175281    0.0328112   -0.0599028   -0.0658072  -0.18845      0.176571   -0.0323587    0.154428    -0.178842    -0.0105762
  0.141921    -0.11222      0.128915     0.0614657     0.0853201     0.031764     0.000637705   0.00759475   -0.0550943   -0.102479     0.132731    -0.162591    -0.135809     0.114054     0.118325     0.116874     0.034198    -0.064149    -0.0727124    0.158468   -0.121713     0.0541064  -0.223714     0.163923    -0.0199281   -0.0123468
 -0.0300131   -0.00562551   0.0155721    0.0751552    -0.064534      0.0197655    0.00172288    0.0963108    -0.0524245    0.0979855   -0.103601    -0.0995697    0.0505354   -0.138691    -0.00195441  -0.0455289   -0.00221162   0.0638163    0.191273    -0.0276429  -0.0810717   -0.0673387   0.206567    -0.0481236   -0.143853     0.0230811
  0.0609738   -0.0580246    0.0367967   -0.0467336    -0.183945      0.0208739   -0.0726795     0.000372756   0.0701185    0.0616112    0.00440196   0.111387     0.0410405    0.0766756    0.041422     0.0208875   -0.115613    -0.206692    -0.0354844    0.0169075  -0.0933304   -0.317119    0.0195031    0.0146337    0.0850215   -0.186136
 -0.100145    -0.11517     -0.0993054    0.0380016    -0.0410968     0.0553417    0.0977176    -0.150214      0.180659    -0.00919928  -0.0468382    0.125221     0.112308    -0.099394     0.0790651    0.0246985   -0.141249     0.143268    -0.0909674    0.0110322   0.0832429    0.0436168   0.0853494    0.170409     0.084439    -0.0122568
  0.0210184   -0.0922927   -0.119099     0.206699     -0.0248926    -0.16081      0.0415046    -0.0783953    -0.0270453    0.0236524   -0.0324216    0.117698    -0.00948364   0.00310707  -0.0172506    0.0142013   -0.0731373    0.0613364    0.093218     0.116461   -0.199632    -0.0633303  -0.0358733   -0.0704032   -0.0342303   -0.0411075
 -0.0429074    0.624969    -0.0830664    0.041966     -0.0332487     0.0897382   -0.00738417    0.125674     -0.191891     0.0739273   -0.045291    -0.195278     0.111069     0.197282    -0.20017      0.0427801   -0.015628    -0.0617478    0.134923    -0.225736   -0.0016254    0.0213024   0.0912767    0.0657155   -0.150456    -0.101549
  0.0114856   -0.120205     0.103757     0.105006      0.235868     -0.0102235    0.0332266     0.196097      0.20192     -0.0215913   -0.064194    -0.148166     0.0534524    0.0205232    0.00399726   0.00581088   0.144136     0.0280915    0.148768     0.0307923  -0.0836144   -0.147256   -0.0373047   -0.0110863   -0.133515    -0.124284
  0.00430489  -0.0420819    0.0936295   -0.198207     -0.127151     -0.0450681    0.017424     -0.132964     -0.179325     0.204186     0.00701446  -0.0270444    0.0101358    0.00148217   0.0938274   -0.206195     0.234394    -0.133634    -0.262244    -0.152955    0.0304322    0.0406355  -0.00550393  -0.00825027   0.23359      0.0703296
 -0.230342     0.118622    -0.0445653   -0.0342893    -0.0209896     0.173857    -0.179999     -0.0645702     0.00885698   0.081917     0.0622642   -0.126785     0.0323971    0.00869782   0.0140722   -0.0316242    0.00243116  -0.0250027   -0.0683429   -0.103419    0.054903     0.0425975  -0.098675    -0.146704    -0.0809978   -0.00760152
 -0.150554     0.0979207   -0.130966    -0.157697      0.000450656   0.0942185    0.103656      0.0625398     0.171208    -0.0211666   -0.0335499   -0.079246     0.134874    -0.0428612   -0.00497624  -0.108241    -0.0200546   -0.00766922   0.072483    -0.0760677  -0.0575309    0.0400018  -0.0238603   -0.0399299    0.0230416    0.119303
  0.0213416    0.0268222   -0.1426       0.0764371     0.0729092    -0.0696192   -0.016428     -0.063708      0.0387256    0.128359    -0.266503    -0.0851962   -0.0959266   -0.191098    -0.0633994    0.011673     0.118724    -0.218012     0.0787773   -0.129984   -0.117551     0.0139739  -0.0549779   -0.0546291   -0.120462    -0.0397312
  0.0570457    0.0460838   -0.0585703    0.00230353    0.0698467     0.0639366   -0.144659      0.168106      0.0262865    0.0363566   -0.133687     0.136823     0.0562737    0.0587342    0.24364     -0.0284788    0.147981    -0.0105298   -0.0482474   -0.0467704  -0.0778959    0.0362356  -0.0294263   -0.0441622    0.135987    -0.132275
 -0.03844     -0.0217789   -0.0670204    0.0538368     0.101693      0.131705     0.053128     -0.160708     -0.088994     0.160027     0.0471073   -0.242538     0.0226012   -0.14881     -0.0508283    0.0916125    0.00725625   0.18034     -0.0458048   -0.220663   -0.042542    -0.02691    -0.152063    -0.0426352    0.0415742   -0.00349772
 -0.0566896   -0.0109254   -0.0957127    0.171681      0.0616129     0.0558481   -0.14587      -0.0902619    -0.137565     0.0736074    0.161429     0.0181422   -0.0727925   -0.133478     0.0460645    0.0745719   -0.0636376    0.0737042   -0.0593522    0.018169    0.0343808   -0.0543932  -0.00532613  -0.255026     0.139356    -0.0872752
  0.0389174   -2.2323      -0.266443     0.0572413    -0.0832439     0.0908423   -0.0221061     0.115576     -0.16547      0.0949898   -0.125573    -0.24362      0.105379     0.191417     0.129333    -0.0375166   -0.00531395  -0.0835969    0.109912    -0.111114    0.1097       0.0263738  -0.0815545   -0.0355547   -0.0801306   -0.0745468
  0.0570485    0.0577841    0.0636922    0.0225735     0.00467219    0.172809     0.0443751    -0.0585294     0.102615    -0.0425942   -0.0259368    0.0924687    0.0803434    0.0392076    0.00809978   0.037769     0.0469614    0.116662    -0.104008     0.0533557  -0.0955986   -0.0431907  -0.133224    -0.17393      0.00919382  -0.0693176
  0.0322364    0.0119864    0.037631     0.0445948     0.216753      0.0108991   -0.15259      -0.219683     -0.0941668   -0.0867362    0.0352373    0.102409    -0.0868766   -0.0945016    0.0304749   -0.055309    -0.170719     0.0555379   -0.0775338   -0.0369424   0.0775553   -0.0882117  -0.0828188    0.0472088   -0.195249    -0.00126517
  0.0735302   -0.00379548  -0.0827935    0.000741998   7.77394e-5   -0.00195439  -0.0346447     0.163865     -0.10266     -0.122222     0.203486     0.0258946    0.0247064    0.0279529    0.281499    -0.0678584   -0.1273      -0.056739    -0.00826961  -0.0843469  -0.0768132    0.0605869   0.10768      0.0423424    0.0139127    0.220509
 -0.0413482   -0.071885    -0.0385595    0.0217268    -0.170724     -0.117615    -0.0116732     0.176349     -0.165862     0.0773062    0.151059     0.00196318  -0.0573101    0.161989     0.0547424    0.0961069    0.0822665    0.0660229   -0.119728    -0.11867    -0.00331869   0.134614   -0.0275829   -0.0581958    0.149533    -0.0295358[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.021387
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      6
│      7
│     12
│      ⋮
│     21
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.966806
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      6
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.992058
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      7
│     12
│     13
│     16
│     21
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.988054
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      6
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.993749
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      6
│      7
│      ⋮
│     23
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.959991
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.019701
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      6
│      7
│     12
│      ⋮
│     21
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.965974
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      6
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.991808
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      7
│     12
│     13
│     16
│     21
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.988028
┌ Info: EM with 100000 data points 10 iterations avll -0.988028
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.025084     -0.0728374    0.0810612    0.00509228   0.0289125     0.0141026   -0.00233877   0.0741622    0.168569    -0.190586    0.160449     0.0794264   -0.0547229  -0.139201      0.0977892   -0.00618495   0.0394979   -0.0696734    0.0285455     0.0287697     0.0144237    0.181244     0.030534   -0.206269      0.027687     0.030117
 -0.024837     -0.198362     0.160401    -0.0990101   -0.0552174     0.0146592   -0.0291338    0.0408371    0.041415     0.0583029   0.130287    -0.111319     0.0246969  -0.000175585  -0.0696861    0.109001     0.110666    -0.101086     0.0713285    -0.0553006    -0.0172145   -0.0950561   -0.0456883   0.133261      0.0470496   -0.0304143
 -0.0739933    -0.0941151    0.17425      0.0159285    0.0269805    -0.0559899   -0.0143608   -0.039849     0.0244071   -0.0011116  -0.0797541    0.0184672    0.0868365   0.105819      0.0403092    0.120523     0.0367634    0.101521     0.189339     -0.0657242     0.0730121   -0.0548904    0.0752913  -0.0907253    -0.0212968   -0.0175622
 -0.0950823     0.0112959    0.134524    -0.126199     0.0237896     0.0755417   -0.0275729    0.145646     0.038478    -0.0650289  -0.0419542   -0.00381451  -0.0378594  -0.0508829    -0.0703685   -0.190305     0.118196    -0.0377103   -0.0365063    -0.152167      0.00511064   0.0763692    0.0303793  -0.0143937    -0.0316945   -0.0952933
  0.0230878    -0.0179549   -0.148158    -0.0808061   -0.21484       0.0551085    0.0197851    0.0929489   -0.182787     0.0997013   0.0658609    0.0484858   -0.120445   -0.0866788    -0.0016267   -0.0154254    0.0322505    0.141477    -0.121833      0.0391489     0.0605865    0.0137749    0.0379584  -0.0346218    -0.0925718    0.0450691
 -0.04676       0.0205321   -0.187212     0.037994    -0.171862      0.10416      0.115674    -0.135116    -0.0234667    0.0609816  -0.0529894   -0.0364072   -0.0916768  -0.00311429    0.138784     0.155782    -0.0330048    0.180876    -0.176827     -0.0759254    -0.0644093   -0.0200317   -0.0456642   0.0670846     0.111008    -0.0952818
 -0.0216361     0.106459     0.130788    -0.0304678   -0.0487823    -0.0644879   -0.0486075    0.0777385   -0.00294928  -0.0248677  -0.0563187   -0.172196     0.0913034  -0.0808194    -0.114398     0.103583     0.23956     -0.154487     0.0111323     0.131751     -0.0589767    0.150277    -0.139173   -0.0404887     0.00356764  -0.0729638
  0.0947815    -0.00401442  -0.07256      0.108439    -0.000877832   0.0402366    0.189468    -0.0394928   -0.0659837    0.0292126   0.0624984   -0.0208732    0.104224   -0.0720207    -0.192043    -0.11849     -0.0677192   -0.0984681    0.0747288     0.092892     -0.0168538    0.181277    -0.127821   -0.0221505     0.027063     0.029162
 -0.0135746    -0.100898     0.00698693   0.196734    -0.106777      0.0984698   -0.015704     0.0396874    0.0768162   -0.0825011  -0.00269401  -0.11852      0.027288    0.0886231     0.00466126  -0.0544854    0.00627613   0.00535078  -0.141086      0.0899398     0.0110886   -0.0362161    0.0015404  -0.16506       0.0528282   -0.0712326
  0.215819     -0.191466    -0.106298    -0.0551806   -0.116028     -0.0786489   -0.0951893    0.0106511    0.0244678   -0.0816375  -0.0539899   -0.123264     0.205763   -0.108813     -0.0223823   -0.143743    -0.083285    -0.0974638    0.0138571     0.131464      0.133261     0.0778143    0.102633    0.158099      0.2095       0.224734
 -0.0152258    -0.08319     -0.0523655   -0.0980665    0.0640895     0.0651302    0.0423857   -0.0460102    0.0317389   -0.0359471  -0.269648    -0.0321329    0.0886982   0.036324      0.130676     0.0726781    0.0706501   -0.00396316   0.137704      0.0783137    -0.104209    -0.058543     0.0860385   0.0548439    -0.188031    -0.0330921
 -0.0154201    -0.169939     0.00223718   0.0841743   -0.046482      0.0637475    0.105418     0.126893     0.144108    -0.0791229  -0.0949362   -0.0255242    0.0742879   0.0191443    -0.231374     0.0310767   -0.0717962    0.00269832   0.163708      0.0446783    -0.0987129   -0.0213156   -0.0491154  -0.00171573   -0.123083     0.0216465
  0.167457     -0.127197    -0.144279    -0.227649    -0.0927968     0.0568375   -0.194146    -0.122695    -0.0893514   -0.106133    0.127365    -0.0119329    0.121487   -0.0746264    -0.154611    -0.0311662   -0.0255213    0.0364146   -0.0250939    -0.0631165    -0.0535435    0.0382104    0.221856    0.096314      0.00416705   0.0142439
  0.0257267    -0.121417     0.0294557   -0.181967    -0.0487476     0.0414196    0.217967    -0.015707    -0.0174048    0.0605761   0.0890441   -0.0124261   -0.0681943  -0.0104726    -0.0192285    0.155121    -0.286933    -0.114896    -0.075819      0.0902911    -0.0767744   -0.0150465   -0.0386675  -0.0629621     0.133796     0.00959299
 -0.109761     -0.0543925   -0.0612415    0.172229    -0.0742715    -0.159097     0.0986592    0.00364473   0.0816123   -0.140936    0.0378371   -0.0197265   -0.0442683   0.00336174    0.0311209   -0.081193     0.135219     0.0713112   -0.111735      0.100262      0.00150676   0.162348     0.167971   -0.000204999   0.0464703    0.00495071
 -0.0910614     0.133507    -0.0362633   -0.00423433   0.096416     -0.154131    -0.104333    -0.125472     0.0522284   -0.0482338   0.00653927   0.0765979    0.0333773   0.139531      0.0883872   -0.127534    -0.11855     -0.101775     0.0694252    -0.0587715    -0.0871976    0.106115    -0.0664761   0.253902      0.133231     0.0223283
 -0.0439554     0.088767     0.255702     0.0273201    0.0957879    -0.010888     0.189411     0.0644009    0.0757944    0.0598315   0.0923047   -0.0238475    0.069336    0.0651755     0.052786    -0.0180246    0.11812      0.207244     0.0611633    -0.139735     -0.175226    -0.0848327   -0.103906    0.036447     -0.132972    -0.0164305
 -0.0687979    -0.100882    -0.00380692  -0.0411271    0.154223      0.0362854    0.188585    -0.119473     0.0297516   -0.0499779   0.0205775   -0.0621075    0.347774   -0.0481775     0.0639111   -0.0306575    0.106377     0.0635809   -0.143858     -0.0889086    -0.07082      0.0561229   -0.0339052   0.146877      0.108538    -0.0451859
 -0.110266     -0.0761653   -0.0319302    0.0530562    0.327109     -0.0845484    0.0510736    0.0786243   -0.0282907   -0.0672756   0.0712234    0.109893     0.0478131   0.0469837    -0.156834     0.0465921    0.0765582   -0.041328    -0.245082     -0.0544851     0.0332992   -0.0238053   -0.072324   -0.13138      -0.0579848   -0.0464347
  0.144031      0.0460457    0.15462      0.0552941   -0.0614563     0.00226961   0.0910732    0.079777    -0.181654     0.038635   -0.0804647    0.13855      0.0168042  -0.118811      0.0119911   -0.0953061   -0.0352979    0.0116744   -0.0412248     0.0107316     0.158108     0.195869    -0.159908   -0.0927338     0.00430789   0.0371021
 -0.000782459  -0.0445297   -0.12771      0.0998873   -0.0197016     0.188185     0.0298081   -0.0551302   -0.0844321   -0.0911861   0.145687     0.15823      0.0526262   0.0579982     0.0995981    0.0628495   -0.145199    -0.202786    -0.149269      0.0892011    -0.00788766   0.114279     0.0618819   0.024546      0.00232787  -0.0825725
  0.0878954    -0.0784818    0.0477212   -0.131983     0.0110425     0.0653619   -0.0400791    0.0185487    0.00997966  -0.0627312  -0.00596814  -0.113325     0.111315   -0.0659193    -0.0430039   -0.135198    -0.101373    -0.106807    -0.0675835    -0.0117952    -0.0198469    0.017147    -0.10217    -0.0598531    -0.0802715   -0.12918
 -0.146413     -0.0111617   -0.0225271   -0.0501091   -0.00267386    0.0857696   -0.118734     0.0338814    0.0430427   -0.0837864   0.137483    -0.19273     -0.0648115  -0.00971688    0.0325475   -0.0919356    0.0387211    0.119008    -0.110481     -0.000534237  -0.0583975    0.113955     0.0654556  -0.0713854    -0.081351     0.148383
 -0.119677      0.0205881   -0.144227    -0.0614417    0.0990782     0.113947     0.0505085    0.207189    -0.00406579  -0.0326552  -0.0627051   -0.0988473    0.149229   -0.0465121    -0.0422965   -0.0157612    0.0127995    0.0458971    0.102611      0.1738        0.0794667   -0.00371678  -0.125916    0.13198      -0.0116641   -0.0617909
 -0.0506578    -0.0947778    0.234102     0.0509298   -0.113884     -0.0533121   -0.0781208    0.0230395    0.218158    -0.0647173  -0.162909     0.171083     0.13513     0.0510899     0.163749     0.0693963   -0.198303     0.0279697   -0.115952      0.0425486     0.0915653   -0.0177064   -0.0318937   0.0988969     0.103676     0.0028116
  0.0289572    -0.0676734   -0.280858    -0.0568056   -0.0876594    -0.0674564   -0.104016    -0.0294948   -0.156306     0.044705   -0.141631    -0.00413351  -0.0148534   0.0108607    -0.0189043   -0.0272793    0.0884427   -0.118756     0.107372     -0.0567876     0.0386281    0.0452847    0.139229    0.0205441     0.111354     0.150156
  0.0836382    -0.0452703    0.0794234   -0.101883     0.131361     -0.0748857    0.0620116    0.0703631   -0.0418102    0.0851331   0.0187438   -0.0390174    0.173997    0.0935479     0.00788259  -0.284975     0.0593147   -0.11403     -0.0162915    -0.0468802     0.0109023   -0.125731    -0.0483712  -0.0112799     0.1103      -0.174757
  0.0760947    -0.0967607    0.131131     0.0286682    0.179959      0.109903    -0.0323584    0.0277318    0.0384975    0.110283    0.111132     0.166856     0.209121    0.0641575    -0.145141     0.209609     0.037162    -0.0569619   -0.0444923     0.0790475     0.010047    -0.0171064   -0.0247089  -0.0556096     0.11658      0.0667201
 -0.0326255     0.138052     0.0776111    0.0998382   -0.167419      0.0839141   -0.0880754   -0.0863771   -0.0206896   -0.222261    0.0860067   -0.00659565   0.0266996  -0.116133     -0.0668518    0.134581     0.090262     0.252463    -0.0876671     0.0339033    -0.00257053   0.0571253    0.0693469  -0.19229       0.0271471    0.0309557
  0.00867042   -0.175329    -0.101225     0.104905     0.11876      -0.0850783    0.013489     0.0904131    0.0414158   -0.18461    -0.0448056    0.0637064   -0.196889    0.0441818     0.015331    -0.0217792   -0.0770094    0.0639909    0.168755      0.087463     -0.04208      0.0920466    0.0323607  -0.0166154    -0.0560801    0.136628
  0.00518964   -0.0133302   -0.056142    -0.0655009   -0.0536112    -0.187979     0.0997475   -0.0821122    0.0348787   -0.205909   -0.0685874   -0.129762    -0.0166404  -0.103928      0.191539    -0.0603907    0.0901048   -0.0344931   -0.000764412   0.0849249     0.0234188    0.113339    -0.0909288  -0.0179843    -0.0413055    7.61444e-5
 -0.0640926    -0.0689539    0.0532642    0.0544022    0.148323      0.122561    -0.0300093   -0.158826     0.0827372   -0.0738967  -0.0200481    0.0313131    0.060377   -0.111327     -0.0574052    0.0802411   -0.0948587   -0.102403     0.0677029    -0.00303568    0.00823605   0.167163    -0.0131302   0.0942482     0.116388     0.00633447kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4191826104983123
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419201
[ Info: iteration 2, average log likelihood -1.419106
[ Info: iteration 3, average log likelihood -1.419030
[ Info: iteration 4, average log likelihood -1.418941
[ Info: iteration 5, average log likelihood -1.418832
[ Info: iteration 6, average log likelihood -1.418696
[ Info: iteration 7, average log likelihood -1.418516
[ Info: iteration 8, average log likelihood -1.418255
[ Info: iteration 9, average log likelihood -1.417837
[ Info: iteration 10, average log likelihood -1.417178
[ Info: iteration 11, average log likelihood -1.416271
[ Info: iteration 12, average log likelihood -1.415286
[ Info: iteration 13, average log likelihood -1.414502
[ Info: iteration 14, average log likelihood -1.414046
[ Info: iteration 15, average log likelihood -1.413835
[ Info: iteration 16, average log likelihood -1.413747
[ Info: iteration 17, average log likelihood -1.413712
[ Info: iteration 18, average log likelihood -1.413698
[ Info: iteration 19, average log likelihood -1.413692
[ Info: iteration 20, average log likelihood -1.413689
[ Info: iteration 21, average log likelihood -1.413688
[ Info: iteration 22, average log likelihood -1.413688
[ Info: iteration 23, average log likelihood -1.413687
[ Info: iteration 24, average log likelihood -1.413687
[ Info: iteration 25, average log likelihood -1.413687
[ Info: iteration 26, average log likelihood -1.413687
[ Info: iteration 27, average log likelihood -1.413687
[ Info: iteration 28, average log likelihood -1.413686
[ Info: iteration 29, average log likelihood -1.413686
[ Info: iteration 30, average log likelihood -1.413686
[ Info: iteration 31, average log likelihood -1.413686
[ Info: iteration 32, average log likelihood -1.413686
[ Info: iteration 33, average log likelihood -1.413686
[ Info: iteration 34, average log likelihood -1.413686
[ Info: iteration 35, average log likelihood -1.413686
[ Info: iteration 36, average log likelihood -1.413686
[ Info: iteration 37, average log likelihood -1.413686
[ Info: iteration 38, average log likelihood -1.413686
[ Info: iteration 39, average log likelihood -1.413686
[ Info: iteration 40, average log likelihood -1.413686
[ Info: iteration 41, average log likelihood -1.413686
[ Info: iteration 42, average log likelihood -1.413686
[ Info: iteration 43, average log likelihood -1.413686
[ Info: iteration 44, average log likelihood -1.413685
[ Info: iteration 45, average log likelihood -1.413685
[ Info: iteration 46, average log likelihood -1.413685
[ Info: iteration 47, average log likelihood -1.413685
[ Info: iteration 48, average log likelihood -1.413685
[ Info: iteration 49, average log likelihood -1.413685
[ Info: iteration 50, average log likelihood -1.413685
┌ Info: EM with 100000 data points 50 iterations avll -1.413685
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4192009301660156
│     -1.4191059848352536
│      ⋮
└     -1.413685399408655
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413703
[ Info: iteration 2, average log likelihood -1.413606
[ Info: iteration 3, average log likelihood -1.413526
[ Info: iteration 4, average log likelihood -1.413433
[ Info: iteration 5, average log likelihood -1.413323
[ Info: iteration 6, average log likelihood -1.413203
[ Info: iteration 7, average log likelihood -1.413089
[ Info: iteration 8, average log likelihood -1.412994
[ Info: iteration 9, average log likelihood -1.412922
[ Info: iteration 10, average log likelihood -1.412868
[ Info: iteration 11, average log likelihood -1.412825
[ Info: iteration 12, average log likelihood -1.412788
[ Info: iteration 13, average log likelihood -1.412753
[ Info: iteration 14, average log likelihood -1.412720
[ Info: iteration 15, average log likelihood -1.412688
[ Info: iteration 16, average log likelihood -1.412657
[ Info: iteration 17, average log likelihood -1.412629
[ Info: iteration 18, average log likelihood -1.412605
[ Info: iteration 19, average log likelihood -1.412583
[ Info: iteration 20, average log likelihood -1.412565
[ Info: iteration 21, average log likelihood -1.412550
[ Info: iteration 22, average log likelihood -1.412538
[ Info: iteration 23, average log likelihood -1.412528
[ Info: iteration 24, average log likelihood -1.412520
[ Info: iteration 25, average log likelihood -1.412513
[ Info: iteration 26, average log likelihood -1.412508
[ Info: iteration 27, average log likelihood -1.412503
[ Info: iteration 28, average log likelihood -1.412499
[ Info: iteration 29, average log likelihood -1.412495
[ Info: iteration 30, average log likelihood -1.412492
[ Info: iteration 31, average log likelihood -1.412489
[ Info: iteration 32, average log likelihood -1.412486
[ Info: iteration 33, average log likelihood -1.412484
[ Info: iteration 34, average log likelihood -1.412482
[ Info: iteration 35, average log likelihood -1.412480
[ Info: iteration 36, average log likelihood -1.412478
[ Info: iteration 37, average log likelihood -1.412476
[ Info: iteration 38, average log likelihood -1.412474
[ Info: iteration 39, average log likelihood -1.412472
[ Info: iteration 40, average log likelihood -1.412471
[ Info: iteration 41, average log likelihood -1.412469
[ Info: iteration 42, average log likelihood -1.412468
[ Info: iteration 43, average log likelihood -1.412467
[ Info: iteration 44, average log likelihood -1.412465
[ Info: iteration 45, average log likelihood -1.412464
[ Info: iteration 46, average log likelihood -1.412463
[ Info: iteration 47, average log likelihood -1.412462
[ Info: iteration 48, average log likelihood -1.412461
[ Info: iteration 49, average log likelihood -1.412460
[ Info: iteration 50, average log likelihood -1.412459
┌ Info: EM with 100000 data points 50 iterations avll -1.412459
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4137034884318112
│     -1.41360585408927
│      ⋮
└     -1.4124586362369624
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412469
[ Info: iteration 2, average log likelihood -1.412419
[ Info: iteration 3, average log likelihood -1.412373
[ Info: iteration 4, average log likelihood -1.412315
[ Info: iteration 5, average log likelihood -1.412238
[ Info: iteration 6, average log likelihood -1.412139
[ Info: iteration 7, average log likelihood -1.412021
[ Info: iteration 8, average log likelihood -1.411889
[ Info: iteration 9, average log likelihood -1.411756
[ Info: iteration 10, average log likelihood -1.411630
[ Info: iteration 11, average log likelihood -1.411516
[ Info: iteration 12, average log likelihood -1.411415
[ Info: iteration 13, average log likelihood -1.411327
[ Info: iteration 14, average log likelihood -1.411252
[ Info: iteration 15, average log likelihood -1.411190
[ Info: iteration 16, average log likelihood -1.411139
[ Info: iteration 17, average log likelihood -1.411099
[ Info: iteration 18, average log likelihood -1.411067
[ Info: iteration 19, average log likelihood -1.411043
[ Info: iteration 20, average log likelihood -1.411024
[ Info: iteration 21, average log likelihood -1.411008
[ Info: iteration 22, average log likelihood -1.410996
[ Info: iteration 23, average log likelihood -1.410986
[ Info: iteration 24, average log likelihood -1.410977
[ Info: iteration 25, average log likelihood -1.410970
[ Info: iteration 26, average log likelihood -1.410963
[ Info: iteration 27, average log likelihood -1.410956
[ Info: iteration 28, average log likelihood -1.410950
[ Info: iteration 29, average log likelihood -1.410943
[ Info: iteration 30, average log likelihood -1.410937
[ Info: iteration 31, average log likelihood -1.410931
[ Info: iteration 32, average log likelihood -1.410924
[ Info: iteration 33, average log likelihood -1.410917
[ Info: iteration 34, average log likelihood -1.410911
[ Info: iteration 35, average log likelihood -1.410904
[ Info: iteration 36, average log likelihood -1.410897
[ Info: iteration 37, average log likelihood -1.410890
[ Info: iteration 38, average log likelihood -1.410883
[ Info: iteration 39, average log likelihood -1.410875
[ Info: iteration 40, average log likelihood -1.410868
[ Info: iteration 41, average log likelihood -1.410861
[ Info: iteration 42, average log likelihood -1.410854
[ Info: iteration 43, average log likelihood -1.410847
[ Info: iteration 44, average log likelihood -1.410840
[ Info: iteration 45, average log likelihood -1.410834
[ Info: iteration 46, average log likelihood -1.410827
[ Info: iteration 47, average log likelihood -1.410821
[ Info: iteration 48, average log likelihood -1.410815
[ Info: iteration 49, average log likelihood -1.410810
[ Info: iteration 50, average log likelihood -1.410804
┌ Info: EM with 100000 data points 50 iterations avll -1.410804
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4124685935839965
│     -1.41241878411223
│      ⋮
└     -1.4108041067236123
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410808
[ Info: iteration 2, average log likelihood -1.410755
[ Info: iteration 3, average log likelihood -1.410707
[ Info: iteration 4, average log likelihood -1.410650
[ Info: iteration 5, average log likelihood -1.410582
[ Info: iteration 6, average log likelihood -1.410499
[ Info: iteration 7, average log likelihood -1.410401
[ Info: iteration 8, average log likelihood -1.410294
[ Info: iteration 9, average log likelihood -1.410181
[ Info: iteration 10, average log likelihood -1.410069
[ Info: iteration 11, average log likelihood -1.409961
[ Info: iteration 12, average log likelihood -1.409859
[ Info: iteration 13, average log likelihood -1.409764
[ Info: iteration 14, average log likelihood -1.409678
[ Info: iteration 15, average log likelihood -1.409601
[ Info: iteration 16, average log likelihood -1.409531
[ Info: iteration 17, average log likelihood -1.409468
[ Info: iteration 18, average log likelihood -1.409412
[ Info: iteration 19, average log likelihood -1.409362
[ Info: iteration 20, average log likelihood -1.409317
[ Info: iteration 21, average log likelihood -1.409276
[ Info: iteration 22, average log likelihood -1.409239
[ Info: iteration 23, average log likelihood -1.409206
[ Info: iteration 24, average log likelihood -1.409177
[ Info: iteration 25, average log likelihood -1.409150
[ Info: iteration 26, average log likelihood -1.409125
[ Info: iteration 27, average log likelihood -1.409103
[ Info: iteration 28, average log likelihood -1.409083
[ Info: iteration 29, average log likelihood -1.409065
[ Info: iteration 30, average log likelihood -1.409048
[ Info: iteration 31, average log likelihood -1.409033
[ Info: iteration 32, average log likelihood -1.409018
[ Info: iteration 33, average log likelihood -1.409005
[ Info: iteration 34, average log likelihood -1.408993
[ Info: iteration 35, average log likelihood -1.408981
[ Info: iteration 36, average log likelihood -1.408970
[ Info: iteration 37, average log likelihood -1.408960
[ Info: iteration 38, average log likelihood -1.408950
[ Info: iteration 39, average log likelihood -1.408940
[ Info: iteration 40, average log likelihood -1.408931
[ Info: iteration 41, average log likelihood -1.408923
[ Info: iteration 42, average log likelihood -1.408914
[ Info: iteration 43, average log likelihood -1.408906
[ Info: iteration 44, average log likelihood -1.408898
[ Info: iteration 45, average log likelihood -1.408891
[ Info: iteration 46, average log likelihood -1.408883
[ Info: iteration 47, average log likelihood -1.408876
[ Info: iteration 48, average log likelihood -1.408868
[ Info: iteration 49, average log likelihood -1.408861
[ Info: iteration 50, average log likelihood -1.408854
┌ Info: EM with 100000 data points 50 iterations avll -1.408854
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4108084479070515
│     -1.4107549233105445
│      ⋮
└     -1.408854222074028
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408856
[ Info: iteration 2, average log likelihood -1.408785
[ Info: iteration 3, average log likelihood -1.408715
[ Info: iteration 4, average log likelihood -1.408631
[ Info: iteration 5, average log likelihood -1.408524
[ Info: iteration 6, average log likelihood -1.408387
[ Info: iteration 7, average log likelihood -1.408222
[ Info: iteration 8, average log likelihood -1.408037
[ Info: iteration 9, average log likelihood -1.407844
[ Info: iteration 10, average log likelihood -1.407657
[ Info: iteration 11, average log likelihood -1.407484
[ Info: iteration 12, average log likelihood -1.407331
[ Info: iteration 13, average log likelihood -1.407196
[ Info: iteration 14, average log likelihood -1.407080
[ Info: iteration 15, average log likelihood -1.406980
[ Info: iteration 16, average log likelihood -1.406893
[ Info: iteration 17, average log likelihood -1.406819
[ Info: iteration 18, average log likelihood -1.406753
[ Info: iteration 19, average log likelihood -1.406696
[ Info: iteration 20, average log likelihood -1.406645
[ Info: iteration 21, average log likelihood -1.406599
[ Info: iteration 22, average log likelihood -1.406557
[ Info: iteration 23, average log likelihood -1.406518
[ Info: iteration 24, average log likelihood -1.406483
[ Info: iteration 25, average log likelihood -1.406449
[ Info: iteration 26, average log likelihood -1.406418
[ Info: iteration 27, average log likelihood -1.406389
[ Info: iteration 28, average log likelihood -1.406361
[ Info: iteration 29, average log likelihood -1.406334
[ Info: iteration 30, average log likelihood -1.406309
[ Info: iteration 31, average log likelihood -1.406284
[ Info: iteration 32, average log likelihood -1.406261
[ Info: iteration 33, average log likelihood -1.406239
[ Info: iteration 34, average log likelihood -1.406218
[ Info: iteration 35, average log likelihood -1.406198
[ Info: iteration 36, average log likelihood -1.406178
[ Info: iteration 37, average log likelihood -1.406160
[ Info: iteration 38, average log likelihood -1.406142
[ Info: iteration 39, average log likelihood -1.406125
[ Info: iteration 40, average log likelihood -1.406108
[ Info: iteration 41, average log likelihood -1.406093
[ Info: iteration 42, average log likelihood -1.406078
[ Info: iteration 43, average log likelihood -1.406063
[ Info: iteration 44, average log likelihood -1.406049
[ Info: iteration 45, average log likelihood -1.406036
[ Info: iteration 46, average log likelihood -1.406023
[ Info: iteration 47, average log likelihood -1.406011
[ Info: iteration 48, average log likelihood -1.405999
[ Info: iteration 49, average log likelihood -1.405987
[ Info: iteration 50, average log likelihood -1.405976
┌ Info: EM with 100000 data points 50 iterations avll -1.405976
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4088560593357167
│     -1.4087848976154376
│      ⋮
└     -1.405975569062124
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4191826104983123
│     -1.4192009301660156
│     -1.4191059848352536
│     -1.4190299617625257
│      ⋮
│     -1.4059986565361515
│     -1.4059869484798468
└     -1.405975569062124
32×26 Array{Float64,2}:
  0.750387    -0.0203221   0.21981       0.0921036   -0.0877928   0.20632     0.666769   -0.0231337   -0.253506    0.0613481   0.100233    -0.928283    -0.249917    0.217739    0.247496     -0.236031   -0.566362      0.00375315   0.237089   -0.689447     -0.0706368  -0.0874772  -0.314564   -0.145293    0.138029   -0.0518464
  0.193628    -0.201623    0.0648213     0.328311     0.619897   -0.0232313   0.205387   -0.160081    -0.239645    0.0894057  -0.0305812   -0.731754     0.212785   -0.0517504   0.174705      0.0167901  -0.496152     -0.38748     -0.273926    0.273168      0.12167    -0.206189   -0.477554    0.036093    0.391108   -0.243601
 -0.0206938   -0.121252    0.0229458    -0.181102    -0.302716    0.180123   -0.0185967   0.0834897    0.257579   -0.25597     0.235584    -0.425598    -0.217628   -0.0537596  -0.210198     -0.305786    0.243796     -0.212944    -0.165842   -0.327808     -0.232342    0.120224   -0.616233    0.151164   -0.0830494  -0.438658
  0.188342     0.0182868   0.288324     -0.0324005   -0.275853    0.079934   -0.11053    -0.368001     0.137806    0.279689    0.321654    -0.267339    -0.227677    0.120474   -0.336427     -0.198219    0.00755284    0.107036    -0.0994435   0.000135034   0.0661276   0.22329     0.542819   -0.076085   -0.254306    0.0302761
  0.195554    -0.183215    0.0376688     0.0944101    0.112673    0.0851917   0.016831    0.0582219    0.0470007  -0.296154    0.0231204    0.0795838    0.0993816  -0.0625626   0.098794      0.0181112  -0.084478      0.151951     0.148544    0.0932818     0.244841    0.0417381  -0.212068   -0.143368   -0.108519    0.100624
 -0.221541     0.374425   -0.000681788   0.106358    -0.0804497  -0.291543    0.0448872   0.160548     0.308328    0.0759413  -0.11268      0.12193      0.26679    -0.163241    0.0651885     0.0780344   0.101429     -0.135708     0.209624   -0.067344     -0.365909    0.0774382  -0.288861   -0.0940133   0.0301141   0.267232
 -0.519428    -0.132507   -0.281509     -0.075184    -0.195804   -0.0441758  -0.496443    0.126564     0.0965825  -0.655364   -0.340991     0.695564     0.256521   -0.35045    -0.164328     -0.213935    0.422167      0.129185    -0.0507001   0.454129      0.204351    0.0898369   0.289337    0.107878   -0.130787   -0.00270473
  0.47683     -0.131295    0.102534      0.133221    -0.164348   -0.360829   -0.0249337  -0.0876621   -0.213049   -0.395452   -0.709755    -0.0259424    0.285445   -0.236187    0.165281     -0.303214   -0.169805      0.306582    -0.12423     0.0559525     0.0350086  -0.294681    0.210264    0.483973   -0.168798    0.0736504
  0.0468049   -0.661188    0.233238     -0.28035     -0.109749    0.602125    0.464354    0.686956    -0.679244    0.579762   -0.120356    -0.151757     0.304039   -0.13249    -0.618409      0.102513   -0.757919      0.0495477    0.359748    0.438517     -0.122696   -0.0630955   0.238726    0.573897    0.0153868   0.243728
  0.116114    -0.548835    0.238495     -0.614937     0.61092     0.826631    0.147154   -0.215333     0.0482789  -0.252305   -0.00738614  -0.0331829    0.217523    0.0709488  -0.228458      0.297003    0.380956      0.397522     0.136975    0.158356      0.362611    0.047255    0.0458809   0.140966   -0.372653   -0.025203
 -0.362475     0.163413   -0.26944      -0.245863     0.0935971   0.539297    0.0746145   0.593943     0.148981    0.260594   -0.293536    -0.168401    -0.429013    0.141742   -0.0559015     0.599552    0.178108     -0.277801     0.462144   -0.378195     -0.206306    0.132224    0.395123    0.681001   -0.686763   -0.0409354
  0.550934     0.44215    -0.364662      0.0641443   -0.0874656   0.502153    0.429253    0.055848    -0.440067    0.584327    0.176852    -0.0454485   -0.552931    0.39344    -0.217801      0.46757    -0.114435     -0.111328    -0.0854877   0.0465757    -0.480839   -0.179576   -0.0477703   0.0162517  -0.303667   -0.0365577
 -0.344125    -0.143888   -0.430296     -0.165295     0.1312     -0.127237    0.11108    -0.00678322  -0.461561    0.274865    0.0125934    0.393703     0.262329   -0.0627292  -0.151805      0.322964   -0.0510689    -0.168573    -0.149593   -0.0497006    -0.0200331   0.0593424   0.218405   -0.172877    0.536027   -0.116483
 -0.751674     0.105148   -0.113547     -0.415385     0.501546    0.122414    0.051892   -0.0180099   -0.16978     0.0972263   0.0821009    0.0686524    0.0400907   0.708822   -0.241036     -0.189549    0.274623     -0.247426    -0.473618    0.101126     -0.155752   -0.180945    0.360481   -0.0123428   0.326989   -0.392509
  0.0708942   -0.646792    0.35184       0.0838459   -0.47694    -0.581868   -0.311564    0.194719     0.173859   -0.142739    0.181709     0.166879    -0.3696      0.109498    0.521873      0.0825804  -0.0440241     0.112738    -0.236087    0.0483138    -0.119699    0.0383304   0.426429    0.261465    0.251785   -0.0479759
 -0.684338     0.742503    0.210781      0.0592581   -0.0351998  -0.124368   -0.110058    0.465111     0.0406877   0.065888    0.427        0.0789199    0.312767    0.0403589   0.789373      0.123514   -0.399845      0.199489    -0.0510859   0.163179      0.402224    0.139201    0.440666    0.424687    0.17828     0.320817
  0.0061788    0.316822   -0.345768      0.0863484   -0.0540674  -0.17721     0.435984    0.0768629   -0.245075    0.445119    0.0731096    0.289282     0.228032   -0.596769    0.276937      0.276387   -0.471081     -0.881382    -0.27841    -0.282856     -0.440087   -0.0217188  -0.761441   -0.278874    0.528894   -0.22778
 -0.196373     0.377277    0.208741      0.00288447   0.231087   -0.41683    -0.179046   -0.233812    -0.180795    0.0669709  -0.797188    -0.274501     0.441607   -0.187938   -0.142327      0.236399    0.130851     -0.483229    -0.31761    -0.118066     -0.801202    0.153575    0.165086    0.549895    0.235732   -0.352067
 -0.0616115    0.181353   -0.169811     -0.25058     -0.295024   -0.180204    0.206013    0.666844    -0.140807   -0.34622    -0.502667     0.700611     0.318804    0.0196949   0.000788023  -0.0804405   0.267051      0.128454     0.554518    0.202307     -0.371385   -0.0798273   0.137716    0.159871   -0.503586    0.311842
 -0.280528    -0.547754    0.0638061    -0.141131     0.409432   -0.248856    0.206252    1.03996      0.0600001  -0.674946   -0.413834     0.466693     0.0726673   0.237083    0.561492      0.150017    0.137547     -0.294976     0.438212    0.00414413   -0.101934   -0.191541   -0.630268   -0.150236    0.455202   -0.0943694
  0.151665    -0.044541   -0.00563642   -0.316409     0.0578365  -0.281942    0.0894817  -0.61078      0.263155   -0.315169    0.0466995    0.226041     0.660913   -0.0842772  -0.402365     -0.02814     0.386233     -0.051804     0.134974   -0.260668     -0.665704    0.144895   -0.939759   -0.744507   -0.0140058   0.0511714
 -0.00999578  -0.17585    -0.123297     -0.19716      0.576315    0.0248092   0.539628   -0.244723    -0.174528   -0.187832   -0.144434     0.0910077    0.641451    0.0237802  -0.0531678     0.192695   -0.312643      0.277639     0.244045   -0.0666721     0.422439    0.428386   -0.0515867  -0.583879   -0.178281    0.173378
  0.147324     0.0965843  -0.10832       0.551506     0.131456   -0.749084   -0.329499   -0.669314     0.257514   -0.238116    0.0359844    0.0794398    0.445623   -0.362571    0.424666     -0.387068   -0.122653     -0.0145898   -0.313743    0.25852       0.35887     0.118329   -0.449919   -0.557851    0.828508   -0.185067
 -0.440013    -0.323546   -0.162223     -0.135706     0.425679   -0.147369    0.0720791  -0.481768    -0.384594   -0.2264      0.0835012    0.389115    -0.218339    0.725991    0.119004     -0.17669     0.153922     -0.284215    -0.51493     0.0705481     0.183917    0.0900192   0.488678   -0.499104    0.605213   -0.675953
  0.167681     0.18644    -0.737062      0.536361    -0.314481    0.694813    0.631802   -0.768062    -0.149931    0.492098    0.0627989    0.00815917  -0.0841758  -0.596508   -0.750541     -0.0347131  -0.250747      0.136431    -0.265168    0.300872      0.379462    0.534634    0.159321   -0.0227628  -0.293592    0.0697991
 -0.226955    -0.187681    0.419858      0.067872    -0.147296    0.413779   -0.214029   -0.415068     0.509997    0.876478    1.08476     -0.824994    -0.325809   -0.290592   -0.0598236     0.606725   -0.329964     -0.238374    -0.474818   -0.411253      0.240094    0.422676   -0.0587395  -0.189462    0.331968    0.0329463
 -0.171612    -0.0138087  -0.0882004    -0.192375    -0.612349    0.100396    0.148195    0.325884     0.111963    0.257054    0.580653    -0.131199    -0.827199    0.453359   -0.414821     -0.118167   -0.0698475    -0.102344    -0.113842   -0.154775     -0.431639   -0.185237    0.0756777   0.404053   -0.198298   -0.44927
  0.241001    -0.26437     0.0229658     0.0576993   -0.24779     0.471221    0.0532603   0.130002    -0.0759871   0.0423512   0.817569     0.273336    -0.49275     0.338637    0.187474     -0.154201    0.000314934   0.639799     0.409947    0.0579316     0.666122   -0.101768    0.294436   -0.739529   -0.0826089   0.488952
  0.543908     0.320548   -0.106632      0.46614     -0.659192    0.154016   -0.462591    0.0798958    0.695782   -0.285289   -0.00155507  -0.446497     0.0974467  -0.728057   -0.0300599    -0.0404928  -0.0755278     0.114807     0.139967   -0.140535      0.148513    0.15661    -0.541316    0.603818   -0.290563    0.376169
  0.204401    -0.176131    0.671384     -0.224266     0.14678     0.0968663  -0.499897   -0.0819412    0.0134547  -0.0674697  -0.0332475   -0.39944      0.297618   -0.252532    0.0762528    -0.260059   -0.259722      0.50007     -0.0410407   0.0546521     0.594162   -0.184009    0.37726     0.346125   -0.210993    0.464336
 -0.314691     0.406294    0.0380737     0.547107     0.0773608  -0.231586   -0.821909   -0.0172201    0.37903    -0.286174    0.160633    -0.400602    -0.290834    0.11748    -0.136988     -0.24815     0.836891      0.218729    -1.02588     0.651538      0.0885046   0.473099    0.877146   -0.105269   -0.294788    0.303545
  0.0168217   -0.481122    0.121629      0.173597     0.219756    0.202051   -0.570015   -0.0811704    0.55807    -0.113597   -0.559938    -0.39534     -0.621114    0.0687243  -0.00523692   -0.343742    1.28824      -0.101158     0.453211    0.648975     -0.0156497  -0.452017    0.29856     0.269332    0.0426457   0.112783[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405964
[ Info: iteration 2, average log likelihood -1.405954
[ Info: iteration 3, average log likelihood -1.405943
[ Info: iteration 4, average log likelihood -1.405933
[ Info: iteration 5, average log likelihood -1.405923
[ Info: iteration 6, average log likelihood -1.405913
[ Info: iteration 7, average log likelihood -1.405903
[ Info: iteration 8, average log likelihood -1.405893
[ Info: iteration 9, average log likelihood -1.405884
[ Info: iteration 10, average log likelihood -1.405874
┌ Info: EM with 100000 data points 10 iterations avll -1.405874
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.503043e+05
      1       6.997223e+05      -1.505820e+05 |       32
      2       6.843165e+05      -1.540577e+04 |       32
      3       6.783306e+05      -5.985919e+03 |       32
      4       6.753109e+05      -3.019689e+03 |       32
      5       6.734921e+05      -1.818839e+03 |       32
      6       6.721914e+05      -1.300647e+03 |       32
      7       6.712337e+05      -9.576641e+02 |       32
      8       6.705047e+05      -7.290713e+02 |       32
      9       6.699276e+05      -5.770822e+02 |       32
     10       6.694366e+05      -4.910179e+02 |       32
     11       6.690362e+05      -4.003476e+02 |       32
     12       6.686971e+05      -3.390808e+02 |       32
     13       6.683867e+05      -3.104431e+02 |       32
     14       6.681054e+05      -2.813475e+02 |       32
     15       6.678557e+05      -2.496492e+02 |       32
     16       6.676275e+05      -2.281862e+02 |       32
     17       6.674422e+05      -1.853366e+02 |       32
     18       6.672644e+05      -1.778219e+02 |       32
     19       6.671066e+05      -1.577462e+02 |       32
     20       6.669608e+05      -1.457864e+02 |       32
     21       6.668127e+05      -1.481259e+02 |       32
     22       6.666701e+05      -1.426096e+02 |       32
     23       6.665414e+05      -1.287387e+02 |       32
     24       6.664163e+05      -1.250422e+02 |       32
     25       6.663047e+05      -1.116289e+02 |       32
     26       6.662011e+05      -1.035419e+02 |       32
     27       6.660911e+05      -1.100370e+02 |       32
     28       6.659948e+05      -9.630738e+01 |       32
     29       6.659182e+05      -7.661553e+01 |       32
     30       6.658521e+05      -6.608894e+01 |       32
     31       6.657830e+05      -6.912390e+01 |       32
     32       6.657168e+05      -6.614953e+01 |       32
     33       6.656493e+05      -6.749707e+01 |       32
     34       6.655910e+05      -5.836804e+01 |       32
     35       6.655379e+05      -5.300664e+01 |       32
     36       6.654860e+05      -5.191966e+01 |       32
     37       6.654374e+05      -4.858202e+01 |       32
     38       6.653966e+05      -4.084175e+01 |       32
     39       6.653531e+05      -4.346353e+01 |       32
     40       6.653090e+05      -4.417643e+01 |       32
     41       6.652656e+05      -4.332880e+01 |       32
     42       6.652281e+05      -3.750959e+01 |       32
     43       6.651912e+05      -3.695959e+01 |       32
     44       6.651558e+05      -3.535378e+01 |       32
     45       6.651180e+05      -3.776645e+01 |       32
     46       6.650845e+05      -3.350634e+01 |       32
     47       6.650539e+05      -3.064901e+01 |       32
     48       6.650206e+05      -3.333544e+01 |       32
     49       6.649904e+05      -3.016133e+01 |       32
     50       6.649619e+05      -2.845667e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 664961.936146877)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417688
[ Info: iteration 2, average log likelihood -1.412648
[ Info: iteration 3, average log likelihood -1.411283
[ Info: iteration 4, average log likelihood -1.410259
[ Info: iteration 5, average log likelihood -1.409188
[ Info: iteration 6, average log likelihood -1.408207
[ Info: iteration 7, average log likelihood -1.407534
[ Info: iteration 8, average log likelihood -1.407154
[ Info: iteration 9, average log likelihood -1.406939
[ Info: iteration 10, average log likelihood -1.406797
[ Info: iteration 11, average log likelihood -1.406690
[ Info: iteration 12, average log likelihood -1.406601
[ Info: iteration 13, average log likelihood -1.406524
[ Info: iteration 14, average log likelihood -1.406456
[ Info: iteration 15, average log likelihood -1.406396
[ Info: iteration 16, average log likelihood -1.406341
[ Info: iteration 17, average log likelihood -1.406291
[ Info: iteration 18, average log likelihood -1.406246
[ Info: iteration 19, average log likelihood -1.406204
[ Info: iteration 20, average log likelihood -1.406166
[ Info: iteration 21, average log likelihood -1.406130
[ Info: iteration 22, average log likelihood -1.406097
[ Info: iteration 23, average log likelihood -1.406067
[ Info: iteration 24, average log likelihood -1.406039
[ Info: iteration 25, average log likelihood -1.406012
[ Info: iteration 26, average log likelihood -1.405987
[ Info: iteration 27, average log likelihood -1.405964
[ Info: iteration 28, average log likelihood -1.405942
[ Info: iteration 29, average log likelihood -1.405921
[ Info: iteration 30, average log likelihood -1.405901
[ Info: iteration 31, average log likelihood -1.405883
[ Info: iteration 32, average log likelihood -1.405865
[ Info: iteration 33, average log likelihood -1.405848
[ Info: iteration 34, average log likelihood -1.405831
[ Info: iteration 35, average log likelihood -1.405816
[ Info: iteration 36, average log likelihood -1.405801
[ Info: iteration 37, average log likelihood -1.405786
[ Info: iteration 38, average log likelihood -1.405773
[ Info: iteration 39, average log likelihood -1.405759
[ Info: iteration 40, average log likelihood -1.405747
[ Info: iteration 41, average log likelihood -1.405735
[ Info: iteration 42, average log likelihood -1.405723
[ Info: iteration 43, average log likelihood -1.405711
[ Info: iteration 44, average log likelihood -1.405701
[ Info: iteration 45, average log likelihood -1.405690
[ Info: iteration 46, average log likelihood -1.405680
[ Info: iteration 47, average log likelihood -1.405670
[ Info: iteration 48, average log likelihood -1.405660
[ Info: iteration 49, average log likelihood -1.405651
[ Info: iteration 50, average log likelihood -1.405642
┌ Info: EM with 100000 data points 50 iterations avll -1.405642
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.354825    0.399423   -0.0818909    0.215136      0.046685   -0.494139    0.0269223    0.465235    0.19584    -0.140763   -0.144872    0.418442    0.509118    -0.248848    0.355689    0.151915    -0.0877606   0.104067    0.180222     0.131103      0.0116753   0.0550053  -0.0868865  -0.20266     0.189936     0.493211
 -0.414422    0.0756363  -0.133311    -0.214575      0.0735179   0.0821785   0.154389     0.0529156   0.0221804   0.189971    0.145992   -0.0508335   0.00877709   0.260947   -0.22893    -0.0289762    0.121977   -0.246224   -0.202986    -0.0765188    -0.239185    0.0643406  -0.011121   -0.0197353   0.218618    -0.228435
  0.272752   -0.0535537  -0.141494     0.557617      0.468547   -0.459787    0.0772523   -0.650783   -0.0581749  -0.216576    0.0190573  -0.157899    0.503827    -0.206374    0.38149    -0.312927    -0.42787    -0.338949   -0.370492     0.339061      0.256567    0.0454831  -0.807098   -0.569745    0.815084    -0.424022
  0.0572151   0.0284646  -0.0497207   -0.362241      0.055998   -0.295587    0.0714222   -0.607969    0.352179   -0.259075    0.0210271   0.21152     0.724596    -0.0856968  -0.397775    0.0152349    0.474252   -0.0531282   0.133747    -0.321249     -0.679656    0.210368   -0.947097   -0.661637    0.0539409    0.0565989
 -0.839368    0.0175521  -0.0890234   -0.275582      0.54944    -0.170881   -0.156881    -0.415419   -0.346407   -0.117411   -0.0865802   0.262381    0.0443818    0.730648   -0.0149697  -0.167096     0.30804    -0.407603   -0.671238     0.000976285   0.0216851  -0.0782141   0.689653   -0.163687    0.586908    -0.578952
  0.275969   -0.0341972   0.238593     0.0874367    -0.172544    0.0665655  -0.0570098    0.0275926   0.262823   -0.156997    0.159273   -0.141913   -0.151508    -0.0784873   0.0179914  -0.107732     0.0145846   0.127702    0.136525     0.00190346    0.0473413   0.11992    -0.101476   -0.0108304  -0.337155     0.146074
  0.112314    0.206499   -0.135295    -0.201105      0.117241    0.137339    0.369707     0.273258   -0.874312    0.438615   -0.361829   -0.0113802   0.203398     0.392938   -0.23311     0.214408    -0.228237    0.106014    0.201641     0.274177     -0.228257   -0.12329     0.43487     0.370263   -0.0205333    0.210116
  0.290047   -0.0442912  -0.336117     0.52829      -0.679026   -0.216044    0.23963     -0.26997    -0.0816996   0.321603    0.0559416   0.402384   -0.283428    -0.479088   -0.153032    0.37061     -0.452628   -0.0691171  -0.127454    -0.0486229    -0.157203    0.511367    0.156367    0.0969045  -0.0659327    0.0294949
 -0.21559    -0.799489    0.479895    -0.239195      0.278651   -0.475351   -0.493885     0.618075    0.327503   -0.640594   -0.0540164   0.192817   -0.201217     0.570959    0.760033   -0.173035     0.325894   -0.294459    0.291145    -0.00670687    0.0161312   0.0269954   0.177139   -0.269711    0.404132     0.110863
 -0.516942   -0.263501    0.0564567   -0.306506     -0.206939    0.21061    -0.187276     0.293019    0.332648   -0.693537   -0.268389    0.193051   -0.233239    -0.0331976  -0.470757   -0.180904     0.860898    0.402112    0.11173      0.371758     -0.0354027   0.292285    0.613205    0.373488   -0.703131     0.270057
 -0.224119   -0.270833   -0.276538    -0.66645       0.495832   -0.14918     0.825421     0.0786526  -0.646425    0.371728    0.266562    0.401904    0.31967      0.026942    0.220195    0.428807    -0.322278   -0.216394   -0.0280243   -0.147677      0.206358    0.384952    0.0345031  -0.672055    0.612535     0.0158058
  0.556952   -0.331474   -0.047597    -0.0646285     0.0278921   0.381856    0.00716288  -0.858519    0.167548    0.331122   -0.598361   -0.425278   -0.653225    -0.0646632  -0.807874   -0.547688     1.02593    -0.291521    0.174697     0.290972     -0.261753   -0.037301    0.212614   -0.289198   -0.27116     -0.25243
  0.169267   -0.381654    0.00572054  -0.629791      0.0358083   1.05019     0.523743     0.546942   -0.048611    0.466407    0.215484   -0.168328   -0.0984823   -0.0587352  -0.357063    0.583086     0.314664    0.262279    0.177238     0.133297      0.115762    0.232128   -0.0485307   0.838189   -0.53233      0.0784586
  0.10535    -0.841273    0.489634    -0.000470269   0.0127769   0.413855    0.343697     0.751601   -0.312092    0.478078   -0.133067   -0.31027     0.160439    -0.190025   -0.385343   -0.0685755   -1.59451    -0.303927    0.394731     0.333002     -0.0768455  -0.133903    0.184992    0.402933    0.134898     0.24036
  0.252569   -0.142779    0.578608     0.00276098    0.140286    0.109324   -0.904108     0.20986     0.0686797  -0.105778   -0.205339   -0.269555    0.413415    -0.530919    0.274181   -0.113012    -0.18854     0.415249    0.0674213    0.242645      0.714546   -0.273893    0.275708    0.637748   -0.224968     0.61757
 -0.544023    0.215631    0.273995    -0.886513     -0.608535    0.0306809  -0.611126     0.60854     0.438576    0.618114    0.45888    -0.0203066  -0.593273     0.148159   -0.118572    0.141429    -0.0923079  -0.215737    0.232987    -0.587691     -0.564048   -0.494387    0.373733    0.713765   -0.137164    -0.0151036
  0.125645   -0.631133   -0.105694    -0.279665      0.288551    0.185806    0.299188    -0.444671    0.103348   -0.441846   -0.380837   -0.012445    0.503979     0.236404   -0.0658113   0.0698583   -0.205124    0.789022    0.080121     0.0194227     0.712365    0.0245595   0.198647   -0.0282173  -0.321734    -0.0378739
 -0.151368    0.571607   -0.470641     0.117477      0.119571    0.898955    0.334288    -0.37939    -0.133111    0.0747954   0.120656   -0.262467    0.554249    -0.449537   -0.661707   -0.293586    -0.386312    0.0621133   0.0590438    0.20575       0.497144    0.20968    -0.253657    0.0634759  -0.519698     0.286156
 -0.357758    0.189433   -0.154307    -0.054217      0.561076    0.294971   -0.0296945   -0.0141554   0.135888    0.445754   -0.445609   -0.526171   -0.0849527   -0.195096    0.35762     0.765792     0.307951   -0.531537    0.542838    -0.277546     -0.582648    0.225465    0.0926709   0.204029   -0.201377     0.129317
  0.123055   -0.403461    0.138386    -0.0460715    -0.235079   -0.391307   -0.159769    -0.0342284  -0.245643   -0.206315   -0.116064   -0.179548   -0.0492844   -0.0333769   0.243698   -0.219736    -0.090945    0.281157   -0.359074    -0.100529      0.0244494  -0.274731    0.290102    0.318936    0.451569    -0.276511
  0.527032   -0.467539    0.685803    -0.0924314    -0.0696866   0.0348603  -0.0894756   -0.637676    0.110778    0.016875    0.682789   -0.238021   -0.282877     0.280321   -0.0648087  -0.2653      -0.297967    0.765361    0.00740223  -0.00279949    0.415957    0.136581    0.266181   -0.666502   -0.121749     0.351531
 -0.0581008   0.385925    0.193411     0.111576     -0.194714   -0.545198   -0.379472    -0.104565   -0.0682212  -0.268506   -0.626005   -0.0641983   0.698616    -0.486519   -0.052662   -0.279981     0.0119289  -0.420029   -0.464834     0.0715551    -0.566448   -0.0740212   0.0533379   0.597814   -0.314686    -0.202217
  0.0198744   0.230711   -0.207146     0.317249     -0.450218    0.766556    0.165475     0.418909   -0.216999   -0.0368447   0.546139    0.0273672  -0.7053       0.460679    0.225855   -0.267836     0.160423    0.619152    0.394135    -0.108367      0.599021   -0.0467901   0.697674   -0.307197   -0.121247     0.392611
  0.812533    0.241776    0.0828959    0.00943673   -0.42598     0.105474    0.676446     0.0565566  -0.251498    0.132103    0.317676   -0.562088   -0.112665    -0.0997289   0.0718094  -0.169021    -0.729317   -0.130405    0.215759    -0.538301     -0.405003   -0.198619   -0.729724   -0.0280875  -0.0722781   -0.127196
  0.262638   -0.168441   -0.058538     0.222557      0.435505    0.0737361   0.144701    -0.178786   -0.122897   -0.163779   -0.252979   -0.160557    0.361645    -0.245763    0.0749766   0.130321    -0.0724766  -0.112145   -0.0539723   -0.0522399     0.191432   -0.0407063  -0.361442   -0.141347    0.113106    -0.00390874
  0.0545397  -0.0197554  -0.391287     0.0981236    -0.231254    0.393491    0.332498     0.210736   -0.115215    0.349232    0.429964   -0.143383   -0.961614     0.565044   -0.196638    0.192781    -0.114216   -0.467008   -0.373242    -0.0906844    -0.332043   -0.160943   -0.117922    0.0378564   0.00923398  -0.57254
  0.20964     0.086212   -0.167155     0.414293     -0.456703   -0.0969897  -0.638792    -0.103291    0.814887   -0.549734    0.0339534  -0.419625   -0.203331    -0.631239    0.209687   -0.186884     0.36954    -0.0464329  -0.241088    -0.361064      0.256487    0.222709   -0.456293    0.297037    0.17427     -0.0135117
  0.0173476   0.136935   -0.055597     0.0510698    -0.0876773  -0.204888    0.243757     0.187549   -0.105052   -0.040181   -0.138104    0.232083    0.259492    -0.168887    0.0970165   0.114083    -0.117862   -0.130834    0.0717559   -0.0357327    -0.263974    0.0355336  -0.181417   -0.0294521   0.0773808    0.0154518
 -0.329731   -0.197843   -0.203251    -0.164579      0.0168556   0.0622499  -0.475204    -0.199222   -0.261188   -0.281419    0.158618    0.869005    0.203791    -0.0756965  -0.207037    0.00476385   0.29186     0.12127    -0.0177349    0.485688      0.228128    0.0929127   0.368075   -0.266885    0.0434312   -0.125171
 -0.132846   -0.341042   -0.169966    -0.306979      0.196968    0.0792121   0.293409     0.844574   -0.0723988  -0.774744   -0.483992    0.41375     0.141243     0.208858    0.136243   -0.0599848    0.301752   -0.194364    0.475903    -0.00103849   -0.191237   -0.273161   -0.795895    0.0689467  -0.0357857   -0.284424
 -0.235213   -0.0625794   0.337265     0.121989     -0.0848019   0.372192   -0.209865    -0.397354    0.357412    0.894416    0.903469   -0.81668    -0.180485    -0.199168   -0.129747    0.37319     -0.350739   -0.318839   -0.500102    -0.283131      0.234698    0.384889    0.0360237  -0.0704655   0.285611    -0.0683799
 -0.179663    0.189119    0.165137     0.648338      0.0838024  -0.319971   -0.33409      0.260381    0.492691    0.0562939  -0.0862735  -0.226008   -0.399038     0.334346    0.238094   -0.0830789    0.570344    0.23651    -0.379619     0.884746      0.0645952  -0.213524    0.692644    0.550962    0.0715656   -0.101153[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405633
[ Info: iteration 2, average log likelihood -1.405625
[ Info: iteration 3, average log likelihood -1.405617
[ Info: iteration 4, average log likelihood -1.405609
[ Info: iteration 5, average log likelihood -1.405601
[ Info: iteration 6, average log likelihood -1.405594
[ Info: iteration 7, average log likelihood -1.405587
[ Info: iteration 8, average log likelihood -1.405579
[ Info: iteration 9, average log likelihood -1.405573
[ Info: iteration 10, average log likelihood -1.405566
┌ Info: EM with 100000 data points 10 iterations avll -1.405566
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
