Julia Version 1.5.0-DEV.204
Commit 529b3655ad (2020-01-30 07:59 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed GaussianMixtures ─── v0.3.0
  Installed CMake ────────────── v1.1.2
  Installed ScikitLearnBase ──── v0.5.0
  Installed Blosc ────────────── v0.5.1
  Installed OrderedCollections ─ v1.1.0
  Installed NearestNeighbors ─── v0.4.4
  Installed Clustering ───────── v0.13.3
  Installed Compat ───────────── v2.2.0
  Installed Distances ────────── v0.8.2
  Installed BinDeps ──────────── v1.0.0
  Installed BinaryProvider ───── v0.5.8
  Installed QuadGK ───────────── v2.3.1
  Installed Parameters ───────── v0.12.0
  Installed Distributions ────── v0.22.4
  Installed JLD ──────────────── v0.9.2
  Installed Rmath ────────────── v0.6.0
  Installed Arpack ───────────── v0.4.0
  Installed PDMats ───────────── v0.9.11
  Installed CMakeWrapper ─────── v0.2.3
  Installed URIParser ────────── v0.4.0
  Installed DataAPI ──────────── v1.1.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed HDF5 ─────────────── v0.12.5
  Installed SpecialFunctions ─── v0.9.0
  Installed StatsBase ────────── v0.32.0
  Installed Missings ─────────── v0.4.3
  Installed SortingAlgorithms ── v0.3.1
  Installed Arpack_jll ───────── v3.5.0+2
  Installed FillArrays ───────── v0.8.4
  Installed FileIO ───────────── v1.2.1
  Installed StatsFuns ────────── v0.9.3
  Installed DataStructures ───── v0.17.9
  Installed StaticArrays ─────── v0.12.1
  Installed LegacyStrings ────── v0.4.1
#=#=#                                                                         ##O#- #                                                                       ##O=#  #                                                                      #                                                                          2.1%####                                                                       6.4%########                                                                  12.1%#############                                                             19.4%####################                                                      27.8%#######################                                                   32.4%################################                                          45.7%###########################################                               60.8%##########################################################                81.3%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_1OaDXo/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -2.7484775632490363e7, [372.52916580015756, 99627.47083419983], [-166.03909377210826 389.11890402987774 -159.99921682258187; 628.3579725942928 -618.5224873243378 103.00052146835911], [[398.3569489173062 -127.51627518559643 58.68848954035865; -127.51627518559643 423.49363889987063 -110.05404731174892; 58.68848954035865 -110.0540473117489 398.17837548802885], [98639.6787831397 -38.63181963167109 -323.1219916609294; -38.63181963167109 99551.03145936655 275.7855167817095; -323.1219916609294 275.7855167817095 99475.60144773123]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.619426e+03
      1       9.622174e+02      -6.572090e+02 |        5
      2       9.177704e+02      -4.444701e+01 |        2
      3       9.033185e+02      -1.445185e+01 |        0
      4       9.033185e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 903.3185003274966)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.070183
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.743252
[ Info: iteration 2, lowerbound -3.590524
[ Info: iteration 3, lowerbound -3.435437
[ Info: iteration 4, lowerbound -3.269824
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.099120
[ Info: iteration 6, lowerbound -2.940575
[ Info: iteration 7, lowerbound -2.823405
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.752170
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.688347
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.622355
[ Info: iteration 11, lowerbound -2.552596
[ Info: iteration 12, lowerbound -2.484286
[ Info: iteration 13, lowerbound -2.424380
[ Info: iteration 14, lowerbound -2.377720
[ Info: iteration 15, lowerbound -2.343072
[ Info: iteration 16, lowerbound -2.319142
[ Info: iteration 17, lowerbound -2.307979
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.303054
[ Info: iteration 19, lowerbound -2.299263
[ Info: iteration 20, lowerbound -2.299258
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan 31 21:25:35 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan 31 21:25:42 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Fri Jan 31 21:25:45 2020: EM with 272 data points 0 iterations avll -2.070183
5.8 data points per parameter
, Fri Jan 31 21:25:47 2020: GMM converted to Variational GMM
, Fri Jan 31 21:25:55 2020: iteration 1, lowerbound -3.743252
, Fri Jan 31 21:25:55 2020: iteration 2, lowerbound -3.590524
, Fri Jan 31 21:25:55 2020: iteration 3, lowerbound -3.435437
, Fri Jan 31 21:25:55 2020: iteration 4, lowerbound -3.269824
, Fri Jan 31 21:25:55 2020: dropping number of Gaussions to 7
, Fri Jan 31 21:25:55 2020: iteration 5, lowerbound -3.099120
, Fri Jan 31 21:25:55 2020: iteration 6, lowerbound -2.940575
, Fri Jan 31 21:25:55 2020: iteration 7, lowerbound -2.823405
, Fri Jan 31 21:25:55 2020: dropping number of Gaussions to 6
, Fri Jan 31 21:25:55 2020: iteration 8, lowerbound -2.752170
, Fri Jan 31 21:25:55 2020: dropping number of Gaussions to 4
, Fri Jan 31 21:25:55 2020: iteration 9, lowerbound -2.688347
, Fri Jan 31 21:25:55 2020: dropping number of Gaussions to 3
, Fri Jan 31 21:25:55 2020: iteration 10, lowerbound -2.622355
, Fri Jan 31 21:25:55 2020: iteration 11, lowerbound -2.552596
, Fri Jan 31 21:25:55 2020: iteration 12, lowerbound -2.484286
, Fri Jan 31 21:25:55 2020: iteration 13, lowerbound -2.424380
, Fri Jan 31 21:25:55 2020: iteration 14, lowerbound -2.377720
, Fri Jan 31 21:25:55 2020: iteration 15, lowerbound -2.343072
, Fri Jan 31 21:25:55 2020: iteration 16, lowerbound -2.319142
, Fri Jan 31 21:25:55 2020: iteration 17, lowerbound -2.307979
, Fri Jan 31 21:25:55 2020: dropping number of Gaussions to 2
, Fri Jan 31 21:25:55 2020: iteration 18, lowerbound -2.303054
, Fri Jan 31 21:25:55 2020: iteration 19, lowerbound -2.299263
, Fri Jan 31 21:25:55 2020: iteration 20, lowerbound -2.299258
, Fri Jan 31 21:25:55 2020: iteration 21, lowerbound -2.299255
, Fri Jan 31 21:25:55 2020: iteration 22, lowerbound -2.299254
, Fri Jan 31 21:25:55 2020: iteration 23, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 24, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 25, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 26, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 27, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 28, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 29, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 30, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 31, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 32, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 33, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 34, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 35, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 36, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 37, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 38, lowerbound -2.299253
, Fri Jan 31 21:25:55 2020: iteration 39, lowerbound -2.299253
, Fri Jan 31 21:25:56 2020: iteration 40, lowerbound -2.299253
, Fri Jan 31 21:25:56 2020: iteration 41, lowerbound -2.299253
, Fri Jan 31 21:25:56 2020: iteration 42, lowerbound -2.299253
, Fri Jan 31 21:25:56 2020: iteration 43, lowerbound -2.299253
, Fri Jan 31 21:25:56 2020: iteration 44, lowerbound -2.299253
, Fri Jan 31 21:25:56 2020: iteration 45, lowerbound -2.299253
, Fri Jan 31 21:25:56 2020: iteration 46, lowerbound -2.299253
, Fri Jan 31 21:25:56 2020: iteration 47, lowerbound -2.299253
, Fri Jan 31 21:25:56 2020: iteration 48, lowerbound -2.299253
, Fri Jan 31 21:25:56 2020: iteration 49, lowerbound -2.299253
, Fri Jan 31 21:25:56 2020: iteration 50, lowerbound -2.299253
, Fri Jan 31 21:25:56 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260139, 95.95490777398612]
β = [178.0450922260139, 95.95490777398612]
m = [4.250300733269909 79.28686694436182; 2.00022925777537 53.85198717246129]
ν = [180.0450922260139, 97.95490777398612]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.184041555474848 -0.007644049042327603; 0.0 0.00858170516633346], [0.3758763611948411 -0.008953123827346032; 0.0 0.01274866477740943]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9825023081756853
avll from llpg:  -0.9825023081756851
avll direct:     -0.9825023081756853
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9711670320040561
avll from llpg:  -0.9711670320040561
avll direct:     -0.971167032004056
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.119034     0.0415785   -0.0825297  -0.0434206   -0.0838366    0.00666572   -0.190825     0.0953049   -0.194999    -0.0259201   -0.0305695   -0.154963    -0.0369153    0.0439394    0.0625446   -0.00405965  -0.10296      0.177949      0.226084     0.0979384    0.0812334   -0.0830954    0.068272     0.243646    -0.0951882    0.150529
 -0.0513953    0.235777     0.200007   -0.0867055   -0.107427    -0.172382      0.059366     0.128574    -0.0631871   -0.085335    -0.0879241    0.0811891    0.0289856   -0.0033845   -0.0881835    0.105668     0.0946335    0.124879     -0.177302     0.145182    -0.0464399   -0.108775     0.125803     0.0111506   -0.00867369   0.22061
  0.0884736    0.0608982   -0.072021   -0.275599     0.0861865    0.178279      0.260232     0.00982984   0.0304569   -0.00012524  -0.0768398   -0.00831234  -0.0332323   -0.0116733    0.0505869    0.054839    -0.120187     0.109878      0.0132915   -0.00316304  -0.00391731  -0.158209     0.114436    -0.0448203    0.0218253    0.172819
  0.0248635   -0.119345    -0.0721543  -0.0533117    0.102563    -0.198821      0.00852093   0.0734622   -0.0621346   -0.0206784    0.0698989   -0.0364791   -3.73853e-5   0.0323999   -0.0858085    0.022821     0.0973022   -0.0432883    -0.0119284   -0.0335632    0.019554     0.0556225    0.0394818   -0.0655452    0.100837     0.129678
 -0.0392486   -0.083323    -0.0349518   0.0085337   -0.042853     0.0386276    -0.00956573  -0.0195335    0.0774303    0.05048     -0.0656599    0.0990377    0.156555     0.192259     0.0126878   -0.0997501    0.125618     0.0297713    -0.0539385   -0.0804847    0.0240742    0.0252212    0.144014    -0.0356804   -0.187635     0.184732
 -0.110413     0.0358454   -0.0494408   0.0845233   -0.0897056    0.052911     -0.0985418    0.0803039   -0.119335     0.031872     0.0506363    0.0228625    0.0662575    0.100713     0.190915    -0.0361845   -0.0762702    0.0527851     0.00885001  -0.0213477    0.0484045   -0.0133646    0.0598138   -0.112353    -0.0981451    0.0848759
 -0.00363269   0.0419317    0.0882378   0.113167    -0.103073    -0.0111756     0.0152801    0.0881587   -0.184722    -0.0133911    0.0102973    0.048415    -0.113533     0.0844703   -0.121105    -0.0122556   -0.0524954    0.0440271     0.00562466   0.164656    -0.107188     0.0326272   -0.00647746  -0.0840785    0.105098     0.0087797
 -0.236068     0.0798442   -0.0956508  -0.153575    -0.166529     0.171815     -0.0923702   -0.00522078   0.0276476    0.0152855    0.0127228    0.0588003   -0.0639503   -0.11413     -0.0958004    0.00951079  -0.00621815   0.0157391     0.174207     0.127567     0.137276    -0.0279585   -0.0777187    0.170889    -0.122555    -0.127556
  0.133926     0.0359127   -0.0758887  -0.146024    -0.00935124   0.0733877    -0.111411     0.0666638   -0.154716    -0.0296474   -0.0333467   -0.0413199   -0.0957775    0.0771312   -0.134178    -0.0405377   -0.070293    -0.127592      0.00421388  -0.107327    -0.0279673   -0.0324554   -0.0332109   -0.00920359   0.083719    -0.174933
 -0.0799587    0.131271     0.107399    0.0380376    0.105149    -0.026782     -0.00566619   0.0464356    0.0497663    0.104489    -0.0733204    0.214966     0.178698     0.0515984   -0.151766     0.144367    -0.0745941    0.0497253    -0.0371257    0.118567    -0.151182     0.0309372   -0.0481928    0.00196639  -0.0629392    0.103261
 -0.119488    -0.0336728   -0.0368963   0.0199078    0.0186535   -0.0574829     0.0443274   -0.0473418    0.0213321   -0.167436    -0.111608     0.0622814   -0.11962      0.0603668    0.0106446    0.0130505    0.0404481    0.0909291     0.0691736   -0.00554406  -0.0189203   -0.0871803   -0.0301291    0.047499    -0.0230887   -0.164487
 -0.0705738    0.0419581    0.189368   -0.0923487    0.00432861   0.0157416    -0.0389936    0.0352235   -0.0616542   -0.102933    -0.119287     0.146779     0.0394133   -0.0534271   -0.0447467    0.119657    -0.089405     0.0387952     0.0461537   -0.0889387   -0.186413    -0.241055     0.0547152    0.0980716   -0.214213    -0.148234
  0.0938523   -0.0111707   -0.0151431   0.0927249    0.132105    -0.0286165     0.00715853  -0.0621404   -0.00579413   0.122172    -0.0846645    0.0265706    0.157398     0.0442009    0.101675    -0.0449746    0.00204126   0.0423526     0.0517509   -0.0248694   -0.0109983   -0.099295     0.00902825   0.104677     0.0318197    0.138905
 -0.107513     0.170609    -0.0216533  -0.0715297   -0.101949    -0.051287      0.00378141   0.0387693    0.0153098   -0.0142479   -0.118144     0.191832    -0.0137967   -0.0624747   -0.105501     0.0190081    0.079395     0.220229      0.035339    -0.155145    -0.0903571   -0.122245     0.0399982   -0.0230744    0.191529    -0.172721
  0.00707068  -0.0900412   -0.145163   -0.0442387    0.0928191    0.165726     -0.0846093   -0.0687806   -0.011755     0.0384164    0.0528551   -0.105326     0.16318     -0.00742589   0.161843    -0.120461    -0.105235    -0.010416     -0.0636594    0.17375      0.0281222   -0.130964     0.0180686   -0.163317    -0.00408842  -0.0629854
 -0.0568873   -0.00313948  -0.176961   -0.00215355  -0.0512879    0.0838663    -0.149151    -0.0782263    0.0417706   -0.0746701   -0.0941165   -0.0561203    0.136318     0.0601234    0.183438     0.0548249    0.0377199   -0.000689253  -0.0872823   -0.118556     0.00439033   0.15877     -0.106525     0.0621549    0.0677483    0.148996
 -0.184665    -0.00925684  -0.0594672   0.100378    -0.0136334   -0.138544     -0.0960607    0.0384731    0.085686    -0.138385     0.0658662   -0.164226    -0.0342001   -0.0914599    0.100889     0.268852    -0.0408073    0.18737       0.00720959   0.210099     0.0452885    0.170617     0.198339     0.110208     0.0272107    0.0461514
  0.00254388   0.0638514   -0.152189   -0.0954602    0.120012    -0.000454119   0.121239     0.0734112    0.0419985   -0.0787807   -0.0176091   -0.195023     0.0171983    0.0985523   -0.0812916    0.0539622    0.100192    -0.164526     -0.123683     0.0509971   -0.0842039   -0.0688231    0.0432517   -0.0480448    0.0383517   -0.232719
  0.0413596   -0.0865652   -0.13643    -0.0544722   -0.00740302  -0.166357      0.138582    -0.196814    -0.105649    -0.0609465    0.00467402   0.18156      0.170799    -0.14475     -0.0956801    0.0339346    0.0906041    0.236071     -0.131561    -0.0530698    0.0334259   -0.12202      0.0234412    0.054302    -0.00520117   0.10056
 -0.00808616   0.0002338   -0.146989    0.0678801    0.130564    -0.172245     -0.0697721    0.0119692   -0.0513578    0.153746     0.0360305    0.0109395   -0.0425236   -0.0623468   -0.0262234    0.0179961    0.0416693   -0.154684     -0.100521     0.170063    -0.205908    -0.0560767    0.161292    -0.0506074    0.0654882    0.198557
  0.0386992   -0.107472     0.0405662  -0.083264     0.0934023   -0.0927494     0.0537845    0.118886    -0.105611    -0.0209478   -0.0430908   -0.218383    -0.042149     0.0479609    0.128119    -0.0216843    0.00400972  -0.108595     -0.0178415    0.124468     0.0777814    0.0691902   -0.0106921    0.132235    -0.185008     0.152118
 -0.214108     0.1815       0.0620183  -0.0226882    0.0717219   -0.120774     -0.140841    -0.158918    -0.112477     0.142286    -0.0348452   -0.0255373   -0.0933565   -0.0394288    0.0709244    0.0393206    0.123156     0.204741     -0.171721     0.0643478    0.115711     0.076821    -0.0322191   -0.0657061    0.0785168   -0.00628335
  0.00166267  -0.0372544    0.253684    0.201333    -0.0871191    0.0740916     0.106073    -0.00751363   0.0553002   -0.00622741  -0.0201519    0.156416    -0.0127451    0.0248379   -0.0583821   -0.113945    -0.00749679  -0.195263     -0.084859     0.0560269    0.0286198    0.105278     0.075434     0.0250943    0.0957303   -0.160662
 -0.0477524    0.0375659   -0.0915261  -0.115733     0.0895636    0.0531068     0.041489     0.0285374   -0.136496    -0.0325308    0.0990891   -0.002398    -0.144342     0.0768794    0.0525878   -0.23861      0.0600705    0.0818369    -0.00364622  -0.226462     0.0819046   -0.00221388  -0.0415246   -0.0138218   -0.0775234    0.0394328
 -0.0192435    0.0306479    0.0731796   0.062539     0.100456     0.0551052    -0.0305251    0.0761492    0.0206894   -0.143216    -0.151914     0.00889432  -0.15259     -0.0715239    0.0897385   -0.192422    -0.12798      0.114904     -0.0175418   -0.0753004   -0.113296     0.146844     0.0314298    0.00622979   0.0355416    0.0211068
  0.123598     0.0500349   -0.0326964   0.0170034    0.179004    -0.00489709    0.0629078    0.0901378    0.0915052   -0.124684     0.193589    -0.0387649    0.0367894   -0.0759763   -0.0971179    0.0465175   -0.0766691   -0.00478192    0.0330336    0.191725    -0.065421    -0.212786    -0.137173    -0.133936     0.0810079    0.0942653
 -0.144995     0.110787    -0.0828022  -0.103148     0.0998098    0.0179689     0.0423628    0.0156329    0.051621     0.0926997   -0.0279124    0.0803672   -0.0185583    0.253839    -0.0365778    0.0885302   -0.040952     0.044847     -0.0785608    0.0549478   -0.161549     0.0731657   -0.0198739    0.0824751   -0.0539256    0.0813148
 -0.0145199   -0.199653    -0.0595628   0.022408    -0.0818728    0.0532567    -0.132992     0.154869    -0.0783459   -0.0557948    0.0100927   -0.153974     0.0576369    0.129993     0.0492364    0.114102     0.0287509    0.023796     -0.0422267   -0.0418069   -0.0676675    0.00999388   0.136729     0.0293032   -0.098609    -0.157746
  0.00594137   0.0330232   -0.172562    0.0266566    0.0114886   -0.00632695   -0.00202352   0.0354573   -0.0519764   -0.0784684    0.0496206    0.0487714   -0.0157133    0.0658435   -0.00772369  -0.253859    -0.0842049    0.130561     -0.0681503   -0.0347536    0.032476    -0.0498966   -0.0425227    0.0938971   -0.0148821   -0.0721853
 -0.0130454   -0.0454103   -0.0606267  -0.0507118    0.176502    -0.105058     -0.00853444   0.162121    -0.068212    -0.100541     0.19935     -0.0582781    0.16129     -0.00332995  -0.0383355   -0.146361    -0.122396    -0.0630358    -0.130917    -0.0188038    0.0835617   -0.152816    -0.156473     0.0161651    0.0869127   -0.0386191
  0.0894155    0.0353135    0.0138228  -0.0399939   -0.127384     0.0842916    -0.0323214   -0.0828403    0.0521962   -0.021474    -0.182836     0.0073973    0.0886015   -0.0583042    0.0727024    0.0359963    0.0413665    0.0327414    -0.153925     0.0633751   -0.0411698    0.0613689    0.0209295    0.143807    -0.0581535    0.0457628
 -0.21234      0.110947    -0.0440748   0.0510526   -0.0214316   -0.10101      -0.142546     0.124718    -0.0349631   -0.0330648    0.136725     0.205242    -0.0217376    0.0164627   -0.141596     0.00979078  -0.0545684    0.0109296     0.0558547    0.0123443   -0.140768    -0.0630654   -0.130663    -0.0464934    0.0827775   -0.200428kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3927498317371223
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.392872
[ Info: iteration 2, average log likelihood -1.392754
[ Info: iteration 3, average log likelihood -1.391733
[ Info: iteration 4, average log likelihood -1.382195
[ Info: iteration 5, average log likelihood -1.365716
[ Info: iteration 6, average log likelihood -1.359144
[ Info: iteration 7, average log likelihood -1.355691
[ Info: iteration 8, average log likelihood -1.352831
[ Info: iteration 9, average log likelihood -1.350629
[ Info: iteration 10, average log likelihood -1.349212
[ Info: iteration 11, average log likelihood -1.348324
[ Info: iteration 12, average log likelihood -1.347897
[ Info: iteration 13, average log likelihood -1.347679
[ Info: iteration 14, average log likelihood -1.347539
[ Info: iteration 15, average log likelihood -1.347435
[ Info: iteration 16, average log likelihood -1.347347
[ Info: iteration 17, average log likelihood -1.347265
[ Info: iteration 18, average log likelihood -1.347185
[ Info: iteration 19, average log likelihood -1.347097
[ Info: iteration 20, average log likelihood -1.346958
[ Info: iteration 21, average log likelihood -1.346704
[ Info: iteration 22, average log likelihood -1.346384
[ Info: iteration 23, average log likelihood -1.346149
[ Info: iteration 24, average log likelihood -1.346029
[ Info: iteration 25, average log likelihood -1.345974
[ Info: iteration 26, average log likelihood -1.345948
[ Info: iteration 27, average log likelihood -1.345934
[ Info: iteration 28, average log likelihood -1.345926
[ Info: iteration 29, average log likelihood -1.345921
[ Info: iteration 30, average log likelihood -1.345918
[ Info: iteration 31, average log likelihood -1.345917
[ Info: iteration 32, average log likelihood -1.345916
[ Info: iteration 33, average log likelihood -1.345915
[ Info: iteration 34, average log likelihood -1.345914
[ Info: iteration 35, average log likelihood -1.345914
[ Info: iteration 36, average log likelihood -1.345914
[ Info: iteration 37, average log likelihood -1.345914
[ Info: iteration 38, average log likelihood -1.345913
[ Info: iteration 39, average log likelihood -1.345913
[ Info: iteration 40, average log likelihood -1.345913
[ Info: iteration 41, average log likelihood -1.345913
[ Info: iteration 42, average log likelihood -1.345913
[ Info: iteration 43, average log likelihood -1.345913
[ Info: iteration 44, average log likelihood -1.345913
[ Info: iteration 45, average log likelihood -1.345913
[ Info: iteration 46, average log likelihood -1.345913
[ Info: iteration 47, average log likelihood -1.345913
[ Info: iteration 48, average log likelihood -1.345913
[ Info: iteration 49, average log likelihood -1.345913
[ Info: iteration 50, average log likelihood -1.345913
┌ Info: EM with 100000 data points 50 iterations avll -1.345913
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.392872210248808
│     -1.392754488919352
│      ⋮
└     -1.345913216502162
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.346090
[ Info: iteration 2, average log likelihood -1.345920
[ Info: iteration 3, average log likelihood -1.344928
[ Info: iteration 4, average log likelihood -1.333568
[ Info: iteration 5, average log likelihood -1.307565
[ Info: iteration 6, average log likelihood -1.298850
[ Info: iteration 7, average log likelihood -1.297298
[ Info: iteration 8, average log likelihood -1.296674
[ Info: iteration 9, average log likelihood -1.296289
[ Info: iteration 10, average log likelihood -1.296017
[ Info: iteration 11, average log likelihood -1.295817
[ Info: iteration 12, average log likelihood -1.295674
[ Info: iteration 13, average log likelihood -1.295567
[ Info: iteration 14, average log likelihood -1.295487
[ Info: iteration 15, average log likelihood -1.295426
[ Info: iteration 16, average log likelihood -1.295379
[ Info: iteration 17, average log likelihood -1.295341
[ Info: iteration 18, average log likelihood -1.295310
[ Info: iteration 19, average log likelihood -1.295284
[ Info: iteration 20, average log likelihood -1.295261
[ Info: iteration 21, average log likelihood -1.295241
[ Info: iteration 22, average log likelihood -1.295225
[ Info: iteration 23, average log likelihood -1.295211
[ Info: iteration 24, average log likelihood -1.295198
[ Info: iteration 25, average log likelihood -1.295186
[ Info: iteration 26, average log likelihood -1.295173
[ Info: iteration 27, average log likelihood -1.295160
[ Info: iteration 28, average log likelihood -1.295147
[ Info: iteration 29, average log likelihood -1.295135
[ Info: iteration 30, average log likelihood -1.295123
[ Info: iteration 31, average log likelihood -1.295112
[ Info: iteration 32, average log likelihood -1.295101
[ Info: iteration 33, average log likelihood -1.295092
[ Info: iteration 34, average log likelihood -1.295083
[ Info: iteration 35, average log likelihood -1.295075
[ Info: iteration 36, average log likelihood -1.295069
[ Info: iteration 37, average log likelihood -1.295063
[ Info: iteration 38, average log likelihood -1.295058
[ Info: iteration 39, average log likelihood -1.295054
[ Info: iteration 40, average log likelihood -1.295050
[ Info: iteration 41, average log likelihood -1.295047
[ Info: iteration 42, average log likelihood -1.295045
[ Info: iteration 43, average log likelihood -1.295043
[ Info: iteration 44, average log likelihood -1.295042
[ Info: iteration 45, average log likelihood -1.295041
[ Info: iteration 46, average log likelihood -1.295040
[ Info: iteration 47, average log likelihood -1.295040
[ Info: iteration 48, average log likelihood -1.295039
[ Info: iteration 49, average log likelihood -1.295039
[ Info: iteration 50, average log likelihood -1.295039
┌ Info: EM with 100000 data points 50 iterations avll -1.295039
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3460904852370856
│     -1.345920216340691
│      ⋮
└     -1.2950387190241448
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.295279
[ Info: iteration 2, average log likelihood -1.295054
[ Info: iteration 3, average log likelihood -1.294365
[ Info: iteration 4, average log likelihood -1.288693
[ Info: iteration 5, average log likelihood -1.272375
[ Info: iteration 6, average log likelihood -1.258314
[ Info: iteration 7, average log likelihood -1.252809
[ Info: iteration 8, average log likelihood -1.250323
[ Info: iteration 9, average log likelihood -1.248233
[ Info: iteration 10, average log likelihood -1.245287
[ Info: iteration 11, average log likelihood -1.241855
[ Info: iteration 12, average log likelihood -1.239537
[ Info: iteration 13, average log likelihood -1.237869
[ Info: iteration 14, average log likelihood -1.236396
[ Info: iteration 15, average log likelihood -1.235076
[ Info: iteration 16, average log likelihood -1.233714
[ Info: iteration 17, average log likelihood -1.232147
[ Info: iteration 18, average log likelihood -1.230986
[ Info: iteration 19, average log likelihood -1.230295
[ Info: iteration 20, average log likelihood -1.229870
[ Info: iteration 21, average log likelihood -1.229607
[ Info: iteration 22, average log likelihood -1.229453
[ Info: iteration 23, average log likelihood -1.229366
[ Info: iteration 24, average log likelihood -1.229316
[ Info: iteration 25, average log likelihood -1.229288
[ Info: iteration 26, average log likelihood -1.229272
[ Info: iteration 27, average log likelihood -1.229262
[ Info: iteration 28, average log likelihood -1.229256
[ Info: iteration 29, average log likelihood -1.229251
[ Info: iteration 30, average log likelihood -1.229248
[ Info: iteration 31, average log likelihood -1.229245
[ Info: iteration 32, average log likelihood -1.229242
[ Info: iteration 33, average log likelihood -1.229239
[ Info: iteration 34, average log likelihood -1.229237
[ Info: iteration 35, average log likelihood -1.229235
[ Info: iteration 36, average log likelihood -1.229233
[ Info: iteration 37, average log likelihood -1.229231
[ Info: iteration 38, average log likelihood -1.229229
[ Info: iteration 39, average log likelihood -1.229227
[ Info: iteration 40, average log likelihood -1.229225
[ Info: iteration 41, average log likelihood -1.229223
[ Info: iteration 42, average log likelihood -1.229221
[ Info: iteration 43, average log likelihood -1.229218
[ Info: iteration 44, average log likelihood -1.229216
[ Info: iteration 45, average log likelihood -1.229213
[ Info: iteration 46, average log likelihood -1.229210
[ Info: iteration 47, average log likelihood -1.229207
[ Info: iteration 48, average log likelihood -1.229203
[ Info: iteration 49, average log likelihood -1.229199
[ Info: iteration 50, average log likelihood -1.229194
┌ Info: EM with 100000 data points 50 iterations avll -1.229194
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.295279109130061
│     -1.2950543155194716
│      ⋮
└     -1.229193840992282
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.229495
[ Info: iteration 2, average log likelihood -1.229139
[ Info: iteration 3, average log likelihood -1.227585
[ Info: iteration 4, average log likelihood -1.213767
[ Info: iteration 5, average log likelihood -1.182002
[ Info: iteration 6, average log likelihood -1.155977
[ Info: iteration 7, average log likelihood -1.145959
[ Info: iteration 8, average log likelihood -1.141452
[ Info: iteration 9, average log likelihood -1.139109
[ Info: iteration 10, average log likelihood -1.137808
[ Info: iteration 11, average log likelihood -1.136678
[ Info: iteration 12, average log likelihood -1.135554
[ Info: iteration 13, average log likelihood -1.134599
[ Info: iteration 14, average log likelihood -1.134058
[ Info: iteration 15, average log likelihood -1.133830
[ Info: iteration 16, average log likelihood -1.133713
[ Info: iteration 17, average log likelihood -1.133590
[ Info: iteration 18, average log likelihood -1.133344
[ Info: iteration 19, average log likelihood -1.132699
[ Info: iteration 20, average log likelihood -1.131220
[ Info: iteration 21, average log likelihood -1.129353
[ Info: iteration 22, average log likelihood -1.128273
[ Info: iteration 23, average log likelihood -1.128089
[ Info: iteration 24, average log likelihood -1.128075
[ Info: iteration 25, average log likelihood -1.128067
[ Info: iteration 26, average log likelihood -1.128061
[ Info: iteration 27, average log likelihood -1.128057
[ Info: iteration 28, average log likelihood -1.128053
[ Info: iteration 29, average log likelihood -1.128050
[ Info: iteration 30, average log likelihood -1.128048
[ Info: iteration 31, average log likelihood -1.128046
[ Info: iteration 32, average log likelihood -1.128045
[ Info: iteration 33, average log likelihood -1.128043
[ Info: iteration 34, average log likelihood -1.128043
[ Info: iteration 35, average log likelihood -1.128042
[ Info: iteration 36, average log likelihood -1.128041
[ Info: iteration 37, average log likelihood -1.128041
[ Info: iteration 38, average log likelihood -1.128040
[ Info: iteration 39, average log likelihood -1.128040
[ Info: iteration 40, average log likelihood -1.128040
[ Info: iteration 41, average log likelihood -1.128040
[ Info: iteration 42, average log likelihood -1.128039
[ Info: iteration 43, average log likelihood -1.128039
[ Info: iteration 44, average log likelihood -1.128039
[ Info: iteration 45, average log likelihood -1.128039
[ Info: iteration 46, average log likelihood -1.128039
[ Info: iteration 47, average log likelihood -1.128039
[ Info: iteration 48, average log likelihood -1.128039
[ Info: iteration 49, average log likelihood -1.128039
[ Info: iteration 50, average log likelihood -1.128039
┌ Info: EM with 100000 data points 50 iterations avll -1.128039
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2294950971790124
│     -1.2291394021161801
│      ⋮
└     -1.1280389059134976
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.128393
[ Info: iteration 2, average log likelihood -1.127958
[ Info: iteration 3, average log likelihood -1.126139
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.103520
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     16
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.055924
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.042426
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│     21
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.018533
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.041307
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     16
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.027345
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.030749
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     16
│     21
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.019722
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.033347
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│      ⋮
│     24
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.010103
[ Info: iteration 14, average log likelihood -1.047157
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     16
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.014269
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.018442
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     16
│     21
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.021572
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.040168
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│     21
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.009315
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.043921
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     16
│     21
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.010768
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.028743
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     16
│     21
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.029183
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.034696
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│      ⋮
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -0.999310
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.049161
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     16
│     21
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.020750
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.023593
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     16
│     21
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.019362
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.039871
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│     21
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.009511
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.039603
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     16
│     21
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.012987
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.029053
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     16
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.029539
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.030352
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│      ⋮
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.001092
[ Info: iteration 38, average log likelihood -1.048546
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     16
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.014357
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.019691
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     16
│     21
│     23
│     24
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.015722
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.041106
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│     21
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.009357
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.040463
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     16
│     21
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.009043
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.027003
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     16
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.030861
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.031561
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│      ⋮
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -0.997912
[ Info: iteration 50, average log likelihood -1.048095
┌ Info: EM with 100000 data points 50 iterations avll -1.048095
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1283934186023736
│     -1.1279577820008606
│      ⋮
└     -1.0480954994968361
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3927498317371223
│     -1.392872210248808
│     -1.392754488919352
│     -1.3917330337001659
│      ⋮
│     -1.0315607831963018
│     -0.9979120557621333
└     -1.0480954994968361
32×26 Array{Float64,2}:
 -0.0350366   -0.205107    -0.0329503    0.0346724  -0.0961934    0.0738765   -0.14151      0.163139    -0.143302    -0.0653571   -0.0538364  -0.202415     0.110757      0.122559     0.0609084    0.0996495   -0.0281316     0.0433716   -0.0670409   -0.0894391   -0.139832    -0.00399089    0.166183    -0.138706     -0.53653      -0.176463
  0.0105437   -0.192731    -0.0682154    0.0100042  -0.0559638    0.0278847   -0.151163     0.128427     0.0336352   -0.0192928    0.0522506  -0.143428    -0.0770273     0.0684744    0.0252403    0.137684     0.0990102    -0.0145741   -0.0310537    0.0309339   -0.013616     0.0258004     0.147354     0.329135      0.433211     -0.0742441
 -0.0220409    0.0323512    0.0707012    0.0782354   0.102565     0.0549609   -0.00856662   0.0725812    0.00892119  -0.167709    -0.160918    0.0267194   -0.145922     -0.0723103    0.0966963   -0.199528    -0.123502      0.117208    -0.0195436   -0.0797693   -0.11124      0.145586      0.00509801  -0.0559542     0.0298424     0.0380365
 -0.177604    -0.0101892   -0.0509312    0.112275   -0.00701262  -0.138387    -0.0758867    0.0318982    0.083535    -0.101437     0.0644661  -0.108015    -0.0239994    -0.0775731    0.0972861    0.26754     -0.0386028     0.201322     0.0324691    0.212577     0.045272     0.0968434     0.21105      0.124947      0.0153004     0.00347853
 -0.121286    -0.678516    -0.0693492    0.0210313   0.0146211   -0.0490844    0.0470182   -0.075138    -0.00860244  -0.146394    -0.0896128   0.0897302   -0.0866402     0.0350939    0.0248857   -0.00525234  -0.00903512    0.0291122    0.101773    -0.179305    -0.0229856   -0.0651045     0.00625522   0.0654665    -0.0280325    -0.281962
 -0.107022     0.736323     0.0216263    0.0120861   0.0192917   -0.0565307    0.0328977   -0.0187561    0.0361245   -0.175275    -0.130486    0.0577196   -0.162573     -0.0193613   -0.0128849    0.0483961    0.0853563     0.132551     0.086823     0.128505    -0.0203821   -0.0918805     0.0143421    0.0284243    -0.0152526    -0.0285425
  0.135617     0.0357791   -0.0943139   -0.136731   -0.0183353    0.0661748   -0.103494     0.0724613   -0.155658    -0.0371511   -0.0877293  -0.0362572   -0.132236      0.093078    -0.131837    -0.0781446   -0.033143     -0.126762     0.00274075  -0.103252    -0.0291543   -0.0306479    -0.0649976   -0.000893674   0.0694028    -0.173541
 -0.0249279    0.0778369    0.0968247    0.127849   -0.0941082   -0.0150124    0.0191237    0.105513    -0.18544     -0.0437044    0.0254446   0.0516692   -0.0994289     0.0334996   -0.115083     0.0117215   -0.0532933     0.0430457    0.00599227   0.172441    -0.106518     0.0304655    -0.022921    -0.0957479     0.13806      -0.000378005
  0.0944398   -0.0103024   -0.0199549    0.0917789   0.132095    -0.028107     0.00729936  -0.065097    -0.0036137    0.124873    -0.0911017   0.0283575    0.156654      0.0542729    0.114111    -0.039078    -0.00914643    0.0506379    0.0509286   -0.0232698   -0.0441873   -0.082104      0.00541746   0.0853326     0.0436664     0.139067
 -0.112887     0.0460845   -0.0513514    0.122527   -0.0896151    0.0346102   -0.120855     0.0795909   -0.117226     0.0223067    0.0424854   0.00785568   0.0596527     0.0899944    0.177371    -0.0194296   -0.0658825     0.0461783    0.0197541   -0.020363     0.0736898   -0.0242546     0.0676848   -0.0950523    -0.0931776     0.087501
  0.047762    -0.114818    -0.0759673   -0.0462958   0.0824511   -0.194051     0.0150751    0.0619514   -0.0561038   -0.0625034    0.0707579  -0.0665553    0.0080594     0.0185018   -0.0870964    0.0190934    0.0995218    -0.0432599   -0.00185539  -0.0324618    0.024187     0.06295       0.0435685   -0.06611       0.101488      0.148106
  0.0372392   -0.0883077   -0.131907    -0.0587322   0.00370628  -0.174161     0.161565    -0.214792    -0.110168    -0.054492     0.010344    0.148697     0.171113     -0.12367     -0.10558      0.0314564    0.0885484     0.254042    -0.072792    -0.076295     0.0228099   -0.130078      0.026944    -0.0128625    -0.00530395    0.103335
 -0.132103     0.0451171   -0.0587899   -0.631243   -0.167917     0.166841    -0.0915964   -0.0234715    0.0415651    0.0628885    0.0118051   0.0107821   -0.0293218    -0.0398255   -0.0785797    0.0175554    0.00114196   -0.00403716   0.170138     0.0854627   -0.198011    -0.0264622    -0.0865329    0.203286     -0.145847     -0.138249
 -0.242918     0.0953665   -0.161121     0.177279   -0.160776     0.173936    -0.124082    -0.00628237  -0.0163724   -0.0044384    0.015384    0.127079    -0.128206     -0.196341    -0.107964     0.00593073  -0.0127259     6.43618e-5   0.177002     0.174086     0.60467      0.028389     -0.0723927    0.12338      -0.114651     -0.107058
 -0.207294     0.0961344    0.00469803   0.0851727  -0.0100046   -0.108557    -0.137923     0.118604    -0.0240733   -0.0268931    0.136876    0.212819    -0.00904824    0.0235315   -0.152659     0.00986564  -0.0533954     0.00705932   0.0609951    0.00807457  -0.16276     -0.0595898    -0.157928    -0.0202823     0.074803     -0.197671
 -0.00616299   0.0283792   -0.136965     0.0495318   0.0281259   -0.00736296  -0.00375012   0.026292    -0.0487155   -0.0773192    0.0497202   0.0451977   -0.00487392    0.129762    -0.00626922  -0.259095    -0.0793383     0.138187    -0.0558438   -0.0360888   -0.0110997    0.0046371    -0.0195038    0.101785     -0.0333722    -0.080809
  0.0899734    0.0629706   -0.0716088   -0.284086    0.0819946    0.168744     0.281094     0.00983771   0.024378    -0.00266746  -0.079859    0.0518569   -0.0761078     0.00364444   0.0510117    0.0321757   -0.179319      0.0853864    0.0178354    0.0315346    0.010561    -0.166512      0.107185    -0.0463427     0.0103008     0.180675
 -0.117358     0.0707104   -0.0065099   -0.0352986   0.104535    -0.110243    -0.0688028   -0.00614202  -0.0689135    0.0249776    0.0774174  -0.0218053    0.0245693    -0.0171986   -0.0253028   -0.0426646   -0.000332698   0.0926927   -0.165763     0.0265132    0.102805     0.000219097  -0.0805915   -0.0265371     0.111114     -0.0252592
  0.0860668    0.18438      0.00597562  -0.0848061  -0.108025     0.0923978   -0.127047    -0.11924      0.04856      0.113065    -0.154471   -0.079544    -0.247776     -0.0535582    0.0847897    0.0799558    0.0108894     0.0207282   -0.184016     0.0263501   -0.0937281    0.084214      0.0143446    0.199257     -0.0582595     0.0566204
  0.0929597   -0.115058     0.0370699    0.0748916  -0.158706     0.126733     0.0644118   -0.0661923    0.0493214   -0.116178    -0.205411    0.0784787    0.478106     -0.0790865    0.00350316  -0.0367784    0.11746       0.0609049   -0.136136     0.101428     0.0460394    0.0342958    -0.0604088    0.0994859    -0.0591402     0.0350308
 -0.0177099    0.0123955   -0.117708     0.0609304   0.116733    -0.15946     -0.0767984   -0.00116412  -0.0371103    0.148221     0.0297352   0.045707    -0.0249391    -0.0773375   -0.0302569    0.0294651    0.0487277    -0.138562    -0.0898301    0.173016    -0.231392    -0.0407644     0.142855    -0.046109      0.062694      0.185094
 -0.0705784    0.0755654    0.149469     0.0288776   0.120966    -0.00405266  -0.0319915    0.0327107    0.118361     0.100768    -0.078048    0.269222     0.231127      0.0750297   -0.165208     0.164536    -0.0440194     0.092586    -0.036686     0.0936614   -0.137247     0.0381543    -0.101248     0.0129661    -0.0629057     0.0659026
 -0.111918     0.15945     -0.0272191   -0.067065   -0.0882157   -0.0496766   -0.00448295   0.0734042    0.0137338   -0.0105492   -0.0895559   0.179169    -0.018896     -0.0543895   -0.132065     0.0100665    0.101928      0.222992     0.071709    -0.162326    -0.0873786   -0.117569      0.0437606   -0.0247225     0.186747     -0.16639
  0.0122588    0.0701322   -0.122867    -0.0836678   0.109507     0.00118233   0.118363     0.0979698    0.0207037   -0.110856    -0.0319008  -0.184493    -0.0271144     0.0846919   -0.0865567    0.0463379    0.0646736    -0.159761    -0.129425     0.0354347   -0.0652947   -0.0751779     0.0579431   -0.0528112     0.045203     -0.238771
  0.0359763   -0.0758311    0.0697885   -0.106319    0.0928762   -0.120944     0.0541735    0.103117    -0.116478    -0.0253171   -0.0526977  -0.204444    -0.0262958     0.0514879    0.127181    -0.00391956   0.00197697   -0.10791     -0.00229822   0.12263      0.0861425    0.0734308    -0.0106513    0.137199     -0.19649       0.107083
 -0.072804     0.0786674    0.0868424   -0.0453447  -0.0776243   -0.0775061    0.0285896    0.0578686    0.0128435   -0.0289533   -0.0525951   0.079246     0.0854052     0.0878488   -0.041364     0.0104566    0.110655      0.0837625   -0.125863     0.0381642    0.00530671  -0.0487241     0.137224    -0.00690064   -0.0919359     0.195776
  0.01007     -0.0677262   -0.131419    -0.0440242   0.0693052    0.165968    -0.0822238   -0.0546209   -0.0146312    0.0110519    0.0623319  -0.104798     0.182877     -0.0237846    0.167103    -0.108514    -0.106688     -0.0109849   -0.0513116    0.16902      0.0254812   -0.141377      0.0690371   -0.144257     -0.000852374  -0.076707
  0.190677     0.0501813   -0.0336498    0.0192371   0.174557    -0.0123749    0.0636766    0.0865556    0.0671592   -0.140087     0.181121   -0.00301362   0.0392257    -0.0796129   -0.108097     0.0426555   -0.0781345    -0.00277161   0.0299129    0.202277    -0.0579437   -0.216762     -0.141251    -0.118978      0.0852956     0.0859406
 -0.0568133   -0.00537743  -0.17829     -0.0205625  -0.0569392    0.102513    -0.146674    -0.0773095    0.0532295   -0.0769785   -0.0936399  -0.0532197    0.130558      0.0586501    0.187967     0.0446747    0.0276848    -0.0392573   -0.0758669   -0.127571     0.0166647    0.153705     -0.108444     0.0449205     0.0712668     0.159198
  0.104541     0.0419353   -0.0836113   -0.0439022  -0.0803107    0.0105277   -0.187658     0.0915886   -0.189094    -0.0319906   -0.0343901  -0.148879    -0.0493895     0.0275793    0.0718118   -0.00422707  -0.0625598     0.167563     0.225597     0.0865469    0.0585444   -0.0331938     0.0626631    0.282245     -0.0886604     0.142777
 -0.033959     0.0161376    0.172834     0.0334829   0.00272513   0.0613123    0.03174      0.0174727   -0.0557767   -0.0606914   -0.0421437   0.129409     0.000249523   0.00193316  -0.033985    -0.0368765   -0.0464498    -0.0806252   -0.00332392  -0.0592114   -0.0503753   -0.0537173     0.0405672    0.0494836    -0.0676371    -0.124988
 -0.132497     0.0878499   -0.0979569   -0.113069    0.107424     0.0221955    0.0502582    0.0259939    0.0149128    0.0430678    0.0217384   0.0215148   -0.0573425     0.199061     0.00615964  -0.0161952   -0.0134761     0.062181    -0.0686168   -0.0302404   -0.0778124    0.0503695    -0.024813     0.0803037    -0.0363478     0.0753284[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     16
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.014578
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│     21
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.997253
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     16
│     21
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.003514
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│     21
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.002971
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     16
│     21
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.007393
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│      ⋮
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.992712
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     16
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.013654
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│     21
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.995106
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     16
│     21
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.004009
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     11
│     16
│     21
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.002062
┌ Info: EM with 100000 data points 10 iterations avll -1.002062
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.298789e+05
      1       6.643755e+05      -1.655034e+05 |       32
      2       6.375680e+05      -2.680750e+04 |       32
      3       6.227968e+05      -1.477124e+04 |       32
      4       6.130291e+05      -9.767740e+03 |       32
      5       6.050297e+05      -7.999342e+03 |       32
      6       6.013234e+05      -3.706354e+03 |       32
      7       5.994096e+05      -1.913755e+03 |       32
      8       5.979658e+05      -1.443781e+03 |       32
      9       5.968004e+05      -1.165436e+03 |       32
     10       5.958497e+05      -9.507324e+02 |       32
     11       5.948271e+05      -1.022586e+03 |       32
     12       5.935190e+05      -1.308034e+03 |       32
     13       5.926587e+05      -8.603327e+02 |       32
     14       5.920592e+05      -5.995380e+02 |       32
     15       5.915213e+05      -5.379163e+02 |       32
     16       5.908878e+05      -6.334563e+02 |       32
     17       5.898704e+05      -1.017401e+03 |       32
     18       5.883693e+05      -1.501083e+03 |       32
     19       5.868750e+05      -1.494305e+03 |       32
     20       5.858599e+05      -1.015157e+03 |       32
     21       5.850450e+05      -8.148885e+02 |       32
     22       5.840838e+05      -9.611720e+02 |       32
     23       5.830043e+05      -1.079492e+03 |       32
     24       5.824728e+05      -5.315449e+02 |       32
     25       5.823384e+05      -1.343322e+02 |       32
     26       5.822930e+05      -4.538926e+01 |       30
     27       5.822784e+05      -1.465692e+01 |       31
     28       5.822712e+05      -7.221753e+00 |       27
     29       5.822686e+05      -2.598324e+00 |       25
     30       5.822659e+05      -2.637837e+00 |       26
     31       5.822629e+05      -3.067295e+00 |       26
     32       5.822606e+05      -2.295372e+00 |       19
     33       5.822591e+05      -1.487797e+00 |       18
     34       5.822581e+05      -1.007482e+00 |       20
     35       5.822565e+05      -1.521275e+00 |       21
     36       5.822546e+05      -1.974991e+00 |       22
     37       5.822522e+05      -2.369021e+00 |       19
     38       5.822500e+05      -2.169033e+00 |       21
     39       5.822476e+05      -2.475680e+00 |       18
     40       5.822455e+05      -2.031900e+00 |       22
     41       5.822432e+05      -2.313366e+00 |       18
     42       5.822416e+05      -1.578688e+00 |       18
     43       5.822404e+05      -1.262642e+00 |       19
     44       5.822388e+05      -1.605325e+00 |       21
     45       5.822373e+05      -1.475934e+00 |       19
     46       5.822356e+05      -1.685771e+00 |       20
     47       5.822343e+05      -1.277853e+00 |       19
     48       5.822322e+05      -2.071206e+00 |       16
     49       5.822313e+05      -9.116779e-01 |       12
     50       5.822308e+05      -4.993403e-01 |       10
K-means terminated without convergence after 50 iterations (objv = 582230.8373792302)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.287915
[ Info: iteration 2, average log likelihood -1.249379
[ Info: iteration 3, average log likelihood -1.213141
[ Info: iteration 4, average log likelihood -1.177925
[ Info: iteration 5, average log likelihood -1.133794
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.071386
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.041244
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.049829
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.047404
[ Info: iteration 10, average log likelihood -1.043298
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     11
│     13
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.001719
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.043450
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.044078
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.025022
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     11
│     13
│     24
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -0.999017
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.047387
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.024641
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.013966
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     11
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.027181
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.031851
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.026509
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.032173
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.027684
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     18
│     20
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.009518
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.043262
[ Info: iteration 26, average log likelihood -1.045859
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.002415
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│     13
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.012729
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.060458
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.028165
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.003484
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.025453
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.046712
[ Info: iteration 34, average log likelihood -1.032071
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -0.990642
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.019300
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.043858
[ Info: iteration 38, average log likelihood -1.032237
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.990688
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.019155
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.043802
[ Info: iteration 42, average log likelihood -1.032227
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -0.990677
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.019144
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.043799
[ Info: iteration 46, average log likelihood -1.032226
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -0.990676
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.019143
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.043799
[ Info: iteration 50, average log likelihood -1.032226
┌ Info: EM with 100000 data points 50 iterations avll -1.032226
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.184591     0.0524122   -0.0337069   0.0184007    0.172421    -0.00426348   0.0594647    0.0824512    0.0663583   -0.138568     0.174331    -0.00569624   0.0420291   -0.079562     -0.100521     0.0398089    -0.0786475    0.00197809    0.0269566    0.202527    -0.0542976    -0.21614     -0.136774     -0.121402     0.0825223    0.085775
 -0.175712    -0.0101622   -0.0511933   0.111663    -0.00566736  -0.140158    -0.074365     0.0323654    0.0837308   -0.100528     0.0655798   -0.10492     -0.0244181   -0.0764225     0.0976579    0.266105     -0.0394634    0.202417      0.0316556    0.214609     0.0434593     0.0909987    0.210389      0.124633     0.0164284    0.0050238
  0.0502001   -0.0382132    0.17234     0.22685     -0.0586375    0.154891     0.0856353    0.00478615  -0.0228987    0.00223577  -0.0347016    0.10089     -0.0267586    0.0319032    -0.0867924   -0.128315     -0.0210856   -0.177612     -0.00726771  -0.00330674   0.0216661     0.0821439    0.0504995     0.0234563    0.158163    -0.243208
  0.0391155   -0.0693827    0.064395   -0.103594     0.0948577   -0.112206     0.0528065    0.101419    -0.114164    -0.0267078   -0.0602138   -0.201608    -0.0263435    0.0503524     0.126068    -0.00833558    0.00139827  -0.109136     -0.00308468   0.123015     0.0823084     0.0731683   -0.00955893    0.136394    -0.186318     0.104981
  0.0972741    0.0429974   -0.0834229  -0.0470341   -0.0850668    0.00538583  -0.184699     0.0931585   -0.188469    -0.0261931   -0.0294633   -0.150804    -0.0443482    0.0250644     0.0552405   -0.00571037   -0.0671547    0.160723      0.229786     0.0941935    0.0629498    -0.0215414    0.0695682     0.270969    -0.0894581    0.157882
  0.0888889    0.0406448    0.0211199  -0.00896091  -0.132202     0.104816    -0.0346526   -0.0930562    0.0486442    0.00545195  -0.178401    -0.00493373   0.0986921   -0.0667778     0.0436807    0.0219867     0.0623345    0.0395519    -0.160668     0.0629662   -0.0271528     0.060751    -0.0204468     0.149674    -0.0585412    0.0468659
 -0.0108724   -0.00713783  -0.128157    0.0892605    0.0794407   -0.175436    -0.0334967    0.0056993   -0.0334032    0.121637     0.0901019    0.0366028   -0.0572511   -0.0692314     0.0281147   -0.0216406     0.0570448   -0.19         -0.133102     0.14333     -0.166496     -0.0191173    0.145346     -0.031468     0.0669106    0.0931806
 -0.0490266    0.0588929    0.0615733   0.0465242    0.122502    -0.0632325   -0.0509591    0.0107369    0.0594622    0.144337    -0.0361669    0.176469     0.132025     0.0225238    -0.121724     0.109909     -0.0137135   -0.00113708   -0.0487804    0.128454    -0.175488      0.0156893   -0.000866076  -0.0134623   -0.00600049   0.122287
 -0.320068     0.0152297   -0.204961   -0.10801     -0.165132     0.174366    -0.136477     0.00869268  -0.0368149    0.0138724    0.00203071   0.0915877   -0.151189    -0.30822      -0.108834    -0.000472936  -0.0152133    0.00556331    0.177458     0.156476     0.730951     -0.0545075   -0.0708198     0.124918    -0.155334    -0.0848026
 -0.205284     0.0961903    0.0065596   0.0858056   -0.00940944  -0.106246    -0.134637     0.117527    -0.024656    -0.0278601    0.136444     0.21049     -0.00793947   0.0262729    -0.150965     0.0110708    -0.0531891    0.00807434    0.0590683    0.00633328  -0.163681     -0.0580212   -0.15559      -0.0169681    0.0727537   -0.197419
  0.00362588  -0.0185768   -0.092419   -0.053366     0.134003    -0.0998112    0.0054972    0.152807    -0.022237    -0.10567      0.19328     -0.0225851    0.203308    -0.000681335  -0.0379552   -0.148288     -0.108659    -0.0203743    -0.142868    -0.0117383    0.0865351    -0.143597    -0.114963      0.014039     0.131349    -0.0198457
  0.0943454   -0.010324    -0.0197398   0.0918619    0.132113    -0.0276423    0.0074464   -0.0646531   -0.00317812   0.124873    -0.0911221    0.0285211    0.156687     0.0536948     0.113615    -0.0389631    -0.00971754   0.050682      0.0509442   -0.0233427   -0.0448953    -0.0818908    0.00539371    0.0848221    0.0442569    0.139147
 -0.00167419   0.0285024   -0.141521    0.0429681    0.0320795   -0.00719735  -0.00296716   0.0266039   -0.0448434   -0.0811099    0.0518472    0.0463955   -0.00475071   0.132371     -0.00515367  -0.273086     -0.0789351    0.138747     -0.0596738   -0.0347917   -0.00653542    0.00421305  -0.0244735     0.0968725   -0.0322679   -0.0838028
 -0.0780179   -0.0943652   -0.0371186  -0.00189638  -0.0474487    0.0265233   -0.0101611   -0.0291113    0.0734738    0.0441535   -0.0373392    0.0964852    0.149939     0.189907      0.0162254   -0.0987497     0.129348     0.0271522    -0.0624097   -0.0808591    0.0587235     0.020523     0.157992     -0.0235733   -0.185324     0.173581
 -0.0239067    0.0455491    0.0659039   0.109305     0.108583     0.0657047    0.0223525    0.0696828   -0.00365119  -0.126093    -0.11626      0.051777    -0.142151    -0.0742585     0.105807    -0.205733     -0.11941      0.142265     -0.0417217   -0.105279    -0.160493      0.14111     -0.0762736     0.0270113    0.0174816   -0.0368264
  0.089357     0.0627948   -0.0707629  -0.278183     0.0863299    0.164784     0.28745      0.0098203    0.0285394   -0.00205585  -0.080164     0.0512069   -0.0774609   -0.000167167   0.0513343    0.0314713    -0.169951     0.0848173     0.0146579    0.03411      0.00518527   -0.169333     0.109991     -0.0462283    0.013975     0.179739
  0.0361572   -0.0884582   -0.13243    -0.0583274    0.00795645  -0.174898     0.157438    -0.20919     -0.110026    -0.055081     0.011704     0.146614     0.169697    -0.126717     -0.107251     0.0308116     0.0899739    0.242182     -0.074331    -0.0721732    0.0268261    -0.127826     0.0292056    -0.0137084   -0.00514095   0.105193
  0.0080272    0.0737384    0.0715496   0.0953739   -0.0871146    0.00143512   0.00427399   0.0971163   -0.180049    -0.0491361    0.0115244    0.0376394   -0.1202       0.0547972    -0.118524    -0.011365     -0.0551044    0.0127881     0.00301668   0.124139    -0.0914866     0.0177807   -0.0300343    -0.0829374    0.138743    -0.0183695
 -0.11424      0.01219     -0.0267881   0.015931     0.0169076   -0.0534961    0.0395933   -0.0478331    0.0130858   -0.161563    -0.109709     0.0742392   -0.124351     0.00852727    0.00665694   0.0208865     0.036158     0.0800256     0.0958051   -0.0285523   -0.0216921    -0.0794163    0.0116476     0.0468373   -0.0221976   -0.158292
 -0.0528184    0.184403     0.255194   -0.0657011   -0.0925961   -0.144864     0.0705005    0.0953412   -0.0434401   -0.0835834   -0.0723342    0.0676812    0.0275927   -0.0138646    -0.0831329    0.0681283     0.0809156    0.0530317    -0.185179     0.153695    -0.0458079    -0.0907568    0.123385      0.00770253  -0.0113698    0.163269
 -0.113134     0.0466443   -0.0502079   0.124206    -0.0898018    0.035079    -0.124277     0.0787845   -0.117521     0.0247521    0.0384547    0.00995447   0.0628146    0.094343      0.179736    -0.0194991    -0.0671735    0.0454494     0.0165119   -0.0193762    0.0727102    -0.0239964    0.0673354    -0.0983506   -0.0925157    0.0848507
 -0.0554855   -0.0046154   -0.175597   -0.0161206   -0.0601651    0.101484    -0.146981    -0.0705293    0.0435423   -0.0762284   -0.0931449   -0.0557351    0.122006     0.0563742     0.188594     0.0409785     0.0252818   -0.0375841    -0.0659946   -0.121787     0.020648      0.153599    -0.105711      0.0539043    0.0718425    0.157262
 -0.214558     0.173747     0.0703719  -0.0202332    0.0532221   -0.129293    -0.130739    -0.148539    -0.115645     0.139342    -0.0307676   -0.0168332   -0.167932    -0.0252514    -0.0103415    0.0901045     0.115829     0.195709     -0.185574     0.0720274    0.111705      0.137168    -0.0212795    -0.0657626    0.0770515   -0.00351771
  0.00191278  -0.0805825   -0.141845   -0.0464107    0.0664449    0.237867    -0.0667981   -0.0574829   -0.00895865   0.00951503   0.0610113   -0.10921      0.199863    -0.0146488     0.144644    -0.112245     -0.092284    -0.0365085    -0.0549686    0.157005     0.0202006    -0.143461     0.0704851    -0.150125     0.00211026  -0.125993
 -0.0892443    0.113588    -0.0350128  -0.301935    -0.163088     0.167542    -0.0855415   -0.0330357    0.0495131    0.0394538    0.0217814    0.0532153   -0.0253588    0.0270631    -0.0821658    0.0207744     0.00173318  -0.00851578    0.170335     0.111357    -0.19127       0.0463558   -0.0860315     0.190721    -0.110145    -0.151558
  0.121066     0.0624102   -0.135448   -0.286138    -0.0136433    0.0611777   -0.166373     0.085939    -0.155164    -0.0626373   -0.11306     -0.0433488   -0.144467     0.081997     -0.129799    -0.0665532    -0.0430247   -0.121358      0.0137462   -0.104243    -0.0277172    -0.0277575   -0.111728      0.00505533   0.0183146   -0.193585
  0.0416083   -0.110089    -0.0766612  -0.0522844    0.0717147   -0.197281     0.00345122   0.0724658   -0.0568418   -0.051985     0.0665477   -0.0641887    0.00818317   0.0216142    -0.0845393    0.02662       0.0929169   -0.0433026    -0.00849647  -0.0310546   -0.000188558   0.060022     0.0425269    -0.0501242    0.110089     0.149151
 -0.0110857   -0.0216627    0.0905748  -0.0467666    0.0720942    0.00500098  -0.129875     0.0879814    0.0547529   -0.351617    -0.340011    -0.0581177   -0.16077     -0.0639057     0.0631592   -0.17332      -0.136655     0.021509      0.0757785    0.0280444    0.0801001     0.163606     0.339379     -0.384719     0.0853771    0.336226
 -0.0173752   -0.200858    -0.0450037   0.0299352   -0.0828294    0.0643528   -0.149658     0.150721    -0.0691082   -0.0517919   -0.00924529  -0.182849     0.0316129    0.108399      0.0524134    0.11829       0.0247437    0.021797     -0.0535568   -0.0426274   -0.0932966     0.00620725   0.164421      0.0629965   -0.136725    -0.140072
 -0.0653429    0.0613987    0.180223   -0.0538012    0.0263877    0.0117762   -0.0189401    0.0510409   -0.0672511   -0.101132    -0.111323     0.136        0.0340956   -0.034816     -0.0443587    0.099733     -0.0771769    0.000139369   0.00423088  -0.0648134   -0.16796      -0.193323     0.0596271     0.0662226   -0.183214    -0.0997913
 -0.122867     0.0843121   -0.0911981  -0.0997708    0.103103     0.0337259    0.051023     0.0226886   -0.0232887    0.027347     0.0360463    0.02459     -0.0723104    0.176814      0.0153386   -0.0507978    -0.00442669   0.0695722    -0.0517607   -0.0665924   -0.0471813     0.0383289   -0.0295001     0.0754232   -0.0463134    0.0609423
 -0.0492769    0.11644     -0.0765274  -0.0762999    0.00951338  -0.0322365    0.0515858    0.0826205    0.0166883   -0.0603512   -0.0713232    0.00455861  -0.0250988    0.00982896   -0.100473     0.024537      0.0744906    0.0418141    -0.0248838   -0.0554181   -0.0727125    -0.0982534    0.04975      -0.0440452    0.111908    -0.19857[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.990676
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│     11
│      ⋮
│     24
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.962107
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.989926
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│     11
│      ⋮
│     24
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.960172
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.989954
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│     11
│      ⋮
│     24
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.960145
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.989954
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│     11
│      ⋮
│     24
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.960142
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.989954
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│     11
│      ⋮
│     24
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.960142
┌ Info: EM with 100000 data points 10 iterations avll -0.960142
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.134092     0.0727243   -0.0692928   0.0720274     0.049997     0.105541     0.088008     0.140049     0.0977898     0.0558341   -0.0370518    0.0279918   -0.0219015   -0.0193656    0.00817563    0.0252123    0.0997515    0.069235     0.167853    -0.0571217   -0.000106477  -0.0948867   -0.038352    -0.0555237   -0.193666    -0.0613194
  0.0127735   -0.081294    -0.178832   -0.110903      0.118285    -0.0649486    0.0708878    0.0326123    0.170316      0.0173181    0.0335605    0.0513673   -0.0494997   -0.00272996   0.145417     -0.0208578   -0.127308    -0.0755296    0.150581     0.011506     0.0944051     0.220189    -0.0209517    0.125243     0.00157848  -0.0737158
  0.168967     0.0964174    0.0655472  -0.160628      0.0393318    0.0959048   -0.284882    -0.00572666  -0.161006      0.11377      0.205891    -0.118225    -0.0703808    0.0972378    0.109823     -0.0548435    0.189323    -0.00813367   0.0350951   -0.10215      0.0246681     0.0654902    0.0200904   -0.0160334    0.14607      0.00777194
 -0.0126831    0.0775641    0.196717   -0.0514897    -0.0171414    0.0213847   -0.0534381   -0.165356    -0.0414398    -0.0281943    0.0171315    0.241949    -0.0105157    0.0225692    0.124944      0.146678     0.056635    -0.191349     0.00562643   0.108914    -0.0458223    -0.0374523    0.0447029    0.0405863    0.0123268    0.125019
 -0.062377     0.0462692   -0.0933512   0.0513978    -0.0795026    0.0879058   -0.10005     -0.227805    -0.0770224    -0.0698836   -0.0916139   -0.00608061  -0.194125    -0.0587864   -0.0692082    -0.132903     0.0118385    0.0157025   -0.0565315    0.0519123    0.198022      0.0624235   -0.0349521   -0.0172508   -0.256166    -0.00523953
  0.0496218    0.0606171   -0.0198372   0.0531045    -0.108357     0.130827    -0.114287     0.0693445   -0.0802749     0.0153367   -0.0117247    0.00996711   0.13515     -0.0648455   -0.000689291  -0.0364232    0.219108     0.129373     0.221871     0.0356366    0.0471141     0.0785014   -0.0835027   -0.0571195   -0.0234713    0.0629841
 -0.0389821   -0.0552594    0.161217    0.0261697     0.0635927    0.0371225   -0.158057     0.141592     0.119692     -0.0165101    0.032511    -0.118047     0.152505     0.112308    -0.0137104    -0.00808129   0.0645858   -0.0273142   -0.123694     0.0639574    0.206408      0.0809489   -0.00172069  -0.00561917   0.0462671    0.0437015
 -0.0338523   -0.190358     0.0608548  -0.0425926     0.0359752    0.0103137   -0.0495051   -0.0549923    0.0614243     0.00174635  -0.280413    -0.222643    -0.0988952   -0.0175086   -0.0511805    -0.033152    -0.249733    -0.0385505    0.158573     0.0888561    0.110257     -0.0554134   -0.0871242    0.153942    -0.114366    -0.0242369
  0.0797911   -0.0758053   -0.14284     0.124131      0.0503259    0.00773983  -0.0290839   -0.0879748    0.204692     -0.0831956   -0.0197049    0.12123      0.12502     -0.0941253   -0.0367193    -0.0890435    0.0363297    0.0483296    0.013307    -0.0708636    0.0148618     0.120901    -0.0192335    0.0669935    0.0449863    0.171473
  0.130307     0.130719     0.190582    0.0445811     0.117512    -0.136087    -0.0874884    0.00677814   0.0756355     0.00656839   0.172552    -0.1515      -0.0569503   -0.103154     0.219987     -0.0561397   -0.0856037   -0.0104093    0.00142487  -0.0434882    0.043652      0.141865    -0.0647183    0.112354     0.0390445   -0.171931
  0.0198388   -0.27426      0.110374   -0.026674     -0.243426     0.0147535   -0.0229599   -0.0723603   -0.0326256    -0.18594     -0.0965987   -0.11074     -0.0218431   -0.24031      0.0771572    -0.162059    -0.0157309   -0.0794467   -0.186563    -0.00191745  -0.251212     -0.0141218    0.176889    -0.00779131  -0.130233     0.012816
  0.00850917   0.0601981   -0.0677296   0.107476      0.050969    -0.0720557    0.12212      0.114508    -0.173033      0.00947093  -0.117721    -0.0224477   -0.158357    -0.0614479   -0.0074811     0.0566683   -0.0398176    0.0591346    0.0509742    0.0276617    0.00739129   -0.00882842  -0.0608621    0.0136857   -0.0342167   -0.151849
  0.116386    -0.0487831   -0.260724    0.0833235     0.163407     0.0779615   -0.0302872    0.0247877   -0.1388       -0.177369    -0.0938961   -0.140253     0.0436511   -0.217961    -0.00556422    0.0161175   -0.00717217   0.177089    -0.034481     0.0950026   -0.0855813    -0.156754    -0.047791     0.158778    -0.127323    -0.100752
  0.0375059    0.044581     0.0608937  -0.000365372   0.0633393   -0.0946653    0.125946    -0.0402234    0.0468501    -0.0764944    0.11924     -0.105663    -0.139108     0.0574851    0.027245      0.0361366   -0.103295    -0.00217795   0.105939     0.0551115   -0.0912335     0.191349     0.119329     0.0530576    0.0634366   -0.0725274
 -0.134412     0.0478082    0.0788534  -0.0165884     0.172061     0.188041     0.0028092   -0.278341     0.120802      0.126774     0.0641586    0.0802014    0.0568322   -0.00225272   0.0239583     0.133563    -0.0655062   -0.104599     0.00291305   0.171109    -0.0607495     0.14413     -0.244005     0.0352238   -0.00689887  -0.0721576
 -0.140108    -0.0160968   -0.0240674  -0.0229415    -0.00349018   0.0494897   -0.126341     0.0113667   -0.0648546    -0.138107     0.0145157   -0.138443    -0.0762902   -0.117998     0.0202794    -0.0338532   -0.0890664    0.110775     0.0275942    0.0226128    0.0330643    -0.0746875   -0.039898     0.00250793  -0.0333016    0.00360453
  0.0899023   -0.0798188   -0.0804096  -0.104151      0.264626    -0.0498436    0.0650651    0.0025429   -0.0996146     0.126067    -0.0443118    0.137211     0.128339    -0.035076     0.0018729    -0.251469     0.0342459   -0.0475991   -0.132452    -0.0740112   -0.0489873     0.0941689   -0.13576      0.0773598   -0.112445    -0.00642555
 -0.0901931    0.0686929    0.129273    0.00224772    0.00326761   0.0943166   -0.181707    -0.0307334   -0.0895656    -0.00522376  -0.0806543   -0.0401414   -0.0431736   -0.0263181    0.105874      0.0542203   -0.0378437    0.0671682    0.00345059  -0.0927365   -0.208633     -0.114071    -0.171171    -0.107721     0.0353742    0.0594326
 -0.0558968    0.027722    -0.087187   -0.0789171     0.0898882   -0.0413531    0.0512052   -0.0114551   -0.088683     -0.12118     -0.149418    -0.249964    -0.0122143   -0.0401696    0.0342903     0.0928061    0.01881     -0.137424    -0.0530873    0.126735     0.0375305    -0.00843341   0.290148    -0.171026     0.119492    -0.104088
  0.0367907    0.115118    -0.0216834  -0.02481      -0.0023376    0.0484554    0.104066     0.0112671    0.0602748    -0.131872    -0.00165558  -0.04291      0.0127711   -0.0313538   -0.0922748     0.0151992    0.101593    -0.0126889   -0.128275    -0.216274     0.0334165    -0.0721818   -0.148936    -0.0322159   -0.0361593    0.00796973
 -0.0741096    0.144982    -0.0884473  -0.0316377    -0.0689655   -0.0697877    0.0433519    0.0799051    0.0664564     0.0814915    0.0527102   -0.100284    -0.0661823    0.012912    -0.0308974    -0.116856     0.107414     0.146459    -0.0896818   -0.126155     0.0249898     0.00475101  -0.128941    -0.125596     0.0398971   -0.148021
  0.0113197   -0.00455085   0.141088    0.185716      0.0136223   -0.121864    -0.0690691   -0.17205     -0.111352     -0.0109036    0.174385     0.139334    -0.0302487   -0.0643106   -0.0898893    -0.125377    -0.0704644   -0.115341    -0.0168295    0.0282049   -0.198646     -0.0144793    0.153165     0.0339577    0.0015063    0.0270289
  0.0997586    0.0301342   -0.120271   -0.0373789    -0.0468422   -0.259032     0.0882521   -0.00511073  -0.0748256     0.144853    -0.114754     0.0572348   -0.0045268   -0.0366543   -0.125678     -0.022648     0.0981881    0.104721     0.226714    -0.0847836   -0.198777     -0.0323854    0.0283881    0.123423     0.0654882   -0.20486
 -0.108809    -0.119572    -0.179622   -0.0238557     0.121382     0.0833458    0.0101322    0.0213976   -0.00213159   -0.0344642   -0.00254638  -0.0952884    0.00736265  -0.0856952    0.00271439    0.0412194    0.0553944   -0.0667733    0.161455     0.063324    -0.0938551     0.0426867   -0.0176164    0.0577316   -0.0773168   -0.0404168
 -0.00805655   0.0822785    0.123373    0.0665886     0.196804    -0.0647573   -0.120366     0.0528155    0.0931657    -0.0519643   -0.0519723    0.0646116    0.196045     0.0621904    0.179571      0.0820386    0.00272671   0.0331825    0.0131037    0.142343     0.154525     -0.129954     0.0156585    0.178489    -0.00694527  -0.109644
 -0.146404    -0.130907     0.0732143  -0.127411     -0.15076      0.0844484   -0.207989    -0.0672539   -0.0326131     0.0654351   -0.0801362   -0.0530555   -0.0444052    0.0285672   -0.160144      0.02701     -0.101111    -0.0888216   -0.0327946    0.036426    -0.125066      0.0250752    0.176973    -0.173467     0.00650034   0.0643853
 -0.0397001   -0.152432    -0.160709   -0.0847673     0.0418495    0.0418112    0.00853458   0.0781064    0.184828      0.164006    -0.111265    -0.00597695  -0.0706258    0.11871      0.0241401    -0.075193     0.119688     0.12264     -0.156798     0.0703486   -0.114816     -0.112572     0.0735397   -0.0781746    0.0185468   -0.0906932
 -0.0497454   -0.108422    -0.141669   -0.0499977    -0.141939    -0.0592341   -0.0800723    0.0774353   -0.00429168    0.148959     0.0288042    0.0576544    0.0173008    0.204514     0.0263957    -0.0514589    0.0930613    0.0616938    0.0257805    0.0638422   -0.199088      0.149249     0.0188909    0.0651552    0.0645263    0.0240861
 -0.161717    -0.0330267    0.0858254  -0.0151872    -0.105284    -0.0247524    0.0941197   -0.106163     0.0347097    -0.0601975   -0.105159    -0.21911      0.152743    -0.176685     0.128575      0.237986    -0.00861671  -0.126939     0.0612959   -0.0317469   -0.0766642     0.0809374   -0.150321     0.109608     0.0120951    0.0071136
  0.0252408    0.155146    -0.14376    -0.0190856    -0.164491    -0.0203898    0.0947079    0.0326651   -0.176847     -0.0783462    0.0434439   -0.0964795    0.139384    -0.0714238    0.0478016    -0.184525    -0.105284    -0.220987    -0.064843     0.241711     0.0668112    -0.204194     0.0529134   -0.031158    -0.025083     0.130902
 -0.12896      0.121111    -0.0866396   0.0256378     0.119767     0.0534732    0.103537    -0.00681185   0.000505854   0.134505    -0.132379    -0.125269    -0.0715186    0.17097     -0.0962977     0.0230051    0.0690848   -0.129988     0.104281     0.0961801    0.0127012     0.0689935    0.056249    -0.019725     0.157376     0.0158945
 -0.0893243   -0.0387512    0.20887    -0.103278     -0.00803213   0.156425     0.0149365   -0.0690314   -0.000775734  -0.0946316   -0.0711183   -0.107766    -0.0867236    0.0448656    0.096878      0.0858093   -0.165975    -0.0139951    0.136226     0.0910108   -0.158363     -0.0354107   -0.0111913   -0.012925    -0.0802351   -0.0184285kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4226826515025282
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422702
[ Info: iteration 2, average log likelihood -1.422640
[ Info: iteration 3, average log likelihood -1.422594
[ Info: iteration 4, average log likelihood -1.422538
[ Info: iteration 5, average log likelihood -1.422471
[ Info: iteration 6, average log likelihood -1.422393
[ Info: iteration 7, average log likelihood -1.422308
[ Info: iteration 8, average log likelihood -1.422225
[ Info: iteration 9, average log likelihood -1.422150
[ Info: iteration 10, average log likelihood -1.422086
[ Info: iteration 11, average log likelihood -1.422026
[ Info: iteration 12, average log likelihood -1.421954
[ Info: iteration 13, average log likelihood -1.421835
[ Info: iteration 14, average log likelihood -1.421609
[ Info: iteration 15, average log likelihood -1.421176
[ Info: iteration 16, average log likelihood -1.420433
[ Info: iteration 17, average log likelihood -1.419426
[ Info: iteration 18, average log likelihood -1.418458
[ Info: iteration 19, average log likelihood -1.417814
[ Info: iteration 20, average log likelihood -1.417492
[ Info: iteration 21, average log likelihood -1.417353
[ Info: iteration 22, average log likelihood -1.417296
[ Info: iteration 23, average log likelihood -1.417273
[ Info: iteration 24, average log likelihood -1.417263
[ Info: iteration 25, average log likelihood -1.417259
[ Info: iteration 26, average log likelihood -1.417258
[ Info: iteration 27, average log likelihood -1.417257
[ Info: iteration 28, average log likelihood -1.417256
[ Info: iteration 29, average log likelihood -1.417256
[ Info: iteration 30, average log likelihood -1.417256
[ Info: iteration 31, average log likelihood -1.417256
[ Info: iteration 32, average log likelihood -1.417256
[ Info: iteration 33, average log likelihood -1.417256
[ Info: iteration 34, average log likelihood -1.417256
[ Info: iteration 35, average log likelihood -1.417256
[ Info: iteration 36, average log likelihood -1.417256
[ Info: iteration 37, average log likelihood -1.417256
[ Info: iteration 38, average log likelihood -1.417256
[ Info: iteration 39, average log likelihood -1.417256
[ Info: iteration 40, average log likelihood -1.417256
[ Info: iteration 41, average log likelihood -1.417256
[ Info: iteration 42, average log likelihood -1.417256
[ Info: iteration 43, average log likelihood -1.417256
[ Info: iteration 44, average log likelihood -1.417256
[ Info: iteration 45, average log likelihood -1.417256
[ Info: iteration 46, average log likelihood -1.417256
[ Info: iteration 47, average log likelihood -1.417256
[ Info: iteration 48, average log likelihood -1.417256
[ Info: iteration 49, average log likelihood -1.417256
[ Info: iteration 50, average log likelihood -1.417256
┌ Info: EM with 100000 data points 50 iterations avll -1.417256
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.422702349817653
│     -1.4226403652209416
│      ⋮
└     -1.417255544389041
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417272
[ Info: iteration 2, average log likelihood -1.417205
[ Info: iteration 3, average log likelihood -1.417155
[ Info: iteration 4, average log likelihood -1.417099
[ Info: iteration 5, average log likelihood -1.417035
[ Info: iteration 6, average log likelihood -1.416962
[ Info: iteration 7, average log likelihood -1.416883
[ Info: iteration 8, average log likelihood -1.416803
[ Info: iteration 9, average log likelihood -1.416726
[ Info: iteration 10, average log likelihood -1.416655
[ Info: iteration 11, average log likelihood -1.416594
[ Info: iteration 12, average log likelihood -1.416543
[ Info: iteration 13, average log likelihood -1.416503
[ Info: iteration 14, average log likelihood -1.416472
[ Info: iteration 15, average log likelihood -1.416449
[ Info: iteration 16, average log likelihood -1.416432
[ Info: iteration 17, average log likelihood -1.416419
[ Info: iteration 18, average log likelihood -1.416408
[ Info: iteration 19, average log likelihood -1.416399
[ Info: iteration 20, average log likelihood -1.416391
[ Info: iteration 21, average log likelihood -1.416384
[ Info: iteration 22, average log likelihood -1.416378
[ Info: iteration 23, average log likelihood -1.416371
[ Info: iteration 24, average log likelihood -1.416366
[ Info: iteration 25, average log likelihood -1.416360
[ Info: iteration 26, average log likelihood -1.416355
[ Info: iteration 27, average log likelihood -1.416350
[ Info: iteration 28, average log likelihood -1.416345
[ Info: iteration 29, average log likelihood -1.416341
[ Info: iteration 30, average log likelihood -1.416337
[ Info: iteration 31, average log likelihood -1.416333
[ Info: iteration 32, average log likelihood -1.416330
[ Info: iteration 33, average log likelihood -1.416326
[ Info: iteration 34, average log likelihood -1.416323
[ Info: iteration 35, average log likelihood -1.416320
[ Info: iteration 36, average log likelihood -1.416317
[ Info: iteration 37, average log likelihood -1.416314
[ Info: iteration 38, average log likelihood -1.416312
[ Info: iteration 39, average log likelihood -1.416309
[ Info: iteration 40, average log likelihood -1.416307
[ Info: iteration 41, average log likelihood -1.416305
[ Info: iteration 42, average log likelihood -1.416303
[ Info: iteration 43, average log likelihood -1.416301
[ Info: iteration 44, average log likelihood -1.416299
[ Info: iteration 45, average log likelihood -1.416297
[ Info: iteration 46, average log likelihood -1.416295
[ Info: iteration 47, average log likelihood -1.416294
[ Info: iteration 48, average log likelihood -1.416292
[ Info: iteration 49, average log likelihood -1.416290
[ Info: iteration 50, average log likelihood -1.416289
┌ Info: EM with 100000 data points 50 iterations avll -1.416289
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4172716019996816
│     -1.4172054194186774
│      ⋮
└     -1.416288867007915
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416306
[ Info: iteration 2, average log likelihood -1.416247
[ Info: iteration 3, average log likelihood -1.416205
[ Info: iteration 4, average log likelihood -1.416158
[ Info: iteration 5, average log likelihood -1.416102
[ Info: iteration 6, average log likelihood -1.416038
[ Info: iteration 7, average log likelihood -1.415968
[ Info: iteration 8, average log likelihood -1.415895
[ Info: iteration 9, average log likelihood -1.415822
[ Info: iteration 10, average log likelihood -1.415752
[ Info: iteration 11, average log likelihood -1.415685
[ Info: iteration 12, average log likelihood -1.415620
[ Info: iteration 13, average log likelihood -1.415555
[ Info: iteration 14, average log likelihood -1.415491
[ Info: iteration 15, average log likelihood -1.415427
[ Info: iteration 16, average log likelihood -1.415366
[ Info: iteration 17, average log likelihood -1.415306
[ Info: iteration 18, average log likelihood -1.415250
[ Info: iteration 19, average log likelihood -1.415199
[ Info: iteration 20, average log likelihood -1.415153
[ Info: iteration 21, average log likelihood -1.415111
[ Info: iteration 22, average log likelihood -1.415075
[ Info: iteration 23, average log likelihood -1.415043
[ Info: iteration 24, average log likelihood -1.415015
[ Info: iteration 25, average log likelihood -1.414991
[ Info: iteration 26, average log likelihood -1.414971
[ Info: iteration 27, average log likelihood -1.414953
[ Info: iteration 28, average log likelihood -1.414938
[ Info: iteration 29, average log likelihood -1.414924
[ Info: iteration 30, average log likelihood -1.414913
[ Info: iteration 31, average log likelihood -1.414903
[ Info: iteration 32, average log likelihood -1.414893
[ Info: iteration 33, average log likelihood -1.414885
[ Info: iteration 34, average log likelihood -1.414878
[ Info: iteration 35, average log likelihood -1.414871
[ Info: iteration 36, average log likelihood -1.414865
[ Info: iteration 37, average log likelihood -1.414859
[ Info: iteration 38, average log likelihood -1.414854
[ Info: iteration 39, average log likelihood -1.414848
[ Info: iteration 40, average log likelihood -1.414844
[ Info: iteration 41, average log likelihood -1.414839
[ Info: iteration 42, average log likelihood -1.414834
[ Info: iteration 43, average log likelihood -1.414830
[ Info: iteration 44, average log likelihood -1.414826
[ Info: iteration 45, average log likelihood -1.414822
[ Info: iteration 46, average log likelihood -1.414817
[ Info: iteration 47, average log likelihood -1.414813
[ Info: iteration 48, average log likelihood -1.414809
[ Info: iteration 49, average log likelihood -1.414805
[ Info: iteration 50, average log likelihood -1.414801
┌ Info: EM with 100000 data points 50 iterations avll -1.414801
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4163056672251833
│     -1.416246949452123
│      ⋮
└     -1.4148014197015966
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414807
[ Info: iteration 2, average log likelihood -1.414751
[ Info: iteration 3, average log likelihood -1.414703
[ Info: iteration 4, average log likelihood -1.414648
[ Info: iteration 5, average log likelihood -1.414581
[ Info: iteration 6, average log likelihood -1.414499
[ Info: iteration 7, average log likelihood -1.414400
[ Info: iteration 8, average log likelihood -1.414286
[ Info: iteration 9, average log likelihood -1.414164
[ Info: iteration 10, average log likelihood -1.414041
[ Info: iteration 11, average log likelihood -1.413924
[ Info: iteration 12, average log likelihood -1.413817
[ Info: iteration 13, average log likelihood -1.413721
[ Info: iteration 14, average log likelihood -1.413637
[ Info: iteration 15, average log likelihood -1.413561
[ Info: iteration 16, average log likelihood -1.413495
[ Info: iteration 17, average log likelihood -1.413436
[ Info: iteration 18, average log likelihood -1.413383
[ Info: iteration 19, average log likelihood -1.413335
[ Info: iteration 20, average log likelihood -1.413292
[ Info: iteration 21, average log likelihood -1.413251
[ Info: iteration 22, average log likelihood -1.413214
[ Info: iteration 23, average log likelihood -1.413178
[ Info: iteration 24, average log likelihood -1.413145
[ Info: iteration 25, average log likelihood -1.413112
[ Info: iteration 26, average log likelihood -1.413080
[ Info: iteration 27, average log likelihood -1.413050
[ Info: iteration 28, average log likelihood -1.413021
[ Info: iteration 29, average log likelihood -1.412992
[ Info: iteration 30, average log likelihood -1.412965
[ Info: iteration 31, average log likelihood -1.412938
[ Info: iteration 32, average log likelihood -1.412913
[ Info: iteration 33, average log likelihood -1.412889
[ Info: iteration 34, average log likelihood -1.412866
[ Info: iteration 35, average log likelihood -1.412844
[ Info: iteration 36, average log likelihood -1.412823
[ Info: iteration 37, average log likelihood -1.412804
[ Info: iteration 38, average log likelihood -1.412785
[ Info: iteration 39, average log likelihood -1.412767
[ Info: iteration 40, average log likelihood -1.412751
[ Info: iteration 41, average log likelihood -1.412735
[ Info: iteration 42, average log likelihood -1.412720
[ Info: iteration 43, average log likelihood -1.412706
[ Info: iteration 44, average log likelihood -1.412693
[ Info: iteration 45, average log likelihood -1.412680
[ Info: iteration 46, average log likelihood -1.412668
[ Info: iteration 47, average log likelihood -1.412657
[ Info: iteration 48, average log likelihood -1.412646
[ Info: iteration 49, average log likelihood -1.412636
[ Info: iteration 50, average log likelihood -1.412627
┌ Info: EM with 100000 data points 50 iterations avll -1.412627
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4148067181296047
│     -1.4147511024517672
│      ⋮
└     -1.4126267293784793
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412627
[ Info: iteration 2, average log likelihood -1.412555
[ Info: iteration 3, average log likelihood -1.412487
[ Info: iteration 4, average log likelihood -1.412405
[ Info: iteration 5, average log likelihood -1.412302
[ Info: iteration 6, average log likelihood -1.412172
[ Info: iteration 7, average log likelihood -1.412016
[ Info: iteration 8, average log likelihood -1.411839
[ Info: iteration 9, average log likelihood -1.411652
[ Info: iteration 10, average log likelihood -1.411467
[ Info: iteration 11, average log likelihood -1.411295
[ Info: iteration 12, average log likelihood -1.411142
[ Info: iteration 13, average log likelihood -1.411008
[ Info: iteration 14, average log likelihood -1.410892
[ Info: iteration 15, average log likelihood -1.410793
[ Info: iteration 16, average log likelihood -1.410707
[ Info: iteration 17, average log likelihood -1.410633
[ Info: iteration 18, average log likelihood -1.410568
[ Info: iteration 19, average log likelihood -1.410511
[ Info: iteration 20, average log likelihood -1.410461
[ Info: iteration 21, average log likelihood -1.410416
[ Info: iteration 22, average log likelihood -1.410376
[ Info: iteration 23, average log likelihood -1.410339
[ Info: iteration 24, average log likelihood -1.410307
[ Info: iteration 25, average log likelihood -1.410277
[ Info: iteration 26, average log likelihood -1.410249
[ Info: iteration 27, average log likelihood -1.410224
[ Info: iteration 28, average log likelihood -1.410201
[ Info: iteration 29, average log likelihood -1.410179
[ Info: iteration 30, average log likelihood -1.410159
[ Info: iteration 31, average log likelihood -1.410141
[ Info: iteration 32, average log likelihood -1.410123
[ Info: iteration 33, average log likelihood -1.410106
[ Info: iteration 34, average log likelihood -1.410091
[ Info: iteration 35, average log likelihood -1.410076
[ Info: iteration 36, average log likelihood -1.410062
[ Info: iteration 37, average log likelihood -1.410049
[ Info: iteration 38, average log likelihood -1.410036
[ Info: iteration 39, average log likelihood -1.410024
[ Info: iteration 40, average log likelihood -1.410012
[ Info: iteration 41, average log likelihood -1.410001
[ Info: iteration 42, average log likelihood -1.409990
[ Info: iteration 43, average log likelihood -1.409980
[ Info: iteration 44, average log likelihood -1.409970
[ Info: iteration 45, average log likelihood -1.409960
[ Info: iteration 46, average log likelihood -1.409951
[ Info: iteration 47, average log likelihood -1.409941
[ Info: iteration 48, average log likelihood -1.409932
[ Info: iteration 49, average log likelihood -1.409924
[ Info: iteration 50, average log likelihood -1.409915
┌ Info: EM with 100000 data points 50 iterations avll -1.409915
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4126270354091663
│     -1.41255518234195
│      ⋮
└     -1.409915172141689
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4226826515025282
│     -1.422702349817653
│     -1.4226403652209416
│     -1.4225937156229072
│      ⋮
│     -1.4099323697700508
│     -1.409923662244306
└     -1.409915172141689
32×26 Array{Float64,2}:
 -0.192142    0.159435    0.161882     0.188761   -0.681359    -0.282807    -0.197684   -0.206598     0.173689     -0.742448     0.260562    0.0547516   0.0801479   -0.343739    0.133404   -0.0219747    0.00285214   0.0390823   -0.664586   -0.592053   -0.191183    -0.224843   -0.00551307  -0.180334   -0.100099     -0.193664
  0.155221   -0.0572412   0.0107705   -0.10883    -0.632604     0.366266     0.110223   -0.276439    -0.29967      -0.834524     0.13133     0.0679307  -0.494677     0.60797     0.0954354  -0.135732    -0.301413    -0.108391     0.228074    0.0927891   0.163613    -0.0464738  -0.126841     0.152849    0.0252526     0.414787
 -0.300868   -0.505368    0.691755    -0.350797   -0.680137     0.246351    -0.284115   -0.268154     0.240142      0.305483     0.0831775  -0.111334   -0.329914     0.438286    0.124621    0.0602632    0.0783016    0.107081    -0.459503    0.120772   -0.052414     0.254838   -0.331778    -0.509635    0.0659403     0.111637
 -0.454887   -0.458856    0.178336     0.668094   -0.207575    -0.0156373   -0.0303069   0.502234     0.267256      0.0866929    0.715314    0.23466    -0.543108     0.487156   -0.391744   -0.0970801    0.246838     0.209187    -0.297204    0.374532    0.403137     0.166662   -0.880589     0.0372547  -0.141408     -0.0273881
  0.0711629   0.131393    0.0323241    0.243109   -0.114541     0.183876    -0.101688   -0.00849139  -0.195146      0.197711     0.0145309   0.125115   -0.113043     0.0546526   0.224071   -0.450014    -0.202877     0.25965      0.378046    0.098531   -0.0457049    0.0361134  -0.281044    -0.0515734   0.0507681     0.296539
  0.0672493   0.0319073  -0.0513496   -0.172194    0.0552197   -0.0471783    0.0385263  -0.0550755   -0.0851151    -0.0978947   -0.049724    0.0144534  -0.0770062   -0.025022    0.0920228   0.158584     0.0243286   -0.00127683   0.0997741  -0.055425   -0.071537    -0.0748594   0.161674    -0.0166945   0.0228444    -0.111102
 -0.518801    0.005081   -0.0666458   -0.170885   -0.0376027    0.194798     0.156273   -0.193907     0.0081539     0.019827     0.172769    0.197307   -0.0781365   -0.0787859  -0.663281    0.0111121   -0.385335    -0.0917156   -0.241603    0.106481    0.0390008    0.108637    0.295502     0.160053   -0.00743051    0.365734
  0.611307   -0.049602   -0.02702      0.0589787  -0.0912783   -0.32267      0.220934   -0.207757     0.000425367   0.269709     0.110175   -0.444481    0.357915    -0.216979   -0.573038   -0.0512122   -0.249587    -0.127598    -0.18859     0.34251    -0.110483    -0.0144051   0.266082     0.180987   -0.0873968     0.566934
 -0.10082    -0.0246015  -0.0689349    0.0216367   0.0572571   -0.102129    -0.0164224  -0.0653814    0.246495      0.0990898   -0.644039    0.041019    0.28897     -0.13771    -0.325786   -0.5546       0.728269    -0.0204951   -0.114114    0.0496449   0.371142    -0.333677    0.284858    -0.497904    0.181191     -0.6344
  0.187888   -0.253696   -0.392234    -0.329655   -0.179676     0.00299335   0.868471    0.401643     0.125412      0.0833021   -0.065395    0.190437    0.127099     0.0347588  -0.278478    0.658618     0.928116    -0.309656    -0.592339    0.0630941  -0.00135533  -0.371503    0.151172     0.027341   -0.0781882    -0.531966
 -0.0902767  -0.0215003  -0.260353     0.331099    0.0406425    0.0329943   -0.242159    0.185691     0.397524     -0.116639    -0.392947   -0.182451    0.266273     0.0934115   0.0489399  -0.360195     0.395833    -0.245614    -0.178721   -0.179517    0.116594     0.11975    -0.326019     0.289464   -0.285656     -0.227583
 -0.324555   -0.0488289   0.228825     0.191787    0.441513    -0.175151     0.138138    0.215365     0.396024      0.278408     0.202607   -0.206774    0.269002    -0.25366    -0.0337686   0.574739     0.131911    -0.0447175   -0.129224    0.224097   -0.190859     0.300945   -0.35077     -0.0743299  -0.209923     -0.425809
 -0.421365   -0.61616    -0.0635432    0.0750482   0.617507    -0.130468    -0.156589   -0.0699422   -0.627531     -0.681405     0.392817   -0.288686   -0.454114     0.420332    0.177963    0.0920447    0.0295427   -0.621449     0.534676   -0.343641   -0.183771    -0.420685    0.233507    -0.432601    0.0877712    -0.0647869
  0.0020486   0.0808814  -0.114908    -0.724648    1.01987     -0.0390717    0.0358692   0.154261    -0.226349      0.414444    -0.451546   -0.0265415  -0.20965      0.0739687  -0.0992366  -0.00345955   0.430264    -0.275272    -0.027065   -0.151053   -0.38494      0.0553053   0.399736     0.0693666  -0.000484407  -0.535866
  0.141758   -0.460048   -0.750718     0.0195653   0.616914     0.436389     0.411058   -0.313612    -0.515147      0.19845     -0.183609    0.172418    0.606999    -0.0491453   0.466836    0.195303    -0.697633    -0.265622     0.654216   -0.0388952   0.202835     0.0649395  -0.333716     0.51798     0.557735     -0.313188
  0.219534   -0.23036     0.498434    -0.126163    0.392493    -0.0988762    0.259771   -0.480828    -0.0149344    -0.351042    -0.143306   -0.096804   -0.0761738    0.254011    0.324435    0.678369     0.375634    -0.446735     0.132642   -0.0864137   0.203566     0.608825   -0.257547     0.571731    0.393239     -0.426041
  0.346831   -0.759649    0.304148     0.186063   -0.365999     0.195826     0.268156   -0.0776249   -0.386842     -0.275084    -0.545047   -0.989037   -0.0204762   -0.604502    0.0744281   0.286123    -0.0914385    0.278688     0.523983    0.0421341  -0.328704    -0.880762    0.366473    -0.429547   -0.168183      0.665942
  0.654268    0.627418   -0.0912629   -0.467229    0.0743318    0.0926076   -0.411616   -0.717473    -0.251312      0.0980246   -0.363729   -0.39942     0.398366    -0.39078     0.511459   -0.0400676   -0.260491    -0.022461     0.401836   -0.624735   -0.343585    -0.262267    0.828989    -0.135121    0.0422659     0.264429
 -0.194852    0.0321136   0.318578     0.123835   -0.0787119   -0.194714    -0.635572   -0.00861666   0.302451     -0.301587     0.046511   -0.60293     0.00197637  -0.36405     0.11672     0.0175103   -0.55015      0.0248557    0.703681    0.34988     0.252669     0.386759   -0.203481    -0.313022    0.382234      0.111828
  0.239027   -0.33227     0.518853    -0.0684781  -0.20306      0.545714    -0.437473    0.371203    -0.0549094    -0.334794    -0.50274    -0.799368    0.00182631  -0.0736706  -0.0344074  -0.199256     0.986367    -0.298961     0.467902    0.433163   -0.0914036    0.125305    0.127361    -0.320746    0.1306       -0.0699038
 -0.706808   -0.725511   -0.527511    -0.257389   -0.216616     0.698051    -0.943042    0.684346    -0.167424      0.0565545   -0.619422    0.396271   -0.275907     1.03664     0.261543   -0.953648     0.109755     0.304139     1.09387    -0.125155    0.675752     0.232403   -0.421827    -0.16691     0.698205     -1.00641
 -0.0647124   0.356779   -0.0457619   -0.0772751  -0.352993     0.273167    -0.329278    0.109449    -0.284878      0.04985     -0.763778    0.422651   -0.173018    -0.28054    -0.148844   -0.983434    -0.147133     0.00351804   0.146508   -0.122101   -0.381205     0.331918   -0.0650953    0.0184638   0.567617      0.573969
 -0.0940182   0.508184   -0.701116    -0.29254     0.170603    -0.10353      0.0839738   0.160808    -0.475712     -0.00294267   0.041075    0.522219    0.286628    -0.597407    0.445295    0.170556    -0.152054    -0.147285    -0.0879024  -0.264985   -0.526807     0.419832   -0.167205     0.881584   -0.257212     -0.116657
 -0.0143021   1.03161    -0.25493     -0.128404   -6.84497e-5   0.307404    -0.541777    0.0245836    0.422501      0.130599     0.0756698   0.466794   -0.191425     0.131811    0.392775   -0.0724037   -0.104402     0.618387    -0.267414    0.336635   -0.291333     0.115848    0.171904     0.283843   -0.128785     -0.0894432
  0.0706657   0.112139    0.00885311  -0.115286   -0.463498    -0.0821543   -0.0610672  -0.340865    -0.123401     -0.28694      0.534247   -0.0670158  -0.266355     0.030532   -0.0502775  -0.195613    -1.00842      0.123793     0.0382713   0.178163    0.206984    -0.124686    0.0583013    0.132927   -0.154794      0.546081
 -0.0320112  -0.416351    0.46736     -0.498045    0.0494574    0.323977     0.283312   -0.148262    -0.287474      0.70231      0.465503    0.221623   -0.17473      0.277755   -0.470886    0.287013    -0.492115     0.437623    -0.311218    0.357556   -0.0373732   -0.231335    0.338133    -0.448129    0.0298516     0.39105
  0.0340186   0.239228    0.0472373   -0.129547   -0.156104    -0.0939153    0.357173    0.596262    -0.229566      0.388705     0.710948   -0.226202   -0.0293965   -0.0622059   0.442805    0.185052    -0.163186     0.315985     0.410944    0.264223   -0.181287    -0.685388    0.0316266   -0.432737   -0.416684     -0.353135
 -0.0627515  -0.138328   -0.216922     0.427269    1.20185     -0.336215    -0.0536455   0.359403     0.285147      0.456613     0.066839   -0.0951254  -0.410963     0.032733    0.371602    0.056019     0.00545799   0.595678     0.609971    0.142129   -0.0137774   -0.0123013   0.199433     0.17911    -0.392296      0.032611
  0.301011   -0.365779   -0.745308     0.91902     0.0842414   -0.455404     0.414935   -0.561486    -0.486731     -0.00493631  -0.293341    0.282448    0.28225     -0.0747215   0.0203735  -0.342234    -0.0669029   -0.280453    -0.71294    -0.155428    0.139034    -0.314529   -0.581792     0.290691   -0.582993      0.148708
  0.0485235   0.42564    -0.293087     0.226724   -0.152247    -0.200789    -0.233074   -0.132963     0.822417     -0.0636269   -0.473954    0.0543542   0.688436    -0.102214   -0.219853   -0.235464     0.331852    -0.432777    -0.285847   -0.337325    0.635002     0.358525   -0.200859     0.658423   -0.154626     -0.56054
  0.272909    0.221869   -0.0540901   -0.27727     0.204367    -0.149324    -0.0919367   0.0125917   -0.0379069    -0.238196    -0.337799   -0.171757   -0.226318     0.0601134   0.309498    0.104899     0.449302    -0.111643    -0.161682   -0.340033   -0.272729    -0.353366    0.515788    -0.107457   -0.347456     -0.234139
 -0.304637   -0.34346     0.0929579    0.48102     0.307835     0.0359515    0.19924     0.0612942    0.278793      0.228687     0.0177416  -0.0142314   0.511464    -0.206242   -0.268352    0.184234     0.300267    -0.0667089   -0.131476    0.250369    0.0484736    0.392099   -0.472129    -0.0524349   0.113894     -0.221859[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409907
[ Info: iteration 2, average log likelihood -1.409899
[ Info: iteration 3, average log likelihood -1.409891
[ Info: iteration 4, average log likelihood -1.409883
[ Info: iteration 5, average log likelihood -1.409876
[ Info: iteration 6, average log likelihood -1.409868
[ Info: iteration 7, average log likelihood -1.409861
[ Info: iteration 8, average log likelihood -1.409854
[ Info: iteration 9, average log likelihood -1.409847
[ Info: iteration 10, average log likelihood -1.409840
┌ Info: EM with 100000 data points 10 iterations avll -1.409840
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.451060e+05
      1       7.042287e+05      -2.408773e+05 |       32
      2       6.913850e+05      -1.284370e+04 |       32
      3       6.867346e+05      -4.650421e+03 |       32
      4       6.841294e+05      -2.605228e+03 |       32
      5       6.825095e+05      -1.619906e+03 |       32
      6       6.813282e+05      -1.181248e+03 |       32
      7       6.804814e+05      -8.467870e+02 |       32
      8       6.798357e+05      -6.456808e+02 |       32
      9       6.793151e+05      -5.206773e+02 |       32
     10       6.789223e+05      -3.928104e+02 |       32
     11       6.785656e+05      -3.566423e+02 |       32
     12       6.782536e+05      -3.119862e+02 |       32
     13       6.779597e+05      -2.939232e+02 |       32
     14       6.776908e+05      -2.689324e+02 |       32
     15       6.774423e+05      -2.485227e+02 |       32
     16       6.772414e+05      -2.008265e+02 |       32
     17       6.770566e+05      -1.848623e+02 |       32
     18       6.768697e+05      -1.868235e+02 |       32
     19       6.766919e+05      -1.778611e+02 |       32
     20       6.765406e+05      -1.512323e+02 |       32
     21       6.764151e+05      -1.255964e+02 |       32
     22       6.763134e+05      -1.016795e+02 |       32
     23       6.762202e+05      -9.316438e+01 |       32
     24       6.761338e+05      -8.642910e+01 |       32
     25       6.760580e+05      -7.573915e+01 |       32
     26       6.759858e+05      -7.226392e+01 |       32
     27       6.759195e+05      -6.625028e+01 |       32
     28       6.758482e+05      -7.136969e+01 |       32
     29       6.757847e+05      -6.348944e+01 |       32
     30       6.757322e+05      -5.246833e+01 |       32
     31       6.756768e+05      -5.538960e+01 |       32
     32       6.756247e+05      -5.213035e+01 |       32
     33       6.755696e+05      -5.504878e+01 |       32
     34       6.755144e+05      -5.523086e+01 |       32
     35       6.754629e+05      -5.148954e+01 |       32
     36       6.754214e+05      -4.153259e+01 |       32
     37       6.753783e+05      -4.305201e+01 |       32
     38       6.753391e+05      -3.926278e+01 |       32
     39       6.753044e+05      -3.469807e+01 |       32
     40       6.752663e+05      -3.807297e+01 |       32
     41       6.752351e+05      -3.123512e+01 |       32
     42       6.752037e+05      -3.136152e+01 |       32
     43       6.751705e+05      -3.316815e+01 |       32
     44       6.751396e+05      -3.091827e+01 |       32
     45       6.751084e+05      -3.125423e+01 |       32
     46       6.750776e+05      -3.073411e+01 |       32
     47       6.750466e+05      -3.097559e+01 |       32
     48       6.750185e+05      -2.811869e+01 |       32
     49       6.749914e+05      -2.714595e+01 |       32
     50       6.749678e+05      -2.354590e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 674967.8323990098)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421668
[ Info: iteration 2, average log likelihood -1.416705
[ Info: iteration 3, average log likelihood -1.415360
[ Info: iteration 4, average log likelihood -1.414358
[ Info: iteration 5, average log likelihood -1.413324
[ Info: iteration 6, average log likelihood -1.412393
[ Info: iteration 7, average log likelihood -1.411748
[ Info: iteration 8, average log likelihood -1.411373
[ Info: iteration 9, average log likelihood -1.411156
[ Info: iteration 10, average log likelihood -1.411014
[ Info: iteration 11, average log likelihood -1.410909
[ Info: iteration 12, average log likelihood -1.410825
[ Info: iteration 13, average log likelihood -1.410754
[ Info: iteration 14, average log likelihood -1.410692
[ Info: iteration 15, average log likelihood -1.410637
[ Info: iteration 16, average log likelihood -1.410589
[ Info: iteration 17, average log likelihood -1.410544
[ Info: iteration 18, average log likelihood -1.410504
[ Info: iteration 19, average log likelihood -1.410467
[ Info: iteration 20, average log likelihood -1.410433
[ Info: iteration 21, average log likelihood -1.410401
[ Info: iteration 22, average log likelihood -1.410372
[ Info: iteration 23, average log likelihood -1.410344
[ Info: iteration 24, average log likelihood -1.410318
[ Info: iteration 25, average log likelihood -1.410293
[ Info: iteration 26, average log likelihood -1.410270
[ Info: iteration 27, average log likelihood -1.410247
[ Info: iteration 28, average log likelihood -1.410226
[ Info: iteration 29, average log likelihood -1.410205
[ Info: iteration 30, average log likelihood -1.410185
[ Info: iteration 31, average log likelihood -1.410166
[ Info: iteration 32, average log likelihood -1.410147
[ Info: iteration 33, average log likelihood -1.410129
[ Info: iteration 34, average log likelihood -1.410112
[ Info: iteration 35, average log likelihood -1.410095
[ Info: iteration 36, average log likelihood -1.410079
[ Info: iteration 37, average log likelihood -1.410063
[ Info: iteration 38, average log likelihood -1.410048
[ Info: iteration 39, average log likelihood -1.410033
[ Info: iteration 40, average log likelihood -1.410019
[ Info: iteration 41, average log likelihood -1.410006
[ Info: iteration 42, average log likelihood -1.409993
[ Info: iteration 43, average log likelihood -1.409981
[ Info: iteration 44, average log likelihood -1.409969
[ Info: iteration 45, average log likelihood -1.409958
[ Info: iteration 46, average log likelihood -1.409947
[ Info: iteration 47, average log likelihood -1.409936
[ Info: iteration 48, average log likelihood -1.409926
[ Info: iteration 49, average log likelihood -1.409916
[ Info: iteration 50, average log likelihood -1.409907
┌ Info: EM with 100000 data points 50 iterations avll -1.409907
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.377872     0.429602     0.27481       0.36223     -0.215106   -0.224136    -0.53927    -0.502656   -0.0940448   -0.0700287  -0.224348    -0.203731     0.121235   -0.295259      0.687159   -0.348623   -0.376705      0.506427     0.337543   -0.764416   -0.453261    -0.421015    0.230517   -0.384648   -0.260733     0.173423
 -0.264708    -0.00660659  -0.011702      0.554872     1.09907    -0.238082     0.137662    0.0988087   0.37067      0.567334   -0.0756789   -0.0599386    0.543607   -0.37248      -0.22268     0.418635    0.198893      0.282854     0.116128    0.300688   -0.122183     0.572852   -0.196398    0.103748   -0.145622    -0.231066
 -0.0758173    0.279427     0.312355      0.107985    -0.126359    0.00704533  -0.332524    0.0805523   0.448509    -0.251897    0.269377    -0.447222    -0.350451    0.052044      0.364437    0.315885   -0.621176      0.180653     0.665841    0.376015    0.0448156    0.384396   -0.209118    0.112753   -0.0219515    0.343559
 -0.198907     0.168286     0.0164144    -0.100448    -0.373651   -0.0366172    0.0602827  -0.166653    0.133594    -0.390838    0.0491546    0.0702428   -0.0766838  -0.150642     -0.301014   -0.0741829   0.000856178  -0.104449    -0.31121    -0.253474   -0.104552    -0.241079    0.384826   -0.184037    0.119855     0.0917328
 -0.349934     0.442602    -0.519022      0.516027    -0.194305   -0.0859135   -0.0621321  -0.14816     0.461073     0.152137    0.739094     0.536135     0.418944   -0.0243021    -0.157704   -0.196564   -0.571064      0.1683      -0.712448   -0.065561    0.507895     0.178026   -0.378917    0.251789   -0.0995222   -0.237602
 -0.155136    -0.365512     0.585891      0.0369364   -0.342652    0.239598    -0.446771    0.136322    0.287234    -0.120767   -0.453772    -0.75906      0.115809   -0.158946      0.052903   -0.167276    0.663437     -0.183882     0.0241513   0.140244   -0.141453     0.0673016  -0.25927    -0.40063     0.0243862   -0.28383
 -0.646219    -0.353286     0.363866     -0.930236    -0.438553    0.206398    -0.509835   -0.182535    0.074366     0.0649119   0.458046     0.0716532   -0.605519    0.452786     -0.115908    0.393739   -0.24846      -0.00943491  -0.809071   -0.0464639   0.120708    -0.37339     0.396305   -0.267006   -0.312387     0.500934
 -0.064859    -0.409399    -0.0080284     0.306375    -0.0884301  -0.0751406    0.15882    -0.0407927  -0.723686    -0.35894     0.595471    -0.133649    -0.454607    0.178047      0.0950393  -0.138348   -0.461217     -0.052145     0.472266    0.0442727  -0.0559934   -0.503664    0.0514796  -0.283812   -0.167021     0.433896
 -0.327549     0.507175     0.138256     -0.185907     0.0358839   0.232543    -0.30521    -0.214947    0.339201     0.0492294  -0.496557     0.941792    -0.112112    0.198744     -0.0174688  -0.207       0.525692      0.157278    -0.65533    -0.0579655  -0.221448     0.601352   -0.0353919   0.261815    0.131279    -0.325674
 -0.0509259    0.0592947   -0.158074     -0.0928464    0.124209   -0.234478     0.0294083   0.29649     0.407234     0.146262   -0.209683    -0.0786799    0.319401   -0.181082     -0.172008    0.103061    0.530872     -0.129187    -0.449551   -0.0163828   0.00204857  -0.297883    0.056337   -0.166996   -0.3168      -0.707424
 -0.0918157   -0.466585     0.553936     -0.230764     0.569757   -0.201734     0.33989    -0.206241    0.135052    -0.343753    0.161773    -0.122357    -0.182716    0.309348      0.138124    0.815096    0.538688     -0.590386    -0.0476392   0.0388581   0.403666     0.537206   -0.304413    0.501921    0.267249    -0.70268
  0.552549    -0.419941     0.341781     -0.588913     0.0147687   0.463567     0.0873564  -0.129843   -0.624536    -0.450626   -0.61658     -0.921294    -0.175372   -0.0629425     0.234086    0.236685    0.508252     -0.144686     0.71523     0.0755602  -0.690523    -0.487527    0.468705   -0.440754   -0.058677     0.10613
  0.407872     0.629877    -0.399287     -0.596006     0.385945   -0.132181    -0.110705   -0.0637395   0.132667    -0.0317113  -0.531287    -0.00666784   0.34878    -0.323731     -0.0365864   0.0414592   0.25269      -0.368624    -0.148925   -0.421841   -0.179323     0.0600472   0.864307    0.245331    0.050133    -0.340752
  0.531487     0.139388    -0.156869      0.413258    -0.101132    0.567183     0.670434    0.569514   -0.308562    -0.217695   -0.118238     0.387887     0.288395   -0.142345      0.224878    0.771799    1.0624       -0.369767    -0.144538    0.031929   -0.670633    -0.229404   -0.194663    0.300077    0.027374    -0.188907
 -0.242946     0.189246    -0.149595      0.184712     0.0156195   0.274926    -0.105071    0.210928    0.071637     0.0720573  -0.20495      0.111817    -0.085678   -0.000102722   0.0433941  -0.470441    0.00127618    0.114192     0.219033    0.0603759   0.0103244    0.0814299  -0.2127      0.185325   -0.0602896    0.0980281
  0.414391     0.175431     0.073307      0.240599     0.0572437  -0.676673     0.398639   -0.542088   -0.0889042    0.184126    0.398276    -0.360952     0.253057   -0.659098     -0.426848    0.339558   -0.413148     -0.144021    -0.699298    0.45307    -0.786743    -0.0576944   0.29016     0.379762   -0.26975      0.8037
  0.0260811    0.33902      0.447964     -0.690456    -0.0378705   0.489072    -0.0290502   0.123084   -0.179347     0.630091    0.45509      0.108953     0.0822893  -0.211982     -0.262706   -0.0553527  -0.607296      0.496309     0.274688    0.450138   -0.305809     0.036583    0.371414   -0.528483    0.358395     0.249686
 -0.420787    -0.51065      0.344508      0.556988    -0.401175    0.0598614   -0.0604751   0.353447    0.239163     0.211862    0.605109     0.211842    -0.481376    0.406866     -0.219119    0.0446529   0.285439      0.365302    -0.257       0.364806    0.178565     0.157597   -0.784438   -0.235608   -0.188705     0.0799779
  0.376945    -0.166117     0.00549741    0.197472     0.0250969  -0.148036     0.0346341   0.165096    0.377728    -0.0990781  -0.00510289  -0.56558      0.47759    -0.0174095    -0.596656   -0.186791    0.192655     -0.39839      0.400477    0.353143    1.00978     -0.0477061   0.397793   -0.166532    0.00893533   0.0741803
  0.00140725   0.629792    -0.646402     -0.251617     0.281244    0.187812    -0.149256    0.0396748  -0.120289    -0.0822478   0.261552     0.186586    -0.519431    0.150343      0.235645   -0.142261   -0.082283      0.708922    -0.136448    0.402224   -0.0282343   -0.5637      0.608167    0.29867    -0.557863    -0.0943159
  0.296047     0.158674    -0.158198     -0.364085     0.371504    0.063493    -0.115871   -0.403636   -0.191248    -0.125819   -0.549489    -0.0700193    0.0103318  -0.0451735     0.231954    0.0239366   0.0509091    -0.232227     0.352238   -0.228347   -0.0521613    0.0648564   0.449468    0.240049    0.319604     0.0200715
  0.535996    -0.687708    -0.175597     -0.760621    -0.278348   -0.430974     0.835669   -0.0227185   0.0391798    0.486157   -0.0321265    0.317372     0.377732    0.26589       0.210413    0.414816    0.46369       0.469646    -0.56588    -0.247352    0.270606    -0.23343     0.29509    -0.122996   -0.31554     -0.344875
 -0.0676909   -0.533778    -0.627872      0.0628463    0.67293     0.435419     0.277724   -0.280595   -0.516771     0.100771   -0.169138     0.119861     0.559634    0.0496625     0.489108    0.236049   -0.600145     -0.282092     0.795712   -0.0710065   0.231591     0.0762632  -0.443994    0.381341    0.560435    -0.419672
 -0.44998      0.00990113  -0.13906       0.0759222    0.0301229   0.158389    -0.776274    0.300263   -0.00831368  -0.10023    -0.52448      0.100782    -0.344443    0.0106269     0.0149061  -0.902445   -0.00483111    0.158431     0.492677    0.106256    0.0739225    0.459753   -0.217473    0.0663451   0.553573     0.0228889
  0.754695    -0.0807997   -0.284685      0.199771    -0.544731    0.198735     0.0914748  -0.317901   -0.426616     0.296518   -0.453525     0.208812     0.19099    -0.0999172    -0.16912    -0.955755   -0.186029      0.187557    -0.0154575   0.261276    0.198173    -0.101168   -0.307472    0.102191   -0.0504022    0.597221
  0.137435    -0.140098     0.115234     -0.00159492   0.029294   -0.106238     0.0526419  -0.106078   -0.105604     0.0713052   0.176571    -0.115742    -0.0199821   0.0626279     0.0976566   0.245227   -0.0985049     0.0364761    0.106815    0.115063   -0.040345     0.0688752  -0.125185   -0.0498683  -0.0237028   -0.0264162
 -0.036043    -0.0685758   -0.608124      0.81944     -0.014336   -0.511697    -0.057217   -0.122109    0.140649    -0.488478   -0.484527    -0.0928822    0.282688   -0.00150438    0.208726   -0.239366    0.466107     -0.547954    -0.511981   -0.476742    0.226804    -0.0812036  -0.59599     0.557924   -0.530654    -0.339579
 -0.00859963  -0.232002     0.150195      0.216907    -0.0570804  -0.0396716    0.218554   -0.0262732   0.0369854    0.0586587   0.331763     0.00621502   0.0380362  -0.0497648    -0.0892217   0.247055   -0.0911629     0.103351    -0.135536    0.1538      0.105051    -0.16377    -0.115283   -0.142773   -0.202254    -0.00381816
 -0.251343     0.0436212   -0.000581635  -0.0900353    0.717347   -0.253916     0.128795    0.604408   -0.00746046   0.52895     0.201926    -0.112973    -0.428847    0.0497748     0.581198    0.113689    0.231302      0.150852     0.485847    0.0664434  -0.25883     -0.352283    0.0711702  -0.284684   -0.308321    -0.47151
 -0.118605     0.262051    -0.653229     -0.465874     0.130323   -0.0287229    0.177454    0.1295     -0.54318      0.159772    0.157586     0.418907     0.049574   -0.34906       0.265796    0.284147   -0.353704     -0.148253    -0.281705   -0.280703   -0.737888     0.486972   -0.253176    0.739712   -0.171591     0.0835341
 -0.00877966   0.183765     0.329464     -0.22757     -1.06918     0.283959     0.0203739  -0.513171   -0.0340143   -0.620841   -0.0778029    0.0902652    0.224872    0.0335745    -0.0392236  -0.0655211  -0.354567     -0.524705    -0.155968   -0.117145    0.198316     0.410435   -0.430435    0.0683279   0.516473    -0.0468722
 -0.209907    -0.940235     0.128184     -0.0270643    0.386057    0.146836     0.393678   -0.122871   -0.0559662    0.33763    -0.209248    -0.299077    -0.08266     0.360873     -0.886915   -0.215306   -0.0975147    -0.165207    -0.363985    0.109107   -0.0655049   -0.0135605   0.0329197  -0.342976    0.240129     0.172122[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409898
[ Info: iteration 2, average log likelihood -1.409889
[ Info: iteration 3, average log likelihood -1.409881
[ Info: iteration 4, average log likelihood -1.409872
[ Info: iteration 5, average log likelihood -1.409864
[ Info: iteration 6, average log likelihood -1.409857
[ Info: iteration 7, average log likelihood -1.409849
[ Info: iteration 8, average log likelihood -1.409842
[ Info: iteration 9, average log likelihood -1.409834
[ Info: iteration 10, average log likelihood -1.409827
┌ Info: EM with 100000 data points 10 iterations avll -1.409827
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
