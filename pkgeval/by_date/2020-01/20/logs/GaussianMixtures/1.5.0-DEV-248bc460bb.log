Julia Version 1.5.0-DEV.107
Commit 248bc460bb (2020-01-19 02:41 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed DataAPI ──────────── v1.1.0
 Installed Compat ───────────── v2.2.0
 Installed NearestNeighbors ─── v0.4.4
 Installed Parameters ───────── v0.12.0
 Installed BinDeps ──────────── v1.0.0
 Installed SpecialFunctions ─── v0.9.0
 Installed HDF5 ─────────────── v0.12.5
 Installed CMakeWrapper ─────── v0.2.3
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed OrderedCollections ─ v1.1.0
 Installed Arpack ───────────── v0.4.0
 Installed StatsFuns ────────── v0.9.3
 Installed Missings ─────────── v0.4.3
 Installed LegacyStrings ────── v0.4.1
 Installed BinaryProvider ───── v0.5.8
 Installed JLD ──────────────── v0.9.1
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed URIParser ────────── v0.4.0
 Installed StatsBase ────────── v0.32.0
 Installed Rmath ────────────── v0.6.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed DataStructures ───── v0.17.9
 Installed Blosc ────────────── v0.5.1
 Installed SortingAlgorithms ── v0.3.1
 Installed CMake ────────────── v1.1.2
 Installed StaticArrays ─────── v0.12.1
 Installed Distances ────────── v0.8.2
 Installed QuadGK ───────────── v2.3.1
 Installed FillArrays ───────── v0.8.4
 Installed Distributions ────── v0.22.3
 Installed Clustering ───────── v0.13.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed PDMats ───────────── v0.9.10
 Installed FileIO ───────────── v1.2.1
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_80vNIK/Project.toml`
 [no changes]
  Updating `/tmp/jl_80vNIK/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_CAgVof/Project.toml`
 [no changes]
  Updating `/tmp/jl_CAgVof/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_AQu7HH/Project.toml`
 [no changes]
  Updating `/tmp/jl_AQu7HH/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_yOAvIv/Project.toml`
 [no changes]
  Updating `/tmp/jl_yOAvIv/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_ap1WcD/Project.toml`
 [no changes]
  Updating `/tmp/jl_ap1WcD/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_ap1WcD/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -669278.6336505365, [90864.50925201093, 9135.490747989092], [9342.536840617675 -275.4660588263739 2443.5334950554193; -9291.517684349506 281.4766096248452 -2738.986197617282], [[87334.5953474005 1838.1029618431087 -282.62846809434086; 1838.1029618431091 95917.14065195729 1582.6527445788954; -282.6284680943408 1582.6527445788952 91279.63055995153], [12424.865922996694 -1883.0956697912434 -35.257189785686755; -1883.0956697912434 3744.504507836315 -1774.8851759621418; -35.257189785686776 -1774.8851759621418 8738.491633432606]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.243397e+03
      1       9.144999e+02      -3.288971e+02 |        7
      2       8.649572e+02      -4.954275e+01 |        0
      3       8.649572e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 864.9571905624039)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.078054
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.804537
[ Info: iteration 2, lowerbound -3.660247
[ Info: iteration 3, lowerbound -3.496574
[ Info: iteration 4, lowerbound -3.304976
[ Info: iteration 5, lowerbound -3.109714
[ Info: iteration 6, lowerbound -2.935142
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.781986
[ Info: iteration 8, lowerbound -2.653323
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.554880
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.475016
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.411693
[ Info: iteration 12, lowerbound -2.365585
[ Info: iteration 13, lowerbound -2.334346
[ Info: iteration 14, lowerbound -2.314124
[ Info: iteration 15, lowerbound -2.307399
[ Info: dropping number of Gaussions to 2
[ Info: iteration 16, lowerbound -2.302938
[ Info: iteration 17, lowerbound -2.299261
[ Info: iteration 18, lowerbound -2.299257
[ Info: iteration 19, lowerbound -2.299255
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Jan 21 04:14:13 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Jan 21 04:14:21 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Tue Jan 21 04:14:24 2020: EM with 272 data points 0 iterations avll -2.078054
5.8 data points per parameter
, Tue Jan 21 04:14:26 2020: GMM converted to Variational GMM
, Tue Jan 21 04:14:34 2020: iteration 1, lowerbound -3.804537
, Tue Jan 21 04:14:34 2020: iteration 2, lowerbound -3.660247
, Tue Jan 21 04:14:34 2020: iteration 3, lowerbound -3.496574
, Tue Jan 21 04:14:34 2020: iteration 4, lowerbound -3.304976
, Tue Jan 21 04:14:34 2020: iteration 5, lowerbound -3.109714
, Tue Jan 21 04:14:34 2020: iteration 6, lowerbound -2.935142
, Tue Jan 21 04:14:35 2020: dropping number of Gaussions to 6
, Tue Jan 21 04:14:35 2020: iteration 7, lowerbound -2.781986
, Tue Jan 21 04:14:35 2020: iteration 8, lowerbound -2.653323
, Tue Jan 21 04:14:35 2020: dropping number of Gaussions to 5
, Tue Jan 21 04:14:35 2020: iteration 9, lowerbound -2.554880
, Tue Jan 21 04:14:35 2020: dropping number of Gaussions to 4
, Tue Jan 21 04:14:35 2020: iteration 10, lowerbound -2.475016
, Tue Jan 21 04:14:35 2020: dropping number of Gaussions to 3
, Tue Jan 21 04:14:35 2020: iteration 11, lowerbound -2.411693
, Tue Jan 21 04:14:35 2020: iteration 12, lowerbound -2.365585
, Tue Jan 21 04:14:35 2020: iteration 13, lowerbound -2.334346
, Tue Jan 21 04:14:35 2020: iteration 14, lowerbound -2.314124
, Tue Jan 21 04:14:35 2020: iteration 15, lowerbound -2.307399
, Tue Jan 21 04:14:35 2020: dropping number of Gaussions to 2
, Tue Jan 21 04:14:35 2020: iteration 16, lowerbound -2.302938
, Tue Jan 21 04:14:35 2020: iteration 17, lowerbound -2.299261
, Tue Jan 21 04:14:35 2020: iteration 18, lowerbound -2.299257
, Tue Jan 21 04:14:35 2020: iteration 19, lowerbound -2.299255
, Tue Jan 21 04:14:35 2020: iteration 20, lowerbound -2.299254
, Tue Jan 21 04:14:35 2020: iteration 21, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 22, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 23, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 24, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 25, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 26, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 27, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 28, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 29, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 30, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 31, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 32, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 33, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 34, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 35, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 36, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 37, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 38, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 39, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 40, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 41, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 42, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 43, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 44, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 45, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 46, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 47, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 48, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 49, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: iteration 50, lowerbound -2.299253
, Tue Jan 21 04:14:35 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601388, 95.95490777398618]
β = [178.04509222601388, 95.95490777398618]
m = [4.250300733269908 79.28686694436182; 2.000229257775371 53.8519871724613]
ν = [180.04509222601388, 97.95490777398618]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554748428 -0.007644049042327385; 0.0 0.008581705166333308], [0.37587636119484036 -0.008953123827345958; 0.0 0.01274866477740938]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -0.9539160359949085
avll from llpg:  -0.9539160359948857
avll direct:     -0.9539160359948858
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.987828262128355
avll from llpg:  -0.9878282621283552
avll direct:     -0.9878282621283552
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.145507   -0.0270745    0.0723574    0.121658      0.0734075    0.147224    -0.199036     0.181115     0.00918638    0.0198607   -0.0749332    0.053542    -0.0128504    0.0918821    0.0103304     0.0366223    -0.0136216    0.0103652     0.0148393  -0.287059     -0.021919    -0.074342      0.0201664   -0.0123885    0.113041    -0.145215
  0.11956     0.0158505    0.0983139   -0.0373037    -0.0606022   -0.133013    -0.0224493   -0.0468845   -0.0851148     0.16371     -0.163061     0.108139     0.0303717   -0.195235     0.160106     -0.120423     -0.0343496    0.178871      0.29503     0.162867     -0.0401647    0.0521044     0.116736     0.0108361   -0.0544224    0.201589
 -0.0242651  -0.0783299   -0.0682837    0.075418      0.142811    -0.0654496    0.156844    -0.031606     0.0290534    -0.0736728    0.0945525   -0.0349024    0.0696814    0.0480415    0.0790713     0.0253507    -0.0990937    0.00217176    0.0860688  -0.0131712    -0.191329     0.0850851    -0.1156       0.115107    -0.233651     0.0818599
 -0.0576866   0.0348896    0.104628    -0.130871      0.029856     0.127284     0.0501007    0.0843938   -0.0035222    -0.188308    -0.055226     0.0733072    0.0388918   -0.139797     0.116719      0.0146385     0.0184205    0.000191114  -0.0433879  -0.000812859  -0.201948     0.244375     -0.120359    -0.0643319   -0.00134012   0.0389418
 -0.112945   -0.178551    -0.0424847    0.0520504     0.057451     0.081006    -0.0420443   -0.011138    -0.00531922    0.0439313   -0.00502548  -0.0638884   -0.151101     0.0665339   -0.0608945    -0.164827      0.0493094    0.0614747    -0.0135582  -0.0698838     0.0349126   -0.0816284     0.14222     -0.085875     0.0214043   -0.114298
  0.0235956   0.136572    -0.100475    -0.0625415     0.0987608    0.117266    -0.080438     0.109023     0.0722372     0.0238229   -0.0266879    2.9504e-5    0.110444    -0.0989321   -0.000754515   0.0319393    -0.122841    -0.0259944     0.165564    0.120525     -0.00116701  -0.029835     -0.0219104    0.125995    -0.0227148   -0.019987
  0.0796881  -0.00768706  -0.0347382   -0.125585      0.00400263   0.00146447  -0.00446991   0.10711      0.0965409    -0.0877481   -0.0230064    0.05754     -0.139965    -0.0500426    0.0967076    -0.20007      -0.119928     0.00850186   -0.0513897   0.00731714    0.0168541    0.136609     -0.0977696    0.0582797   -0.0319116    0.0155101
 -0.0269695   0.121492    -0.0674451   -0.0408199     0.172072    -0.0795402    0.010753     0.156039     0.0399411     0.0360711   -0.0930558   -0.00627793   0.177973     0.0171221    0.00366673    0.137551     -0.169829     0.155914     -0.0582293   0.143889      0.0601276   -0.182738     -0.0153663   -0.151875     0.108169     0.16289
  0.053241   -0.104808     0.0423839   -0.0191422    -0.0373171    0.0682689    0.108964     0.0920096   -0.00381024   -0.00758319  -0.0767305    0.0521882   -0.126352    -0.0952728    0.128766      0.0829215     0.0678473   -0.110061      0.002326   -0.0782325     0.152755     0.124338      0.0345977   -0.0530316   -0.0199309   -0.0972947
  0.0796065   0.00337096   0.033402     0.0901987    -0.110797     0.115155     0.155864     0.185389     0.119226      0.0193759   -0.00189531  -0.0374127    0.0155182    0.0801776   -0.0359398    -0.0104676    -0.00635231  -0.0113809    -0.167505   -0.0474194    -0.120715     0.165312     -0.023788     0.0222407    0.0559424    0.0550405
 -0.15447     0.197881     0.09412     -0.0223765    -0.108877     0.101048     0.0307982    0.0337203   -0.0247948     0.0535076   -0.0716866   -0.0556668   -0.00626822   0.022462     0.0446994     0.0340747     0.0727422    0.219007      0.210886    0.0140778    -0.0130982   -0.0917955    -0.1202       0.0182797   -0.0979246   -0.0536327
 -0.0616063  -0.0406424   -0.110326     0.0807647    -0.0304248    0.00897739   0.0675791   -0.0828753    0.00547143   -0.0329787   -0.0846306   -0.144556    -0.00805115  -0.00540196   0.0284021    -0.129597      0.121606    -0.136117      0.219489    0.0283081     0.0470641    0.138879      0.0505792    0.0106442    0.0875158    0.0748949
  0.196685    0.015518    -0.0523267    0.150555     -0.099186    -0.098621    -0.0839313    0.0789115   -0.168344      0.0356455    0.163119    -0.0161903    0.109943    -0.131261    -0.052927     -0.0756515    -0.0985677   -0.0902795     0.176459   -0.0248287     0.0764129   -0.0430195     0.0784997    0.0491968    0.171518     0.148808
 -0.150758   -0.0117993   -0.0854373   -0.028047      0.213671     0.0267891    0.0775461   -0.0758216   -0.0133944    -0.157111     0.00708666   0.115433    -0.0810313   -0.0911428    0.125656      0.290563     -0.0308448   -0.00260285    0.0176417  -0.0226187    -0.0140221   -0.0979944    -0.0845606   -0.0614055   -0.13695     -0.00323342
 -0.326358    0.00590598   0.140124    -0.184014      0.00194287  -0.00955483   0.0400751   -0.0415321    0.100654     -0.0358323    0.0178027    0.226155     0.0517676    0.0777138    0.158049     -0.0889906     0.065914     0.208731     -0.124967   -0.0125661     0.143285     0.0391285     0.13435      0.0174879    0.149887     0.0360778
 -0.101706   -0.0517461   -0.0145428    0.123495     -0.0266529    0.0192169   -0.0279683    0.0773458   -0.0876628     0.0589031   -0.0741847    0.0947172    0.0534974   -0.224749     0.00861106    0.108299     -0.035777     0.077685     -0.0197643   0.103816      0.268963     0.0787126     0.0546715   -0.0862776    0.0637992   -0.0540293
  0.0550866  -0.0935074   -0.113232     0.113439      0.0234944    0.117676     0.195568    -0.029305     0.0915884    -0.11343     -0.155054     0.00501093  -0.110292     0.0402741    0.163902      0.0996829    -0.117143     0.132517     -0.086268    0.10189       0.0295313    0.0386221     0.0202926   -0.0579555    0.0231      -0.127296
  0.189494    0.0394165    0.00588013   0.0513662    -0.0088074   -0.0169566    0.0640124   -0.0162437   -0.0526145     0.161863     0.127271     0.108972     0.188425    -0.0498895    0.0537651    -0.000115083  -0.00820343  -0.0543103    -0.147221   -0.00988489   -0.14089     -0.0976302    -0.296599     0.107097     0.0271608   -0.0295655
 -0.122976   -0.0700455   -0.017334     0.177712     -0.00604832  -0.0474782    0.0056321    0.0739555   -0.00785054   -0.0492732   -0.0528411   -0.00618963   0.0626865   -0.117732     0.157466     -0.0797353     0.051922     0.108651      0.0159683  -0.127247     -0.0704904   -0.0622587     0.0659474   -0.0450561   -0.152257     0.116812
 -0.112538   -0.0498564   -0.00956308   0.0885789     0.0850534    0.0907984    0.0129992   -0.143877    -0.0169888     0.03193     -0.0636917   -0.132529    -0.046155    -0.0554343    0.0094258     0.286133     -0.0257592    0.100398      0.0290304  -0.0422103     0.1641       0.0175326    -0.0311101   -0.0368748   -0.00938783  -0.0363714
 -0.0370021  -0.0286524   -0.0721559   -0.0391735     0.0608133    0.0831221   -0.170591     0.103613     0.0173374    -0.107797     0.301459    -0.0322761    0.10518      0.121291     0.0866879    -0.0337168    -0.022182    -0.035681     -0.145801    0.0714103     0.0556776   -0.235782     -0.0282664    0.0490535    0.0846257   -0.00997508
  0.04299     0.0497069    0.00316149   0.000325234   0.0730139    0.102703    -0.0606232   -0.0564554   -0.02512      -0.0291241    0.0273909    0.0842894    0.1508      -0.0291612   -0.108867     -0.0921204    -0.131771     0.0635175     0.0869375  -0.204588     -0.123788     0.0242283     0.00305355   0.139182     0.27172      0.125243
 -0.0978401  -0.0437794   -0.0143029    0.215048      0.0673552   -0.0167177   -0.150799    -0.0229658    0.126481      0.150288    -0.191489    -0.0444541    0.0658525   -0.0600114    0.0660748    -0.0031559     0.124198    -0.0334965    -0.0568519  -0.0152799    -0.100563     0.0239263    -0.0131494    0.00173066   0.201206     0.0918298
  0.0925882   0.0251307   -0.0268364    0.100263      0.00706808  -0.0518926    0.0994953    0.00324999  -0.17106      -0.047007     0.0639418   -0.00922437   0.277937     0.100212    -0.0873955    -0.122781     -0.0431728   -0.0946572    -0.0515684  -0.0384605    -0.0552329    0.0431785    -0.0323476    0.0404826   -0.232235     0.125059
 -0.0838989  -0.066893    -0.12368     -0.0993885     0.0236842   -0.0943781   -0.034651    -0.121833    -0.275605     -0.181871     0.118391    -0.188784     0.169288    -0.169317    -0.122515      0.0744951    -0.0676551    0.0483082    -0.0344602  -0.0209492    -0.0149505    0.0212095     0.0178136   -0.0439303   -0.0547892    0.0186446
  0.03265     0.106788    -0.00369957  -0.0327039    -0.126866    -0.294963    -0.0433852    0.101883     0.149458     -0.0109632   -0.113792    -0.0161444    0.107084    -0.184644     0.0606759     0.0693738    -0.0570067   -0.179172      0.20476    -0.11446       0.0231621   -0.0377505    -0.124089    -0.0764857    0.0956571    0.104482
 -0.0361595  -0.14802      0.00900095   0.0170832    -0.0699973   -0.160628     0.110538     0.129021     0.0956653    -0.128601    -0.0382487    0.028419    -0.0506831   -0.191664     0.0454436     0.0383077     0.123308    -0.0595265    -0.0675169   0.111305     -0.0732401    0.0373945     0.0741611    0.0236421   -0.0195297    0.0744323
  0.163715    0.0937533   -0.00931532   0.0182502     0.00693526   0.112311    -0.305581    -0.115327    -0.0672069    -0.00661683   0.0629958   -0.0446782   -0.108475     0.0270045    0.0773142     0.017538     -0.0411402    0.0836917    -0.0653821   0.022287     -0.0223639    0.000849713   0.0232487   -0.0250858   -0.0232731   -0.0139219
  0.0947292   0.324056    -0.135297    -0.0199978     0.0611952   -0.181479    -0.0163371    0.0774366   -0.242702     -0.137598    -0.0270813   -0.128953    -0.198909     0.10572     -0.0161426     0.0382598     0.0449815   -0.0307945     0.123329   -0.111094     -0.129462    -0.0207885     0.00908282   0.192154     0.00214646   0.0728965
 -0.049119   -0.118484    -0.173759    -0.0746785    -0.0717305    0.0259667    0.179365    -0.1129       0.000497244   0.0486805    0.188946     0.0414302    0.165454     0.020821    -0.0338737    -0.0900562     0.141666    -0.0337053     0.0591555   0.0757943     0.13289     -0.0667486     0.0369015   -0.0315255    0.134018    -0.079283
  0.176032    0.0509065   -0.0334677   -0.180134      0.0896687   -0.073547    -0.177745     0.0722016   -0.127748      0.0350403    0.0239794   -0.00913171   0.0110185   -0.0614579    0.0782601    -0.0950186    -0.00760304   0.0283025    -0.087025    0.067696      0.00300642  -0.0551173    -0.21238     -0.0588697   -0.00242484   0.0264248
 -0.0644307  -0.117522    -0.0875208    0.111481     -0.00916693  -0.0287769    0.0832283    0.0511673   -0.0284213    -0.167457    -0.0919055   -0.0904388   -0.172251     0.0462482   -0.153625     -0.0390118     0.0467831   -0.0128034    -0.125742   -0.0325448    -0.0281802    0.152681      0.0221956   -0.00929069  -0.0451076    0.0268087kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.415924230951938
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415994
[ Info: iteration 2, average log likelihood -1.415910
[ Info: iteration 3, average log likelihood -1.415076
[ Info: iteration 4, average log likelihood -1.406499
[ Info: iteration 5, average log likelihood -1.388272
[ Info: iteration 6, average log likelihood -1.382786
[ Info: iteration 7, average log likelihood -1.381882
[ Info: iteration 8, average log likelihood -1.381513
[ Info: iteration 9, average log likelihood -1.381325
[ Info: iteration 10, average log likelihood -1.381220
[ Info: iteration 11, average log likelihood -1.381153
[ Info: iteration 12, average log likelihood -1.381107
[ Info: iteration 13, average log likelihood -1.381074
[ Info: iteration 14, average log likelihood -1.381050
[ Info: iteration 15, average log likelihood -1.381031
[ Info: iteration 16, average log likelihood -1.381016
[ Info: iteration 17, average log likelihood -1.381004
[ Info: iteration 18, average log likelihood -1.380993
[ Info: iteration 19, average log likelihood -1.380984
[ Info: iteration 20, average log likelihood -1.380976
[ Info: iteration 21, average log likelihood -1.380968
[ Info: iteration 22, average log likelihood -1.380961
[ Info: iteration 23, average log likelihood -1.380955
[ Info: iteration 24, average log likelihood -1.380949
[ Info: iteration 25, average log likelihood -1.380944
[ Info: iteration 26, average log likelihood -1.380939
[ Info: iteration 27, average log likelihood -1.380934
[ Info: iteration 28, average log likelihood -1.380930
[ Info: iteration 29, average log likelihood -1.380927
[ Info: iteration 30, average log likelihood -1.380923
[ Info: iteration 31, average log likelihood -1.380920
[ Info: iteration 32, average log likelihood -1.380916
[ Info: iteration 33, average log likelihood -1.380913
[ Info: iteration 34, average log likelihood -1.380910
[ Info: iteration 35, average log likelihood -1.380906
[ Info: iteration 36, average log likelihood -1.380902
[ Info: iteration 37, average log likelihood -1.380898
[ Info: iteration 38, average log likelihood -1.380894
[ Info: iteration 39, average log likelihood -1.380889
[ Info: iteration 40, average log likelihood -1.380883
[ Info: iteration 41, average log likelihood -1.380877
[ Info: iteration 42, average log likelihood -1.380870
[ Info: iteration 43, average log likelihood -1.380863
[ Info: iteration 44, average log likelihood -1.380854
[ Info: iteration 45, average log likelihood -1.380843
[ Info: iteration 46, average log likelihood -1.380832
[ Info: iteration 47, average log likelihood -1.380819
[ Info: iteration 48, average log likelihood -1.380805
[ Info: iteration 49, average log likelihood -1.380789
[ Info: iteration 50, average log likelihood -1.380772
┌ Info: EM with 100000 data points 50 iterations avll -1.380772
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4159942508670604
│     -1.4159103809315416
│      ⋮
└     -1.3807721216527957
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.380870
[ Info: iteration 2, average log likelihood -1.380734
[ Info: iteration 3, average log likelihood -1.380095
[ Info: iteration 4, average log likelihood -1.374882
[ Info: iteration 5, average log likelihood -1.362269
[ Info: iteration 6, average log likelihood -1.351661
[ Info: iteration 7, average log likelihood -1.345716
[ Info: iteration 8, average log likelihood -1.342465
[ Info: iteration 9, average log likelihood -1.340390
[ Info: iteration 10, average log likelihood -1.339134
[ Info: iteration 11, average log likelihood -1.338394
[ Info: iteration 12, average log likelihood -1.337900
[ Info: iteration 13, average log likelihood -1.337509
[ Info: iteration 14, average log likelihood -1.337182
[ Info: iteration 15, average log likelihood -1.336928
[ Info: iteration 16, average log likelihood -1.336741
[ Info: iteration 17, average log likelihood -1.336607
[ Info: iteration 18, average log likelihood -1.336515
[ Info: iteration 19, average log likelihood -1.336453
[ Info: iteration 20, average log likelihood -1.336412
[ Info: iteration 21, average log likelihood -1.336382
[ Info: iteration 22, average log likelihood -1.336361
[ Info: iteration 23, average log likelihood -1.336345
[ Info: iteration 24, average log likelihood -1.336331
[ Info: iteration 25, average log likelihood -1.336319
[ Info: iteration 26, average log likelihood -1.336309
[ Info: iteration 27, average log likelihood -1.336299
[ Info: iteration 28, average log likelihood -1.336290
[ Info: iteration 29, average log likelihood -1.336282
[ Info: iteration 30, average log likelihood -1.336274
[ Info: iteration 31, average log likelihood -1.336267
[ Info: iteration 32, average log likelihood -1.336260
[ Info: iteration 33, average log likelihood -1.336253
[ Info: iteration 34, average log likelihood -1.336246
[ Info: iteration 35, average log likelihood -1.336240
[ Info: iteration 36, average log likelihood -1.336234
[ Info: iteration 37, average log likelihood -1.336229
[ Info: iteration 38, average log likelihood -1.336223
[ Info: iteration 39, average log likelihood -1.336218
[ Info: iteration 40, average log likelihood -1.336213
[ Info: iteration 41, average log likelihood -1.336208
[ Info: iteration 42, average log likelihood -1.336203
[ Info: iteration 43, average log likelihood -1.336198
[ Info: iteration 44, average log likelihood -1.336194
[ Info: iteration 45, average log likelihood -1.336189
[ Info: iteration 46, average log likelihood -1.336185
[ Info: iteration 47, average log likelihood -1.336181
[ Info: iteration 48, average log likelihood -1.336176
[ Info: iteration 49, average log likelihood -1.336173
[ Info: iteration 50, average log likelihood -1.336169
┌ Info: EM with 100000 data points 50 iterations avll -1.336169
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3808697636662328
│     -1.3807339834292118
│      ⋮
└     -1.3361689748392727
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.336362
[ Info: iteration 2, average log likelihood -1.336163
[ Info: iteration 3, average log likelihood -1.335521
[ Info: iteration 4, average log likelihood -1.330050
[ Info: iteration 5, average log likelihood -1.314778
[ Info: iteration 6, average log likelihood -1.300765
[ Info: iteration 7, average log likelihood -1.292919
[ Info: iteration 8, average log likelihood -1.288571
[ Info: iteration 9, average log likelihood -1.285993
[ Info: iteration 10, average log likelihood -1.284070
[ Info: iteration 11, average log likelihood -1.282494
[ Info: iteration 12, average log likelihood -1.281205
[ Info: iteration 13, average log likelihood -1.280102
[ Info: iteration 14, average log likelihood -1.279101
[ Info: iteration 15, average log likelihood -1.278288
[ Info: iteration 16, average log likelihood -1.277660
[ Info: iteration 17, average log likelihood -1.277129
[ Info: iteration 18, average log likelihood -1.276637
[ Info: iteration 19, average log likelihood -1.276182
[ Info: iteration 20, average log likelihood -1.275783
[ Info: iteration 21, average log likelihood -1.275407
[ Info: iteration 22, average log likelihood -1.274984
[ Info: iteration 23, average log likelihood -1.274369
[ Info: iteration 24, average log likelihood -1.273200
[ Info: iteration 25, average log likelihood -1.270623
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.266143
[ Info: iteration 27, average log likelihood -1.282450
[ Info: iteration 28, average log likelihood -1.276085
[ Info: iteration 29, average log likelihood -1.273703
[ Info: iteration 30, average log likelihood -1.271635
[ Info: iteration 31, average log likelihood -1.268414
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.263869
[ Info: iteration 33, average log likelihood -1.281599
[ Info: iteration 34, average log likelihood -1.275526
[ Info: iteration 35, average log likelihood -1.273302
[ Info: iteration 36, average log likelihood -1.271211
[ Info: iteration 37, average log likelihood -1.268014
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.263439
[ Info: iteration 39, average log likelihood -1.280622
[ Info: iteration 40, average log likelihood -1.274840
[ Info: iteration 41, average log likelihood -1.272805
[ Info: iteration 42, average log likelihood -1.270866
[ Info: iteration 43, average log likelihood -1.268176
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.264027
[ Info: iteration 45, average log likelihood -1.278675
[ Info: iteration 46, average log likelihood -1.273332
[ Info: iteration 47, average log likelihood -1.271848
[ Info: iteration 48, average log likelihood -1.270593
[ Info: iteration 49, average log likelihood -1.269048
[ Info: iteration 50, average log likelihood -1.266842
┌ Info: EM with 100000 data points 50 iterations avll -1.266842
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.336361626152813
│     -1.336163038137346
│      ⋮
└     -1.2668418248783422
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.263154
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.262858
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.261559
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.248054
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.214354
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.192283
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.195353
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.181438
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.170878
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.180194
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.185743
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.174644
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.183200
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.173807
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.166578
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.190744
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.177636
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.170048
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.180259
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.171060
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.164273
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.190502
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.177415
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.169916
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.180138
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.170905
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.178190
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.184521
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.174399
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.167912
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.178474
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.169113
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.178219
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.184508
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.174320
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.167771
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.178301
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.183021
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.172588
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.181822
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.172771
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.166105
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.176590
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.183040
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.172576
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.181748
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.172641
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.165947
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.190482
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.177429
┌ Info: EM with 100000 data points 50 iterations avll -1.177429
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2631538526667256
│     -1.262857568220244
│      ⋮
└     -1.1774286535052279
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.170227
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.168277
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.165599
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.157525
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.140829
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│     22
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.110550
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.099112
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│     22
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.098714
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.088984
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.083550
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.081760
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.089297
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.083590
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.091271
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.075463
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.078201
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.083051
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│     22
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.089419
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.076593
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│     22
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.087505
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.078401
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.078983
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.087584
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.083009
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.078365
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.087825
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.072421
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.085320
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.088623
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│     22
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.083324
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.072323
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.084607
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.086056
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.083573
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.081169
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.079216
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.075748
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.095523
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.077776
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.079350
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.084571
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.080720
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.079970
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│     22
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.089123
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.079738
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.079782
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.078522
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│      ⋮
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.086873
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.081119
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.089515
┌ Info: EM with 100000 data points 50 iterations avll -1.089515
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1702272081536778
│     -1.1682771544236445
│      ⋮
└     -1.0895145537899815
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.415924230951938
│     -1.4159942508670604
│     -1.4159103809315416
│     -1.415076178488095
│      ⋮
│     -1.0868726421358375
│     -1.0811194940909872
└     -1.0895145537899815
32×26 Array{Float64,2}:
  0.193924     0.030174     0.00938948    0.0522895  -0.0144992     0.0059896    0.0696217    -0.0171989   -0.00938074   0.164191     0.120977     0.117149      0.186526   -0.0510746    0.0619888    0.00272891  -0.0165883   -0.0573049   -0.143002   -0.0151296  -0.0685143   -0.101933    -0.295036     0.119466      0.0284916   -0.0111485
  0.018655    -0.0817069    0.0430405     0.0511617  -0.0694677    -0.024306     0.132258      0.154889     0.104524    -0.0413493   -0.0303769   -0.00767678   -0.0143367  -0.0468241    0.00588664   0.0290491    0.0465749   -0.0405339   -0.11007     0.0264477  -0.0894921    0.100848     0.0170668    0.0304121     0.0258825    0.0652276
  0.0380564    0.073397    -0.0128175    -0.0303027  -0.139435     -0.292944    -0.0705593     0.10558      0.156569     0.0161218   -0.11272     -0.0169152     0.116914   -0.18341      0.0545656    0.0762252   -0.0432627   -0.177246     0.194626   -0.133073    0.0668659   -0.100159    -0.126477    -0.0714242     0.0919675    0.109277
 -0.111802    -0.091168    -0.00625407    0.0933249   0.0901425     0.0641002    0.00896689   -0.136047    -0.00033964   0.0334923   -0.0744973   -0.132204     -0.0466571  -0.0377609    0.0082751    0.301055    -0.0193664    0.0996987    0.0534406  -0.0465711   0.169818     0.0175473   -0.0111945    0.010338     -0.0575588   -0.11212
  0.172266     0.050648    -0.0374212    -0.581296    0.122411     -0.0735458   -0.175763      0.0647551   -0.129704     0.0542551   -0.0347415    0.00379692   -0.0392925  -0.0469723    0.0474511   -0.0496351   -0.00673146  -0.0396256   -0.0894765   0.168291   -0.0207676   -0.0429562   -0.209988     0.240914      0.00265747   0.0868264
  0.173551     0.0507558   -0.0242656     0.20269     0.0979552    -0.0733196   -0.175658      0.0797549   -0.121524     0.0119129    0.0469235   -0.0042995     0.0761863  -0.0910512    0.0753628   -0.155251    -0.00702092   0.0197667   -0.0915081   0.0613751  -0.00822961  -0.0514136   -0.222168    -0.252967      0.00903125   0.0103936
 -0.0601059    0.00326917  -0.075068      0.137841    0.120017      0.0436877   -0.180054      0.0998203   -0.0210992   -0.121351     0.325842    -0.0241115     0.105761    0.118554    -0.989152    -0.0044383   -0.0161006   -0.0174321   -0.152755    0.06678     0.0673347   -0.237157    -0.0469059    0.0204261     0.0071946   -0.019174
 -0.0395833   -0.0550202   -0.0628018    -0.232157   -0.00931507    0.108493    -0.157396      0.112681     0.027691    -0.0859971    0.282514    -0.044201      0.0951063   0.120746     1.1027      -0.0604432   -0.0624789   -0.0651961   -0.141041    0.0665494   0.0520462   -0.236861    -0.0653287    0.00713218    0.172665     0.0434496
 -0.0623407   -0.119163    -0.081574      0.098479    0.00305592   -0.0333077    0.072678      0.0563011   -0.0661389   -0.165924    -0.100321    -0.081553     -0.193792    0.0443453   -0.1132      -0.0453073    0.0815885   -0.0121396   -0.139719   -0.0284939  -0.0361398    0.15052      0.0180321   -0.0263161    -0.0308535    0.0481836
 -0.127481    -0.0431186    0.0321046     0.172562    0.0742806     0.0533161   -0.172861      0.0958916    0.057091     0.0819082   -0.13246      0.000765158   0.0357243  -0.00696949   0.043356     0.0360058    0.0440723   -0.0174442   -0.0304845  -0.17977    -0.0590993   -0.0187884    0.0205851   -0.000973556   0.196776    -0.027711
  0.151155     0.0951061   -0.00553439   -0.0917797  -0.0266932     0.0526035   -0.239027     -0.117557     0.00790248   0.105667     0.0560068   -0.0635196    -0.22581    -0.00384916   0.0689891   -0.0328482   -0.050512     0.10966     -0.0691248  -0.34673    -0.0660541    0.0550613    0.073856    -0.0566327    -0.0323138    0.00847012
  0.175055     0.0897094   -0.0100942     0.0617095   0.0476244     0.14642     -0.376549     -0.109829     0.00708132  -0.11309      0.0620164   -0.00734301   -0.0199194   0.033207     0.0812818    0.151126    -0.0536638    0.0508579    0.0601552   0.335242    0.0502295   -0.032899    -0.026825    -0.0201664    -0.0125832   -0.0239252
 -0.326147     0.0425427    0.119038     -0.152508    0.00668959   -0.01468      0.0261784    -0.0366005    0.0991347   -0.00781032   0.0206745    0.229558      0.0570049   0.0519193    0.151341    -0.0964948    0.0743043    0.192184    -0.163188    0.0208111   0.200464     0.0384904    0.13731      0.0316316     0.151523     0.0410406
 -0.00705204  -0.0357817   -0.0392577     0.144996   -0.0103403    -0.0292977    0.0346048     0.042343    -0.136371     0.0085855   -0.00189507   0.0513684     0.163607   -0.0480608   -0.0435307    0.00115415  -0.0495824   -0.0355796   -0.0422225   0.0354552   0.114958     0.0882313    0.00687403  -0.0140488    -0.074429     0.0346989
  0.00170854  -0.0919082    0.0829252     0.0700143   0.225095     -0.109851    -0.0263213    -0.082455    -0.00421434  -0.0773683    0.0884337   -0.084488      0.0781706   0.0193684    0.102053    -0.0320778    0.0284917    0.00281111   0.0965789  -0.0616045  -0.163227     0.0172657   -0.131167    -0.0983182    -0.249401     0.0579074
 -0.0133067   -0.0586826   -0.184029      0.0516296   0.0451532    -0.0177642    0.182454      0.0131076    0.0556403   -0.0716255    0.0984514    0.0105292     0.0696173   0.101571     0.0567864    0.0027867   -0.26367      0.0694668    0.150217   -0.014976   -0.231032     0.191674    -0.104203     0.287994     -0.152805     0.102691
  0.106954     0.100415    -0.0678111    -0.0318483   0.163282     -0.0752277   -0.0239751     0.0346225    0.046344     0.0418181   -0.0939714   -0.0102384     0.184148    0.00832315  -0.0170196    0.127204    -0.183635     0.140615    -0.0725508   0.154366   -1.11089     -0.118969    -0.0281202   -0.162608      0.0890326    0.159425
 -0.13497      0.125961    -0.0676302    -0.0496975   0.180411     -0.0395775    0.0168043     0.257771     0.0314865    0.0385787   -0.0886935   -0.00444287    0.176003    0.00727594   0.0213994    0.14515     -0.166916     0.123828    -0.0611495   0.18334     1.23343     -0.217023    -0.065888    -0.140467      0.138763     0.165538
 -0.0534811   -0.00456696  -0.0740326    -0.0467335   0.0517575     0.00230813  -0.0593838    -0.0969351   -0.161923    -0.0964673    0.0737495   -0.0230388     0.161549   -0.102242    -0.115767    -0.00649207  -0.114835     0.0503455    0.0256726  -0.107614   -0.0693822    0.00832183   0.00955345   0.0436135     0.115724     0.0623089
 -0.0331818    0.0738384    0.000575315  -0.0901235   0.0301344     0.0548768   -0.0183639     0.119004     0.0448955   -0.0707516   -0.0386434    0.0174288     0.077725   -0.143401     0.0685065    0.0308777   -0.0382691   -0.0248974    0.0788267   0.0205429  -0.0768974    0.0876391   -0.0591688    0.0281156    -0.00808186   0.0217189
 -0.107972    -0.140171    -0.106775      0.0329253   0.0415365     0.0122774   -0.063389      0.248169    -0.0581323    0.0434141   -0.257262    -0.0194205    -0.150696    0.0666953   -0.41635     -0.689939     0.301102     0.0257437   -0.0146291  -0.0716464   0.325768    -0.103533    -0.168765    -0.0844861     0.0101994   -0.108212
 -0.118213    -0.183404     0.0100202     0.0470939   0.0432775     0.0887885   -0.024081     -0.38453     -0.00660704   0.0446805   -0.265902    -0.0910091    -0.150505    0.0660857    0.0500251   -0.0114689    0.0195681    0.276       -0.0155565  -0.0715932  -0.118477    -0.0744899   -0.174933    -0.0868614     0.0207049   -0.115873
 -0.118195    -0.182298    -0.127028      0.0604894   0.0686215     0.147995    -0.0406875    -0.17164     -0.0252557    0.0442536    0.544935    -0.133803     -0.150379    0.0662546   -0.323017    -0.21107      0.0132247   -0.246636    -0.0154524  -0.0775103  -0.573456    -0.0722357    0.254988    -0.0841278     0.0185842   -0.109986
 -0.109168    -0.225667     0.0350012     0.0804638   0.0731909     0.0427802   -0.00179979    0.235562     0.0307838    0.044749     0.0174015   -0.0199946    -0.150168    0.0664527    0.109946     0.253093     0.00757741   0.113958    -0.0162784  -0.0727096   0.351942    -0.0565038    0.530607    -0.0879246     0.0381449   -0.120965
  0.156165    -0.0514307   -0.0092428     0.0773913  -0.057995     -0.0211233   -0.0190907     0.0696621   -0.0919326    0.0196767    0.058194     0.0206913     0.0243082  -0.13158      0.0297475    0.00401272  -0.0192603   -0.100159     0.0848762  -0.0452089   0.105759     0.0336284    0.0590078   -0.000697703   0.0739292    0.038296
  0.0920388    0.288529    -0.108959     -0.027052    0.0448123    -0.163353    -0.000241297   0.099412    -0.192164    -0.138791    -0.035081    -0.0740206    -0.20198     0.0755879    0.0226742    0.0449176    0.0183532   -0.0357466    0.0960642  -0.153485   -0.0956232    0.0377656    0.00832437   0.16038       0.00316001   0.0512582
 -0.0252076   -0.0828955   -0.0664213     0.123642   -0.000287554   0.030133     0.0945331     0.00714178   0.0464798   -0.0898212   -0.0990429    0.000536745  -0.0174647  -0.0462655    0.162304     0.00694506  -0.0453599    0.103186    -0.0339817  -0.0168738  -0.0220265   -0.01761      0.0258507   -0.0513706    -0.0739296   -0.0269862
  0.112641     0.012014     0.0914411    -0.0434311  -0.0576186    -0.102665    -0.0292547    -0.0142758   -0.0827552    0.153655    -0.162158     0.0993789     0.0742853  -0.187268     0.16836     -0.11063      0.021752     0.163879     0.246389    0.158073   -0.0437956    0.0781361    0.111293     0.0245942    -0.0546368    0.202333
 -0.0646525   -0.0598794   -0.119102      0.0899591  -0.0291059     0.0258034    0.0767389    -0.082641     0.00968572  -0.0319498   -0.129389    -0.160583     -0.0531231  -0.0170614    0.0262671   -0.116096     0.112858    -0.137688     0.215934    0.0246294   0.0374655    0.160493     0.0462533    0.0139121     0.0612979    0.0837603
 -0.111863     0.0458869   -0.0235253    -0.0397328  -0.0944567     0.0641438    0.0834569    -0.0158216   -0.0122363    0.0580138    0.0145253   -0.019566      0.075633    0.0487518    0.0142002   -0.0301499    0.0972418    0.07667      0.128901    0.0425841   0.0599765   -0.0995468   -0.035684    -0.000628149   0.0230054   -0.0395594
  0.094996    -0.00123813  -0.0587855    -0.198984   -0.0139097    -0.00920717  -0.00744428    0.0969838    0.0930196   -0.0750093   -0.0276385    0.0691794    -0.148161    0.0347674    0.0961763   -0.262544    -0.127184     0.0167711   -0.0502971   0.0473705   0.0164086    0.166347    -0.0944094    0.0475105     0.0262829    0.0459151
 -0.15432     -0.0504915   -0.0781081    -0.0265604   0.20194       0.0371301    0.0762952    -0.0739218   -0.00560801  -0.16945      0.00492221   0.11397      -0.0707105  -0.103341     0.114357     0.317879    -0.0340946    0.00291113   0.0119983  -0.0319064  -0.0114926   -0.0933389   -0.0836821   -0.0453222    -0.0965366   -0.0109874[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.073658
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.061248
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│     22
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.073127
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.060931
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│      ⋮
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.073128
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.062529
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│      ⋮
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.071556
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.062556
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      6
│     21
│      ⋮
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.071502
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.062554
┌ Info: EM with 100000 data points 10 iterations avll -1.062554
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.511468e+05
      1       6.848005e+05      -1.663463e+05 |       32
      2       6.526085e+05      -3.219201e+04 |       32
      3       6.395503e+05      -1.305822e+04 |       32
      4       6.320867e+05      -7.463519e+03 |       32
      5       6.266674e+05      -5.419308e+03 |       32
      6       6.227497e+05      -3.917706e+03 |       32
      7       6.205828e+05      -2.166946e+03 |       32
      8       6.191305e+05      -1.452277e+03 |       32
      9       6.172356e+05      -1.894930e+03 |       32
     10       6.150440e+05      -2.191557e+03 |       32
     11       6.135388e+05      -1.505203e+03 |       32
     12       6.128689e+05      -6.698972e+02 |       32
     13       6.124059e+05      -4.630076e+02 |       32
     14       6.118264e+05      -5.795369e+02 |       32
     15       6.110973e+05      -7.290976e+02 |       32
     16       6.101756e+05      -9.216480e+02 |       32
     17       6.092777e+05      -8.979556e+02 |       32
     18       6.086426e+05      -6.351070e+02 |       32
     19       6.080276e+05      -6.149826e+02 |       32
     20       6.073094e+05      -7.181837e+02 |       32
     21       6.066294e+05      -6.800032e+02 |       32
     22       6.062960e+05      -3.333443e+02 |       32
     23       6.061699e+05      -1.261509e+02 |       32
     24       6.060956e+05      -7.430371e+01 |       32
     25       6.060329e+05      -6.266442e+01 |       32
     26       6.059691e+05      -6.378940e+01 |       32
     27       6.058921e+05      -7.702778e+01 |       32
     28       6.057905e+05      -1.016163e+02 |       32
     29       6.056537e+05      -1.367975e+02 |       32
     30       6.054903e+05      -1.634204e+02 |       32
     31       6.053206e+05      -1.696866e+02 |       32
     32       6.051315e+05      -1.891040e+02 |       32
     33       6.049823e+05      -1.492289e+02 |       32
     34       6.048883e+05      -9.397282e+01 |       32
     35       6.048121e+05      -7.622669e+01 |       32
     36       6.047459e+05      -6.615198e+01 |       31
     37       6.046893e+05      -5.659811e+01 |       32
     38       6.046476e+05      -4.167339e+01 |       32
     39       6.046199e+05      -2.769390e+01 |       32
     40       6.046021e+05      -1.782692e+01 |       32
     41       6.045853e+05      -1.676142e+01 |       29
     42       6.045720e+05      -1.331626e+01 |       31
     43       6.045595e+05      -1.252827e+01 |       30
     44       6.045481e+05      -1.135706e+01 |       29
     45       6.045397e+05      -8.480181e+00 |       28
     46       6.045344e+05      -5.310097e+00 |       27
     47       6.045306e+05      -3.749106e+00 |       27
     48       6.045280e+05      -2.569748e+00 |       21
     49       6.045258e+05      -2.230379e+00 |       16
     50       6.045234e+05      -2.418683e+00 |       21
K-means terminated without convergence after 50 iterations (objv = 604523.3874779867)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.332241
[ Info: iteration 2, average log likelihood -1.305001
[ Info: iteration 3, average log likelihood -1.275153
[ Info: iteration 4, average log likelihood -1.241532
[ Info: iteration 5, average log likelihood -1.202798
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.140460
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     16
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.085291
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.089620
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.093736
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.066959
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     16
│     18
│     20
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.053357
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.089401
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.104026
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.060771
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│     20
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.022052
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.121973
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.100197
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.070250
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.044003
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     13
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.107993
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.080665
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.080912
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│     20
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.036264
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.128439
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.088143
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.059411
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│     20
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.034345
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.121703
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.067478
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.074321
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│     20
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.024842
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.110050
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.084383
[ Info: iteration 34, average log likelihood -1.074751
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.014051
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.114340
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.086356
[ Info: iteration 38, average log likelihood -1.084184
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│     20
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.020867
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.107452
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.093245
[ Info: iteration 42, average log likelihood -1.082000
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│      ⋮
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.013126
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.127705
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.081962
[ Info: iteration 46, average log likelihood -1.084080
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│      ⋮
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.017154
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.114977
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.097963
[ Info: iteration 50, average log likelihood -1.075808
┌ Info: EM with 100000 data points 50 iterations avll -1.075808
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0391682   -0.109241     0.0484599     0.0141604  -0.0513376    0.059284     0.0898787    0.0933583    0.00972386  -0.0102646   -0.0764214    0.0572713   -0.118838    -0.103001    0.140355     0.104809      0.107503    -0.0998207   -0.00545984  -0.0600261    0.131113     0.120581     0.0414434   -0.044268    -0.0182487    -0.0614006
 -0.0645806   -0.120309    -0.0814492     0.0989479   0.00501127  -0.034521     0.0662321    0.0532477   -0.0654894   -0.16037     -0.093454    -0.0828185   -0.192154     0.0456187  -0.124279    -0.0440739     0.0768647   -0.0123532   -0.134566    -0.0301439   -0.0383952    0.144301     0.0204393   -0.027709    -0.031654      0.0442259
  0.0743871   -0.00872927  -0.0222995     0.135272    0.0031715   -0.0587994    0.0805702    0.0169889   -0.174104    -0.0332145    0.0599324   -0.00484658   0.261601     0.0850759  -0.0909349   -0.0900611    -0.0503819   -0.0925652   -0.0589623   -0.00767958  -0.00434747   0.0652355   -0.0313761    0.053462    -0.187261      0.102951
 -0.135601    -0.0511271   -0.119222     -0.0864328   0.0337524   -0.078743    -0.0406951   -0.118053    -0.272106    -0.168563     0.115889    -0.145278     0.167694    -0.166676   -0.119792     0.0711528    -0.0853048    0.0414717   -0.0305282   -0.0280484   -0.0241739   -0.0024024    0.0182256   -0.0374334   -0.0572708     0.0139996
  0.0261417   -0.11519     -0.120624      0.1277      0.0316489    0.116268     0.199037    -0.0615984    0.0894191   -0.102757    -0.149084     0.0108728   -0.0940833    0.038868    0.149624     0.0975038    -0.186269     0.144214    -0.0900258    0.100885     0.0206509    0.0406531   -0.00712159  -0.0576961    0.0191433    -0.151883
 -0.0617606   -0.117324    -0.192441     -0.0693383  -0.0839915    0.0595488    0.165836    -0.112058     0.00176193   0.0522977    0.183774     0.0451558    0.15326      0.0482884  -0.0141948   -0.0872362     0.132665    -0.0433928    0.0464718    0.0773149    0.135988    -0.0766972    0.0384054   -0.00984083   0.124754     -0.0528681
  0.0809845   -0.0195645    0.0511682     0.0850843  -0.114688     0.123028     0.174737     0.179543     0.134036     0.0386932   -0.0118519   -0.0308638    0.0090602    0.0820229  -0.022803    -0.00903238   -0.00417091  -0.0147796   -0.162057    -0.0447413   -0.123208     0.164676    -0.0151892    0.0560197    0.0585972     0.0556095
 -0.0492282   -0.0271121   -0.0693108    -0.0532709   0.0551091    0.078383    -0.167193     0.107335     0.00535393  -0.102225     0.304421    -0.034846     0.098333     0.119597    0.099447    -0.0355225    -0.0377381   -0.0422533   -0.14537      0.0655838    0.059642    -0.236421    -0.0530861    0.0141189    0.0930159     0.0105777
  0.130389     0.0220132    0.0971267    -0.0523588  -0.058768    -0.113209    -0.0256278   -0.0137704   -0.0897209    0.160184    -0.166651     0.111493     0.0702793   -0.203377    0.168657    -0.121187      0.0188036    0.179094     0.282859     0.16879     -0.0460263    0.0742975    0.125227     0.0268467   -0.0691279     0.20698
 -0.0453072    0.095176    -0.0877696    -0.0638736   0.0520368    0.0576586   -0.0847212    0.108852     0.0715985    0.0187153   -0.00604421  -0.0250876    0.0975975   -0.136774    0.0231991    0.0403155    -0.0680124   -0.0174022    0.157807     0.0892697    0.0109054   -0.0426184    0.00103616   0.140822    -0.0233614    -0.015373
  0.163312     0.092468    -0.00856312   -0.0122074   0.0119492    0.102061    -0.310972    -0.114352     0.00546486  -0.00688961   0.0598339   -0.0378088   -0.119008     0.0148873   0.0753189    0.0612144    -0.0513898    0.082853    -0.00491607   0.0046384   -0.0069078    0.00802347   0.0202506   -0.0373473   -0.0221945    -0.00943248
 -0.157282     0.199381     0.138638     -0.0107308  -0.1034       0.0649687    0.00775716   0.0625329   -0.0265109    0.0736015   -0.147803    -0.0858926   -0.00284236   0.0577445   0.0401393    0.0228056     0.0712851    0.204932     0.205628     0.00904839  -0.0151273   -0.113951    -0.10251      0.0165901   -0.0738503    -0.0254132
 -0.109637    -0.0455907   -0.0114143     0.212917    0.0610988   -0.020208    -0.156129    -0.012925     0.110482     0.149007    -0.189758    -0.0409532    0.0580696   -0.0868465   0.0625207   -0.0020245     0.110764    -0.0427003   -0.107722    -0.0432055   -0.100743     0.0329679    0.00215167   0.0150422    0.252652      0.0960701
 -0.00824014  -0.0738043   -0.0481902     0.0677053   0.137904    -0.0667504    0.0857389   -0.0337278    0.0232869   -0.0737021    0.0935193   -0.037576     0.071027     0.0527379   0.0798876   -0.00939724   -0.117114     0.0341403    0.121716    -0.0409833   -0.194606     0.101734    -0.118996     0.0967539   -0.199916      0.0769852
 -0.075092    -0.155089     0.0319692     0.0277276  -0.0320031   -0.273522     0.0766131    0.127184     0.0811718   -0.0882085   -0.0927574    0.00694814  -0.0641703   -0.221284    0.0696209    0.135613      0.139695    -0.0379662   -0.0474365    0.0436398   -0.119049     0.00115794   0.1034      -0.0122139   -0.00645738    0.0197653
 -0.111036    -0.081981    -0.0622646     0.155224   -0.0253397    0.00909416  -0.0328386    0.076062    -0.0864968    0.0626359   -0.0794156    0.129594     0.0298371   -0.217173    0.0105092    0.125202     -0.0438962    0.0328746   -0.0527096    0.0978632    0.272878     0.10172      0.0593437   -0.101182     0.0625178    -0.0527126
 -0.320027     0.0489009    0.120044     -0.156064    0.0102746   -0.015857     0.0268564   -0.0362072    0.0935184   -0.0125963    0.0243144    0.224481     0.0522167    0.0496213   0.150533    -0.0984919     0.0729746    0.197112    -0.157328     0.0244491    0.200088     0.0373972    0.131639     0.0344785    0.147285      0.0346449
 -0.108801    -0.0874855   -0.00694488    0.0911503   0.0848825    0.0581786    0.00578715  -0.130736     0.00249139   0.0331289   -0.0748208   -0.126285    -0.0429152   -0.0347907   0.0088482    0.293808     -0.0187079    0.094803     0.0499236   -0.0513758    0.162295     0.0157603   -0.0162497    0.0130823   -0.059866     -0.102334
  0.0616829    0.0189852   -0.0394623    -0.0947762   0.0353892    0.0403094   -0.043592     0.0177655    0.0331231   -0.0541234   -0.00084537   0.0908266   -0.00658595  -0.0076409  -0.00122802  -0.165382     -0.132125     0.0349889    0.00774746  -0.0743235   -0.0471924    0.0926837   -0.0514816    0.0880613    0.151916      0.0703316
 -0.0600141   -0.00145502   0.104472     -0.130613    0.0303272    0.139293     0.0548912    0.145625    -0.00399295  -0.167155    -0.0566124    0.0731586    0.0296347   -0.131483    0.0870651    0.00601965    0.0335006   -0.00172639  -0.0441788   -0.0213194   -0.220528     0.278542    -0.128952    -0.089789    -0.00211131    0.0369697
 -0.152359    -0.0463444    0.0788702     0.131666    0.0970914    0.15027     -0.187029     0.19229      0.00715192   0.00265565  -0.0734352    0.0501817    0.0149109    0.0724075   0.0267851    0.0611523    -0.0573299    0.00489768   0.055075    -0.285573    -0.0221801   -0.0720211    0.0364431   -0.0156154    0.164073     -0.12483
 -0.103607    -0.166825    -0.0469555     0.0438778   0.0514994    0.0513704    0.00165917   0.00978488   0.00385175  -0.0092836   -0.00662636  -0.0542181   -0.109162     0.0406957  -0.123575    -0.237273      0.120554     0.0133823   -0.0318363   -0.0118224   -0.0246135   -0.0374559    0.118533    -0.056346     0.0167531    -0.0446749
  0.0913689    0.319758    -0.116675     -0.0133899   0.0409954   -0.191852    -0.020812     0.101234    -0.221673    -0.156868    -0.0268917   -0.0852796   -0.21444      0.0841744   0.00844491   0.0392397     0.0166468   -0.023058     0.104197    -0.159037    -0.124945     0.0217979    0.00896492   0.183789     0.00346849    0.0629609
 -0.064969    -0.0693871   -0.0151756     0.108855   -0.0237482   -0.047805    -0.01598      0.0574517   -0.0108369   -0.0608402   -0.0527812   -0.00672213   0.0601674   -0.117834    0.178885    -0.08012       0.0775244    0.0944467    0.0254917   -0.136227    -0.06966     -0.087693     0.067394    -0.0459162   -0.168062      0.0937795
 -0.0184616    0.113639    -0.067684     -0.0408332   0.172327    -0.0572803   -0.00327353   0.150507     0.0388402    0.0401617   -0.0912186   -0.00705082   0.179938     0.0076921   0.00333876   0.136471     -0.174906     0.132441    -0.0665458    0.169819     0.0974195   -0.169878    -0.0471726   -0.150866     0.11415       0.162617
 -0.266794    -0.133734    -0.00213638   -0.0459828   0.159922     0.0415396    0.0997098   -0.0315914   -0.00942192  -0.139255    -0.0286694    0.093815    -0.0678565   -0.143573    0.164338     0.0684726     0.0306753    0.0377958   -0.00731446   0.0263447    0.00914357  -0.0967017   -0.0633672   -0.0307718    0.00442586    0.015103
  0.191286     0.0278533    0.00988905    0.0522165  -0.0160848    0.00296698   0.0708107   -0.0172427   -0.0069905    0.163049     0.123223     0.115596     0.183687    -0.0483761   0.0592625   -0.000863461  -0.0122603   -0.0575598   -0.142187    -0.0155582   -0.0717912   -0.101172    -0.295859     0.119737     0.0280439    -0.016303
  0.0338903    0.0882021   -0.000553586  -0.0316777  -0.101115    -0.300268    -0.0530074    0.110083     0.14315      0.00238968  -0.111931    -0.0147902    0.104801    -0.186729    0.0456102    0.0688133    -0.0520335   -0.170574     0.178406    -0.124135     0.06468     -0.0835995   -0.105215    -0.0729204    0.093434      0.10439
 -0.137275    -0.0526892   -0.0916081    -0.0272514   0.210473     0.0343158    0.0777816   -0.0748752   -0.0155359   -0.176656     0.00367878   0.106178    -0.0717623   -0.104803    0.116381     0.37751      -0.0322528   -0.00359714   0.0148157   -0.0247102   -0.0117267   -0.0912517   -0.0797228   -0.0445005   -0.109988     -0.0121454
  0.172977     0.0458748   -0.0255612    -0.191818    0.124055    -0.0704804   -0.170302     0.0747016   -0.121162     0.0340125    0.00277279  -0.00102345   0.0178938   -0.071467    0.0588622   -0.0989834    -0.00683951  -0.0150986   -0.0883145    0.115693    -0.00686052  -0.0441814   -0.211341    -0.0204873   -0.000430728   0.049042
  0.226982    -0.00205376  -0.0579835     0.149817   -0.100506    -0.0948967   -0.0894316    0.0442625   -0.156314     0.0357893    0.169237    -0.0092695    0.12334     -0.123349   -0.0484779   -0.0552425    -0.122638    -0.0852843    0.149069    -0.0268967    0.0744815   -0.0394812    0.077283     0.0420853    0.148433      0.13163
 -0.064505    -0.0557269   -0.119326      0.0912016  -0.0282819    0.0261305    0.0752735   -0.0834211    0.00932937  -0.0317511   -0.12908     -0.164012    -0.052685    -0.0142713   0.0244633   -0.117303      0.112635    -0.137752     0.216417     0.0239111    0.0373483    0.160292     0.0490155    0.0131049    0.0595915     0.0831958[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.005656
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      4
│      9
│     15
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.993080
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.994500
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      4
│      9
│     15
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.996174
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.994412
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      4
│      9
│     15
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.996149
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.994160
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      4
│      9
│     15
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.990748
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      9
│     16
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.996100
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      4
│      9
│     16
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.997508
┌ Info: EM with 100000 data points 10 iterations avll -0.997508
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.123145    -0.012091    -0.0819782    0.143285   -0.111776    -0.0437352    0.092959     0.0981069   -0.0165074   -0.0630857    0.0305291    -0.0471188    0.0658882   -0.0253191  -0.102115    -0.0841383   -0.0244801    0.0972915   -0.113655     0.100725     0.122431     0.150259     0.0411704   -0.142814     0.0949254    -0.177631
  0.0106524    0.0780242    0.0472454   -0.0641181   0.00534698   0.154968    -0.00902525   0.154105    -0.141476    -0.0235417    0.0997558    -0.180059     0.051683     0.042051   -0.178509    -0.201225     0.063406     0.0067146    0.107649     0.00337605  -0.146574    -0.108038     0.0176408    0.0457007   -0.0489238    -0.0948077
 -0.0115325   -0.069098     0.0433593   -0.143096   -0.0365903   -0.117789     0.0243618   -0.144466    -0.103105     0.187956    -0.0525334    -0.0276932   -0.0388111    0.119567   -0.011173     0.00680889  -0.00843195  -0.0800571    0.115414    -0.00505963   0.0745553    9.11242e-5   0.0291696    0.00837942   0.000382029  -0.164422
  0.148803    -0.00885521  -0.0615206    0.0643201  -0.0580241   -0.00731324  -0.255609     0.00788331   0.0493587    0.0443842    0.0630695     0.239818    -0.00729184   0.0997026  -0.0709789    0.128793    -0.0536892    0.078896     0.0555229   -0.103228    -0.153262     0.0901391   -0.0453224    0.292189    -0.0346586     0.347629
 -0.267939    -0.0786892    0.00791045  -0.0490495   0.0116454    0.0473112   -0.0478529   -0.028814    -0.110288    -0.0194109   -0.0695149     0.061099     0.0681067    0.0308795   0.10174     -0.133794    -0.134861     0.0726477   -0.0675677   -0.0920121    0.0993054   -0.0330707    0.0629972   -0.0793003   -0.233522      0.0464968
 -0.0416038   -0.00629926   0.0269005    0.0280771  -0.00247781  -0.104065    -0.0394508    0.180134     0.324207    -0.076701     0.078396      0.0111774   -0.170978    -0.304227   -0.102779    -0.102904    -0.130167     0.13405     -0.0229519   -0.0354514   -0.0181695    0.0680504    0.0956309    0.0964109   -0.142778     -0.0988041
  0.130007     0.0219033   -0.0503306    0.0454248  -0.25068      0.00463599  -0.135885     0.118057     0.0320022    0.090427    -0.000186937   0.14532      0.178058     0.13638     0.0425025   -0.00740943   0.0299104    0.111505     0.0718466   -0.110544     0.148602    -0.00865812   0.186382     0.189832    -0.0151636     0.167844
 -0.185904    -0.145562    -0.0215506   -0.0716212   0.0687582    0.0355221    0.0799383   -0.100124    -0.00552708  -0.183353    -0.101482     -0.119376     0.0876487   -0.189661    0.0927173   -0.01029      0.0119561    0.083926    -0.269221    -0.0329277    0.0811658    0.0905893   -0.0411847   -0.0196524   -0.0942286     0.120363
 -0.0148703    0.149517     0.272312     0.123734   -0.0320498   -0.00812084  -0.117252    -0.0206897   -0.0553213   -0.077091     0.0548332     0.207609     0.119699    -0.0278126  -0.160563     0.0104558   -0.0934865    0.122494     0.279592    -0.00315849  -0.185069    -0.070848    -0.0829014   -0.0261382    0.0285636     0.104965
  0.00665984   0.0124242    0.048157    -0.0265628   0.117298    -0.113327    -0.0459326    0.0126022   -0.172251     0.00061957  -0.0219628    -0.158925     0.0837829    0.0531643  -0.014814    -0.0573106   -0.0413782    0.0988463   -0.138644     0.00916335  -0.0686424    0.0517025    0.155194    -0.147161    -0.106484      0.101881
 -0.0173432   -0.0171309   -0.0481782   -0.0831141  -0.0425473    0.00305044  -0.0168552    0.00104356   0.0762801    0.0629276    0.118641      0.0916878   -0.183221     0.178146    0.235531    -0.089384     0.0670279    0.0466675   -0.113982     0.140449    -0.101992     0.138718     0.0931805   -0.234553    -0.00811577    0.131717
  0.075926    -0.0320262   -0.00967345  -0.0475328  -0.0558369    0.0923825    0.0455795    0.122982     0.0793891   -0.0623595    0.0820623     0.124338     0.054491     0.0171406   0.0361885    0.0669468   -0.0332434   -0.0651921   -0.102745     0.0416515    0.090988    -0.0308       0.0193862    0.123884     0.0105866     0.112407
 -0.0621332    0.0220103   -0.0895665   -0.0252697   0.124381     0.0101037    0.121848    -0.0210331    0.152356    -0.0193825   -0.17894       0.128802    -0.0650511   -0.164266   -0.0106704    0.157576     0.0171963    0.125211    -0.0100242   -0.129782    -0.0491541    0.0684871   -0.0140023   -0.015174    -0.051719      0.0977657
 -0.142843    -0.196858     0.171238    -0.031539   -0.0401701    0.139355     0.0761273    0.0392129    0.0999384   -0.0695499   -0.0762389    -0.105414    -0.0126836   -0.128668    0.0713657   -0.068141    -0.131869    -0.021759     0.00812767  -0.00142721  -0.0518866    0.211012    -0.247683    -0.148        0.0178515     0.0295624
 -0.00760009   0.158771     0.25736      0.0308841  -0.18342      0.101155    -0.0376673   -0.0576209   -0.0871001    0.0111369   -0.149531      0.0822688    0.0281268   -0.118625   -0.00614889  -0.164459     0.0942722   -0.143799     0.115548    -0.071613     0.100624     0.115967     0.0256269    0.0656244    0.0494927    -0.0489931
  0.00943382  -0.0833251   -0.0268404    0.0931673  -0.164996     0.128557     0.113737     0.103838    -0.0063191   -0.0366789   -0.0120721    -0.0387008    0.0148385    0.0500105  -0.0727656    0.0294799   -0.0493741   -0.0247085    0.116009    -0.0398681    0.238652     0.00965864   0.0227062   -0.0177197    0.173593     -0.0484804
  0.0944658    0.0586266   -0.0737716    0.15588     0.0149539   -0.0166031   -0.0602945    0.0240788   -0.204017     0.0741715    0.131363     -0.00230076   0.0045317    0.148903    0.087767     0.0721109    0.0744618    0.119144    -0.0404616    0.0612347   -0.0262906   -0.00245017  -0.206265    -0.0577092    0.108749      0.184456
  0.074793     0.0934727   -0.110338    -0.0105776  -0.201594    -0.0739853   -0.0430037   -0.0746718   -0.0825952   -0.0692706    0.16375       0.101       -0.102854    -0.0305513  -0.0177056   -0.0627991   -0.150048     0.0871484    0.0343593    0.240556     0.0691577    0.0264466   -0.0240797    0.0151571    0.0267522     0.0538793
 -0.123023    -0.0613432    0.047956    -0.0248037   0.00171124  -0.043372    -0.0423837    0.192689     0.0346891    0.144804    -0.103153     -0.0888343   -0.09573      0.041123    0.112165    -0.0180477    0.0716466   -0.053226     0.10011      0.102527    -0.0720733   -0.0763378    0.229424    -0.144746    -0.0350164    -0.0648734
 -0.0447989   -0.0883537    0.0643588   -0.104472    0.066372    -0.197952    -0.0705413   -0.021866     0.305459     0.148225     0.0989167     0.137232     0.0412154   -0.0340618   0.00448067  -0.0587983   -0.101724    -0.0194293   -0.16204     -0.112091     0.0256626   -0.00786715   0.00384121  -0.0100143   -0.200864     -0.00386809
  0.00863434   0.13715     -0.0347785   -0.080938    0.158875    -0.0515359    0.104128     0.0188151    0.00412353  -0.158608     0.0552602     0.128723     0.0860577    0.0804477  -0.054787    -0.133901    -0.100928    -0.0279829    0.0855696    0.339079     0.0331035    0.124555     0.0178646    0.0238811   -0.227407     -0.000270768
 -0.061578    -0.0778718    0.161722     0.0538479   0.094759     0.0630853   -0.107589     0.0730345   -0.0235471    0.17918     -0.0909977     0.094617     0.0185175   -0.26306    -0.129253     0.0752533    0.0327028    0.070531     0.0452506    0.0469856    0.119718    -0.0460076    0.0472522   -0.0561736   -0.0912438    -0.114982
 -0.0881767    0.109531    -0.0814162   -0.0991489   0.0382863   -0.0231338    0.0414588    0.156678    -0.10503     -0.0271034    0.00581595    0.0877651   -0.0151984    0.0851615  -0.137868    -0.00466306  -0.059708     0.0385841   -0.116501     0.024263    -0.00930254  -0.0228179    0.0515646   -0.0334706    0.0232929     0.109995
  0.0460799   -0.0341472    0.032136    -0.0730356  -0.267313     0.135169     0.0641313    0.128841    -0.106599    -0.084481     0.132463      0.163431    -0.0114795    0.0506575  -0.162909    -0.10327      0.00921061  -0.0766306    0.0682251   -0.0158193   -0.0233784   -0.0145352    0.025159    -0.0234463   -0.0547703     0.0856658
 -0.311316     0.039       -0.0876042   -0.250503    0.0343986   -0.0275053   -0.0552481   -0.0459119    0.0622063   -0.0543285   -0.0829746     0.0167498   -0.0668146    0.11106    -0.0752457    0.0658931    0.0160332   -0.215754    -0.113        0.0138995    0.298411    -0.0184344    0.0485941    0.00197051   0.104483      0.00405558
 -0.114736     0.0201968    0.0626135   -0.133148    0.0673747   -0.150912    -0.0883658   -0.0255145   -0.0643017   -0.0249023   -0.0083137     0.0118782   -0.0656362    0.0730496  -0.00974758  -0.0354971    0.0089242   -0.0043289   -0.106857    -0.0179733   -0.033811     0.013889    -0.131419    -0.0248935   -0.041964      0.00315053
  0.049009     0.143099    -0.0874109   -0.080835    0.103812    -0.0290318    0.00585134   0.0397368    0.00346948   0.0272214    0.126897     -0.0634061   -0.0432687   -0.112235    0.0815124    0.0444467    0.113996     0.130415    -0.141333     0.0399927   -0.0934383   -0.121834    -0.0508793    0.0205035   -0.103064      0.03465
  0.157556     0.18284      0.157933    -0.128442    0.234691     0.112681     0.160948    -0.0672903   -0.0058949   -0.0137438   -0.0599342     0.0165348    0.17026     -0.0870299   0.0846245    0.10838      0.0989687   -0.0733955    0.109618    -0.234275    -0.0575      -0.0473242   -0.0855593    0.20111     -0.144079      0.22759
 -0.0412504   -0.0279473   -0.124618    -0.143094   -0.174902    -0.0562498   -0.0460173    0.106201     0.0248037   -0.0102278    0.0101134    -0.152283    -0.108944    -0.0805763   0.0793429    0.187055    -0.180562     0.0932978   -0.196297    -0.0875432    0.0668437    0.129032    -0.101512    -0.126996    -0.0885344    -0.0611236
  0.0225762    0.0862718   -0.0930857   -0.0623922  -0.0908936    0.157066     0.110089     0.0927752    0.0889469   -0.0883327    0.0235458     0.176325    -0.174545     0.194296    0.143094    -0.0195602   -0.00381999  -0.00250093   0.0884601    0.0352877    0.100396     0.130163    -0.0345582   -0.0457802    0.119939      0.197204
  0.178439    -0.0441497    0.211877    -0.0551009   0.0172643   -0.0679392   -0.0333329    0.186771    -0.0195895   -0.0216251   -0.0935133    -0.0174681    0.114006    -0.0774537  -0.050151    -0.0364916   -0.0489036   -0.0153262    0.0670772    0.0352679   -0.124162     0.167825     0.0723282   -0.0843422   -0.237299      0.0376325
  0.0569784   -0.0503711   -0.16805      0.0732471  -0.0975728    0.0582297    0.0121003   -0.0181504   -0.00239505   0.0510154    0.0588451     0.0302574   -0.118444     0.173601   -0.0260595    0.0994781   -0.00642478  -0.0518278    0.0940271   -0.0465194    0.0712753    0.0656649    0.0406725    0.105772     0.156899     -0.231012kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4260894913276612
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426109
[ Info: iteration 2, average log likelihood -1.426064
[ Info: iteration 3, average log likelihood -1.426035
[ Info: iteration 4, average log likelihood -1.426001
[ Info: iteration 5, average log likelihood -1.425958
[ Info: iteration 6, average log likelihood -1.425898
[ Info: iteration 7, average log likelihood -1.425806
[ Info: iteration 8, average log likelihood -1.425637
[ Info: iteration 9, average log likelihood -1.425281
[ Info: iteration 10, average log likelihood -1.424557
[ Info: iteration 11, average log likelihood -1.423386
[ Info: iteration 12, average log likelihood -1.422133
[ Info: iteration 13, average log likelihood -1.421313
[ Info: iteration 14, average log likelihood -1.420951
[ Info: iteration 15, average log likelihood -1.420817
[ Info: iteration 16, average log likelihood -1.420769
[ Info: iteration 17, average log likelihood -1.420750
[ Info: iteration 18, average log likelihood -1.420742
[ Info: iteration 19, average log likelihood -1.420739
[ Info: iteration 20, average log likelihood -1.420738
[ Info: iteration 21, average log likelihood -1.420737
[ Info: iteration 22, average log likelihood -1.420736
[ Info: iteration 23, average log likelihood -1.420736
[ Info: iteration 24, average log likelihood -1.420736
[ Info: iteration 25, average log likelihood -1.420735
[ Info: iteration 26, average log likelihood -1.420735
[ Info: iteration 27, average log likelihood -1.420735
[ Info: iteration 28, average log likelihood -1.420735
[ Info: iteration 29, average log likelihood -1.420735
[ Info: iteration 30, average log likelihood -1.420735
[ Info: iteration 31, average log likelihood -1.420734
[ Info: iteration 32, average log likelihood -1.420734
[ Info: iteration 33, average log likelihood -1.420734
[ Info: iteration 34, average log likelihood -1.420734
[ Info: iteration 35, average log likelihood -1.420734
[ Info: iteration 36, average log likelihood -1.420734
[ Info: iteration 37, average log likelihood -1.420734
[ Info: iteration 38, average log likelihood -1.420734
[ Info: iteration 39, average log likelihood -1.420734
[ Info: iteration 40, average log likelihood -1.420734
[ Info: iteration 41, average log likelihood -1.420734
[ Info: iteration 42, average log likelihood -1.420734
[ Info: iteration 43, average log likelihood -1.420734
[ Info: iteration 44, average log likelihood -1.420733
[ Info: iteration 45, average log likelihood -1.420733
[ Info: iteration 46, average log likelihood -1.420733
[ Info: iteration 47, average log likelihood -1.420733
[ Info: iteration 48, average log likelihood -1.420733
[ Info: iteration 49, average log likelihood -1.420733
[ Info: iteration 50, average log likelihood -1.420733
┌ Info: EM with 100000 data points 50 iterations avll -1.420733
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.426108589177759
│     -1.4260637688894415
│      ⋮
└     -1.420733362178085
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420752
[ Info: iteration 2, average log likelihood -1.420705
[ Info: iteration 3, average log likelihood -1.420674
[ Info: iteration 4, average log likelihood -1.420638
[ Info: iteration 5, average log likelihood -1.420594
[ Info: iteration 6, average log likelihood -1.420541
[ Info: iteration 7, average log likelihood -1.420481
[ Info: iteration 8, average log likelihood -1.420418
[ Info: iteration 9, average log likelihood -1.420357
[ Info: iteration 10, average log likelihood -1.420301
[ Info: iteration 11, average log likelihood -1.420251
[ Info: iteration 12, average log likelihood -1.420207
[ Info: iteration 13, average log likelihood -1.420167
[ Info: iteration 14, average log likelihood -1.420130
[ Info: iteration 15, average log likelihood -1.420093
[ Info: iteration 16, average log likelihood -1.420056
[ Info: iteration 17, average log likelihood -1.420019
[ Info: iteration 18, average log likelihood -1.419981
[ Info: iteration 19, average log likelihood -1.419943
[ Info: iteration 20, average log likelihood -1.419905
[ Info: iteration 21, average log likelihood -1.419868
[ Info: iteration 22, average log likelihood -1.419831
[ Info: iteration 23, average log likelihood -1.419796
[ Info: iteration 24, average log likelihood -1.419763
[ Info: iteration 25, average log likelihood -1.419732
[ Info: iteration 26, average log likelihood -1.419703
[ Info: iteration 27, average log likelihood -1.419678
[ Info: iteration 28, average log likelihood -1.419655
[ Info: iteration 29, average log likelihood -1.419636
[ Info: iteration 30, average log likelihood -1.419619
[ Info: iteration 31, average log likelihood -1.419604
[ Info: iteration 32, average log likelihood -1.419592
[ Info: iteration 33, average log likelihood -1.419582
[ Info: iteration 34, average log likelihood -1.419573
[ Info: iteration 35, average log likelihood -1.419565
[ Info: iteration 36, average log likelihood -1.419559
[ Info: iteration 37, average log likelihood -1.419553
[ Info: iteration 38, average log likelihood -1.419548
[ Info: iteration 39, average log likelihood -1.419544
[ Info: iteration 40, average log likelihood -1.419540
[ Info: iteration 41, average log likelihood -1.419537
[ Info: iteration 42, average log likelihood -1.419533
[ Info: iteration 43, average log likelihood -1.419531
[ Info: iteration 44, average log likelihood -1.419528
[ Info: iteration 45, average log likelihood -1.419525
[ Info: iteration 46, average log likelihood -1.419523
[ Info: iteration 47, average log likelihood -1.419521
[ Info: iteration 48, average log likelihood -1.419519
[ Info: iteration 49, average log likelihood -1.419517
[ Info: iteration 50, average log likelihood -1.419515
┌ Info: EM with 100000 data points 50 iterations avll -1.419515
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.420752212833982
│     -1.4207050415684417
│      ⋮
└     -1.4195148432152873
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419524
[ Info: iteration 2, average log likelihood -1.419465
[ Info: iteration 3, average log likelihood -1.419411
[ Info: iteration 4, average log likelihood -1.419343
[ Info: iteration 5, average log likelihood -1.419254
[ Info: iteration 6, average log likelihood -1.419143
[ Info: iteration 7, average log likelihood -1.419013
[ Info: iteration 8, average log likelihood -1.418875
[ Info: iteration 9, average log likelihood -1.418741
[ Info: iteration 10, average log likelihood -1.418620
[ Info: iteration 11, average log likelihood -1.418517
[ Info: iteration 12, average log likelihood -1.418430
[ Info: iteration 13, average log likelihood -1.418359
[ Info: iteration 14, average log likelihood -1.418301
[ Info: iteration 15, average log likelihood -1.418254
[ Info: iteration 16, average log likelihood -1.418215
[ Info: iteration 17, average log likelihood -1.418182
[ Info: iteration 18, average log likelihood -1.418155
[ Info: iteration 19, average log likelihood -1.418131
[ Info: iteration 20, average log likelihood -1.418110
[ Info: iteration 21, average log likelihood -1.418091
[ Info: iteration 22, average log likelihood -1.418074
[ Info: iteration 23, average log likelihood -1.418058
[ Info: iteration 24, average log likelihood -1.418044
[ Info: iteration 25, average log likelihood -1.418030
[ Info: iteration 26, average log likelihood -1.418018
[ Info: iteration 27, average log likelihood -1.418006
[ Info: iteration 28, average log likelihood -1.417996
[ Info: iteration 29, average log likelihood -1.417985
[ Info: iteration 30, average log likelihood -1.417976
[ Info: iteration 31, average log likelihood -1.417967
[ Info: iteration 32, average log likelihood -1.417958
[ Info: iteration 33, average log likelihood -1.417950
[ Info: iteration 34, average log likelihood -1.417942
[ Info: iteration 35, average log likelihood -1.417935
[ Info: iteration 36, average log likelihood -1.417927
[ Info: iteration 37, average log likelihood -1.417921
[ Info: iteration 38, average log likelihood -1.417914
[ Info: iteration 39, average log likelihood -1.417907
[ Info: iteration 40, average log likelihood -1.417901
[ Info: iteration 41, average log likelihood -1.417895
[ Info: iteration 42, average log likelihood -1.417889
[ Info: iteration 43, average log likelihood -1.417883
[ Info: iteration 44, average log likelihood -1.417877
[ Info: iteration 45, average log likelihood -1.417872
[ Info: iteration 46, average log likelihood -1.417866
[ Info: iteration 47, average log likelihood -1.417860
[ Info: iteration 48, average log likelihood -1.417855
[ Info: iteration 49, average log likelihood -1.417849
[ Info: iteration 50, average log likelihood -1.417844
┌ Info: EM with 100000 data points 50 iterations avll -1.417844
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4195242630333387
│     -1.419465337899618
│      ⋮
└     -1.417844001554684
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417847
[ Info: iteration 2, average log likelihood -1.417791
[ Info: iteration 3, average log likelihood -1.417741
[ Info: iteration 4, average log likelihood -1.417686
[ Info: iteration 5, average log likelihood -1.417619
[ Info: iteration 6, average log likelihood -1.417540
[ Info: iteration 7, average log likelihood -1.417448
[ Info: iteration 8, average log likelihood -1.417346
[ Info: iteration 9, average log likelihood -1.417240
[ Info: iteration 10, average log likelihood -1.417132
[ Info: iteration 11, average log likelihood -1.417029
[ Info: iteration 12, average log likelihood -1.416931
[ Info: iteration 13, average log likelihood -1.416842
[ Info: iteration 14, average log likelihood -1.416760
[ Info: iteration 15, average log likelihood -1.416686
[ Info: iteration 16, average log likelihood -1.416620
[ Info: iteration 17, average log likelihood -1.416562
[ Info: iteration 18, average log likelihood -1.416510
[ Info: iteration 19, average log likelihood -1.416465
[ Info: iteration 20, average log likelihood -1.416425
[ Info: iteration 21, average log likelihood -1.416390
[ Info: iteration 22, average log likelihood -1.416358
[ Info: iteration 23, average log likelihood -1.416330
[ Info: iteration 24, average log likelihood -1.416305
[ Info: iteration 25, average log likelihood -1.416281
[ Info: iteration 26, average log likelihood -1.416259
[ Info: iteration 27, average log likelihood -1.416239
[ Info: iteration 28, average log likelihood -1.416220
[ Info: iteration 29, average log likelihood -1.416201
[ Info: iteration 30, average log likelihood -1.416184
[ Info: iteration 31, average log likelihood -1.416167
[ Info: iteration 32, average log likelihood -1.416151
[ Info: iteration 33, average log likelihood -1.416135
[ Info: iteration 34, average log likelihood -1.416120
[ Info: iteration 35, average log likelihood -1.416105
[ Info: iteration 36, average log likelihood -1.416091
[ Info: iteration 37, average log likelihood -1.416077
[ Info: iteration 38, average log likelihood -1.416063
[ Info: iteration 39, average log likelihood -1.416049
[ Info: iteration 40, average log likelihood -1.416036
[ Info: iteration 41, average log likelihood -1.416024
[ Info: iteration 42, average log likelihood -1.416011
[ Info: iteration 43, average log likelihood -1.415999
[ Info: iteration 44, average log likelihood -1.415987
[ Info: iteration 45, average log likelihood -1.415975
[ Info: iteration 46, average log likelihood -1.415964
[ Info: iteration 47, average log likelihood -1.415953
[ Info: iteration 48, average log likelihood -1.415942
[ Info: iteration 49, average log likelihood -1.415932
[ Info: iteration 50, average log likelihood -1.415922
┌ Info: EM with 100000 data points 50 iterations avll -1.415922
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4178474638064158
│     -1.4177910843419927
│      ⋮
└     -1.4159218773383637
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415921
[ Info: iteration 2, average log likelihood -1.415846
[ Info: iteration 3, average log likelihood -1.415774
[ Info: iteration 4, average log likelihood -1.415687
[ Info: iteration 5, average log likelihood -1.415580
[ Info: iteration 6, average log likelihood -1.415451
[ Info: iteration 7, average log likelihood -1.415304
[ Info: iteration 8, average log likelihood -1.415147
[ Info: iteration 9, average log likelihood -1.414986
[ Info: iteration 10, average log likelihood -1.414829
[ Info: iteration 11, average log likelihood -1.414681
[ Info: iteration 12, average log likelihood -1.414544
[ Info: iteration 13, average log likelihood -1.414420
[ Info: iteration 14, average log likelihood -1.414310
[ Info: iteration 15, average log likelihood -1.414214
[ Info: iteration 16, average log likelihood -1.414130
[ Info: iteration 17, average log likelihood -1.414056
[ Info: iteration 18, average log likelihood -1.413992
[ Info: iteration 19, average log likelihood -1.413935
[ Info: iteration 20, average log likelihood -1.413885
[ Info: iteration 21, average log likelihood -1.413841
[ Info: iteration 22, average log likelihood -1.413801
[ Info: iteration 23, average log likelihood -1.413765
[ Info: iteration 24, average log likelihood -1.413733
[ Info: iteration 25, average log likelihood -1.413703
[ Info: iteration 26, average log likelihood -1.413675
[ Info: iteration 27, average log likelihood -1.413650
[ Info: iteration 28, average log likelihood -1.413625
[ Info: iteration 29, average log likelihood -1.413603
[ Info: iteration 30, average log likelihood -1.413581
[ Info: iteration 31, average log likelihood -1.413561
[ Info: iteration 32, average log likelihood -1.413541
[ Info: iteration 33, average log likelihood -1.413522
[ Info: iteration 34, average log likelihood -1.413504
[ Info: iteration 35, average log likelihood -1.413486
[ Info: iteration 36, average log likelihood -1.413469
[ Info: iteration 37, average log likelihood -1.413453
[ Info: iteration 38, average log likelihood -1.413437
[ Info: iteration 39, average log likelihood -1.413421
[ Info: iteration 40, average log likelihood -1.413406
[ Info: iteration 41, average log likelihood -1.413391
[ Info: iteration 42, average log likelihood -1.413377
[ Info: iteration 43, average log likelihood -1.413363
[ Info: iteration 44, average log likelihood -1.413349
[ Info: iteration 45, average log likelihood -1.413336
[ Info: iteration 46, average log likelihood -1.413323
[ Info: iteration 47, average log likelihood -1.413310
[ Info: iteration 48, average log likelihood -1.413298
[ Info: iteration 49, average log likelihood -1.413285
[ Info: iteration 50, average log likelihood -1.413273
┌ Info: EM with 100000 data points 50 iterations avll -1.413273
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.415920742626644
│     -1.4158464015646541
│      ⋮
└     -1.4132731276733421
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4260894913276612
│     -1.426108589177759
│     -1.4260637688894415
│     -1.4260352653728097
│      ⋮
│     -1.4132975453873478
│     -1.4132852402136251
└     -1.4132731276733421
32×26 Array{Float64,2}:
 -0.149812   -0.0628514  -0.114906    -0.0295989  -0.20775     -0.00354506  -0.102094    -0.0227832  -0.295007      0.319148    -0.0175341   0.252236      0.198378    0.0284216   -0.168396   -0.156682     0.115067    -0.0193462   0.0990267   -0.183798   -0.0814301    0.0809571   -0.0558135  -0.0131609   -0.0186594   0.0402539
 -0.152215    0.046655    0.116318     0.0349536   0.300423     0.0556233    0.163509    -0.0666174  -0.178993      0.191771     0.084627   -0.0478405    -0.235643   -0.387097     0.0700026   0.0530882   -0.213464     0.0866382   0.00259493  -0.172281    0.0536006   -0.118842    -0.177046   -0.375747    -0.367229    0.0759412
 -0.377591   -0.0552833   0.41706     -0.327284    0.358845     0.362704     0.0207048   -0.29942    -0.0143766     0.00174052  -0.266252   -0.231725      0.113899    0.207476    -0.183118    0.389277    -0.0809307   -0.108201   -0.183512     0.27603    -0.470128     0.034708    -0.309543   -0.279993    -0.210449    0.536878
 -0.281322   -0.718561    0.402789    -0.373236    0.0316765   -0.105853     0.514268     0.0770056  -0.145007     -0.110677    -0.797504    0.503884      0.580861    0.520791    -0.12615     0.178044    -0.365724    -0.057424    0.599761     0.11403    -0.414281     0.0220755   -0.267433    0.908656     0.170224    0.0178101
  0.233834   -0.0870793  -0.00773316  -0.312701    0.0633365   -0.223444     0.11662      0.0877631   0.175136     -0.20767     -0.353149   -0.10568      -0.22917     0.0286444   -0.0219331   0.11183     -0.134041     0.0562471  -0.0643217    0.14544     0.145386     0.0785655    0.107175    0.00956275   0.199658    0.0212857
  0.139187    0.161698    0.0278549    0.212264   -0.0408102    0.126013    -0.0364163    0.117969    0.334953     -0.223451     0.381058   -0.165424      0.0591773   0.148092     0.124339    0.0832102   -0.0946241   -0.0507027  -0.0521818    0.0259628   0.10303     -0.0601742    0.0376719   0.35799     -0.0729117  -0.186705
  0.300289    0.656175    0.0877665    0.352368    0.438912     0.0325928    0.330469    -0.126795   -0.0160773    -0.412459    -0.153691    0.467607      0.0648114  -0.161437     0.162888    0.00402329   0.624988     0.146507    0.242396    -0.328295   -0.333962     0.40846     -0.0110619   0.455958     0.0995539   0.596019
  0.0459901   0.115912   -0.0666562   -0.201676    0.00107223   0.193656     0.0445065   -0.0690138   0.323616     -0.419492    -0.16515     0.51968       0.396182    0.143978     0.299215   -0.176501     0.640794     0.0932931   0.0444445    0.703403    0.0661747    0.0621607    0.146013    0.17109     -0.138516    0.214898
  0.182016    0.205337   -0.593604    -0.757032   -0.510362    -0.117842    -0.602757    -0.252893   -0.743234     -0.00197642  -0.0671418   0.348455      0.118881    0.480993     0.119218   -0.626286    -0.0508709    0.174083   -0.376349     0.0311622  -0.177756    -0.0887877   -0.274553   -0.307259    -0.277665    0.0103071
  0.0366966   0.242824    0.332791    -0.401984   -0.0137499   -0.415182     0.0346905   -0.0616968  -0.242702     -0.306223     0.475459   -0.000856745   0.127308    0.705971     0.219215   -0.754883    -0.0571651    0.13526    -0.564769     0.0306205  -0.230232    -0.592654    -0.376673    0.301131     0.0380699  -0.414599
  0.198925   -0.464693   -0.109864    -0.12145    -0.439603    -0.142071     0.172861     0.0394929  -0.287267      0.207549    -0.0217366   0.050371      0.179154   -0.0206039    0.0764014  -0.273928    -0.871633    -0.0365061   0.201379    -1.03597     0.498711     0.164485    -0.260093   -0.233575     0.168298   -0.103753
  0.0967686  -0.437702    0.186542    -0.770248   -0.425524    -0.0585123   -0.0142299    0.2548     -0.161305      0.231657    -0.113668    0.0151527    -0.146678    0.160599    -0.0642846  -0.126568    -0.666834     0.0238473  -0.15939      0.583451    0.407716    -0.306967     0.263063   -0.665855    -0.0273504  -0.197974
  0.434379    0.507161    0.273934    -0.199327    0.437398    -0.175883    -0.0934866   -0.0496107  -0.141183      0.808775    -0.0979633   0.863958      0.270744    0.505092    -0.312816   -0.18224      0.17444      0.243968    0.362522     0.0705841  -0.295817    -0.333873     0.886098    0.144994    -0.678363    0.23773
  0.022809    0.425754   -0.15307      0.399066   -0.438611    -0.0129741   -0.728918     0.396719   -0.0171039     0.387088     0.0908102   0.290007     -0.0722611   0.176801    -0.120878   -0.0144423    0.131425     0.0226476   0.35165      0.28054    -0.154217    -0.0259679    0.942887    0.0817745    0.218361   -0.328268
 -0.186224   -0.162266   -0.139674     0.329278   -0.263137    -0.569366    -0.271094    -0.169992   -0.000555289   0.741408     0.412861    0.0972092     0.0572572  -0.191235    -0.104288   -0.254455     0.140123     0.16145     0.102749    -0.374683    0.521963    -0.00899528   0.100335   -0.0177561   -0.430361   -0.684562
 -0.26017    -0.0754638   0.385474     0.497018   -0.218872     0.630498    -0.0151141    0.207894   -0.274455      0.0995226    0.130099    0.375759      0.238242   -0.151575    -0.0177662  -0.193247     0.262745     0.182687    0.627727    -0.359046    0.405663     0.53419     -0.13333    -0.220405     0.0841201   0.17988
 -0.308957   -0.653113   -0.262866    -0.0179135  -0.274064     0.460544     0.27984      0.158268    0.194554     -0.739382     0.354421   -0.609769     -0.463457   -0.637242     0.486224    0.372158    -0.210705    -0.291634   -0.255906     0.0569609   0.142111     0.17996     -1.07421    -0.314977     0.363501    0.247439
 -0.318053   -0.0506011  -0.3343       0.384509    0.174773     0.639014    -0.100413     0.181145    0.425571     -0.560131     0.223794   -0.432862      0.691925   -0.387213     0.213975    0.0566865   -0.303524    -0.464546   -0.290031    -0.188593   -0.055777     0.389588     0.304411   -0.421739     0.531725    0.428541
  0.0739103  -0.709115   -0.536761     0.433729    0.0401914    0.356092    -0.234833     0.196738    0.297875      0.348094    -0.530497    0.263627     -0.259711   -0.829654    -0.363732    0.664176    -0.299095     0.0281283   0.755198    -0.0877716   0.249655     0.543524     0.346181   -0.454733    -0.192882    0.186034
  0.0758605  -0.134732    0.408922     0.536897    0.454642    -0.22998      0.331916    -0.0587052   0.563177     -0.0569045   -0.117473   -0.540048     -0.174484   -0.491862    -0.367866    0.862434    -0.00759365  -0.281303    0.152401    -0.0453956   0.195953     0.300778     0.303713    0.337111    -0.0554159   0.0398183
 -0.0531046   0.0602632  -0.284007    -0.231556   -0.922014     0.304113    -0.1404       0.443456   -0.0992435     0.0192191    0.103918   -0.45065      -0.0759343   0.682781    -0.0755053   0.642751    -0.24451     -0.425051    0.0160617   -0.160416   -0.319282     0.361108     0.140653    0.293414     0.199501    0.380697
  0.433539    0.049368   -0.142162    -0.503666   -0.0638779   -0.241363    -0.0446912    0.39455     0.56091      -0.834705    -0.0905261  -0.101446     -0.155353    0.71876      0.0962616   0.0746146   -0.0387302   -0.660399   -0.0424988    0.347715   -0.0036172   -0.167888     0.0751977   0.27412      0.574765    0.549892
  0.167669    0.357632    0.326356    -0.101537    0.184401     0.323243     0.102159     0.343866    0.634116     -0.377054    -0.146469   -0.361101     -0.19224    -0.0642859    0.513473    0.290389    -0.81032      0.538867   -0.178741     0.306871   -0.1285      -0.221225     0.38965     0.00788391  -0.0214749   0.00686448
  0.226601    0.297184    0.0225677   -0.127771   -0.208679     0.217985     0.23438     -0.144192    0.682071     -0.285253     0.366206   -0.201035     -0.343564    0.513043     0.258448    0.416751     0.884124     0.283934   -0.130664     0.772577    0.00533834  -0.216001     0.119891    0.484462    -0.418298   -0.229941
  0.347762    0.39278    -0.122287    -0.104046    0.470017     0.234717     0.101716     0.512593   -0.703532      0.26757      0.202555    0.182194     -0.304518   -0.776388    -0.57658    -0.443493    -0.603037     0.314349   -0.523898    -0.303739   -0.5989       0.257494     0.301602   -0.131324     0.22413     0.00643851
 -0.302042   -0.174089   -0.512069    -0.270404    0.244709    -0.571901     0.432684     0.770278   -0.247363      0.213397    -0.261477    0.0975133    -0.645584   -0.347744    -0.805657    0.068581     0.540231    -0.172456   -0.133444     0.126283   -0.0372744   -0.272584    -0.119104    0.317296     0.0370981  -0.0772776
 -0.485119    0.0575766  -0.00959431  -0.487012   -0.297945     0.0921582    0.00464186   0.549313   -0.704302      0.325307    -0.394349    0.0360653    -0.231232    9.33913e-5  -0.164193   -0.26486     -0.13383      0.0936698  -0.184829     0.0515354   0.00712044  -0.142881     0.0936359  -0.423557     0.0935026   0.200813
  0.177669   -0.185684    0.0799254    0.227038   -0.0752906   -0.0440874   -0.212104    -0.349237    0.207475     -0.154424     0.284803    0.110536      0.315687    0.188252     0.108252    0.0312633    0.0523664   -0.0559723   0.214353    -0.0520692   0.0539771    0.263583     0.0350681   0.235537    -0.0516612  -0.158841
  0.0121559   0.821631    0.036444     0.348351    0.228358     0.0605356   -0.703427    -0.431375   -0.00582952   -0.200165     0.788637   -0.362929     -0.484512   -0.349667     0.0866153  -0.189966     0.373342     0.137755   -0.58535     -0.194335    0.231166    -0.0204845    0.024696   -1.21903     -0.0323852   0.275168
 -0.699942    0.469897   -0.0300011    0.879738    0.0656143    0.479547    -0.181292    -0.200441   -0.119906     -0.138722     0.107213   -0.305649      0.583683   -0.482088    -0.103406   -0.248567     0.483457     0.0884343  -0.059686    -0.49365    -0.23268      0.0694373   -0.724806    0.86119     -0.516634   -0.0849662
 -0.0687186  -0.311907   -0.0282357    0.011885    0.695466    -0.253482     0.290408    -0.650237   -0.272874      0.305036     0.193286    0.395133     -0.0188621  -0.474197     0.242051   -0.359826    -0.186332    -0.0765873  -0.0604867   -0.331493    0.291525    -0.280726    -0.653294   -0.561989    -0.738227    0.245679
 -0.280881   -0.216891    0.167763     0.152138    0.366887    -0.593295     0.0752121   -0.74373     0.348816     -0.167607    -0.226549    0.0909524    -0.0384501  -0.38904      0.174209   -0.125352     0.560319     0.378611   -0.111765     0.0576366   0.0649496    0.627529    -0.389675    0.00796982   0.243161   -0.124051[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413261
[ Info: iteration 2, average log likelihood -1.413249
[ Info: iteration 3, average log likelihood -1.413238
[ Info: iteration 4, average log likelihood -1.413226
[ Info: iteration 5, average log likelihood -1.413215
[ Info: iteration 6, average log likelihood -1.413203
[ Info: iteration 7, average log likelihood -1.413192
[ Info: iteration 8, average log likelihood -1.413181
[ Info: iteration 9, average log likelihood -1.413170
[ Info: iteration 10, average log likelihood -1.413159
┌ Info: EM with 100000 data points 10 iterations avll -1.413159
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.820881e+05
      1       7.088404e+05      -1.732477e+05 |       32
      2       6.929552e+05      -1.588519e+04 |       32
      3       6.876388e+05      -5.316414e+03 |       32
      4       6.848321e+05      -2.806727e+03 |       32
      5       6.830310e+05      -1.801095e+03 |       32
      6       6.818259e+05      -1.205080e+03 |       32
      7       6.809695e+05      -8.564531e+02 |       32
      8       6.802519e+05      -7.175286e+02 |       32
      9       6.796138e+05      -6.381330e+02 |       32
     10       6.790648e+05      -5.489620e+02 |       32
     11       6.785604e+05      -5.044628e+02 |       32
     12       6.781156e+05      -4.447956e+02 |       32
     13       6.777193e+05      -3.962453e+02 |       32
     14       6.773537e+05      -3.656215e+02 |       32
     15       6.770355e+05      -3.182538e+02 |       32
     16       6.767695e+05      -2.659903e+02 |       32
     17       6.765245e+05      -2.450234e+02 |       32
     18       6.763167e+05      -2.077743e+02 |       32
     19       6.761470e+05      -1.697048e+02 |       32
     20       6.759866e+05      -1.604141e+02 |       32
     21       6.758552e+05      -1.313656e+02 |       32
     22       6.757276e+05      -1.275809e+02 |       32
     23       6.756151e+05      -1.124662e+02 |       32
     24       6.755099e+05      -1.052083e+02 |       32
     25       6.754099e+05      -1.000664e+02 |       32
     26       6.753164e+05      -9.347307e+01 |       32
     27       6.752236e+05      -9.280512e+01 |       32
     28       6.751339e+05      -8.973148e+01 |       32
     29       6.750461e+05      -8.779843e+01 |       32
     30       6.749594e+05      -8.666246e+01 |       32
     31       6.748653e+05      -9.413930e+01 |       32
     32       6.747843e+05      -8.095833e+01 |       32
     33       6.747162e+05      -6.810232e+01 |       32
     34       6.746507e+05      -6.551801e+01 |       32
     35       6.745927e+05      -5.798164e+01 |       32
     36       6.745372e+05      -5.553548e+01 |       32
     37       6.744887e+05      -4.850896e+01 |       32
     38       6.744414e+05      -4.727421e+01 |       32
     39       6.743910e+05      -5.041788e+01 |       32
     40       6.743500e+05      -4.101030e+01 |       32
     41       6.743120e+05      -3.792418e+01 |       32
     42       6.742754e+05      -3.668044e+01 |       32
     43       6.742398e+05      -3.557336e+01 |       32
     44       6.742052e+05      -3.457995e+01 |       32
     45       6.741734e+05      -3.178863e+01 |       32
     46       6.741446e+05      -2.884715e+01 |       32
     47       6.741191e+05      -2.543054e+01 |       32
     48       6.740946e+05      -2.448622e+01 |       32
     49       6.740701e+05      -2.458099e+01 |       32
     50       6.740489e+05      -2.111930e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 674048.9450714751)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425291
[ Info: iteration 2, average log likelihood -1.420150
[ Info: iteration 3, average log likelihood -1.418806
[ Info: iteration 4, average log likelihood -1.417833
[ Info: iteration 5, average log likelihood -1.416777
[ Info: iteration 6, average log likelihood -1.415725
[ Info: iteration 7, average log likelihood -1.414939
[ Info: iteration 8, average log likelihood -1.414482
[ Info: iteration 9, average log likelihood -1.414233
[ Info: iteration 10, average log likelihood -1.414081
[ Info: iteration 11, average log likelihood -1.413975
[ Info: iteration 12, average log likelihood -1.413894
[ Info: iteration 13, average log likelihood -1.413828
[ Info: iteration 14, average log likelihood -1.413771
[ Info: iteration 15, average log likelihood -1.413720
[ Info: iteration 16, average log likelihood -1.413675
[ Info: iteration 17, average log likelihood -1.413633
[ Info: iteration 18, average log likelihood -1.413594
[ Info: iteration 19, average log likelihood -1.413558
[ Info: iteration 20, average log likelihood -1.413523
[ Info: iteration 21, average log likelihood -1.413490
[ Info: iteration 22, average log likelihood -1.413458
[ Info: iteration 23, average log likelihood -1.413428
[ Info: iteration 24, average log likelihood -1.413399
[ Info: iteration 25, average log likelihood -1.413371
[ Info: iteration 26, average log likelihood -1.413344
[ Info: iteration 27, average log likelihood -1.413319
[ Info: iteration 28, average log likelihood -1.413295
[ Info: iteration 29, average log likelihood -1.413272
[ Info: iteration 30, average log likelihood -1.413250
[ Info: iteration 31, average log likelihood -1.413229
[ Info: iteration 32, average log likelihood -1.413209
[ Info: iteration 33, average log likelihood -1.413190
[ Info: iteration 34, average log likelihood -1.413172
[ Info: iteration 35, average log likelihood -1.413155
[ Info: iteration 36, average log likelihood -1.413139
[ Info: iteration 37, average log likelihood -1.413123
[ Info: iteration 38, average log likelihood -1.413108
[ Info: iteration 39, average log likelihood -1.413094
[ Info: iteration 40, average log likelihood -1.413080
[ Info: iteration 41, average log likelihood -1.413066
[ Info: iteration 42, average log likelihood -1.413053
[ Info: iteration 43, average log likelihood -1.413040
[ Info: iteration 44, average log likelihood -1.413028
[ Info: iteration 45, average log likelihood -1.413015
[ Info: iteration 46, average log likelihood -1.413003
[ Info: iteration 47, average log likelihood -1.412991
[ Info: iteration 48, average log likelihood -1.412980
[ Info: iteration 49, average log likelihood -1.412968
[ Info: iteration 50, average log likelihood -1.412957
┌ Info: EM with 100000 data points 50 iterations avll -1.412957
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.626554   -0.540567    -0.394329    -0.191507   -0.213412     0.370608   -0.222532    -0.366434    0.291202     0.199539    0.617624    0.502415    0.947957    0.19805      0.120059   -0.29849      0.159835   -0.469627    0.270586      0.382954    -0.0597198   0.569151     0.268034     0.0721187  -0.236064    -0.305754
  0.0117682  -0.0714636   -0.00448773  -0.348088   -0.224881     0.13383     0.0158323    0.101658   -0.26676      0.0793022  -0.137777    0.345029    0.122192    0.367003    -0.339654    0.102202     0.173854   -0.120665    0.199513      0.170898    -0.377701    0.0800863    0.336937     0.402941   -0.225457     0.234336
  0.379817    0.422822    -0.246247     0.477908   -0.387203    -0.0351758  -0.460048     0.265577   -0.0789462    0.614624    0.238936    0.34135     0.173583    0.442113    -0.220167   -0.0858238    0.0213861   0.0830722   0.398466     -0.175135    -0.156634   -0.0967829    0.77969      0.45075    -0.180859    -0.287523
 -0.277961    0.190783    -0.0085455   -0.0701136  -0.735215     0.233267   -0.131261     0.450994   -0.0432462   -0.107583    0.184296   -0.581192   -0.304234    0.635372    -0.109547    0.531454    -0.0135695  -0.397899    0.223544     -0.00773306   0.0568811   0.380498     0.0327299    0.253759    0.383519     0.142363
 -0.0471694   0.00774181   0.0701862    0.0507621   0.00277496   0.016165   -0.00873022   0.076577   -0.00906619   0.0962173   0.0359603  -0.0338135  -0.0816922  -0.0352601   -0.101995    0.110538    -0.0612888  -0.0182533   0.0282451    -0.0654639    0.0212412  -0.00654641   0.0298873    0.0124835  -0.0232779   -0.0327237
 -0.109473    0.646919     0.0308404    0.263162    0.259129     0.0371939  -0.541641    -0.424158   -0.0889698   -0.157732    0.768787   -0.20782    -0.471982   -0.378666     0.0786652  -0.260281     0.353176    0.0655367  -0.5072       -0.33882      0.31493     0.00132686  -0.118625    -1.22481     0.020892     0.327493
  0.707766    0.257222    -0.211003    -0.323855   -0.428978     0.439258   -0.405149    -0.255441   -0.400646     0.0229723   0.164947   -0.261245    0.143078    0.179467     0.391848   -0.198455    -1.04521     0.0858486  -0.448062     -0.128084    -0.120953    0.232765     0.443483    -0.618144   -0.0709086   -0.143763
  0.373979    0.458284    -0.303551     0.456234    0.361658    -0.0569701   0.217419    -0.189493    0.0800569   -0.303734    0.0814817   0.181951   -0.0400692  -0.0981483    0.294683    0.24069      0.666756    0.0513126  -0.0717299     0.084849    -0.261818    0.376146    -0.0263301    0.537549    0.00763646   0.0506651
  0.0297697   0.050006    -0.581402    -0.119675    0.617728    -0.379138    0.414166     0.728345   -0.498793     0.302674   -0.150374    0.104194   -0.710592   -0.916213    -0.917367   -0.128239    -0.0486788  -0.019606   -0.25949      -0.0620622   -0.527235    0.0555999    0.00722293   0.262534    0.181593    -0.189055
 -0.0651632  -0.601595    -0.445944     0.534419   -0.0294054   -0.0304547  -0.156416     0.0433562   0.123979     0.522369   -0.297175    0.312569   -0.199239   -0.76153     -0.349914    0.417368     0.033137   -0.124156    0.669131     -0.382526     0.460243    0.623734     0.240414    -0.384768   -0.141133     0.227041
  0.0488771   0.154011     0.0143715   -0.277315   -0.121277     0.604444   -0.0397962    0.656935   -0.411283    -0.0643451  -0.360501    0.203082    0.0404574  -0.187106    -0.453567   -0.229468    -0.20828    -0.242915   -0.138205     -0.0490296   -0.354434   -0.184766     0.39931     -0.385206   -0.218861     0.699614
 -0.573001    0.639791     0.171351     0.16617     0.17178      0.0206189  -0.876239    -0.193502   -0.170571     0.350897    0.138051   -0.0568458  -0.299345   -0.0598102   -0.0505139   0.391177     0.244995    0.092963   -0.0906458     0.939071    -0.820283   -0.550971     0.624839    -0.283832   -0.241511    -0.075065
  0.163693    0.0308461    0.689364    -0.810416    0.112033    -0.102942   -0.156807     0.499153   -0.302698     0.481361   -0.250069    0.724502   -0.0679976   0.182732    -0.356188   -0.00492625  -0.449289    0.3756      0.325713      0.0723091    0.365492   -0.051386     0.796076    -0.679639    0.10816      0.0854459
 -0.512534   -0.497753    -0.39278     -0.417967   -1.05487     -0.38382    -0.358419     0.592066   -0.747197     0.324443   -0.410007   -0.0652973   0.327361   -0.190381    -0.0483394  -0.305942    -0.846281    0.0199814  -0.286233      0.0442334    0.443076   -0.0643377   -0.348275    -0.569331    0.719872    -0.105903
 -0.333254    0.0955261    0.450504     0.696001    0.0757298    0.118632    0.0727034   -0.0256569  -0.202486    -0.0948123  -0.0786996   0.280587    0.107795   -0.522909    -0.0673246  -0.308088     0.545746    0.371261    0.194551     -0.190202     0.15307     0.76864     -0.0689657   -0.0534768   0.323216     0.0944454
  0.72835    -0.077504    -0.420007    -0.771277   -0.27277     -0.680828   -0.0713325    0.213894    0.290767    -0.372745   -0.0557171   0.128954   -0.467163    0.650379    -0.0438341   0.176744    -0.169852   -0.436609    0.0344827     0.405025     0.158779   -0.213613     0.304785    -0.105062    0.549925     0.339942
 -0.512791    0.31033     -0.0450804   -0.333287   -0.576469    -0.0888018  -0.210389    -0.0564904  -0.55534     -0.030578    0.266429   -0.0657409   0.430195    0.865705     0.0184991  -0.719862     0.659252   -0.480153   -0.304263     -0.32647     -0.283462   -0.0340965   -0.688572     0.606533   -0.211111     0.0879029
  0.224411    0.112526     0.381685    -0.436751    0.102377    -0.257007   -0.127577    -0.118669   -0.14555     -0.653658    0.384397    0.0633747   0.150424    0.614495     0.150512   -0.587453    -0.41632     0.168794   -0.596149      0.180097    -0.50055    -0.686517    -0.27786      0.319276    0.0280872   -0.252839
  0.129908   -0.209999    -0.318892    -0.219503   -0.266341    -0.216127    0.00152148  -0.100452   -0.280828     0.154743   -0.0146497   0.345862    0.139309   -0.00764757   0.0582859  -0.509112    -0.122266    0.158176    0.000549199  -0.356699     0.36317     0.0326907   -0.162558    -0.0952001   0.0103176   -0.175113
  0.116833   -0.160484     0.295416     0.330753    0.412734    -0.118553    0.0492787   -0.688895    0.52861     -0.390643    0.177588   -0.127255    0.114214   -0.191237     0.376255    0.0699262    0.0708608   0.0258496   0.0964563    -0.0445288    0.083589    0.237971    -0.254381     0.0184456  -0.0983646    0.0313122
 -0.0364139  -0.390294     0.214354     0.267866   -0.0642702   -0.339729   -0.174572     0.0378695   0.4089       0.318073    0.132657   -0.4816     -0.0530028  -0.34209      0.134989    0.150208    -0.498425    0.0860635   0.0145907     0.0780383    0.394047   -0.114952     0.134599    -0.208142   -0.270901    -0.753774
  0.0710108   0.355664    -0.341167    -1.10233    -0.0681249   -0.55273     0.437301    -0.203868    0.417033     0.102499    0.169343   -0.269159   -0.58385     0.365021    -0.0771319   0.391622     0.227482    0.355487   -0.925069      0.224618    -0.157599    0.146712     0.120578     0.173161   -0.144266    -0.142069
 -0.425499   -0.46988      0.276729    -0.235853   -0.0173303    0.0851206   0.3944      -0.22232    -0.514469     0.262905   -0.121501   -0.160574   -0.285967   -0.0127235   -0.0692982   0.109582    -0.216992   -0.0428283   0.168137     -0.0863758    0.0744487  -0.0614515   -0.917173    -0.594105   -0.384538     0.245768
 -0.1574     -0.662039    -0.454156    -0.16197    -0.218926     0.585761    0.173411     0.172084    0.343557    -0.803094    0.200248   -0.450358   -0.312982   -0.459876     0.359063    0.498774    -0.29544    -0.299347   -0.326009      0.110207    -0.0635498   0.210904    -0.647745    -0.203687    0.480407     0.399389
  0.348336    0.0860512    0.208978    -0.289447   -0.340832    -0.0349229   0.0419529   -0.191476    0.411986    -0.150955    0.0859045   0.415992    0.0879196   0.616226     0.144441   -0.155467     0.86436     0.561537    0.0906555     0.790501     0.465339   -0.214151     0.23057      0.228874   -0.238749    -0.23092
 -0.0318742   0.157825     0.101102    -0.412003    0.393376     0.122362    0.137127    -0.146315    0.212454    -0.222226   -0.283899    0.233054    0.316866   -0.0252113    0.297238   -0.0459134    0.149563    0.175312   -0.0489593     0.340228    -0.242407    0.0875906   -0.0444993   -0.0216122  -0.238251     0.423536
 -0.146695   -0.610815     0.505676    -0.251072    0.136254    -0.169948    0.476101    -0.0401286   0.00648431  -0.168473   -0.742156    0.367114    0.40626     0.629191    -0.240429    0.245678    -0.214625   -0.206415    0.578491      0.0249971   -0.258024    0.0544772   -0.294794     0.769358    0.312492     0.143616
  0.045828    0.0373182   -0.139267    -0.188122    0.341552    -0.408241   -0.0393546   -0.230424   -0.502101     0.643027    0.212115    0.540324   -0.0335142  -0.129907     0.0173845  -0.813953    -0.016446    0.310166   -0.299423     -0.273485     0.256573   -0.517609    -0.265168    -0.39713    -0.638108    -0.237544
  0.129391    0.438752     0.0598071    0.481684    0.140033     0.346962   -0.0798428    0.126726    0.880086    -0.626164    0.0987103  -0.328031    0.215484    0.191079     0.497884    0.11317      0.0145949  -0.349652    0.261971      0.0079006    0.406605   -0.120022    -0.167937     0.26037    -0.121367     0.361306
 -0.282513    0.363322     0.0113397   -0.237172   -0.110124     0.36248     0.151221     1.19019     0.266078    -0.454386   -0.28558    -0.256724   -0.436644    0.27722      0.391279   -0.0385498   -0.240289    0.146629   -0.198263      0.272124     0.0118754  -0.252308     0.386164     0.084237    0.569339     0.165232
  0.0907798  -0.0430816    0.368921     0.17956     0.414563     0.0781518   0.419874     0.180235    0.561155    -0.221585   -0.184109   -0.523074   -0.0450797  -0.500873    -0.303669    0.890197    -0.309225   -0.0763749  -0.0857834     0.00870907  -0.0118218   0.203395     0.503188     0.26215     0.127617     0.291562
 -0.66184     0.300237     0.101211     0.793112    0.230309     0.372344   -0.0757853   -0.150029   -0.0990145   -0.0703961   0.145104   -0.231317    0.497706   -0.733219    -0.212127   -0.0843324    0.281134    0.381499   -0.0529381    -0.583363    -0.168205    0.0803738   -0.711973     0.775807   -0.455332    -0.287209[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412945
[ Info: iteration 2, average log likelihood -1.412934
[ Info: iteration 3, average log likelihood -1.412923
[ Info: iteration 4, average log likelihood -1.412912
[ Info: iteration 5, average log likelihood -1.412901
[ Info: iteration 6, average log likelihood -1.412890
[ Info: iteration 7, average log likelihood -1.412880
[ Info: iteration 8, average log likelihood -1.412869
[ Info: iteration 9, average log likelihood -1.412859
[ Info: iteration 10, average log likelihood -1.412849
┌ Info: EM with 100000 data points 10 iterations avll -1.412849
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
