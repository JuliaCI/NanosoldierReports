Julia Version 1.5.0-DEV.122
Commit a3ee6fe70d (2020-01-20 16:27 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed LegacyStrings ────── v0.4.1
 Installed URIParser ────────── v0.4.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed Parameters ───────── v0.12.0
 Installed StatsFuns ────────── v0.9.3
 Installed Clustering ───────── v0.13.3
 Installed Rmath ────────────── v0.6.0
 Installed DataAPI ──────────── v1.1.0
 Installed Distributions ────── v0.22.3
 Installed HDF5 ─────────────── v0.12.5
 Installed NearestNeighbors ─── v0.4.4
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed JLD ──────────────── v0.9.1
 Installed DataStructures ───── v0.17.9
 Installed FillArrays ───────── v0.8.4
 Installed ScikitLearnBase ──── v0.5.0
 Installed BinaryProvider ───── v0.5.8
 Installed OrderedCollections ─ v1.1.0
 Installed PDMats ───────────── v0.9.10
 Installed Missings ─────────── v0.4.3
 Installed Compat ───────────── v2.2.0
 Installed SortingAlgorithms ── v0.3.1
 Installed FileIO ───────────── v1.2.1
 Installed StaticArrays ─────── v0.12.1
 Installed Blosc ────────────── v0.5.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Arpack ───────────── v0.4.0
 Installed BinDeps ──────────── v1.0.0
 Installed QuadGK ───────────── v2.3.1
 Installed CMake ────────────── v1.1.2
 Installed Distances ────────── v0.8.2
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed StatsBase ────────── v0.32.0
 Installed SpecialFunctions ─── v0.9.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_Ef04bt/Project.toml`
 [no changes]
  Updating `/tmp/jl_Ef04bt/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_1L2nm6/Project.toml`
 [no changes]
  Updating `/tmp/jl_1L2nm6/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_y4CPNK/Project.toml`
 [no changes]
  Updating `/tmp/jl_y4CPNK/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_BUVGdK/Project.toml`
 [no changes]
  Updating `/tmp/jl_BUVGdK/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_MdGIK4/Project.toml`
 [no changes]
  Updating `/tmp/jl_MdGIK4/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_MdGIK4/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -3.181285781310049e6, [90923.73383633228, 9076.266163667719], [9883.44477885907 6087.836894029533 -11248.0719595811; -10149.482619193599 -5800.585879521518 10674.218015192608], [[84037.90882095552 -5059.927992274412 11001.87960735234; -5059.927992274412 89116.50335801065 5170.905624484423; 11001.87960735234 5170.905624484423 84381.74757765859], [15610.691069198572 4906.303937832458 -10740.94145234197; 4906.303937832458 11743.342333259545 -4846.105948188633; -10740.94145234197 -4846.105948188633 16076.88553631992]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.087244e+03
      1       9.323816e+02      -1.548622e+02 |        6
      2       9.234435e+02      -8.938044e+00 |        2
      3       9.210765e+02      -2.366991e+00 |        0
      4       9.210765e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 921.0765417588632)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.075480
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.772516
[ Info: iteration 2, lowerbound -3.624356
[ Info: iteration 3, lowerbound -3.468869
[ Info: iteration 4, lowerbound -3.303955
[ Info: iteration 5, lowerbound -3.150597
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -3.014954
[ Info: iteration 7, lowerbound -2.912054
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.842562
[ Info: iteration 9, lowerbound -2.801587
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.782258
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.765831
[ Info: iteration 12, lowerbound -2.747913
[ Info: iteration 13, lowerbound -2.725550
[ Info: iteration 14, lowerbound -2.691672
[ Info: iteration 15, lowerbound -2.643528
[ Info: iteration 16, lowerbound -2.581741
[ Info: iteration 17, lowerbound -2.513050
[ Info: iteration 18, lowerbound -2.448510
[ Info: iteration 19, lowerbound -2.396088
[ Info: iteration 20, lowerbound -2.356603
[ Info: iteration 21, lowerbound -2.328011
[ Info: iteration 22, lowerbound -2.311026
[ Info: iteration 23, lowerbound -2.307883
[ Info: dropping number of Gaussions to 2
[ Info: iteration 24, lowerbound -2.302917
[ Info: iteration 25, lowerbound -2.299260
[ Info: iteration 26, lowerbound -2.299256
[ Info: iteration 27, lowerbound -2.299254
[ Info: iteration 28, lowerbound -2.299254
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Jan 21 03:20:16 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Jan 21 03:20:24 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Tue Jan 21 03:20:27 2020: EM with 272 data points 0 iterations avll -2.075480
5.8 data points per parameter
, Tue Jan 21 03:20:29 2020: GMM converted to Variational GMM
, Tue Jan 21 03:20:37 2020: iteration 1, lowerbound -3.772516
, Tue Jan 21 03:20:37 2020: iteration 2, lowerbound -3.624356
, Tue Jan 21 03:20:37 2020: iteration 3, lowerbound -3.468869
, Tue Jan 21 03:20:37 2020: iteration 4, lowerbound -3.303955
, Tue Jan 21 03:20:37 2020: iteration 5, lowerbound -3.150597
, Tue Jan 21 03:20:37 2020: dropping number of Gaussions to 7
, Tue Jan 21 03:20:37 2020: iteration 6, lowerbound -3.014954
, Tue Jan 21 03:20:37 2020: iteration 7, lowerbound -2.912054
, Tue Jan 21 03:20:37 2020: dropping number of Gaussions to 5
, Tue Jan 21 03:20:37 2020: iteration 8, lowerbound -2.842562
, Tue Jan 21 03:20:37 2020: iteration 9, lowerbound -2.801587
, Tue Jan 21 03:20:37 2020: dropping number of Gaussions to 4
, Tue Jan 21 03:20:37 2020: iteration 10, lowerbound -2.782258
, Tue Jan 21 03:20:37 2020: dropping number of Gaussions to 3
, Tue Jan 21 03:20:37 2020: iteration 11, lowerbound -2.765831
, Tue Jan 21 03:20:37 2020: iteration 12, lowerbound -2.747913
, Tue Jan 21 03:20:37 2020: iteration 13, lowerbound -2.725550
, Tue Jan 21 03:20:37 2020: iteration 14, lowerbound -2.691672
, Tue Jan 21 03:20:37 2020: iteration 15, lowerbound -2.643528
, Tue Jan 21 03:20:37 2020: iteration 16, lowerbound -2.581741
, Tue Jan 21 03:20:37 2020: iteration 17, lowerbound -2.513050
, Tue Jan 21 03:20:37 2020: iteration 18, lowerbound -2.448510
, Tue Jan 21 03:20:37 2020: iteration 19, lowerbound -2.396088
, Tue Jan 21 03:20:37 2020: iteration 20, lowerbound -2.356603
, Tue Jan 21 03:20:37 2020: iteration 21, lowerbound -2.328011
, Tue Jan 21 03:20:37 2020: iteration 22, lowerbound -2.311026
, Tue Jan 21 03:20:37 2020: iteration 23, lowerbound -2.307883
, Tue Jan 21 03:20:37 2020: dropping number of Gaussions to 2
, Tue Jan 21 03:20:37 2020: iteration 24, lowerbound -2.302917
, Tue Jan 21 03:20:37 2020: iteration 25, lowerbound -2.299260
, Tue Jan 21 03:20:37 2020: iteration 26, lowerbound -2.299256
, Tue Jan 21 03:20:37 2020: iteration 27, lowerbound -2.299254
, Tue Jan 21 03:20:37 2020: iteration 28, lowerbound -2.299254
, Tue Jan 21 03:20:37 2020: iteration 29, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 30, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 31, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 32, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 33, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 34, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 35, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 36, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 37, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 38, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 39, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 40, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 41, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 42, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 43, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 44, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 45, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 46, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 47, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 48, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 49, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: iteration 50, lowerbound -2.299253
, Tue Jan 21 03:20:37 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222602704, 95.9549077739729]
β = [178.04509222602704, 95.9549077739729]
m = [4.250300733269805 79.28686694436028; 2.00022925777526 53.85198717246071]
ν = [180.04509222602704, 97.9549077739729]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547483736 -0.007644049042328894; 0.0 0.008581705166331588], [0.37587636119502543 -0.008953123827347855; 0.0 0.012748664777409775]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9965317505998795
avll from llpg:  -0.9965317505998799
avll direct:     -0.9965317505998799
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9886121983743908
avll from llpg:  -0.9886121983743908
avll direct:     -0.9886121983743907
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0774997   -0.103133     0.0382796   -0.000455982  -0.00200871  -0.017856     0.149397     0.0206119   -0.0445655   -0.0509621    0.0987535   -0.136747    -0.0284617  -0.156072     0.022952     0.0756315    0.249856     -0.0445445    0.0755643    -0.0539257   -0.061827      0.0194738     0.0808483   -0.0488157     0.0609118   -0.0738769
 -0.0282827   -0.0990943    0.151688     0.0108754     0.18473     -0.0198383   -0.119554     0.0664072    0.108433     0.00985168  -0.157518    -2.80646e-5  -0.234324    0.14226      0.149412     0.095251     0.0237165     0.0515809   -0.0532161    -0.267992    -0.00324932    0.163736     -0.14949      0.0170795     0.10008      0.0145502
  0.167677     0.119852     0.174408     0.00787496    0.152243    -0.1972      -0.25336      0.0796721    0.119511    -0.0757416    0.0918011   -0.181709    -0.0781141   0.120876     0.0790573    0.00604761   0.0794865    -0.0103152    0.0604129    -0.0535092   -0.047967      0.0129531    -0.0369757    0.0759568    -0.158671     0.056972
  0.0282235    0.137748     0.134708    -0.158233     -0.193589     0.0506548   -0.138612     0.152349     0.137402     0.0775198   -0.0614119    0.138392     0.103238   -0.115956    -0.00511152  -0.0419408   -0.0141403     0.0690392   -0.117591      0.00842997   0.0234481     0.107814      0.0538967   -0.025425     -0.0557411   -0.0956975
 -0.0253496    0.027407     0.0681553   -0.0412396     0.166343     0.00624155  -0.097203     0.106086    -0.0890444   -0.074525     0.0966474    0.0763411    0.0220929  -0.123133     0.00760222  -0.0211735    0.0249721    -0.103264     0.0634776    -0.233607     0.0825022    -0.0788112    -0.017242     0.0187816    -0.0934984   -0.0106089
 -0.00225654  -0.164124    -0.00658665   0.117427      0.1805      -0.0453662   -0.0413652   -0.092692     0.043325    -0.0937618    0.135747    -0.0533543   -0.146865   -0.160914     0.063128     0.0482033    0.0227334     0.0443729   -0.0293448     0.0352926    0.0102641    -0.0233015    -0.0187446    0.153975      0.159348     0.258003
  0.167476    -0.0737583    0.106124    -0.0140796    -0.0629693   -0.0412129   -0.0573254    0.0339364   -0.101233    -0.1497      -0.168544     0.124423     0.153703    0.12269     -0.10387     -0.157258    -0.00310765    0.0151838   -0.0416586     0.0708053    0.11596      -0.11907      -0.132148     0.0599979    -0.129827     0.0178158
 -0.0510332    0.077929    -0.152471    -0.00464362   -0.137714    -0.0759621    0.0543133   -0.176916     0.0874889    0.0439396   -0.093795     0.147309    -0.0598951  -0.0123101   -0.0309193   -0.085335    -0.115972      0.0185431    0.000251223   0.126459    -0.0260719     0.034447     -0.0617627   -0.0815872     0.0137317    0.0483638
 -0.103172    -0.215519     0.186727     0.0695644     0.12407      0.150047     0.111122     0.0220883    0.0608452   -0.0421807    0.0277553    0.0147893    0.08216    -0.023283    -0.0310085    0.163235    -0.105132      0.140913     0.107142      0.298109     0.234278     -0.11282       0.139147     0.132939     -0.214802    -0.028132
 -0.0089667   -0.0975555   -0.0181409    0.0716993    -0.0224935   -0.0545562    0.0102425    0.180708     0.11885      0.130673     0.0857995   -0.0998133   -0.0110416  -0.106356    -0.0896298    0.0784778   -0.0648274     0.212344    -0.00874133    0.00817565  -0.117446     -0.0232863     0.132066    -0.0100962     0.174053     0.0157296
 -0.0916348   -0.0833719    0.0631217    0.000352382   0.0443561    0.0540335    0.0573182   -0.0349754    0.137508    -0.0604166    0.0640726   -0.170016    -0.175442    0.0866983   -0.00753523  -0.0620284    0.132        -0.0127396   -0.028012      0.0569389    0.000333791  -0.112533     -0.0540019   -0.0438639     0.0482769    0.028286
 -0.105685    -0.0101983    0.181243    -0.0495677     0.0578271    0.102065     0.107136     0.118552    -0.0376459    0.0791314   -0.002545     0.150163     0.0524072   0.0705331    0.0614939   -0.00455302   0.0978795    -0.0159832   -0.196742     -0.0687448   -0.133116      0.140154      0.121359     0.0268019    -0.00876485  -0.125349
 -0.126737     0.0831848    0.134918    -0.0154036    -0.0166158   -0.0152211    0.0332883   -0.0380138    0.00912506  -0.147215     0.0197171    0.0340852   -0.022114    0.142075     0.0164792   -0.00760912   0.000457569  -0.00335664  -0.138039     -0.00447972  -0.0861232     0.101389     -0.0764051   -0.0629803    -0.078462    -0.128112
 -0.0699028   -0.167764    -0.0498861   -0.0150542     0.0241017   -0.129077     0.0248541   -0.0556261    0.146101    -0.0413808   -0.100169    -0.0228296    0.163143   -0.263474    -0.115508     0.0546492    0.0202181    -0.0677458    0.0493463     0.0849332    0.132842      0.025658      0.110295     0.120331      0.0352665    0.00615803
 -0.107714     0.00316173   0.0166588   -0.0243069    -0.134647     0.270826    -0.0902026    0.0751725   -0.0981055    0.0306481   -0.180514    -0.0608532   -0.225335   -0.0135557    0.124469     0.160922    -0.153011     -0.061305     0.194114      0.0437886    0.066166      0.11834      -0.137077    -0.0212951    -0.0569047   -0.120864
 -0.00899461   0.108367     0.124442     0.0927345     0.115322     0.0944222   -0.0152832   -0.0724517    0.0668284   -0.0901853    0.0527192    0.0935933   -0.0525213   0.0354509    0.209607    -0.171377     0.0194985     0.112027    -0.196611     -0.144282     0.0630896    -0.0499171    -0.0445772    0.172618      0.0297557    0.128798
  0.129793    -0.0676801   -0.0468048    0.263126      0.154871     0.137322    -0.0443576   -0.0507872   -0.0358396   -0.0170156    0.143994    -0.138897    -0.151799   -0.127377     0.086006    -0.0117785   -0.0167272    -0.0347639    0.0535638     0.0526808    0.000808657   0.0678157     0.0237352   -0.00956693    0.223746    -0.191148
  0.158642     0.0118976   -0.282183     0.0312536    -0.0815927    0.0225329    0.0596965    0.0498772    0.0989021    0.0556657   -0.194116    -0.156475    -0.0786498   0.0940128   -0.160074    -0.033594     0.104869      0.0900152   -0.0253891     0.159775     0.233032     -0.0909068    -0.00209457   0.175314      0.0232731    0.0123275
 -0.00463675  -0.0295372   -0.0151552    0.0455646     0.00839567  -0.0613402   -0.0883336   -0.0830518   -0.118121     0.0361399    0.0455239    0.226694     0.0505915   0.0576847   -0.00811303  -0.0768175    0.0967559     0.0229555   -0.117021      0.0707675   -0.0996127    -0.0776859    -0.110319     0.158215      0.161653     0.191002
 -0.0392971    0.240062    -0.0372476   -0.0121023     0.138546    -0.00764407   0.0708403    0.146113     0.091569     0.0450291   -0.0830324   -0.0271209   -0.0673802   0.121127     0.0179595    0.156644    -0.047575     -0.00776625  -0.0500572    -0.0968535    0.0707447     0.0884239    -0.143787     0.0128863    -0.00417509  -0.0302112
 -0.0290374   -0.0438816    0.0599924   -0.269676      0.0357398   -0.0777374   -0.0662696    0.0603049   -0.0179138   -0.112192    -0.16944     -0.0167257    0.0951131   0.249671    -0.0841689    0.167545     0.0579104    -0.101403     0.198666      0.023721    -0.0539599     0.000580772   0.12406      0.19133      -0.054203     0.0278025
 -0.202866    -0.0328907    0.038084     0.0292577    -0.0447893    0.0712853    0.025716     0.110683    -0.090725    -0.013588     0.105821     0.0564461    0.119456    0.0372244   -0.0420434    0.00678174  -0.0897674     0.161827     0.0267823     0.119922    -0.0419078    -0.131592      0.223921     0.163722      0.11206      0.073584
  0.110692    -0.121631     0.0241753   -0.0225272     0.130404    -0.106273     0.0728296   -0.211003    -0.0531008    0.0182583    0.0841598    0.0646586    0.0877131  -0.00567539  -0.0116154    0.0878274   -0.0739494     0.0782949   -0.0574639     0.108547     0.0487141    -0.151294     -0.0246592    0.0934014    -0.0549493    0.0898875
 -0.0924327    0.0174667    0.00711249  -0.0184628     0.258719     0.15587     -0.0154034    0.132983    -0.0879202    0.0249015   -0.0158277   -0.157616     0.0928159   0.0569791   -0.0143015   -0.0217722   -0.016036     -0.309476    -0.193359      0.0709521   -0.0247746    -0.109265      0.0112715    0.0938288     0.119145     0.0535933
  0.113968     0.0476186   -0.170666     0.124179      0.0469281   -0.0683513    0.0910879   -0.0942303    0.0681581   -0.0734141   -0.0565397   -0.0494412   -0.0643555  -0.0785025   -0.0218696   -0.0436849    0.261706     -0.0176531   -0.133843      0.0675031    0.11258      -0.0456508    -0.0670829   -0.000171627  -0.0465447   -0.0727311
  0.0235972   -0.104792    -0.0516092   -0.0137106    -0.122413     0.0467556   -0.0388273   -0.140801    -0.108513     0.0713177    0.0479814    0.0135817    0.156677    0.1353       0.0439398    0.0260755   -0.000458259   0.0640034    0.000360442   0.126028     0.318772      0.196993     -0.027917    -0.206463     -0.0727814    0.0633608
 -0.00112422   0.0464066    0.00332578   0.00279728   -0.074261    -0.0223135   -0.247516     0.0227168    0.0418359   -0.1015      -0.0278195   -0.0113455   -0.0948618   0.221498     0.0197875    0.0851301   -0.13315      -0.0723991    0.00437226   -0.00638929   0.0524836    -0.0108897    -0.135771     0.0423261     0.295687    -0.195527
 -0.0123633    0.0836787   -0.0753741    0.188331     -0.0825355    0.132563    -0.183564     0.0782882   -0.0898701    0.259275     0.0609671    0.0605707   -0.0230894  -0.0680255    0.0155017   -0.0808421   -0.0258923    -0.0740639   -0.0578316     0.0889521   -0.0939527    -0.101012      0.104742     0.0349626    -0.0621869    0.0283228
 -0.108605     0.149237    -0.13509      0.258192      0.0251308    0.0571213    0.00345999   0.00772574   0.0650081    0.151277    -0.178581     0.0169142    0.0595243  -0.0229365    0.149285     0.0683947   -0.0340512     0.0472406    0.0958659    -0.0517351    0.0303478     0.124454     -0.0773475    0.0299636     0.0508266   -0.0517665
 -0.047116     0.0156663    0.0577584    0.225246     -0.250582    -0.0489873    0.0653209   -0.0387988    0.190501     0.132553     0.00405288   0.120861    -0.0793418  -0.086957    -0.183348     0.0393732    0.0145651     0.0539302   -0.227287     -0.0747047   -0.0579187    -0.0366802    -0.125542    -0.0141604    -0.0734049    0.0137449
  0.141531    -0.0551273    0.0681586    0.115888      0.0391269    0.158569     0.0963522    0.0897668   -0.0254033    0.100052     0.0342802    0.0748752    0.1318      0.0197714   -0.0538597    0.0186824    0.0603475    -0.0155024    0.00693948    0.159426     0.224786     -0.0515392    -0.186541    -0.0714409    -0.124832    -0.0236363
  0.16455      0.0590136   -0.0993422    0.05265      -0.0424445    0.105408     0.158435    -0.078989    -0.0671251    0.0215168   -0.0430599   -0.0553511   -0.0122789  -0.00151524  -0.0628765   -0.179356     0.0420745    -0.00386813   0.0617765    -0.0218406    0.00522014    0.1055        0.113142    -0.3378       -0.0180758    0.0517127kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3993486668415132
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.399417
[ Info: iteration 2, average log likelihood -1.399358
[ Info: iteration 3, average log likelihood -1.399117
[ Info: iteration 4, average log likelihood -1.396355
[ Info: iteration 5, average log likelihood -1.383493
[ Info: iteration 6, average log likelihood -1.371991
[ Info: iteration 7, average log likelihood -1.369646
[ Info: iteration 8, average log likelihood -1.368777
[ Info: iteration 9, average log likelihood -1.368151
[ Info: iteration 10, average log likelihood -1.367562
[ Info: iteration 11, average log likelihood -1.366997
[ Info: iteration 12, average log likelihood -1.366500
[ Info: iteration 13, average log likelihood -1.366099
[ Info: iteration 14, average log likelihood -1.365799
[ Info: iteration 15, average log likelihood -1.365566
[ Info: iteration 16, average log likelihood -1.365378
[ Info: iteration 17, average log likelihood -1.365224
[ Info: iteration 18, average log likelihood -1.365098
[ Info: iteration 19, average log likelihood -1.364995
[ Info: iteration 20, average log likelihood -1.364910
[ Info: iteration 21, average log likelihood -1.364840
[ Info: iteration 22, average log likelihood -1.364782
[ Info: iteration 23, average log likelihood -1.364734
[ Info: iteration 24, average log likelihood -1.364694
[ Info: iteration 25, average log likelihood -1.364661
[ Info: iteration 26, average log likelihood -1.364635
[ Info: iteration 27, average log likelihood -1.364613
[ Info: iteration 28, average log likelihood -1.364596
[ Info: iteration 29, average log likelihood -1.364582
[ Info: iteration 30, average log likelihood -1.364571
[ Info: iteration 31, average log likelihood -1.364562
[ Info: iteration 32, average log likelihood -1.364554
[ Info: iteration 33, average log likelihood -1.364548
[ Info: iteration 34, average log likelihood -1.364543
[ Info: iteration 35, average log likelihood -1.364540
[ Info: iteration 36, average log likelihood -1.364536
[ Info: iteration 37, average log likelihood -1.364534
[ Info: iteration 38, average log likelihood -1.364531
[ Info: iteration 39, average log likelihood -1.364530
[ Info: iteration 40, average log likelihood -1.364528
[ Info: iteration 41, average log likelihood -1.364527
[ Info: iteration 42, average log likelihood -1.364526
[ Info: iteration 43, average log likelihood -1.364525
[ Info: iteration 44, average log likelihood -1.364524
[ Info: iteration 45, average log likelihood -1.364524
[ Info: iteration 46, average log likelihood -1.364523
[ Info: iteration 47, average log likelihood -1.364523
[ Info: iteration 48, average log likelihood -1.364522
[ Info: iteration 49, average log likelihood -1.364522
[ Info: iteration 50, average log likelihood -1.364522
┌ Info: EM with 100000 data points 50 iterations avll -1.364522
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3994166778808972
│     -1.3993583012306976
│      ⋮
└     -1.3645219510743347
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.364628
[ Info: iteration 2, average log likelihood -1.364534
[ Info: iteration 3, average log likelihood -1.364272
[ Info: iteration 4, average log likelihood -1.362049
[ Info: iteration 5, average log likelihood -1.353742
[ Info: iteration 6, average log likelihood -1.342799
[ Info: iteration 7, average log likelihood -1.336014
[ Info: iteration 8, average log likelihood -1.332191
[ Info: iteration 9, average log likelihood -1.329067
[ Info: iteration 10, average log likelihood -1.326312
[ Info: iteration 11, average log likelihood -1.324202
[ Info: iteration 12, average log likelihood -1.322907
[ Info: iteration 13, average log likelihood -1.322180
[ Info: iteration 14, average log likelihood -1.321731
[ Info: iteration 15, average log likelihood -1.321422
[ Info: iteration 16, average log likelihood -1.321185
[ Info: iteration 17, average log likelihood -1.320994
[ Info: iteration 18, average log likelihood -1.320845
[ Info: iteration 19, average log likelihood -1.320726
[ Info: iteration 20, average log likelihood -1.320628
[ Info: iteration 21, average log likelihood -1.320541
[ Info: iteration 22, average log likelihood -1.320459
[ Info: iteration 23, average log likelihood -1.320373
[ Info: iteration 24, average log likelihood -1.320279
[ Info: iteration 25, average log likelihood -1.320168
[ Info: iteration 26, average log likelihood -1.320037
[ Info: iteration 27, average log likelihood -1.319880
[ Info: iteration 28, average log likelihood -1.319696
[ Info: iteration 29, average log likelihood -1.319488
[ Info: iteration 30, average log likelihood -1.319261
[ Info: iteration 31, average log likelihood -1.319020
[ Info: iteration 32, average log likelihood -1.318772
[ Info: iteration 33, average log likelihood -1.318504
[ Info: iteration 34, average log likelihood -1.318194
[ Info: iteration 35, average log likelihood -1.317842
[ Info: iteration 36, average log likelihood -1.317438
[ Info: iteration 37, average log likelihood -1.316938
[ Info: iteration 38, average log likelihood -1.316325
[ Info: iteration 39, average log likelihood -1.315614
[ Info: iteration 40, average log likelihood -1.314876
[ Info: iteration 41, average log likelihood -1.314207
[ Info: iteration 42, average log likelihood -1.313677
[ Info: iteration 43, average log likelihood -1.313317
[ Info: iteration 44, average log likelihood -1.313074
[ Info: iteration 45, average log likelihood -1.312897
[ Info: iteration 46, average log likelihood -1.312751
[ Info: iteration 47, average log likelihood -1.312625
[ Info: iteration 48, average log likelihood -1.312514
[ Info: iteration 49, average log likelihood -1.312407
[ Info: iteration 50, average log likelihood -1.312294
┌ Info: EM with 100000 data points 50 iterations avll -1.312294
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3646277148833383
│     -1.3645335415625328
│      ⋮
└     -1.3122942850724313
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.312337
[ Info: iteration 2, average log likelihood -1.312074
[ Info: iteration 3, average log likelihood -1.311218
[ Info: iteration 4, average log likelihood -1.304875
[ Info: iteration 5, average log likelihood -1.288162
[ Info: iteration 6, average log likelihood -1.272775
[ Info: iteration 7, average log likelihood -1.265178
[ Info: iteration 8, average log likelihood -1.261621
[ Info: iteration 9, average log likelihood -1.259235
[ Info: iteration 10, average log likelihood -1.257110
[ Info: iteration 11, average log likelihood -1.255250
[ Info: iteration 12, average log likelihood -1.253407
[ Info: iteration 13, average log likelihood -1.250308
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.243465
[ Info: iteration 15, average log likelihood -1.260756
[ Info: iteration 16, average log likelihood -1.254191
[ Info: iteration 17, average log likelihood -1.250172
[ Info: iteration 18, average log likelihood -1.244504
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.237199
[ Info: iteration 20, average log likelihood -1.259788
[ Info: iteration 21, average log likelihood -1.253207
[ Info: iteration 22, average log likelihood -1.249771
[ Info: iteration 23, average log likelihood -1.245276
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.237730
[ Info: iteration 25, average log likelihood -1.259313
[ Info: iteration 26, average log likelihood -1.252900
[ Info: iteration 27, average log likelihood -1.249738
[ Info: iteration 28, average log likelihood -1.245694
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.238263
[ Info: iteration 30, average log likelihood -1.259264
[ Info: iteration 31, average log likelihood -1.252861
[ Info: iteration 32, average log likelihood -1.249775
[ Info: iteration 33, average log likelihood -1.245898
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.238513
[ Info: iteration 35, average log likelihood -1.259252
[ Info: iteration 36, average log likelihood -1.252849
[ Info: iteration 37, average log likelihood -1.249798
[ Info: iteration 38, average log likelihood -1.246005
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.238652
[ Info: iteration 40, average log likelihood -1.259248
[ Info: iteration 41, average log likelihood -1.252845
[ Info: iteration 42, average log likelihood -1.249813
[ Info: iteration 43, average log likelihood -1.246064
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.238732
[ Info: iteration 45, average log likelihood -1.259245
[ Info: iteration 46, average log likelihood -1.252843
[ Info: iteration 47, average log likelihood -1.249821
[ Info: iteration 48, average log likelihood -1.246098
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.238778
[ Info: iteration 50, average log likelihood -1.259244
┌ Info: EM with 100000 data points 50 iterations avll -1.259244
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3123366250618158
│     -1.3120744122969792
│      ⋮
└     -1.2592440423772309
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.253023
[ Info: iteration 2, average log likelihood -1.249712
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.242798
[ Info: iteration 4, average log likelihood -1.235602
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.192530
[ Info: iteration 6, average log likelihood -1.180454
[ Info: iteration 7, average log likelihood -1.161947
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.147190
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.145700
[ Info: iteration 10, average log likelihood -1.156621
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.145616
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.154169
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.149013
[ Info: iteration 14, average log likelihood -1.150138
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.132563
[ Info: iteration 16, average log likelihood -1.155740
[ Info: iteration 17, average log likelihood -1.145766
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.132459
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.139821
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.143442
[ Info: iteration 21, average log likelihood -1.155910
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.133180
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.135562
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.144095
[ Info: iteration 25, average log likelihood -1.149644
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.130346
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.134180
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.149570
[ Info: iteration 29, average log likelihood -1.151056
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.134129
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.136567
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.144130
[ Info: iteration 33, average log likelihood -1.149952
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.131086
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.134604
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.143953
[ Info: iteration 37, average log likelihood -1.149293
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.129807
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.141246
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.144950
[ Info: iteration 41, average log likelihood -1.150393
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.132535
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.135246
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.144063
[ Info: iteration 45, average log likelihood -1.149585
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.130266
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.134180
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.149574
[ Info: iteration 49, average log likelihood -1.151050
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.134127
┌ Info: EM with 100000 data points 50 iterations avll -1.134127
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2530230118519747
│     -1.2497121284631385
│      ⋮
└     -1.134126943404277
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.136822
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.125453
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.130310
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     20
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.084040
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.052478
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      6
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.026632
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.053101
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│     11
│     13
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.016137
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.051664
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     20
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.044274
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.034527
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│     11
│     13
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.029183
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.062058
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     20
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.043132
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.034364
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     13
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.039984
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.054188
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│     11
│     20
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.038816
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     17
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.045519
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     13
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.032925
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.050473
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     20
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.049986
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.038032
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│     11
│     13
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.028979
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.061615
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     20
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.043009
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      8
│     17
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.034461
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     13
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.040210
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.054165
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│     11
│     20
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.038758
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.045579
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     13
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.032981
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.050449
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     20
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.049898
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     17
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.038059
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│     11
│     13
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.028975
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.061597
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     20
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.042906
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.034476
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     13
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.040151
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.054150
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│     11
│     20
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.038664
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     17
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.045587
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     13
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.032948
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.050441
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     20
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.049835
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.038067
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│     11
│     13
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.028943
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.061588
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     20
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.042870
┌ Info: EM with 100000 data points 50 iterations avll -1.042870
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.13682243252463
│     -1.1254532289373638
│      ⋮
└     -1.0428696859974276
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3993486668415132
│     -1.3994166778808972
│     -1.3993583012306976
│     -1.3991167853639859
│      ⋮
│     -1.0289430153954544
│     -1.0615881977616781
└     -1.0428696859974276
32×26 Array{Float64,2}:
 -0.0432829    0.00235382    0.105668    -0.252484     0.00797171  -0.0800564  -0.0655974    0.0528579  -0.0159575   -0.107064    -0.165942   -0.022305     0.0958188    0.255922    -0.0744667    0.165926     0.0629695    -0.106793     0.186171     0.0319438   -0.0617504   -0.0101892     0.1329       0.184478    -0.0342214    0.0116422
 -0.0190408    0.119782      0.164057     0.0046778    0.121107     0.089509    0.0191279   -0.0891966   0.065123    -0.064413     0.0505506   0.115965    -0.0255043    0.0296428    0.223616    -0.1643       0.0372185     0.110147    -0.196474    -0.134235     0.0612523   -0.0398827    -0.0368916    0.163852     0.0325858    0.128587
  0.0831373   -0.116119      0.01283     -0.0316271    0.10523     -0.0953893   0.0763816   -0.177023   -0.0543045    0.0118058    0.0829336   0.0590761    0.081079    -0.00420635  -0.00620866   0.0927902   -0.0807796     0.0782435   -0.0539129    0.153092     0.0668751   -0.151633     -0.0162967    0.0911338   -0.0563192    0.0334069
  0.149306     0.00574828   -0.279259    -0.0169002   -0.09998      0.0254524   0.067373     0.0445666   0.0866811    0.0769747   -0.191865   -0.157879    -0.0779083    0.0927129   -0.155171    -0.0364251    0.103945      0.0887286   -0.0266923    0.166587     0.232944    -0.0924034    -0.0183586    0.176318     0.0397665    0.02369
 -0.0618938   -0.102991      0.0422089    0.0118387    0.00626199  -0.0121678   0.158326     0.0176452  -0.00656512  -0.0533768    0.0982273  -0.142468    -0.0310224   -0.152239    -0.0224049    0.0934379    0.275127     -0.0502491    0.0556271   -0.0237334   -0.0331037    0.0455439     0.0838047   -0.0450058    0.0545999   -0.0558131
 -0.201004    -0.0458264     0.0357565    0.106371    -0.0390529    0.0630949   0.0120109    0.110465   -0.0868425   -0.0213511    0.101486    0.110972     0.128763     0.0368249   -0.031645     0.00910388  -0.0723377     0.157457     0.0321584    0.109919    -0.0498347   -0.123325      0.217073     0.173366     0.113225     0.0677839
  0.17664     -0.129365      0.109884    -0.0371483   -0.0824804   -0.0410163  -0.0548566    0.0585789  -0.153619    -0.139168    -0.179802    0.126657     0.141661     0.133668    -0.0961938   -0.153376     0.0323113     0.015201    -0.0301301    0.0823135    0.144389    -0.112484     -0.133598     0.0664424   -0.148838     0.0309625
 -0.154071     0.177624      0.166236    -0.0090376   -0.0181825   -0.0157427   0.0114568   -0.0297828   0.0065963   -0.157986     0.0164706   0.0392216   -0.0220567    0.0872878    0.0258781    0.0168992   -0.00181108   -0.0101676   -0.138428    -0.00710655  -0.0771496    0.0834523    -0.0769952   -0.049027    -0.0693801   -0.125268
 -0.0689587   -0.0291994     0.0675198    0.00402129  -0.00237825   0.153985   -0.0815158    0.0736917   0.0226263    0.00555727  -0.185549   -0.0228359   -0.243479     0.0513894    0.132394     0.121547    -0.0787785    -0.0298347    0.0782068   -0.0827932    0.0275215    0.130706     -0.125785     0.00761304  -0.00738767  -0.0402356
 -0.0682248    0.169911     -0.0715294    0.112403     0.0972467    0.0178385   0.0530028    0.075231    0.103157     0.093484    -0.128942    0.00422055  -0.019573     0.0701006    0.0903672    0.0960148   -0.041481      0.00697571  -0.0177674   -0.0804023    0.0339232    0.102633     -0.116674     0.0194728    0.0315965   -0.0154193
 -0.0113882    0.0777494     0.0700024   -0.0399414    0.161508    -0.018283   -0.0872816    0.109062   -0.0831173   -0.0434121    0.0974176   0.0751984    0.0389643   -0.125369    -0.00688546  -0.0642114    0.0194879    -0.10562      0.0259368   -0.223611     0.0816452   -0.0405866    -0.0105143    0.0156569   -0.0928786   -0.021829
  0.115058     0.093326      0.0602374    0.0948784    0.0121047   -0.0414083  -0.240803     0.0738527   0.0103775    0.0814004    0.0721904  -0.065479    -0.0477723    0.0346103    0.0741352   -0.0344105    0.0213129    -0.0367718    0.00775455   0.0258622   -0.0729332   -0.039073      0.0290188    0.0568575   -0.111878     0.0622776
  0.00122312  -0.0106874     0.0288594    0.030064    -0.0907557   -0.0217875  -0.26326      0.0218187   0.0442281   -0.0898449   -0.0306955  -0.00949723  -0.0932266    0.205809     0.0232395    0.0720674   -0.116037     -0.0424447   -0.0238459    0.0536955    0.0262711   -0.0390898    -0.114829     0.0412934    0.288366    -0.197954
 -0.089516     0.000756191   0.120984     0.0919202   -0.0976643    0.028696    0.0851329    0.0224928   0.0779244    0.107112     0.0104594   0.119645    -0.0207316   -0.0014901   -0.0910062    0.0302979    0.057682      0.0117203   -0.206976    -0.049771    -0.0995006    0.0460039    -0.00433046   0.00693802  -0.0530507   -0.0590249
 -0.00858698  -0.124058     -0.00694535   0.0500315   -0.0335341   -0.0791418   0.0274367    0.104024    0.123939     0.105878     0.0422023  -0.0975091    0.0158121   -0.121694    -0.0936181    0.0240764   -0.0665647     0.187855     0.00396221  -0.0131447   -0.0694257   -0.000459483   0.123833    -0.00773115   0.150582     0.00949741
 -0.0435979   -0.106316     -0.0373409    0.0196102    0.0407775   -0.07545    -0.086599    -0.0415712  -0.0120397    0.00590684  -0.0651148   0.126688     0.110747    -0.0648748   -0.0504582   -0.0151854    0.0706054    -0.0400195   -0.0417036    0.0641334   -0.00949925  -0.0310063     0.0202602    0.18538      0.109111     0.121022
 -0.0960192    0.0462424     0.0118848   -0.0227086    0.328072     0.172021   -0.0236423    0.121146   -0.108407     0.0273977   -0.13344    -0.117972     0.0848893    0.107558    -0.555362    -0.0205384    0.0523945    -0.351559    -0.153555     0.111248     0.0052881   -0.207921      0.026685     0.136964     0.103746    -0.285808
 -0.0855691    0.00688501    0.00243346  -0.015673     0.233236     0.138289   -0.0152629    0.142931   -0.0962643    0.0217181    0.111046   -0.255223     0.0949572   -0.0153328    0.440684    -0.024716    -0.0737039    -0.30975     -0.258998     0.0078782   -0.0897103   -0.0108464    -0.00793914   0.0243962    0.151325     0.359035
  0.0671257    0.0756193    -0.0335209   -0.0164068   -0.0795686   -0.0184073  -0.0316136    0.0223192   0.121114    -0.0188039   -0.0592668   0.0406601    0.0102991   -0.093269    -0.0135458   -0.0428718    0.102789      0.0340775   -0.114339     0.0393334    0.0703281    0.0286947    -0.0129387   -0.0202074   -0.0504372   -0.0904265
 -0.0950703   -0.215643      0.167643     0.0732011    0.133865     0.145442    0.110207     0.026492    0.02374     -0.0472194    0.0468074   0.0146288    0.0808391   -0.00435614  -0.0374211    0.15832     -0.0988411     0.140201     0.174033     0.293426     0.164985    -0.138084      0.131525     0.128108    -0.211805    -0.0393177
  0.180398     0.0564595    -0.0774153    0.0163435   -0.0364606    0.188777    0.151902    -0.0549384   0.31325      0.0766446   -0.0284439  -0.142369    -0.00246356   0.058439    -0.0632604   -0.167726    -0.0668938    -0.0576273    0.0733768   -0.0258448   -0.627589     0.0999471     0.0993222   -0.306671     0.0130225    0.0584907
  0.126199     0.0787087    -0.12278      0.102137    -0.0434532    0.147753    0.169435    -0.0914584  -0.457298    -0.00830905  -0.0514931   0.016805    -0.01219     -0.104161    -0.0570861   -0.172939     0.107902      0.0501498    0.050281    -0.0253139    0.56681      0.108151      0.118899    -0.353345    -0.0255586    0.0484639
 -0.0167354   -0.0739778    -0.0355714   -3.51828e-5  -0.158504     0.261265   -0.034411    -0.169879   -0.108471     0.22444      0.0915031  -0.243737     0.17876      0.20868     -0.442049    -0.00675765   0.000332775   0.178228     0.0575041    0.0555551    0.335341     0.265375     -0.0240151   -0.231853    -0.150269    -0.0451319
  0.0547721   -0.143548     -0.0669322   -0.0339818   -0.0894574   -0.0673819  -0.0430452   -0.111099   -0.109167    -0.0803134    0.0144889   0.0793797    0.152232     0.121103     0.521079     0.0527173   -0.000572293   0.0424593    0.0040063    0.143551     0.29619      0.147635     -0.0309432   -0.163126    -0.00687819   0.0911934
  0.116926    -0.0866883     0.0543295    0.105236     0.0228407    0.0950299   0.00659356   0.140919   -0.00816469   0.118234    -0.0281804   0.20861     -0.34665      0.0209805   -0.0794357   -0.0980132    0.0558157     0.0690945    0.00244028   0.200683     0.222974    -0.0974296    -0.0522237   -0.0341564   -0.0883983   -0.016896
  0.118613    -0.0474278     0.0829135    0.109614     0.0796993    0.211143    0.162998     0.0581285  -0.0423566    0.0850842    0.0947018   0.00258796   0.537804     0.0259594   -0.0172133    0.140834     0.0646966    -0.049815     0.0093604    0.10982      0.239585     0.0190658    -0.274532    -0.0832105   -0.218595    -0.0422206
  0.121491    -0.0603024    -0.0522781    0.244185     0.156348     0.150617   -0.0462379   -0.0508816  -0.039563    -0.0195059    0.153059   -0.14768     -0.149237    -0.130119     0.0863781   -0.0278254   -0.016671     -0.0351416    0.0491485    0.0504836   -0.00999199   0.0766191     0.0141378   -0.00409906   0.224364    -0.206892
 -0.105137    -0.0958579     0.0685508    0.00288543   0.0462489    0.054973    0.0612043   -0.0363416   0.137233    -0.0731496    0.0932487  -0.151454    -0.189932     0.0909499   -0.012538    -0.0375804    0.140449     -0.00522359  -0.0287826    0.0452767    0.0281752   -0.110733     -0.0539757   -0.046868     0.0482342    0.0298548
 -0.0561862    0.0963836    -0.15196     -0.00429978  -0.145525    -0.0367432   0.0463846   -0.181045    0.0929697    0.0574238   -0.0722738   0.105401    -0.0631195   -0.0109333    0.0190951   -0.104295    -0.127661      0.0173228   -0.67602      0.151058    -0.0590199    0.149751     -0.201192    -0.0753169    0.0130074    0.0600984
 -0.0470102    0.0943097    -0.129944    -0.00466653  -0.129641    -0.101521    0.0493534   -0.196939    0.0815211    0.0158453   -0.129548    0.119413    -0.0650694   -0.0118826   -0.0886713   -0.0667961   -0.0972917     0.0225425    0.69006      0.107291     0.00616956  -0.0301716    -0.044223    -0.083255    -0.0158219    0.0997341
  0.00856621  -0.143525     -0.00603373   0.118531     0.181772    -0.0456244  -0.0407564   -0.0373853   0.0472932   -0.0906303    0.132948   -0.0534187   -0.155556    -0.158296     0.14375      0.0549926   -0.519247      0.104558    -0.0267265   -0.00439707   0.0121624    0.0229545    -0.00387302   0.205696     0.0921081    0.256274
 -0.00411193  -0.18111      -0.00629671   0.117103     0.182909    -0.0452556  -0.0417544   -0.107286    0.0439834   -0.0948426    0.134034   -0.0562143   -0.159444    -0.155308    -0.0290303    0.0596893    0.55263       0.0483158   -0.0252707    0.0897697    0.00741052  -0.0572526    -0.041637     0.13003      0.265815     0.256833[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.034479
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.000878
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      8
│     17
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.034313
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.999690
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.034328
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.999580
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      8
│     17
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.034329
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.999569
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      8
│     17
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.034329
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.999567
┌ Info: EM with 100000 data points 10 iterations avll -0.999567
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.935009e+05
      1       6.737614e+05      -2.197395e+05 |       32
      2       6.459311e+05      -2.783030e+04 |       32
      3       6.299499e+05      -1.598124e+04 |       32
      4       6.181604e+05      -1.178946e+04 |       32
      5       6.095805e+05      -8.579895e+03 |       32
      6       6.039032e+05      -5.677270e+03 |       32
      7       6.000930e+05      -3.810204e+03 |       32
      8       5.979673e+05      -2.125703e+03 |       32
      9       5.969050e+05      -1.062315e+03 |       32
     10       5.964006e+05      -5.044053e+02 |       32
     11       5.961464e+05      -2.542063e+02 |       32
     12       5.959766e+05      -1.697831e+02 |       32
     13       5.958334e+05      -1.432619e+02 |       32
     14       5.955751e+05      -2.582244e+02 |       32
     15       5.950825e+05      -4.926246e+02 |       32
     16       5.944707e+05      -6.118104e+02 |       32
     17       5.939464e+05      -5.243233e+02 |       32
     18       5.935835e+05      -3.628264e+02 |       32
     19       5.933856e+05      -1.978956e+02 |       32
     20       5.932552e+05      -1.304170e+02 |       32
     21       5.931504e+05      -1.048207e+02 |       32
     22       5.930266e+05      -1.238471e+02 |       32
     23       5.928838e+05      -1.428048e+02 |       32
     24       5.926635e+05      -2.202293e+02 |       32
     25       5.923839e+05      -2.795943e+02 |       32
     26       5.921024e+05      -2.815738e+02 |       32
     27       5.917788e+05      -3.235646e+02 |       32
     28       5.915022e+05      -2.765741e+02 |       32
     29       5.912646e+05      -2.376384e+02 |       32
     30       5.911037e+05      -1.608762e+02 |       32
     31       5.910080e+05      -9.575549e+01 |       32
     32       5.909727e+05      -3.524764e+01 |       32
     33       5.909546e+05      -1.807963e+01 |       30
     34       5.909404e+05      -1.424450e+01 |       31
     35       5.909304e+05      -1.001502e+01 |       29
     36       5.909240e+05      -6.372483e+00 |       28
     37       5.909192e+05      -4.773469e+00 |       22
     38       5.909154e+05      -3.818455e+00 |       27
     39       5.909111e+05      -4.327293e+00 |       24
     40       5.909059e+05      -5.148747e+00 |       26
     41       5.908998e+05      -6.108757e+00 |       26
     42       5.908931e+05      -6.694772e+00 |       27
     43       5.908868e+05      -6.286085e+00 |       29
     44       5.908809e+05      -5.918064e+00 |       26
     45       5.908762e+05      -4.704517e+00 |       27
     46       5.908723e+05      -3.927262e+00 |       27
     47       5.908682e+05      -4.102961e+00 |       28
     48       5.908621e+05      -6.122138e+00 |       27
     49       5.908565e+05      -5.562181e+00 |       26
     50       5.908521e+05      -4.411506e+00 |       24
K-means terminated without convergence after 50 iterations (objv = 590852.0868163984)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.312333
[ Info: iteration 2, average log likelihood -1.279443
[ Info: iteration 3, average log likelihood -1.249162
[ Info: iteration 4, average log likelihood -1.211769
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.150046
[ Info: iteration 6, average log likelihood -1.098208
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     11
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.037644
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│     15
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.058612
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.076585
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.056858
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     11
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.023969
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.062649
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     13
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.036157
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.038016
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.058644
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.036436
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     11
│     13
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -0.992836
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     10
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.031615
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.049001
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     13
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.032937
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.042927
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      4
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.016333
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     13
│     15
│     23
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.007843
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.075990
[ Info: iteration 25, average log likelihood -1.057527
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│     11
│     13
│     19
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.979000
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     15
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.055781
[ Info: iteration 28, average log likelihood -1.087536
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.032650
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     11
│     19
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -0.999735
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│     13
│     15
│     23
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.037344
[ Info: iteration 32, average log likelihood -1.102159
[ Info: iteration 33, average log likelihood -1.040419
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     10
│     11
│     13
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -0.977928
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.063676
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.059352
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     13
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.026428
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.027831
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     15
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.011254
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     13
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.030548
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.035613
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.034220
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     13
│     15
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.006483
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      9
│     10
│     11
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.045639
[ Info: iteration 45, average log likelihood -1.081859
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     19
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.023084
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│      6
│     10
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.021877
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.053888
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     13
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.020524
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.033629
┌ Info: EM with 100000 data points 50 iterations avll -1.033629
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0931694   -0.2128       0.162284     0.0705313    0.130218     0.140186     0.113089     0.0267884    0.0205584   -0.046326     0.0479793    0.0136384    0.0774021   -0.00857277  -0.0488612    0.15671     -0.0890912    0.134107     0.165222     0.287546    0.156302    -0.137864    0.134039    0.123472    -0.205086     -0.0418659
  0.0876901   -0.116639     0.016562    -0.020632     0.103793    -0.0913211    0.0764489   -0.172053    -0.0551724    0.0132101    0.0860966    0.0493388    0.0758446   -0.00195221   0.0043322    0.091182    -0.0804253    0.0770014   -0.0551878    0.152004    0.0650166   -0.154151   -0.0108283   0.0858961   -0.0483652     0.0378558
 -0.0320188    0.062771     0.13021     -0.128917     0.0711629    0.00348229  -0.0218001   -0.0163024    0.0235977   -0.0881235   -0.0620065    0.0445675    0.0366377    0.139436     0.0789093    0.00278637   0.0533045    0.00389892  -0.00493113  -0.054009    0.00250297  -0.0257382   0.0490857   0.178113    -0.00285337    0.0730735
 -0.159843     0.172857     0.167159    -0.0154658   -0.00920292  -0.0145173    0.0178855   -0.0381395    0.00803356  -0.157626     0.0247273    0.0304196   -0.0266982    0.110257     0.032652     0.0260065   -0.0101865   -0.0106907   -0.136924    -0.0101513  -0.0867554    0.0872752  -0.0756254  -0.0581595   -0.0648101    -0.130851
  0.119467    -0.0665194    0.0671347    0.109906     0.0527911    0.154007     0.0850964    0.0988663   -0.024894     0.097982     0.0381865    0.111181     0.101682     0.01994     -0.0492491    0.0234169    0.0602854    0.00570676   0.00498269   0.159277    0.225852    -0.0426477  -0.161097   -0.0627225   -0.158163     -0.0285356
 -0.0649045   -0.106584    -0.113244     0.0934038   -0.673602    -0.118376    -0.0772022    0.0397484    0.113856     0.121261    -0.0175994    0.0217257   -0.0243883    0.0209285   -0.071304    -0.0630561    0.0446572    0.164817     0.00554824   0.0229639   0.203713    -0.0651689  -0.0499649  -0.0404224    0.214576     -0.00149742
  0.0214003   -0.110438    -0.0512607   -0.0196424   -0.12219      0.089089    -0.0390064   -0.138324    -0.109133     0.0622626    0.052891    -0.0721203    0.165877     0.162332     0.0671658    0.0245447    3.42381e-5   0.106606     0.0315412    0.102731    0.315351     0.205516   -0.027818   -0.19621     -0.0751678     0.0263305
 -0.0271092   -0.046847    -0.020983     0.0466699    0.0342797   -0.0449336   -0.123761    -0.0710518   -0.116705     0.0324382    0.0261033    0.211964     0.0912439    0.0639445   -0.0113746   -0.0743919    0.0946411    0.019238    -0.116875     0.0917727  -0.0983233   -0.111231   -0.0395335   0.166726     0.170421      0.193437
  0.0668362   -0.125764     0.0251668    0.0510236   -0.0928744   -0.019429    -0.0604811   -0.0164206    0.11022      0.0413874    0.162931    -0.123036    -0.0550907    0.0415093   -0.061777     0.0662913   -0.116098     0.152973    -0.0106632   -0.0299295  -0.182773    -0.0226927   0.0613859  -0.00365156   0.197025     -0.0813653
 -0.0121086    0.0794499    0.0720026   -0.0409408    0.166235    -0.0240393   -0.0933775    0.10989     -0.0870045   -0.0506475    0.108804     0.075923     0.0351769   -0.128209    -0.00875046  -0.0606614    0.0212435   -0.108435     0.0314667   -0.231652    0.0838748   -0.0412434  -0.0140123   0.0150028   -0.0939613    -0.0151639
  0.00198648  -0.169221    -0.00619617   0.11733      0.182057    -0.0452259   -0.0410242   -0.0772043    0.0446217   -0.0933797    0.131076    -0.0554219   -0.153844    -0.156379     0.0601511    0.0574209    0.0169944    0.0747799   -0.0259777    0.0440054   0.00946127  -0.0161685  -0.0221266   0.169749     0.18305       0.254922
 -0.0103443    0.0775107   -0.0724559    0.189852    -0.115603     0.135418    -0.21498      0.0662534   -0.093811     0.265054     0.0452526    0.0629236   -0.00420592  -0.0607628    0.0523457   -0.0755033   -0.0285177   -0.0657672   -0.0549118    0.10735    -0.101793    -0.101903    0.10432     0.0287461   -0.0590179     0.0129345
 -0.140547    -0.0828311    0.0521313    0.00330768   0.0143902   -0.0113812    0.172311     0.0194627   -0.0158859   -0.0648666    0.0804983   -0.183297    -0.0286652   -0.122112    -0.0236882    0.091433     0.341712    -0.0454296    0.118425    -0.0204802  -0.0230006    0.0392665   0.0877755  -0.0290471    0.0785785    -0.0385878
  0.135095    -0.096788     0.110638    -0.0319925   -0.0799446   -0.0389908   -0.0499386    0.0526295   -0.142183    -0.140668    -0.163765     0.124286     0.12144      0.123141    -0.0891558   -0.140048     0.0346962    0.0127345   -0.0378563    0.0738531   0.122067    -0.0965266  -0.121283    0.0648774   -0.13552       0.0227468
  0.148763     0.00519938  -0.279009    -0.0148349   -0.102        0.0231616    0.065631     0.0440776    0.0861829    0.0763174   -0.191039    -0.158243    -0.0787878    0.0927633   -0.155235    -0.0374477    0.104182     0.0885589   -0.0285546    0.16658     0.232998    -0.093301   -0.021012    0.177824     0.0395153     0.0225841
 -0.100783     0.0105179    0.0157798   -0.0248856   -0.158242     0.288399    -0.0916842    0.0588804   -0.0818963   -0.00459929  -0.178483    -0.0373212   -0.240821    -0.0104772    0.121645     0.140383    -0.147071    -0.0826299    0.170652     0.0581042   0.0629305    0.115069   -0.123277   -0.0113816   -0.0738052    -0.12308
  0.0641337    0.0782273   -0.0274911   -0.0199283   -0.0812407   -0.0190942   -0.0334574    0.023987     0.12133     -0.0182733   -0.059715     0.043011     0.012366    -0.0930225   -0.0135656   -0.0447607    0.097721     0.0340428   -0.116951     0.0388353   0.069499     0.0311234  -0.0127658  -0.0200728   -0.0470948    -0.0885674
 -0.0393615    0.224427    -0.026395    -0.00886628   0.15166     -0.0104603    0.112049     0.144504     0.113442     0.0419522   -0.0811139   -0.0328951   -0.0639352    0.120219     0.0119918    0.142881    -0.0592967   -0.0316851   -0.066194    -0.0933987   0.0729915    0.0824617  -0.14272     0.0117735    0.00503091    0.00119401
 -0.0797225   -0.171431    -0.0635936   -0.0179366    0.0320521   -0.121558     0.0176852    0.00256816   0.141362    -0.0123314   -0.144987    -0.0129401    0.147034    -0.261691    -0.115504     0.0522111    0.0168434   -0.0709896    0.0448505    0.0487976   0.130157     0.0529698   0.124932    0.162616     0.0386947    -0.00633951
 -0.0911977    0.0281183    0.00752249  -0.0194639    0.284006     0.156378    -0.0196355    0.131371    -0.101982     0.0249225   -0.02076     -0.181057     0.0894749    0.0511337   -0.0947403   -0.0224447   -0.00557801  -0.332033    -0.202738     0.0638942  -0.0395558   -0.116327    0.0109124   0.0851565    0.125679      0.0137406
 -0.0386154    0.0257545    0.0688272    0.207024    -0.251959    -0.0662138    0.0717048   -0.0839816    0.19614      0.130863     0.00409658   0.047096    -0.102798    -0.0658399   -0.212248     0.0543693    0.0139371    0.0502671   -0.217741    -0.067861   -0.0500979   -0.0364634  -0.133093   -0.0142937   -0.0848133     0.00521301
 -0.132148    -0.0214987    0.169329    -0.0305572    0.0445911    0.113715     0.0987973    0.122678    -0.031161     0.0828351    0.0267332    0.184458     0.0562506    0.0695715    0.023752     0.00716581   0.0985439   -0.0224015   -0.198737    -0.0418252  -0.132768     0.124635    0.115437    0.0275682   -0.00837646   -0.124313
 -0.0106807   -0.101986     0.149281     0.0146354    0.214651    -0.0203955   -0.111236     0.091622     0.132859     0.00778642  -0.195917    -0.00548158  -0.262623     0.147352     0.132065     0.0921304    0.0129628    0.0562811   -0.0493304   -0.267308   -0.0155096    0.160692   -0.134064    0.0342645    0.104428      0.0561163
 -0.0136041   -0.180232     0.0276433    0.0235703    0.182255    -0.112178    -0.138575     0.474002     0.140874     0.105112    -0.292152    -0.0977639    0.0506429   -0.190485    -0.0837263    0.0255358   -0.0385379    0.163728     0.00784156   0.0144599   0.0893149   -0.0169208   0.119649    0.0306564    0.179904      0.0139279
  0.230469     0.118345     0.182752     0.0083634    0.131554    -0.201948    -0.237764     0.0797712    0.112098    -0.0860032    0.0871507   -0.183637    -0.0726249    0.120202     0.0979466    0.00319166   0.0711589   -0.0103749    0.0689885   -0.0479806  -0.0460003    0.0199117  -0.0355481   0.0806475   -0.157167      0.0906898
  0.0395775    0.033936     0.0248561   -0.00923394  -0.140075    -0.0333557   -0.296882     0.0113057    0.0334724   -0.104933     0.00656541  -0.0244486   -0.0748488    0.18666      0.0533356    0.0702227   -0.0821128   -0.119442    -0.0303663    0.0317592   0.0771508   -0.0267565  -0.130847    0.0345658    0.25286      -0.180973
  0.120997    -0.0608707   -0.0524469    0.245814     0.156567     0.150691    -0.0470117   -0.0507926   -0.0396706   -0.0201737    0.152771    -0.148242    -0.14933     -0.129848     0.0865018   -0.0282849   -0.0177563   -0.0354329    0.0496347    0.0500585  -0.011126     0.076068    0.0166131  -0.00268241   0.224261     -0.207689
 -0.193447    -0.0576506    0.0292925    0.113748    -0.0315869    0.0530732    0.0554744    0.0881976   -0.0855768   -0.015572     0.12172      0.111391     0.0852628    0.0258693   -0.0475316    0.0284433   -0.0477632    0.145855     0.0425743    0.110687   -0.0771981   -0.101725    0.198073    0.132709     0.120033      0.0497885
 -0.103991    -0.0959091    0.0687903    0.00297787   0.0475368    0.0553725    0.0603072   -0.0363382    0.138861    -0.0715468    0.0994629   -0.152038    -0.191293     0.0902718   -0.0127654   -0.0413774    0.144547    -0.00394398  -0.0289867    0.0471422   0.0284045   -0.111239   -0.0521673  -0.0456556    0.0487778     0.0310728
  0.151565     0.0673989   -0.0994855    0.058329    -0.0400157    0.168113     0.160368    -0.0727568   -0.0751639    0.0351824   -0.0393648   -0.0658586   -0.00722387  -0.0238135   -0.0602716   -0.170126     0.0175917   -0.00309199   0.0613528   -0.0250099  -0.0301691    0.104222    0.109789   -0.329207    -0.0051841     0.053735
 -0.101947     0.115433    -0.139721     0.265192     0.0125551    0.0554913    0.00869695   0.0106797    0.0972083    0.144141    -0.192697     0.053977     0.0487363   -0.0262635    0.167498     0.0401471   -0.0343528    0.0482724    0.0518529   -0.0393486  -0.00380101   0.121576   -0.0877686   0.0319223    0.0439782    -0.0248267
 -0.0505177    0.0916262   -0.141675    -0.00409022  -0.137682    -0.0699147    0.0495896   -0.193216     0.0877933    0.0368399   -0.103526     0.110193    -0.0633755   -0.010881    -0.0332445   -0.0864364   -0.112304     0.0203449    0.0156371    0.12833    -0.0234235    0.0572182  -0.120348   -0.080589    -0.000193444   0.0775631[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      4
│     11
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.010540
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│     11
│     13
│     15
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.969515
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│     10
│     11
│     15
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.970911
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│     11
│     13
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.965789
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│      6
│     10
│      ⋮
│     23
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.974526
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│      9
│     11
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.970212
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│     11
│     15
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.983631
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      4
│     10
│     11
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.957654
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      6
│      9
│     11
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.978624
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│     11
│     13
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.968060
┌ Info: EM with 100000 data points 10 iterations avll -0.968060
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0151378    0.0355739     0.0173478    -0.00182465   0.0124748    0.0608942    0.223799      0.137888      0.0670364    0.00647467   0.0980869    0.0287642    0.0252709    0.0632246   -0.086862      0.0645024    0.029827   -0.0388744    -0.036676    -0.113242    -0.227086    -0.0103658   -0.0341433   -0.0405555     0.0242562   -0.102943
  0.0136805    0.0797895     0.123376     -0.00193416  -0.0693375    0.111168    -0.0749741    -0.105977     -0.0737256    0.0424494   -0.0112104    0.119318     0.216562    -0.0472304    0.00576018    0.0189917    0.0671173   0.00230063   -0.178173     0.0888442    0.0831955   -0.0861138   -0.152641     0.175523     -0.124312    -0.0496261
  0.119924     0.0783701     0.192362      0.176132    -0.036068     0.154702    -0.0723964     0.031958      0.192435    -0.0316496   -0.077208    -0.0132682   -0.0979593    0.135423     0.0451061    -0.0894682   -0.0591439  -0.0824664     0.115074     0.0204857   -0.060683    -0.0493618   -0.0889341    0.0375982     0.2293       0.0136357
 -0.0427474   -0.0436137     0.202918      0.0477507    0.0131913   -0.0741988    0.0219637    -0.169541     -0.108049     0.0375783    0.141879    -0.126805    -0.0189562    0.134472     0.0674016     0.0112676   -0.0646305   0.0580244     0.0174754    0.0494544   -0.134562    -0.0356347   -0.0158019   -0.172301      0.0319203    0.082871
  0.0998165   -0.021374     -0.115724      0.0156474   -0.105014    -0.0367907    0.16014      -0.0412311     0.0339143    0.0867587   -0.013907     0.0197159    0.0259668   -0.0190136   -0.0796128    -0.00274584  -0.0532807  -0.0730128     0.152421    -0.0810518   -0.0434425   -0.0937252   -0.103087     0.0684019    -0.124173    -0.0162329
  0.178107    -0.0900132     0.131087     -0.0276784   -0.0497145    0.0612679   -0.105815      0.158251     -0.190077     0.0381714    0.314729     0.0569678   -0.0104503   -0.222163     0.0337042     0.105022    -0.0571003   0.0898696    -0.204939     0.216315     0.187213     0.0555933    0.0247107   -0.160942      0.079328    -0.00964835
  0.124978     0.0134087     0.153592      0.0164372    0.176137     0.145274     0.0675367     0.104803     -0.0719589    0.00793767  -0.053448    -0.0699294    0.0910107    0.0367665    0.162806      0.118848     0.0596327  -0.170982      0.0869573    0.0928067    0.0101241    0.0866677   -0.0303317   -0.0668874    -0.0892274   -0.0443366
 -0.128804     0.000685984  -0.13292      -0.0351196    0.152034     0.0189605    0.0320109     0.103598     -0.204251     0.00290943   0.28618     -0.013538     0.0213594    0.0229738    0.0562867     0.0132425   -0.0501845  -0.0140157    -0.11624     -0.12768     -0.0225769   -0.0301853   -0.0413949    0.00482138   -0.0547701    0.249571
  0.0644679    0.0429709    -0.189013     -0.0679727    0.0482702   -0.0248717    0.137786      0.110707      0.0108679    0.145333     0.0148311   -0.0257179    0.00752933   0.0960842   -0.0190808     0.112578     0.169093    0.00804634    0.0625683   -0.146273    -0.0656625    0.0030616    0.0716582   -0.0173359    -0.0540137   -0.0146586
  0.0248561   -0.178582      0.0549967    -0.0304084   -0.0606689   -0.135111     0.125427      0.0470819     0.0756856   -0.0549797    0.144866     0.0254985   -0.0283425   -0.0259904   -0.215976      0.0472233    0.0334746  -0.0722345     0.135554    -0.0561178    0.0969509   -0.0834619    0.0634562   -0.0054477    -0.0587313   -0.220941
  0.0551871   -0.0121028     0.0549109    -0.100182     0.00985733  -0.10799     -0.000182371  -0.160208      0.0103066    0.0468165    0.0785499    0.00254271   0.076579     0.106886     0.0209483     0.0868795   -0.075561    0.0883774     0.0440227    0.228004     0.0141678    0.0605328   -0.0011706   -0.131488      0.141332     0.0862216
  0.0240304   -0.059147     -0.150259      0.0946357   -0.00799194  -0.0243666   -0.0515325    -0.0142455    -0.175156    -0.137703    -0.302159    -0.103389     0.198181     0.0607883   -0.211826     -0.0587866   -0.0589932   0.102345     -0.0287484   -0.195869    -0.156248     0.00398672   0.00349825   0.0406038     0.0145776    0.0935519
  0.189636     0.0108384    -0.037461      0.174983    -0.0931873    0.0937425    0.105081      0.0461445     0.0384275   -0.00328975  -0.0574209    0.0301897   -0.00512062  -0.189265     0.244802      0.205707     0.129722    0.0859781     0.144883    -0.0628281    0.143498     0.0191431    0.0952689    0.025828      0.13976     -0.290129
 -0.0030447    0.00763348    0.098598      0.00202847   0.00742415   0.0215328   -0.0567624     0.0173096    -0.0543397    0.00682533  -0.0528099   -0.108277     0.143147    -0.0494786   -0.122626      0.039743     0.0457326   0.0880005    -0.134234    -0.00851515  -0.0422898    0.106967    -0.0878653    0.0169134     0.0702123    0.107411
 -0.093821    -0.112991     -0.105306      0.140177    -0.0291003    0.105985    -0.00371947   -0.0672544     0.232755     0.120286    -0.0644539    0.103053     0.0897267   -0.0370217    0.000384412   0.0889364   -0.123583   -0.0209675     0.0865616    0.0751674   -0.0517831    0.0996794    0.11775     -0.104982     -0.00279414   0.0998376
  0.0111054   -0.145233     -0.0966588     0.128757    -0.0957785   -0.0472257    0.0534686    -0.000128704   0.0752893   -0.0188948   -0.0795557    0.129365     0.219564    -0.184081    -0.101841      0.0176279   -0.0962194  -0.0712779     0.148958     0.20509     -0.083661    -0.112615    -0.0113941    0.0632482     0.163533     0.148974
 -0.0485587    0.00314763   -0.0956959    -0.0707995    0.132995    -0.039706     0.0117444    -0.0882265     0.0365577    0.324244     0.0777747   -0.0130079   -0.0240892    0.162222    -0.0307363     0.0419088   -0.0622743  -0.000313278  -0.0121493   -0.0045376    0.0848683    0.0285556   -0.0641376    0.059179     -0.0224243    0.0136558
  0.0652669    0.159325     -0.000145491  -0.0831725    0.0461883   -0.0217107   -0.0721946     0.196181     -0.259466     0.0817802    0.103597     0.0493375   -0.0928532    0.169456     0.0356258    -0.105291     0.0347456  -0.142435     -0.0457401   -0.114914     0.0260766   -0.1949       0.0180856    0.000219007  -0.156676     0.0528376
 -0.327271     0.037986     -0.0726595     0.133795     0.0238843   -0.0542695    0.0169201    -0.0066785     0.00394661   0.0680787   -0.0718982    0.0712082    0.0723871    0.132244     0.0310404     0.0400257   -0.274429    0.0572291     0.0671789    0.0344681   -0.00236737  -0.0964558    0.0566407    0.00994489    0.0177953    0.182608
  0.0839044   -0.100686      0.107342     -0.072465     0.00411445  -0.13225      0.10549      -0.0798861    -0.0995203    0.115561    -0.12767      0.173544     0.173935    -0.103303     0.103592     -0.0817453    0.0238028   0.00707922    0.0958533    0.123413     0.0759926   -0.205136    -0.128308    -0.135295      0.0169693    0.164076
  0.05673      0.124005     -0.0513524     0.00511469  -0.209006     0.083057     0.0647813     0.153016     -0.120558    -0.10053     -0.0197589   -0.114939     0.0828242    0.16079     -0.182445      0.064982    -0.155174   -0.00484257   -0.0517815   -0.0955164   -0.0805943    0.011666     0.0141644    0.0151598     0.0713345    0.112145
  0.0921459    0.0268387     0.0479867     0.0785627   -0.00584686   0.13567      0.0954193     0.0742804     0.0737539    0.00340667  -0.0202582    0.00384586  -0.0380466    0.008371    -0.156576      0.0479136    0.0714504   0.0206132    -0.0353361    0.0322505    0.0717635    0.0480592    0.0654667    0.00638386    0.030955     0.11418
  0.251674    -0.103365     -0.223627      0.00233797   0.102785     0.00120802   0.0200541    -0.080645      0.0165511    0.0625346   -0.0610354    0.0296086   -0.0392375    0.0659061    0.079021      0.0194048   -0.0359999  -0.104595      0.0217317    0.0301456   -0.0787001    0.0739158   -0.0190727    0.0691466    -0.183909    -0.102295
 -0.126928     0.186707     -0.0313288     0.0722586    0.0896403   -0.0124501    0.00537681   -0.273769      0.222439     0.235474     0.095969    -0.0789645    0.0973967   -0.0192605   -0.0462432    -0.0425335    0.289996    0.0439732    -0.112152    -0.0229838   -0.11376     -0.04755      0.0598709    0.0266782     0.118387     0.0978122
 -0.107852    -0.0610427    -0.209555      0.0558097    0.0570115   -0.0393065   -0.0525049     0.149634      0.198342     0.0397164   -0.0324824   -0.0033508    0.0598746    0.0536228   -0.21126      -0.0309705   -0.141878    0.0374674    -0.0823144   -0.0589261   -0.105817     0.0416443    0.0794977    0.0280266     0.00776748   0.105161
 -0.0594043   -0.0116347    -0.023654     -0.103121     0.0873      -0.139538    -0.0503133     0.0260945    -0.0246275   -0.0324636   -0.00400202   0.00318318   0.00985782  -0.00256613   0.0810423    -0.0397113   -0.0144762  -0.105063      0.119335     0.0653804   -0.0167312    0.020795     0.00362528   0.0380084    -4.94626e-5  -0.123276
  0.114709    -0.010277      0.087486     -0.0750098    0.0287747    0.0251095    0.126901     -0.0275847     0.132214    -0.0240895    0.0487084   -0.0217062    0.015985    -0.0244185    0.0281696     0.0284276    0.170593   -0.177082      0.00546707  -0.0797883    0.084758    -0.0164216    0.149849     0.0212948     0.106273    -0.022043
 -0.00976176  -0.0390698     0.0188403     0.0882581    0.00526549  -0.133888    -0.107567      0.00278108    0.136613    -0.0108816   -0.0397746   -0.0791031    0.101889    -0.105663     0.0893466    -0.214268     0.250741    0.0501978    -0.125804     0.122166    -0.0191981    0.0438337    0.105697    -0.0561832     0.00221697  -0.0266345
  0.0354857    0.0619979    -0.0811716     0.0384073   -0.0193158   -0.219773    -0.0353805     0.0873118     0.133388    -0.0865642    0.0955156    0.0444345    0.0793316    0.0369304    0.192282     -0.103589    -0.0519065   0.128289     -0.042367     0.135153    -0.182038    -0.0970696   -0.0450413   -0.0645518    -0.057638    -0.1447
 -0.0868178    0.102438     -0.0876311     0.0590592    0.135611     0.00216379   0.158791     -0.12782       0.124922     0.110276     0.0698268    0.042016    -0.0904086    0.115256    -0.122941     -0.118057     0.211079    0.0544995     0.0623415    0.123796    -0.0838922    0.0555456    0.0139603   -0.122066      0.17038     -0.0963063
 -0.0297837   -0.101114      0.00999342    0.0563945    0.0995961   -0.154234    -0.0798072     0.0330125     0.18016      0.0323473   -0.185103     6.87555e-5   0.00346216  -0.132891     0.00580755   -0.0974931    0.087188    0.142106      0.0262781    0.101012    -0.126892     0.0200996   -0.00993232   0.0229348     0.0592576   -0.0518714
  0.0370232   -0.0234877    -0.0237627     0.0186406    0.11592     -0.201922    -0.0746509    -0.0747926    -0.0454886   -0.112653    -0.0181741    0.0514932   -0.0883277   -0.114018    -0.193462     -0.217776     0.0493023   0.0772984    -0.0387902   -0.0259494    0.0806398    0.0459545    0.040235    -0.120498     -0.0941003    0.107971kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4227642300175394
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422784
[ Info: iteration 2, average log likelihood -1.422684
[ Info: iteration 3, average log likelihood -1.422595
[ Info: iteration 4, average log likelihood -1.422489
[ Info: iteration 5, average log likelihood -1.422367
[ Info: iteration 6, average log likelihood -1.422239
[ Info: iteration 7, average log likelihood -1.422122
[ Info: iteration 8, average log likelihood -1.422030
[ Info: iteration 9, average log likelihood -1.421966
[ Info: iteration 10, average log likelihood -1.421927
[ Info: iteration 11, average log likelihood -1.421904
[ Info: iteration 12, average log likelihood -1.421890
[ Info: iteration 13, average log likelihood -1.421881
[ Info: iteration 14, average log likelihood -1.421872
[ Info: iteration 15, average log likelihood -1.421860
[ Info: iteration 16, average log likelihood -1.421843
[ Info: iteration 17, average log likelihood -1.421812
[ Info: iteration 18, average log likelihood -1.421755
[ Info: iteration 19, average log likelihood -1.421650
[ Info: iteration 20, average log likelihood -1.421459
[ Info: iteration 21, average log likelihood -1.421127
[ Info: iteration 22, average log likelihood -1.420592
[ Info: iteration 23, average log likelihood -1.419847
[ Info: iteration 24, average log likelihood -1.419009
[ Info: iteration 25, average log likelihood -1.418297
[ Info: iteration 26, average log likelihood -1.417844
[ Info: iteration 27, average log likelihood -1.417611
[ Info: iteration 28, average log likelihood -1.417505
[ Info: iteration 29, average log likelihood -1.417458
[ Info: iteration 30, average log likelihood -1.417438
[ Info: iteration 31, average log likelihood -1.417429
[ Info: iteration 32, average log likelihood -1.417424
[ Info: iteration 33, average log likelihood -1.417422
[ Info: iteration 34, average log likelihood -1.417421
[ Info: iteration 35, average log likelihood -1.417420
[ Info: iteration 36, average log likelihood -1.417419
[ Info: iteration 37, average log likelihood -1.417419
[ Info: iteration 38, average log likelihood -1.417418
[ Info: iteration 39, average log likelihood -1.417418
[ Info: iteration 40, average log likelihood -1.417418
[ Info: iteration 41, average log likelihood -1.417417
[ Info: iteration 42, average log likelihood -1.417417
[ Info: iteration 43, average log likelihood -1.417417
[ Info: iteration 44, average log likelihood -1.417417
[ Info: iteration 45, average log likelihood -1.417416
[ Info: iteration 46, average log likelihood -1.417416
[ Info: iteration 47, average log likelihood -1.417416
[ Info: iteration 48, average log likelihood -1.417416
[ Info: iteration 49, average log likelihood -1.417416
[ Info: iteration 50, average log likelihood -1.417416
┌ Info: EM with 100000 data points 50 iterations avll -1.417416
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4227838051191137
│     -1.4226838480166566
│      ⋮
└     -1.4174156209981492
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417432
[ Info: iteration 2, average log likelihood -1.417335
[ Info: iteration 3, average log likelihood -1.417243
[ Info: iteration 4, average log likelihood -1.417128
[ Info: iteration 5, average log likelihood -1.416990
[ Info: iteration 6, average log likelihood -1.416837
[ Info: iteration 7, average log likelihood -1.416685
[ Info: iteration 8, average log likelihood -1.416547
[ Info: iteration 9, average log likelihood -1.416429
[ Info: iteration 10, average log likelihood -1.416334
[ Info: iteration 11, average log likelihood -1.416263
[ Info: iteration 12, average log likelihood -1.416213
[ Info: iteration 13, average log likelihood -1.416182
[ Info: iteration 14, average log likelihood -1.416162
[ Info: iteration 15, average log likelihood -1.416150
[ Info: iteration 16, average log likelihood -1.416142
[ Info: iteration 17, average log likelihood -1.416137
[ Info: iteration 18, average log likelihood -1.416134
[ Info: iteration 19, average log likelihood -1.416131
[ Info: iteration 20, average log likelihood -1.416129
[ Info: iteration 21, average log likelihood -1.416127
[ Info: iteration 22, average log likelihood -1.416125
[ Info: iteration 23, average log likelihood -1.416124
[ Info: iteration 24, average log likelihood -1.416122
[ Info: iteration 25, average log likelihood -1.416121
[ Info: iteration 26, average log likelihood -1.416120
[ Info: iteration 27, average log likelihood -1.416119
[ Info: iteration 28, average log likelihood -1.416118
[ Info: iteration 29, average log likelihood -1.416118
[ Info: iteration 30, average log likelihood -1.416117
[ Info: iteration 31, average log likelihood -1.416116
[ Info: iteration 32, average log likelihood -1.416115
[ Info: iteration 33, average log likelihood -1.416115
[ Info: iteration 34, average log likelihood -1.416114
[ Info: iteration 35, average log likelihood -1.416114
[ Info: iteration 36, average log likelihood -1.416113
[ Info: iteration 37, average log likelihood -1.416113
[ Info: iteration 38, average log likelihood -1.416112
[ Info: iteration 39, average log likelihood -1.416112
[ Info: iteration 40, average log likelihood -1.416112
[ Info: iteration 41, average log likelihood -1.416111
[ Info: iteration 42, average log likelihood -1.416111
[ Info: iteration 43, average log likelihood -1.416110
[ Info: iteration 44, average log likelihood -1.416110
[ Info: iteration 45, average log likelihood -1.416110
[ Info: iteration 46, average log likelihood -1.416110
[ Info: iteration 47, average log likelihood -1.416109
[ Info: iteration 48, average log likelihood -1.416109
[ Info: iteration 49, average log likelihood -1.416109
[ Info: iteration 50, average log likelihood -1.416109
┌ Info: EM with 100000 data points 50 iterations avll -1.416109
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4174316221060608
│     -1.4173352969886934
│      ⋮
└     -1.416108592772228
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416119
[ Info: iteration 2, average log likelihood -1.416060
[ Info: iteration 3, average log likelihood -1.416003
[ Info: iteration 4, average log likelihood -1.415932
[ Info: iteration 5, average log likelihood -1.415840
[ Info: iteration 6, average log likelihood -1.415724
[ Info: iteration 7, average log likelihood -1.415588
[ Info: iteration 8, average log likelihood -1.415441
[ Info: iteration 9, average log likelihood -1.415298
[ Info: iteration 10, average log likelihood -1.415169
[ Info: iteration 11, average log likelihood -1.415061
[ Info: iteration 12, average log likelihood -1.414975
[ Info: iteration 13, average log likelihood -1.414909
[ Info: iteration 14, average log likelihood -1.414858
[ Info: iteration 15, average log likelihood -1.414820
[ Info: iteration 16, average log likelihood -1.414790
[ Info: iteration 17, average log likelihood -1.414766
[ Info: iteration 18, average log likelihood -1.414746
[ Info: iteration 19, average log likelihood -1.414730
[ Info: iteration 20, average log likelihood -1.414716
[ Info: iteration 21, average log likelihood -1.414705
[ Info: iteration 22, average log likelihood -1.414694
[ Info: iteration 23, average log likelihood -1.414685
[ Info: iteration 24, average log likelihood -1.414676
[ Info: iteration 25, average log likelihood -1.414668
[ Info: iteration 26, average log likelihood -1.414661
[ Info: iteration 27, average log likelihood -1.414654
[ Info: iteration 28, average log likelihood -1.414647
[ Info: iteration 29, average log likelihood -1.414641
[ Info: iteration 30, average log likelihood -1.414635
[ Info: iteration 31, average log likelihood -1.414629
[ Info: iteration 32, average log likelihood -1.414623
[ Info: iteration 33, average log likelihood -1.414617
[ Info: iteration 34, average log likelihood -1.414612
[ Info: iteration 35, average log likelihood -1.414606
[ Info: iteration 36, average log likelihood -1.414601
[ Info: iteration 37, average log likelihood -1.414596
[ Info: iteration 38, average log likelihood -1.414590
[ Info: iteration 39, average log likelihood -1.414585
[ Info: iteration 40, average log likelihood -1.414580
[ Info: iteration 41, average log likelihood -1.414575
[ Info: iteration 42, average log likelihood -1.414570
[ Info: iteration 43, average log likelihood -1.414565
[ Info: iteration 44, average log likelihood -1.414560
[ Info: iteration 45, average log likelihood -1.414555
[ Info: iteration 46, average log likelihood -1.414550
[ Info: iteration 47, average log likelihood -1.414545
[ Info: iteration 48, average log likelihood -1.414540
[ Info: iteration 49, average log likelihood -1.414536
[ Info: iteration 50, average log likelihood -1.414531
┌ Info: EM with 100000 data points 50 iterations avll -1.414531
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4161189157462295
│     -1.416060137062914
│      ⋮
└     -1.4145309049034218
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414535
[ Info: iteration 2, average log likelihood -1.414481
[ Info: iteration 3, average log likelihood -1.414434
[ Info: iteration 4, average log likelihood -1.414380
[ Info: iteration 5, average log likelihood -1.414316
[ Info: iteration 6, average log likelihood -1.414239
[ Info: iteration 7, average log likelihood -1.414147
[ Info: iteration 8, average log likelihood -1.414043
[ Info: iteration 9, average log likelihood -1.413930
[ Info: iteration 10, average log likelihood -1.413813
[ Info: iteration 11, average log likelihood -1.413698
[ Info: iteration 12, average log likelihood -1.413590
[ Info: iteration 13, average log likelihood -1.413490
[ Info: iteration 14, average log likelihood -1.413400
[ Info: iteration 15, average log likelihood -1.413320
[ Info: iteration 16, average log likelihood -1.413249
[ Info: iteration 17, average log likelihood -1.413187
[ Info: iteration 18, average log likelihood -1.413132
[ Info: iteration 19, average log likelihood -1.413083
[ Info: iteration 20, average log likelihood -1.413040
[ Info: iteration 21, average log likelihood -1.413000
[ Info: iteration 22, average log likelihood -1.412965
[ Info: iteration 23, average log likelihood -1.412932
[ Info: iteration 24, average log likelihood -1.412902
[ Info: iteration 25, average log likelihood -1.412874
[ Info: iteration 26, average log likelihood -1.412848
[ Info: iteration 27, average log likelihood -1.412824
[ Info: iteration 28, average log likelihood -1.412801
[ Info: iteration 29, average log likelihood -1.412780
[ Info: iteration 30, average log likelihood -1.412760
[ Info: iteration 31, average log likelihood -1.412741
[ Info: iteration 32, average log likelihood -1.412723
[ Info: iteration 33, average log likelihood -1.412706
[ Info: iteration 34, average log likelihood -1.412689
[ Info: iteration 35, average log likelihood -1.412674
[ Info: iteration 36, average log likelihood -1.412659
[ Info: iteration 37, average log likelihood -1.412645
[ Info: iteration 38, average log likelihood -1.412631
[ Info: iteration 39, average log likelihood -1.412618
[ Info: iteration 40, average log likelihood -1.412606
[ Info: iteration 41, average log likelihood -1.412594
[ Info: iteration 42, average log likelihood -1.412582
[ Info: iteration 43, average log likelihood -1.412571
[ Info: iteration 44, average log likelihood -1.412561
[ Info: iteration 45, average log likelihood -1.412551
[ Info: iteration 46, average log likelihood -1.412541
[ Info: iteration 47, average log likelihood -1.412532
[ Info: iteration 48, average log likelihood -1.412523
[ Info: iteration 49, average log likelihood -1.412514
[ Info: iteration 50, average log likelihood -1.412506
┌ Info: EM with 100000 data points 50 iterations avll -1.412506
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414535006130107
│     -1.4144814033511595
│      ⋮
└     -1.412505896706251
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412506
[ Info: iteration 2, average log likelihood -1.412443
[ Info: iteration 3, average log likelihood -1.412382
[ Info: iteration 4, average log likelihood -1.412309
[ Info: iteration 5, average log likelihood -1.412218
[ Info: iteration 6, average log likelihood -1.412105
[ Info: iteration 7, average log likelihood -1.411972
[ Info: iteration 8, average log likelihood -1.411823
[ Info: iteration 9, average log likelihood -1.411667
[ Info: iteration 10, average log likelihood -1.411509
[ Info: iteration 11, average log likelihood -1.411358
[ Info: iteration 12, average log likelihood -1.411216
[ Info: iteration 13, average log likelihood -1.411087
[ Info: iteration 14, average log likelihood -1.410972
[ Info: iteration 15, average log likelihood -1.410870
[ Info: iteration 16, average log likelihood -1.410782
[ Info: iteration 17, average log likelihood -1.410704
[ Info: iteration 18, average log likelihood -1.410637
[ Info: iteration 19, average log likelihood -1.410577
[ Info: iteration 20, average log likelihood -1.410525
[ Info: iteration 21, average log likelihood -1.410478
[ Info: iteration 22, average log likelihood -1.410436
[ Info: iteration 23, average log likelihood -1.410397
[ Info: iteration 24, average log likelihood -1.410361
[ Info: iteration 25, average log likelihood -1.410328
[ Info: iteration 26, average log likelihood -1.410298
[ Info: iteration 27, average log likelihood -1.410269
[ Info: iteration 28, average log likelihood -1.410241
[ Info: iteration 29, average log likelihood -1.410216
[ Info: iteration 30, average log likelihood -1.410191
[ Info: iteration 31, average log likelihood -1.410168
[ Info: iteration 32, average log likelihood -1.410146
[ Info: iteration 33, average log likelihood -1.410125
[ Info: iteration 34, average log likelihood -1.410105
[ Info: iteration 35, average log likelihood -1.410085
[ Info: iteration 36, average log likelihood -1.410067
[ Info: iteration 37, average log likelihood -1.410049
[ Info: iteration 38, average log likelihood -1.410031
[ Info: iteration 39, average log likelihood -1.410015
[ Info: iteration 40, average log likelihood -1.409999
[ Info: iteration 41, average log likelihood -1.409983
[ Info: iteration 42, average log likelihood -1.409968
[ Info: iteration 43, average log likelihood -1.409954
[ Info: iteration 44, average log likelihood -1.409940
[ Info: iteration 45, average log likelihood -1.409927
[ Info: iteration 46, average log likelihood -1.409914
[ Info: iteration 47, average log likelihood -1.409901
[ Info: iteration 48, average log likelihood -1.409889
[ Info: iteration 49, average log likelihood -1.409878
[ Info: iteration 50, average log likelihood -1.409866
┌ Info: EM with 100000 data points 50 iterations avll -1.409866
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4125061256984068
│     -1.4124434208087024
│      ⋮
└     -1.409866377238168
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4227642300175394
│     -1.4227838051191137
│     -1.4226838480166566
│     -1.4225946780845358
│      ⋮
│     -1.4098891042015804
│     -1.4098775259235359
└     -1.409866377238168
32×26 Array{Float64,2}:
  0.213087      0.348472      0.045875     0.206509    0.259721   -0.376571     0.149419    0.0595407  -0.577053    -0.421485   -0.340602   -0.346363     0.751134    -0.238306    -0.872272     0.11844      0.00831228   0.682678    0.0554381   0.0514072   -0.730272   -0.505101    -0.047057     0.246493   -0.17935     -0.00637457
 -0.316594      0.0890369    -0.649134    -0.311028    0.390859   -0.183664     0.352924   -0.296251   -0.914997     0.056617   -0.337255    0.0535466    0.285024    -0.516872    -0.0334158    0.194246     0.0929192    0.121423    0.231118   -0.042511    -0.438045    0.0855032    0.141709    -0.193575    0.0878149    0.0495035
 -0.0323956     0.212951     -0.00945378   0.181128   -0.352188   -0.523808     0.397525    0.457405   -0.29603      0.066496   -0.1706     -0.225451    -0.0697132   -0.315038    -0.492029     0.604281     0.236526     0.172637    0.0921619   0.500791    -0.0177829  -0.00804167   0.252413    -0.576787    0.338305    -0.385069
  0.202546      0.154107      0.987699     0.218578    0.0503526  -0.329976     0.311151    0.284554    0.216448     0.279743   -0.315408    0.64407     -0.211961    -0.194174    -0.436334    -0.00795211   0.138784     0.651462   -0.694527   -0.0299004   -0.201564    0.0437167    0.00638316  -0.465101    0.36627      0.3031
 -0.424768     -0.486727     -0.137777    -0.467188    0.123717   -0.0201624    0.01277    -0.582191    0.692499    -0.210033   -0.121746   -0.134751     0.114385     0.315008    -0.157224     0.228076    -0.0788463   -0.144238    0.641166    0.879867    -0.0568165   0.0703949   -0.34078     -0.92823    -0.226855     0.319329
  0.392811     -0.593707     -0.157338    -0.0527089   0.520384   -0.186055    -0.862368   -0.109404    0.216824    -0.160989    0.288305   -0.0773358   -0.00387366   0.348361    -0.66082      0.234018    -0.0171339    0.421643    0.595804    0.134765    -0.0518901  -0.591501     0.142452     0.577706   -0.458063    -0.181459
 -0.142488     -0.410863     -0.284219     0.23405    -0.297758   -0.169384     0.174675    0.360471    0.599052     0.192198    0.405324    0.0738567   -0.954586     0.0717425   -0.491497    -0.200041    -0.162376     0.210383    0.239529   -0.388843     0.273593    0.21937      0.282373    -0.268151    0.219777    -0.19265
  0.0499545    -0.0729612     0.259835    -0.0764523   0.0567735   0.405943    -0.295318    0.520828    0.573576    -0.241829    0.293137    0.319129    -0.0981465   -0.227454     0.0181906   -0.0116515    0.418384     0.0168698   0.485422    0.0718503    0.200922    0.16872     -0.283489     0.0433176   0.142852    -0.471514
 -0.287205      0.591997     -0.120556    -0.0368124   0.647111    0.299664    -0.0695324   0.117386    0.152201    -0.34731     0.0804251  -0.0779054    0.524741     0.643992    -0.451719    -0.441818    -0.575931    -0.333724   -0.168701   -0.445204    -0.046458    0.064874     0.0253912   -0.0500547  -0.375101     0.368659
 -0.241075      0.176303      0.297575     0.659789   -0.118806   -0.0770861    0.0917854  -0.148813   -0.295782     0.066508   -0.1428     -0.154579     0.370978     0.40466     -0.00947431   0.0104379   -0.273134    -0.218961   -0.558274   -0.110084     0.124341   -0.348906     0.763347     0.258055    0.0559379    0.211125
  0.472917      0.435715      0.107083    -0.494549   -0.036851   -0.218806     0.506299   -0.156782   -0.180386     0.0197086  -0.369368   -0.314975    -0.115902     0.287708     0.0478961   -0.179659    -0.320587     0.0265721  -1.10404    -0.479016    -0.12934     0.297389    -0.372036     0.141557   -0.0693293    0.332324
  0.320712      0.0751793     0.228418     0.092909    0.0210335  -0.0117681    0.0602945  -0.859809   -0.284516     0.0639226  -0.315332   -0.106712     0.147756     0.364722     1.38644     -0.390977    -0.408128    -0.654419    0.442942    0.143916    -0.28001     0.328209    -0.759493     0.446634   -0.132089     0.226007
 -0.500129     -0.075374      0.025493     0.380604   -1.01859     0.36987      0.0586869   0.667343    0.657799     0.65666    -0.933514   -0.045096     0.192421    -0.814566     0.306465     0.16981     -0.421415    -0.696272   -0.411352    0.568966    -0.0486387  -0.28356      0.735065     0.143469   -0.114508     0.204568
 -0.750999     -0.1311        0.0286826    0.156427   -0.224361    0.594104     0.0750127  -0.321517    0.163577     0.432072   -0.0282208  -0.0691682   -0.314524    -0.135966     0.727025    -0.541796    -0.0590304   -0.503427   -0.628354    0.278275     0.508316    0.607333     0.265987    -0.194078    0.200116     0.118187
  0.217318     -0.506259     -0.166247    -0.614557    0.0554141   0.23384     -0.186539   -0.151954   -0.0786192    0.440624   -0.397928    0.498193    -0.450843    -0.438007     0.451764     0.0811841    0.451576    -0.232901    0.0957678   0.158927     0.100206   -0.117439    -0.335843    -0.45063    -0.393089     0.0813443
  0.262871     -0.805084      0.0467324    0.0467979  -0.357257   -0.344526    -0.25993    -0.724508   -0.129029     0.334522    0.178849    0.0208434   -0.369104    -0.0605995    0.7618       0.408317     0.670592     0.28902     0.17425     0.219794     0.203988   -0.140263    -0.0204772    0.0973119   0.286249    -0.273592
 -0.000848009   0.648828      0.0573673    0.225257   -0.200563   -0.200502     0.438915   -0.197784   -0.398533     0.24189    -0.445861    0.0549581    0.28362     -0.0139584    0.557435     0.0583089   -0.072462    -0.317012   -0.273807    0.117205     0.106496    0.389211     0.0747477   -0.10982     0.374649    -0.148135
 -0.0275971     0.198448     -0.218656     0.149458    0.154991   -0.0292714    0.308337   -0.187587    0.0146059   -0.0143836  -0.0416332  -0.0668313   -0.0351688    0.172008    -0.0754541   -0.26833     -0.067724    -0.260396   -0.172221   -0.398341    -0.356138    0.57741     -0.106111     0.327443   -0.0105079   -0.197002
  0.51042       0.365288     -0.334382     0.339723   -0.0635694   0.168598    -0.650226    0.414811    0.460167     0.0725572   0.153687   -0.852935     0.565685     0.0697307    0.29206     -0.215822     0.503641    -0.121856    0.183106   -0.0126596    0.105083   -0.616354    -0.782041     0.155786    0.0327378   -0.067693
  1.04647       0.528902     -0.441126     0.127315   -0.0863875  -0.649174     0.19977     0.506585   -0.157592     0.222918    0.0159701   0.00547178  -0.0727303   -0.156183     0.334799    -0.11873      0.0528921   -0.241811    0.270287   -0.598382    -0.125667    0.0380941   -0.218987     0.474049    0.283467    -0.261149
  0.296258     -0.206659      0.418874     0.085407    0.310872    0.00386664   0.35257    -0.282109   -0.275726    -0.122408   -0.212111   -0.231799    -0.0257515    0.324208    -0.0163039    0.569895    -0.00295906  -0.576555   -0.436919    0.202967    -0.507778   -0.161272    -0.00261642   0.0641406  -0.331777    -0.0691761
 -0.0280758     0.000916502   0.239927     0.293883   -0.215228    0.477955    -0.260141    0.406368   -0.334933    -0.177618   -0.242986   -0.700137    -0.514405    -0.0996727    0.103007    -0.0590476   -0.137922    -0.483339   -0.243509    0.015164    -0.344536    0.257099    -0.146527     0.455468    0.399172    -0.635654
 -0.110275     -0.579978      0.429876    -0.165764    0.0111404   0.214558    -0.298541    0.135561    0.00509262  -0.323101    0.436001    0.279595     0.187908     0.130054    -0.0912301    0.241167    -0.291555     0.312947   -0.296589   -0.501311    -0.504751   -0.130655    -0.0652197    0.461492   -0.0609299    0.427539
 -0.0710438     0.273193     -0.0281644    0.216619    0.0111864   0.153699    -0.162488    0.106569   -0.191427    -0.132193    0.345975   -0.135047     0.290059     0.271636    -0.0041894   -0.0148807   -0.58463     -0.0382238  -0.309518   -0.382715     0.450293   -0.211635     0.36989      0.326121    0.00939338   0.151674
  0.10499      -0.132628     -0.189321    -0.141167    0.181241   -0.273109     0.213182    0.0754705   0.0981529   -0.0965159  -0.153096   -0.057502    -0.0365834   -0.0272122   -0.395928     0.152755     0.12223      0.101938    0.305669    0.015538    -0.41096    -0.0819902   -0.0750713   -0.213428   -0.136705    -0.0639348
  0.119948     -0.0633428     0.0756996   -0.0731799  -0.0565029  -0.00540418  -0.0981546  -0.0009883   0.0352657    0.180161    0.0591924   0.0890725   -0.0286925   -0.0213298    0.149762    -0.013148     0.0754924    0.0239862   0.0308504   0.188548     0.252996   -0.119196    -0.0175049   -0.130447    0.0891827    0.0698727
  0.2146       -0.0647933     0.119845     0.0935171   0.0230917   0.447737    -0.315966    0.0788869   0.8059      -0.247628    0.643262   -0.0344523   -0.138036     0.343403    -0.151596    -0.472478     0.0391707   -0.329167    0.36959     0.34253      0.2138      0.0792628   -0.446723     0.104876    0.0329246   -0.419997
 -0.566303     -0.580463      0.149142     0.272305    0.171352    0.423404    -0.0950617   0.179074    0.256647     0.0105198   0.187862    0.303363    -0.137592     0.036698    -0.355892     0.152846     0.407331     0.184194    0.188696    0.288558    -0.0533609  -0.10361      0.493219    -0.224075   -0.184546    -0.272715
 -0.264469      0.32068      -0.391485    -0.192516    0.0680969  -0.0213261   -0.0429407  -0.310293    0.242729     0.290516   -0.104337    0.168903     0.294199    -0.25003      0.237724    -0.708678     0.411656     0.487427    0.260054    0.00281654   0.153226   -0.00687201  -0.630631    -0.0830825   0.148611     0.546003
 -0.305254     -0.0696142    -0.73481     -0.210984   -0.210541   -0.213955     0.15881    -0.155436   -0.0615047    0.27732    -0.0321741  -0.0146869    0.309423    -0.102081     0.0965248   -0.265325    -0.0486692    0.345114    0.0126153  -0.246506     0.112461   -0.172085     0.543068     0.116894   -0.200266     0.726371
  0.606115     -0.0296194    -0.211035    -0.851602    0.364898   -0.595119     0.110156    0.1759      0.29672     -0.0181289   1.05934     0.711723     0.614705    -0.0844491   -0.568128     0.400455    -0.240314     0.707806    0.3767      0.153469     0.383515   -0.0828158   -0.212548    -0.500869   -0.0295672    0.585787
  0.128621      0.404193      0.148804     0.529867    0.189809    0.010742    -0.163598    0.27915    -0.00956231   0.0696229   0.900924    0.689272     0.435648    -0.00142373  -0.130443     0.028103    -0.253585     0.378709    0.341213    0.450098     0.759399   -0.077063     0.598096    -0.359228    0.0262833   -0.00806068[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409856
[ Info: iteration 2, average log likelihood -1.409845
[ Info: iteration 3, average log likelihood -1.409835
[ Info: iteration 4, average log likelihood -1.409826
[ Info: iteration 5, average log likelihood -1.409817
[ Info: iteration 6, average log likelihood -1.409808
[ Info: iteration 7, average log likelihood -1.409799
[ Info: iteration 8, average log likelihood -1.409791
[ Info: iteration 9, average log likelihood -1.409783
[ Info: iteration 10, average log likelihood -1.409775
┌ Info: EM with 100000 data points 10 iterations avll -1.409775
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.579654e+05
      1       7.018925e+05      -2.560728e+05 |       32
      2       6.898751e+05      -1.201743e+04 |       32
      3       6.850119e+05      -4.863222e+03 |       32
      4       6.824313e+05      -2.580603e+03 |       32
      5       6.808061e+05      -1.625133e+03 |       32
      6       6.797251e+05      -1.081059e+03 |       32
      7       6.788843e+05      -8.407945e+02 |       32
      8       6.781961e+05      -6.882163e+02 |       32
      9       6.776036e+05      -5.924892e+02 |       32
     10       6.770569e+05      -5.466557e+02 |       32
     11       6.765665e+05      -4.904123e+02 |       32
     12       6.761509e+05      -4.156350e+02 |       32
     13       6.757852e+05      -3.656388e+02 |       32
     14       6.754746e+05      -3.106192e+02 |       32
     15       6.751903e+05      -2.842632e+02 |       32
     16       6.749200e+05      -2.703224e+02 |       32
     17       6.746558e+05      -2.642160e+02 |       32
     18       6.744233e+05      -2.324833e+02 |       32
     19       6.742129e+05      -2.103838e+02 |       32
     20       6.740215e+05      -1.914583e+02 |       32
     21       6.738407e+05      -1.808091e+02 |       32
     22       6.736799e+05      -1.607225e+02 |       32
     23       6.735441e+05      -1.358893e+02 |       32
     24       6.734195e+05      -1.245403e+02 |       32
     25       6.733174e+05      -1.020882e+02 |       32
     26       6.732219e+05      -9.557572e+01 |       32
     27       6.731312e+05      -9.064633e+01 |       32
     28       6.730526e+05      -7.857154e+01 |       32
     29       6.729867e+05      -6.590854e+01 |       32
     30       6.729274e+05      -5.937507e+01 |       32
     31       6.728737e+05      -5.368301e+01 |       32
     32       6.728184e+05      -5.528794e+01 |       32
     33       6.727692e+05      -4.921188e+01 |       32
     34       6.727213e+05      -4.788419e+01 |       32
     35       6.726834e+05      -3.789682e+01 |       32
     36       6.726439e+05      -3.949356e+01 |       32
     37       6.725964e+05      -4.750304e+01 |       32
     38       6.725453e+05      -5.112361e+01 |       32
     39       6.724940e+05      -5.127761e+01 |       32
     40       6.724517e+05      -4.226541e+01 |       32
     41       6.724077e+05      -4.404780e+01 |       32
     42       6.723541e+05      -5.360422e+01 |       32
     43       6.723062e+05      -4.790802e+01 |       32
     44       6.722616e+05      -4.451376e+01 |       32
     45       6.722192e+05      -4.248386e+01 |       32
     46       6.721827e+05      -3.645608e+01 |       32
     47       6.721473e+05      -3.545195e+01 |       32
     48       6.721135e+05      -3.372578e+01 |       32
     49       6.720812e+05      -3.233102e+01 |       32
     50       6.720459e+05      -3.526041e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672045.9406432228)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421935
[ Info: iteration 2, average log likelihood -1.416895
[ Info: iteration 3, average log likelihood -1.415608
[ Info: iteration 4, average log likelihood -1.414697
[ Info: iteration 5, average log likelihood -1.413690
[ Info: iteration 6, average log likelihood -1.412638
[ Info: iteration 7, average log likelihood -1.411813
[ Info: iteration 8, average log likelihood -1.411318
[ Info: iteration 9, average log likelihood -1.411043
[ Info: iteration 10, average log likelihood -1.410874
[ Info: iteration 11, average log likelihood -1.410752
[ Info: iteration 12, average log likelihood -1.410655
[ Info: iteration 13, average log likelihood -1.410573
[ Info: iteration 14, average log likelihood -1.410501
[ Info: iteration 15, average log likelihood -1.410437
[ Info: iteration 16, average log likelihood -1.410379
[ Info: iteration 17, average log likelihood -1.410326
[ Info: iteration 18, average log likelihood -1.410278
[ Info: iteration 19, average log likelihood -1.410233
[ Info: iteration 20, average log likelihood -1.410192
[ Info: iteration 21, average log likelihood -1.410154
[ Info: iteration 22, average log likelihood -1.410119
[ Info: iteration 23, average log likelihood -1.410085
[ Info: iteration 24, average log likelihood -1.410054
[ Info: iteration 25, average log likelihood -1.410025
[ Info: iteration 26, average log likelihood -1.409998
[ Info: iteration 27, average log likelihood -1.409972
[ Info: iteration 28, average log likelihood -1.409947
[ Info: iteration 29, average log likelihood -1.409924
[ Info: iteration 30, average log likelihood -1.409902
[ Info: iteration 31, average log likelihood -1.409881
[ Info: iteration 32, average log likelihood -1.409861
[ Info: iteration 33, average log likelihood -1.409842
[ Info: iteration 34, average log likelihood -1.409823
[ Info: iteration 35, average log likelihood -1.409806
[ Info: iteration 36, average log likelihood -1.409789
[ Info: iteration 37, average log likelihood -1.409774
[ Info: iteration 38, average log likelihood -1.409758
[ Info: iteration 39, average log likelihood -1.409744
[ Info: iteration 40, average log likelihood -1.409729
[ Info: iteration 41, average log likelihood -1.409716
[ Info: iteration 42, average log likelihood -1.409703
[ Info: iteration 43, average log likelihood -1.409690
[ Info: iteration 44, average log likelihood -1.409678
[ Info: iteration 45, average log likelihood -1.409666
[ Info: iteration 46, average log likelihood -1.409654
[ Info: iteration 47, average log likelihood -1.409643
[ Info: iteration 48, average log likelihood -1.409632
[ Info: iteration 49, average log likelihood -1.409622
[ Info: iteration 50, average log likelihood -1.409611
┌ Info: EM with 100000 data points 50 iterations avll -1.409611
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0723148   -0.40538       0.719595     -0.151242    0.480597    0.545047   -0.136714   -0.465439     0.497987    -0.335516   -0.0350873   -0.420964     0.0905931   0.295912    -0.157735    0.0880175   0.247162    -0.401751     0.0317799   0.573997    -0.557423    0.0831896   -0.912885   -0.15974    -0.0782411   0.108662
 -0.13958     -0.0877465    -0.406245     -0.374948   -0.576161   -0.343125    0.697882   -0.0189424    0.146999     0.208484   -0.13112     -0.0410311   -0.395194   -0.32627      0.394348   -0.266376    0.210262    -0.350052    -0.204251   -0.308071    -0.138319    0.470317    -0.331787    0.052869    0.209356    0.37244
  0.0407842   -0.453178     -0.576811     -0.396323   -0.0586515  -0.383992    0.143444   -0.277278     0.378046    -0.0300992  -0.423787     0.0887565    0.204894    0.148902    -0.559183    0.0933234  -0.299286     0.335204     0.313868   -0.074997    -0.488215   -0.236179    -0.082308   -0.31192    -0.624115    0.620244
 -0.0169446   -0.74022       0.167844     -0.0957802  -0.154246    0.131264   -0.500591   -0.0313126    0.089885    -0.0562818   0.257035     0.255507     0.106263    0.0723256    0.237002    0.176126    0.0325218    0.257908     0.140814   -0.093451    -0.0935442  -0.356569     0.0612663   0.29257     0.0019969   0.244452
 -0.457589     0.3497       -0.474511      0.0294943   0.269296   -0.107503    0.279717   -0.447399    -0.316521     0.108112   -0.279771     0.288973     0.669663   -0.150347     0.143375   -0.200593    0.176674     0.464312    -0.104796   -0.143496    -0.188718    0.0949055    0.0254274  -0.0355569   0.0496709   0.526792
  0.202387     0.074395     -0.0701309    -0.264787    0.288073    0.212992   -0.414683   -0.283452    -0.130113     0.34401    -0.239064     0.109247    -0.0922231  -0.163489     0.346476   -0.280529    0.465638     0.0642635    0.320459    0.588328     0.641809   -0.382684    -0.264624   -0.470195   -0.388986    0.0650367
  0.313085    -0.0181727     0.185916      0.245387   -0.601428    0.124684    0.0231198   0.501234     1.11344      0.0898491   0.913511     0.408865    -0.309971    0.0841445   -0.480013   -0.351474   -0.249825     0.253058     0.0866938   0.060528     0.335906   -0.143908    -0.145942   -0.439384   -0.0689355   0.0738867
  0.434805    -0.208943      0.308771      0.399649   -0.252992   -0.551599    0.417348   -0.654878    -0.494881     0.325379   -0.291347    -0.517283    -0.120244    0.436969     0.625494    0.593382   -0.00386507  -0.457238    -0.21735     0.325841    -0.336736    0.0462269   -0.132804    0.0332061  -0.0129202   0.0232366
  0.493559     0.327887     -0.674844      0.087812   -0.0277601  -0.175345   -0.202624    0.161251     0.786907    -0.250957    0.444251    -0.403115     0.167817    0.194681     0.0892397  -0.0161839   0.305679    -0.257896     0.858365    0.250319     0.140486    0.12774     -0.86277    -0.366967    0.367598   -0.386562
  0.0989947   -0.290565      0.579805      0.267297    0.0630104   0.392397   -0.76369     0.465087     0.548674    -0.253127    0.549973     0.40804     -0.154967    0.126365    -0.0329879  -0.133056    0.231807    -0.0594923    0.484741    0.20573      0.0934266  -0.0818401   -0.0293338   0.728656   -0.0534788  -0.667627
 -0.350765    -0.221852     -0.999941     -0.302522    0.363902    0.198251   -0.417821   -0.513171    -0.591207     0.0172445   0.0692045   -0.837811     0.253814    0.13795      0.132686    0.0775086   0.111062    -0.39701      0.793797    0.169881    -0.117093   -0.225697    -0.11189     0.603248   -0.220858   -0.138587
  0.0562427    0.0846618    -0.0222332     0.160786    0.138884    0.204395    0.0367486   0.0715407   -0.147003    -0.0780818   0.0931804   -0.174864    -0.0332909   0.26106     -0.0813696   0.0204193  -0.195582    -0.205546    -0.206722   -0.418174    -0.116862    0.124721     0.0753211   0.412654   -0.0565976  -0.191927
 -0.57048     -0.496469      0.302368      0.269414   -0.132044   -0.122116    0.366123    0.179054    -0.112291    -0.0246268   0.162182     0.215249    -0.0570561  -0.0155411   -0.243346    0.556215    0.314511     0.0217329    0.293831    0.952265     0.0183478  -0.398126     0.706866   -0.551475   -0.133836   -0.281904
  0.139882    -0.0614763     1.11014       0.216645    0.0733167  -0.27102     0.306916    0.194062     0.0613261    0.317962   -0.302493     0.582321    -0.271135   -0.147586    -0.349325    0.040886    0.240326     0.578493    -0.700902   -0.122108    -0.331484   -0.00397654   0.0591126  -0.257467    0.396322    0.340144
  0.631063     0.209382     -0.127013      0.0960748   0.249866   -0.429107    0.0265287   0.498201    -0.448802    -0.156786   -0.229231    -0.104219     0.157467   -0.418075    -0.383532    0.309508    0.364944     0.228166     0.271928   -0.123893    -0.734974   -0.403605    -0.264949    0.136144   -0.0636369  -0.297015
 -0.110231     0.0712644    -0.0133991     0.0501456   0.0364577  -0.0305939   0.211747    0.0188388   -0.107053    -0.0686621  -0.14426     -0.00350416   0.22089    -0.0840168   -0.293548    0.0954855  -0.00163652   0.118468    -0.0498485   0.0486048   -0.173475   -0.102158     0.113797   -0.145614    0.0146671   0.249329
  0.152195     0.136285     -0.000801143  -0.0141301  -0.0704853  -0.176876    0.0823546  -0.00283818   0.0399657    0.145636   -0.0310479    0.0107798    0.0177006  -0.0188235    0.116075   -0.0297251   0.0278909   -0.0298577    0.0382374   0.198605     0.147202   -0.0185034   -0.0484763  -0.144003    0.135813    0.0128734
  0.386247     0.47361       0.16945       0.0468549  -0.0466266  -0.0570706   0.249498   -0.450736    -0.355379     0.232812   -0.298382     0.281796     0.248473   -0.00593974   1.28607    -0.540518   -0.265778    -0.579179     0.243006   -0.00958928  -0.104814    0.458948    -0.582073    0.376606    0.246535    0.00821489
 -0.112715     0.0720823    -0.537579     -0.534234    0.0507012  -0.0895683  -0.0292165   0.454081    -0.154642     0.290485    0.563895     0.0862344    0.0294281  -0.68324     -0.368805   -0.125289   -0.0170287    0.472916     0.0865684   0.253412     0.753058   -0.213355     0.145636   -0.160304    0.548947    0.843329
 -0.615381    -0.237376     -0.0275174    -0.271628    0.207469    0.307007    0.105885   -0.299207     0.817277     0.125874   -0.00133985   0.34201     -0.278836    0.37007      0.480477   -0.775865   -0.254313    -0.367889     0.123628    0.285039     0.557084    0.649367     0.297164   -0.496386    0.0373714  -0.0648482
 -0.364242    -0.432263     -0.107702      0.319275   -0.657018    0.110504   -0.293684   -0.410064     0.232392     0.690965   -0.14179     -0.161567    -0.0432084   0.101626     0.66972    -0.0620591  -0.100969    -0.15775     -0.597386    0.139084     0.7176     -0.19743      0.564854    0.0705212   0.0852019   0.164504
 -0.0377279   -0.787306     -0.245393      0.1967      0.193428    0.181201   -0.197118    0.167049     0.832451     0.0410909   0.270251    -0.298347    -0.811506    0.185836    -0.579437    0.238944    0.46978      0.523447     0.33318    -0.365769     0.346182   -0.0925247    0.0967209   0.0397081  -0.299816   -0.297607
  0.0743977    0.620487     -0.343079      0.117343    0.0495279   0.199159   -0.532314    0.185944     0.391368     0.0763671   0.104604    -0.48265      0.502811    0.284707     0.123488   -0.771688   -0.0138338    0.00942162  -0.0155769  -0.509518     0.342952   -0.1871      -0.153408    0.479014   -0.122421    0.263358
 -0.466193     0.0324626     0.360517      0.179122    0.220489    0.493484   -0.155791    0.0748656   -0.21604     -0.294194    0.195276     0.190173     0.466239    0.38454     -0.140452    0.203206   -0.779419    -0.21304     -0.523271   -0.35476     -0.0796473  -0.242484     0.469654    0.100228   -0.259406    0.412772
  0.00110561   0.813175      0.0600919     0.32284    -0.284572   -0.240642    0.488248    0.315716    -0.271029     0.234574   -0.282471    -0.0337929    0.270648   -0.299623    -0.145899    0.401121   -0.0406335   -0.0459358   -0.309274    0.295535     0.179971    0.22012      0.332649   -0.448949    0.312877   -0.394169
  0.534657     0.565196      0.132913     -0.349488    0.430177   -0.163483    0.300834   -0.0850386   -0.375851    -0.138325   -0.181498    -0.193969    -0.0731582   0.391284    -0.146577   -0.203337   -0.352788    -0.0545111   -0.957357   -0.647827    -0.262085    0.206731    -0.263336    0.221287   -0.23297     0.186511
  0.605042    -0.000398725   0.0805972    -0.366447    0.671193   -0.381099   -0.158618    0.0281662   -0.00114634  -0.211847    1.09463      0.814628     0.777084    0.353084    -0.595961    0.417324   -0.323558     0.71647      0.505839    0.0594412    0.424339   -0.122794     0.0326272  -0.327093   -0.21422     0.170776
 -0.219264    -0.249347     -0.098129      0.0316414   0.361304    0.222625    0.18802     0.0370135    0.190956    -0.0326598   0.251351     0.344736    -0.218213    0.0324429   -0.50209     0.0288843   0.240581     0.0117137    0.268923    0.0528402   -0.272802    0.288694     0.146046   -0.43049    -0.104677   -0.260768
  0.227792     0.28511      -0.555611      0.513713   -0.473576   -0.713315    0.41138     0.503309    -0.529543     0.299545    0.0173589    0.194413    -0.19415     0.0316662    0.137465   -0.242433   -0.500942    -0.0368384    0.0375408  -0.939523     0.287204   -0.121967     0.936666    0.632359    0.415716   -0.213903
 -0.268551     0.0291876     0.243766      0.40507    -0.415397    0.870253   -0.205487    0.35683     -0.0983537    0.0821668  -0.373335    -0.668245    -0.55677    -0.406308     0.434339   -0.180481   -0.0914382   -0.62111     -0.498307    0.294798    -0.299163    0.297144    -0.0226399   0.25947     0.177861   -0.444241
  0.00449161   0.0628477     0.248685      0.244496    0.104854   -0.607764    0.140289   -0.0218307   -0.282618    -0.586579   -0.102924    -0.844853     0.342709    0.214158    -0.774699   -0.0462321  -0.319132     0.174547    -0.163659    0.224454    -0.260524   -0.104656     0.330425    0.46448     0.33892    -0.30465
  0.161857    -0.698345     -0.132144     -0.523649    0.0141122  -0.0422263  -0.309978   -0.247944    -0.109777     0.267874   -0.192115     0.687141    -0.437215   -0.648277     0.43487     0.379501    0.496353     0.170122     0.176967    0.0399298   -0.0879728   0.185953    -0.136161   -0.504933    0.0733077  -0.249189[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409601
[ Info: iteration 2, average log likelihood -1.409592
[ Info: iteration 3, average log likelihood -1.409582
[ Info: iteration 4, average log likelihood -1.409573
[ Info: iteration 5, average log likelihood -1.409564
[ Info: iteration 6, average log likelihood -1.409555
[ Info: iteration 7, average log likelihood -1.409547
[ Info: iteration 8, average log likelihood -1.409539
[ Info: iteration 9, average log likelihood -1.409531
[ Info: iteration 10, average log likelihood -1.409523
┌ Info: EM with 100000 data points 10 iterations avll -1.409523
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
