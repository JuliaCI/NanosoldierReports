Julia Version 1.5.0-DEV.71
Commit 15d693b0ec (2020-01-15 18:13 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed GaussianMixtures ─── v0.3.0
 Installed PDMats ───────────── v0.9.10
 Installed Arpack_jll ───────── v3.5.0+2
 Installed JLD ──────────────── v0.9.1
 Installed Rmath ────────────── v0.6.0
 Installed FileIO ───────────── v1.2.1
 Installed Parameters ───────── v0.12.0
 Installed FillArrays ───────── v0.8.4
 Installed SortingAlgorithms ── v0.3.1
 Installed Missings ─────────── v0.4.3
 Installed URIParser ────────── v0.4.0
 Installed StaticArrays ─────── v0.12.1
 Installed StatsBase ────────── v0.32.0
 Installed OrderedCollections ─ v1.1.0
 Installed BinaryProvider ───── v0.5.8
 Installed SpecialFunctions ─── v0.9.0
 Installed CMake ────────────── v1.1.2
 Installed CMakeWrapper ─────── v0.2.3
 Installed DataAPI ──────────── v1.1.0
 Installed NearestNeighbors ─── v0.4.4
 Installed StatsFuns ────────── v0.9.3
 Installed ScikitLearnBase ──── v0.5.0
 Installed Distances ────────── v0.8.2
 Installed BinDeps ──────────── v1.0.0
 Installed HDF5 ─────────────── v0.12.5
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Arpack ───────────── v0.4.0
 Installed LegacyStrings ────── v0.4.1
 Installed Blosc ────────────── v0.5.1
 Installed DataStructures ───── v0.17.8
 Installed Compat ───────────── v2.2.0
 Installed Clustering ───────── v0.13.3
 Installed QuadGK ───────────── v2.3.1
 Installed Distributions ────── v0.22.2
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.8
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.2
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_agGhBt/Project.toml`
 [no changes]
  Updating `/tmp/jl_agGhBt/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_1rkIdR/Project.toml`
 [no changes]
  Updating `/tmp/jl_1rkIdR/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_knJpsM/Project.toml`
 [no changes]
  Updating `/tmp/jl_knJpsM/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_5efdTr/Project.toml`
 [no changes]
  Updating `/tmp/jl_5efdTr/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_GgPowz/Project.toml`
 [no changes]
  Updating `/tmp/jl_GgPowz/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_GgPowz/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.2
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.6112616441573342e6, [99762.85100765436, 237.14899234563504], [-492.37123911979495 -150.26029647092753 873.9735023280472; 612.0776041992515 127.06619218214433 -390.17729314598665], [[98357.82290995121 -146.11325905005083 829.2149982618995; -146.11325905005086 99605.93279461584 -254.907319845539; 829.2149982618995 -254.90731984553906 98831.077991945], [1680.2056669051685 287.5976629235419 -901.2417467472993; 287.5976629235419 316.74309645075374 -176.0694702758984; -901.2417467472993 -176.0694702758984 831.3702197660948]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.419439e+03
      1       9.552372e+02      -4.642022e+02 |        8
      2       9.205790e+02      -3.465819e+01 |        2
      3       9.167738e+02      -3.805206e+00 |        2
      4       9.118660e+02      -4.907853e+00 |        2
      5       9.026108e+02      -9.255221e+00 |        2
      6       9.016850e+02      -9.257196e-01 |        0
      7       9.016850e+02       0.000000e+00 |        0
K-means converged with 7 iterations (objv = 901.6850330463103)
┌ Info: K-means with 272 data points using 7 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.085384
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.811066
[ Info: iteration 2, lowerbound -3.686582
[ Info: iteration 3, lowerbound -3.563713
[ Info: iteration 4, lowerbound -3.421399
[ Info: iteration 5, lowerbound -3.264120
[ Info: iteration 6, lowerbound -3.107474
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.970679
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.858967
[ Info: iteration 9, lowerbound -2.795085
[ Info: dropping number of Gaussions to 5
[ Info: iteration 10, lowerbound -2.771506
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.743230
[ Info: iteration 12, lowerbound -2.709679
[ Info: iteration 13, lowerbound -2.670527
[ Info: iteration 14, lowerbound -2.616679
[ Info: iteration 15, lowerbound -2.551085
[ Info: iteration 16, lowerbound -2.482977
[ Info: iteration 17, lowerbound -2.423190
[ Info: iteration 18, lowerbound -2.376674
[ Info: iteration 19, lowerbound -2.342224
[ Info: iteration 20, lowerbound -2.318602
[ Info: iteration 21, lowerbound -2.307862
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.303037
[ Info: iteration 23, lowerbound -2.299263
[ Info: iteration 24, lowerbound -2.299258
[ Info: iteration 25, lowerbound -2.299255
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan 16 03:57:00 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan 16 03:57:09 2020: K-means with 272 data points using 7 iterations
11.3 data points per parameter
, Thu Jan 16 03:57:11 2020: EM with 272 data points 0 iterations avll -2.085384
5.8 data points per parameter
, Thu Jan 16 03:57:13 2020: GMM converted to Variational GMM
, Thu Jan 16 03:57:22 2020: iteration 1, lowerbound -3.811066
, Thu Jan 16 03:57:22 2020: iteration 2, lowerbound -3.686582
, Thu Jan 16 03:57:22 2020: iteration 3, lowerbound -3.563713
, Thu Jan 16 03:57:22 2020: iteration 4, lowerbound -3.421399
, Thu Jan 16 03:57:22 2020: iteration 5, lowerbound -3.264120
, Thu Jan 16 03:57:22 2020: iteration 6, lowerbound -3.107474
, Thu Jan 16 03:57:22 2020: dropping number of Gaussions to 7
, Thu Jan 16 03:57:22 2020: iteration 7, lowerbound -2.970679
, Thu Jan 16 03:57:22 2020: dropping number of Gaussions to 6
, Thu Jan 16 03:57:22 2020: iteration 8, lowerbound -2.858967
, Thu Jan 16 03:57:22 2020: iteration 9, lowerbound -2.795085
, Thu Jan 16 03:57:22 2020: dropping number of Gaussions to 5
, Thu Jan 16 03:57:22 2020: iteration 10, lowerbound -2.771506
, Thu Jan 16 03:57:22 2020: dropping number of Gaussions to 3
, Thu Jan 16 03:57:22 2020: iteration 11, lowerbound -2.743230
, Thu Jan 16 03:57:22 2020: iteration 12, lowerbound -2.709679
, Thu Jan 16 03:57:22 2020: iteration 13, lowerbound -2.670527
, Thu Jan 16 03:57:22 2020: iteration 14, lowerbound -2.616679
, Thu Jan 16 03:57:22 2020: iteration 15, lowerbound -2.551085
, Thu Jan 16 03:57:22 2020: iteration 16, lowerbound -2.482977
, Thu Jan 16 03:57:22 2020: iteration 17, lowerbound -2.423190
, Thu Jan 16 03:57:22 2020: iteration 18, lowerbound -2.376674
, Thu Jan 16 03:57:22 2020: iteration 19, lowerbound -2.342224
, Thu Jan 16 03:57:22 2020: iteration 20, lowerbound -2.318602
, Thu Jan 16 03:57:22 2020: iteration 21, lowerbound -2.307862
, Thu Jan 16 03:57:22 2020: dropping number of Gaussions to 2
, Thu Jan 16 03:57:22 2020: iteration 22, lowerbound -2.303037
, Thu Jan 16 03:57:22 2020: iteration 23, lowerbound -2.299263
, Thu Jan 16 03:57:22 2020: iteration 24, lowerbound -2.299258
, Thu Jan 16 03:57:22 2020: iteration 25, lowerbound -2.299255
, Thu Jan 16 03:57:22 2020: iteration 26, lowerbound -2.299254
, Thu Jan 16 03:57:22 2020: iteration 27, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 28, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 29, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 30, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 31, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 32, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 33, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 34, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 35, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 36, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 37, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 38, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 39, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 40, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 41, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 42, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 43, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 44, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 45, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 46, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 47, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 48, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 49, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: iteration 50, lowerbound -2.299253
, Thu Jan 16 03:57:22 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398217, 178.0450922260178]
β = [95.95490777398217, 178.0450922260178]
m = [2.0002292577753376 53.851987172461115; 4.250300733269878 79.28686694436139]
ν = [97.95490777398217, 180.0450922260178]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948995 -0.008953123827346804; 0.0 0.012748664777409498], [0.18404155547483922 -0.0076440490423276995; 0.0 0.008581705166333024]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000006
avll from stats: -0.9858396655607444
avll from llpg:  -0.9858396655607463
avll direct:     -0.9858396655607463
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9886388382742901
avll from llpg:  -0.9886388382742901
avll direct:     -0.9886388382742901
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.133845    0.0652916    -0.11765      -0.0998711     0.117032    -0.0460089    0.0411881    -0.193645      0.00904208  -0.0972714   -0.0174501    0.0795975   -0.0134476     0.0659586   -0.016013    -0.0770214   -0.093079     0.0956163    0.0957077     0.0584446    0.050737     0.119724    0.049839     0.0391674    0.103987      0.125459
  0.0991016  -0.0620429     0.139398     -0.0567167    -0.0293798    0.123111    -0.0337316     0.0926641    -0.100722    -0.0535865   -0.149692    -0.0445724   -0.0897363    -0.015071    -0.0514093    0.0629258   -0.149348    -0.0355605    0.0172445     0.0191738   -0.0032274    0.189742    0.0307439   -0.0205446   -0.0334989    -0.0134815
  0.0320673  -0.0401604    -0.0338297    -0.157462     -0.0453797    0.0524317    0.102266     -0.0845506     0.115036    -0.130293     0.0273771   -0.136875    -0.041148      0.0238712    0.0107291    0.0341508   -0.0186447    0.288823     0.0680942    -0.0192245   -0.17393     -0.0225314  -0.0175212   -0.0205721   -0.060251     -0.127599
 -0.0627502   0.0607065     0.000484422   0.0939796    -0.101161     0.236965     0.0298271    -0.00729603    0.102926     0.056364    -0.154664    -0.188095    -0.0647106     0.155513    -0.0511977   -0.026284    -0.0393609    0.0953143    0.0448763    -0.0635875   -0.0430887    0.0604322   0.114467    -0.0544249   -0.164349      0.0142216
  0.0455683  -0.0939412    -0.0615931     0.154264     -0.0955772    0.162836    -0.0616274    -0.0015498    -0.0115145   -0.100096    -0.0679413    0.0333546   -0.0840523     0.020392     0.0211217    0.216933     0.00992632   0.080232     0.0918302     0.17563      0.0439447    0.113667    0.113113     0.025678    -0.165172      0.198852
  0.101768    0.0667688    -0.0263169     0.0229256     0.122582     0.0961783    0.154889      0.00503944    0.0726288    0.186903    -0.0489687    0.0186441    0.103094     -0.152754    -0.0350397    0.0123388    0.0781437    0.00610141   0.0425708    -0.0830494    0.0438385    0.15888    -0.0356629    0.0515819   -0.135473     -0.0781851
  0.128755   -0.035459     -0.0326909     0.00369101   -0.0167618   -0.132306    -0.104599      0.00402439    0.171707    -0.061468     0.09669     -0.104138    -0.0664927    -0.0297175    0.0718042   -0.0344185   -0.120281    -0.016304     0.016493      0.0654693    0.00476167  -0.149012    0.00119998  -0.00972818   0.0431647     0.0309201
  0.0377308  -0.108192      0.211591     -0.088409      0.020962    -0.0384019   -0.105463      0.000559459  -0.125222    -0.0240294   -0.0924882   -0.244208     0.122357     -0.191318     0.0718387   -0.115028    -0.0191256   -0.118217     0.300808     -0.0630691   -0.184443    -0.0217549   0.0596296   -0.0954494    0.0404764     0.141462
 -0.212843    0.113198      0.0387021    -0.074776     -0.00589207   0.137179     0.127037      0.0673784    -0.0524502   -0.0544328    0.0370491   -0.0480853   -0.0721127    -0.0683575   -0.0334252   -0.0821349    0.0171345   -0.129005     0.0809873    -0.0645712    0.210363     0.222326    0.0297572   -0.0152427   -0.113661     -0.131437
  0.0349761   0.0410693    -0.00301962   -0.111167     -0.00416577   0.114718     0.109954     -0.011035     -0.203425     0.120821     0.1324      -0.0390474   -0.119767     -0.0919365    0.190136    -0.0249131   -0.0771859   -0.12282     -0.0910173    -0.05225      0.0910706    0.0235002  -0.0866917   -0.181006    -0.10733      -0.167158
 -0.0514595   0.17367       0.00135404   -0.0154525     0.0319568   -0.0807028   -0.0857231    -0.0597661     0.17666     -0.011861     0.0624562   -0.108855     0.0669718    -0.0680435   -0.282849     0.169968     0.105227    -0.0458513    0.0101287    -0.0208298   -0.0755705   -0.0756606   0.255774    -0.0248746    0.105136      0.15378
  0.186916    0.0294391     0.096386      0.0581815    -0.070852    -0.0113816    0.0660331     0.0701113    -0.0465527   -0.0401892    0.0846526   -0.0689156    0.114912     -0.0237806    0.106187     0.0057833   -0.0811408   -0.0805673   -0.0672265     0.184834    -0.0976588   -0.0697307  -0.0152511    0.0309445    0.107391     -0.000501683
 -0.0757544  -0.101398      0.104829      0.199938      0.1373      -0.00251748   0.000312841   0.0558955    -0.0910015    0.1544       0.0139522    0.0786859   -0.0964358    -0.0775474   -0.0750673   -0.0131243    0.0580481    0.0388956    0.215229     -0.0606877    0.0647257   -0.0289323   0.0795602   -0.0307945    0.00553923    0.121643
  0.0311844  -0.0125767    -0.00303406   -0.0672658     0.25154     -0.0899809    0.113233     -0.041204      0.125214     0.0912119   -0.114314     0.125946     0.147229     -0.0974351   -0.0232887    0.00416151  -0.0420711   -0.0639322    0.0101583     0.171824    -0.0271425    0.0533801   0.00970895   0.0490078   -0.0291605    -0.0206308
  0.0758154   0.205235     -0.116543      0.056681     -0.0764891   -0.14908     -0.05077       0.0114038    -0.10731     -0.0592877   -0.052199     0.070631     0.0390232     0.107029     0.0305608   -0.00524792  -0.0108126    0.0137562    0.106085      0.045435    -0.0449133    0.0312735  -0.373348    -0.0487958    0.0086152     0.110873
 -0.0664303   0.0923674     0.0121718    -0.144674      0.139642     0.0338633    0.149591      0.245591      0.00599994  -0.0587489   -0.130915    -0.0625374    0.141452     -0.0955751   -0.1558      -0.101347    -0.104283     0.129808     0.0550211    -0.00186365  -0.128004    -0.0702673   0.0860427   -0.0686477   -0.136048      0.0724067
 -0.0582841  -0.0467742     0.0600641     0.0463319     0.125571    -0.0384953    0.131224     -0.24304      -0.0586361    0.04131      0.152345    -0.00615822   0.101114     -0.0770703   -0.0287999   -0.00102231  -0.0680749    0.0448663    0.0160917     0.069356     0.0574803   -0.294687   -0.0745826   -0.0468717    0.133366      0.0653955
  0.0275675  -0.058838      0.129327      0.128461     -0.140684    -0.189352    -0.0247333    -0.0272074     0.0422669   -0.167385     0.11043      0.11743      0.0762912     0.0166356   -0.00113751  -0.0506139    0.0183335   -0.0687734    0.125065     -0.0058103   -0.0829388    0.0540289   0.246057     0.151856    -0.124233     -0.0188067
  0.0556172  -0.0551647    -0.0088994    -0.15527       0.174355     0.0417922    0.0012997    -0.00579065   -0.0272139   -0.0125865    0.0403119   -0.0871853    0.0198134    -0.0859262   -0.033804    -0.0833449    0.0879683   -0.186513     0.0852587     0.110584    -0.141449    -0.0527989  -0.0857916    0.0862303   -0.0401158     0.0872992
  0.0564601   0.0434955     0.0249582     0.09775      -0.201352     0.0261755   -0.0343531     0.0341288    -0.0221928   -0.0236412    0.0676459    0.0528654   -0.0678392    -0.146055    -0.0860817   -0.0249737   -0.09159     -0.122907     0.0602604    -0.0707746   -0.110454     0.0787561  -0.0455026   -0.055939    -0.0846081     0.09719
  0.108795    0.0359521     0.109569     -0.0301479     0.147325     0.159405    -0.0410681     0.0432976     0.0910411   -0.108771     0.0638854   -0.0205137    0.0151522     0.133938     0.0040106    0.0133041    0.107916    -0.0132818   -0.0431476    -0.0964035    0.221046     0.0375512   0.0916896    0.0731559    0.000447244  -0.11223
 -0.0279599   0.0363416    -0.0861249     0.000127016  -0.0780327    0.0268482   -0.00505781    0.103861     -0.0386875    0.119542     0.0400952   -0.0523902   -0.217484     -0.0643737   -0.10109     -0.0695139    0.108723     0.0102596    0.0502009     0.0890568   -0.0248415   -0.0578667   0.00166656   0.0991035    0.127718     -0.0230778
  0.0682163  -0.01586       0.0384872     0.0637863    -0.0350099   -0.0397288    0.174573      0.0534617     0.0842504   -0.0602289    0.00721002   0.00281374   0.0533168     0.0247975    0.0620369    0.188635     0.120366     0.167784     0.143781      0.0849825    0.0105829    0.197574    0.0847064   -0.134321    -0.0515645     0.00643028
  0.237551    0.173757     -0.110191     -0.0549762     0.00969292   0.0500771    0.0385984    -0.13916       0.0302052    0.0162459   -0.0274214    0.104246    -0.045971     -0.069675     0.0752701    0.0727588   -0.0497244   -0.0055366   -0.0795047    -0.144626    -0.0178923   -0.0406015   0.0899409    0.117144    -0.0830044     0.0999836
  0.0331781  -0.061904      0.0814307     0.0898969    -0.0401472   -0.117927    -0.211021      0.170542      0.103408     0.00828894  -0.163432    -0.0257262   -0.14684      -0.0556035   -0.272296    -0.0572433    0.118721    -0.119501     0.0537606    -0.0859182   -0.0553977    0.0419391   0.0731521    0.0789006    0.129676      0.0489607
  0.0206671  -0.000690295   0.0480186    -0.0174378    -0.0565524    0.0383053    0.0107475     0.0464454    -0.0801596    0.0467434    0.219195    -0.063908    -0.128307     -0.075816    -0.0807949   -0.0410204   -0.00156733  -0.0556511   -0.12124      -0.0118189    0.0262766    0.283301    0.0743658   -0.220742    -0.083733     -0.0776582
 -0.138742    0.122854     -0.148938     -0.0348432     0.0168888   -0.0233997   -0.122538     -0.106104     -0.0528939   -0.11024      0.164136     0.0148012    0.0059515    -0.0378338    0.064638    -0.22525      0.0223194   -0.0809724   -0.144949      0.168053     0.161519     0.148605    0.0880781   -0.104774    -0.0153894    -0.0119127
  0.0118222   0.0449738    -0.10833      -0.0546228     0.012396     0.0403327    0.0400055     0.0421577     0.0432611   -0.0155558   -0.00300939   0.0606143   -0.0719728    -0.00159848  -0.03588      0.238556    -0.117317    -0.0585731   -0.0459186    -0.163797    -0.135633    -0.0195232   0.0147347    0.17484     -0.0115286     0.0544543
 -0.0690378  -0.188899     -0.133641      0.023087     -0.138496     0.0310557   -0.10064       0.00985183    0.0376709   -0.011924     0.0834252   -0.0492035   -0.000605121   0.144137    -0.0398319   -0.0368418   -0.218393     0.104533    -0.0382693    -0.0760299    0.0315028    0.0484364   0.0866368   -0.0264878    0.255487      0.13812
 -0.0178483  -0.146977      0.0072932     0.0809323    -0.0591105   -0.101428    -0.0360365     0.0149077    -0.0810184    0.241661     0.040157    -0.108712    -0.0603311    -0.0486805    0.0360739   -0.140538    -0.160536     0.00879674   0.000890437   0.096541     0.013536     0.268978   -0.0777178   -0.0648719    0.0715924     0.103043
 -0.0908027   0.0495823    -0.136242     -0.234497     -0.162181    -0.149447    -0.0416565     0.0388918     0.120422     0.00842985  -0.0787834   -0.115378     0.224057      0.0981214   -0.0907209    0.052628    -0.0298226    0.142579     0.00360864   -0.0232451   -0.0256041   -0.0638452  -0.163583    -0.189722     0.0582923     0.0676696
 -0.10128    -0.0497382    -0.107699      0.112799     -0.00825483   0.122003    -0.167144     -0.0782571     0.015138     0.0675713    0.0282724   -0.0579362    0.0512924     0.0607411    0.0646124   -0.0975742    0.0159672    0.00299178  -0.0182862     0.244362     0.164104    -0.0943771  -0.184576    -0.0305813   -0.0421167     0.043653kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3782991312276123
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.378357
[ Info: iteration 2, average log likelihood -1.378303
[ Info: iteration 3, average log likelihood -1.377957
[ Info: iteration 4, average log likelihood -1.374384
[ Info: iteration 5, average log likelihood -1.362007
[ Info: iteration 6, average log likelihood -1.352757
[ Info: iteration 7, average log likelihood -1.351018
[ Info: iteration 8, average log likelihood -1.350540
[ Info: iteration 9, average log likelihood -1.350299
[ Info: iteration 10, average log likelihood -1.350150
[ Info: iteration 11, average log likelihood -1.350044
[ Info: iteration 12, average log likelihood -1.349964
[ Info: iteration 13, average log likelihood -1.349901
[ Info: iteration 14, average log likelihood -1.349850
[ Info: iteration 15, average log likelihood -1.349809
[ Info: iteration 16, average log likelihood -1.349775
[ Info: iteration 17, average log likelihood -1.349747
[ Info: iteration 18, average log likelihood -1.349723
[ Info: iteration 19, average log likelihood -1.349702
[ Info: iteration 20, average log likelihood -1.349684
[ Info: iteration 21, average log likelihood -1.349669
[ Info: iteration 22, average log likelihood -1.349655
[ Info: iteration 23, average log likelihood -1.349643
[ Info: iteration 24, average log likelihood -1.349632
[ Info: iteration 25, average log likelihood -1.349622
[ Info: iteration 26, average log likelihood -1.349613
[ Info: iteration 27, average log likelihood -1.349605
[ Info: iteration 28, average log likelihood -1.349597
[ Info: iteration 29, average log likelihood -1.349590
[ Info: iteration 30, average log likelihood -1.349584
[ Info: iteration 31, average log likelihood -1.349578
[ Info: iteration 32, average log likelihood -1.349572
[ Info: iteration 33, average log likelihood -1.349566
[ Info: iteration 34, average log likelihood -1.349561
[ Info: iteration 35, average log likelihood -1.349556
[ Info: iteration 36, average log likelihood -1.349551
[ Info: iteration 37, average log likelihood -1.349546
[ Info: iteration 38, average log likelihood -1.349541
[ Info: iteration 39, average log likelihood -1.349536
[ Info: iteration 40, average log likelihood -1.349532
[ Info: iteration 41, average log likelihood -1.349527
[ Info: iteration 42, average log likelihood -1.349523
[ Info: iteration 43, average log likelihood -1.349518
[ Info: iteration 44, average log likelihood -1.349514
[ Info: iteration 45, average log likelihood -1.349510
[ Info: iteration 46, average log likelihood -1.349506
[ Info: iteration 47, average log likelihood -1.349502
[ Info: iteration 48, average log likelihood -1.349498
[ Info: iteration 49, average log likelihood -1.349494
[ Info: iteration 50, average log likelihood -1.349490
┌ Info: EM with 100000 data points 50 iterations avll -1.349490
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3783570795354598
│     -1.3783025511449942
│      ⋮
└     -1.3494895195233596
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.349576
[ Info: iteration 2, average log likelihood -1.349483
[ Info: iteration 3, average log likelihood -1.349006
[ Info: iteration 4, average log likelihood -1.344307
[ Info: iteration 5, average log likelihood -1.330268
[ Info: iteration 6, average log likelihood -1.317334
[ Info: iteration 7, average log likelihood -1.309706
[ Info: iteration 8, average log likelihood -1.305520
[ Info: iteration 9, average log likelihood -1.303401
[ Info: iteration 10, average log likelihood -1.302243
[ Info: iteration 11, average log likelihood -1.301568
[ Info: iteration 12, average log likelihood -1.301120
[ Info: iteration 13, average log likelihood -1.300783
[ Info: iteration 14, average log likelihood -1.300503
[ Info: iteration 15, average log likelihood -1.300265
[ Info: iteration 16, average log likelihood -1.300067
[ Info: iteration 17, average log likelihood -1.299911
[ Info: iteration 18, average log likelihood -1.299791
[ Info: iteration 19, average log likelihood -1.299699
[ Info: iteration 20, average log likelihood -1.299625
[ Info: iteration 21, average log likelihood -1.299566
[ Info: iteration 22, average log likelihood -1.299517
[ Info: iteration 23, average log likelihood -1.299477
[ Info: iteration 24, average log likelihood -1.299444
[ Info: iteration 25, average log likelihood -1.299415
[ Info: iteration 26, average log likelihood -1.299390
[ Info: iteration 27, average log likelihood -1.299368
[ Info: iteration 28, average log likelihood -1.299348
[ Info: iteration 29, average log likelihood -1.299329
[ Info: iteration 30, average log likelihood -1.299311
[ Info: iteration 31, average log likelihood -1.299294
[ Info: iteration 32, average log likelihood -1.299278
[ Info: iteration 33, average log likelihood -1.299261
[ Info: iteration 34, average log likelihood -1.299245
[ Info: iteration 35, average log likelihood -1.299227
[ Info: iteration 36, average log likelihood -1.299208
[ Info: iteration 37, average log likelihood -1.299187
[ Info: iteration 38, average log likelihood -1.299164
[ Info: iteration 39, average log likelihood -1.299138
[ Info: iteration 40, average log likelihood -1.299110
[ Info: iteration 41, average log likelihood -1.299079
[ Info: iteration 42, average log likelihood -1.299045
[ Info: iteration 43, average log likelihood -1.299008
[ Info: iteration 44, average log likelihood -1.298968
[ Info: iteration 45, average log likelihood -1.298921
[ Info: iteration 46, average log likelihood -1.298866
[ Info: iteration 47, average log likelihood -1.298803
[ Info: iteration 48, average log likelihood -1.298731
[ Info: iteration 49, average log likelihood -1.298646
[ Info: iteration 50, average log likelihood -1.298545
┌ Info: EM with 100000 data points 50 iterations avll -1.298545
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3495762196018875
│     -1.3494828308874651
│      ⋮
└     -1.2985449259314066
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.298562
[ Info: iteration 2, average log likelihood -1.298283
[ Info: iteration 3, average log likelihood -1.297576
[ Info: iteration 4, average log likelihood -1.292746
[ Info: iteration 5, average log likelihood -1.279167
[ Info: iteration 6, average log likelihood -1.263218
[ Info: iteration 7, average log likelihood -1.252572
[ Info: iteration 8, average log likelihood -1.247667
[ Info: iteration 9, average log likelihood -1.245174
[ Info: iteration 10, average log likelihood -1.243198
[ Info: iteration 11, average log likelihood -1.240262
[ Info: iteration 12, average log likelihood -1.236982
[ Info: iteration 13, average log likelihood -1.235564
[ Info: iteration 14, average log likelihood -1.234817
[ Info: iteration 15, average log likelihood -1.234326
[ Info: iteration 16, average log likelihood -1.233984
[ Info: iteration 17, average log likelihood -1.233720
[ Info: iteration 18, average log likelihood -1.233506
[ Info: iteration 19, average log likelihood -1.233338
[ Info: iteration 20, average log likelihood -1.233212
[ Info: iteration 21, average log likelihood -1.233114
[ Info: iteration 22, average log likelihood -1.233036
[ Info: iteration 23, average log likelihood -1.232972
[ Info: iteration 24, average log likelihood -1.232916
[ Info: iteration 25, average log likelihood -1.232865
[ Info: iteration 26, average log likelihood -1.232815
[ Info: iteration 27, average log likelihood -1.232762
[ Info: iteration 28, average log likelihood -1.232703
[ Info: iteration 29, average log likelihood -1.232633
[ Info: iteration 30, average log likelihood -1.232545
[ Info: iteration 31, average log likelihood -1.232432
[ Info: iteration 32, average log likelihood -1.232287
[ Info: iteration 33, average log likelihood -1.232101
[ Info: iteration 34, average log likelihood -1.231863
[ Info: iteration 35, average log likelihood -1.231562
[ Info: iteration 36, average log likelihood -1.231201
[ Info: iteration 37, average log likelihood -1.230807
[ Info: iteration 38, average log likelihood -1.230418
[ Info: iteration 39, average log likelihood -1.230076
[ Info: iteration 40, average log likelihood -1.229814
[ Info: iteration 41, average log likelihood -1.229625
[ Info: iteration 42, average log likelihood -1.229488
[ Info: iteration 43, average log likelihood -1.229384
[ Info: iteration 44, average log likelihood -1.229304
[ Info: iteration 45, average log likelihood -1.229244
[ Info: iteration 46, average log likelihood -1.229200
[ Info: iteration 47, average log likelihood -1.229168
[ Info: iteration 48, average log likelihood -1.229144
[ Info: iteration 49, average log likelihood -1.229127
[ Info: iteration 50, average log likelihood -1.229114
┌ Info: EM with 100000 data points 50 iterations avll -1.229114
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2985615067545706
│     -1.2982828535594622
│      ⋮
└     -1.229114326518742
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.229259
[ Info: iteration 2, average log likelihood -1.229028
[ Info: iteration 3, average log likelihood -1.227208
[ Info: iteration 4, average log likelihood -1.211130
[ Info: iteration 5, average log likelihood -1.181243
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.157931
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.163421
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.163805
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.152425
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.144723
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.161123
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.155714
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.164971
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.149170
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.154665
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.152541
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.151596
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.162576
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.160776
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.157460
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.145009
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     10
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.147326
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.172771
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.162552
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.149493
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.140775
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     10
│     11
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.147622
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.178794
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.156856
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.146825
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.151974
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     10
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.150094
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.170906
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.152411
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.156704
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.153497
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     10
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.141519
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.165197
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.159797
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.154348
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.141113
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     10
│     12
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.133033
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.171627
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.158949
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.145153
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.135882
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     10
│     11
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.142180
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.172662
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.150811
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.140885
┌ Info: EM with 100000 data points 50 iterations avll -1.140885
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2292588486080953
│     -1.229028246163584
│      ⋮
└     -1.1408848570818408
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     21
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.146206
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.130584
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     21
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.136044
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.112086
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     21
│     22
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.105804
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.078486
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     18
│     19
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.075419
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     21
│     22
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.075050
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     18
│     19
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.055148
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      7
│     15
│     16
│     19
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.062104
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.076717
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.063922
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.062409
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.068704
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.054128
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      7
│     15
│     16
│     19
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.060777
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.074551
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.061948
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.044527
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.066200
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.046033
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.039885
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     18
│     20
│     21
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.056079
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.053839
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.045141
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.064108
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.044134
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.042979
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     18
│     20
│     21
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.053757
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.057937
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.041632
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.065541
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.042384
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.043189
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     18
│     20
│     21
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.055331
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.052522
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.044962
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.065937
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.047552
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.043439
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.056890
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.059140
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.039307
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.065917
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.046931
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.040594
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     18
│     20
│     21
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.054788
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.057491
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.042328
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     19
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.064953
┌ Info: EM with 100000 data points 50 iterations avll -1.064953
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1462062158305344
│     -1.1305841948304518
│      ⋮
└     -1.0649529001343916
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3782991312276123
│     -1.3783570795354598
│     -1.3783025511449942
│     -1.3779570164754822
│      ⋮
│     -1.0574910469309673
│     -1.0423275944146628
└     -1.0649529001343916
32×26 Array{Float64,2}:
  0.0291487   -0.00157751   0.0570648    -0.0364593  -0.0368462    0.0660074   -0.0196307    0.0818004   -0.0558088    0.0656272   -0.0848963   -0.0459388    -0.156063    -0.0417275   -0.095478   -0.00155947   -0.0131884   -0.0346988    0.0487381    0.0506194   -0.00941236   0.0631201    0.0217066   0.0368508    0.0398834  -0.0161659
  0.0265624    0.0365379   -0.168578     -0.0535914  -0.0309937    0.0553027    0.0221213    0.0890902    0.0391152   -0.0167712   -0.0187737    0.0577407    -0.0647151    0.0281808   -0.0791394   0.230896     -0.117043    -0.0785239   -0.034088    -0.163472    -0.117166    -0.0152762    0.010872    0.174756    -0.0328437   0.0483374
 -0.0735572   -0.255014    -0.157474      0.233157   -0.10768     -0.222466    -0.083177     0.00260411   0.0492093   -0.0634681    0.096468    -0.029264     -0.0121307    0.0871348   -0.208398   -0.0374032    -0.241517     0.0573286   -0.0438496   -0.0351634    0.0189945    0.06346      0.0504456  -0.0633759    0.257194    0.136506
 -0.076013    -0.103724    -0.0532202    -0.11612    -0.147078     0.290161    -0.20672      0.0187042    0.0881424    0.0239831    0.0262584   -0.0614136     0.00965104   0.177903     0.0477433  -0.03257      -0.171191     0.211071    -0.0298415   -0.154482     0.041001     0.0208078    0.0932034   0.0139114    0.263401    0.136725
  0.0849496    0.0116894   -0.0453234    -0.0237727  -0.0764767    0.0300741   -0.0355133   -0.0485882    0.00583234  -0.0401133   -0.0764186   -0.0149687     0.034702    -0.0339666    0.0258901   0.0890637    -0.020062     0.0346259    0.0628008   -0.018847    -0.0317343    0.00581649   0.0430186  -0.0192216   -0.056321    0.139764
 -0.0477752    0.175299     0.00831993   -0.0191068   0.0870335   -0.0462617   -0.0923393   -0.0602924    0.222339    -0.00404595   0.0619822   -0.106304      0.0578611   -0.07539     -0.279603    0.192094      0.105741    -0.0423827    0.0101344   -0.0137084   -0.0669528   -0.0868745    0.252754   -0.0196905    0.10485     0.132316
  0.0336525    0.00199248   0.0206995    -0.0493323  -0.0409351    0.0134196    0.107197     0.0263094   -0.0427313    0.0304664    0.0298868   -0.0263249    -0.00596198  -0.0101814    0.0951502   0.06384       0.0134996    0.0337296    0.0292045    0.00842641   0.0317401    0.0853677   -0.0132278  -0.140441    -0.0753382  -0.0681869
 -0.0319887   -0.0510736    0.0235446     0.122858   -0.07996     -0.0236581   -0.101956    -0.0613825    0.0379178   -0.0102267    0.065234     0.0376267     0.046705     0.042222     0.0239183  -0.08296       0.0181109   -0.0301625    0.0598485    0.11177      0.0760741   -0.0366555    0.013649    0.067116    -0.0797652   0.0126693
  0.0202835   -0.0295394    0.129776     -0.0919155  -0.07986      0.0218542    0.0402303    0.0397546   -0.262239     0.0490469    0.225678    -0.214442     -0.113573    -0.100693    -0.0810021  -0.0808276     0.00194025  -0.0856811   -0.106856    -0.100123     0.00172345   0.294772     0.1153     -0.88684     -0.155106   -0.03366
  0.0193375    0.0914304    0.0226371     0.058433   -0.0364623    0.0444987   -0.0268822    0.0481594    0.037925     0.0216783    0.229949     0.0800894    -0.143892    -0.0473399   -0.0773138   0.00148199   -0.0490745   -0.0323092   -0.125458     0.0954743    0.0751892    0.332809     0.0357564   0.37433     -0.0191941  -0.023728
  0.0438541    0.0471223    0.13305       0.037331   -0.199097     0.0281008   -0.0503012    0.0316475   -0.0498974   -0.0273111    0.076562     0.0384203    -0.0499776   -0.142562    -0.112865    0.00416066   -0.137594    -0.133799     0.0577882   -0.0819234   -0.172826     0.0487041   -0.0315229  -0.0635271   -0.074414    0.0948352
 -0.0532155    0.0840459    0.0136107    -0.0260793   0.0478427    0.0920004    0.114552     0.0689429   -0.0229066    0.0602479   -0.00147016  -0.0425168     0.0209032   -0.114634    -0.0300438  -0.0392957     0.0267159   -0.057429     0.0729618   -0.0707503    0.112259     0.179398     0.0163832   0.0198482   -0.112174   -0.104501
  0.148186     0.135571    -0.00469592    0.0600334  -0.0907464   -0.0881092    0.00972715   0.04088     -0.0691642   -0.0490428    0.0107916    0.00338645    0.099017     0.0429871    0.0755777   0.00292078   -0.0515262   -0.0383602   -0.00778466   0.118423    -0.0677877   -0.00395302  -0.173359    0.0281896    0.0821645   0.0511134
  0.0713883   -0.00097415   0.0448809    -0.0517526   0.219297     0.0193883    0.0424277   -0.0318182    0.111819    -0.00186863  -0.0327898    0.0616131     0.0686854   -0.00162423  -0.0256952   0.00945975    0.0304689   -0.0357009   -0.00835138   0.0421209    0.0838849    0.0469331    0.0529991   0.0604039   -0.0178612  -0.0605694
 -0.0807187   -0.085045     0.103485      0.128247    0.148679    -0.145314     0.0290841   -0.0195821   -0.0844079    0.154504    -0.0494505   -0.854524     -0.200798    -0.154264    -0.0718475   0.116214     -0.0667669   -0.0454593    0.247698    -0.0409998    0.0646092   -0.154064     0.0670738  -0.0148347    0.125604    0.134161
 -0.0726515   -0.101896     0.10485       0.261445    0.14664      0.159329    -0.0222242    0.0446784   -0.0831236    0.156277     0.0852274    0.672424     -0.0155508   -0.0827521   -0.0697481  -0.0859742     0.154477     0.0689043    0.210923    -0.0779239    0.0646306    0.0489312    0.0675592  -0.00421836  -0.0840851   0.112716
  0.00373135  -0.144918     0.0182351     0.0798625  -0.0622711   -0.100025    -0.0817528    0.0103159   -0.088143     0.271108     0.038763    -0.122326     -0.0603457   -0.0426229    0.0529643  -0.148817     -0.177737    -0.00171487   0.0150404    0.09688      0.0328252    0.266692    -0.086018   -0.0672388    0.0724849   0.0872823
 -0.146427     0.111651    -0.146051      0.0145763   0.0261943   -0.0287685   -0.115902    -0.117115    -0.0469938   -0.0706327    0.159013     0.0127967     6.31059e-5  -0.00872122   0.0539678  -0.157804      0.0199008   -0.0948962   -0.143165     0.166659     0.176771     0.151916     0.101431   -0.111802    -0.021123   -0.0156263
  0.271857    -0.258626    -0.00151781   -0.141904    0.171912    -0.0406198    0.00798089  -0.00484366  -0.0849316    0.0255961    0.0716187   -0.0894321     0.0196281   -0.0693537   -0.0440954  -0.150711      0.0630773   -0.603391     0.0768119    0.094702    -0.014075    -0.0521233    0.0498622   0.0951458   -0.245993    0.219712
  0.0489911   -0.0424623   -0.0143369    -0.155366    0.183186     0.0663169    0.00241315  -0.00672092  -0.0096707   -0.0176564    0.0201683   -0.085182      0.018995    -0.0948738   -0.035568   -0.054076      0.0968539   -0.114356     0.0834625    0.108317    -0.198506    -0.0488019   -0.116178    0.0530395   -0.0375745   0.061747
 -0.0106856    0.108739    -0.0702558    -0.130841    0.229292     0.0399188   -0.102087     0.234052     0.00586793  -0.20941     -0.171846    -0.0124722     0.141949    -0.0945075   -0.682395    0.22291      -0.0997704    0.0502292    0.0783417   -0.0150816   -0.138678    -0.15287      0.105137   -0.0695203   -0.204971    0.0610431
 -0.146552     0.0036182    0.0953565    -0.142521    0.0431554    0.00160378   0.393644     0.237889     0.00610008   0.0371045   -0.108314    -0.118747      0.139785    -0.0957112    0.367851   -0.44241      -0.103868     0.138718     0.0317149   -0.0121961   -0.113047    -0.0275827    0.106217   -0.0722704   -0.112897    0.0657846
  0.117926    -0.0486957   -0.0322734    -0.0835509  -0.00751349  -0.122966    -0.0598684    0.014878     0.177238    -0.0197525    0.0856038   -0.105315     -0.300088    -0.0322046    0.0554677  -0.018016     -0.115244    -0.0193661    0.018888     0.671323     0.00804953  -0.199934    -0.108969   -0.0349148    0.0371996   0.0299159
  0.120819    -0.0486147   -0.0417793     0.146401   -0.014081    -0.0947412   -0.165429    -0.0111357    0.167852    -0.119546     0.0734565   -0.106961      0.36115     -0.0315949    0.131273   -0.0758785    -0.12833     -0.021855     0.0407029   -0.960971     0.0100714   -0.192814     0.0851106   0.0191543    0.0397042   0.030834
  0.0410308   -0.0612886    0.0827237     0.174868   -0.0133252   -0.121794    -0.13877      0.168672     0.0920416    0.00953399  -0.189475     0.00774415   -0.458224     0.00525528  -0.266343   -0.0428801     0.14179     -0.119585    -0.622616     0.130104    -0.0425668    0.145252     0.117929    0.0718295    0.0650739   0.0535102
  0.0266686   -0.0656451    0.0675689     0.0936035  -0.0330654   -0.115105    -0.23106      0.173106     0.107549    -0.00342222  -0.139467    -0.0469341     0.147525    -0.00330738  -0.287451   -0.0816331     0.110497    -0.118862     0.546959    -0.275344    -0.0641592   -0.0101231    0.0223929   0.0840878    0.161458    0.037631
 -0.0622734    0.0567609    0.000797068   0.0905912  -0.0944349    0.2239      -0.00341948  -0.0132847    0.0948111    0.0521418   -0.153179    -0.163258     -0.084969     0.145455    -0.0506337  -0.0246258    -0.0323817    0.088274     0.0539833   -0.0596273   -0.0337151    0.0646916    0.142954   -0.0567105   -0.156536    0.0333884
  0.0326526   -0.0300462   -0.0294346    -0.13929    -0.0716353    0.0508263    0.104042    -0.104403     0.119017    -0.134559     0.0197464   -0.136614     -0.0426899    0.0292822    0.0115841   0.0453523     0.00126086   0.283472     0.0543544   -0.014961    -0.179769    -0.0172969   -0.017567   -0.0213689   -0.0847546  -0.130597
 -0.131669     0.0341081   -0.124025     -0.108539    0.154255    -0.0507176    0.0383386   -0.189822     0.0137101   -0.0985083   -0.0341651    0.0198247    -0.0140001    0.0572148   -0.016413   -0.0740969    -0.0714033    0.142832     0.0649476    0.057617     0.0398604    0.296485     0.0490277   0.0663304    0.103323    0.120807
 -0.132489     0.0611761   -0.0848004    -0.135839    0.107179    -0.0505938    0.0363896   -0.178384     0.00963563  -0.0901188   -0.0210555    0.0451798    -0.0127618    0.0705772   -0.151417   -0.0755712    -0.103018     0.0997833    0.0979992    0.0527569    0.077063    -0.00371702   0.0489866  -0.0160725    0.104769    0.126268
 -0.0562426   -0.0286764    0.122646      0.0470905   0.267242    -0.0402291    0.12476     -0.175877     0.202542     0.0388368    0.126838    -0.0164029     0.186183    -0.0780527   -0.0115222  -0.000223773  -0.0751064   -0.0298581   -0.573029     0.0733829    0.0581268   -0.295147    -0.0761479  -0.0423467    0.173323   -0.000820753
 -0.0322922   -0.0601302    0.0148669     0.0386689   0.0713588   -0.0399408    0.148431    -0.295266    -0.315793     0.0425206    0.17385     -0.000229994   0.00893238  -0.0772076   -0.0321686  -0.00189575   -0.068031     0.102842     0.744597     0.104641     0.0683721   -0.294443    -0.0758899  -0.0340281    0.134125    0.101849[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.043328
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     15
│     16
│     18
│     20
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.030582
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     18
│     19
│     20
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.038178
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     15
│     16
│     18
│     20
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.029410
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.032511
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      7
│     15
│     16
│     18
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.020340
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     20
│     21
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.034547
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     15
│     16
│     18
│     20
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.021617
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     18
│     20
│     21
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.030450
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│     15
│     16
│     18
│     19
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.024373
┌ Info: EM with 100000 data points 10 iterations avll -1.024373
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.007688e+05
      1       6.506329e+05      -1.501359e+05 |       32
      2       6.244634e+05      -2.616950e+04 |       32
      3       6.068185e+05      -1.764493e+04 |       32
      4       5.927486e+05      -1.406992e+04 |       32
      5       5.862356e+05      -6.512978e+03 |       32
      6       5.830908e+05      -3.144782e+03 |       32
      7       5.810278e+05      -2.062981e+03 |       32
      8       5.796293e+05      -1.398557e+03 |       32
      9       5.787905e+05      -8.387946e+02 |       32
     10       5.780401e+05      -7.503469e+02 |       32
     11       5.771491e+05      -8.910535e+02 |       32
     12       5.760641e+05      -1.085005e+03 |       32
     13       5.748723e+05      -1.191758e+03 |       32
     14       5.734435e+05      -1.428783e+03 |       32
     15       5.720488e+05      -1.394706e+03 |       32
     16       5.714028e+05      -6.460072e+02 |       32
     17       5.711774e+05      -2.253803e+02 |       32
     18       5.711005e+05      -7.691587e+01 |       32
     19       5.710605e+05      -4.003080e+01 |       32
     20       5.710351e+05      -2.541909e+01 |       32
     21       5.710168e+05      -1.831107e+01 |       32
     22       5.710016e+05      -1.521669e+01 |       31
     23       5.709896e+05      -1.190525e+01 |       31
     24       5.709788e+05      -1.087916e+01 |       27
     25       5.709673e+05      -1.150257e+01 |       32
     26       5.709589e+05      -8.349642e+00 |       27
     27       5.709544e+05      -4.532015e+00 |       27
     28       5.709491e+05      -5.301524e+00 |       26
     29       5.709442e+05      -4.859388e+00 |       25
     30       5.709406e+05      -3.669746e+00 |       24
     31       5.709381e+05      -2.462849e+00 |       22
     32       5.709370e+05      -1.130152e+00 |       20
     33       5.709364e+05      -5.939085e-01 |       18
     34       5.709357e+05      -6.655959e-01 |       16
     35       5.709351e+05      -6.409123e-01 |       19
     36       5.709339e+05      -1.153825e+00 |       16
     37       5.709330e+05      -9.545862e-01 |       14
     38       5.709322e+05      -7.096709e-01 |       13
     39       5.709315e+05      -6.987856e-01 |       16
     40       5.709308e+05      -7.064140e-01 |       10
     41       5.709303e+05      -5.095196e-01 |        7
     42       5.709298e+05      -5.490767e-01 |       11
     43       5.709286e+05      -1.149375e+00 |       15
     44       5.709275e+05      -1.122003e+00 |       12
     45       5.709270e+05      -4.772832e-01 |        9
     46       5.709265e+05      -5.196409e-01 |       12
     47       5.709259e+05      -6.260158e-01 |       13
     48       5.709254e+05      -5.066650e-01 |       12
     49       5.709250e+05      -4.216238e-01 |       10
     50       5.709247e+05      -2.492244e-01 |        5
K-means terminated without convergence after 50 iterations (objv = 570924.7064253828)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.302875
[ Info: iteration 2, average log likelihood -1.272336
[ Info: iteration 3, average log likelihood -1.236674
[ Info: iteration 4, average log likelihood -1.197612
[ Info: iteration 5, average log likelihood -1.159771
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.101595
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│      7
│      8
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.049848
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.093906
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     19
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.045314
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     10
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.070570
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.068940
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      8
│     17
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.030164
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     16
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.059988
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     10
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.046710
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.048995
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.032013
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      7
│      8
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.023747
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      9
│     10
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.044453
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.079886
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.037269
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.022270
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│     10
│     19
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.020221
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.083069
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     17
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.033515
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     10
│     18
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.024646
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.066731
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.052271
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     19
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.019555
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      8
│     10
│     18
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.025891
[ Info: iteration 30, average log likelihood -1.096531
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      7
│      9
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.035674
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.034005
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     10
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.027202
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.063802
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.030070
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     19
│     21
│     23
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.007601
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     10
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.053559
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.065709
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.035639
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     21
│     23
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -0.994918
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     10
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.055250
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.056475
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.033673
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     19
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.040710
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.047056
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.042874
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.017273
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      6
│     19
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.041983
[ Info: iteration 49, average log likelihood -1.076889
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.023940
┌ Info: EM with 100000 data points 50 iterations avll -1.023940
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0210707  -0.0975675    0.220715     -0.103838    0.024389    -0.0216818  -0.101316    -0.035027     -0.12886     -0.0248416   -0.110246     -0.222701     0.114946     -0.192558    0.0833915   -0.117061     -0.0159233   -0.105256     0.283983    -0.0527646    -0.186351    -0.0264277    0.0515449    -0.105394     0.06064      0.11962
  0.0195883   0.0310754    0.0737157    -0.014391   -0.0562837    0.0341079   0.00597048   0.0440128    -0.109963     0.0352899    0.22786      -0.0601262   -0.129571     -0.0746638  -0.0800673   -0.0406854    -0.0195473   -0.0536699   -0.118399     0.000393077   0.037719     0.316932     0.0780526    -0.248588    -0.0852107   -0.0286493
 -0.208516    0.11605      0.0359307    -0.065233   -0.0212628    0.131057    0.126638     0.100032     -0.100943    -0.047321     0.0421836    -0.0828421   -0.076292     -0.0697411  -0.034315    -0.0811841     0.0239894   -0.119182     0.080039    -0.0715176     0.207309     0.230872     0.0284864    -0.00104076  -0.113266    -0.119762
  0.116199   -0.109422    -0.0053938    -0.141042    0.190033     0.0622912   0.00797813  -0.00435687   -0.0234951   -0.00666389   0.028759     -0.0880125    0.0184423    -0.0909548  -0.0409238   -0.079089      0.0936777   -0.24278      0.0848734    0.105029     -0.216228    -0.043009    -0.0991716     0.0689989   -0.106537     0.0922028
 -0.0754638  -0.176737    -0.102838      0.046933   -0.12821      0.0512397  -0.146403     0.0114208     0.0705523   -0.0169714    0.058276     -0.0464454   -0.000530515   0.135561   -0.0746793   -0.0347659    -0.204609     0.140957    -0.0365782   -0.0999075     0.031        0.0420272    0.0735099    -0.022825     0.261009     0.136683
  0.123952   -0.0408256   -0.0313196     0.019206   -0.00997349  -0.114157   -0.0941214    0.000763987   0.176774    -0.0594912    0.0850201    -0.102517    -0.0544967    -0.0304231   0.0916525   -0.0411826    -0.122247    -0.0256622    0.0236522    0.0441282     0.00889405  -0.19297     -0.030443     -0.0115387    0.0368676    0.0304866
  0.0512854  -0.0141438   -0.0111828    -0.0590156   0.265116    -0.110569    0.119477    -0.0987453     0.134198     0.0914264   -0.113675      0.133343     0.113368     -0.106492   -0.0186349    0.00329166   -0.0408351   -0.0570697    0.0102831    0.164556     -0.0281818    0.0493159    0.0220549     0.048215    -0.0267269   -0.0205862
  0.098716   -0.0830998    0.17404      -0.0563316  -0.00504363   0.113675   -0.0388143    0.0764538    -0.0794527   -0.0485078   -0.161822     -0.045322    -0.0901163    -0.0165081  -0.059827     0.0609321    -0.138236    -0.0900663    0.00310493   0.0110232    -0.00343288   0.200141     0.0367212     0.0100113   -0.0395383   -0.00743511
  0.0798844  -0.026954     0.0280901     0.0635589  -0.0389744   -0.0339248   0.165765     0.05486       0.0575203   -0.0451875    0.000178409  -0.00309951   0.0225889     0.0440466   0.0592211    0.160875      0.11346      0.171639     0.134776     0.0701622     0.0119601    0.177372     0.0639311    -0.113512    -0.0973774    0.00475431
 -0.0838144   0.0648915   -6.57533e-5   -0.13946     0.139297     0.0170719   0.136061     0.212694      0.00630353  -0.0916019   -0.138358     -0.0555117    0.132955     -0.088269   -0.164406    -0.103093     -0.107048     0.102966     0.0568142   -0.0102469    -0.114749    -0.0707822    0.101677     -0.0650024   -0.138165     0.0688635
 -0.0150047   0.00550899   0.0351404     0.115415   -0.0648008    0.0684277  -0.0957415    0.0749867     0.101723     0.0312051   -0.165369     -0.101281    -0.120665      0.0822893  -0.158656    -0.0443159     0.0465079   -0.00028107   0.0337756   -0.0779681    -0.0442928    0.0642206    0.1114        0.00739179  -0.0344715    0.0450825
  0.105911    0.0643675   -0.0278216     0.0293721   0.109845     0.0915635   0.138539     0.0554952     0.0653302    0.185696    -0.036093      0.00700163   0.0877716    -0.151587   -0.040861     0.00977032    0.0321436    0.00341884   0.040686    -0.0658467     0.0774937    0.140042    -0.00201796    0.0621878   -0.126318    -0.109771
  0.0734365   0.237532    -0.116781      0.0582373  -0.07961     -0.138478   -0.05135      0.0120312    -0.0845048   -0.0571731   -0.0703739     0.0765551    0.0750122     0.107075    0.0443093    0.00351162   -0.0123896    0.0152128    0.102408     0.0596349    -0.0475752    0.041958    -0.36651      -0.00131963   0.0418051    0.0918566
  0.0107377   0.0440485    0.152229      0.0357703  -0.1909       0.0123078  -0.112196     0.0210592    -0.0417255    6.15297e-5   0.0621779     0.0935802    0.0683204    -0.137076   -0.0918227    0.000784187   0.400291    -0.134931     0.0398492   -0.062121     -0.266641     0.0898317   -0.0901395    -0.0644388   -0.0222557    0.0797503
  0.0378694  -0.0697565   -0.0696396     0.149378   -0.096121     0.163678   -0.023485    -0.0164822    -0.0032275   -0.11041     -0.0552039     0.0681993   -0.0723011     0.0115483   0.0195499    0.245536      0.00952426   0.0680757    0.0831999    0.160622      0.0825231    0.132007     0.109907     -0.0414073   -0.187622     0.182493
  0.0329487  -0.0311134   -0.0310572    -0.138515   -0.0736444    0.0512021   0.103213    -0.103596      0.118163    -0.130487     0.0188975    -0.137486    -0.0457365     0.0308311   0.0116483    0.0444613     0.00228395   0.282601     0.0483476   -0.0129397    -0.183391    -0.0189165   -0.0152479    -0.0211247   -0.0863043   -0.134146
 -0.0777966  -0.0982453    0.10382       0.213766    0.154024     0.0646504  -0.00632166   0.018461     -0.083741     0.153253     0.0335197     0.0686675   -0.101816     -0.117698   -0.0819787   -0.00651853    0.0665524    0.0300478    0.240037    -0.0764376     0.0634873   -0.0338992    0.0653047    -0.0186218   -0.00446984   0.12186
 -0.0422736   0.0655562   -0.0544976    -0.0188733  -0.0714684    0.0140047  -0.00334751   0.0831919    -0.0371766    0.161693    -0.00542358   -0.0502687   -0.213788     -0.0671809  -0.120421    -0.0684794     0.09741      0.0123638    0.0936466    0.0951946    -0.0172037   -0.0705045    0.00661154    0.0721302    0.119671    -0.0198441
  0.0289738  -0.0460587    0.16545       0.123182   -0.205569    -0.181956   -0.0354146   -0.0227526     0.00543524  -0.181584     0.111328      0.142248     0.0666356     0.0187609   0.00973184  -0.0528292     0.0167112   -0.107407     0.11568     -0.0347844    -0.0846007    0.0430101    0.309011      0.140812    -0.122841    -0.0456408
  0.0243624   0.0357404   -0.178273     -0.0536468  -0.033563     0.0556578   0.0230749    0.0850425     0.0360753   -0.0146515   -0.0215706     0.0602499   -0.0702026     0.0209701  -0.080323     0.235353     -0.122533    -0.0804999   -0.0351678   -0.164572     -0.126712    -0.0170938    0.01021       0.175777    -0.0335002    0.0527565
  0.0193302   0.0395854   -0.000647087  -0.101633   -0.016116     0.137032    0.0866379   -0.0122171    -0.213896     0.112745     0.107507     -0.0395272   -0.106837     -0.0972235   0.189025    -0.0360939    -0.107621    -0.158279    -0.152832    -0.0342377     0.10677     -0.00440733  -0.0839984    -0.185428    -0.0913429   -0.19332
 -0.0873503   0.0445918   -0.125385     -0.243605   -0.157376    -0.148419   -0.0468475    0.027559      0.118525     0.00804993  -0.0909541    -0.116653     0.227123      0.094518   -0.090162     0.0518956    -0.0303063    0.145313    -0.0112843   -0.033536     -0.0428685   -0.0316806   -0.145187     -0.141322     0.0596873    0.0659672
  0.112148    0.0891149    0.0406017    -0.0477373   0.149902    -0.0517693   0.0406143   -0.00773788    0.116969     0.0445521    0.0469353    -0.0408218    0.0571708    -0.116824    0.0303541    0.0219079    -0.0693235   -0.0914948    0.0729563    0.15765      -0.0442937   -0.0188146    0.0325205     0.138447     0.208681    -0.0350236
 -0.0595843  -0.0437595    0.0620047     0.0304382   0.166616    -0.0432759   0.12349     -0.231732     -0.0450451    0.0288987    0.148589     -0.0172003    0.0805879    -0.0631544  -0.0179846   -0.0123673    -0.0712923    0.0210355    0.0975267    0.0856938     0.0638312   -0.344292    -0.0580591    -0.0366328    0.152725     0.056639
  0.103815    0.0494879    0.103061      0.0475677  -0.213579     0.0482028   0.0378009    0.0480731    -0.0711903   -0.0735284    0.112248     -0.0295309   -0.232349     -0.150711   -0.164238     0.00462444   -0.998254    -0.132148     0.0757021   -0.104643     -0.0201262    0.00948194   0.0667849    -0.0566652   -0.14449      0.118901
 -0.0720659  -0.0149629   -0.0656503     0.0395871  -0.0103849   -0.0630827  -0.101513    -0.050851     -0.0667983    0.091458     0.0970656    -0.0544557   -0.0282947    -0.0243671   0.0496784   -0.153323     -0.0669271   -0.0542829   -0.0603562    0.132793      0.101194     0.190895    -0.000855278  -0.0839833    0.0225674    0.0437471
  0.0940012   0.0219089    0.110339     -0.0426353   0.158895     0.164968   -0.0460101    0.0500016     0.0910187   -0.109054     0.0678724    -0.0191364    0.0257077     0.133669   -0.0333606    0.0189188     0.116392    -0.00785934  -0.0371249   -0.097221      0.221674     0.041492     0.0847436     0.0750867    0.00106891  -0.114263
  0.256722    0.158279    -0.126906     -0.0527673  -0.0398286    0.0536057   0.0394325   -0.143425      0.0243155    0.0126791   -0.0406407     0.102252    -0.0538378    -0.0619636   0.0645282    0.0743307    -0.0479481   -0.00314254  -0.0672314   -0.155492     -0.0180988   -0.0471746    0.100679      0.112521    -0.0735929    0.102667
 -0.123313    0.0451906   -0.0998581    -0.0872819   0.155773    -0.0623888   0.0437808   -0.184689      0.0138181   -0.0945253   -0.00963349    0.0861073   -0.0178676     0.0699159  -0.106408    -0.0705905    -0.0782623    0.154566     0.09419      0.0599012     0.0472459    0.239235     0.0516409     0.0553792    0.0776165    0.112782
 -0.0722052  -0.0528307   -0.0776881     0.117511   -0.010651     0.0999703  -0.15838     -0.0852484     0.0602004    0.118305     0.0316564    -0.0374855    0.0461828     0.0625872   0.0341623   -0.0965525     0.0166851    0.00572702   0.0128043    0.214223      0.186963    -0.0987758   -0.176447      0.0128342   -0.0435328    0.041789
 -0.0472062   0.177013     0.00676377   -0.0195667   0.0878638   -0.0491747  -0.0949982   -0.05989       0.219298    -0.00247098   0.0629435    -0.106503     0.0614096    -0.0753628  -0.279709     0.189875      0.106659    -0.043603     0.0101172   -0.0160446    -0.0702548   -0.0872261    0.253947     -0.0201491    0.10584      0.1362
  0.197331    0.0267711    0.0961081     0.0716251  -0.0915547   -0.0889712   0.0639977    0.0674883    -0.0379771   -0.0215103    0.0651847    -0.0659228    0.110609     -0.0339165   0.0954568    0.00581895   -0.0802444   -0.0907321   -0.0975522    0.180138     -0.0827654   -0.048229     0.00511345    0.081491     0.114887     0.0508512[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      8
│     10
│     17
│      ⋮
│     21
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.000971
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      6
│      8
│     10
│      ⋮
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.967757
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      8
│      9
│     10
│      ⋮
│     21
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.984169
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      6
│      7
│      8
│      ⋮
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.971560
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      8
│     10
│     17
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.972275
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      6
│      8
│      9
│      ⋮
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.976820
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      8
│     10
│     17
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.981205
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      6
│      8
│     10
│      ⋮
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.977248
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│      7
│      8
│      9
│      ⋮
│     21
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.965282
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      6
│      8
│     10
│      ⋮
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.976457
┌ Info: EM with 100000 data points 10 iterations avll -0.976457
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0732367   -0.0101913   -0.00406797  -0.107067    -0.114536     0.0782095   -0.220251    -0.0258435    0.0143471    0.0386998    0.0298465    0.0898201     0.119386    -0.0265388   -0.111634    -0.139147     -0.100446     0.208661    -0.16592      0.0557096  -0.0393864    -0.0654372    0.0433507     0.0235047   -0.0213531   -0.307072
  0.110321     0.111916     0.208458    -0.0300162    4.12275e-5   0.0600632    0.156944    -0.14077      0.0388968    0.0770963   -0.0234918   -0.131424     -0.029894     0.161211    -0.00898292   0.082496      0.0602586   -0.0126804   -0.0800092   -0.0875724  -0.0039672     0.179154    -0.0548682     0.0324022    0.238607     0.0281759
  0.215166    -0.0489568    0.00515082  -0.0420085   -0.242217     0.0084634   -0.0192823    0.065038     0.0779463   -0.13031      0.1011      -0.057772     -0.0507089    0.21384      0.167603    -0.0903524    -0.181322     0.170414     0.101942     0.0880396   0.0258066    -0.0881985   -0.0133471     0.149705     0.12296      0.0785408
 -0.034993     0.134593    -0.00102077   0.0783106    0.0931768   -0.0705574   -0.0288342   -0.0059392    0.165811     0.0361545    0.159744     0.0756743    -0.0950887   -0.0836682    0.0262305    0.160534     -0.101692     0.180234    -0.0948193   -0.0316683  -0.165283     -0.10235      0.136888      0.114848    -0.0756274    0.151158
 -0.0314865   -0.102369     0.0126602    0.0329083    0.110671     0.0293353   -0.0296986   -0.0830984    0.0461978   -0.0435027   -0.0245787   -0.01457       0.161945     0.168354     0.0447027   -0.0890286    -0.111283     0.0167225    0.0585583   -0.0249389  -0.050925      0.209542     0.0704588     0.0178307   -0.0331476    0.0983097
  0.0309229    0.0994232   -0.0297402    0.0613783    0.0854683   -0.0359703    0.150787    -0.036564    -0.045473     0.126974    -0.0259591   -0.149542      0.0123418    0.027289     0.152851     0.0517813    -0.0907191   -0.0430506    0.108893     0.133992    0.00991835    0.0381684   -0.146628     -0.222514     0.0272637    0.169544
 -0.039554     0.00450024  -0.219798     0.0545636    0.0129149    0.0510239    0.0326689   -0.0193186    0.00726726   0.0640999   -0.211302    -0.161902      0.0653575    0.012608    -0.0192819   -0.186924      0.0167804   -0.0332013   -0.0818458    0.0181153   0.0602837     0.0314291   -0.0771519    -0.287189    -0.0159111   -0.14864
  0.0785777    0.0649411   -0.104036     0.116763    -0.00907678  -0.0582149   -0.132841    -0.14564     -0.00616872   0.0801898    0.00180575   0.0305844    -0.0878926   -0.107975    -0.0318956    0.0280835    -0.0426914    0.027881     0.0746742   -0.0993025  -0.0292496     0.194967     0.0112575    -0.107267    -0.117249    -0.0880206
  0.156139     0.05275     -0.0655318   -0.0664509    0.0338931    0.138337     0.0187076    0.0626024    0.0779511    0.0872201   -0.0561056   -0.0759717     0.00168044   0.0504816   -0.093512     0.161722      0.128408    -0.0686932    0.0355417   -0.0975706  -0.0581973     0.0701046   -0.000838087  -0.234152     0.100325     0.186848
  0.0884675    0.0654215   -0.0691243   -0.0128923   -0.19864      0.00303481   0.181533     0.161649    -0.024157     0.120658    -0.082472    -0.0186322    -0.0349567   -0.0752509    0.0255333   -0.00377907    0.0255727    0.137463    -0.0358772   -0.0708704   0.000759695  -0.0816662    0.0353208     0.157486     0.121981     0.0750654
 -0.0832327    0.0740896   -0.219274     0.12593     -0.00811907  -2.52855e-5  -0.0388803    0.051452    -0.0455276    0.187683     0.0156272    0.000689823   0.0667403    0.200727    -0.0286451   -0.0631117    -0.00265412   0.0648302   -0.0830227    0.0473242   0.0430292    -0.0959792   -0.0505635    -0.111246    -0.106195     0.0139856
 -0.00590264   0.0240816    0.0176552    0.0576636    0.252162    -0.0263017    0.0307033   -0.260254    -0.116784     0.0305216   -0.0599129    0.24          0.120142    -0.0858061   -0.0392331    0.12121       0.0444603   -0.0778413   -0.150849     0.180934    0.0177604     0.186815    -0.00431027    0.0480249   -0.0831701    0.162541
  0.278421    -0.0588739   -0.00091479  -0.263988     0.110389    -0.0660072    0.0361178    0.0461064    0.0103503    0.0406286   -0.00284528   0.138039     -0.0826397   -0.0493961   -0.0508027   -0.0209014     0.00145831  -0.0877767    0.116901    -0.0941462   0.0576402    -0.0203845   -0.0225185    -0.0937558   -0.0928133    0.0170628
 -0.0571529   -0.0673507    0.0466312    0.0340138    0.0610791    0.120913    -0.0552975    0.0433451    0.208752     0.0102916   -0.0367716    0.0656727    -0.0189328   -0.0193508    0.115287    -0.0748908     0.0359319   -0.0247954    0.0534606    0.0481073  -0.113931      0.141047     0.157746     -0.116504     0.28974     -0.0784235
 -0.0296703    0.0812269    0.135954    -0.0825897   -0.199982    -0.0230522   -0.0633749    0.0928246    0.106608     0.00855015  -0.0845708   -0.0701425    -0.073101     0.104843     0.0962138   -0.0165015     0.0422996   -0.0192114   -0.0364612   -0.103922    0.0704452     0.00668719   0.131923     -0.0566166   -0.214626    -0.0256963
 -0.146167    -0.146639     0.0255368   -0.104097     0.0683815   -0.0404404   -0.109306     0.0657695    0.0121105   -0.178892    -0.0126462    0.0407798     0.00581144   0.0485931   -0.152225     0.0577756    -0.00864636  -0.0347487    0.0443307   -0.0511561  -0.156633      0.151945     0.103874     -0.0752353    0.0243214    0.106465
  0.0157185    0.0121016    0.113163     0.206926     0.101493     0.012469     0.0114328   -0.0188362    0.0795566    0.0831802   -0.00108553  -0.139322      0.0348152    0.00811971  -0.0150937    0.0562653    -0.0997074    0.221162     0.0825782   -0.0257754  -0.149386      0.130262    -0.0467281     0.00277234  -0.121328     0.047144
  0.0328345   -0.00586973   0.0740917   -0.0583524   -0.0299939    0.17339      0.0986962   -0.0925035    0.0989838    0.119721    -0.0401344    0.0814554     0.2881      -0.0501042    0.040357     0.0306118    -0.0527784   -0.0776229   -0.0285563    0.0561217   0.0686559    -0.133203     0.0114863    -0.0122624    0.13308     -0.0608605
 -0.089791    -0.125134     0.0060319    0.0534013    0.126719    -0.106821     0.133593    -0.0230726   -0.00594833   0.0988671   -0.0455907    0.194528      0.0725744   -0.00496252  -0.0286721   -0.178505     -0.0353042    0.0614882   -0.0690784    0.0767782   0.115786     -0.0132679   -0.0812765    -0.0209615    0.0374531   -0.0662641
  0.181087     0.13211      0.00826702  -0.138621    -0.0583512    0.00542287   0.0176268   -0.15779      0.0667877    0.0158901    0.101611     0.0112919    -0.115447    -0.0773093   -0.0858746    0.0447991    -0.142049    -0.0336542    0.0675604    0.0603275   0.0105584     0.157206     0.0812226     0.00451459  -0.0371662   -0.0230706
 -0.0991312   -0.0115647    0.0245821   -0.0453004   -0.0667932   -0.0492823    0.0535049    0.0119882   -0.209804    -0.0561254   -0.0304869    0.0218697    -0.0715125   -0.0702455   -0.204977     0.119692     -0.00251527  -0.00273613   0.0354901    0.0339553   0.00452203   -0.158824    -0.0119607    -0.131216    -0.0743016   -0.0774769
 -0.188525    -6.89527e-5  -0.121684    -0.211657    -0.136339     0.016481    -0.0418495    0.00802943  -0.00376307   0.139937    -0.00909154  -0.107357     -0.0504235   -0.240017    -0.0703704   -0.036188      0.0190954    0.10946      0.0592962   -0.0143118  -0.146561      0.0766477    0.115073     -0.364269     0.0339192   -0.094222
 -0.0195706    0.0496902   -0.083808     0.0346645   -0.0867785   -0.00117177  -0.0317948    0.0345619   -0.045885     0.0760453    0.132818     0.0903337     0.0635105    0.077127    -0.0573684    0.238381      0.132894     0.0770239   -0.172909     0.0483198   0.0585223     0.0432139    0.123878      0.0458015    0.117457    -0.0684827
 -0.0215408   -0.0228977    0.066956    -0.132473    -0.0145162    0.126199     0.0833096   -0.00632743  -0.0968099   -0.0816004   -0.0187696    0.0248057     0.00165687  -0.0257575   -0.0404655    0.0941947    -0.121268    -0.00649796  -0.0660513   -0.103679   -0.0587822     0.115386    -0.0866449    -0.132061    -0.00848953   0.0377001
  0.0914095   -0.0211695    0.162708    -0.063846    -0.0421708    0.0625824   -0.00517048  -0.104299    -0.0120641    0.0700795    0.00892924  -0.0401544     0.128141    -0.0958502   -0.0190995    0.0213742    -0.0186907   -0.011414    -0.0328686    0.051676   -0.0197218     0.085361     0.0435838     0.0255759    0.146578    -0.0501797
 -0.0394578   -0.0388159   -0.0748748   -0.0935074    0.127809     0.022995    -0.181007    -0.113394     0.126898    -0.0769713   -0.104278    -0.0298549     0.109105     0.108403     0.205517     5.60962e-5    0.005802    -0.0621401    0.0626189   -0.153747    0.0566247     0.184708     0.0242374     0.0380452   -0.00674997   0.155915
  0.140744    -0.132878     0.226973     0.0418304   -0.0941174   -0.0639464   -0.00854201  -0.111123    -0.01041     -0.0660737    0.00512651   0.0938222     0.131198     0.0772478   -0.171805    -0.000428024   0.137382     0.031547     0.272823    -0.275811   -0.0702641     0.0408419    0.102812     -0.0645319   -0.0183782   -0.1064
 -0.0582694   -0.0210983   -0.0157756   -0.0289717   -0.218805     0.0366695    0.0167111    0.0131922    0.0235275   -0.100759     0.129719    -0.0831474     0.0294772    0.122771     0.128975    -0.0689822     0.0389241    0.0471214   -0.170852     0.177635    0.12031       0.00529542  -0.197535     -0.00603412  -0.142744    -0.000613401
 -0.168385     0.0200719   -0.155162    -0.00680982  -0.0786269   -0.0125033   -0.0816885   -0.0490365   -0.0272593    0.0322141    0.0513123   -0.0538155    -0.0931477   -0.107895    -0.0115725    0.150493      0.206979    -0.0511841   -0.187614     0.0216148  -0.0140627     0.0413056   -0.0653825    -0.0334137    0.0715015    0.0880674
  0.00741926  -0.132936    -0.0419704    0.00316369  -0.00510605   0.0209602    0.0282692   -0.233437    -0.216899     0.0767609   -0.0743681    0.086528      0.0363398   -0.118827     0.0488395   -0.0629735    -0.0830927    0.0763608   -0.1875       0.0604211  -0.0620098     0.0181901    0.0635915     0.0713592    0.226051     0.182147
  0.016912     0.161235    -0.0996846   -0.0131721    0.0331405   -0.00544013  -0.227247     0.0315524   -0.0558095    0.0160767    0.117762    -0.0425806     0.092016     0.00259745   0.167795    -0.0250295     0.139146    -0.0348406   -0.286033    -0.0437399  -0.128033     -0.0130818    0.0518518    -0.0916341    0.0155454    0.0249298
  0.0883944   -0.130423     0.0302422    0.0337319    0.101432    -0.0448162   -0.0652487    0.170215    -0.155808     0.0473814    0.0748182   -0.136292      0.0594604   -0.0994336    0.163229    -0.0232752    -0.233422     0.0294797    0.00790824  -0.102264   -0.17034       0.0568001   -0.034065      0.105498    -0.0223384    0.0823065kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4222184071363633
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422237
[ Info: iteration 2, average log likelihood -1.422187
[ Info: iteration 3, average log likelihood -1.422144
[ Info: iteration 4, average log likelihood -1.422086
[ Info: iteration 5, average log likelihood -1.422005
[ Info: iteration 6, average log likelihood -1.421892
[ Info: iteration 7, average log likelihood -1.421732
[ Info: iteration 8, average log likelihood -1.421491
[ Info: iteration 9, average log likelihood -1.421091
[ Info: iteration 10, average log likelihood -1.420413
[ Info: iteration 11, average log likelihood -1.419409
[ Info: iteration 12, average log likelihood -1.418294
[ Info: iteration 13, average log likelihood -1.417430
[ Info: iteration 14, average log likelihood -1.416942
[ Info: iteration 15, average log likelihood -1.416715
[ Info: iteration 16, average log likelihood -1.416618
[ Info: iteration 17, average log likelihood -1.416577
[ Info: iteration 18, average log likelihood -1.416559
[ Info: iteration 19, average log likelihood -1.416552
[ Info: iteration 20, average log likelihood -1.416548
[ Info: iteration 21, average log likelihood -1.416547
[ Info: iteration 22, average log likelihood -1.416546
[ Info: iteration 23, average log likelihood -1.416545
[ Info: iteration 24, average log likelihood -1.416545
[ Info: iteration 25, average log likelihood -1.416545
[ Info: iteration 26, average log likelihood -1.416544
[ Info: iteration 27, average log likelihood -1.416544
[ Info: iteration 28, average log likelihood -1.416544
[ Info: iteration 29, average log likelihood -1.416544
[ Info: iteration 30, average log likelihood -1.416544
[ Info: iteration 31, average log likelihood -1.416544
[ Info: iteration 32, average log likelihood -1.416543
[ Info: iteration 33, average log likelihood -1.416543
[ Info: iteration 34, average log likelihood -1.416543
[ Info: iteration 35, average log likelihood -1.416543
[ Info: iteration 36, average log likelihood -1.416543
[ Info: iteration 37, average log likelihood -1.416543
[ Info: iteration 38, average log likelihood -1.416543
[ Info: iteration 39, average log likelihood -1.416543
[ Info: iteration 40, average log likelihood -1.416543
[ Info: iteration 41, average log likelihood -1.416543
[ Info: iteration 42, average log likelihood -1.416543
[ Info: iteration 43, average log likelihood -1.416543
[ Info: iteration 44, average log likelihood -1.416543
[ Info: iteration 45, average log likelihood -1.416543
[ Info: iteration 46, average log likelihood -1.416543
[ Info: iteration 47, average log likelihood -1.416543
[ Info: iteration 48, average log likelihood -1.416543
[ Info: iteration 49, average log likelihood -1.416543
[ Info: iteration 50, average log likelihood -1.416543
┌ Info: EM with 100000 data points 50 iterations avll -1.416543
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4222369694413621
│     -1.4221867567208977
│      ⋮
└     -1.4165425424625788
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416557
[ Info: iteration 2, average log likelihood -1.416483
[ Info: iteration 3, average log likelihood -1.416416
[ Info: iteration 4, average log likelihood -1.416335
[ Info: iteration 5, average log likelihood -1.416235
[ Info: iteration 6, average log likelihood -1.416121
[ Info: iteration 7, average log likelihood -1.416003
[ Info: iteration 8, average log likelihood -1.415895
[ Info: iteration 9, average log likelihood -1.415805
[ Info: iteration 10, average log likelihood -1.415735
[ Info: iteration 11, average log likelihood -1.415680
[ Info: iteration 12, average log likelihood -1.415639
[ Info: iteration 13, average log likelihood -1.415607
[ Info: iteration 14, average log likelihood -1.415582
[ Info: iteration 15, average log likelihood -1.415564
[ Info: iteration 16, average log likelihood -1.415549
[ Info: iteration 17, average log likelihood -1.415538
[ Info: iteration 18, average log likelihood -1.415528
[ Info: iteration 19, average log likelihood -1.415519
[ Info: iteration 20, average log likelihood -1.415511
[ Info: iteration 21, average log likelihood -1.415503
[ Info: iteration 22, average log likelihood -1.415496
[ Info: iteration 23, average log likelihood -1.415488
[ Info: iteration 24, average log likelihood -1.415481
[ Info: iteration 25, average log likelihood -1.415473
[ Info: iteration 26, average log likelihood -1.415465
[ Info: iteration 27, average log likelihood -1.415457
[ Info: iteration 28, average log likelihood -1.415448
[ Info: iteration 29, average log likelihood -1.415439
[ Info: iteration 30, average log likelihood -1.415430
[ Info: iteration 31, average log likelihood -1.415421
[ Info: iteration 32, average log likelihood -1.415412
[ Info: iteration 33, average log likelihood -1.415402
[ Info: iteration 34, average log likelihood -1.415393
[ Info: iteration 35, average log likelihood -1.415383
[ Info: iteration 36, average log likelihood -1.415373
[ Info: iteration 37, average log likelihood -1.415363
[ Info: iteration 38, average log likelihood -1.415353
[ Info: iteration 39, average log likelihood -1.415343
[ Info: iteration 40, average log likelihood -1.415334
[ Info: iteration 41, average log likelihood -1.415324
[ Info: iteration 42, average log likelihood -1.415315
[ Info: iteration 43, average log likelihood -1.415306
[ Info: iteration 44, average log likelihood -1.415297
[ Info: iteration 45, average log likelihood -1.415289
[ Info: iteration 46, average log likelihood -1.415281
[ Info: iteration 47, average log likelihood -1.415274
[ Info: iteration 48, average log likelihood -1.415266
[ Info: iteration 49, average log likelihood -1.415260
[ Info: iteration 50, average log likelihood -1.415253
┌ Info: EM with 100000 data points 50 iterations avll -1.415253
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4165566149283515
│     -1.416482831760554
│      ⋮
└     -1.4152532585888362
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415257
[ Info: iteration 2, average log likelihood -1.415198
[ Info: iteration 3, average log likelihood -1.415143
[ Info: iteration 4, average log likelihood -1.415076
[ Info: iteration 5, average log likelihood -1.414993
[ Info: iteration 6, average log likelihood -1.414889
[ Info: iteration 7, average log likelihood -1.414766
[ Info: iteration 8, average log likelihood -1.414632
[ Info: iteration 9, average log likelihood -1.414495
[ Info: iteration 10, average log likelihood -1.414365
[ Info: iteration 11, average log likelihood -1.414250
[ Info: iteration 12, average log likelihood -1.414152
[ Info: iteration 13, average log likelihood -1.414072
[ Info: iteration 14, average log likelihood -1.414008
[ Info: iteration 15, average log likelihood -1.413957
[ Info: iteration 16, average log likelihood -1.413917
[ Info: iteration 17, average log likelihood -1.413886
[ Info: iteration 18, average log likelihood -1.413860
[ Info: iteration 19, average log likelihood -1.413840
[ Info: iteration 20, average log likelihood -1.413822
[ Info: iteration 21, average log likelihood -1.413806
[ Info: iteration 22, average log likelihood -1.413792
[ Info: iteration 23, average log likelihood -1.413780
[ Info: iteration 24, average log likelihood -1.413768
[ Info: iteration 25, average log likelihood -1.413756
[ Info: iteration 26, average log likelihood -1.413746
[ Info: iteration 27, average log likelihood -1.413736
[ Info: iteration 28, average log likelihood -1.413726
[ Info: iteration 29, average log likelihood -1.413717
[ Info: iteration 30, average log likelihood -1.413708
[ Info: iteration 31, average log likelihood -1.413699
[ Info: iteration 32, average log likelihood -1.413691
[ Info: iteration 33, average log likelihood -1.413683
[ Info: iteration 34, average log likelihood -1.413676
[ Info: iteration 35, average log likelihood -1.413668
[ Info: iteration 36, average log likelihood -1.413661
[ Info: iteration 37, average log likelihood -1.413655
[ Info: iteration 38, average log likelihood -1.413648
[ Info: iteration 39, average log likelihood -1.413642
[ Info: iteration 40, average log likelihood -1.413637
[ Info: iteration 41, average log likelihood -1.413631
[ Info: iteration 42, average log likelihood -1.413626
[ Info: iteration 43, average log likelihood -1.413621
[ Info: iteration 44, average log likelihood -1.413616
[ Info: iteration 45, average log likelihood -1.413611
[ Info: iteration 46, average log likelihood -1.413607
[ Info: iteration 47, average log likelihood -1.413602
[ Info: iteration 48, average log likelihood -1.413598
[ Info: iteration 49, average log likelihood -1.413594
[ Info: iteration 50, average log likelihood -1.413590
┌ Info: EM with 100000 data points 50 iterations avll -1.413590
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4152567849228006
│     -1.4151981676415928
│      ⋮
└     -1.4135903381481854
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413598
[ Info: iteration 2, average log likelihood -1.413549
[ Info: iteration 3, average log likelihood -1.413505
[ Info: iteration 4, average log likelihood -1.413453
[ Info: iteration 5, average log likelihood -1.413389
[ Info: iteration 6, average log likelihood -1.413308
[ Info: iteration 7, average log likelihood -1.413208
[ Info: iteration 8, average log likelihood -1.413090
[ Info: iteration 9, average log likelihood -1.412957
[ Info: iteration 10, average log likelihood -1.412815
[ Info: iteration 11, average log likelihood -1.412673
[ Info: iteration 12, average log likelihood -1.412538
[ Info: iteration 13, average log likelihood -1.412414
[ Info: iteration 14, average log likelihood -1.412304
[ Info: iteration 15, average log likelihood -1.412208
[ Info: iteration 16, average log likelihood -1.412127
[ Info: iteration 17, average log likelihood -1.412057
[ Info: iteration 18, average log likelihood -1.411998
[ Info: iteration 19, average log likelihood -1.411947
[ Info: iteration 20, average log likelihood -1.411902
[ Info: iteration 21, average log likelihood -1.411863
[ Info: iteration 22, average log likelihood -1.411828
[ Info: iteration 23, average log likelihood -1.411796
[ Info: iteration 24, average log likelihood -1.411767
[ Info: iteration 25, average log likelihood -1.411740
[ Info: iteration 26, average log likelihood -1.411715
[ Info: iteration 27, average log likelihood -1.411691
[ Info: iteration 28, average log likelihood -1.411669
[ Info: iteration 29, average log likelihood -1.411648
[ Info: iteration 30, average log likelihood -1.411629
[ Info: iteration 31, average log likelihood -1.411610
[ Info: iteration 32, average log likelihood -1.411592
[ Info: iteration 33, average log likelihood -1.411575
[ Info: iteration 34, average log likelihood -1.411559
[ Info: iteration 35, average log likelihood -1.411544
[ Info: iteration 36, average log likelihood -1.411529
[ Info: iteration 37, average log likelihood -1.411514
[ Info: iteration 38, average log likelihood -1.411500
[ Info: iteration 39, average log likelihood -1.411487
[ Info: iteration 40, average log likelihood -1.411474
[ Info: iteration 41, average log likelihood -1.411461
[ Info: iteration 42, average log likelihood -1.411449
[ Info: iteration 43, average log likelihood -1.411437
[ Info: iteration 44, average log likelihood -1.411425
[ Info: iteration 45, average log likelihood -1.411414
[ Info: iteration 46, average log likelihood -1.411403
[ Info: iteration 47, average log likelihood -1.411392
[ Info: iteration 48, average log likelihood -1.411381
[ Info: iteration 49, average log likelihood -1.411371
[ Info: iteration 50, average log likelihood -1.411360
┌ Info: EM with 100000 data points 50 iterations avll -1.411360
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.413597981541743
│     -1.4135487684614618
│      ⋮
└     -1.4113601523663648
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411359
[ Info: iteration 2, average log likelihood -1.411283
[ Info: iteration 3, average log likelihood -1.411207
[ Info: iteration 4, average log likelihood -1.411115
[ Info: iteration 5, average log likelihood -1.410998
[ Info: iteration 6, average log likelihood -1.410851
[ Info: iteration 7, average log likelihood -1.410676
[ Info: iteration 8, average log likelihood -1.410483
[ Info: iteration 9, average log likelihood -1.410282
[ Info: iteration 10, average log likelihood -1.410084
[ Info: iteration 11, average log likelihood -1.409896
[ Info: iteration 12, average log likelihood -1.409722
[ Info: iteration 13, average log likelihood -1.409566
[ Info: iteration 14, average log likelihood -1.409428
[ Info: iteration 15, average log likelihood -1.409309
[ Info: iteration 16, average log likelihood -1.409207
[ Info: iteration 17, average log likelihood -1.409119
[ Info: iteration 18, average log likelihood -1.409043
[ Info: iteration 19, average log likelihood -1.408977
[ Info: iteration 20, average log likelihood -1.408918
[ Info: iteration 21, average log likelihood -1.408866
[ Info: iteration 22, average log likelihood -1.408818
[ Info: iteration 23, average log likelihood -1.408775
[ Info: iteration 24, average log likelihood -1.408735
[ Info: iteration 25, average log likelihood -1.408698
[ Info: iteration 26, average log likelihood -1.408664
[ Info: iteration 27, average log likelihood -1.408633
[ Info: iteration 28, average log likelihood -1.408603
[ Info: iteration 29, average log likelihood -1.408576
[ Info: iteration 30, average log likelihood -1.408549
[ Info: iteration 31, average log likelihood -1.408525
[ Info: iteration 32, average log likelihood -1.408501
[ Info: iteration 33, average log likelihood -1.408479
[ Info: iteration 34, average log likelihood -1.408458
[ Info: iteration 35, average log likelihood -1.408437
[ Info: iteration 36, average log likelihood -1.408418
[ Info: iteration 37, average log likelihood -1.408399
[ Info: iteration 38, average log likelihood -1.408381
[ Info: iteration 39, average log likelihood -1.408364
[ Info: iteration 40, average log likelihood -1.408347
[ Info: iteration 41, average log likelihood -1.408331
[ Info: iteration 42, average log likelihood -1.408316
[ Info: iteration 43, average log likelihood -1.408301
[ Info: iteration 44, average log likelihood -1.408287
[ Info: iteration 45, average log likelihood -1.408273
[ Info: iteration 46, average log likelihood -1.408259
[ Info: iteration 47, average log likelihood -1.408246
[ Info: iteration 48, average log likelihood -1.408233
[ Info: iteration 49, average log likelihood -1.408221
[ Info: iteration 50, average log likelihood -1.408209
┌ Info: EM with 100000 data points 50 iterations avll -1.408209
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4113588991937327
│     -1.4112827459272428
│      ⋮
└     -1.4082087272559807
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4222184071363633
│     -1.4222369694413621
│     -1.4221867567208977
│     -1.4221442330208731
│      ⋮
│     -1.4082331227283047
│     -1.4082207413117198
└     -1.4082087272559807
32×26 Array{Float64,2}:
 -0.189086     -0.290624    -0.196606    -0.0745014  -0.196649     0.390458    0.23868    -0.37474     0.652119     -0.0652533  -0.276978    -0.784061    0.575977    -0.114224   -0.507661   -0.849157    0.0516459   -0.0762094     0.221646   -0.0126248  -0.0309156   -0.323558   -0.799373     0.179688    -0.075388   -0.174955
 -0.244153     -0.316921    -0.18511      0.21874     0.147955     1.20782     0.205008   -0.130684    1.14256       1.11668     0.566297    -0.232035    1.00463     -0.64839     0.789765   -0.232226    0.119203     0.14902      -0.126585    0.296034    0.642389    -0.672146   -0.0950695    0.293423    -0.232806    0.296255
 -0.00570297   -0.357434     0.128849     0.626984   -0.509299     0.574916   -0.391823   -0.423299   -0.0688551     0.880186   -0.465253    -0.0365281   0.515262    -0.0884968   0.193179   -0.404947    0.165876     0.488199      0.17328     0.133612   -0.610516     0.807199   -0.481967    -0.352231    -0.0369104   0.502907
  0.177439      0.147791    -0.221808     0.479141   -0.490749     0.297878    0.500783   -0.177604   -0.374685      0.672832    0.287058     0.0297027   1.00581      0.243989    0.786221   -0.313798   -0.40011      0.147373     -0.150529   -0.538854   -0.0607285    0.0836543   0.104794     0.377602     0.230399    0.0631956
  0.0789698    -0.0355015    0.0210817    0.357949   -0.491531     0.731251   -0.203801   -0.0587959  -0.482647     -0.0451022  -0.322269    -0.161638    0.38252     -0.188767   -0.215112    0.24623     0.23043     -0.145881     -0.464239    0.107172    0.518205    -0.115928    0.167322     0.0565788    0.151158   -0.259948
 -0.0321802     0.115964    -0.663458     0.332871    0.0423482    0.186438    0.277036    0.229697   -0.267156      0.130487   -0.293901    -0.200278    0.12569     -0.222515   -0.766373    0.896225    0.83004     -0.442398      0.793046    0.453965    0.468284     0.108825    0.207427    -0.539046    -0.649482   -0.15992
  0.0236198    -0.00712169   0.180122    -0.61337    -0.255128     0.465242   -0.285223   -0.317105   -0.316327     -0.630572   -0.270205     0.0793509   0.143442     0.437616    0.536547   -0.733524   -0.636678     0.394339     -0.368915   -0.405712    0.00120428   0.0813224  -0.0289155    0.0513979    0.188111    0.193492
  0.000805447   0.345603     0.253235    -0.297946    0.121082     0.230344   -0.478437    0.6808     -0.233158     -0.207201   -0.897091     0.324307    0.721496    -0.0336479   0.421067   -0.0116957   0.0956855   -0.35168      -0.197354    0.980726   -0.0760697    0.149898    0.646172     0.179027     0.245897   -0.0290968
 -0.796387      0.16735     -0.214116    -0.619996   -0.019597    -0.19878     0.182244    0.133774    0.0778878     0.110539   -0.324336     0.534986   -0.192745    -0.158663    0.313605   -0.0859483   0.12662      0.607553     -0.321073    0.156994   -0.510203     0.0787834  -0.105094    -0.0998588   -0.599627    0.0179177
  0.0305089    -0.613415     0.113455    -0.315676   -0.0544596   -0.275654    0.313095    0.640587    0.824539      0.436281   -0.0377281    0.186121    0.00729556  -0.189997    0.345428    0.0690781   0.0479934   -0.0201813    -0.015446   -0.819767   -1.10173     -0.214459   -0.356293    -0.162073     0.357414    0.182877
 -0.110324      0.439982    -0.299643     0.016929    0.0225736   -0.226548    0.0420097  -0.25559    -0.0303368     0.448928    1.16043     -0.238962   -0.244796     0.501686    0.32911     0.118581    0.34946      0.14948       0.0126139  -0.276619    0.0742911   -0.18784    -0.110712    -0.238214    -0.265426    0.573544
 -0.0827957     0.11474     -0.195771    -0.237368    0.4764      -0.4211      0.155283    0.0932916  -0.000533506   0.471111    0.869684    -0.0131485   0.172044     0.329437    0.365562   -0.01892    -0.0893117   -0.134086      0.509971   -0.129296   -0.0400098    0.490028    0.199211    -0.198971    -0.0461328   0.120215
  0.264867      0.710694    -0.0730167   -0.330428   -0.162805    -0.715667   -0.0132459   0.170738   -0.906221     -0.407219   -0.526527    -0.0312136  -0.826714     0.33183    -0.397805    0.764554    0.149356     0.000171179  -0.0929002  -0.375526   -0.649014     0.712319    0.155239    -0.346565     0.522483    0.248878
  0.859451      0.194142     0.768437     0.167223   -0.391175    -0.113555   -0.120985   -0.232962    0.693119     -0.336891    0.270528    -0.671743    0.06483      0.34793    -0.364439    0.189393    0.174468    -0.578586      0.649358   -0.366268    0.339982    -0.107864    0.203401     0.168323     0.548013    0.224298
 -0.0424046    -0.226667     0.0835041    0.0392344   0.418662    -0.256912   -0.20301    -0.062684    0.268997     -0.175838   -0.026415     0.107549   -0.814961    -0.230153   -0.638406    0.240864   -0.0876354    0.278531     -0.121868    0.316889   -0.0698527   -0.240803   -0.171244    -0.170582    -0.101271    0.021116
  0.507681     -0.386815     0.116207     0.22362     0.290045    -0.296923   -0.390143   -0.272691    0.398284     -0.40329     0.0130095    0.0363538  -0.39624     -0.279435   -0.205488    0.0107529  -0.163784     0.484693     -0.102627   -0.311598   -0.314145    -0.190015    0.0113529    0.806886    -0.114047   -0.509635
 -0.237622     -0.16779      0.128168    -0.337884    0.474579    -0.179982   -0.304555    0.185361    0.28276      -0.328616    0.0755272   -0.329357   -0.646275    -0.260983   -0.860332    0.092819    0.244495    -0.0888964     0.0346114   0.201475   -0.17021     -0.231971   -0.205339    -0.31446     -0.0951245   0.0738997
 -0.677632     -0.402046    -0.106617    -0.132406   -0.013428     0.255032   -0.232185   -0.330999   -0.0505669    -0.325409   -0.375848     0.120145   -0.149163    -0.44636    -0.59527     0.0981291  -0.188599    -0.391769     -0.146083    0.667735    0.0194253    0.72845     0.00387973  -0.475697    -0.189381    0.249025
 -0.284507     -0.089387    -0.616933     0.0677182   0.181311     0.182702    0.526024    0.202397    0.278017      0.222468   -0.288538     0.299458   -0.167452    -0.43049    -0.381704    0.179824   -0.51232      0.154271     -0.302494    0.387324   -0.0847033   -0.699182    0.10369      0.0303275    0.349131   -0.230283
 -0.264196     -0.768326     0.495207     0.368698    0.191254     0.289037   -0.322147    0.119319    0.192839     -0.068013   -0.206997     0.162018    0.168014    -0.283583   -0.267703    0.113444   -0.534776     0.376686     -0.0300065   0.382538    0.0287081   -0.319206    0.178655    -0.0251264    0.513551   -0.0937313
  0.00333915    0.275045    -0.265094     0.273222   -0.177231     0.309994   -0.120871   -0.130394   -0.694158     -0.128119   -0.392653     0.125172    0.231401     0.275033    0.0515618  -0.109999    0.00181763   0.32758      -0.430162    0.414972    0.322408     0.0959846   0.143723     0.0674953   -0.0783027   0.0430905
  0.0683822     0.264636     0.54536     -0.248464    0.333619    -0.0656201  -0.337775    0.0263768  -0.551564     -0.0889154   0.609882     0.472575   -0.196683     0.277266   -0.0550772  -0.220372   -0.310208    -0.0571931    -0.293238   -0.0944548   0.385595     0.249681    0.191073     0.113129    -0.261138    0.241433
  0.141173     -0.411976     0.292856    -0.141844   -0.255112    -0.0147886   0.554403   -0.382949   -0.424685      0.29556    -0.07429      0.685305   -0.313302    -0.176687   -0.104982    0.0286351  -0.635946    -0.0618936    -0.34687    -0.590596   -0.169025     0.189798   -0.44439     -0.0918995    0.294352    0.322495
  0.13363      -0.196015    -0.0703542    0.217749   -0.660054     0.0853356   0.310525   -0.190427   -0.212086      0.355543   -0.365151    -0.152076   -0.121755    -0.31234    -0.357405    0.348452    0.513141    -0.0961406    -0.322381   -0.49523    -0.0487043    0.0818696  -0.561712     0.237755     0.366111   -0.138001
  0.127304      0.654876    -0.530208     0.181352    0.256646    -0.623071    0.304935   -0.0221341   0.24801      -0.247623    0.0176339   -0.430558   -0.167366     0.594365    0.157754   -0.0737536   0.0512545    0.105295     -0.247231    0.522148    0.162606    -0.227376    0.143073    -0.157028    -0.752378   -0.674106
  0.281687      0.499588    -0.168402    -0.27849    -0.46579     -0.244279   -0.0346802  -0.145781   -0.00107241   -0.0478615  -0.00619228  -0.2688      0.647652     0.240675    0.519504   -0.33996     0.787419    -0.373574      0.35379    -0.594361   -0.0314914    0.0983866  -0.426739     0.127097    -0.814149   -0.177821
  0.189026     -0.275542    -0.17207      0.0671831   0.428264    -0.16279     0.133217   -0.18556    -0.173549     -0.257403    0.323354    -0.387003    0.252262     0.401981    0.0319316  -0.617467   -0.521047    -0.206695      0.446382    0.166172    0.183115     0.310007    0.4078       0.00320916   0.161447   -0.316547
  0.334627     -0.101249    -0.307087     0.192456   -0.00265069  -0.19065     0.327414   -0.504952    0.278532     -0.0373224  -0.0953689   -0.247909    0.284078     0.333451    0.619497    0.421005   -0.0650328    0.163525      0.608338   -0.141505   -0.108502     0.539605    0.388274    -0.110622     0.430016    0.128433
 -0.141988      0.286466    -0.0595602   -0.340995    0.136344    -0.087339   -0.468974    0.748405    0.368187      0.338204    0.186132    -0.147162    0.299725    -0.0199714   0.510374    0.160353    0.31085     -0.395345      0.366751    0.154236    0.0591021    0.22533     0.425717    -0.473176     0.0927124  -0.100371
  0.503818      0.306061     0.546371     0.122179    0.031686    -0.0754542  -0.0430464   0.335907   -0.199373      0.363782    0.164898     0.52013    -0.454713    -0.436771    0.104688    0.922728    0.266466    -0.105887      0.0247492   0.0492028   0.15281      0.0471751   0.44002     -0.507137     0.136972    0.120675
 -0.165619     -0.0624453   -0.00885901  -0.059182    0.218406    -0.211397    0.0726664  -0.0382362   0.0703101     0.116028    0.206423     0.120452   -0.201435    -0.0822079   0.010686    0.121932   -0.00532607   0.0843594     0.0208854  -0.0107505  -0.174584     0.0651949  -0.0757345   -0.234879    -0.0769221   0.10585
  0.135105      0.0505891    0.0494158   -0.131304   -0.258812     0.135005   -0.119832   -0.0610872   0.116252     -0.0323667  -0.111172    -0.107107    0.250115     0.0634137   0.087467   -0.137034    0.014517    -0.0105424    -0.0256955  -0.154655   -0.0824804   -0.0194495   0.035661     0.178654     0.0432065  -0.0144196[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408197
[ Info: iteration 2, average log likelihood -1.408186
[ Info: iteration 3, average log likelihood -1.408175
[ Info: iteration 4, average log likelihood -1.408164
[ Info: iteration 5, average log likelihood -1.408154
[ Info: iteration 6, average log likelihood -1.408144
[ Info: iteration 7, average log likelihood -1.408134
[ Info: iteration 8, average log likelihood -1.408124
[ Info: iteration 9, average log likelihood -1.408115
[ Info: iteration 10, average log likelihood -1.408106
┌ Info: EM with 100000 data points 10 iterations avll -1.408106
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.472772e+05
      1       7.054589e+05      -2.418183e+05 |       32
      2       6.903789e+05      -1.508001e+04 |       32
      3       6.847897e+05      -5.589176e+03 |       32
      4       6.820305e+05      -2.759262e+03 |       32
      5       6.803132e+05      -1.717273e+03 |       32
      6       6.791188e+05      -1.194424e+03 |       32
      7       6.781982e+05      -9.206094e+02 |       32
      8       6.774581e+05      -7.400685e+02 |       32
      9       6.767877e+05      -6.703714e+02 |       32
     10       6.761999e+05      -5.878007e+02 |       32
     11       6.756885e+05      -5.114422e+02 |       32
     12       6.752516e+05      -4.368653e+02 |       32
     13       6.748721e+05      -3.795500e+02 |       32
     14       6.745169e+05      -3.551391e+02 |       32
     15       6.741888e+05      -3.280848e+02 |       32
     16       6.738847e+05      -3.041603e+02 |       32
     17       6.736119e+05      -2.727872e+02 |       32
     18       6.733786e+05      -2.332795e+02 |       32
     19       6.731554e+05      -2.232110e+02 |       32
     20       6.729615e+05      -1.938957e+02 |       32
     21       6.727955e+05      -1.659868e+02 |       32
     22       6.726555e+05      -1.399832e+02 |       32
     23       6.725371e+05      -1.184706e+02 |       32
     24       6.724125e+05      -1.245406e+02 |       32
     25       6.722985e+05      -1.139833e+02 |       32
     26       6.722039e+05      -9.464276e+01 |       32
     27       6.721131e+05      -9.084350e+01 |       32
     28       6.720225e+05      -9.056412e+01 |       32
     29       6.719330e+05      -8.944796e+01 |       32
     30       6.718555e+05      -7.754567e+01 |       32
     31       6.717849e+05      -7.062748e+01 |       32
     32       6.717240e+05      -6.090069e+01 |       32
     33       6.716647e+05      -5.927117e+01 |       32
     34       6.716071e+05      -5.763323e+01 |       32
     35       6.715486e+05      -5.843779e+01 |       32
     36       6.714846e+05      -6.402278e+01 |       32
     37       6.714094e+05      -7.519492e+01 |       32
     38       6.713317e+05      -7.775119e+01 |       32
     39       6.712586e+05      -7.305288e+01 |       32
     40       6.711892e+05      -6.942586e+01 |       32
     41       6.711298e+05      -5.934679e+01 |       32
     42       6.710741e+05      -5.568594e+01 |       32
     43       6.710241e+05      -5.004766e+01 |       32
     44       6.709835e+05      -4.057854e+01 |       32
     45       6.709419e+05      -4.158546e+01 |       32
     46       6.708922e+05      -4.969508e+01 |       32
     47       6.708460e+05      -4.626130e+01 |       32
     48       6.708030e+05      -4.302352e+01 |       32
     49       6.707595e+05      -4.350702e+01 |       32
     50       6.707154e+05      -4.400332e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 670715.4477228812)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420211
[ Info: iteration 2, average log likelihood -1.415262
[ Info: iteration 3, average log likelihood -1.413909
[ Info: iteration 4, average log likelihood -1.412845
[ Info: iteration 5, average log likelihood -1.411679
[ Info: iteration 6, average log likelihood -1.410595
[ Info: iteration 7, average log likelihood -1.409870
[ Info: iteration 8, average log likelihood -1.409489
[ Info: iteration 9, average log likelihood -1.409293
[ Info: iteration 10, average log likelihood -1.409174
[ Info: iteration 11, average log likelihood -1.409089
[ Info: iteration 12, average log likelihood -1.409021
[ Info: iteration 13, average log likelihood -1.408962
[ Info: iteration 14, average log likelihood -1.408910
[ Info: iteration 15, average log likelihood -1.408861
[ Info: iteration 16, average log likelihood -1.408817
[ Info: iteration 17, average log likelihood -1.408774
[ Info: iteration 18, average log likelihood -1.408734
[ Info: iteration 19, average log likelihood -1.408696
[ Info: iteration 20, average log likelihood -1.408660
[ Info: iteration 21, average log likelihood -1.408626
[ Info: iteration 22, average log likelihood -1.408592
[ Info: iteration 23, average log likelihood -1.408561
[ Info: iteration 24, average log likelihood -1.408531
[ Info: iteration 25, average log likelihood -1.408502
[ Info: iteration 26, average log likelihood -1.408474
[ Info: iteration 27, average log likelihood -1.408448
[ Info: iteration 28, average log likelihood -1.408423
[ Info: iteration 29, average log likelihood -1.408400
[ Info: iteration 30, average log likelihood -1.408377
[ Info: iteration 31, average log likelihood -1.408356
[ Info: iteration 32, average log likelihood -1.408336
[ Info: iteration 33, average log likelihood -1.408317
[ Info: iteration 34, average log likelihood -1.408300
[ Info: iteration 35, average log likelihood -1.408283
[ Info: iteration 36, average log likelihood -1.408267
[ Info: iteration 37, average log likelihood -1.408253
[ Info: iteration 38, average log likelihood -1.408239
[ Info: iteration 39, average log likelihood -1.408226
[ Info: iteration 40, average log likelihood -1.408214
[ Info: iteration 41, average log likelihood -1.408203
[ Info: iteration 42, average log likelihood -1.408192
[ Info: iteration 43, average log likelihood -1.408182
[ Info: iteration 44, average log likelihood -1.408173
[ Info: iteration 45, average log likelihood -1.408164
[ Info: iteration 46, average log likelihood -1.408155
[ Info: iteration 47, average log likelihood -1.408148
[ Info: iteration 48, average log likelihood -1.408140
[ Info: iteration 49, average log likelihood -1.408133
[ Info: iteration 50, average log likelihood -1.408126
┌ Info: EM with 100000 data points 50 iterations avll -1.408126
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.367001   -0.580315    -0.0628333  -0.166924    0.484946   -0.353495   -0.0342527  -0.175356    0.383255   -0.301514   -0.0564015   -0.0176778  -0.832949   -0.326311    -0.951381    0.120876     0.13854      0.0984401   0.0469521     0.169406   -0.337595   -0.0558097    -0.423101   -0.105918    -0.163416     -0.0135704
  0.0952996   0.118521    -0.11008     0.0443006   0.146143   -0.220241    0.0521935  -0.0509293  -0.190167    0.0812596   0.19812     -0.0574256  -0.31586     0.153258    -0.0853941   0.200529    -0.051465     0.120624   -0.0130951    -0.10834    -0.096983    0.207994      0.0423982  -0.2049       0.0800422     0.127071
  0.411468    0.295411     0.490145    0.0849611  -0.526811    0.561484   -0.450753   -0.453465   -0.0535363  -0.351782   -0.202389    -0.0194125   0.80731     0.0458606    0.887058   -0.146724    -0.406982     0.0481679  -0.543171     -0.857672   -0.0276655  -0.0730658     1.15083    -0.024168    -0.0133635    -0.361355
 -0.0541911  -0.172281     0.0982238   0.106557   -0.0762136  -0.0622926   0.110606   -0.0486329  -0.0803591   0.148869   -0.0719244    0.258968   -0.299107   -0.274673    -0.166151    0.427559     0.0383146    0.0621904  -0.102288     -0.0696297  -0.17298     0.0842508    -0.0464293  -0.216828     0.102736      0.115874
  0.0822021   0.134497     0.141624   -0.259188   -0.144067    0.0972733  -0.261112    0.0678511   0.165569   -0.0109277  -0.0649357   -0.0958881   0.142199    0.00266431   0.0486863  -0.164621     0.127962    -0.0495964   0.000866192  -0.0929339  -0.145384   -0.0306509    -0.0518704   0.05423     -0.00981205    0.0456835
 -0.370909    0.0865951   -0.353419   -0.44796     0.0289937   0.184291   -0.308389    0.184244   -0.0519132  -0.300204   -0.805537     0.0888622   0.439084    0.125868     0.0778043  -0.626029    -0.0216451    0.163292   -0.42307       0.675124   -0.171501    0.0145849     0.154286    0.403802    -0.406746     -0.553931
 -0.127648    0.350868    -0.28105     0.0348182  -0.213336    0.347539    0.206067    0.253461   -0.598271    0.535973    0.244388     0.144939    1.04179     0.387178     0.971639   -0.119577    -0.0492116   -0.14741     0.0782956    -0.234582   -0.0146726   0.198345      0.276472    0.205143     0.413846      0.559907
  0.239512    0.0218451    0.651747   -0.298608   -0.563551    0.495236   -0.233167   -0.499436   -0.600105   -0.757291   -0.388395     0.128565   -0.202563    0.262998    -0.0819911  -0.3346      -0.405423     0.24759    -0.208062     -0.176701    0.221342    0.224805     -0.463942    0.0315491    0.130864      0.311665
  0.218858    0.00823515  -0.14512     0.181031    0.805803   -0.262303   -0.0991295   0.347869    0.147622    0.0819942   0.419143    -0.0414887  -0.222786   -0.16764     -0.325626    0.00423532  -0.289929    -0.324017    0.200014      0.421772   -0.123171   -0.150861      0.278515   -0.129364     0.119813     -0.213312
  0.627173    0.378357     0.293452   -0.070639    0.243036   -0.146353   -0.0998305   0.236929   -0.667063   -0.101916   -0.170679     0.702717   -0.367195   -0.110067     0.514065    0.558625    -0.0532348   -0.024306    0.067755      0.335959    0.230364    0.453951      1.01702    -0.216941     0.160041     -0.217439
 -0.440371    0.0117869   -0.211066    0.0188817  -0.162684    0.286129    0.565888    0.338186   -0.127127    0.327049   -0.587454     0.703789   -0.15068    -0.353531    -0.116081   -0.0183289   -0.325891     0.226474   -0.807647      0.286255    0.0072439  -0.72953      -0.118679   -0.0271799    0.0745032    -0.054743
 -0.0647123  -0.424087    -0.0546175   0.188569   -0.0811715   1.13753     0.196696   -0.240475    0.626052    0.65451     0.221568    -0.526361    0.946505   -0.382927     0.0151736  -0.494072     0.142285    -0.0368781  -0.0162643     0.0513212   0.501689   -0.488925     -0.402809    0.229108    -0.153092     -0.122678
 -0.206506   -0.681472     0.846178   -0.151698    0.170601    0.257152   -0.298442    0.664028    0.92062     0.0665467  -0.270737     0.38154     0.310157   -0.0316216    0.303909   -0.297351    -0.573482    -0.107045    0.00959986   -0.0231798  -0.763386   -0.493075      0.186234   -0.00175762   0.966197      0.236499
 -0.198846   -0.707757     0.169779    0.503396    0.0986192   0.521698   -0.250637    0.100115   -0.178143   -0.0932786  -0.268074     0.0267724  -0.0126598  -0.325468    -0.603962    0.405678    -0.528152     0.566142   -0.0610128     0.35279     0.256601   -0.135361      0.416568   -0.0214838    0.766621     -0.0732632
 -0.659823    0.59839     -0.570669   -0.400566   -0.422639   -1.12873     0.625758   -0.185332    0.416399   -0.552703   -0.0401918    0.247089   -0.233385   -0.183161     0.509957    0.103985    -0.409506     0.344678   -0.0103824     0.632114   -0.475713    0.0602913     0.405478   -0.4358      -0.50398      -0.00655684
 -0.132384   -0.356794     0.0526422   0.659114   -0.68001     0.417242    0.0290974  -0.616742   -0.0752737   0.979908   -0.359903     0.247452    0.67579    -0.0416495    0.448879   -0.46644     -0.133476     0.863527    0.0313385    -0.0297816  -0.575451    0.604601     -0.550502   -0.176921    -0.0671671     0.311554
 -0.0223734   0.240255    -0.721981    0.361901    0.0719242   0.100577    0.314728    0.237387   -0.216541    0.123252   -0.318153    -0.227359    0.0555527  -0.128318    -0.708076    0.828632     0.811644    -0.357427    0.672084      0.501064    0.491444    0.0372077     0.200002   -0.52769     -0.747507     -0.298981
 -0.125605   -0.00811412  -0.163483   -0.345647    0.135613   -0.280102   -0.157649    0.664987    0.536174    0.581809    0.171777    -0.0105883   0.329277    0.0729054    0.768374    0.396074     0.30711     -0.185272    0.470512     -0.20423    -0.278475    0.377586      0.478651   -0.422216     0.123601     -0.0181172
  0.0831321  -0.0834258   -0.249986    0.14131     0.0460987  -0.0681177   0.359313   -0.345172   -0.279368   -0.036882    0.14199      0.0454696   0.262002    0.412275     0.302712   -0.194458    -0.301459     0.228343    0.0415889    -0.190089    0.131953    0.271016      0.185002    0.212864    -0.000704198  -0.0445343
  0.123926    0.429904    -0.246583    0.234174   -0.205154    0.298829   -0.367435   -0.0330079  -0.607411   -0.153411   -0.37132     -0.0946527   0.35502     0.314525     0.0180807  -0.138051    -0.00707624   0.141065   -0.481544      0.639402    0.380217    0.085763      0.333755    0.0323109   -0.0276607     0.00437145
  0.653813   -0.14551     -0.131514    0.497827   -0.21801    -0.0745865   0.291386   -0.52012     0.508678   -0.213982   -0.007416    -0.910273    0.472755    0.225633     0.230042   -0.144264     0.0108119   -0.340821    0.751009      0.0744151  -0.0871857   0.254922      0.0249723  -0.00342848   0.472987     -0.0403131
  0.310212   -0.181407     0.0130493   0.260073   -0.703194    0.238408    0.179697   -0.151892   -0.340491    0.313071   -0.332067    -0.310505    0.0462597  -0.174494    -0.456506    0.261588     0.344373    -0.280001   -0.345839     -0.577896    0.0432693   0.000417404  -0.401756    0.452215     0.424719     -0.171521
 -0.551628   -0.307518    -0.24896    -0.300568    0.120928    0.0298627  -0.0625339  -0.11833     0.496765   -0.331616   -0.200826    -0.494881    0.273985   -0.0948113   -0.200578   -0.547094    -0.205332     0.0718696   0.138207      0.26065    -0.102738   -0.104652     -0.156388   -0.0957643   -0.0400276    -0.313561
  0.267157    0.594044    -0.191847   -0.15921    -0.294284   -0.290847   -0.0460399  -0.142989   -0.126215    0.0206329   0.190357    -0.254808    0.385503    0.409961     0.422333   -0.331049     0.741654    -0.310538    0.143997     -0.505074    0.0807351   0.180364     -0.397769    0.136812    -1.00898      -0.142218
  0.352489    0.130116     0.697514   -0.772493    0.159638   -0.319441    0.145107   -0.147572   -0.349546    0.315731    0.780677     0.620296   -0.119083    0.0960408   -0.0843188  -0.350866    -0.790213    -0.406932   -0.204178     -0.288684    0.0959005   0.225712      0.158533    0.0568845    0.273474      0.39609
 -0.482668    0.142439     0.197006   -0.215131    0.720298    0.0116348  -0.552958    0.105604   -0.303451   -0.100251    0.436549     0.465181   -0.261809    0.313963     0.0283513  -0.0448238    0.0257029    0.361245   -0.216558      0.202745    0.183312    0.236973     -0.0292873  -0.249554    -0.643154      0.309448
  0.10796    -0.395087     0.0293347  -0.397853   -0.239983   -0.328655    0.477072    0.182166    0.457552    0.326232    0.00887836   0.174523   -0.241451   -0.353247     0.262284   -0.0521931   -0.0537717    0.107686   -0.0698995    -1.13463    -0.761512    0.0205167    -0.905972   -0.0563178    0.112573      0.123724
 -0.773996   -0.316727    -0.149421   -0.123523   -0.153901    0.52265    -0.0844532  -0.301113   -0.306521   -0.0694393  -0.351665     0.344137    0.04558    -0.367384    -0.30855     0.241959    -0.102611    -0.671537   -0.0520632     0.458735    0.153648    1.02974      -0.0225715  -0.520684    -0.206534      0.587605
 -0.280209    0.580677    -0.285744   -0.0966885  -0.109173   -0.168995    0.33191    -0.25423     0.243968    0.56812     0.776144    -0.235609   -0.268873    0.188251     0.238186    0.240875     0.279806     0.22597     0.130694     -0.140466    0.181152   -0.295206     -0.142934   -0.552509    -0.223782      0.325265
  0.547048   -0.151233    -0.127609    0.427751    0.303382   -0.43468    -0.249614   -0.244036    0.314755   -0.112056    0.298912     0.0890998  -0.491518    0.177744     0.202801   -0.0622559   -0.105082     0.927143   -0.392058     -0.205678   -0.27018    -0.479544     -0.12361     0.495409    -0.230229     -0.165092
  0.125942    0.247372     0.636084   -0.221763   -0.137341    0.0916985  -0.73649     0.547856    0.140843    0.0285002  -0.410461     0.0127557   0.0769018  -0.707981    -0.296       0.623652     0.912149    -0.523871   -0.287463      0.69675    -0.0807816  -0.0993429    -0.0436734  -0.555481     0.0701471     0.121088
  0.523354    0.303782     0.581524   -0.21896     0.0816723  -0.247059   -0.259958    0.0720725   0.435935   -0.388119    0.474619    -0.54101    -0.197345    0.331064    -0.455501    0.355838     0.238374    -0.489192    0.510296     -0.313953    0.500872   -0.22207       0.456489    0.176849     0.175377     -0.0533206[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408120
[ Info: iteration 2, average log likelihood -1.408113
[ Info: iteration 3, average log likelihood -1.408108
[ Info: iteration 4, average log likelihood -1.408102
[ Info: iteration 5, average log likelihood -1.408096
[ Info: iteration 6, average log likelihood -1.408091
[ Info: iteration 7, average log likelihood -1.408086
[ Info: iteration 8, average log likelihood -1.408081
[ Info: iteration 9, average log likelihood -1.408076
[ Info: iteration 10, average log likelihood -1.408072
┌ Info: EM with 100000 data points 10 iterations avll -1.408072
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
