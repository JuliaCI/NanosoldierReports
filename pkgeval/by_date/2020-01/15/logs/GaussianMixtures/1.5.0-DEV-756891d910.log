Julia Version 1.5.0-DEV.62
Commit 756891d910 (2020-01-14 06:58 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed DataAPI ──────────── v1.1.0
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Blosc ────────────── v0.5.1
 Installed Distances ────────── v0.8.2
 Installed SpecialFunctions ─── v0.9.0
 Installed HDF5 ─────────────── v0.12.5
 Installed BinaryProvider ───── v0.5.8
 Installed Missings ─────────── v0.4.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed SortingAlgorithms ── v0.3.1
 Installed URIParser ────────── v0.4.0
 Installed Parameters ───────── v0.12.0
 Installed QuadGK ───────────── v2.3.1
 Installed FileIO ───────────── v1.2.1
 Installed NearestNeighbors ─── v0.4.4
 Installed BinDeps ──────────── v1.0.0
 Installed PDMats ───────────── v0.9.10
 Installed OrderedCollections ─ v1.1.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed Compat ───────────── v2.2.0
 Installed Rmath ────────────── v0.6.0
 Installed StaticArrays ─────── v0.12.1
 Installed StatsFuns ────────── v0.9.3
 Installed Clustering ───────── v0.13.3
 Installed Arpack ───────────── v0.4.0
 Installed CMake ────────────── v1.1.2
 Installed FillArrays ───────── v0.8.4
 Installed StatsBase ────────── v0.32.0
 Installed LegacyStrings ────── v0.4.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed DataStructures ───── v0.17.8
 Installed CMakeWrapper ─────── v0.2.3
 Installed Distributions ────── v0.22.2
 Installed JLD ──────────────── v0.9.1
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.8
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.2
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_XlgXkT/Project.toml`
 [no changes]
  Updating `/tmp/jl_XlgXkT/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_zLl0Mi/Project.toml`
 [no changes]
  Updating `/tmp/jl_zLl0Mi/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_DJbFVI/Project.toml`
 [no changes]
  Updating `/tmp/jl_DJbFVI/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_L8vBft/Project.toml`
 [no changes]
  Updating `/tmp/jl_L8vBft/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_tehFsB/Project.toml`
 [no changes]
  Updating `/tmp/jl_tehFsB/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_tehFsB/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.2
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.151618052229928e6, [2.317270355543587e-20, 100000.0], [6.466739834358264e-20 -5.742159236290046e-20 3.9360444194165533e-20; -497.8813471928039 -131.09141715163878 442.8934194206507], [[1.8046545188901625e-19 -1.6024478871899978e-19 1.0984206055709256e-19; -1.6024478871899978e-19 1.4228979634793112e-19 -9.75345573678423e-20; 1.0984206055709256e-19 -9.753455736784229e-20 6.68564455740019e-20], [99970.24427034006 28.138537584775356 -340.2542262590466; 28.138537584775356 99784.64108758526 -158.59977754558264; -340.2542262590466 -158.59977754558264 100426.29214830033]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.047481e+03
      1       1.276850e+03      -7.706307e+02 |        7
      2       1.189063e+03      -8.778668e+01 |        5
      3       1.132249e+03      -5.681395e+01 |        2
      4       1.127048e+03      -5.201614e+00 |        0
      5       1.127048e+03       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 1127.0477413861017)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.067061
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.636131
[ Info: iteration 2, lowerbound -3.465342
[ Info: iteration 3, lowerbound -3.309169
[ Info: iteration 4, lowerbound -3.167240
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.040573
[ Info: dropping number of Gaussions to 6
[ Info: iteration 6, lowerbound -2.930426
[ Info: iteration 7, lowerbound -2.848561
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.800505
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.761406
[ Info: iteration 10, lowerbound -2.740406
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.714883
[ Info: iteration 12, lowerbound -2.684657
[ Info: iteration 13, lowerbound -2.651967
[ Info: iteration 14, lowerbound -2.613794
[ Info: iteration 15, lowerbound -2.571672
[ Info: iteration 16, lowerbound -2.527930
[ Info: iteration 17, lowerbound -2.485149
[ Info: iteration 18, lowerbound -2.445291
[ Info: iteration 19, lowerbound -2.409008
[ Info: iteration 20, lowerbound -2.375887
[ Info: iteration 21, lowerbound -2.345957
[ Info: iteration 22, lowerbound -2.321854
[ Info: iteration 23, lowerbound -2.308739
[ Info: dropping number of Gaussions to 2
[ Info: iteration 24, lowerbound -2.303158
[ Info: iteration 25, lowerbound -2.299264
[ Info: iteration 26, lowerbound -2.299258
[ Info: iteration 27, lowerbound -2.299255
[ Info: iteration 28, lowerbound -2.299254
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan 16 03:20:14 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan 16 03:20:21 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Thu Jan 16 03:20:24 2020: EM with 272 data points 0 iterations avll -2.067061
5.8 data points per parameter
, Thu Jan 16 03:20:26 2020: GMM converted to Variational GMM
, Thu Jan 16 03:20:34 2020: iteration 1, lowerbound -3.636131
, Thu Jan 16 03:20:34 2020: iteration 2, lowerbound -3.465342
, Thu Jan 16 03:20:34 2020: iteration 3, lowerbound -3.309169
, Thu Jan 16 03:20:34 2020: iteration 4, lowerbound -3.167240
, Thu Jan 16 03:20:35 2020: dropping number of Gaussions to 7
, Thu Jan 16 03:20:35 2020: iteration 5, lowerbound -3.040573
, Thu Jan 16 03:20:35 2020: dropping number of Gaussions to 6
, Thu Jan 16 03:20:35 2020: iteration 6, lowerbound -2.930426
, Thu Jan 16 03:20:35 2020: iteration 7, lowerbound -2.848561
, Thu Jan 16 03:20:35 2020: dropping number of Gaussions to 5
, Thu Jan 16 03:20:35 2020: iteration 8, lowerbound -2.800505
, Thu Jan 16 03:20:35 2020: dropping number of Gaussions to 4
, Thu Jan 16 03:20:35 2020: iteration 9, lowerbound -2.761406
, Thu Jan 16 03:20:35 2020: iteration 10, lowerbound -2.740406
, Thu Jan 16 03:20:35 2020: dropping number of Gaussions to 3
, Thu Jan 16 03:20:35 2020: iteration 11, lowerbound -2.714883
, Thu Jan 16 03:20:35 2020: iteration 12, lowerbound -2.684657
, Thu Jan 16 03:20:35 2020: iteration 13, lowerbound -2.651967
, Thu Jan 16 03:20:35 2020: iteration 14, lowerbound -2.613794
, Thu Jan 16 03:20:35 2020: iteration 15, lowerbound -2.571672
, Thu Jan 16 03:20:35 2020: iteration 16, lowerbound -2.527930
, Thu Jan 16 03:20:35 2020: iteration 17, lowerbound -2.485149
, Thu Jan 16 03:20:35 2020: iteration 18, lowerbound -2.445291
, Thu Jan 16 03:20:35 2020: iteration 19, lowerbound -2.409008
, Thu Jan 16 03:20:35 2020: iteration 20, lowerbound -2.375887
, Thu Jan 16 03:20:35 2020: iteration 21, lowerbound -2.345957
, Thu Jan 16 03:20:35 2020: iteration 22, lowerbound -2.321854
, Thu Jan 16 03:20:35 2020: iteration 23, lowerbound -2.308739
, Thu Jan 16 03:20:35 2020: dropping number of Gaussions to 2
, Thu Jan 16 03:20:35 2020: iteration 24, lowerbound -2.303158
, Thu Jan 16 03:20:35 2020: iteration 25, lowerbound -2.299264
, Thu Jan 16 03:20:35 2020: iteration 26, lowerbound -2.299258
, Thu Jan 16 03:20:35 2020: iteration 27, lowerbound -2.299255
, Thu Jan 16 03:20:35 2020: iteration 28, lowerbound -2.299254
, Thu Jan 16 03:20:35 2020: iteration 29, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 30, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 31, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 32, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 33, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 34, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 35, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 36, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 37, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 38, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 39, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 40, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 41, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 42, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 43, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 44, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 45, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 46, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 47, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 48, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 49, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: iteration 50, lowerbound -2.299253
, Thu Jan 16 03:20:35 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222603554, 95.95490777396449]
β = [178.04509222603554, 95.95490777396449]
m = [4.250300733269734 79.28686694435922; 2.0002292577751892 53.85198717246036]
ν = [180.04509222603554, 97.95490777396449]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547482112 -0.007644049042329319; 0.0 0.0085817051663299], [0.37587636119514395 -0.008953123827349705; 0.0 0.012748664777410417]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000006
avll from stats: -0.9961692902595647
avll from llpg:  -0.9961692902595591
avll direct:     -0.9961692902595591
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9978110336352031
avll from llpg:  -0.9978110336352031
avll direct:     -0.9978110336352031
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0157058     0.0660324   0.067459      0.000533974  -0.0836934    0.0750197     0.194564    -0.0149555   0.0200871    0.0449196   -0.106717     0.0494188     0.17662     -0.190819      0.0463829    0.0441952    0.178406    0.075077     -0.10111     -0.142176    -0.138019     0.0366032    0.200887     -0.0453285   -0.015404     0.00562499
  0.135784      0.0133724  -0.187942      0.0259524    -0.0493602    0.012472     -0.100383     0.0391116   0.237534     0.0482241    0.188355     0.0412308     0.0246988   -0.122772     -0.0224133   -0.0386631   -0.061184   -0.0364869     0.0332129    0.0776466   -0.0232784   -0.0255347   -0.120862     -0.0215657    0.0230701    0.0541075
 -0.108848      0.0869222  -0.205266     -0.137995      0.0309126   -0.0896352     0.0914769    0.0589955  -0.00445451  -0.0814174   -0.00996372  -0.0507082     0.137866     0.0619185     0.128217    -0.0893253   -0.0749797   0.185373     -0.0952973    0.206183    -0.00515634  -0.075123    -0.0521987    -0.0706189    0.0851816    0.131184
 -0.054042     -0.0875974  -0.0727588     0.168574      0.164655     0.0394208     0.0221189    0.105592    0.170629     0.00845728  -0.15811     -0.0258195    -0.00863072   0.0773317    -0.174234    -0.0154498    0.0519821  -0.000974278   0.116576    -0.0691824   -0.0739166    0.0401161    0.124244     -0.071365    -0.152884    -0.00763239
 -0.0361814    -0.163666    0.0418789     0.0243273    -0.145163     0.111954      0.0956927    0.0468365   0.129665    -0.0185488    0.156906    -0.136202      0.00628093  -0.179992      0.0432      -0.0263794   -0.0382901   0.049502     -0.106436    -0.00791933  -0.0330307    0.110627     0.16563      -0.312011    -0.124407     0.00149574
 -0.0664309    -0.0714241  -0.140001      0.271675      0.0767069   -0.139538     -0.195753     0.119352   -0.0655893    0.0437899   -0.0418805   -0.0542145    -0.0154035    0.0500255    -0.146843    -0.00333188   0.0796525  -0.103501     -0.0349493    0.198972     0.154572     0.0267714    0.163771     -0.0396487   -0.092827    -0.0212562
 -0.084342     -0.121033    0.0863193     0.0445054    -0.0083849   -0.0204145    -0.0351123   -0.242278   -0.0333924    0.115264    -0.105648     0.0922951    -0.0521226   -0.00463338    0.0705758   -0.189812     0.101492    0.0445325    -0.0175303   -0.0893516    0.090918     0.109178    -0.107742      0.195067     0.059789    -0.0997835
 -0.0165481     0.0665641   0.16387      -0.0624034    -0.0295454   -0.120258     -0.00247757  -0.189756    0.100679     0.00295436  -0.147121    -0.212463      0.187151     0.147525     -0.0747745   -0.310213     0.067574    0.0087227     0.0400227   -0.0373758    0.0441842    0.0819484    0.130835      0.002685     0.0114938   -0.0400513
  0.0841121    -0.173619    0.0608052    -0.279196      0.0280787    0.0365127     0.211822     0.0837872  -0.0523433   -0.134026     0.0621454   -0.120354      0.181435     0.173433      0.155503     0.103017    -0.122784   -0.0753491     0.0592372   -0.0363821   -0.0420626   -0.0730108   -0.100122     -0.00969837   0.0268646    0.00996507
 -0.16725      -0.172507    0.0372323     0.0184001    -0.0738245    0.151524      0.015018     0.175013    0.0637931    0.0828725    0.00584862   0.00487041    0.0467189    0.202027      0.0172607   -0.153426     0.0453812   0.0540867    -0.177805     0.128253    -0.0210511    0.142038    -0.0265729    -0.0925157   -0.0986251    0.0294878
 -0.000577119   0.0765651   0.156307      0.0530261    -0.0422025   -0.000794507   0.0798652   -0.0313805  -0.135152     0.0146856   -0.0584272    0.0934613     0.0535261   -0.0588904     0.071088     0.00817047   0.015771    0.0921978     0.0603609   -0.0490055    0.113622    -0.0292875    0.0381025    -0.16302      0.126064    -0.0732436
  0.141105     -0.0766237   0.0673295    -0.00108043   -0.0258631    0.0610249     0.0501689   -0.0289519  -0.169786     0.118841     0.00826426  -0.000419408  -0.0692065   -0.0236222    -0.174556    -0.0867359    0.125664   -0.0593722    -0.0217663   -0.192469     0.119242     0.144702    -0.049869     -0.146643     0.0658384    0.137605
 -0.0216139    -0.114923    0.0566693     0.121663     -0.106957    -0.00573369    0.0878891    0.130309   -0.0422749   -0.0469063    0.0155937    0.027815      0.0314897   -0.264659      0.0520735   -0.0538891   -0.0819544   0.0235619     0.117595    -0.185343    -0.0585483    0.165401    -0.0162804     0.0288514   -0.00804056  -0.0809706
 -0.0106383     0.034277    0.0407436    -0.0172375     0.0129167   -0.0438661    -0.240364     0.0571293  -0.0170893    0.0103572   -0.0060917   -0.118806     -0.0489483   -0.0716222     0.00867276   0.0565921   -0.0923815   0.0866576    -0.0280185   -0.00597555  -0.0399188   -0.0201631   -0.00199245    0.0807144   -0.098579    -0.0691648
  0.0455877    -0.011646    0.000962157   0.0674431     0.00473936   0.0421336    -0.113174    -0.0594832   0.102052     0.102385     0.117178     0.0186466    -0.0316442    0.15964       0.0921342   -0.0923544    0.124545    0.195293     -0.0200442   -0.0249942   -0.0263805    0.0344172    0.000923418   0.137471     0.0627129   -0.0989631
 -0.145541     -0.145857    0.109175     -0.058262     -0.0995154    0.235064     -0.0634554    0.0491319   0.0941164    0.172239     0.0636085   -0.0747876    -0.0449129    0.118689      0.0756825    0.0130064   -0.0306736   0.190767      0.0557998   -0.0522849    0.157424    -0.00996619   0.0192129    -0.057217     0.142651     0.00957749
 -0.117965     -0.210948   -0.0105134    -0.0324621     0.0331287    0.101952     -0.0494057   -0.203244    0.0426194    0.0894904    0.0579318   -0.113558     -0.0643785    0.129462     -0.0204382    0.052962     0.0151216   0.0784107    -0.0269522   -0.0997585    0.052515    -0.0489251   -0.141934     -0.0175756   -0.0402136    0.0110875
  0.0232094     0.140181    0.062694     -0.0299349    -0.107396    -0.0879688     0.254192     0.0114147   0.0805632   -0.0740651    0.137945    -0.0984594     0.0284724   -0.140386     -0.0464986    0.00637282  -0.0161039  -0.146661     -0.0852218    0.177487    -0.00194178   0.0405159   -0.0209201     0.0211118   -0.0865613    0.000676727
  0.101155      0.117173    0.00136421   -0.113864     -0.00696408  -0.0816168     0.105019     0.0603454  -0.0988171    0.0700231    0.0402267    0.0878914     0.091621     0.000599706   0.00493289   0.0162747    0.0550287   0.0655024    -0.0111473   -0.0443992   -0.0356719   -0.0112006   -0.0962668     0.117882    -0.0346689    0.0625402
 -0.00405931   -0.0810277  -0.072127      0.127314     -0.121275    -0.100868      0.0444752    0.151383    0.00772979   0.0325921    0.16177     -0.0991294    -0.0287049   -0.0265429     0.215277     0.0329573    0.0631854   0.0237668     0.0245401    0.00418794  -0.0492998    0.053654     0.0499602     0.0290863    0.0126716   -0.0452025
 -0.0800704     0.0425408   0.0174513    -0.079917     -0.0695372   -0.031141      0.0243996   -0.142246    0.135648    -0.0034087    0.134665     0.0104913     0.0583772    0.0111589    -0.228793     0.0570866    0.0719008  -0.0380766    -0.00075511  -0.0445199    0.0739341    0.157907    -0.0658019    -0.255356     0.111732     0.0537487
 -0.177836     -0.0317825   0.0570826    -0.210929      0.0394576    0.121668      0.00443116   0.0795732   0.128435    -0.0377951   -0.0193137    0.130371     -0.00613297  -0.0229473    -0.0982613   -0.0274059    0.170472   -0.00721634   -0.0590472   -0.18739     -0.0626997   -0.0962693   -0.0870621     0.0191787   -0.12148     -0.11956
 -0.0927781     0.139347   -0.066956      0.0573208    -0.191452    -0.109101     -0.0408902   -0.0519995  -0.101681     0.0711708   -0.0121639    0.0266039     0.0637975    0.0287042     0.0643834   -0.0401391    0.0329305   0.138143     -0.0589771   -0.0141299   -0.178702     0.0874421    0.00279442   -0.15919      0.0156087    0.0624462
 -0.245436      0.0583673  -0.0180046    -0.179516      0.0913638   -0.173383      0.0889938   -0.0922244   0.0114281   -0.113083     0.348617     0.0369541     0.0195563   -0.128929     -0.187664    -0.00677805   0.0799975  -0.0935407     0.0141297    0.0728406   -0.163446    -0.0879469   -0.0909586    -0.143049    -0.0944289    0.0560722
  0.0962757     0.134178   -0.0325868     0.0221144    -0.0393228    0.171663     -0.101497    -0.132576   -0.0185177    0.0928851    0.00339974   0.0513262    -0.0109049   -0.0614922     0.291651     0.0460119   -0.0594496   0.109814      0.21602      0.124632    -0.0113974    0.179665    -0.00525168   -0.0672049   -0.00699293  -0.0115862
  0.0235212    -0.100322   -0.0507517     0.0336321    -0.0229823    0.0214889     0.105469    -0.126629    0.0199604   -0.0751552   -0.115541     0.0179464     0.0615714    0.0846066    -0.161982    -0.0103189   -0.106377    0.0120518     0.0941379    0.103627     0.0702754    0.111855    -0.214927      0.00298364   0.0156527   -0.0510093
  0.0532386     0.161278   -0.130042      0.0739812    -0.0411047    0.0685235    -0.0539341   -0.0788656   0.0426382    0.00317069   0.0724312    0.0611131     0.123744     0.140304      0.0798457    0.0142963    0.0534782  -0.0732184    -0.175844     0.00906931   0.0510467   -0.0785986   -0.105239      0.116873    -0.0302621    0.0151635
 -0.0570495    -0.0235686  -0.109401      0.0440732     0.0565675   -0.106708      0.237271    -0.0597909   0.0159246   -0.047984    -0.0514672   -0.00796474    0.0803169   -0.167062      0.101356     0.0742681    0.100662    0.0546176    -0.138603    -0.14059      0.121321     0.00580485   0.064225     -0.00391139   0.158334     0.111241
  0.0722624    -0.0774783   0.0102447    -0.0222896     0.195945     0.0720107    -0.00779051   0.110875   -0.12313      0.0270976   -0.167131    -0.00698757   -0.157849     0.0955336     0.197459    -0.169399     0.0110361   0.0266504     0.0321732   -0.0706779   -0.168513     0.167381     0.0392051    -0.224082     0.192232    -0.0420813
 -0.129745     -0.0256207  -0.139697     -0.0494006    -0.00388823  -0.0419595    -0.0607838   -0.0523025   0.0233841    0.00877675   0.168803     0.0456838     0.043652    -0.112475     -0.0359189    0.0280763   -0.0600618   0.0140529    -0.0236827   -0.00528491   0.0801283    0.0387391    0.0815773    -0.0205753   -0.0568655    0.0496011
  0.021906     -0.19715     0.0484742    -0.0323486    -0.0510615    0.21573       0.00488153  -0.0639483   0.0566994    0.0544935   -0.0282389    0.107261      0.0915762    0.0322399     0.0904584   -0.0287438    0.0786028   0.0607548     0.00373135   0.0768744    0.116003     0.051032    -0.127992     -0.101808    -0.0228675    0.0470973
  0.051543     -0.0257098   0.0439029     0.143949     -0.117384     0.0315013    -0.0327294   -0.242687    0.0143774    0.0410295    0.0402705   -0.0967235     0.0196984    0.108295      0.109645     0.00211444  -0.0723163   0.114757     -0.0605997   -0.123385    -0.0796995   -0.0414549   -0.0352695    -0.0892915   -0.0903575    0.0174637kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4140108575633061
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414158
[ Info: iteration 2, average log likelihood -1.414049
[ Info: iteration 3, average log likelihood -1.413697
[ Info: iteration 4, average log likelihood -1.409856
[ Info: iteration 5, average log likelihood -1.395739
[ Info: iteration 6, average log likelihood -1.384217
[ Info: iteration 7, average log likelihood -1.380844
[ Info: iteration 8, average log likelihood -1.379324
[ Info: iteration 9, average log likelihood -1.377866
[ Info: iteration 10, average log likelihood -1.376679
[ Info: iteration 11, average log likelihood -1.376079
[ Info: iteration 12, average log likelihood -1.375664
[ Info: iteration 13, average log likelihood -1.375311
[ Info: iteration 14, average log likelihood -1.374962
[ Info: iteration 15, average log likelihood -1.374592
[ Info: iteration 16, average log likelihood -1.374248
[ Info: iteration 17, average log likelihood -1.373990
[ Info: iteration 18, average log likelihood -1.373822
[ Info: iteration 19, average log likelihood -1.373724
[ Info: iteration 20, average log likelihood -1.373670
[ Info: iteration 21, average log likelihood -1.373640
[ Info: iteration 22, average log likelihood -1.373624
[ Info: iteration 23, average log likelihood -1.373615
[ Info: iteration 24, average log likelihood -1.373610
[ Info: iteration 25, average log likelihood -1.373608
[ Info: iteration 26, average log likelihood -1.373606
[ Info: iteration 27, average log likelihood -1.373605
[ Info: iteration 28, average log likelihood -1.373604
[ Info: iteration 29, average log likelihood -1.373604
[ Info: iteration 30, average log likelihood -1.373604
[ Info: iteration 31, average log likelihood -1.373603
[ Info: iteration 32, average log likelihood -1.373603
[ Info: iteration 33, average log likelihood -1.373603
[ Info: iteration 34, average log likelihood -1.373603
[ Info: iteration 35, average log likelihood -1.373603
[ Info: iteration 36, average log likelihood -1.373603
[ Info: iteration 37, average log likelihood -1.373603
[ Info: iteration 38, average log likelihood -1.373603
[ Info: iteration 39, average log likelihood -1.373603
[ Info: iteration 40, average log likelihood -1.373603
[ Info: iteration 41, average log likelihood -1.373603
[ Info: iteration 42, average log likelihood -1.373603
[ Info: iteration 43, average log likelihood -1.373603
[ Info: iteration 44, average log likelihood -1.373603
[ Info: iteration 45, average log likelihood -1.373603
[ Info: iteration 46, average log likelihood -1.373603
[ Info: iteration 47, average log likelihood -1.373603
[ Info: iteration 48, average log likelihood -1.373603
[ Info: iteration 49, average log likelihood -1.373603
[ Info: iteration 50, average log likelihood -1.373603
┌ Info: EM with 100000 data points 50 iterations avll -1.373603
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414158087921113
│     -1.4140486286067637
│      ⋮
└     -1.3736027767037098
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.373788
[ Info: iteration 2, average log likelihood -1.373641
[ Info: iteration 3, average log likelihood -1.373226
[ Info: iteration 4, average log likelihood -1.368427
[ Info: iteration 5, average log likelihood -1.350913
[ Info: iteration 6, average log likelihood -1.336017
[ Info: iteration 7, average log likelihood -1.331492
[ Info: iteration 8, average log likelihood -1.329913
[ Info: iteration 9, average log likelihood -1.329025
[ Info: iteration 10, average log likelihood -1.328363
[ Info: iteration 11, average log likelihood -1.327763
[ Info: iteration 12, average log likelihood -1.327125
[ Info: iteration 13, average log likelihood -1.326384
[ Info: iteration 14, average log likelihood -1.325463
[ Info: iteration 15, average log likelihood -1.324347
[ Info: iteration 16, average log likelihood -1.323081
[ Info: iteration 17, average log likelihood -1.321950
[ Info: iteration 18, average log likelihood -1.321065
[ Info: iteration 19, average log likelihood -1.320324
[ Info: iteration 20, average log likelihood -1.319713
[ Info: iteration 21, average log likelihood -1.319284
[ Info: iteration 22, average log likelihood -1.319025
[ Info: iteration 23, average log likelihood -1.318881
[ Info: iteration 24, average log likelihood -1.318800
[ Info: iteration 25, average log likelihood -1.318754
[ Info: iteration 26, average log likelihood -1.318727
[ Info: iteration 27, average log likelihood -1.318712
[ Info: iteration 28, average log likelihood -1.318703
[ Info: iteration 29, average log likelihood -1.318697
[ Info: iteration 30, average log likelihood -1.318694
[ Info: iteration 31, average log likelihood -1.318692
[ Info: iteration 32, average log likelihood -1.318691
[ Info: iteration 33, average log likelihood -1.318690
[ Info: iteration 34, average log likelihood -1.318689
[ Info: iteration 35, average log likelihood -1.318689
[ Info: iteration 36, average log likelihood -1.318689
[ Info: iteration 37, average log likelihood -1.318688
[ Info: iteration 38, average log likelihood -1.318688
[ Info: iteration 39, average log likelihood -1.318688
[ Info: iteration 40, average log likelihood -1.318688
[ Info: iteration 41, average log likelihood -1.318688
[ Info: iteration 42, average log likelihood -1.318688
[ Info: iteration 43, average log likelihood -1.318688
[ Info: iteration 44, average log likelihood -1.318688
[ Info: iteration 45, average log likelihood -1.318688
[ Info: iteration 46, average log likelihood -1.318688
[ Info: iteration 47, average log likelihood -1.318688
[ Info: iteration 48, average log likelihood -1.318688
[ Info: iteration 49, average log likelihood -1.318688
[ Info: iteration 50, average log likelihood -1.318688
┌ Info: EM with 100000 data points 50 iterations avll -1.318688
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3737876104086495
│     -1.373640936300354
│      ⋮
└     -1.318688122854269
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.318954
[ Info: iteration 2, average log likelihood -1.318724
[ Info: iteration 3, average log likelihood -1.318356
[ Info: iteration 4, average log likelihood -1.314805
[ Info: iteration 5, average log likelihood -1.300404
[ Info: iteration 6, average log likelihood -1.286160
[ Info: iteration 7, average log likelihood -1.279541
[ Info: iteration 8, average log likelihood -1.275253
[ Info: iteration 9, average log likelihood -1.272143
[ Info: iteration 10, average log likelihood -1.269957
[ Info: iteration 11, average log likelihood -1.268114
[ Info: iteration 12, average log likelihood -1.266270
[ Info: iteration 13, average log likelihood -1.264178
[ Info: iteration 14, average log likelihood -1.261867
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.259762
[ Info: iteration 16, average log likelihood -1.269426
[ Info: iteration 17, average log likelihood -1.265889
[ Info: iteration 18, average log likelihood -1.264313
[ Info: iteration 19, average log likelihood -1.263565
[ Info: iteration 20, average log likelihood -1.263193
[ Info: iteration 21, average log likelihood -1.262968
[ Info: iteration 22, average log likelihood -1.262795
[ Info: iteration 23, average log likelihood -1.262656
[ Info: iteration 24, average log likelihood -1.262546
[ Info: iteration 25, average log likelihood -1.262461
[ Info: iteration 26, average log likelihood -1.262397
[ Info: iteration 27, average log likelihood -1.262346
[ Info: iteration 28, average log likelihood -1.262305
[ Info: iteration 29, average log likelihood -1.262269
[ Info: iteration 30, average log likelihood -1.262238
[ Info: iteration 31, average log likelihood -1.262210
[ Info: iteration 32, average log likelihood -1.262185
[ Info: iteration 33, average log likelihood -1.262162
[ Info: iteration 34, average log likelihood -1.262141
[ Info: iteration 35, average log likelihood -1.262120
[ Info: iteration 36, average log likelihood -1.262100
[ Info: iteration 37, average log likelihood -1.262081
[ Info: iteration 38, average log likelihood -1.262060
[ Info: iteration 39, average log likelihood -1.262039
[ Info: iteration 40, average log likelihood -1.262014
[ Info: iteration 41, average log likelihood -1.261985
[ Info: iteration 42, average log likelihood -1.261947
[ Info: iteration 43, average log likelihood -1.261890
[ Info: iteration 44, average log likelihood -1.261793
[ Info: iteration 45, average log likelihood -1.261611
[ Info: iteration 46, average log likelihood -1.261235
[ Info: iteration 47, average log likelihood -1.260472
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.259135
[ Info: iteration 49, average log likelihood -1.267032
[ Info: iteration 50, average log likelihood -1.263363
┌ Info: EM with 100000 data points 50 iterations avll -1.263363
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3189539467936993
│     -1.3187240615218674
│      ⋮
└     -1.2633633476252613
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.262748
[ Info: iteration 2, average log likelihood -1.262127
[ Info: iteration 3, average log likelihood -1.261166
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.250879
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.216682
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.191951
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.174974
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.188445
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.179674
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.166469
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.171009
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.179186
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.170034
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.172915
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.169140
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.160284
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.180101
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.174204
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.163157
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.169455
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.178672
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.169868
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.172872
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.169119
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.160242
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.180069
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.174205
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.163144
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.169447
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.178649
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.169858
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.172871
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.169119
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.160225
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.180045
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.174209
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.163141
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.169446
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.178630
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.169850
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.172875
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.169125
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.160216
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.180026
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.174215
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.163144
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.169452
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.178618
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.169847
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.172883
┌ Info: EM with 100000 data points 50 iterations avll -1.172883
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2627479162643975
│     -1.2621270137204215
│      ⋮
└     -1.172882996744002
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.169333
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.158929
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.162022
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.143843
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.111963
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.086408
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.099263
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     15
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.087189
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     12
│     17
│     18
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.074743
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     23
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.082026
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     12
│     17
│     18
│     21
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.077144
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.095087
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     12
│     17
│     18
│     21
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.075687
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.094661
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.082241
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      9
│     10
│     12
│     15
│      ⋮
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.067095
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│     21
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.086866
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.090196
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     12
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.084257
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      9
│     10
│     11
│     15
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.072595
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     17
│     18
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.087043
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.091084
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     11
│     12
│     17
│     18
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.075639
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     23
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.084075
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     17
│     18
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.080977
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     23
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.075649
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     17
│     18
│     21
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.084175
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.093165
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     11
│     12
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.082714
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.076909
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     17
│     18
│     21
│     23
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.072020
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.088767
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.091056
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      9
│     10
│     12
│     15
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.074043
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.086333
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     23
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.081141
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.081046
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     23
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.085495
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.078474
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.079310
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.056455
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.094443
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.077636
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.072140
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.077704
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.088108
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│     21
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.068311
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.087683
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.071710
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.063532
┌ Info: EM with 100000 data points 50 iterations avll -1.063532
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1693332742972273
│     -1.1589286286155496
│      ⋮
└     -1.0635315889435208
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4140108575633061
│     -1.414158087921113
│     -1.4140486286067637
│     -1.4136965962061285
│      ⋮
│     -1.08768278085769
│     -1.0717100659388605
└     -1.0635315889435208
32×26 Array{Float64,2}:
  0.158108     -0.029685    -0.453374     0.00904186   0.173665      0.0651717    -0.018503     0.111078    -0.139578      0.0745757    -0.161952     -0.0381482    -0.327381     0.00151921   0.143763    -0.152767     0.0818981    0.0979868    -0.055249     0.187542    -0.157802      0.168431     0.0788712   -0.21134      0.183339     0.0119757
  0.0202264    -0.117514     0.406415    -0.0185599    0.199617      0.0924772     0.0283481    0.0975628   -0.132559      0.0122104    -0.166867      0.0296475     0.0555249    0.1717       0.207171    -0.199706    -0.0363723    0.0220709     0.0769706   -0.303579    -0.227863      0.167826    -0.0197025   -0.255504     0.204574    -0.0869019
 -0.0413397     0.0666048    0.0604331   -0.0339788   -0.0585645    -0.00934872    0.0496083   -0.0765282    0.0177242     0.00249285    0.0490765     0.0526444     0.0588351   -0.0102548   -0.0950698    0.0406648    0.0741639    0.00116209   -0.00540402  -0.0429563    0.0811428     0.095935    -0.0217888   -0.138136     0.1162      -0.0108982
  0.0539289     0.135728    -0.103113     0.0728357   -0.0273343     0.0653384    -0.0425774   -0.08323      0.0333308     0.0170296     0.0600163     0.0651823     0.124526     0.111635     0.077847     0.0028438    0.0550667   -0.0677968    -0.155605    -0.0622631    0.0466878    -0.11004     -0.117173     0.0257389   -0.0021607    0.000823741
 -0.0859937    -0.0794834   -0.0662184    0.150878     0.154881      0.0400479    -0.0212485    0.1265       0.167332     -0.012081     -0.151334     -0.0194659    -0.0100635    0.0559307   -0.17225      0.0253214   -0.0114983    0.000500385   0.100975    -0.048416    -0.0691913     0.0467193    0.130544    -0.0696057   -0.155603    -0.0634957
 -0.15251      -0.118494     0.109459    -0.0624598   -0.0936047     0.23727      -0.056376     0.0490861    0.0868709     0.16263       0.0649478    -0.0518825    -0.0440791    0.0747447    0.0824806    0.00650397  -0.0105948    0.190056      0.0157714   -0.059484     0.159599     -0.0136149    0.0324283   -0.00801413   0.1598       0.043744
 -0.038815      0.0176939    0.0272498    0.0161335   -0.0624896     0.143965      0.0307389    0.00782728   0.0118814     0.0929123    -0.0311342     0.0429379     0.0856616   -0.0110442    0.129449    -0.0210562    0.0429833    0.108127     -0.00569797   0.031583    -0.050874      0.129296     0.060902    -0.0578155   -0.036804     0.0107754
  0.0917968     0.00805543  -0.0382487   -0.0474551   -0.0228447    -0.0218211     0.107346    -0.0232876   -0.0375688    -0.00755922   -0.0366756     0.0579666     0.0804272    0.0433867   -0.0849723   -0.00343152  -0.033644     0.0408083     0.0165423    0.0189895    0.0063345     0.0520112   -0.161847     0.0550723   -0.00828485  -0.00995114
  0.114392     -0.0673153   -0.378482     0.0198733   -0.00195346    0.067866     -0.0916035    0.132198     0.307525      0.0826878     0.188806      0.0394006     0.0244198   -0.121796    -0.689811    -0.0221317   -0.0900256   -0.0510271     0.0166635    0.117335    -0.0863673    -0.0263894   -0.163129     0.0452776    0.0288222    0.0299446
  0.175601      0.0478488    0.0445959    0.0383932   -0.0951659    -0.0696652    -0.126016    -0.0647817    0.185623      0.0192643     0.188176      0.0458779     0.024321    -0.113023     0.597312    -0.0412031   -0.00244535  -0.0132052     0.117561     0.0765353    0.0115387    -0.0356259   -0.0941602   -0.0872114    0.0082684    0.0692941
 -0.0620029    -0.0364313   -0.125182     0.266201     0.0694129    -0.163818     -0.192554     0.117233    -0.110075      0.0646853    -0.0350544    -0.0472493     0.00410997   0.00128514  -0.138316    -0.00343231   0.0685653   -0.100011     -0.0543087    0.225737     0.151122      0.0190884    0.185444    -0.09162     -0.086938    -0.0135989
  0.00648027    0.131774     0.070605    -0.0108529   -0.0864787    -0.0717518     0.24185      0.0204952    0.0768337    -0.0843025     0.123534     -0.0916574     0.0285405   -0.138135    -0.0479366    0.0101681   -0.0105338   -0.159134     -0.0808197    0.182366    -0.000993893   0.0425763   -0.00243874   0.0378348   -0.0844476    0.00199327
  0.0708358    -0.242692     0.0994063   -0.278735    -1.4638        0.0541814     0.228801     0.109255    -0.00152382   -0.145312      0.0487883    -0.132094      0.116925     0.194311     0.200032     0.0843527   -0.0995706   -0.0711879     0.106763     0.0285835   -0.0669991    -0.0714123   -0.0762215   -0.0341158    0.0278731    0.016889
  0.106465     -0.112537     0.037956    -0.280343     1.47911       0.0625108     0.234096     0.0655137   -0.0420733    -0.129615      0.0652321    -0.120901      0.128666     0.120701     0.138584     0.102282    -0.103449    -0.0715879     0.0891861   -0.164939    -0.000835012  -0.0761832   -0.111658     5.36614e-5   0.0204242    0.0043809
 -0.196442      0.0113552   -0.0673558   -0.126237    -0.121691      0.0305062     0.0375209    0.0542966   -0.0427865    -0.245268     -0.0195975    -0.00417741    0.080345     0.0902214    0.137302    -0.0480114   -0.214699     0.204247      0.285001     0.211252    -0.0085742    -0.0659567   -0.0506432   -0.0654423    0.086574     0.105063
 -0.0687512     0.123712    -0.317316    -0.14399      0.374638     -0.225846      0.126699     0.0616442    0.0178025     0.0638487     0.00246532   -0.0836792     0.142576    -0.0016855    0.123756    -0.112915     0.0406402    0.103244     -0.436287     0.232699    -0.00540439   -0.0844448   -0.0552635   -0.0632606    0.0849035    0.153782
 -0.0536774    -0.0229877   -0.197687     0.0514398    0.0773598    -1.1669        0.470775    -0.106399     0.0272348    -0.0605793    -0.0414207    -0.00449648    0.0943327   -0.151085     0.138353     0.058232     0.156379     0.0551549    -0.148462    -0.126955     0.109307     -0.00740288   0.0530383   -0.00576149  -0.350376     0.101996
 -0.0565871    -0.0249201   -0.0228781    0.0946776    0.00433127    0.853223      0.0448667   -0.0194295    0.02712      -0.0524331    -0.0564633    -0.00590531    0.0765329   -0.155437     0.066956     0.05834     -0.00668769   0.0550531    -0.12945     -0.14364      0.112167      0.00309022   0.0574212   -0.0117741    0.66718      0.121468
 -0.333341     -3.46685e-5  -0.139671    -0.0421817    0.103312     -0.0514444    -0.04191     -0.0998418   -0.0359714     0.0269156     0.168949     -0.122379      0.0380064   -0.2693      -0.0367204   -0.145454    -0.062499     0.00513323   -0.00634463   0.0448748   -0.0303585     0.105603     0.078374    -0.0324898   -0.0550095    0.0489941
  0.297752     -0.0816526   -0.145017    -0.0444324   -0.384342     -0.0736627    -0.0394989   -0.00518742   0.153929      0.000448597   0.168004      0.362615      0.0319567    0.254907    -0.0353936    0.317039     0.0183215    0.035055     -0.0238963   -0.229199     0.200785     -0.0736402    0.10981     -0.0291343   -0.0555337    0.04912
  0.000362027  -0.114099     0.0484756    0.127474    -0.0940507    -0.0138719     0.0979645    0.160111    -0.0116059    -0.0444806     0.0183679     0.058238      0.0280507   -0.250856     0.0783857   -0.0824823   -0.0802269    0.023944      0.105548    -0.123387    -0.0569241     0.17714     -0.00418405   0.024112    -0.00111918  -0.081509
 -0.113173     -0.216775    -0.0249691   -0.0612462    0.029546      0.10815      -0.0626359   -0.190764     0.0235893     0.115769      0.0611616    -0.0638586    -0.0858674    0.129029    -0.0389607    0.0618466    0.0167675    0.0847078    -0.0162615   -0.0787071    0.051068     -0.0493799   -0.148571    -0.0278303   -0.0438626    0.00610347
 -0.0360749    -0.143085     0.0372004    0.0193269   -0.130259      0.0910152     0.15239      0.0393013    0.0878944    -0.0194686     0.125488     -0.0980135     0.0266965   -0.228722     0.0448167   -0.0373474   -0.0356466    0.0573038    -0.12133     -0.0114599   -0.00263706    0.10177      0.170255    -0.304054    -0.12844     -0.00573439
  0.0261773    -0.16387      0.0457297   -0.0414647   -0.0433361     0.265434      0.00844097  -0.0904013    0.0532507     0.0549428    -0.0334932     0.149732      0.102705     0.0462114    0.100571    -0.0202602    0.0956759    0.0506072     0.00503987   0.0991801    0.112587      0.050922    -0.119428    -0.0885222   -0.0155669    0.041595
 -0.231838      0.037719    -0.0179717   -0.168988     0.096479     -0.184636      0.0916264   -0.0910592    0.000782318  -0.105377      0.355228      0.047951      0.0635508   -0.11588     -0.190761    -0.00393439   0.0726095   -0.111902      0.0183687    0.0632388   -0.163115     -0.104566    -0.0898152   -0.137055    -0.0945698    0.0626917
 -0.00790385    0.0506074    0.0377818   -0.0379179    0.059746     -0.0614867    -0.222036     0.0509055   -0.0250638     0.0526612     0.00193575   -0.110153     -0.0728711   -0.0654442    0.00140176   0.0536304   -0.0852861    0.0869549    -0.00515434  -0.00879893  -0.0397633    -0.0205362   -0.00210086   0.0589585   -0.0840853   -0.0564493
 -0.0266124     0.073999     0.145309    -0.0601886   -0.0165682    -0.118407      0.00012432  -0.188871     0.120092      0.0749554    -0.147027     -0.198942      0.19726      0.144143    -0.0711027   -0.312079     0.0447539   -0.000673728   0.0400909   -0.0494785    0.0402309     0.0729072    0.132709     0.00151529  -0.0467729   -0.0384348
 -0.0842255    -0.122758     0.0472629    0.0479707   -0.00787648   -0.0203663    -0.0462796   -0.241137    -0.0467049     0.100928     -0.0857443     0.116598     -0.0479731   -0.014289     0.110373    -0.200842     0.0980755    0.0156686    -0.0198424   -0.0944413    0.0943624     0.139087    -0.108275     0.192115     0.0581698   -0.0886503
 -0.0178279     0.0511135   -0.00557744   0.0973236   -0.156643     -0.040272     -0.0363655   -0.187212     0.0148758     0.0493859     0.0226035    -0.0381115     0.0446139    0.0614656    0.0881402   -0.00893468  -0.0305942    0.115154     -0.0655077   -0.0683989   -0.108482      0.0232096   -0.00530712  -0.144766    -0.0267238    0.0345624
 -0.0167186    -0.0554263   -0.0600954    0.126557    -0.12693      -0.0835322     0.0363903    0.146302     0.0144661     0.0352898     0.243534     -0.0992124    -0.044903    -0.0247844    0.216657     0.0241602    0.0676221    0.0145606     0.0168317    0.00137575  -0.0453421     0.0557497    0.0584916    0.0300165    0.0406188   -0.0375012
 -0.0702709    -0.0212436    0.0342836   -0.0729122    0.0192495     0.0808508    -0.0380278   -0.00723941   0.0850558     0.025068      0.0385205     0.0775874    -0.0128433    0.0532282    0.00835392  -0.0496777    0.152652     0.101894     -0.0507646   -0.10203     -0.053733     -0.0273263   -0.052355     0.0708886   -0.0266787   -0.111492
  0.123125     -0.0368785    0.0490546    0.00934412   0.000824924   0.000865957   0.0488208   -0.0290296   -0.177991      0.130923     -0.000611521  -0.000936691  -0.0568861   -0.0248201   -0.19123     -0.0921555    0.133533    -0.0445072    -0.0260298   -0.198205     0.118407      0.143818    -0.0353521   -0.146639     0.0806952    0.137643[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.088116
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     21
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.065783
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│     21
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.065728
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     23
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.065712
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.081622
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.056589
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     11
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.081390
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     21
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.059530
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│     10
│     11
│     17
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.057234
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      9
│     11
│     15
│      ⋮
│     21
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.076747
┌ Info: EM with 100000 data points 10 iterations avll -1.076747
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.727109e+05
      1       6.794018e+05      -1.933091e+05 |       32
      2       6.450415e+05      -3.436034e+04 |       32
      3       6.280693e+05      -1.697223e+04 |       32
      4       6.188686e+05      -9.200612e+03 |       32
      5       6.126196e+05      -6.249071e+03 |       32
      6       6.087101e+05      -3.909492e+03 |       32
      7       6.060603e+05      -2.649828e+03 |       32
      8       6.043073e+05      -1.752945e+03 |       32
      9       6.034541e+05      -8.531968e+02 |       32
     10       6.030667e+05      -3.874481e+02 |       32
     11       6.028731e+05      -1.935546e+02 |       32
     12       6.027302e+05      -1.429016e+02 |       32
     13       6.026053e+05      -1.248745e+02 |       32
     14       6.024881e+05      -1.171881e+02 |       32
     15       6.023848e+05      -1.033300e+02 |       32
     16       6.023149e+05      -6.994865e+01 |       32
     17       6.022639e+05      -5.093043e+01 |       32
     18       6.022188e+05      -4.509861e+01 |       32
     19       6.021723e+05      -4.656831e+01 |       32
     20       6.021204e+05      -5.190848e+01 |       30
     21       6.020726e+05      -4.772244e+01 |       31
     22       6.020207e+05      -5.196511e+01 |       31
     23       6.019493e+05      -7.134313e+01 |       31
     24       6.018529e+05      -9.645933e+01 |       32
     25       6.017135e+05      -1.393464e+02 |       31
     26       6.015135e+05      -2.000310e+02 |       32
     27       6.012653e+05      -2.481813e+02 |       32
     28       6.009418e+05      -3.234831e+02 |       32
     29       6.005608e+05      -3.810380e+02 |       32
     30       6.001939e+05      -3.668480e+02 |       31
     31       6.000182e+05      -1.757620e+02 |       32
     32       5.999617e+05      -5.652935e+01 |       32
     33       5.999387e+05      -2.293423e+01 |       31
     34       5.999207e+05      -1.796781e+01 |       31
     35       5.999086e+05      -1.214535e+01 |       28
     36       5.998983e+05      -1.029370e+01 |       26
     37       5.998899e+05      -8.402273e+00 |       27
     38       5.998812e+05      -8.674825e+00 |       28
     39       5.998732e+05      -8.037947e+00 |       28
     40       5.998650e+05      -8.164481e+00 |       25
     41       5.998555e+05      -9.540670e+00 |       28
     42       5.998465e+05      -8.988855e+00 |       26
     43       5.998383e+05      -8.226742e+00 |       27
     44       5.998314e+05      -6.828914e+00 |       26
     45       5.998260e+05      -5.442123e+00 |       27
     46       5.998190e+05      -7.043006e+00 |       25
     47       5.998105e+05      -8.480826e+00 |       30
     48       5.997981e+05      -1.235642e+01 |       28
     49       5.997844e+05      -1.376319e+01 |       31
     50       5.997685e+05      -1.585961e+01 |       31
K-means terminated without convergence after 50 iterations (objv = 599768.499646573)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.317871
[ Info: iteration 2, average log likelihood -1.283340
[ Info: iteration 3, average log likelihood -1.249880
[ Info: iteration 4, average log likelihood -1.214417
[ Info: iteration 5, average log likelihood -1.170254
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.111666
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     11
│     16
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.085843
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      5
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.106271
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.104862
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.069630
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│     15
│     16
│     20
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.062181
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.097990
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      8
│     11
│     13
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.050904
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.091749
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      5
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.084484
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.084366
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     15
│     19
│     25
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.039833
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     11
│     13
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.084220
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.094670
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.081847
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     19
│     25
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.040414
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│     15
│     16
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.082622
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.099134
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.056938
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      9
│     19
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.032330
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      8
│     13
│     16
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.080841
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.128680
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.065600
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│      9
│     11
│     16
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.008444
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│      5
│     13
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.098681
[ Info: iteration 31, average log likelihood -1.131531
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.068862
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      8
│     16
│     19
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.024236
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      9
│     11
│     13
│     25
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.065817
[ Info: iteration 35, average log likelihood -1.134964
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.068417
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      8
│     16
│     19
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.042249
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.100674
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      9
│     11
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.056891
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.068501
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      8
│     16
│     19
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.056662
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.123983
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.066866
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      8
│      9
│     11
│      ⋮
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.022160
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│     16
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.102884
[ Info: iteration 46, average log likelihood -1.131541
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.070066
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      5
│      8
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.009812
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      9
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.136056
[ Info: iteration 50, average log likelihood -1.133441
┌ Info: EM with 100000 data points 50 iterations avll -1.133441
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0710154    -0.103035     0.193452    -0.110924     0.193942     0.0863815    0.0269836     0.100913    -0.150452    0.0402084   -0.178426     0.0405964   -0.0475933     0.129554     0.232825     -0.187059    -0.0233682   -0.0174965     0.0477962    -0.264628    -0.209597     0.167517    -0.0380861   -0.267259     0.203464    -0.0812048
 -0.235708     -0.0810088    0.0378798   -0.166845     0.0480308    0.143485     0.000993326   0.137393     0.134628   -0.150578    -0.0536978    0.0938682    0.0116261     0.0286721   -0.0954596    -0.0390933    0.120846    -0.000269291  -0.0813296    -0.138722    -0.0601351   -0.12461     -0.141533     0.0245619   -0.131459    -0.0902246
 -0.0269753     0.0724125    0.146643    -0.0595699   -0.0166708   -0.118471    -0.000278402  -0.189042     0.119414    0.0822243   -0.14532     -0.199202     0.195834      0.143077    -0.0698165    -0.312043     0.0445842   -0.00196044    0.0400944    -0.0498314    0.040605     0.0731711    0.13183      0.00257888  -0.0481164   -0.0383185
 -0.05989      -0.0538471   -0.139209     0.234609     0.0695121   -0.213214    -0.190556      0.156217    -0.135618    0.0610001   -0.0359329   -0.0423547   -0.000936965   0.0816201   -0.128084     -0.0115654    0.078561    -0.0941577    -0.0565245     0.254086     0.147239     0.0168263    0.20008     -0.105537    -0.0869663   -0.00929233
 -0.0023064     0.0656135    0.0346985   -0.0564369    0.0521271   -0.0794663   -0.182528      0.0659454   -0.0271756   0.0478064    0.0253679   -0.113573    -0.0484313    -0.0513181    0.000140594   0.0532744   -0.0584553    0.0819176    -0.000269676  -0.00264191  -0.0339677   -0.0193227   -0.00609191   0.0351874   -0.0700213   -0.0375502
 -0.119107     -0.106792     0.0190434    0.047999     0.0337075    0.133322    -0.0351039     0.0860388    0.129398    0.0801971   -0.0429606   -0.0367332   -0.0220803     0.0737809   -0.0442081     0.011629    -0.0107128    0.0919343     0.0506286    -0.0538809    0.0433102    0.0187574    0.0906018   -0.0417325   -0.00748095  -0.0140574
  0.077073     -0.153046     0.0499641   -0.275928     0.0286247    0.0483911    0.22296       0.0868923   -0.0224528  -0.138253     0.0518452   -0.114862     0.127599      0.145773     0.1618        0.0810051   -0.107564    -0.067757      0.0983902    -0.0425648   -0.0312573   -0.0733332   -0.0892783   -0.0216832    0.0297648    0.016105
 -0.0600117    -0.0306824   -0.110785     0.0339555    0.0453638   -0.108779     0.17386      -0.0392398    0.02671    -0.0383939    0.00918753   0.00349457   0.0698657    -0.142999     0.0522316     0.0271303    0.0552089    0.0403262    -0.103085     -0.128292     0.0885581    0.0235803    0.0625912   -0.0289998    0.103264     0.0895578
 -0.29649      -0.192457     0.0291243   -0.0291718   -0.051215     0.190675    -0.011254      0.180943     0.0684466   0.102755    -0.015291     0.0236702    0.103263      0.159735    -0.00461664   -0.145213     0.05592      0.0398892    -0.130407      0.11752     -0.0144533    0.110393    -0.0232926   -0.0903636   -0.0823603    0.0196015
  0.096108     -0.044369    -0.2194       0.10378      0.183972     0.0691779   -0.0179794     0.107032    -0.111606    0.0415213   -0.146302    -0.0554381   -0.196158      0.0470887    0.107653     -0.167843     0.0662334    0.129432     -0.0228637     0.148444    -0.178327     0.166649     0.0964134   -0.192309     0.178903     0.0137841
  0.154723     -0.00691483   0.0379506   -0.023503     0.0174084    0.0234195    0.0258861     0.0304541   -0.261196    0.200624    -0.0624699    0.00823357  -0.0561818     0.00232873  -0.161765     -0.100146     0.132091    -0.0184692    -0.0584212    -0.174029     0.0662443    0.105246    -0.0395775   -0.150017     0.0822099    0.0995593
 -0.0895037     0.129493    -0.0691061    0.0575879   -0.194466    -0.106445    -0.0415822    -0.0713589   -0.0110936   0.0449387    0.0142559    0.0282695    0.0585176     0.0173372    0.0653338    -0.0252761    0.0233828    0.136387     -0.069394     -0.0149634   -0.14487      0.0838435    0.0200134   -0.167633     0.0232657    0.0468541
  0.0380369    -0.102919     0.0463439    0.0976229   -0.0754609   -0.0192965    0.0893784     0.1232      -0.135702   -0.0300423    0.00852171   0.0583183    0.00360127   -0.183865    -0.00700399   -0.0882711   -0.00816181   0.00483809    0.0650362    -0.188542    -0.0124596    0.178336    -0.00188115  -0.0184981    0.0121454   -0.0266789
  0.0218177    -0.169555     0.0440808   -0.0358594   -0.0434215    0.277728     0.00563926   -0.0936048    0.061841    0.049769    -0.0206848    0.138121     0.101721      0.0495473    0.0962884    -0.0235245    0.0968502    0.0512349     0.00376356    0.0949565    0.106102     0.0521434   -0.114817    -0.0928102   -0.0269888    0.04287
  0.0994201     0.123221    -0.00434364  -0.0850389    0.00549399  -0.0645038    0.129106      0.0751607   -0.0929134   0.15229      0.0458453    0.0919983    0.0710843    -0.00378668  -0.00170844    0.0160338    0.0986389    0.0850719    -0.0503478    -0.0682611   -0.00185041  -0.00770903  -0.194015     0.0648071   -0.0148435    0.0829278
  0.0417842     0.146842    -0.0282793    0.0174127   -0.0275195    0.201925    -0.0409977    -0.0863166   -0.0220274   0.101507     0.00355572   0.0598624    0.00191472   -0.0190959    0.231155      0.0115988   -0.0339253    0.0980027     0.2015        0.130265    -0.0141493    0.151069     0.0213726   -0.0515691   -0.0136972    0.00608991
  0.0495265     0.140365    -0.127831     0.0680579   -0.024825     0.0688323   -0.0538401    -0.0863194    0.0471957   0.0181078    0.0692096    0.0568666    0.123186      0.119123     0.0784625     0.00696636   0.0566683   -0.0622257    -0.173509     -0.0652235    0.0424071   -0.0959982   -0.148272     0.0335262   -0.00459462   0.00697833
 -0.0786497     0.040032    -0.00949325  -0.0868129   -0.0691818   -0.0294375    0.0263705    -0.122274     0.132897   -0.00572142   0.128871     0.0111317    0.0505937    -0.00725477  -0.225009      0.0555985    0.101437    -0.061767     -0.0628334    -0.0377041    0.0540642    0.156691    -0.0614024   -0.128134     0.119933     0.0389623
 -0.0444011    -0.141467     0.037099     0.0236476   -0.149796     0.102214     0.157766      0.033976     0.138874   -0.0216499    0.136783    -0.0995633    0.0322446    -0.359187     0.0290051    -0.0513614   -0.0352185    0.0459603    -0.114152     -0.01467     -0.00407383   0.101183     0.151875    -0.266204    -0.130552    -0.00261617
 -0.0102007     0.0499968    0.067403    -0.00366476  -0.0798578    0.0835663    0.181044     -0.0172034    0.0139638   0.0476993   -0.0964421    0.052807     0.191365     -0.181715     0.0616613     0.0406989    0.164682     0.107557     -0.103378     -0.151666    -0.133385     0.085801     0.198318    -0.0442912   -0.0192108    0.011595
 -0.114656     -0.212359    -0.0227298   -0.0515316    0.0246303    0.106009    -0.0604438    -0.180158     0.0199019   0.1093       0.0561271   -0.0626754   -0.0854859     0.129165    -0.0305522     0.0585617    0.0133905    0.0850404    -0.0125742    -0.079809     0.0461161   -0.0378096   -0.139487    -0.0288706   -0.0434672    0.00291881
 -0.0168536    -0.0590171   -0.0616933    0.126194    -0.126493    -0.0846312    0.0372068     0.147597     0.0171779   0.0350558    0.243652    -0.0988101   -0.0444428    -0.0254767    0.216573      0.0188697    0.0675262    0.0132        0.0183895     0.00106515  -0.0451394    0.0545956    0.0597006    0.0302548    0.0428044   -0.0346417
  0.000918632   0.129228     0.0689593   -0.0120367   -0.0785972   -0.0667998    0.23013       0.0142057    0.0763997  -0.0785492    0.123057    -0.0885873    0.0336392    -0.136218    -0.0453541     0.00332821  -0.0109554   -0.151797     -0.0834913     0.178796    -0.00152169   0.0353176   -0.00137557   0.0284625   -0.0811739    0.00254342
  0.00826305    0.0811688    0.152975     0.0519905   -0.0424604    0.0123639    0.0787071    -0.0272786   -0.13602     0.00864225  -0.0553013    0.110142     0.063674     -0.0163977    0.0728299     0.0151543    0.0283409    0.0829523     0.0599683    -0.0491062    0.114657     0.00531865   0.0461974   -0.16043      0.120139    -0.0729775
 -0.0925309    -0.112602     0.0553542    0.017256    -0.0030252   -0.00671063  -0.0551949    -0.187615    -0.0360292   0.130505    -0.091389     0.116663    -0.0501691    -0.00810323   0.0889364    -0.176895     0.103153     0.0306746    -0.0341948    -0.083192     0.0666943    0.113233    -0.107579     0.162432     0.0362542   -0.0949761
  0.0856475    -0.02705      0.111633     0.155247    -0.140033     0.0320276   -0.0313565    -0.498826     0.0411831   0.0447035    0.045825    -0.0992567    0.0277122     0.116026     0.107512      0.0345217   -0.105871     0.124755     -0.0572866    -0.122367    -0.0737953   -0.0403138   -0.0362935   -0.116954    -0.109239     0.0289264
 -0.172234      0.0694111   -0.0783142   -0.140182     0.140282    -0.178267     0.0766779    -0.00815308  -0.0119172  -0.0687646    0.0875029    0.0406038    0.102043      0.0229995   -0.0426214    -0.0496517   -0.0392191    0.0695182    -0.12652       0.172886    -0.0641171   -0.0437265   -0.0696805   -0.0601136    0.0179288    0.109168
 -0.144337     -0.0390879   -0.13663     -0.0348459   -0.180372    -0.0370843   -0.0738084     0.0162091    0.0183285   0.0323166    0.140027    -0.0108348    0.0326565    -0.00242128  -0.00605803    0.0659833   -0.0604243    0.0291818    -0.00182573   -0.0524722    0.0393416    0.0554751    0.0697104   -0.0103827   -0.049828     0.0388292
  0.0618576    -0.0942588   -0.0742861   -0.00464532  -0.0380129    0.031889     0.101317     -0.0991875    0.0289327  -0.078796    -0.105838     0.0255533    0.0735334     0.0775589   -0.163738     -0.0295982   -0.123963     0.0195428     0.0358981     0.056386     0.0481562    0.0968159   -0.211934    -0.00264769   0.00532851  -0.0470973
  0.0602706     0.00566284   0.00195685   0.0690108   -0.00247568   0.0417004   -0.112824     -0.0760856    0.0900768   0.101731     0.11073      0.0178286   -0.0476911     0.158128     0.12607      -0.0849935    0.121928     0.198946     -0.024374     -0.0233844   -0.0330437    0.0239386    0.0162189    0.128331     0.0585929   -0.104787
  0.126129     -0.00967737  -0.165966     0.0086061   -0.0510374   -0.0017812   -0.0810234     0.0394718    0.213357    0.0509881    0.14802      0.0360964    0.0265506    -0.0919769   -0.0199816    -0.039553    -0.0323806   -0.0301762     0.0477941     0.0757448   -0.0187706   -0.0216094   -0.121282    -0.0260242    0.0208914    0.055291
 -0.21775       0.0190833   -0.0111173   -0.159895     0.105844    -0.17083      0.098907     -0.08596     -0.0166021  -0.102571     0.52058      0.0202609    0.0531969    -0.146291    -0.169806     -0.010154     0.108892    -0.133431      0.0344838     0.0491343   -0.151206    -0.18636     -0.0789569   -0.131789    -0.143755     0.0548029[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.071699
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      8
│     16
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.015245
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      9
│     11
│     13
│     15
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.015427
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      8
│     16
│     19
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.024841
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.045437
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      2
│      4
│      5
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.982547
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.062248
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      8
│     16
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.013158
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      9
│     11
│     13
│     15
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.015735
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      5
│      8
│     16
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.019068
┌ Info: EM with 100000 data points 10 iterations avll -1.019068
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0518845     0.119939     0.119394    -0.105806      0.0519599     0.01609      0.035671    -0.133222    -0.15468      0.0445597   -0.170411     0.205256      0.0320439   -0.190016    -0.0357908    0.0290249   -0.00350216   0.0313778   0.0886576   -0.0596036     0.000522635  -0.0849114    0.0450114     0.0676619   -0.0382203   0.159507
 -0.109624     -0.135313     0.0999141    0.0346005    -0.0731546     0.0881291   -0.280145    -0.138392    -0.0570867   -0.0916057    0.0310617    0.047771      0.145849     0.0845503    0.0725547   -0.0864561   -0.258531    -0.13708    -0.0456057   -0.138184      0.0977546    -0.0100174    0.0978229    -0.0356277   -0.183093   -0.0317901
  0.0690784     0.0116953    0.0360421    0.0885555    -0.000182574  -0.13397      0.0547998    0.00735171  -0.067991    -0.0785414   -0.107544     0.0635932     0.0464589   -0.0567058    0.0938271   -0.0191488   -0.0627939   -0.0544301   0.0674971   -0.0297534    -0.196364      0.0766534    0.0470505    -0.0242301    0.0260689   0.0335629
 -0.0388191     0.0664447    0.0609411   -0.0552297     0.0762201    -0.0118415   -0.0388406    0.141455     0.0295752    0.0540268   -0.0381398   -0.144255     -0.170674    -0.139335     0.00595983   0.263694    -0.0869629    0.0504037   0.203847    -0.0666093     0.00317618    0.0782417   -0.191937      0.0927134   -0.0509604  -0.0087106
  0.0170777    -0.0588974   -0.00119161   0.0442486     0.0187855     0.066304    -0.223013    -0.0142303    0.0815548    0.0246107   -0.025834     0.0654358    -0.0265137    0.130146    -0.0156759    0.136529    -0.0981325    0.0113831  -0.246133     0.0602442    -0.0752177    -0.0938142   -0.186947     -0.0310806    0.0629719  -0.117209
 -0.0977413     0.0785482    0.0138044   -0.10133      -0.00158342    0.118842     0.026377     0.0163111   -0.0573455    0.00281603   0.0774302   -0.177008     -0.0325053    0.0491943   -0.0362341    0.0404329   -0.0865038    0.0338378  -0.0209323   -0.0829745    -0.212606     -0.0634718    0.0378397    -0.207052    -0.0351661  -0.0904374
  0.00598428   -0.193346     0.00902088  -0.00030772   -0.147995     -0.0144112    0.126596     0.0592622    0.0672794   -0.0893009    0.164698    -0.0710907     0.0825215    0.129073     0.105774    -0.0191656    0.0316534    0.0925804   0.155866     0.000315111  -0.0979418    -0.143225     0.0113432    -0.172505    -0.0369618  -0.119929
  0.000189484   0.100006    -0.0557453    0.145482      0.0664325     0.299514     0.0803101    0.0469104   -0.0167752   -0.0177627   -0.0297849    0.103284     -0.0273217    0.0511988    0.0416531   -0.00905302  -0.171116     0.0798884   0.0668715    0.0170641     0.0842841     0.0282868    0.0492911    -0.0862164    0.115834   -0.117134
 -0.108625     -0.0957783   -0.15372      0.0585602     0.128473      0.0509349    0.0221735    0.141412    -0.0548472   -0.113865    -0.107229     0.175635     -0.0291425    0.140541     0.117838     0.0203148   -0.119861    -0.0307273  -0.0610913   -0.00721746   -0.037687      0.0290394    0.0406561    -0.00503258   0.149154   -0.22866
  0.0417724    -0.051527     0.0706015    0.0745804    -0.128931     -0.0349177    0.0536394    0.0958938   -0.0414596    0.160464    -0.0456698   -0.221298     -0.0598398   -0.00111385   0.151735    -0.00262822  -0.0495287   -0.0789817  -0.0919068   -0.167955      0.10047       0.241279    -0.0824176     0.0801616    0.0626208  -0.12495
 -0.0245976    -0.0018628   -0.0710937    0.124593      0.139094     -0.0547316   -0.154881    -0.156915    -0.16883      0.0788428   -0.158651    -0.130838      0.0582916   -0.143005     0.214299     0.0274083    0.0207144    0.0253132  -0.169415    -0.20496      -0.0333695    -0.0792938   -0.0246784     0.0543988   -0.213954   -0.0316358
 -0.15691       0.100365    -0.0669086    0.0421489     0.0554239     0.0109545   -0.0784664    0.196033    -0.091894     0.0745033   -0.144071    -0.147273     -0.251332    -0.160371     0.00786617   0.0689635    0.046301    -0.270756   -0.0964723   -0.00519777    0.0765719     0.0363815   -0.0835936    -0.0444252   -0.119111    0.0111521
 -0.0334835    -0.0854249   -0.00961787   0.0174746     0.105007     -0.0925955    0.121173    -0.0327347   -0.19131     -0.177392    -0.0104074   -0.051503     -0.125826    -0.107808     0.0721103   -0.15697     -0.0234792    0.184248   -0.069223    -0.0746652    -0.0901656    -0.0499491    0.165963      0.220716     0.0842062  -0.0113482
 -0.0162538    -0.196646     0.0346696   -0.108383      0.0466284    -0.0503101    0.0243833   -0.0560343    0.167341     0.0443026   -0.0842938   -0.0666039     0.106285    -0.0199455   -0.0286514    0.056145    -0.0903785    0.020906   -0.0216048   -0.0557232     0.0822264    -0.0558049    0.0721402     0.083661    -0.290167   -0.0715102
  0.245777     -0.0961499   -0.0145655   -0.19714       0.16939      -0.109027     0.0397364    0.0132843    0.175382    -0.200066    -0.00218691  -0.144519     -0.0184169   -0.0622539    0.078872    -0.0922187   -0.0507548    0.112855   -0.0246493   -0.093536     -0.0654687    -0.0433965   -0.0161722     0.0237746   -0.0636621   0.0142014
 -0.181344      0.142827    -0.0134417   -0.0338059     0.0552209    -0.0451414    0.02591      0.0808276   -0.00329946   0.262503     0.0071721   -0.0333728     0.114922    -0.0470493   -0.0689465   -0.096622     0.021619     0.0475299   0.0178698    0.179523      0.163467      0.0286233   -0.00297438   -0.185724    -0.0643411  -0.0319416
 -0.101956     -0.0162307   -0.240407     0.175647     -0.0365055    -0.0536987    0.194322     0.0257545    0.0101509    0.0432641    0.051162     0.0267479     0.138109    -0.120179     0.178329     0.117077    -0.176565    -0.215217   -0.140362     0.0236199     0.0695536    -0.0192202   -0.0248846     0.0572294   -0.158651   -0.028996
  0.00384568   -0.010276    -0.0789742   -0.000917496   0.0472666     0.00864563  -0.0126219   -0.122841    -0.0301903    0.161813     0.115012    -0.0225656    -0.0165755   -0.00734442   0.141749    -0.12922     -0.0239599   -0.156819   -0.0205869   -0.135483      0.0443132    -0.122486    -0.022092     -0.0269271   -0.0911293   0.0650699
  0.0607287     0.063941     0.0342958    0.0330017     0.0918705     0.203657     0.0806955    0.10401      0.0464354   -0.0171405    0.0348358   -0.0729859    -0.106609    -0.00777722   0.0766804   -0.00390053  -0.283787     0.133944    0.0854136    0.0405344     0.00283117   -0.245983    -0.0640179    -0.0280593   -0.129504    0.00459554
 -0.105589      0.039007     0.0115351   -0.16897       0.00771289    0.0998964    0.00703637   0.0603633   -0.138016    -0.0508819   -0.111177    -0.074599      0.120686    -0.0970714    0.032866    -0.0719283    0.0511472    0.0726655  -0.0982236   -0.109147      0.020756     -0.00626854   0.000845002  -0.180398     0.0128302   0.0903638
 -0.099986      0.0638057    0.0602471    0.0170475     0.0048951    -0.0765797   -0.11055     -0.0784977    0.125013     0.147341     0.168132     0.0556154     0.0322547    0.0128556   -0.0520924   -0.0657151   -0.127285    -0.114186    0.0915881   -0.155292      0.0102342    -0.0283353   -0.101957      0.00441431  -0.0550404   0.0184174
 -0.0962584    -0.0181069   -0.0883445   -0.00385293    0.216262     -0.0220051    0.152791     0.0353732   -0.23423     -0.0961693    0.0453597   -0.135438     -0.0107135    0.200064     0.0384035   -0.0111548    0.0665042   -0.0910569  -0.0168657   -0.0579658     0.15992       0.0697753   -0.0211439    -0.0325127   -0.0543493  -0.00194881
 -0.156399      0.0284049   -0.130392    -0.188641     -0.107059      0.215684    -0.119618     0.0288729   -0.0448915   -0.163105     0.0469844    0.0537181     0.17118      0.041767    -0.0864811    0.0446616   -0.0989516    0.0730633   0.195482    -0.0745616    -0.0401775     0.0632032    0.0354347    -0.078459     0.0433963   0.0349352
 -0.0966029     0.0858582    0.0302576   -0.00345794    0.0796171    -0.0480419    0.150285     0.178273     0.0573015    0.00797436   0.204033     0.058675     -0.0119384   -0.0434333    0.1121       0.190146    -0.0552369   -0.0790693   0.0380462    0.116579     -0.176062     -0.0209072   -0.197609      0.0907729   -0.153332   -0.0610406
 -0.0172256     0.0195365    0.0357122    0.103566      0.101222      0.217708     0.0108374   -0.0225584   -0.0132769   -0.059784    -0.00949829  -0.173678     -0.131281     0.0557262   -0.0653078   -0.210093     0.0224735   -0.0181059  -0.145722    -0.105489     -0.0265082     0.0506036    0.0651994     0.117129     0.0423664  -0.101661
  0.0947191    -0.118695    -0.178902     0.0157703    -0.0196139     0.067874     0.00285548  -0.147826    -0.0505626    0.0334951   -0.0513606   -0.0441858    -0.215755     0.0246362    0.240245     0.0467909   -0.0360394   -0.0456491   0.0916522   -0.0790019    -0.102402      0.0755134    0.0336981    -0.0759829   -0.0846768  -0.147808
  0.0732191    -0.0501968    0.172312    -0.0700123    -0.0587708     0.0557491    0.113117     0.0730628   -0.0192294    0.158934     0.152979     0.0347809     0.0108064    0.233719     0.0106118    0.101731     0.104573     0.100952    0.00718532  -0.0593606    -0.0498415     0.00447011  -0.0875048     0.0310871    0.029323   -0.0159764
 -0.0282936     0.247405     0.0088128   -0.0192998     0.104332      0.163451     0.0338406    0.0632669    0.0637441    0.0809921    0.0488227   -0.00725045   -0.0569048   -0.0774892   -0.0937157   -0.0804664    0.0703999    0.242477   -0.170754    -0.0983703    -0.0122408     0.177925     0.0929229     0.112129    -0.136454    0.00805827
 -0.0424975     0.0158046    0.0978294    0.099274     -0.13091       0.0113317    0.0543669   -0.067122     0.086853    -0.0674076    0.0931184    0.000677378  -0.00938452  -0.0331875   -0.0608037    0.102414     0.0562416   -0.0363548   0.0786926    0.174185     -0.0313904     0.0468554    0.0377715     0.107336    -0.0796861   0.0886655
 -0.12011      -0.0982924   -0.0226076    0.0910385    -0.250997     -0.136898    -0.0945018   -0.00692867  -0.0630227   -0.0770855    0.131588     0.0856309     0.0326002   -0.0977688    0.00706761  -0.101041    -0.0191384    0.073952    0.165797     0.101724      0.0483893    -0.0257047    0.00727125    0.14735      0.056919   -0.016743
 -0.104507     -0.00481888  -0.0800301   -0.0619507     0.0320691     0.0336982    0.0960657    0.056675    -0.125607     0.108253     0.0640015    0.139233      0.0135183   -0.125963    -0.0949052    0.0293454    0.194323    -0.0780321   0.0359746    0.0583637     0.0317771    -0.126135    -0.0740527     0.0402487    0.0332437   0.0111487
 -0.0865706    -0.125858     0.172879    -0.129013      0.142719      0.02847      0.0294286    0.17278      0.0763984   -0.128088     0.0636928   -0.151111     -0.151622     0.0257807   -0.00271081  -0.105553     0.0305309   -0.15408     0.0934727   -0.00103041   -0.0776722    -0.0807903   -0.0531219    -0.0405296    0.163385   -0.113261kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4259627946473696
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425982
[ Info: iteration 2, average log likelihood -1.425875
[ Info: iteration 3, average log likelihood -1.425775
[ Info: iteration 4, average log likelihood -1.425655
[ Info: iteration 5, average log likelihood -1.425513
[ Info: iteration 6, average log likelihood -1.425365
[ Info: iteration 7, average log likelihood -1.425232
[ Info: iteration 8, average log likelihood -1.425127
[ Info: iteration 9, average log likelihood -1.425048
[ Info: iteration 10, average log likelihood -1.424978
[ Info: iteration 11, average log likelihood -1.424892
[ Info: iteration 12, average log likelihood -1.424755
[ Info: iteration 13, average log likelihood -1.424523
[ Info: iteration 14, average log likelihood -1.424133
[ Info: iteration 15, average log likelihood -1.423535
[ Info: iteration 16, average log likelihood -1.422746
[ Info: iteration 17, average log likelihood -1.421920
[ Info: iteration 18, average log likelihood -1.421275
[ Info: iteration 19, average log likelihood -1.420893
[ Info: iteration 20, average log likelihood -1.420705
[ Info: iteration 21, average log likelihood -1.420621
[ Info: iteration 22, average log likelihood -1.420584
[ Info: iteration 23, average log likelihood -1.420569
[ Info: iteration 24, average log likelihood -1.420561
[ Info: iteration 25, average log likelihood -1.420558
[ Info: iteration 26, average log likelihood -1.420556
[ Info: iteration 27, average log likelihood -1.420555
[ Info: iteration 28, average log likelihood -1.420554
[ Info: iteration 29, average log likelihood -1.420554
[ Info: iteration 30, average log likelihood -1.420553
[ Info: iteration 31, average log likelihood -1.420553
[ Info: iteration 32, average log likelihood -1.420553
[ Info: iteration 33, average log likelihood -1.420552
[ Info: iteration 34, average log likelihood -1.420552
[ Info: iteration 35, average log likelihood -1.420552
[ Info: iteration 36, average log likelihood -1.420552
[ Info: iteration 37, average log likelihood -1.420551
[ Info: iteration 38, average log likelihood -1.420551
[ Info: iteration 39, average log likelihood -1.420551
[ Info: iteration 40, average log likelihood -1.420551
[ Info: iteration 41, average log likelihood -1.420551
[ Info: iteration 42, average log likelihood -1.420551
[ Info: iteration 43, average log likelihood -1.420551
[ Info: iteration 44, average log likelihood -1.420550
[ Info: iteration 45, average log likelihood -1.420550
[ Info: iteration 46, average log likelihood -1.420550
[ Info: iteration 47, average log likelihood -1.420550
[ Info: iteration 48, average log likelihood -1.420550
[ Info: iteration 49, average log likelihood -1.420550
[ Info: iteration 50, average log likelihood -1.420550
┌ Info: EM with 100000 data points 50 iterations avll -1.420550
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4259823514002001
│     -1.4258746186746245
│      ⋮
└     -1.420550103775075
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420566
[ Info: iteration 2, average log likelihood -1.420471
[ Info: iteration 3, average log likelihood -1.420379
[ Info: iteration 4, average log likelihood -1.420266
[ Info: iteration 5, average log likelihood -1.420132
[ Info: iteration 6, average log likelihood -1.419994
[ Info: iteration 7, average log likelihood -1.419874
[ Info: iteration 8, average log likelihood -1.419781
[ Info: iteration 9, average log likelihood -1.419712
[ Info: iteration 10, average log likelihood -1.419657
[ Info: iteration 11, average log likelihood -1.419607
[ Info: iteration 12, average log likelihood -1.419560
[ Info: iteration 13, average log likelihood -1.419513
[ Info: iteration 14, average log likelihood -1.419468
[ Info: iteration 15, average log likelihood -1.419427
[ Info: iteration 16, average log likelihood -1.419389
[ Info: iteration 17, average log likelihood -1.419355
[ Info: iteration 18, average log likelihood -1.419325
[ Info: iteration 19, average log likelihood -1.419298
[ Info: iteration 20, average log likelihood -1.419274
[ Info: iteration 21, average log likelihood -1.419252
[ Info: iteration 22, average log likelihood -1.419232
[ Info: iteration 23, average log likelihood -1.419214
[ Info: iteration 24, average log likelihood -1.419199
[ Info: iteration 25, average log likelihood -1.419186
[ Info: iteration 26, average log likelihood -1.419175
[ Info: iteration 27, average log likelihood -1.419165
[ Info: iteration 28, average log likelihood -1.419157
[ Info: iteration 29, average log likelihood -1.419150
[ Info: iteration 30, average log likelihood -1.419145
[ Info: iteration 31, average log likelihood -1.419140
[ Info: iteration 32, average log likelihood -1.419136
[ Info: iteration 33, average log likelihood -1.419133
[ Info: iteration 34, average log likelihood -1.419130
[ Info: iteration 35, average log likelihood -1.419128
[ Info: iteration 36, average log likelihood -1.419126
[ Info: iteration 37, average log likelihood -1.419125
[ Info: iteration 38, average log likelihood -1.419124
[ Info: iteration 39, average log likelihood -1.419123
[ Info: iteration 40, average log likelihood -1.419122
[ Info: iteration 41, average log likelihood -1.419121
[ Info: iteration 42, average log likelihood -1.419120
[ Info: iteration 43, average log likelihood -1.419120
[ Info: iteration 44, average log likelihood -1.419119
[ Info: iteration 45, average log likelihood -1.419119
[ Info: iteration 46, average log likelihood -1.419118
[ Info: iteration 47, average log likelihood -1.419118
[ Info: iteration 48, average log likelihood -1.419118
[ Info: iteration 49, average log likelihood -1.419117
[ Info: iteration 50, average log likelihood -1.419117
┌ Info: EM with 100000 data points 50 iterations avll -1.419117
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4205658454902197
│     -1.420470521981035
│      ⋮
└     -1.4191171853896416
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419128
[ Info: iteration 2, average log likelihood -1.419081
[ Info: iteration 3, average log likelihood -1.419041
[ Info: iteration 4, average log likelihood -1.418993
[ Info: iteration 5, average log likelihood -1.418933
[ Info: iteration 6, average log likelihood -1.418858
[ Info: iteration 7, average log likelihood -1.418766
[ Info: iteration 8, average log likelihood -1.418662
[ Info: iteration 9, average log likelihood -1.418551
[ Info: iteration 10, average log likelihood -1.418442
[ Info: iteration 11, average log likelihood -1.418342
[ Info: iteration 12, average log likelihood -1.418254
[ Info: iteration 13, average log likelihood -1.418181
[ Info: iteration 14, average log likelihood -1.418120
[ Info: iteration 15, average log likelihood -1.418071
[ Info: iteration 16, average log likelihood -1.418032
[ Info: iteration 17, average log likelihood -1.418000
[ Info: iteration 18, average log likelihood -1.417974
[ Info: iteration 19, average log likelihood -1.417952
[ Info: iteration 20, average log likelihood -1.417934
[ Info: iteration 21, average log likelihood -1.417919
[ Info: iteration 22, average log likelihood -1.417906
[ Info: iteration 23, average log likelihood -1.417895
[ Info: iteration 24, average log likelihood -1.417884
[ Info: iteration 25, average log likelihood -1.417875
[ Info: iteration 26, average log likelihood -1.417867
[ Info: iteration 27, average log likelihood -1.417859
[ Info: iteration 28, average log likelihood -1.417852
[ Info: iteration 29, average log likelihood -1.417845
[ Info: iteration 30, average log likelihood -1.417839
[ Info: iteration 31, average log likelihood -1.417833
[ Info: iteration 32, average log likelihood -1.417827
[ Info: iteration 33, average log likelihood -1.417822
[ Info: iteration 34, average log likelihood -1.417817
[ Info: iteration 35, average log likelihood -1.417813
[ Info: iteration 36, average log likelihood -1.417808
[ Info: iteration 37, average log likelihood -1.417804
[ Info: iteration 38, average log likelihood -1.417800
[ Info: iteration 39, average log likelihood -1.417796
[ Info: iteration 40, average log likelihood -1.417792
[ Info: iteration 41, average log likelihood -1.417789
[ Info: iteration 42, average log likelihood -1.417785
[ Info: iteration 43, average log likelihood -1.417782
[ Info: iteration 44, average log likelihood -1.417778
[ Info: iteration 45, average log likelihood -1.417775
[ Info: iteration 46, average log likelihood -1.417772
[ Info: iteration 47, average log likelihood -1.417769
[ Info: iteration 48, average log likelihood -1.417766
[ Info: iteration 49, average log likelihood -1.417763
[ Info: iteration 50, average log likelihood -1.417760
┌ Info: EM with 100000 data points 50 iterations avll -1.417760
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4191280919667109
│     -1.4190812830031247
│      ⋮
└     -1.4177597064280678
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417766
[ Info: iteration 2, average log likelihood -1.417711
[ Info: iteration 3, average log likelihood -1.417662
[ Info: iteration 4, average log likelihood -1.417607
[ Info: iteration 5, average log likelihood -1.417541
[ Info: iteration 6, average log likelihood -1.417461
[ Info: iteration 7, average log likelihood -1.417368
[ Info: iteration 8, average log likelihood -1.417266
[ Info: iteration 9, average log likelihood -1.417158
[ Info: iteration 10, average log likelihood -1.417049
[ Info: iteration 11, average log likelihood -1.416945
[ Info: iteration 12, average log likelihood -1.416846
[ Info: iteration 13, average log likelihood -1.416756
[ Info: iteration 14, average log likelihood -1.416675
[ Info: iteration 15, average log likelihood -1.416603
[ Info: iteration 16, average log likelihood -1.416542
[ Info: iteration 17, average log likelihood -1.416489
[ Info: iteration 18, average log likelihood -1.416444
[ Info: iteration 19, average log likelihood -1.416406
[ Info: iteration 20, average log likelihood -1.416373
[ Info: iteration 21, average log likelihood -1.416343
[ Info: iteration 22, average log likelihood -1.416317
[ Info: iteration 23, average log likelihood -1.416293
[ Info: iteration 24, average log likelihood -1.416270
[ Info: iteration 25, average log likelihood -1.416248
[ Info: iteration 26, average log likelihood -1.416227
[ Info: iteration 27, average log likelihood -1.416207
[ Info: iteration 28, average log likelihood -1.416186
[ Info: iteration 29, average log likelihood -1.416166
[ Info: iteration 30, average log likelihood -1.416145
[ Info: iteration 31, average log likelihood -1.416125
[ Info: iteration 32, average log likelihood -1.416104
[ Info: iteration 33, average log likelihood -1.416084
[ Info: iteration 34, average log likelihood -1.416064
[ Info: iteration 35, average log likelihood -1.416044
[ Info: iteration 36, average log likelihood -1.416024
[ Info: iteration 37, average log likelihood -1.416005
[ Info: iteration 38, average log likelihood -1.415986
[ Info: iteration 39, average log likelihood -1.415969
[ Info: iteration 40, average log likelihood -1.415951
[ Info: iteration 41, average log likelihood -1.415935
[ Info: iteration 42, average log likelihood -1.415919
[ Info: iteration 43, average log likelihood -1.415904
[ Info: iteration 44, average log likelihood -1.415889
[ Info: iteration 45, average log likelihood -1.415876
[ Info: iteration 46, average log likelihood -1.415863
[ Info: iteration 47, average log likelihood -1.415850
[ Info: iteration 48, average log likelihood -1.415839
[ Info: iteration 49, average log likelihood -1.415828
[ Info: iteration 50, average log likelihood -1.415817
┌ Info: EM with 100000 data points 50 iterations avll -1.415817
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.417766270043699
│     -1.417710790659235
│      ⋮
└     -1.4158173959718552
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415816
[ Info: iteration 2, average log likelihood -1.415749
[ Info: iteration 3, average log likelihood -1.415684
[ Info: iteration 4, average log likelihood -1.415606
[ Info: iteration 5, average log likelihood -1.415509
[ Info: iteration 6, average log likelihood -1.415387
[ Info: iteration 7, average log likelihood -1.415241
[ Info: iteration 8, average log likelihood -1.415076
[ Info: iteration 9, average log likelihood -1.414901
[ Info: iteration 10, average log likelihood -1.414728
[ Info: iteration 11, average log likelihood -1.414565
[ Info: iteration 12, average log likelihood -1.414416
[ Info: iteration 13, average log likelihood -1.414283
[ Info: iteration 14, average log likelihood -1.414166
[ Info: iteration 15, average log likelihood -1.414064
[ Info: iteration 16, average log likelihood -1.413975
[ Info: iteration 17, average log likelihood -1.413898
[ Info: iteration 18, average log likelihood -1.413831
[ Info: iteration 19, average log likelihood -1.413772
[ Info: iteration 20, average log likelihood -1.413721
[ Info: iteration 21, average log likelihood -1.413675
[ Info: iteration 22, average log likelihood -1.413635
[ Info: iteration 23, average log likelihood -1.413598
[ Info: iteration 24, average log likelihood -1.413565
[ Info: iteration 25, average log likelihood -1.413535
[ Info: iteration 26, average log likelihood -1.413507
[ Info: iteration 27, average log likelihood -1.413481
[ Info: iteration 28, average log likelihood -1.413457
[ Info: iteration 29, average log likelihood -1.413435
[ Info: iteration 30, average log likelihood -1.413413
[ Info: iteration 31, average log likelihood -1.413393
[ Info: iteration 32, average log likelihood -1.413374
[ Info: iteration 33, average log likelihood -1.413355
[ Info: iteration 34, average log likelihood -1.413337
[ Info: iteration 35, average log likelihood -1.413320
[ Info: iteration 36, average log likelihood -1.413304
[ Info: iteration 37, average log likelihood -1.413288
[ Info: iteration 38, average log likelihood -1.413273
[ Info: iteration 39, average log likelihood -1.413258
[ Info: iteration 40, average log likelihood -1.413244
[ Info: iteration 41, average log likelihood -1.413230
[ Info: iteration 42, average log likelihood -1.413217
[ Info: iteration 43, average log likelihood -1.413204
[ Info: iteration 44, average log likelihood -1.413191
[ Info: iteration 45, average log likelihood -1.413179
[ Info: iteration 46, average log likelihood -1.413168
[ Info: iteration 47, average log likelihood -1.413156
[ Info: iteration 48, average log likelihood -1.413145
[ Info: iteration 49, average log likelihood -1.413135
[ Info: iteration 50, average log likelihood -1.413125
┌ Info: EM with 100000 data points 50 iterations avll -1.413125
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4158156306099932
│     -1.4157493404064072
│      ⋮
└     -1.4131247032908918
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4259627946473696
│     -1.4259823514002001
│     -1.4258746186746245
│     -1.425775334076533
│      ⋮
│     -1.4131454151521683
│     -1.4131348825891197
└     -1.4131247032908918
32×26 Array{Float64,2}:
  0.000829164   0.0394588  -0.218929   -0.105617    -0.439441    0.388098     -0.166548     0.00182859  -0.185513      0.473035   -0.50935     -0.452045   -0.311032    0.48038     0.298005     0.236805     0.278367     0.424059     -0.381216    -0.312674   -0.148883   -0.199645     0.0743673  -0.446226   -0.479178   -0.341061
  0.0656638    -0.31063     0.0402711   0.541942    -0.436069    0.0266187    -0.222174    -0.237884     0.0916964     0.276914    0.021195     0.148051    0.570039    0.603031    0.139881     0.476062    -0.444459    -0.0782082    -0.169673    -0.33191    -0.134448   -0.207937     0.347807   -0.464896   -0.636004    0.10735
 -0.0741149     0.11848    -0.652709    0.129018    -0.333446    0.640086      0.115158     0.709773     0.0244094    -0.126663   -0.144369    -0.686643    0.444095    0.674869   -0.401788    -0.494156    -0.823306     0.31383       0.573291    -0.26419     0.283551   -1.04691      0.307096   -0.65292    -0.406146   -0.252501
 -0.223193      0.139706   -0.0692026   0.113371    -0.395649   -0.0571867    -0.0341969    0.317837    -0.188819     -0.287331   -0.148348     0.129398    0.760444   -0.308105   -0.206167     0.381592    -0.743162    -0.420748      0.0871173   -0.265722    0.594769    0.133719    -0.57591    -0.239029   -0.19184    -0.408119
  0.241565      0.1846      0.0975042  -0.0304413    0.112882    0.135365      0.139552     0.253787    -0.248518      0.133227    0.328319    -0.233591    0.0729495   0.242785    0.113281    -0.688211     0.0146295   -0.0109697    -0.0558456    0.16081    -0.558393    0.0510331    0.461539    0.0918667   0.0912698  -0.743146
 -0.219648      0.0557363   0.0853199   0.206366     0.0951783   0.303781     -0.151192     0.055772    -0.366281      0.0408068  -0.210962    -0.36237    -0.105702   -0.129079    0.00455283  -0.439132     0.0968442    0.0469117     0.146221    -0.251876   -0.148755   -0.0103418    0.504467    0.174129    0.347264    0.311707
  0.321826      0.0363342   0.107144    0.226207    -0.137244    0.049638     -0.272366     0.205002     0.0938925    -0.109085    0.0884926    0.244675    0.324242    0.379452   -0.240251     0.330006    -0.283728     0.153327     -0.423723     0.354449   -0.360361    0.169942     0.0897667   0.347875    0.715989    0.270032
  0.418566     -0.108122   -0.0266388   0.183669    -0.0271316   0.056798      0.249335     0.199056    -0.119121      0.407737    0.0482281    0.246758    0.524023   -0.072312    0.098508     0.365035    -0.179497     0.104808      0.503068     0.127638    0.188827   -0.0174991   -0.0612257  -0.315892    0.128415   -0.117347
 -5.60192e-5    0.0354795   0.0696197  -0.0577262    0.0997647   0.0290765    -0.106635    -0.124415    -0.0419721    -0.0648308  -0.0964284   -0.0191876   0.0274938  -0.0825565   0.0903709   -0.0316036   -0.286037     0.102252     -0.0269181   -0.213561    0.0353761   0.0403092   -0.128943   -0.0107442  -0.079968    0.0227786
 -0.300014     -0.0764277  -0.138587   -0.121389     0.0930829  -0.0082727     0.256906     0.0392651    0.154858     -0.0754794   0.121751    -0.109833   -0.204835   -0.0602129  -0.0101255    0.0149173    0.307859    -0.339456     -0.0549874    0.127606   -0.138943    0.0761734   -0.0039552   0.111807   -0.173788   -0.109797
 -0.0485813    -0.198271    0.0850938   0.293221    -0.0366864  -0.371695      0.0831627    0.440671     0.0489548    -0.162305    0.20687      0.0434344  -0.331601    0.111978    0.143401     0.113092     0.138401    -0.0604488    -0.344389     0.0120814   0.45176    -1.03627     -0.144792    0.483217    0.0799758   0.218225
 -0.241476     -0.353291   -0.275895    0.0521799    0.180024    0.0245206     0.130738    -0.285512     0.46079      -0.0504005  -0.279601     0.473831   -0.104652   -0.179259    0.14612      0.72445      0.320851    -0.322076     -0.125815     0.178824    0.383248   -0.0121248   -0.179562    0.232439   -0.119699    0.912926
 -0.190877      0.311638   -0.0295076  -0.24629      0.116844   -0.0275187     0.100629    -0.298432     0.143727     -0.337185   -0.00279331   0.0114219  -0.366517   -0.450195   -0.260769    -0.746925    -0.282317    -0.0296141    -0.177907    -0.754007    0.151347    0.22567     -0.372598    0.0694889  -0.608562   -0.000267958
 -0.109536      0.293882   -0.106451   -0.307788    -0.14192    -0.0853365    -0.1531       0.113355    -0.133699     -0.610726    0.351444     0.0691477  -0.697495    0.182159   -0.455357     0.415521    -0.228331     0.0594832     0.151791    -0.120836   -0.0442765  -0.432615    -0.234407   -0.618049    0.0388677   0.0725147
  0.171276      0.207238   -0.0142009  -0.539367     0.282314   -0.148012      0.127939    -0.140769     0.126691      0.17196     0.398011     0.37972    -0.5984     -0.189768    0.395752     0.0104388    0.362925     0.140603     -0.104305     0.14505     0.361547    0.1312      -0.472374    0.109287   -0.246459   -0.682327
 -0.145754      0.147618    0.712203    0.0879047   -0.492441   -0.77236      -0.146719    -0.255799     0.219779     -0.156115    0.258888    -0.035975   -0.147526   -0.123969   -0.129034     0.134208     0.152254    -0.0581938    -0.520895     0.399444   -0.227448    0.198142    -0.465481   -0.0334602  -0.333721   -0.375449
 -0.305657      0.358113   -0.34417    -0.114253     0.0804796  -0.134477      0.662925     0.366035     0.305912     -0.322559    0.186536    -0.49592    -0.616761   -0.442814   -0.327308    -0.647676     0.434966    -0.419695     -0.0155408    0.521894   -0.195257    0.156312    -0.0961707   0.755101    0.0824436   0.0952917
 -0.397816     -0.194234    0.145017   -0.0777402    0.358255   -0.129159     -0.131692    -0.291042     0.538603     -0.365504    0.154236    -0.484371   -0.548166    0.456446    0.255107    -0.571066     0.35673     -0.245584     -0.598078    -0.315117   -0.893733    0.00174391   0.372934    0.397233   -0.118935    0.155846
  0.0573822     0.0838313   0.244662   -0.005899     0.0863776   0.308054     -0.040778    -0.075085    -0.655427      0.135774   -0.0272985   -0.632648   -0.132195    0.0161865  -0.376118    -1.11671     -0.162039     0.624884     -0.186595    -0.329934   -0.061004   -0.0830524    0.0377085  -0.191166    0.0486595  -0.633638
 -0.373156      0.308176    0.121226   -0.133687     0.189764    0.595722     -0.0123973    0.485481    -0.546858     -0.157393    0.133185    -0.188607   -0.69978    -0.823569    0.467947    -0.935777    -0.22497     -0.254927      0.128892    -0.432598    0.290138   -0.270029     0.508067   -0.35538    -0.406938   -0.0990068
 -0.229328     -0.645421   -0.244394   -0.301277     0.918143    0.506284      0.174463    -0.0973429    0.119011     -0.0574174  -0.0225236   -0.101404    0.473247   -0.163788    0.867882    -0.471215    -0.0144795    0.175668     -0.0379107   -0.521768    0.467308    0.206427    -0.238291    0.608159    0.019843   -0.352138
  0.297662     -0.856022   -0.620368    0.345913     0.472504    0.862203     -0.00579001   0.0962415   -0.325365     -0.141061   -0.0991498   -0.401915   -0.106237    0.0341828   0.240912     0.00531244   0.00378669   0.0142069     0.380499    -0.708635   -0.0806387   0.0567702    0.779824   -0.0771148   0.121887    0.422538
 -0.133438      0.0594232  -0.211969   -0.331453     0.309551    0.288048     -0.155448    -0.508121     0.000211009   0.204933   -0.454953    -0.371175    0.542136   -0.112992    0.0531095    0.0132405   -0.402622    -0.0204495     0.234851    -0.116075   -0.709428    1.11853      0.157094   -0.344815   -0.292993   -0.306496
  0.342625      0.171027    0.235828   -0.0597988    0.697405   -0.0993949     0.107521    -0.175381    -0.0867744     0.0899123  -0.0628175    0.379271   -0.453486   -0.77088     0.546911     0.0386864   -0.311606     0.291694      0.00798147   0.408619   -0.531787    0.670502    -0.174209    0.20269     0.342388    0.293442
 -0.688083     -0.227665    0.011974   -0.383981    -0.0700359  -0.288873     -0.0465761   -0.505873     0.202506      0.10388    -0.23807     -0.0664749   0.17154     0.0116442  -0.0682341   -0.0808426   -0.148375     0.206212      0.171303    -0.668538    0.487992   -0.0963473   -0.43806    -0.575116   -1.04885    -0.161677
 -0.14942      -0.0114385   0.119548   -0.207424    -0.0159937  -0.232677     -0.210722    -0.0391173    0.13572      -0.128999   -0.00213607   0.389123   -0.0565777   0.0723549  -0.0407593    0.620934    -0.0721286    0.0951627    -0.09001      0.0271625   0.324722   -0.0608878   -0.385382   -0.102797    0.134137    0.173858
 -0.128233     -0.0480476   0.141365   -0.247614    -0.113865    0.000742245  -0.288632    -0.0339686   -0.28859       0.742605   -0.081575    -0.513308    0.439885   -0.10861     0.18369     -0.112379     0.0963636    0.473071      1.18535      0.259313    1.10517    -0.0987231   -0.125286   -0.0317146   0.607801   -0.022685
 -0.219793      0.454228    0.308417   -0.329549    -0.182435    0.356419     -0.0192998   -0.0469631   -0.514416      0.0944741   0.16113      1.09179    -0.11593    -0.457526   -0.0633024    0.302618     0.105138    -0.114039      0.442698    -0.367905    0.907392   -0.149229    -0.28262     0.106       0.478272    0.2588
 -0.194127      0.0434086   0.0835461  -0.00728455  -0.0914161  -0.0361259    -0.0425532    0.0553825   -0.325662      0.303991    0.266501    -0.070102   -0.0090793   0.395749   -0.171849     0.588904     0.623661     0.170475      0.527087     0.746407   -0.394191   -0.169241     0.529657   -0.435989    0.447448   -0.185549
  0.575378      0.0507006  -0.225706    0.806254    -0.279657    0.295341      0.207641     0.245985    -0.30271       0.276451    0.113748     0.290577    0.051851    0.137857    0.176886     0.362547     0.0712182   -0.000169368  -0.0650523    0.483466   -0.499901   -0.0756045    0.599396   -0.0366812   0.296672   -0.0201099
  0.453696      0.266595    0.259789   -0.0954531    0.0051445   0.00114872   -0.840536     0.771959     0.179998      0.232054   -0.275449    -0.0297429   0.728305   -0.0347026   0.363066     0.366153    -0.849291    -0.41039      -0.0855181    0.274512    0.316215    0.424552     0.0416493   0.642779    0.127313   -0.217345
  0.298634     -0.534738   -0.139318    0.462368    -0.0187236  -0.144391      0.800973     0.363311     0.205241      0.214898   -0.00621889  -0.292613    0.840664    0.31815    -0.483086     0.0230467   -0.0880462   -0.400076      0.297047     0.175199   -0.426593   -0.0810809   -0.147634    0.194102    0.207725    0.193967[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413115
[ Info: iteration 2, average log likelihood -1.413105
[ Info: iteration 3, average log likelihood -1.413096
[ Info: iteration 4, average log likelihood -1.413087
[ Info: iteration 5, average log likelihood -1.413079
[ Info: iteration 6, average log likelihood -1.413070
[ Info: iteration 7, average log likelihood -1.413062
[ Info: iteration 8, average log likelihood -1.413054
[ Info: iteration 9, average log likelihood -1.413046
[ Info: iteration 10, average log likelihood -1.413039
┌ Info: EM with 100000 data points 10 iterations avll -1.413039
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.357027e+05
      1       7.062092e+05      -2.294935e+05 |       32
      2       6.927820e+05      -1.342717e+04 |       32
      3       6.879652e+05      -4.816827e+03 |       32
      4       6.856165e+05      -2.348669e+03 |       32
      5       6.842550e+05      -1.361563e+03 |       32
      6       6.832707e+05      -9.842880e+02 |       32
      7       6.825642e+05      -7.064499e+02 |       32
      8       6.820072e+05      -5.570686e+02 |       32
      9       6.815486e+05      -4.586117e+02 |       32
     10       6.811689e+05      -3.796162e+02 |       32
     11       6.808308e+05      -3.381345e+02 |       32
     12       6.805758e+05      -2.550251e+02 |       32
     13       6.803701e+05      -2.056711e+02 |       32
     14       6.802010e+05      -1.691290e+02 |       32
     15       6.800623e+05      -1.386865e+02 |       32
     16       6.799406e+05      -1.217359e+02 |       32
     17       6.798313e+05      -1.092722e+02 |       32
     18       6.797313e+05      -9.994888e+01 |       32
     19       6.796460e+05      -8.538579e+01 |       32
     20       6.795623e+05      -8.370871e+01 |       32
     21       6.794756e+05      -8.661023e+01 |       32
     22       6.793815e+05      -9.412027e+01 |       32
     23       6.792726e+05      -1.088981e+02 |       32
     24       6.791618e+05      -1.108642e+02 |       32
     25       6.790573e+05      -1.044420e+02 |       32
     26       6.789506e+05      -1.067239e+02 |       32
     27       6.788440e+05      -1.065472e+02 |       32
     28       6.787478e+05      -9.628524e+01 |       32
     29       6.786427e+05      -1.050571e+02 |       32
     30       6.785403e+05      -1.023666e+02 |       32
     31       6.784458e+05      -9.450232e+01 |       32
     32       6.783626e+05      -8.322514e+01 |       32
     33       6.782762e+05      -8.640033e+01 |       32
     34       6.781973e+05      -7.895538e+01 |       32
     35       6.781187e+05      -7.850432e+01 |       32
     36       6.780411e+05      -7.764322e+01 |       32
     37       6.779717e+05      -6.940777e+01 |       32
     38       6.779130e+05      -5.865948e+01 |       32
     39       6.778607e+05      -5.235974e+01 |       32
     40       6.778098e+05      -5.083202e+01 |       32
     41       6.777602e+05      -4.966126e+01 |       32
     42       6.777110e+05      -4.916900e+01 |       32
     43       6.776587e+05      -5.226666e+01 |       32
     44       6.776016e+05      -5.709977e+01 |       32
     45       6.775460e+05      -5.566647e+01 |       32
     46       6.774819e+05      -6.408251e+01 |       32
     47       6.774283e+05      -5.361960e+01 |       32
     48       6.773811e+05      -4.715920e+01 |       32
     49       6.773370e+05      -4.416180e+01 |       32
     50       6.772969e+05      -4.001509e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 677296.945307927)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424880
[ Info: iteration 2, average log likelihood -1.419778
[ Info: iteration 3, average log likelihood -1.418313
[ Info: iteration 4, average log likelihood -1.417200
[ Info: iteration 5, average log likelihood -1.416121
[ Info: iteration 6, average log likelihood -1.415224
[ Info: iteration 7, average log likelihood -1.414625
[ Info: iteration 8, average log likelihood -1.414265
[ Info: iteration 9, average log likelihood -1.414041
[ Info: iteration 10, average log likelihood -1.413887
[ Info: iteration 11, average log likelihood -1.413772
[ Info: iteration 12, average log likelihood -1.413682
[ Info: iteration 13, average log likelihood -1.413607
[ Info: iteration 14, average log likelihood -1.413545
[ Info: iteration 15, average log likelihood -1.413491
[ Info: iteration 16, average log likelihood -1.413443
[ Info: iteration 17, average log likelihood -1.413400
[ Info: iteration 18, average log likelihood -1.413362
[ Info: iteration 19, average log likelihood -1.413327
[ Info: iteration 20, average log likelihood -1.413294
[ Info: iteration 21, average log likelihood -1.413264
[ Info: iteration 22, average log likelihood -1.413236
[ Info: iteration 23, average log likelihood -1.413209
[ Info: iteration 24, average log likelihood -1.413184
[ Info: iteration 25, average log likelihood -1.413160
[ Info: iteration 26, average log likelihood -1.413138
[ Info: iteration 27, average log likelihood -1.413116
[ Info: iteration 28, average log likelihood -1.413096
[ Info: iteration 29, average log likelihood -1.413076
[ Info: iteration 30, average log likelihood -1.413058
[ Info: iteration 31, average log likelihood -1.413040
[ Info: iteration 32, average log likelihood -1.413023
[ Info: iteration 33, average log likelihood -1.413007
[ Info: iteration 34, average log likelihood -1.412991
[ Info: iteration 35, average log likelihood -1.412977
[ Info: iteration 36, average log likelihood -1.412963
[ Info: iteration 37, average log likelihood -1.412949
[ Info: iteration 38, average log likelihood -1.412937
[ Info: iteration 39, average log likelihood -1.412924
[ Info: iteration 40, average log likelihood -1.412913
[ Info: iteration 41, average log likelihood -1.412902
[ Info: iteration 42, average log likelihood -1.412891
[ Info: iteration 43, average log likelihood -1.412881
[ Info: iteration 44, average log likelihood -1.412871
[ Info: iteration 45, average log likelihood -1.412862
[ Info: iteration 46, average log likelihood -1.412853
[ Info: iteration 47, average log likelihood -1.412844
[ Info: iteration 48, average log likelihood -1.412836
[ Info: iteration 49, average log likelihood -1.412827
[ Info: iteration 50, average log likelihood -1.412819
┌ Info: EM with 100000 data points 50 iterations avll -1.412819
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.431482    0.122707    -0.0490057   0.551207    0.306325     0.489054    0.353493     0.195733     -0.190313   -0.0188126    0.191206     0.540399     0.269786   -0.125488    0.206972   -0.0166486   -0.188417    -0.26725    -0.136932     0.373711    -0.618335    0.367849    0.665405     0.533884     0.439514    0.244282
 -0.0150781  -0.0740811   -0.402503    0.198564   -0.00683879   0.0948724   0.257735     0.789931     -0.0402071   0.108304     0.110456     0.0223666   -0.0790633   0.0937293  -0.1442      0.147716     0.00461421  -0.0548954   0.141353    -0.13554      0.694239   -0.953207    0.0059153    0.131393     0.136002    0.424245
 -0.183955   -0.122002     0.147075   -0.161525    0.0510887   -0.111053   -0.204784    -0.0493772     0.0444151  -0.0947497   -0.0145308   -0.132392    -0.0881036  -0.0109772   0.0186324  -0.10911     -0.162972     0.160315   -0.131672    -0.217571     0.124411   -0.0432825  -0.219898    -0.233184    -0.253922   -0.171139
  0.661306    0.671592    -0.260314   -0.206474    0.00187358   0.126224   -0.891011     0.375186     -0.172771    0.774696    -0.599069    -0.233499    -0.059525    0.219756    0.676963    0.653449    -0.0824348    0.162449   -0.377329     0.339808     0.0634837   0.382407    0.281684     0.601292     0.180255   -0.310501
 -0.137542   -0.0849454   -0.107419   -0.0992886  -0.0216534   -0.544699    0.146669    -0.142466      0.422131    0.011579     0.116226     0.541861     0.187705    0.210639   -0.111877    1.23339      0.259988    -0.228562    0.160011     0.528749     0.211747   -0.131829   -0.419484     0.055164     0.300415    0.399314
  0.376992    0.00222825   0.079577    0.323568   -0.134546     0.169789   -0.260237     0.197477     -0.0343942  -0.119067     0.107902     0.310454     0.341621    0.311356   -0.276103    0.268543    -0.216703     0.119495   -0.285076     0.258791    -0.302557    0.13603     0.132789     0.340314     0.808148    0.290956
  0.0830397  -0.108211     0.215219   -0.0565803  -0.107774     0.297246   -0.36694     -0.0566854    -0.52702     0.477613    -0.100568     0.0151338    0.271829   -0.0833889   0.183728    0.14906      0.17045      0.685798    0.965771    -0.00581896   0.907312   -0.402528    0.111307    -0.0717984    0.599143    0.365778
 -0.157332   -0.085708    -0.221472   -0.0233956  -0.138925     0.122985    0.0559024   -0.0266734     0.12127    -0.0493881   -0.142108    -0.0849235   -0.0674975   0.0898263  -0.0207521   0.222412    -0.0703395    0.0120718  -0.209317    -0.15016     -0.0228923  -0.0739097  -0.157511    -0.140394    -0.225977    0.0769504
  0.168557   -0.562051    -0.148816    0.493102   -0.589145     0.190907   -0.0920488   -0.0676686     0.0870191   0.3273      -0.113581     0.201516     0.4584      0.546061    0.131641    0.721769    -0.331359     0.0474907  -0.305934    -0.312359     0.043036   -0.182478    0.233976    -0.592385    -0.592179    0.228551
  0.311019   -0.513083     0.118533    0.652859   -0.286963    -0.235257    0.490654     0.516512     -0.0139579   0.197504    -0.123268    -0.580823     0.501119    0.349426   -0.48191     0.00411647   0.0102631   -0.453244    0.0393582    0.262924    -0.428149   -0.33583     0.186735     0.171088     0.282462    0.286528
  0.236148    0.0294115    0.0447907  -0.345959    0.0273255    0.114383    0.0738228    0.255566     -0.0809508   0.0529155    0.505739    -0.185086    -0.523584    0.260566   -0.119071    0.045607     0.246971     0.422144    0.227283     0.85405     -0.644337   -0.222863    0.375977    -0.694774     0.312151   -0.297024
 -0.141123   -0.00542012   0.237533    0.269489    0.120635    -0.501945   -0.429919    -0.416603      0.301065   -0.23353      0.204856    -0.0102196   -0.171819    0.491223    0.223476    0.409193     0.0568503   -0.359453   -0.316915    -0.0168063   -0.19477    -0.413057    0.00944814   0.0105655   -0.576668   -0.160018
  0.140257    0.251616     0.133751    0.0222385  -0.354263    -0.132762   -0.159362     0.343029     -0.193723    0.00702563  -0.0710019    0.31669      0.837008   -0.26764    -0.116933    0.379218    -0.959902    -0.284198    0.263491    -0.0829269    0.570546    0.156307   -0.558721    -0.150461    -0.0723158  -0.514542
 -0.273209    0.257179     0.0381262   0.0846589   0.0949041   -0.247904    0.464138     0.514324      0.349602   -0.0738642    0.452358    -0.00980383  -0.157934    0.218647    0.139919   -0.570973    -0.255045    -0.501802   -0.771833     0.34523     -0.408831    0.152129   -0.131889     0.740671    -0.120974   -0.496062
  0.266318    0.00301737  -0.244543    0.336596   -0.261438     0.452722   -0.0152978    0.104901     -0.45053     0.270307    -0.12538     -0.758223     0.229948    0.504776    0.0257441  -0.75766     -0.284898     0.587562    0.0541274   -0.626627    -0.229647   -0.505405    0.329717    -0.399751    -0.298787   -0.706705
 -0.153445   -0.0633852    0.295244   -0.347916   -0.100185    -0.550237    0.301137    -0.102729      0.320963   -0.272784     0.252515     0.0973994   -0.210784   -0.424306   -0.113747    0.0309286    0.18423     -0.183874   -4.04543e-5   0.212061     0.267416   -0.0308459  -0.677841    -5.28456e-5  -0.252407   -0.265875
 -0.0790468   0.0347262   -0.114458    0.289522    0.117535     0.482048    0.117616     0.506369     -0.433918   -0.00350396  -0.127687    -0.500074    -0.492683   -0.957557    0.84445    -1.07828     -0.294043    -0.18653     0.122092    -0.440486     0.205385   -0.341951    0.485657    -0.408418    -0.414677   -0.188729
 -0.436204    0.129271     0.241573   -0.41268     0.220824     0.31328     0.222591     0.234621     -0.280403    0.289046     0.118165    -0.560454    -0.0235009  -0.638734   -0.37181    -1.06935      0.216016    -0.0638961   0.386322     0.256425     0.219831    0.445266    0.0329447    0.169399     0.361392   -0.19943
 -0.702649   -0.0676196   -0.29451    -0.359854    0.147179     0.39589    -0.304879     0.102335     -0.0156194  -0.0687665   -0.487421     0.335906    -0.296251   -0.545476    0.071018    0.58363      0.0190306   -0.718044    0.340011     0.428249     0.753801    0.439647   -0.0230278   -0.139744    -0.169138    0.475218
 -0.28475     0.0390196    0.222022   -0.0725068   0.0781681    0.0932341  -0.389654     0.00233248    0.144137   -0.212942    -0.273026    -0.667675     0.90129     0.210073   -0.242828   -0.107068    -1.02173     -0.102202    0.37683     -0.101832    -0.522076    0.442897    0.314697    -0.232556    -0.252611    0.105032
 -0.177726    0.541798     0.688869    0.0222813  -0.728576    -0.431454   -0.568184    -0.316206     -0.258532    0.0898362    0.0780846    0.0799477   -0.191824    0.159656   -0.1663      0.143671     0.160126     0.443981   -0.380647     0.312693    -0.326213    0.246382   -0.0947695   -0.330406    -0.0414139  -0.25121
  0.282661   -0.418805    -0.225544    0.0916421   0.327267     0.114318    0.329987    -0.145758      0.0088124   0.626643     0.00997196  -0.142464     0.598395    0.137466    0.394466    0.0500914    0.228161    -0.0149639   0.373259     0.12795     -0.233116    0.238534    0.200509    -0.0767642   -0.0138651  -0.345253
  0.21706    -0.0754998    0.229843   -0.0375237   0.654025    -0.103423    0.0213545   -0.328715     -0.0492994  -0.00720689  -0.104585     0.28419     -0.33171    -0.694683    0.415022    0.11593     -0.247909     0.290104   -0.0408171    0.0519239   -0.235684    0.444487   -0.214109     0.16602      0.180634    0.352009
  0.077974    0.395795    -0.230096   -0.370659    0.139529    -0.0359357   0.124718    -0.556823      0.265551   -0.26583     -0.0829751   -0.0450099   -0.42876    -0.494901   -0.177271   -0.832043    -0.289065    -0.0168118  -0.41447     -0.557172    -0.0685869   0.614787   -0.433148     0.0268309   -0.830069   -0.187611
  0.173375    0.0431643    0.258154    0.430769   -0.220024     0.10769     0.429505     0.110032     -0.0022441   1.05811      0.476929     0.955735    -0.663253   -0.33793     0.591132    0.605635     1.10268      0.239157   -0.409181     0.0463528    0.236687   -0.221134   -0.34069     -0.098954    -0.118013   -0.738126
 -0.0312637   0.190178     0.152888   -0.0599613   0.0893       0.0935431   5.52534e-5   0.0933276    -0.225675   -0.00677017   0.0718327   -0.0299494   -0.0384362  -0.111664    0.0476231  -0.266117     0.0192553   -0.0791722   0.193531    -0.0616418   -0.0330959   0.0539355   0.208408     0.0844034    0.0915055  -0.142771
 -0.965853   -0.143546     0.338531   -0.348737    0.181475    -0.142077    0.0827829   -0.702124      0.162652    0.247318    -0.377426     0.151949     0.115379   -0.0408178  -0.226872   -0.371805     0.130564     0.0657499  -0.0762572   -1.14628      0.628006   -0.0760921  -0.307773     0.0823302   -0.50787     0.244824
 -0.460072   -0.269592    -0.0315486  -0.200309    0.373715     0.315939   -0.264226    -0.100825      0.127711   -0.219535     0.0409757   -0.64672     -0.538532    0.383541    0.162531   -0.555956     0.491115    -0.162495   -0.306761    -0.428018    -0.654367    0.195546    0.66513      0.252578     0.0383892   0.230875
 -0.126875   -0.625934    -0.280255   -0.295018    0.892687     0.512033    0.0548039    0.0243697     0.0955845  -0.192128    -0.0300781   -0.0210444    0.355913   -0.0912508   0.904238   -0.314811    -0.112743     0.154777   -0.0433617   -0.576648     0.515893    0.127432   -0.230118     0.587498     0.0911957  -0.256719
 -0.0370332   0.210863    -0.959224   -0.0352311  -0.0181565    0.57327     0.529985    -0.390314     -0.364657   -0.0388177   -0.290512     0.113588     0.0885873   0.192163   -0.452678    0.249696     0.0559578    0.2093      0.848981    -0.463848    -0.248178    0.508781    0.00620388  -0.877271    -0.206956   -0.42129
 -0.332955    0.52376      0.0692837  -0.389207   -0.124937     0.148191   -0.188097     0.231368     -0.304037   -0.690679     0.387077     0.301837    -0.802082   -0.112951   -0.262049   -0.00695346  -0.271074     0.0190267  -0.0237866   -0.644985     0.304816   -0.577539   -0.209503    -0.283682    -0.0141896   0.0454993
 -0.0136371   0.204052    -0.360409    0.283852   -0.0563591   -0.267007    0.631698    -0.000597163   0.192324   -0.469413     0.15585     -0.39677     -0.832224   -0.297131    0.0837014  -0.377219     0.701069    -0.121696   -0.0347296    0.347978    -0.234981   -0.268382   -0.068562     0.920971    -0.107995    0.201521[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412812
[ Info: iteration 2, average log likelihood -1.412804
[ Info: iteration 3, average log likelihood -1.412796
[ Info: iteration 4, average log likelihood -1.412789
[ Info: iteration 5, average log likelihood -1.412782
[ Info: iteration 6, average log likelihood -1.412774
[ Info: iteration 7, average log likelihood -1.412767
[ Info: iteration 8, average log likelihood -1.412760
[ Info: iteration 9, average log likelihood -1.412753
[ Info: iteration 10, average log likelihood -1.412745
┌ Info: EM with 100000 data points 10 iterations avll -1.412745
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
