Julia Version 1.5.0-DEV.35
Commit 375347ea52 (2020-01-09 03:35 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed LegacyStrings ────── v0.4.1
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed ScikitLearnBase ──── v0.5.0
 Installed Rmath ────────────── v0.6.0
 Installed HDF5 ─────────────── v0.12.5
 Installed DataStructures ───── v0.17.7
 Installed StaticArrays ─────── v0.12.1
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed SortingAlgorithms ── v0.3.1
 Installed Missings ─────────── v0.4.3
 Installed CMakeWrapper ─────── v0.2.3
 Installed Arpack ───────────── v0.4.0
 Installed Clustering ───────── v0.13.3
 Installed Parameters ───────── v0.12.0
 Installed JLD ──────────────── v0.9.1
 Installed BinaryProvider ───── v0.5.8
 Installed SpecialFunctions ─── v0.9.0
 Installed Blosc ────────────── v0.5.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed FillArrays ───────── v0.8.2
 Installed StatsBase ────────── v0.32.0
 Installed BinDeps ──────────── v1.0.0
 Installed QuadGK ───────────── v2.3.1
 Installed URIParser ────────── v0.4.0
 Installed StatsFuns ────────── v0.9.3
 Installed DataAPI ──────────── v1.1.0
 Installed CMake ────────────── v1.1.2
 Installed NearestNeighbors ─── v0.4.4
 Installed Compat ───────────── v2.2.0
 Installed PDMats ───────────── v0.9.10
 Installed OrderedCollections ─ v1.1.0
 Installed Distances ────────── v0.8.2
 Installed FileIO ───────────── v1.2.1
 Installed Distributions ────── v0.22.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.0
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_xEFwQI/Project.toml`
 [no changes]
  Updating `/tmp/jl_xEFwQI/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_pC0qwY/Project.toml`
 [no changes]
  Updating `/tmp/jl_pC0qwY/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_dj3QHN/Project.toml`
 [no changes]
  Updating `/tmp/jl_dj3QHN/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_rNeE4q/Project.toml`
 [no changes]
  Updating `/tmp/jl_rNeE4q/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_7ICr1A/Project.toml`
 [no changes]
  Updating `/tmp/jl_7ICr1A/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_7ICr1A/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.0
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.9285410449578252e6, [97724.5640523067, 2275.4359476932937], [-2104.1837276750707 -497.53153777941424 2762.283892304416; 2066.7988430354276 867.6544977464649 -2214.708953128924], [[94552.71241328919 -1904.602593625624 742.3134810147907; -1904.6025936256237 95236.87021249329 614.6056567222304; 742.3134810147908 614.6056567222304 97287.81721040473], [4675.856742435222 1738.9903362321331 -1079.30511131142; 1738.9903362321331 4443.83426943583 15.674858270552381; -1079.30511131142 15.674858270552381 2571.322828241892]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.491163e+03
      1       8.965108e+02      -5.946518e+02 |        4
      2       8.250546e+02      -7.145615e+01 |        4
      3       8.069522e+02      -1.810241e+01 |        0
      4       8.069522e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 806.9522222911596)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.059132
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.765916
[ Info: iteration 2, lowerbound -3.621727
[ Info: iteration 3, lowerbound -3.476135
[ Info: iteration 4, lowerbound -3.328577
[ Info: iteration 5, lowerbound -3.202054
[ Info: iteration 6, lowerbound -3.119063
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.085951
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -3.070955
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -3.051726
[ Info: iteration 10, lowerbound -3.037049
[ Info: iteration 11, lowerbound -3.021020
[ Info: iteration 12, lowerbound -2.998255
[ Info: iteration 13, lowerbound -2.966697
[ Info: iteration 14, lowerbound -2.924065
[ Info: iteration 15, lowerbound -2.868017
[ Info: iteration 16, lowerbound -2.796730
[ Info: iteration 17, lowerbound -2.710637
[ Info: iteration 18, lowerbound -2.615694
[ Info: iteration 19, lowerbound -2.524813
[ Info: iteration 20, lowerbound -2.450437
[ Info: iteration 21, lowerbound -2.396230
[ Info: iteration 22, lowerbound -2.361306
[ Info: dropping number of Gaussions to 3
[ Info: iteration 23, lowerbound -2.331103
[ Info: iteration 24, lowerbound -2.310908
[ Info: iteration 25, lowerbound -2.307970
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.302917
[ Info: iteration 27, lowerbound -2.299259
[ Info: iteration 28, lowerbound -2.299256
[ Info: iteration 29, lowerbound -2.299254
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan  9 08:15:44 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan  9 08:15:52 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Thu Jan  9 08:15:55 2020: EM with 272 data points 0 iterations avll -2.059132
5.8 data points per parameter
, Thu Jan  9 08:15:57 2020: GMM converted to Variational GMM
, Thu Jan  9 08:16:06 2020: iteration 1, lowerbound -3.765916
, Thu Jan  9 08:16:06 2020: iteration 2, lowerbound -3.621727
, Thu Jan  9 08:16:06 2020: iteration 3, lowerbound -3.476135
, Thu Jan  9 08:16:06 2020: iteration 4, lowerbound -3.328577
, Thu Jan  9 08:16:06 2020: iteration 5, lowerbound -3.202054
, Thu Jan  9 08:16:06 2020: iteration 6, lowerbound -3.119063
, Thu Jan  9 08:16:07 2020: dropping number of Gaussions to 7
, Thu Jan  9 08:16:07 2020: iteration 7, lowerbound -3.085951
, Thu Jan  9 08:16:07 2020: dropping number of Gaussions to 5
, Thu Jan  9 08:16:07 2020: iteration 8, lowerbound -3.070955
, Thu Jan  9 08:16:07 2020: dropping number of Gaussions to 4
, Thu Jan  9 08:16:07 2020: iteration 9, lowerbound -3.051726
, Thu Jan  9 08:16:07 2020: iteration 10, lowerbound -3.037049
, Thu Jan  9 08:16:07 2020: iteration 11, lowerbound -3.021020
, Thu Jan  9 08:16:07 2020: iteration 12, lowerbound -2.998255
, Thu Jan  9 08:16:07 2020: iteration 13, lowerbound -2.966697
, Thu Jan  9 08:16:07 2020: iteration 14, lowerbound -2.924065
, Thu Jan  9 08:16:07 2020: iteration 15, lowerbound -2.868017
, Thu Jan  9 08:16:07 2020: iteration 16, lowerbound -2.796730
, Thu Jan  9 08:16:07 2020: iteration 17, lowerbound -2.710637
, Thu Jan  9 08:16:07 2020: iteration 18, lowerbound -2.615694
, Thu Jan  9 08:16:07 2020: iteration 19, lowerbound -2.524813
, Thu Jan  9 08:16:07 2020: iteration 20, lowerbound -2.450437
, Thu Jan  9 08:16:07 2020: iteration 21, lowerbound -2.396230
, Thu Jan  9 08:16:07 2020: iteration 22, lowerbound -2.361306
, Thu Jan  9 08:16:07 2020: dropping number of Gaussions to 3
, Thu Jan  9 08:16:07 2020: iteration 23, lowerbound -2.331103
, Thu Jan  9 08:16:07 2020: iteration 24, lowerbound -2.310908
, Thu Jan  9 08:16:07 2020: iteration 25, lowerbound -2.307970
, Thu Jan  9 08:16:07 2020: dropping number of Gaussions to 2
, Thu Jan  9 08:16:07 2020: iteration 26, lowerbound -2.302917
, Thu Jan  9 08:16:07 2020: iteration 27, lowerbound -2.299259
, Thu Jan  9 08:16:07 2020: iteration 28, lowerbound -2.299256
, Thu Jan  9 08:16:07 2020: iteration 29, lowerbound -2.299254
, Thu Jan  9 08:16:07 2020: iteration 30, lowerbound -2.299254
, Thu Jan  9 08:16:07 2020: iteration 31, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 32, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 33, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 34, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 35, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 36, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 37, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 38, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 39, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 40, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 41, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 42, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 43, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 44, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 45, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 46, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 47, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 48, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 49, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: iteration 50, lowerbound -2.299253
, Thu Jan  9 08:16:07 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777392273, 178.04509222607743]
β = [95.95490777392273, 178.04509222607743]
m = [2.0002292577748366 53.851987172458486; 4.250300733269392 79.28686694435423]
ν = [97.95490777392273, 180.04509222607743]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119573026 -0.008953123827356899; 0.0 0.012748664777411819], [0.18404155547477496 -0.007644049042334479; 0.0 0.008581705166323965]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9763695967342416
avll from llpg:  -0.9763695967342507
avll direct:     -0.9763695967342507
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9973649378145092
avll from llpg:  -0.9973649378145092
avll direct:     -0.9973649378145092
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0609532   -0.103837     -0.0726004   -0.0891061   -0.124278    -0.0481286     0.106903     0.0957521   -0.0246787    0.260528     0.201199     0.0896888   -0.0380133   -0.0466511    0.0596601     0.0141151    -0.0837685     0.0940951    0.0615764    0.172386    0.0174097    0.00944702   0.138984     0.145064      0.0330309   -0.144089
 -0.0224061   -0.139985     -0.0912489   -0.00790208  -0.190995     0.0539754    -0.0673254   -0.0663639    0.0506639   -0.00678367   0.139115    -0.00590257  -0.031118    -0.0250012   -0.0320672     0.0746512    -0.109548     -0.0515663   -0.136818     0.0727232   0.100084    -0.121022    -0.00827097  -0.0603472    -0.038756    -0.134478
 -0.020923     0.0476537     0.121835     0.0274818   -0.00241556  -0.000149896  -0.0785799   -0.0512596   -0.108894     0.0579307   -0.0961291   -0.0420438   -0.10322      0.164419     0.170592      0.0664341     0.0102903     0.0386636    0.0367855   -0.088563   -0.0228563   -0.0180319    0.0667901    0.0182884     0.158022     0.0238314
 -0.12565      0.0822772    -0.02         0.00122761  -0.121692    -0.0308661    -0.0151261    0.053577     0.0284289    0.20575     -0.00126394  -0.0854054   -0.0987194   -0.0365588   -0.0977069    -0.0299532     0.0172827    -0.0355452    0.0179608   -0.081413   -0.0636686    0.0569189    0.0750626   -0.0184408    -0.0144699   -0.0677963
  0.211536    -0.0463796    -0.101431     0.0689231    0.00544915  -0.00147182    0.0288012    0.0202484    0.0653142    0.191818     0.0593766   -0.00313625  -0.110805    -0.0211406   -0.010034      0.100073      0.0708462    -0.034299    -0.0354304   -0.0402568   0.0607715    0.17182      0.0464356    0.12115      -0.0142466    0.0422819
  0.0524493    0.0643251    -0.00746542  -0.0773479    0.0267423   -0.0715096     0.0372956   -0.0697105   -0.200438    -0.0457931    0.00327103  -0.0294048    0.00841644  -0.0336614   -0.180964     -0.0470396     0.0992732    -0.0621339   -0.103502    -0.0243101   0.0988359    0.0413959   -0.0632793    0.133181      0.0306332   -0.056796
  0.122163    -0.167998      0.105961     0.0141001   -0.00300766  -0.0188248    -0.105084     0.122563     0.124032     0.0432201   -0.200158    -0.174003     0.0827704    0.084895    -0.0633586     0.152989     -0.0372076    -0.034323    -0.12229      0.126267    0.043164     0.0147912    0.172456     0.130071     -0.0815725    0.180964
  0.138368     0.0846344    -0.19769      0.0389843   -0.0291275   -0.0630197     0.134521    -0.0443801    0.0972239    0.0530895   -0.152668    -0.172278     0.0111667    0.00982552   0.144848      0.0655745    -0.18251       0.128619    -0.0342514   -0.0132807   0.0869614    0.0519103   -0.0738639    0.0116201    -0.0119272    0.00181301
  0.0741858   -0.0466002    -0.061827     0.262741    -0.0947228    0.171675      0.0397568   -0.0559942    0.0914708    0.134207    -0.0206136    0.151038     0.0291433   -0.107426     0.0810811     0.0615144    -0.0705999    -0.0723096   -0.0338267   -0.121856   -0.0415017    0.1196      -0.0275555    0.106573     -0.0127387   -0.00115823
 -0.0212677    0.0312433     0.157332    -0.0849058    0.0211361   -0.0425667    -0.00755987  -0.0987768    0.0566618   -0.0524949    0.0649415   -0.0891418    0.0146915   -0.0143197   -0.0515921    -0.000476741  -0.05018      -0.0786013    0.0511887   -0.0721504  -0.0243098    0.0430002   -0.0839561   -0.0153891     0.0775996    0.168218
 -0.105041    -0.111331     -0.0678318    0.274844     0.0681016    0.0809986     0.0272902   -0.0210131   -0.0344631   -0.15425     -0.0841163   -0.0513377   -0.0633923    0.028892     0.00202581   -0.040243      0.0163054     0.0684827   -0.0398241    0.0757605   0.0783454    0.0846181   -0.0236787   -0.112589      0.0273066   -0.14297
  0.0766635    0.0811769     0.0945029    0.0994643   -0.103053    -0.0834908    -0.0800225    0.0114999    0.0923599   -0.0568199    0.134307    -0.020592     0.200215     0.0885223    0.0552345     0.123225     -0.021413      0.0064069    0.0150569    0.0585783  -0.017276    -0.130024     0.0526189   -0.244369     -0.179306    -0.00545406
  0.198759     7.19455e-5    0.0852571   -0.0073489    0.00536616   0.132431      0.0225444   -0.160956    -0.0309629   -0.0215418   -0.073027     0.00454699  -0.104978    -0.0670187    0.0331161    -0.0554703     0.12343      -0.0112531    0.0888443    0.139117    0.0276245   -0.0628049   -0.0251378    0.0321442    -0.159057    -0.0966197
  0.0419134   -0.0322998     0.0335205    0.0789748   -0.0650507    0.113543      0.047514    -0.0239809    0.00158501  -0.225073     0.109788     0.043726    -0.184381    -0.0108782   -0.0957513    -0.14773      -0.0265394    -0.103864     0.0103906    0.0690274   0.114192     0.029224    -0.102701     0.0592724    -0.0685345   -0.0755883
  0.0182017    0.0462439     0.186829    -0.0552111   -0.0948234    0.112431     -0.0759216    0.082065    -0.034626     0.0834352    0.16684      0.0424441    0.0316105   -0.028231    -0.150543      0.0575547    -0.0403708    -0.00973431  -0.138143     0.146069    0.174102     0.0759517   -0.11014      0.08018       0.0443977    0.0681962
  0.0283167    0.265708     -0.0459686    0.0200103    0.0599941    0.0161343    -0.126872     0.0886109   -0.12736     -0.0265973    0.00997922  -0.0473394   -0.0599876   -0.0988821   -0.000823952  -0.164701      0.0939084     0.0525536   -0.072775    -0.039581   -0.241703    -0.00812839  -0.00839048  -0.171574     -0.00240933  -0.148889
  0.00182195   0.0295936     0.0553775   -0.070973     0.0775179   -0.060875     -0.0159458   -0.00189387  -0.0120946    0.0527569    0.0666908    0.0447139    0.0114532    0.0898749    0.0177972     0.20942      -0.0550419     0.00233667   0.102577    -0.0900463  -0.0542449   -0.0882405   -0.00140884  -0.0266152     0.102304    -0.0726844
 -0.0873493    0.00295541    0.0700922    0.130598    -0.0690862   -0.0877704     0.0417044   -0.0527019    0.0725411   -0.129256    -0.124575    -0.0301184    0.209198    -0.0718469    0.0462458     0.0730157    -0.00953597   -0.0964638   -0.0617671   -0.0695426   0.141787     0.0675521   -0.197877     0.000516156  -0.0405653    0.175803
 -0.258118     0.101937      0.0281023    0.183804    -0.0142582   -0.0897571     0.0628997   -0.0464777    0.112517     0.115035    -0.0142094    0.00772366   0.0683344    0.0576431    0.154989     -0.062224     -0.0826956     0.074153    -0.210948     0.0568348   0.0891997    0.0510342   -0.0110417   -0.0560647     0.14133      0.0127852
 -0.0246926   -0.141531      0.0797484   -0.00450656  -0.0388994   -0.00966477    0.129754     0.172987     0.0521529   -0.00206787  -0.0196697   -0.0809394   -0.181983     0.0484415    0.0673963     0.02685      -0.0279701     0.279527     0.0820067   -0.0302822  -0.0282262   -0.187101    -0.0210165   -0.0181046    -0.196469     0.00862691
  0.0485497   -0.0136863     0.0427503    0.0388264   -0.151003     0.110139      0.0773876    0.0514843   -0.121359    -0.158277    -0.0118754    0.124986    -0.0133847    0.152597    -0.095335     -0.0529756    -0.151399     -0.0259878   -0.136927     0.036022    0.0510305   -0.0405588    0.115416     0.0830042    -0.0101278    0.00137504
 -0.175199    -0.00453298    0.256706     0.136124     0.00593196   0.081222     -0.309639     0.124426    -0.0450195    0.0134082    0.0384117    0.0158695    0.0600068    0.0247332   -0.0409201     0.113407     -0.17909       0.380791    -0.0666437    0.123687   -0.214145    -0.109255    -0.022166    -0.175688     -0.179693     0.125592
 -0.0465258   -0.0781929    -0.171093    -0.0590368   -0.0401532   -0.141944      0.199167    -0.0284119   -0.030423    -0.0172245    0.029585    -0.119069     0.0722903   -0.0845106    0.211011     -0.10589      -0.178795     -0.0613992   -0.0508618    0.191281    0.0522967   -0.0830371    0.0337459   -0.0763513    -0.0285745   -0.0787295
  0.0148725   -0.0262222    -0.0554091    0.0665979    0.159736     0.0156084     0.145458     0.0836756   -0.195788    -0.0132976    0.102578    -0.107092    -0.116298     0.0693778   -0.0435862    -0.006867     -0.0555032     0.209882     0.0312907    0.0358551  -0.105803     0.0668878   -0.108393     0.081054     -0.0594368   -0.0964642
  0.0880162   -0.150599     -0.0212035   -0.057963     0.0515582   -0.0282586     0.252524     0.0866804   -0.120279     0.149135     0.163047     0.0181337    0.281674    -0.0401129    0.0523821     0.0256427     0.0633548    -0.071035    -0.00859833   0.0540161   0.0142723    0.0596405   -0.0371966    0.111886      0.0435338    0.0233166
  0.11144      0.067359      0.0111797    0.0865288    0.115937     0.0675481     0.0712574   -0.0975237   -0.0131004   -0.0244143    0.050245     0.0384482   -0.0461978   -0.0209369   -0.0917315    -0.165172      0.0679912     0.125425     0.0266068    0.184141    0.0931124    0.0943576    0.21923     -0.0372447    -0.0386245    0.0818732
  0.0833802    0.14618       0.0194023    0.0798024    0.129644    -0.131066      0.0882651    0.0729014   -0.0415368    0.075709     0.0577918    0.00679842   0.0419093   -0.159713    -0.124927     -0.144038     -0.00185267   -0.176959    -0.0415028    0.0619728  -0.10515      0.0235869    0.0419519   -0.133253     -0.0170785   -0.00754228
 -0.00258081  -0.0979481    -0.0317301   -0.051679     0.0428624    0.128307     -0.00696103   0.0703566    0.0518334   -0.0401034   -0.045561    -0.0396887    0.0301008   -0.0179921    0.0787097     0.20824      -0.100559     -0.00289915   0.0328372   -0.175584   -0.0901464    0.0536775    0.17256      0.23588       0.0979221    0.0985568
  0.0483482    0.0384692     0.0017785    0.132316     0.0139222    0.125383      0.0789853    0.0610404   -0.162722    -0.066962     0.122605     0.0589495   -0.0537755    0.00991749  -0.0610302     0.157206     -0.0659764     0.0343856    0.147869    -0.0728135   0.00039666   0.0502106   -0.0848168    0.113229      0.125572     0.161476
 -0.0523566   -0.07639       0.0512121    0.0947489   -0.0534639    0.0069756     0.038488     0.206681     0.115       -0.207542     0.0159859   -0.00598505  -0.0368627    0.112964     0.0774892     0.0991307    -0.107215     -0.0892686    0.209784    -0.0145966   0.0138492   -0.0370822    0.195788    -0.0576692    -0.0261202   -0.275215
 -0.0441149   -0.129427     -0.0757423   -0.124883     0.103974     0.0255671     0.0995611    0.207966    -0.104124     0.0337481    0.0659768   -0.0536644   -0.0563123   -0.113533    -0.0323258     0.0823029     0.139753      0.0488912   -0.203451     0.0548138   0.117129     0.037919     0.0192365    0.0061148     0.147994     0.215272
 -0.11212     -0.000205139  -0.0501001    0.0680907    0.109169    -0.0110814     0.0165944   -0.122304     0.115218    -0.097605     0.0591633    0.00341199   0.12671      0.185738     0.0119192    -0.0744151     0.000799623  -0.0627608   -0.133032     0.0382789  -0.0506066   -0.0540154   -0.0421059    0.229726      0.0863047   -0.290888kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3850299568270297
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.385114
[ Info: iteration 2, average log likelihood -1.385041
[ Info: iteration 3, average log likelihood -1.384536
[ Info: iteration 4, average log likelihood -1.379237
[ Info: iteration 5, average log likelihood -1.364353
[ Info: iteration 6, average log likelihood -1.355357
[ Info: iteration 7, average log likelihood -1.352751
[ Info: iteration 8, average log likelihood -1.351351
[ Info: iteration 9, average log likelihood -1.350751
[ Info: iteration 10, average log likelihood -1.350502
[ Info: iteration 11, average log likelihood -1.350362
[ Info: iteration 12, average log likelihood -1.350270
[ Info: iteration 13, average log likelihood -1.350206
[ Info: iteration 14, average log likelihood -1.350161
[ Info: iteration 15, average log likelihood -1.350126
[ Info: iteration 16, average log likelihood -1.350097
[ Info: iteration 17, average log likelihood -1.350073
[ Info: iteration 18, average log likelihood -1.350052
[ Info: iteration 19, average log likelihood -1.350033
[ Info: iteration 20, average log likelihood -1.350017
[ Info: iteration 21, average log likelihood -1.350002
[ Info: iteration 22, average log likelihood -1.349988
[ Info: iteration 23, average log likelihood -1.349976
[ Info: iteration 24, average log likelihood -1.349964
[ Info: iteration 25, average log likelihood -1.349954
[ Info: iteration 26, average log likelihood -1.349943
[ Info: iteration 27, average log likelihood -1.349933
[ Info: iteration 28, average log likelihood -1.349923
[ Info: iteration 29, average log likelihood -1.349912
[ Info: iteration 30, average log likelihood -1.349901
[ Info: iteration 31, average log likelihood -1.349891
[ Info: iteration 32, average log likelihood -1.349880
[ Info: iteration 33, average log likelihood -1.349869
[ Info: iteration 34, average log likelihood -1.349858
[ Info: iteration 35, average log likelihood -1.349846
[ Info: iteration 36, average log likelihood -1.349834
[ Info: iteration 37, average log likelihood -1.349821
[ Info: iteration 38, average log likelihood -1.349806
[ Info: iteration 39, average log likelihood -1.349789
[ Info: iteration 40, average log likelihood -1.349767
[ Info: iteration 41, average log likelihood -1.349739
[ Info: iteration 42, average log likelihood -1.349702
[ Info: iteration 43, average log likelihood -1.349658
[ Info: iteration 44, average log likelihood -1.349607
[ Info: iteration 45, average log likelihood -1.349555
[ Info: iteration 46, average log likelihood -1.349508
[ Info: iteration 47, average log likelihood -1.349473
[ Info: iteration 48, average log likelihood -1.349447
[ Info: iteration 49, average log likelihood -1.349428
[ Info: iteration 50, average log likelihood -1.349415
┌ Info: EM with 100000 data points 50 iterations avll -1.349415
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3851135327235216
│     -1.3850405305109996
│      ⋮
└     -1.3494146882783957
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.349537
[ Info: iteration 2, average log likelihood -1.349401
[ Info: iteration 3, average log likelihood -1.348675
[ Info: iteration 4, average log likelihood -1.341604
[ Info: iteration 5, average log likelihood -1.323548
[ Info: iteration 6, average log likelihood -1.313797
[ Info: iteration 7, average log likelihood -1.310738
[ Info: iteration 8, average log likelihood -1.309185
[ Info: iteration 9, average log likelihood -1.308177
[ Info: iteration 10, average log likelihood -1.307466
[ Info: iteration 11, average log likelihood -1.306931
[ Info: iteration 12, average log likelihood -1.306525
[ Info: iteration 13, average log likelihood -1.306223
[ Info: iteration 14, average log likelihood -1.306005
[ Info: iteration 15, average log likelihood -1.305846
[ Info: iteration 16, average log likelihood -1.305726
[ Info: iteration 17, average log likelihood -1.305629
[ Info: iteration 18, average log likelihood -1.305548
[ Info: iteration 19, average log likelihood -1.305477
[ Info: iteration 20, average log likelihood -1.305409
[ Info: iteration 21, average log likelihood -1.305343
[ Info: iteration 22, average log likelihood -1.305272
[ Info: iteration 23, average log likelihood -1.305194
[ Info: iteration 24, average log likelihood -1.305105
[ Info: iteration 25, average log likelihood -1.304994
[ Info: iteration 26, average log likelihood -1.304866
[ Info: iteration 27, average log likelihood -1.304728
[ Info: iteration 28, average log likelihood -1.304628
[ Info: iteration 29, average log likelihood -1.304573
[ Info: iteration 30, average log likelihood -1.304536
[ Info: iteration 31, average log likelihood -1.304507
[ Info: iteration 32, average log likelihood -1.304481
[ Info: iteration 33, average log likelihood -1.304457
[ Info: iteration 34, average log likelihood -1.304434
[ Info: iteration 35, average log likelihood -1.304412
[ Info: iteration 36, average log likelihood -1.304390
[ Info: iteration 37, average log likelihood -1.304367
[ Info: iteration 38, average log likelihood -1.304343
[ Info: iteration 39, average log likelihood -1.304317
[ Info: iteration 40, average log likelihood -1.304291
[ Info: iteration 41, average log likelihood -1.304263
[ Info: iteration 42, average log likelihood -1.304236
[ Info: iteration 43, average log likelihood -1.304209
[ Info: iteration 44, average log likelihood -1.304184
[ Info: iteration 45, average log likelihood -1.304159
[ Info: iteration 46, average log likelihood -1.304135
[ Info: iteration 47, average log likelihood -1.304110
[ Info: iteration 48, average log likelihood -1.304085
[ Info: iteration 49, average log likelihood -1.304060
[ Info: iteration 50, average log likelihood -1.304034
┌ Info: EM with 100000 data points 50 iterations avll -1.304034
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3495367953147894
│     -1.349400726617143
│      ⋮
└     -1.3040335361623283
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.304203
[ Info: iteration 2, average log likelihood -1.303982
[ Info: iteration 3, average log likelihood -1.303253
[ Info: iteration 4, average log likelihood -1.297395
[ Info: iteration 5, average log likelihood -1.280376
[ Info: iteration 6, average log likelihood -1.266239
[ Info: iteration 7, average log likelihood -1.259351
[ Info: iteration 8, average log likelihood -1.254423
[ Info: iteration 9, average log likelihood -1.250097
[ Info: iteration 10, average log likelihood -1.246366
[ Info: iteration 11, average log likelihood -1.242962
[ Info: iteration 12, average log likelihood -1.240345
[ Info: iteration 13, average log likelihood -1.238636
[ Info: iteration 14, average log likelihood -1.237599
[ Info: iteration 15, average log likelihood -1.236993
[ Info: iteration 16, average log likelihood -1.236652
[ Info: iteration 17, average log likelihood -1.236466
[ Info: iteration 18, average log likelihood -1.236362
[ Info: iteration 19, average log likelihood -1.236297
[ Info: iteration 20, average log likelihood -1.236251
[ Info: iteration 21, average log likelihood -1.236213
[ Info: iteration 22, average log likelihood -1.236180
[ Info: iteration 23, average log likelihood -1.236151
[ Info: iteration 24, average log likelihood -1.236123
[ Info: iteration 25, average log likelihood -1.236095
[ Info: iteration 26, average log likelihood -1.236065
[ Info: iteration 27, average log likelihood -1.236029
[ Info: iteration 28, average log likelihood -1.235988
[ Info: iteration 29, average log likelihood -1.235940
[ Info: iteration 30, average log likelihood -1.235886
[ Info: iteration 31, average log likelihood -1.235832
[ Info: iteration 32, average log likelihood -1.235780
[ Info: iteration 33, average log likelihood -1.235734
[ Info: iteration 34, average log likelihood -1.235695
[ Info: iteration 35, average log likelihood -1.235662
[ Info: iteration 36, average log likelihood -1.235633
[ Info: iteration 37, average log likelihood -1.235609
[ Info: iteration 38, average log likelihood -1.235589
[ Info: iteration 39, average log likelihood -1.235571
[ Info: iteration 40, average log likelihood -1.235555
[ Info: iteration 41, average log likelihood -1.235541
[ Info: iteration 42, average log likelihood -1.235527
[ Info: iteration 43, average log likelihood -1.235516
[ Info: iteration 44, average log likelihood -1.235505
[ Info: iteration 45, average log likelihood -1.235496
[ Info: iteration 46, average log likelihood -1.235488
[ Info: iteration 47, average log likelihood -1.235481
[ Info: iteration 48, average log likelihood -1.235476
[ Info: iteration 49, average log likelihood -1.235471
[ Info: iteration 50, average log likelihood -1.235467
┌ Info: EM with 100000 data points 50 iterations avll -1.235467
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3042026958453166
│     -1.3039817152120927
│      ⋮
└     -1.2354665461591958
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.235702
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.235430
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.234360
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.223459
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.191762
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.178575
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.171687
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.154240
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.167374
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.163576
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.151045
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.156026
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.167901
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.152950
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.157741
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.159027
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.157838
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.159572
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.160625
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.148965
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.164546
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.162525
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.150528
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.155560
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.167593
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.152546
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.157191
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.158508
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.157645
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.159244
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.160228
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.148506
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.164368
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.162250
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.150137
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.155043
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.167317
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.152071
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.156494
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.157616
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.156881
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.158131
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.158953
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.147134
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.163233
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.160922
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.148774
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.153703
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.166260
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.150938
┌ Info: EM with 100000 data points 50 iterations avll -1.150938
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2357015613549591
│     -1.2354300201301196
│      ⋮
└     -1.1509375291746904
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     3
│     4
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.155804
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.151216
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     3
│     4
│     5
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.144838
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.130293
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     10
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.080053
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     18
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.045654
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.050730
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.041742
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.020802
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.042982
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     13
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.028910
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.032598
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.041553
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.030530
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.020235
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     3
│     4
│     5
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.051377
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     10
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.027008
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.031447
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│      8
│     13
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.032996
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│     10
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.037342
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.030073
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.038582
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│      8
│     13
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.027501
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.027760
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     3
│     4
│     5
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.036429
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     13
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.013102
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│      8
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.032354
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│     10
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.019050
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│      8
│     13
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.026192
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     12
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.024823
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     3
│     4
│     5
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.028777
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.010583
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.038280
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│     10
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.015393
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.011762
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.036682
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     12
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.016817
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│     10
│     13
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.022371
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│      8
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.026274
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.027123
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.011955
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.036688
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│      8
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.016801
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.010130
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.038245
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│     10
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.015391
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.011756
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.027376
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│     12
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.020367
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│     10
│     13
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.018814
┌ Info: EM with 100000 data points 50 iterations avll -1.018814
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1558037241296837
│     -1.1512162425013364
│      ⋮
└     -1.0188139408182664
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3850299568270297
│     -1.3851135327235216
│     -1.3850405305109996
│     -1.3845364590610432
│      ⋮
│     -1.0273761057598219
│     -1.0203668515867583
└     -1.0188139408182664
32×26 Array{Float64,2}:
 -0.0171317    0.0260357     0.185148    -0.0331096    0.0191368   -0.0639461    0.0797476   -0.08712      0.137829    -0.06662      0.0726844   -0.0862508     0.0177945   -0.0220526    0.0377095    0.0126362   -0.0376572    0.0535115     0.0329797    -0.121486     0.00932012   0.219206    -0.0634706   -0.0129021  -0.564772     0.17997
 -0.0120251    0.0365945     0.0776132   -0.132346     0.0204741   -0.0657527   -0.0918875   -0.115677     0.026275    -0.0524776    0.0618689   -0.0928265     0.0119908   -0.0103379   -0.0500819    0.00144315  -0.049045    -0.125331      0.0455158    -0.00384333  -0.0313025   -0.211053    -0.0865692   -0.0177146   0.712048     0.152067
 -0.116906    -0.143707     -0.0360303    0.00151194  -0.109458     0.00670761   0.268073     0.0567535    0.00611449   0.321995    -0.00543552  -0.0754824     0.154597    -0.0347132   -0.126396    -0.0870408    0.0296951   -0.0708834    -0.00866085   -0.197221    -0.0393027    0.101896    -0.435514     0.234894    0.0594752   -0.0677484
 -0.130413     0.288738     -0.00808452   0.00154548  -0.126157    -0.0827977   -0.27756      0.0634253    0.0472391    0.114975    -0.00372805  -0.084486     -0.348288    -0.035237    -0.0497909    0.0685695    0.00788267   0.00379767    0.0349885     0.00469511  -0.0571252   -0.0106374    0.518643    -0.209311   -0.0203896   -0.0526662
 -0.0488424    0.51528      -0.0758487   -0.226853     0.121881    -0.0430159    0.0877916    0.209541    -0.189469     0.032753     0.0607407   -0.0573321    -0.0499454   -0.142672    -0.0296978    0.139653     0.146795     0.313449     -0.206093      0.527624     0.106293     0.0466822    0.0688312   -0.365149   -0.0475033    0.227173
 -0.043977    -0.450385     -0.0756425   -0.023764     0.103527     0.316093     0.0914817    0.203327     0.0288536    0.0330711    0.0674844   -0.00339089   -0.0516074   -0.0848255   -0.0267116    0.072687     0.147137    -0.228728     -0.201167     -0.708102     0.10405      0.0517159    0.0173175   -0.791594    0.558838     0.222545
 -0.0429157   -0.541949     -0.0757264   -0.104895     0.105053     0.0629862    0.0446164    0.208176    -0.0658239    0.0329398    0.0651128   -0.0583849    -0.0307379   -0.150158    -0.0329611    0.0179777    0.132411    -0.0200229    -0.205964      0.163798     0.127218     0.0579988    0.0410366    0.958755    0.0116634    0.220162
 -0.0662253   -0.0964663    -0.0734263   -0.0879281   -0.108482    -0.021167     0.124018     0.0976606   -0.0679337    0.264105     0.195068     0.141128     -0.063047    -0.0511319    0.0394748    0.0138773   -0.103086     0.090326      0.025987      0.169108     0.039376     0.00970953   0.140079     0.140569    0.0278576   -0.144545
  0.0704416   -0.0550473    -0.064085     0.240045    -0.109336     0.172582     0.0383954   -0.0585125    0.0920884    0.144403    -0.0154017    0.150684      0.00177411  -0.110023     0.0647039    0.078441    -0.0708677   -0.0835133    -0.0451237    -0.13383     -0.0385798    0.109637    -0.0259809    0.0991656  -0.0109623   -0.00269326
  0.0806446    0.0807484     0.0685096    0.095097    -0.0986457   -0.0837344   -0.0918694    0.0162222    0.0953679   -0.0539298    0.131827    -0.0196082     0.174996     0.108877     0.0502986    0.141975    -0.0109947    0.0170355    -0.000540462   0.0620321   -0.0199715   -0.133582     0.0553134   -0.244198   -0.173946     0.00469594
  0.192128    -0.0119292     0.0986672    0.057773    -0.315016     0.166817    -0.0203644    0.0798744   -0.130783     0.0206005   -0.361898     0.0760792    -0.0109209    0.0278608    0.0658237   -0.0693695   -0.23311      0.021277     -0.260084      0.105055     0.0487046   -0.0482683    0.0643165    0.120226    0.00573506  -0.0332322
 -0.00838362  -0.0154468    -0.0327372    0.032553     0.0455363    0.0477321    0.155936     0.0501491   -0.11244     -0.259301     0.25368      0.141153     -0.0152238    0.264197    -0.206946    -0.0286014   -0.0777574   -0.0593884    -0.0520682     0.0295616    0.0561084   -0.0296449    0.143933     0.0910435  -0.0287521    0.0108086
 -0.00629778  -0.0917813    -0.0568544   -0.0735976    0.0398956    0.130691    -0.0103097    0.0306084    0.0108286   -0.0281349   -0.0628919   -0.034032      0.0336162   -0.0258646    0.0684617    0.210782    -0.16323     -0.00387223    0.0360751    -0.172789    -0.0973475    0.0435754    0.171844     0.232623    0.0720998    0.092649
  0.134268     0.0831376    -0.202314     0.0579908   -0.0118538   -0.0610318    0.13476     -0.0364008    0.0251668    0.00193847  -0.141374    -0.194436      0.0146195   -0.00126777   0.132044     0.0577038   -0.17687      0.134728     -0.00438234   -0.00769756   0.0855877    0.0332515   -0.0673835    0.0202703   0.0297949    0.00381119
 -0.0341445   -0.140352     -0.0984773    0.0203905   -0.187877     0.0534836   -0.0776726   -0.0619972    0.0459958   -0.0063861    0.135764    -0.0129915    -0.0570095   -0.0227302   -0.0750039    0.029616    -0.110871    -0.0457577    -0.145185      0.0745151    0.107609    -0.109151    -0.0089697   -0.0652606  -0.0408664   -0.141397
 -0.0877629   -0.070137      0.200537     0.0712617   -0.0106717    0.0296893   -0.0795903    0.144028    -0.00654643  -0.00686765   0.00779749  -0.0149397    -0.0295988    0.0355182    0.0222015    0.0946707   -0.118232     0.305302      0.00767113    0.0478139   -0.130538    -0.143904    -0.0276609   -0.115083   -0.176291     0.11148
  0.210055    -0.0237541    -0.146021     0.0858482    0.0195478   -0.0308746    0.0253837    0.0179217    0.126592     0.148807     0.0589639   -0.000840342  -0.100483    -0.0510628   -0.00918468   0.0990229    0.069911    -0.0299349    -0.0215949    -0.0436877    0.0485203    0.161347     0.0331244    0.106556   -0.0349381    0.0281277
 -0.0031265   -0.0415187     0.0455943   -0.0411992    0.0662052   -0.041466    -0.0133499    0.0118842   -0.0229808    0.0479205    0.0314304    0.0457046     0.00682417   0.105512     0.0182729    0.193834    -0.0286544   -0.00134955    0.099503     -0.0778113   -0.0435204   -0.056155    -0.0105729   -0.030991    0.0977331   -0.053347
  0.0963524   -0.179002      0.130518     0.0118476   -0.00183748  -0.025933    -0.0862678    0.122686     0.129285     0.0360572   -0.197983    -0.193607      0.0890895    0.11269     -0.0828916    0.128033    -0.0312782   -0.0214242    -0.144193      0.122358     0.0360353    0.0439961    0.197805     0.122867   -0.0834559    0.169531
  0.0651114    0.0127044     0.00494943   0.135838     0.0116824    0.116105     0.0804363    0.077709    -0.129875    -0.0661853    0.123854     0.0619636    -0.0507839    0.032615    -0.0683138    0.153776    -0.0635074    0.038681      0.140596     -0.072689     0.00255289   0.045779    -0.0680153    0.0634486   0.0981797    0.183479
 -0.0233197    0.0588365     0.100658     0.0319922    0.00446483  -0.00104101  -0.0750762   -0.0568025   -0.104884     0.059864    -0.104526    -0.0560302    -0.104342     0.138115     0.172606     0.0646294    0.0107121    0.0345498     0.0496142    -0.0985933   -0.0688642   -0.0161436    0.0628359    0.0241102   0.157096     0.0196861
  0.0190341   -0.0127554    -0.0472378    0.0811143    0.175206     0.0213734    0.134963     0.0783555   -0.188763    -0.0548891    0.07678     -0.0908955    -0.123011     0.0938818   -0.0458353    0.0134421   -0.0524603    0.216253      0.0323018     0.0318018   -0.105282     0.0693072   -0.107868     0.0806208  -0.0705531   -0.102765
 -0.0367171   -0.0613394     0.0317858    0.0862505   -0.0330446   -0.00431809   0.0152954    0.20755      0.12991     -0.181304     0.0277513    4.16554e-5   -0.0482818    0.106498     0.125134     0.110164    -0.104737    -0.0901273     0.209794     -0.0215977   -0.00727499  -0.0412602    0.193565    -0.0687057  -0.0138946   -0.282215
 -0.0189195   -0.0120537    -0.0322306    0.0936727    0.0450096   -0.0102973    0.0567546   -0.0558518   -0.121341    -0.0819076   -0.0451508   -0.0421503    -0.0178816   -0.00492785  -0.0944375   -0.0543457    0.0722622    0.00975728   -0.0839294     0.0288941    0.091334     0.0667015   -0.0458976    0.0343419   0.0124877   -0.103327
 -0.11254      0.112818      0.0527202    0.123544     0.0731738   -0.0758014    0.0760682   -0.00455714   0.0259217    0.0831042    0.0498452    0.00395516    0.0615625   -0.0244808   -0.00733484  -0.109108    -0.0232641   -0.0590718    -0.0997576     0.0598819   -0.0101089    0.0330513    0.0195172   -0.0988162   0.049834     0.0265226
  0.195487    -0.000521475   0.0832912   -0.030671     0.00406236   0.116513     0.00831744  -0.177525    -0.0301217   -0.0201008   -0.0755303   -0.0205148    -0.0904118   -0.0666088    0.0299692   -0.0585768    0.124767    -0.00382983    0.0719133     0.13615      0.0270005   -0.0405153   -0.0128543    0.0358419  -0.156163    -0.106305
  0.0169135   -0.0570152    -0.0903824   -0.0400095    0.00220059  -0.108597     0.226149     0.0560546   -0.0688778    0.0680105    0.0875117   -0.0511676     0.171887    -0.0665344    0.133195    -0.0294017   -0.0550733   -0.0642858    -0.0251439     0.110788     0.035254    -0.00754463   0.00928284   0.0174929   0.00541227  -0.0181742
 -0.0792986    0.00327421   -0.00522252   0.120357     0.0330552   -0.051454     0.0314832   -0.0877444    0.10849     -0.0969047   -0.0339125   -0.0210342     0.165388     0.0586247    0.0401801    0.00112681  -0.0179445   -0.0779344    -0.0937786    -0.0072559    0.0395064   -0.00180514  -0.11024      0.112067    0.00378957  -0.0557222
  0.0409265    0.282054     -0.0418678    0.0288914    0.0656462    0.0117123   -0.123931     0.10393     -0.130343    -0.0278856    0.00631479  -0.0401383    -0.0493905   -0.120084    -0.0142427   -0.165316     0.091704     0.0508467    -0.0558389    -0.0273435   -0.223147    -0.00256033  -0.00916019  -0.217095   -0.0153637   -0.168067
  0.113391     0.0712449     0.0289406    0.0869748    0.12069      0.0688401    0.0701056   -0.100529    -0.00971548  -0.0236871    0.05398      0.0829214    -0.0452355   -0.0165763   -0.0894094   -0.158452     0.0268282    0.104582      0.0630412     0.168339     0.100741     0.0968944    0.25336     -0.0343638  -0.0541566    0.076726
  0.0428415   -0.0233483     0.0320641    0.106947    -0.0633405    0.115929     0.042134    -0.0706957   -0.0158025   -0.223243     0.0700189    0.0475402    -0.183459     0.00672817  -0.0913265   -0.148538    -0.0203902   -0.0983354     0.0180902     0.0819817    0.112013     0.0384107   -0.0980583    0.0594832  -0.0989832   -0.0731983
 -0.0169774    0.0642338     0.157643    -0.0418395   -0.0976061    0.115456    -0.0742146    0.0824419   -0.0417899    0.0763093    0.184011     0.0381679     0.0311057   -0.0427076   -0.132664     0.0577726   -0.0409404   -0.000989373  -0.115645      0.144123     0.197902     0.0723794   -0.104003     0.0963276   0.0493722    0.0562709[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      7
│      8
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.020523
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     10
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.005818
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.006172
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     10
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.015387
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     12
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.010899
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.001023
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     12
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.020506
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     10
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.005802
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     17
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.006160
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     10
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.015385
┌ Info: EM with 100000 data points 10 iterations avll -1.015385
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.548880e+05
      1       6.377948e+05      -2.170932e+05 |       32
      2       6.098794e+05      -2.791543e+04 |       32
      3       5.940520e+05      -1.582741e+04 |       32
      4       5.823846e+05      -1.166737e+04 |       32
      5       5.750417e+05      -7.342869e+03 |       32
      6       5.709276e+05      -4.114127e+03 |       32
      7       5.692002e+05      -1.727401e+03 |       32
      8       5.684066e+05      -7.936097e+02 |       32
      9       5.679613e+05      -4.452723e+02 |       32
     10       5.676688e+05      -2.924917e+02 |       32
     11       5.674064e+05      -2.624180e+02 |       32
     12       5.671024e+05      -3.039916e+02 |       32
     13       5.667627e+05      -3.396943e+02 |       32
     14       5.662888e+05      -4.739319e+02 |       32
     15       5.657048e+05      -5.839944e+02 |       32
     16       5.650381e+05      -6.666624e+02 |       32
     17       5.644785e+05      -5.596598e+02 |       32
     18       5.641186e+05      -3.598651e+02 |       32
     19       5.638954e+05      -2.232374e+02 |       32
     20       5.637720e+05      -1.234242e+02 |       32
     21       5.637086e+05      -6.333885e+01 |       31
     22       5.636786e+05      -3.000675e+01 |       31
     23       5.636590e+05      -1.964400e+01 |       30
     24       5.636446e+05      -1.439196e+01 |       28
     25       5.636357e+05      -8.901024e+00 |       29
     26       5.636290e+05      -6.680959e+00 |       28
     27       5.636237e+05      -5.310189e+00 |       30
     28       5.636193e+05      -4.344519e+00 |       24
     29       5.636162e+05      -3.113427e+00 |       27
     30       5.636135e+05      -2.684597e+00 |       22
     31       5.636110e+05      -2.540636e+00 |       22
     32       5.636075e+05      -3.474832e+00 |       24
     33       5.636035e+05      -3.975492e+00 |       24
     34       5.635992e+05      -4.337143e+00 |       25
     35       5.635956e+05      -3.571737e+00 |       24
     36       5.635922e+05      -3.428692e+00 |       26
     37       5.635871e+05      -5.144500e+00 |       22
     38       5.635824e+05      -4.690819e+00 |       21
     39       5.635752e+05      -7.215154e+00 |       25
     40       5.635661e+05      -9.030940e+00 |       24
     41       5.635540e+05      -1.210570e+01 |       27
     42       5.635384e+05      -1.563402e+01 |       29
     43       5.635253e+05      -1.306732e+01 |       28
     44       5.635140e+05      -1.131918e+01 |       26
     45       5.635073e+05      -6.700044e+00 |       20
     46       5.635023e+05      -5.038502e+00 |       18
     47       5.634992e+05      -3.022758e+00 |       24
     48       5.634957e+05      -3.526297e+00 |       22
     49       5.634933e+05      -2.430053e+00 |       20
     50       5.634918e+05      -1.486558e+00 |       17
K-means terminated without convergence after 50 iterations (objv = 563491.8001401211)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.289765
[ Info: iteration 2, average log likelihood -1.253463
[ Info: iteration 3, average log likelihood -1.219530
[ Info: iteration 4, average log likelihood -1.186348
[ Info: iteration 5, average log likelihood -1.142906
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.091582
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     24
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.058819
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     16
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.046054
[ Info: iteration 9, average log likelihood -1.052824
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.002983
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     10
│     22
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.025643
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.062972
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.023916
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.005115
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     10
│     16
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -0.993433
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.018448
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.018439
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     16
│     19
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -0.972739
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     10
│     14
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -0.985906
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.030514
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -0.990625
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.002235
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      9
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -0.988702
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.015158
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     14
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -0.989028
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     16
│     19
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.966493
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.027553
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.023196
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -0.981302
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     17
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -0.969522
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.014326
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -0.999913
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -0.983581
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     14
│     17
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -0.973788
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.038247
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -0.998403
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     14
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -0.995581
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     10
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -0.999247
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.993933
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     16
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -0.992469
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      9
│     10
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -0.998341
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.016986
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -0.991753
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      9
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -0.967468
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     17
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -0.996395
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.033058
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     16
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -0.997439
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.009127
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.011280
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     16
│     19
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -0.977637
┌ Info: EM with 100000 data points 50 iterations avll -0.977637
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0112116    -0.0355047     0.0571742   -0.0689345     0.0653347    -0.0526275    -0.015541     0.0162857   -0.0067756    0.0542568    0.0411237    0.041171     0.0180737    0.10369      0.0179696    0.21118      -0.0355767    0.000632422   0.0995842   -0.0868533  -0.0546738   -0.0718788   -0.0110192   -0.0248605    0.101934    -0.039838
  0.096169     -0.18364       0.126629     0.0119204    -0.0034895    -0.027894     -0.0888969    0.122267     0.126812     0.0359136   -0.196325    -0.196017     0.089987     0.111288    -0.0835408    0.131207     -0.029103    -0.0216664    -0.140027     0.123559    0.0352451    0.0478122    0.19671      0.123154    -0.0822026    0.16727
 -0.245718      0.0963775     0.0353364    0.174266      0.00858712   -0.0707637     0.0642021   -0.101251     0.107921     0.113847     0.01582      0.00245938   0.0751571    0.0992311    0.122479    -0.0579296    -0.0733451    0.0817673    -0.20975      0.0567985   0.106691     0.0522432   -0.0115047   -0.0512258    0.141237     0.00440792
 -0.0136454     0.0314845     0.130453    -0.0842391     0.0199338    -0.0656254    -0.00929484  -0.102156     0.0796269   -0.058731     0.0668616   -0.0899697    0.0146702   -0.0160121   -0.00702487   0.00695825   -0.0431564   -0.039457      0.0394222   -0.0616485  -0.0113444   -0.003509    -0.0745596   -0.0155442    0.0924659    0.166106
  0.0704006    -0.0554249    -0.0634856    0.240175     -0.109873      0.17283       0.0385769   -0.0578661    0.0909633    0.144413    -0.0161782    0.150482     0.00197426  -0.109985     0.0651418    0.0783661    -0.0707028   -0.0833893    -0.0454736   -0.134233   -0.0388307    0.109543    -0.0259625    0.0999024   -0.0104305   -0.00280987
  0.00569976    0.0121089     0.054827     0.185819     -0.0884628    -0.102217      0.0419667   -0.0554683    0.0753356   -0.105124    -0.11726     -0.0170741    0.198896    -0.0696642    0.0456084    0.0945783    -0.02478     -0.0947102    -0.0459033   -0.0716442   0.123498     0.0567685   -0.230854    -0.00663448  -0.0491973    0.175208
  0.111868      0.0341295    -0.0882195    0.0479269    -0.0636478     0.0167561     0.107443     0.012596    -0.0421476   -0.0625853   -0.0864789   -0.0427081   -0.00125681   0.078236     0.0245062    0.00399737   -0.164213     0.0545723    -0.0724622    0.0296484   0.0696117    0.00199352   0.0210971    0.0615089    0.00777281  -0.00615538
 -0.0384643    -0.0602198     0.0314375    0.0870665    -0.0335673    -0.00454132    0.0164562    0.208752     0.131007    -0.184677     0.0285078   -0.00118476  -0.0483146    0.106347     0.125152     0.110743     -0.10464     -0.0901665     0.210325    -0.0224857  -0.00689657  -0.0397454    0.193896    -0.068802    -0.0135111   -0.2841
 -0.189778      0.000227105   0.236832     0.146868     -0.000803198   0.08206      -0.298742     0.123895    -0.0362648   -0.0142214    0.0404334    0.0253763    0.0484387    0.0338591   -0.0260262    0.139969     -0.193744     0.379739     -0.0485441    0.12347    -0.214175    -0.103932    -0.0306053   -0.189165    -0.16031      0.159989
  0.101933      0.00209675   -0.0375102    0.140172      0.0124209     0.108012      0.0747428    0.0647968   -0.0971275   -0.0546768    0.118254     0.0527321   -0.0565784    0.0274962   -0.0572305    0.149588     -0.0541542    0.0130491     0.132488    -0.0805482   0.00841348   0.0589756   -0.0585977    0.103975     0.0883791    0.162454
  0.052864      0.0705057    -0.00469021  -0.0416622     0.0264705    -0.0821168     0.0904211   -0.0780548   -0.16926     -0.0123873   -0.00436911  -0.0243546    0.0202805   -0.0297453   -0.174631    -0.0660026     0.0893187   -0.0608309    -0.109095    -0.032546    0.103096     0.0401524   -0.0621927    0.162124     0.00620488  -0.0715844
  0.086112     -0.115453     -0.0315247   -0.0633934     0.0575624    -0.0563644     0.263753     0.123329    -0.11857      0.148687     0.139295     0.0213244    0.277581    -0.041223     0.0509916    0.0370851     0.0716047   -0.0734635    -0.00670713   0.0602575   0.00666612   0.0622984   -0.0215607    0.114309     0.0372409    0.0303555
  0.0365947     0.137724      0.063182     0.076795      0.129816     -0.0759198     0.088894     0.0619794   -0.0395473    0.0579935    0.0611666    0.00759422   0.04776     -0.138707    -0.129799    -0.147446      0.0155347   -0.1831       -0.0105509    0.0596127  -0.104706     0.0245309    0.0486013   -0.132552    -0.0270743    0.0460831
 -0.0323204    -0.0677974     0.0909789    0.0689428     0.0240441     0.0718873    -0.126062     0.198638    -0.0091318    0.211576     0.0287771   -0.0139725    0.0695155    0.017071     0.0124189    0.293121     -0.0903642    0.29714      -0.0506415   -0.0400301  -0.0914029   -0.0418899    0.0631497    0.0882622    0.0816211    0.174041
 -0.00993614    0.0720352     0.164165    -0.0497808    -0.0967548     0.118065     -0.0777556    0.0812149   -0.0420446    0.0765626    0.193573     0.0421081    0.0339784   -0.0455916   -0.136869     0.0581092    -0.0463443   -0.00852303   -0.128167     0.148272    0.201282     0.0897819   -0.108469     0.0976475    0.0581548    0.0580295
 -0.000926866  -0.0913872    -0.0628809   -0.0770564     0.0435772     0.131657     -0.00844108   0.033066     0.00654749  -0.0274825   -0.0621807   -0.034688     0.0322427   -0.024336     0.0686208    0.211526     -0.155457    -0.0117339     0.0403299   -0.174928   -0.0956547    0.0468039    0.172676     0.232955     0.0614423    0.0917731
 -0.111225      0.0727551    -0.0202916    0.000757964  -0.112662     -0.0396621    -0.0106765    0.059335     0.0248684    0.208021    -0.00467647  -0.0742858   -0.102834    -0.0360401   -0.0837081    0.000537617   0.0208637   -0.0374691     0.0074227   -0.0969959  -0.0448978    0.0425988    0.0597974   -0.00261147   0.0209385   -0.051085
  0.0391374     0.285941     -0.0409826    0.0289153     0.0642189     0.0116605    -0.126197     0.103383    -0.132455    -0.0281015    0.00191221  -0.0393058   -0.0541134   -0.126528    -0.0163815   -0.166949      0.0922719    0.0505552    -0.0550404   -0.02987    -0.228331    -0.00331551  -0.0111634   -0.222933    -0.0159607   -0.171087
  0.0162451    -0.0116391    -0.0476065    0.0773183     0.177429      0.024224      0.137032     0.0787969   -0.190817    -0.0540622    0.0797791   -0.0918433   -0.12544      0.0930728   -0.0466984    0.0146096    -0.052897     0.216047      0.0336155    0.0310742  -0.107332     0.0682042   -0.107871     0.0808623   -0.0707955   -0.102942
  0.12006       0.0706427     0.0291578    0.087081      0.126414      0.0693435     0.0696576   -0.0966993   -0.0120161   -0.0236881    0.0508495    0.080276    -0.0456459   -0.0215651   -0.0897514   -0.159593      0.0297641    0.105408      0.0664835    0.171181    0.100036     0.0969235    0.257349    -0.0349691   -0.0565881    0.0784512
  0.196205     -0.00036826    0.0844296   -0.0334698     0.00306857    0.118509      0.00788337  -0.171733    -0.0306294   -0.0204017   -0.074437    -0.0227068   -0.091424    -0.0664015    0.0285696   -0.0612091     0.125265    -0.00534917    0.0740417    0.136858    0.0269285   -0.0429871   -0.012408     0.0346134   -0.159752    -0.106284
 -0.10173      -0.113034     -0.0669141    0.26088       0.0711579     0.0777714     0.0313622   -0.0314344   -0.0688117   -0.151429    -0.0815486   -0.0519671   -0.0680514    0.024769     0.00416776  -0.0239031     0.0469143    0.0688489    -0.0393963    0.0880185   0.0802297    0.104313    -0.0228577   -0.113598     0.0279451   -0.148766
 -0.0321496    -0.140367     -0.101967     0.0181373    -0.190047      0.0533231    -0.0763587   -0.0626453    0.0460533   -0.00571271   0.136034    -0.0153499   -0.0582396   -0.0229146   -0.0760099    0.0289596    -0.111081    -0.0499652    -0.146376     0.0745491   0.109194    -0.110408    -0.0088179   -0.0648466   -0.0409691   -0.143885
 -0.0553704    -0.110305     -0.0747396   -0.10784      -0.00187016    0.0332987     0.0979494    0.151904    -0.0802513    0.1505       0.131583     0.0530055   -0.0540426   -0.0890401    0.0037806    0.0446284     0.0183962    0.0718832    -0.0883313    0.117886    0.0769079    0.0295417    0.0943239    0.0709192    0.0785334    0.0402408
 -0.37193      -0.00672185   -0.0488637    0.0648649     0.0114206    -0.0523336     0.0414373    0.00198771   0.0754058   -0.111683    -0.121062    -0.185827     0.0688751   -0.0672154    0.045036     0.0966185    -0.0609493   -0.093078     -0.113361     0.0321752   0.132582     0.0900166   -0.0386722   -0.0112339   -0.0760151    0.175482
  0.0788363     0.0791215     0.0729669    0.0934425    -0.0989985    -0.0837626    -0.0923814    0.012307     0.095209    -0.0549926    0.132508    -0.0180926    0.168664     0.112824     0.0505134    0.143043     -0.0174789    0.0118431    -0.0014225    0.0643889  -0.0205786   -0.132079     0.0567307   -0.244465    -0.172922     0.00824682
  0.203335     -0.0221407    -0.164781     0.0758799     0.0135907    -0.065138      0.00890788   0.0179195    0.170568     0.210289     0.0482362   -0.00794977  -0.106524    -0.0757642   -0.00327158   0.0979442     0.101232    -0.0285514    -0.0507764   -0.0253401   0.0546563    0.174199     0.0458586    0.081679    -0.0585167    0.0133333
 -0.110691     -0.0022573    -0.0467201    0.0707043     0.133354     -0.0111414     0.0161374   -0.127787     0.136359    -0.100812     0.0568564    0.00634973   0.153588     0.186126     0.030032    -0.0875623     0.00380169  -0.061409     -0.133097     0.0427708  -0.0489684   -0.0721727   -0.00503287   0.232245     0.0565189   -0.289941
  0.0430867    -0.0226439     0.0325507    0.106834     -0.0642048     0.115365      0.0420926   -0.0705283   -0.0165783   -0.223024     0.069292     0.0478464   -0.183856     0.00774345  -0.0898532   -0.148772     -0.0190324   -0.0987118     0.019007     0.0810685   0.112031     0.0409739   -0.097783     0.0600058   -0.0985443   -0.0728173
 -0.0547348    -0.0041889    -0.151322    -0.0290207    -0.0451829    -0.148496      0.190271    -0.00367729  -0.0241413   -0.0134223    0.0496788   -0.11945      0.0711886   -0.0887825    0.213896    -0.103398     -0.173531    -0.0593689    -0.03723      0.170485    0.0530263   -0.0786327    0.0352065   -0.0752409   -0.0294963   -0.0680541
 -0.0236604     0.0589653     0.101057     0.0312116     0.00500941   -0.000244056  -0.0746859   -0.0571431   -0.105217     0.0590838   -0.103462    -0.0563206   -0.104346     0.139105     0.172577     0.0645497     0.0106543    0.034685      0.0501801   -0.0987604  -0.0694746   -0.0162986    0.062732     0.0244144    0.157069     0.0194553
  0.0192702    -0.139501      0.148758    -0.00129436   -0.028622     -0.0217288     0.137228     0.169983     0.017947    -0.00457736  -0.0259889   -0.0607833   -0.118231     0.0455909    0.068743     0.0230498    -0.0459891    0.248505      0.0753048   -0.0278766  -0.0377379   -0.191849    -0.0232702   -0.0266996   -0.196744     0.0464546[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.998876
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     10
│     17
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.953396
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     14
│     16
│     17
│     19
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.942814
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     10
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.988201
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     10
│     17
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.955803
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     14
│     16
│     17
│     19
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.950001
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     10
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.990885
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     10
│     17
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.959542
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      9
│     14
│     16
│      ⋮
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.942891
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     10
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.984621
┌ Info: EM with 100000 data points 10 iterations avll -0.984621
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0968723   -0.0446042    0.0556528   -0.0123465    0.197668    -0.0618417   -0.0451803    0.00698563   -0.0493255   -0.0382253  -0.0651837    0.0942288    -0.0720771    0.0405046   -0.0439768   0.212818   -0.0734485   -0.0352801    0.0709664   -0.0680955   -0.119906    0.00810931  -0.0836521    -0.0220885   -0.123076      0.0716162
  0.0155308   -0.0628809    0.0390566   -0.0277323   -0.0431028    0.160949    -0.01847     -0.000698041   0.0577721    0.0411997  -0.095907    -0.0317076     0.0698635   -0.109608    -0.0555226  -0.0839501   0.10719     -0.0497594   -0.00973086   0.0428092   -0.0749851   0.209536    -0.146193     -0.133809    -0.047701     -0.163745
  0.143163     0.0148238   -0.0503402   -0.155139    -0.067617     0.11485      0.131134    -0.199609      0.0651094   -0.0869922   0.0481686    0.0673892    -0.0367022   -0.249638    -0.0656683   0.0413035   0.103402     0.0585218    0.0781746    0.0597643   -0.046516    0.0788004   -0.0701111    -0.107833    -0.017817     -0.0492395
  0.107825     0.0300821    0.0340462    0.0156729    0.0273831    0.0486376   -0.0724006    0.0855364    -0.0823125   -0.212683   -0.150913    -0.0748725    -0.119033    -0.0982536   -0.077761    0.016481    0.0755498    0.110178     0.013584    -0.142388    -0.0780441  -0.0449425   -0.143065     -0.0303783   -0.0179237    -0.196649
  0.155143    -0.0111722   -0.115626    -0.0223056   -0.128083     0.082581    -0.0301092    0.00530549    0.0408525   -0.136698   -0.0327011   -0.0453151     0.0735247    0.108273     0.323426   -0.0122703   0.043588    -0.117107    -0.180169     0.0233885   -0.140386    0.104275     0.0109006    -0.0864731   -0.00464259   -0.0303396
 -0.114784    -0.122536     0.188262    -0.204924     0.0119433   -0.0918053    0.163158    -0.0222906     0.0818147   -0.0511795   0.220322     0.0414463     0.0220004   -0.18693      0.0892096  -0.144005    0.0500289   -0.195792    -0.130813    -0.197138    -0.0578378  -0.10562     -0.0866855     0.095971     0.0390582    -0.0435584
 -0.0800774   -0.00862272  -0.0372739    0.0494323    0.0610515    0.0381527   -0.0342288    0.100409      0.237828    -0.011347    0.16317     -0.137906      0.185306    -0.00347424  -0.0823268  -0.0184774  -0.177946    -0.108861     0.0456631    0.0544446   -0.0473465   0.00488894   0.0104314    -0.0253172    0.252403      0.0944738
 -0.0209616    0.124609    -0.0340786    0.019267    -0.00446764  -0.0786112   -0.0618748   -0.176543     -0.00185117   0.176212   -0.182568     0.0245963    -0.11858     -0.0010031   -0.0916485   0.110543    0.0709437   -0.0805778   -0.0176098    0.0151961    0.0123085   0.0929667   -0.0480697    -0.0143719    0.0979871    -0.069519
 -0.120313    -0.02958     -0.021454    -0.0267422   -0.0586894    0.0575738    0.129759     0.0213393     0.0251743    0.322799    0.0381479    0.0628728     0.00770163   0.029383     0.0510561  -0.172424    0.0521186   -0.0290269   -0.00707782   0.163051     0.0285854  -0.0213077    0.177889      0.0641113    0.0775941    -0.0512195
 -0.20466     -0.0109018    0.116754     0.00404977  -0.0203196   -0.0139028   -0.0316624   -0.195176     -0.0282894   -0.0403358   0.0810167   -0.166915     -0.0807579   -0.10315      0.0595137   0.0159649  -0.0272396   -0.23336     -0.154423     0.23208      0.0121853  -0.0068143    0.040657     -0.0782239    0.00803098   -0.117602
  0.0395741   -0.0316591   -0.048201     0.112139    -0.0710189    0.185541     0.0716443    0.0570425    -0.102405     0.0557846   0.151379     0.0102041     0.119513     0.0515213    0.155831   -0.0928626  -0.0180804   -0.0152056    0.0624922   -0.0333938    0.0341326   0.0888718    0.0112806     0.0122616    0.000488005   0.020803
 -0.108039    -0.150085    -0.0173755   -0.0430492    0.00704635  -0.0399355    0.0346784   -0.0319355     0.00921799  -0.0220264   0.131446    -0.196199     -0.225777    -0.118088     0.293517    0.0801007   0.0200058   -0.0538283    0.0868545    0.0213802   -0.0245946   0.142254     0.0212372     0.102081    -0.020644     -0.0717465
 -0.0787491    0.0698676   -0.0153825    0.0366058    0.00808977   0.11843     -0.0263954   -0.0400814     0.0806212   -0.165155    0.066296    -0.0385607     0.0188028    0.0301759   -0.243455   -0.103319    0.18497     -0.0531516    0.136217     0.0466923   -0.0644444  -0.0884485    0.0227519     0.0718839   -0.0772609    -0.0932946
 -0.0297234   -0.0529285   -0.00422864  -0.0289018    0.114655    -0.059682     0.131024     0.11574      -0.117623     0.0303666  -0.0348559   -0.000406783  -0.0980231    0.0138771    0.0414217   0.0376453   0.109713    -0.0523018   -0.0363609   -0.108659    -0.0696986   0.0826453   -0.14353      -0.106278     0.0953917     0.00597661
 -0.0442734    0.00145728  -0.0610811    0.0714499    0.345483    -0.181193    -0.107967    -0.169784     -0.0235896    0.131771    0.0932204   -0.0690844     0.201016    -0.141774    -0.228203    0.0890472   0.101493     0.0186957   -0.0412848    0.0589048   -0.0243697  -0.147627    -0.13892       0.0782535    0.0633816    -0.0648365
 -0.0321296    0.0411134    0.00689065   0.0168568   -0.116233    -0.0514268    0.157167    -0.0964929     0.0263089    0.0756944  -0.0285749   -0.0492123     0.0565991   -0.0932875    0.0269977  -0.149647    0.102887     0.107207     0.110676    -0.00304363  -0.0337233   0.205631     0.0661378     0.202861    -0.0246826     0.139162
  0.0662549   -0.0169227    0.0502227   -0.0292809   -0.032069    -0.0198848    0.00501757  -0.0946162    -0.00447179   0.135717   -0.0511021   -0.0802886     0.0047233    0.00530117   0.0589644  -0.057951   -0.0145286    0.0313932   -0.0663863   -0.0423224   -0.0286379  -0.0964343    0.171987     -0.029283     0.0195864    -0.0407307
  0.0790089   -0.085987     0.0214555   -0.0588326    0.0267937    0.0289333    0.0596154   -0.0608474     0.0478099    0.115957    0.124521     0.0276625    -0.0286237   -0.122365     0.0536639   0.0367709   0.137152     0.12256      0.00959378   0.130453     0.0665034   0.0274308    0.0390341     0.0750222    0.0080925     0.0218744
 -0.0689092    0.0184445   -0.0223602    0.052736    -0.0687772    0.243282    -0.00403789   0.0255507    -0.0648122   -3.6593e-5   0.0167789   -0.0225649    -0.121643    -0.130114    -0.10794    -0.0871797   0.0107188    0.0598162    0.0328289   -0.0776945    0.0471217  -0.132213    -0.0279806    -0.0657722   -0.049178     -0.187571
  0.0575013    0.106606     0.164799    -0.0133036   -0.0230115    0.105769     0.0584228    0.108488     -0.0253489    0.0975707   0.0469519    0.0189242    -0.0233739    0.120065    -0.0142811   0.114569    0.00135209  -0.189138     0.00468567  -0.052338     0.107813    0.00567253   0.13441       0.0564097    0.0405355     0.121027
  0.210767    -0.0326309   -0.0195579   -0.0248741   -0.0688678   -0.0723347   -0.0938028   -0.129166     -0.226201     0.11796    -0.0502565    0.0454677    -0.00587276   0.0299564    0.016452    0.0859043  -0.0336201    0.0977706   -0.0702296   -0.0946475   -0.100199    0.23325     -0.194177     -0.0727578    0.0932919    -0.221247
 -0.092446    -0.0993353   -0.120063     0.104142     0.0770522    0.105313    -0.0595165   -0.161264     -0.0538366   -0.147642   -0.0597172    0.000857478  -0.0127744   -0.097851     0.0452522  -0.26396     0.0110035    0.0831314   -0.156098    -0.0245646    0.0369918  -0.0738989    0.145622      0.0767839   -0.182607      0.11215
 -0.121276    -0.0398188    0.10538      0.145032     0.0927366    0.0103027    0.00754755  -0.110859      0.193531    -0.0474463   0.00694423  -0.0551951    -0.159519     0.0540423   -0.0415457   0.10355    -0.179061    -0.0396589   -0.105644     0.0448679   -0.162702    0.0368811    0.123793      0.111468    -0.0288169    -0.0467272
  0.0671461   -0.0155587    0.138405     0.0658081    0.0656633   -0.119538     0.0318823   -0.00586864   -0.088448     0.0394153  -0.132015    -0.131933     -0.0785024    0.0511187    0.0980077  -0.0715785  -0.158094     0.0551179   -0.0698728    0.0228254    0.0661825   0.0423285   -0.0989843    -0.033167    -0.0602976     0.174016
 -0.0756094    0.117353     0.053806    -0.0868926    0.0608       0.0869819    0.20907      0.148912     -0.0976904   -0.123278    0.0105504    0.0846732    -0.101797     0.208745    -0.0240197   0.0570648   0.0832108    0.0824544   -0.151754    -0.192975     0.0913508  -0.0377293   -0.05511       0.0406026    0.0482522    -0.196269
 -0.0329063    0.0877382    0.115789    -0.0912139   -0.133602     0.108687    -0.0180922    0.0414238     0.069147    -0.0642375  -0.0221675    0.0194042    -0.0618841    0.110179    -0.0285189   0.147811   -0.0858279    0.125468     0.126475     0.0889571   -0.0242705   0.0272176   -0.0129295     0.00219948   0.00844009   -0.0102182
  0.0252332   -0.0790185   -0.0359907   -0.034202    -0.0798005   -0.124592     0.143233     0.034483      0.0285755    0.0259813  -0.146084    -0.109548      0.00963357   0.0407267    0.005247    0.024372   -0.0250857    0.042632     0.0826787   -0.0117451   -0.0576503  -0.0593586   -0.0623011    -0.108993     0.180539     -0.0230925
 -0.00929169   0.0965367   -0.00469337  -0.109559    -0.101648    -0.00964787  -0.192223    -0.108084     -0.200095     0.0240535   0.0405693   -0.158653      0.075968    -0.170519     0.0754567  -0.242968    0.0028637   -0.0261799   -0.0258956   -0.121545     0.127878    0.136087     0.00397202    0.120415     0.106244     -0.086119
  0.177969     0.0307224    0.0656954    0.0178557   -0.0449435    0.0755216   -0.00963725  -0.150102     -0.129073    -0.0985961  -0.0876044    0.124155     -0.0820918   -0.214441    -0.0537922  -0.10591    -0.161673    -0.156849     0.0977301    0.0001781   -0.11029     0.00871482  -0.000560381   0.0516807    0.181349     -0.178037
  0.0404021   -0.0958673    0.120049    -0.232369     0.0285898   -0.152856    -0.158355    -0.0612923     0.0495181   -0.0108831   0.016163     0.0292458     0.111473     0.148247    -0.185028    0.0585006   0.0276739    0.00604448  -0.0900926    0.0131089    0.0329144   0.101784    -0.144354     -0.160711     0.0871685    -0.036512
 -0.0212363    0.104262     0.0292134    0.0842652   -0.143954    -0.0904811    0.0641982   -0.0211068     0.0226326    0.0353023   0.0506259   -0.0632527     0.137778    -0.170097    -0.0218307  -0.0329092  -0.179622     0.0734103    0.078451    -0.0408153    0.0115724  -0.091754    -0.0268923    -0.0390263    0.099157     -0.105489
 -0.0562024    0.0415767   -0.116469     0.065885    -0.00117893  -0.0357462   -0.00331115  -0.11749      -0.134349    -0.0226319   0.151225    -0.00286592   -0.136505    -0.0818145   -0.13398     0.0529094  -0.125987    -0.0819143   -0.114668    -0.100408     0.0345913  -0.0464399   -0.220669     -0.0510233    0.123802     -0.031909kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.417650567330909
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417670
[ Info: iteration 2, average log likelihood -1.417619
[ Info: iteration 3, average log likelihood -1.417583
[ Info: iteration 4, average log likelihood -1.417540
[ Info: iteration 5, average log likelihood -1.417482
[ Info: iteration 6, average log likelihood -1.417400
[ Info: iteration 7, average log likelihood -1.417272
[ Info: iteration 8, average log likelihood -1.417049
[ Info: iteration 9, average log likelihood -1.416634
[ Info: iteration 10, average log likelihood -1.415912
[ Info: iteration 11, average log likelihood -1.414903
[ Info: iteration 12, average log likelihood -1.413904
[ Info: iteration 13, average log likelihood -1.413229
[ Info: iteration 14, average log likelihood -1.412889
[ Info: iteration 15, average log likelihood -1.412741
[ Info: iteration 16, average log likelihood -1.412678
[ Info: iteration 17, average log likelihood -1.412651
[ Info: iteration 18, average log likelihood -1.412640
[ Info: iteration 19, average log likelihood -1.412634
[ Info: iteration 20, average log likelihood -1.412632
[ Info: iteration 21, average log likelihood -1.412630
[ Info: iteration 22, average log likelihood -1.412630
[ Info: iteration 23, average log likelihood -1.412629
[ Info: iteration 24, average log likelihood -1.412629
[ Info: iteration 25, average log likelihood -1.412628
[ Info: iteration 26, average log likelihood -1.412628
[ Info: iteration 27, average log likelihood -1.412628
[ Info: iteration 28, average log likelihood -1.412628
[ Info: iteration 29, average log likelihood -1.412627
[ Info: iteration 30, average log likelihood -1.412627
[ Info: iteration 31, average log likelihood -1.412627
[ Info: iteration 32, average log likelihood -1.412627
[ Info: iteration 33, average log likelihood -1.412627
[ Info: iteration 34, average log likelihood -1.412627
[ Info: iteration 35, average log likelihood -1.412627
[ Info: iteration 36, average log likelihood -1.412627
[ Info: iteration 37, average log likelihood -1.412626
[ Info: iteration 38, average log likelihood -1.412626
[ Info: iteration 39, average log likelihood -1.412626
[ Info: iteration 40, average log likelihood -1.412626
[ Info: iteration 41, average log likelihood -1.412626
[ Info: iteration 42, average log likelihood -1.412626
[ Info: iteration 43, average log likelihood -1.412626
[ Info: iteration 44, average log likelihood -1.412626
[ Info: iteration 45, average log likelihood -1.412626
[ Info: iteration 46, average log likelihood -1.412626
[ Info: iteration 47, average log likelihood -1.412626
[ Info: iteration 48, average log likelihood -1.412626
[ Info: iteration 49, average log likelihood -1.412626
[ Info: iteration 50, average log likelihood -1.412626
┌ Info: EM with 100000 data points 50 iterations avll -1.412626
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.417670182617532
│     -1.4176185844851241
│      ⋮
└     -1.4126258494575992
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412645
[ Info: iteration 2, average log likelihood -1.412591
[ Info: iteration 3, average log likelihood -1.412555
[ Info: iteration 4, average log likelihood -1.412511
[ Info: iteration 5, average log likelihood -1.412456
[ Info: iteration 6, average log likelihood -1.412388
[ Info: iteration 7, average log likelihood -1.412309
[ Info: iteration 8, average log likelihood -1.412224
[ Info: iteration 9, average log likelihood -1.412139
[ Info: iteration 10, average log likelihood -1.412061
[ Info: iteration 11, average log likelihood -1.411993
[ Info: iteration 12, average log likelihood -1.411935
[ Info: iteration 13, average log likelihood -1.411884
[ Info: iteration 14, average log likelihood -1.411837
[ Info: iteration 15, average log likelihood -1.411794
[ Info: iteration 16, average log likelihood -1.411752
[ Info: iteration 17, average log likelihood -1.411711
[ Info: iteration 18, average log likelihood -1.411672
[ Info: iteration 19, average log likelihood -1.411633
[ Info: iteration 20, average log likelihood -1.411596
[ Info: iteration 21, average log likelihood -1.411562
[ Info: iteration 22, average log likelihood -1.411530
[ Info: iteration 23, average log likelihood -1.411502
[ Info: iteration 24, average log likelihood -1.411476
[ Info: iteration 25, average log likelihood -1.411455
[ Info: iteration 26, average log likelihood -1.411436
[ Info: iteration 27, average log likelihood -1.411420
[ Info: iteration 28, average log likelihood -1.411406
[ Info: iteration 29, average log likelihood -1.411395
[ Info: iteration 30, average log likelihood -1.411386
[ Info: iteration 31, average log likelihood -1.411378
[ Info: iteration 32, average log likelihood -1.411371
[ Info: iteration 33, average log likelihood -1.411366
[ Info: iteration 34, average log likelihood -1.411361
[ Info: iteration 35, average log likelihood -1.411357
[ Info: iteration 36, average log likelihood -1.411354
[ Info: iteration 37, average log likelihood -1.411351
[ Info: iteration 38, average log likelihood -1.411348
[ Info: iteration 39, average log likelihood -1.411346
[ Info: iteration 40, average log likelihood -1.411345
[ Info: iteration 41, average log likelihood -1.411343
[ Info: iteration 42, average log likelihood -1.411342
[ Info: iteration 43, average log likelihood -1.411340
[ Info: iteration 44, average log likelihood -1.411339
[ Info: iteration 45, average log likelihood -1.411338
[ Info: iteration 46, average log likelihood -1.411337
[ Info: iteration 47, average log likelihood -1.411337
[ Info: iteration 48, average log likelihood -1.411336
[ Info: iteration 49, average log likelihood -1.411335
[ Info: iteration 50, average log likelihood -1.411334
┌ Info: EM with 100000 data points 50 iterations avll -1.411334
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.41264523267889
│     -1.4125914571963765
│      ⋮
└     -1.4113344275908186
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411348
[ Info: iteration 2, average log likelihood -1.411293
[ Info: iteration 3, average log likelihood -1.411251
[ Info: iteration 4, average log likelihood -1.411204
[ Info: iteration 5, average log likelihood -1.411147
[ Info: iteration 6, average log likelihood -1.411077
[ Info: iteration 7, average log likelihood -1.410993
[ Info: iteration 8, average log likelihood -1.410898
[ Info: iteration 9, average log likelihood -1.410796
[ Info: iteration 10, average log likelihood -1.410693
[ Info: iteration 11, average log likelihood -1.410596
[ Info: iteration 12, average log likelihood -1.410508
[ Info: iteration 13, average log likelihood -1.410433
[ Info: iteration 14, average log likelihood -1.410369
[ Info: iteration 15, average log likelihood -1.410314
[ Info: iteration 16, average log likelihood -1.410267
[ Info: iteration 17, average log likelihood -1.410225
[ Info: iteration 18, average log likelihood -1.410187
[ Info: iteration 19, average log likelihood -1.410152
[ Info: iteration 20, average log likelihood -1.410119
[ Info: iteration 21, average log likelihood -1.410087
[ Info: iteration 22, average log likelihood -1.410057
[ Info: iteration 23, average log likelihood -1.410028
[ Info: iteration 24, average log likelihood -1.410001
[ Info: iteration 25, average log likelihood -1.409977
[ Info: iteration 26, average log likelihood -1.409954
[ Info: iteration 27, average log likelihood -1.409934
[ Info: iteration 28, average log likelihood -1.409916
[ Info: iteration 29, average log likelihood -1.409900
[ Info: iteration 30, average log likelihood -1.409885
[ Info: iteration 31, average log likelihood -1.409873
[ Info: iteration 32, average log likelihood -1.409862
[ Info: iteration 33, average log likelihood -1.409852
[ Info: iteration 34, average log likelihood -1.409843
[ Info: iteration 35, average log likelihood -1.409835
[ Info: iteration 36, average log likelihood -1.409827
[ Info: iteration 37, average log likelihood -1.409820
[ Info: iteration 38, average log likelihood -1.409813
[ Info: iteration 39, average log likelihood -1.409807
[ Info: iteration 40, average log likelihood -1.409801
[ Info: iteration 41, average log likelihood -1.409795
[ Info: iteration 42, average log likelihood -1.409789
[ Info: iteration 43, average log likelihood -1.409783
[ Info: iteration 44, average log likelihood -1.409778
[ Info: iteration 45, average log likelihood -1.409773
[ Info: iteration 46, average log likelihood -1.409767
[ Info: iteration 47, average log likelihood -1.409762
[ Info: iteration 48, average log likelihood -1.409757
[ Info: iteration 49, average log likelihood -1.409753
[ Info: iteration 50, average log likelihood -1.409748
┌ Info: EM with 100000 data points 50 iterations avll -1.409748
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4113476176479007
│     -1.4112930645049664
│      ⋮
└     -1.409747806303507
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409755
[ Info: iteration 2, average log likelihood -1.409702
[ Info: iteration 3, average log likelihood -1.409660
[ Info: iteration 4, average log likelihood -1.409614
[ Info: iteration 5, average log likelihood -1.409560
[ Info: iteration 6, average log likelihood -1.409496
[ Info: iteration 7, average log likelihood -1.409421
[ Info: iteration 8, average log likelihood -1.409338
[ Info: iteration 9, average log likelihood -1.409248
[ Info: iteration 10, average log likelihood -1.409157
[ Info: iteration 11, average log likelihood -1.409068
[ Info: iteration 12, average log likelihood -1.408984
[ Info: iteration 13, average log likelihood -1.408905
[ Info: iteration 14, average log likelihood -1.408832
[ Info: iteration 15, average log likelihood -1.408764
[ Info: iteration 16, average log likelihood -1.408702
[ Info: iteration 17, average log likelihood -1.408646
[ Info: iteration 18, average log likelihood -1.408594
[ Info: iteration 19, average log likelihood -1.408546
[ Info: iteration 20, average log likelihood -1.408503
[ Info: iteration 21, average log likelihood -1.408463
[ Info: iteration 22, average log likelihood -1.408427
[ Info: iteration 23, average log likelihood -1.408393
[ Info: iteration 24, average log likelihood -1.408362
[ Info: iteration 25, average log likelihood -1.408332
[ Info: iteration 26, average log likelihood -1.408305
[ Info: iteration 27, average log likelihood -1.408278
[ Info: iteration 28, average log likelihood -1.408253
[ Info: iteration 29, average log likelihood -1.408229
[ Info: iteration 30, average log likelihood -1.408206
[ Info: iteration 31, average log likelihood -1.408184
[ Info: iteration 32, average log likelihood -1.408163
[ Info: iteration 33, average log likelihood -1.408142
[ Info: iteration 34, average log likelihood -1.408122
[ Info: iteration 35, average log likelihood -1.408102
[ Info: iteration 36, average log likelihood -1.408084
[ Info: iteration 37, average log likelihood -1.408066
[ Info: iteration 38, average log likelihood -1.408048
[ Info: iteration 39, average log likelihood -1.408032
[ Info: iteration 40, average log likelihood -1.408015
[ Info: iteration 41, average log likelihood -1.408000
[ Info: iteration 42, average log likelihood -1.407985
[ Info: iteration 43, average log likelihood -1.407971
[ Info: iteration 44, average log likelihood -1.407957
[ Info: iteration 45, average log likelihood -1.407944
[ Info: iteration 46, average log likelihood -1.407932
[ Info: iteration 47, average log likelihood -1.407920
[ Info: iteration 48, average log likelihood -1.407908
[ Info: iteration 49, average log likelihood -1.407897
[ Info: iteration 50, average log likelihood -1.407886
┌ Info: EM with 100000 data points 50 iterations avll -1.407886
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4097545550687849
│     -1.4097024415535855
│      ⋮
└     -1.4078864719344164
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407884
[ Info: iteration 2, average log likelihood -1.407822
[ Info: iteration 3, average log likelihood -1.407762
[ Info: iteration 4, average log likelihood -1.407694
[ Info: iteration 5, average log likelihood -1.407608
[ Info: iteration 6, average log likelihood -1.407501
[ Info: iteration 7, average log likelihood -1.407372
[ Info: iteration 8, average log likelihood -1.407224
[ Info: iteration 9, average log likelihood -1.407063
[ Info: iteration 10, average log likelihood -1.406898
[ Info: iteration 11, average log likelihood -1.406737
[ Info: iteration 12, average log likelihood -1.406586
[ Info: iteration 13, average log likelihood -1.406449
[ Info: iteration 14, average log likelihood -1.406327
[ Info: iteration 15, average log likelihood -1.406220
[ Info: iteration 16, average log likelihood -1.406125
[ Info: iteration 17, average log likelihood -1.406042
[ Info: iteration 18, average log likelihood -1.405969
[ Info: iteration 19, average log likelihood -1.405904
[ Info: iteration 20, average log likelihood -1.405845
[ Info: iteration 21, average log likelihood -1.405793
[ Info: iteration 22, average log likelihood -1.405745
[ Info: iteration 23, average log likelihood -1.405701
[ Info: iteration 24, average log likelihood -1.405660
[ Info: iteration 25, average log likelihood -1.405623
[ Info: iteration 26, average log likelihood -1.405588
[ Info: iteration 27, average log likelihood -1.405556
[ Info: iteration 28, average log likelihood -1.405525
[ Info: iteration 29, average log likelihood -1.405496
[ Info: iteration 30, average log likelihood -1.405469
[ Info: iteration 31, average log likelihood -1.405443
[ Info: iteration 32, average log likelihood -1.405418
[ Info: iteration 33, average log likelihood -1.405394
[ Info: iteration 34, average log likelihood -1.405372
[ Info: iteration 35, average log likelihood -1.405350
[ Info: iteration 36, average log likelihood -1.405330
[ Info: iteration 37, average log likelihood -1.405310
[ Info: iteration 38, average log likelihood -1.405291
[ Info: iteration 39, average log likelihood -1.405273
[ Info: iteration 40, average log likelihood -1.405256
[ Info: iteration 41, average log likelihood -1.405240
[ Info: iteration 42, average log likelihood -1.405224
[ Info: iteration 43, average log likelihood -1.405209
[ Info: iteration 44, average log likelihood -1.405195
[ Info: iteration 45, average log likelihood -1.405181
[ Info: iteration 46, average log likelihood -1.405168
[ Info: iteration 47, average log likelihood -1.405156
[ Info: iteration 48, average log likelihood -1.405144
[ Info: iteration 49, average log likelihood -1.405133
[ Info: iteration 50, average log likelihood -1.405122
┌ Info: EM with 100000 data points 50 iterations avll -1.405122
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4078842494355637
│     -1.4078215145002537
│      ⋮
└     -1.4051219486059061
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.417650567330909
│     -1.417670182617532
│     -1.4176185844851241
│     -1.4175832070918115
│      ⋮
│     -1.4051438232592317
│     -1.4051326179956416
└     -1.4051219486059061
32×26 Array{Float64,2}:
 -0.237285     0.208895    -0.247035    -0.0134674   0.655218     0.46469      0.0295646   0.156547   -0.0575801  -0.526017   -0.133643   -0.0784532  -0.46284     0.16509     -0.840551     0.189155     0.257268    0.497315   -0.188298    -0.0835883   0.136333     0.198117    -0.76087       0.0692383   -0.702832   -0.253895
  0.10689     -0.0449412   -0.133407    -0.260609    0.0710161    0.432273    -0.119948    0.331911    0.0715141  -0.96478    -0.058118   -0.320146    0.579514   -0.217842    -0.695001     0.181587     0.17746    -0.0377966  -0.117606     0.327115    0.451595     0.181308    -0.275073      0.0200677    0.388839   -0.647754
 -0.236514    -0.0142413    0.166392     0.126506   -0.104649     0.203252     0.39507    -0.0181975   0.274683   -0.0666503  -0.210131   -1.02995    -0.405407   -0.326542    -0.854391     0.69554      0.0720311   0.125397    0.218164     0.543308    0.401128     0.204002     0.363979     -0.0359772   -0.914511    0.147896
  0.0308606   -0.00743781   0.0108448    0.0793427  -0.061146     0.289901     0.241808   -0.129753   -0.0339201  -0.1815     -0.0225605   0.023725    0.0732554   0.113122    -0.219415     0.115793     0.108296    0.120292   -0.00875119  -0.0213923   0.0645588    0.0757435   -0.132183      0.0918132   -0.0285315  -0.126636
  0.420277     0.00223978   0.619431    -0.338471   -0.0187347   -0.170083     0.1833     -0.0448452   0.279537   -0.209918    0.515465    0.0129269   0.344925   -0.563758    -0.61617      0.422576     0.362127   -0.0204118   0.202849    -0.197853    0.509727    -0.161782    -0.366912      0.0197997   -0.127014   -0.0968216
  0.505489     0.170253    -0.153189    -0.271512   -0.227222     0.210775    -0.11954     0.101787   -0.101538    0.0863719   0.0286555   0.525029   -0.295508   -0.343743    -0.367594     0.437681    -0.0407227  -0.264331   -0.2349      -0.926776    0.688358     0.228943     0.361161     -0.0333236   -0.504535    0.49995
 -0.275753     0.0984241   -0.411233    -0.270858    0.0130457   -0.130094    -0.121689    0.0600887  -0.0940101   0.233604   -0.0694396  -0.267216   -0.258442    0.683466    -0.119709     0.306607    -0.208106    0.797275    0.76624      0.295491    0.871674     0.142802    -0.0544507    -0.292849    -0.222001    0.0890578
  0.00453926   0.0777041   -0.536737    -0.0736328  -0.184197     0.0236868   -0.501177    0.171691    0.0294941   0.14735     0.212044   -0.0021217   0.0669184  -0.306157    -0.143606     0.554708    -0.42035     0.53162     0.407505     0.124938    1.08528     -0.256897     0.0321805     0.133002     0.547868    0.261121
 -0.275036    -0.0182638    0.451594    -0.216053    0.191664    -0.701377    -0.381626    0.271456   -0.11111     0.428366    0.0959384  -0.367795   -0.12757    -0.625753     0.206366    -0.346003     0.0263728  -0.257573   -0.164723    -0.216829   -0.170319    -0.208285     0.0796358    -0.0814233    0.103262    0.240022
  0.0279812   -0.331525     0.0792115    0.129083    0.18069     -0.873049    -0.012576    0.7756      0.0383204  -0.132585    0.283498    0.312662    0.471192   -0.0372539    0.553951    -0.231514    -0.484477   -0.0208123   0.127589     0.0273873  -0.289632    -0.0925363   -0.295506     -0.123003     0.483488   -0.369685
  0.564854    -0.402537    -0.260163    -0.653536   -0.0546125    0.539912    -0.467457    0.0106275   0.553948    0.710627    0.684458   -0.162604    0.0151354   0.216908     0.0529278    0.0339206   -0.0879226  -0.735002    0.108277    -0.135996   -0.664367     0.330917     0.244624     -0.192806    -0.413678   -0.615039
  0.653218    -0.148025     0.55106      0.0538974  -0.197885    -0.475254    -0.395365   -0.710173    0.173643    0.277516    0.332424    0.30846    -0.487535   -0.593312     0.24494      0.447688    -0.554366   -0.89488     0.239468     0.0601889  -0.339509    -0.00302844  -0.58157      -0.217997    -0.545294    0.0295003
  0.0676455    0.721668     0.223686    -0.575676   -0.0507655    0.516214    -0.796789    0.0139308  -0.204698    0.0833779  -0.311996    0.799818    0.0700245  -0.368304     0.575134    -0.528075     0.413898    0.145448    0.458185    -0.471891   -0.00173298   0.363277    -0.367672     -0.0152098    0.526256   -0.362038
 -0.0728328    0.853693    -0.43353     -0.0850488   0.095184     0.407491     0.290858   -0.643977   -0.381083   -0.309466   -0.644265   -0.0762631  -0.0513654   0.406236     0.389027     0.00396955   0.0909143  -0.19328     0.401568     0.499614   -0.0371343    0.331512     0.0766845     0.29596      0.546551    0.777569
 -0.185171    -0.372611    -0.319954     0.173101   -0.435795     0.336667     0.0903765  -0.150371   -0.429557   -0.0101231  -0.32801     0.201936   -0.179505    1.11201      1.03423     -0.430238    -0.45233     0.0572423   0.00087298  -0.436685   -0.258906    -0.496517     0.467971     -0.0198806    0.160868   -0.420432
  0.12809     -0.0793358   -0.2772       0.658323    0.211794    -0.0785272   -0.385446   -0.75398    -0.0484936   0.805941   -0.418057    0.661042   -0.592194   -0.250106     0.567413    -0.510854     0.0731359   0.0773394  -0.727697    -0.0359141  -0.38671      0.173865     0.513141     -0.102787    -0.0133477   0.384886
 -0.191574     0.0161409    0.291906    -0.0757172  -0.300112     0.606382    -0.225192   -0.635826    0.426814   -0.101699    0.127949   -0.477578   -0.174241    0.150891    -0.124805    -0.277151     0.396758    0.0205689   0.279638     0.746954   -0.147566     0.259787     0.00288638    0.144318     0.0392812  -0.571469
 -0.242239    -0.0702847    0.116742     0.0940585   0.28092      0.0036434    0.713805   -0.265691    0.294754   -0.106749   -0.014978   -0.160005    0.0387992   0.189566    -0.156011    -0.443522     0.438167   -0.225301   -0.411571     0.425093   -1.23358      0.272383    -0.562357      0.0639285   -0.0612356  -0.470986
 -0.288723     0.170596     0.744064     0.344207   -0.602153    -0.167422     0.212334   -0.16263    -0.293306    0.285591    0.251823   -0.216117   -0.0133117  -0.0429559    0.51329      0.235071     0.194196   -0.138429    0.312309     0.171846    0.211922     0.173693    -0.123462      0.00327961   0.0484601  -0.172068
 -0.407243    -0.0466094    0.880683     0.156331    0.293481     0.127742     0.288831   -0.187065   -0.6974     -0.176518    0.152822   -0.134037    0.0242944   0.128568     0.461912     0.0464392    0.616501   -0.693017    0.149988    -0.590154   -0.471572    -0.121082     0.000514154   0.392299    -0.128128   -0.172161
  0.0513679   -0.617386    -0.0527848    0.394963   -0.330618     0.00543762   0.890918   -0.333452    0.0930173  -0.142109    0.0756622  -0.0551558   0.271198    0.448276    -0.13925      0.51243     -0.0844325  -0.248882   -0.2611       0.0339002  -0.320734    -0.252889    -0.0812815    -0.113868    -0.430084   -0.0999637
  0.476112     0.286139    -0.113175     0.698857    0.29371     -0.292828    -0.0555909  -0.308176   -0.178008    0.0618602  -0.115436    0.488017    0.315832    0.0750554    0.109465     0.450603     0.0273904   0.312446    0.133964     0.204819   -0.116608     0.0758156   -0.258639      0.0243455    0.0959563   0.173398
  0.313031    -0.0359009    0.331136    -0.0569305  -0.141319    -0.3049      -0.0118391  -0.125585    0.417315    0.293639    0.216532    0.246227   -0.0746419  -0.321842     0.273526    -0.0484501    0.138709   -0.524151   -0.262515    -0.059859   -0.270016     0.108522    -0.0767527    -0.180923    -0.0438083  -0.116247
  0.197612     0.0620379    0.102013    -0.0999942  -0.0746451   -0.198466    -0.179914    0.0166176  -0.265919   -0.0271157  -0.336158    0.357618   -0.0525509  -0.250301     0.658021     0.0284986   -0.191676    0.100191   -0.201416    -0.356888   -0.0271462    0.363605     0.74687      -0.153328     0.36231     0.0310948
 -0.254592    -0.235675     0.0675237   -0.909494    0.00125505   0.132564     0.0958191   0.178276   -0.0507985   0.0588793   0.153485   -0.373097   -0.184152   -0.0336467   -0.00739053  -0.757316    -0.176779   -0.152584   -0.262799    -0.483293   -0.206009    -0.30067      0.0284595    -0.157569     0.162613   -0.25328
  0.310936    -0.0593259   -0.0360904    0.281444    0.225914    -0.0227462   -0.0596725  -0.171094   -0.541673   -0.241628    0.134181    0.241428    0.970412   -0.00768382   0.146731    -0.50272     -0.10053    -0.598866   -0.275527    -0.680169   -0.665792    -0.35127     -0.129702      0.0297036    0.659261    0.0850243
  0.315306    -0.392004    -0.969381    -0.0964212   0.237734     0.0522716   -0.0373643   0.282493    0.144905   -0.189947   -0.259877    0.0690255   0.255151    0.137543    -0.446417    -0.102553    -0.563846    0.219864   -0.460927    -0.305952   -0.0418191   -0.112778     0.389946     -0.120375    -0.0832803   0.191992
 -0.456782    -0.0208026   -0.33912     -0.350381    0.0387547    0.317144     0.894474    0.420664   -0.166561   -0.250096   -0.114545   -0.146603    0.233107    0.379073     0.0927969   -0.542683     0.590327    0.500321   -0.782409    -0.171787    0.2096      -0.0595899    0.517973      0.257123     0.592418    0.118109
  0.0127717    0.0791711   -0.113532    -0.0408008  -0.0385777    0.168686     0.240454   -0.0704146  -0.0555066  -0.0559825   0.122319   -0.0571778  -0.0350231   0.197716    -0.162948     0.165059    -0.0394926  -0.109303    0.221868    -0.0257638   0.0116252    0.277778    -0.304096      0.148602    -0.168295    0.0475618
 -0.138227    -0.0456348   -0.00174946   0.0506488   0.0412203    0.00718494  -0.0806189   0.0441759  -0.113483   -0.0298788  -0.0816276  -0.12702     0.0406396  -0.129963    -0.0187958   -0.0728004   -0.0423612   0.141869   -0.0947677    0.0356581   0.0904422   -0.220676     0.112691     -0.0780612    0.112881   -0.11476
 -0.0566343   -0.186219    -0.0376115   -0.0707707   0.115969     0.00465347  -0.438809    0.0546827   0.204057    0.129911   -0.450798   -0.288915   -0.344881   -0.452924    -0.186162    -0.459025    -0.0843937   0.187687   -0.0961609    0.406997   -0.0778435    0.0850725    0.15387      -0.0862918    0.530543   -0.173467
 -0.755833     0.140938     0.0663212    0.16257     0.132407    -0.182364    -0.174856    0.208543    0.124392    0.275259    0.135877   -0.275002   -0.655951   -0.28208     -0.0889751   -0.22697     -0.21178     0.026065    0.00925902   0.248371   -0.137361    -0.265838     0.104555      0.244086    -0.188263    0.347582[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405112
[ Info: iteration 2, average log likelihood -1.405102
[ Info: iteration 3, average log likelihood -1.405093
[ Info: iteration 4, average log likelihood -1.405084
[ Info: iteration 5, average log likelihood -1.405076
[ Info: iteration 6, average log likelihood -1.405068
[ Info: iteration 7, average log likelihood -1.405060
[ Info: iteration 8, average log likelihood -1.405053
[ Info: iteration 9, average log likelihood -1.405045
[ Info: iteration 10, average log likelihood -1.405039
┌ Info: EM with 100000 data points 10 iterations avll -1.405039
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.613871e+05
      1       6.964340e+05      -2.649531e+05 |       32
      2       6.824299e+05      -1.400404e+04 |       32
      3       6.776987e+05      -4.731212e+03 |       32
      4       6.753259e+05      -2.372818e+03 |       32
      5       6.738089e+05      -1.517014e+03 |       32
      6       6.727500e+05      -1.058879e+03 |       32
      7       6.719402e+05      -8.098398e+02 |       32
      8       6.712848e+05      -6.553904e+02 |       32
      9       6.707407e+05      -5.440776e+02 |       32
     10       6.703235e+05      -4.172264e+02 |       32
     11       6.699828e+05      -3.406442e+02 |       32
     12       6.696505e+05      -3.323428e+02 |       32
     13       6.693609e+05      -2.895906e+02 |       32
     14       6.691324e+05      -2.284455e+02 |       32
     15       6.689362e+05      -1.962642e+02 |       32
     16       6.687419e+05      -1.943032e+02 |       32
     17       6.685576e+05      -1.842829e+02 |       32
     18       6.683832e+05      -1.743680e+02 |       32
     19       6.682240e+05      -1.592132e+02 |       32
     20       6.680540e+05      -1.700009e+02 |       32
     21       6.679107e+05      -1.433501e+02 |       32
     22       6.677790e+05      -1.317029e+02 |       32
     23       6.676586e+05      -1.203603e+02 |       32
     24       6.675521e+05      -1.065117e+02 |       32
     25       6.674523e+05      -9.977713e+01 |       32
     26       6.673597e+05      -9.263081e+01 |       32
     27       6.672744e+05      -8.524293e+01 |       32
     28       6.671921e+05      -8.237243e+01 |       32
     29       6.671053e+05      -8.672864e+01 |       32
     30       6.670146e+05      -9.077512e+01 |       32
     31       6.669204e+05      -9.410828e+01 |       32
     32       6.668293e+05      -9.115633e+01 |       32
     33       6.667434e+05      -8.592986e+01 |       32
     34       6.666589e+05      -8.449699e+01 |       32
     35       6.665783e+05      -8.060223e+01 |       32
     36       6.664930e+05      -8.522238e+01 |       32
     37       6.664220e+05      -7.107284e+01 |       32
     38       6.663479e+05      -7.409217e+01 |       32
     39       6.662756e+05      -7.225101e+01 |       32
     40       6.662072e+05      -6.842436e+01 |       32
     41       6.661341e+05      -7.308216e+01 |       32
     42       6.660660e+05      -6.813735e+01 |       32
     43       6.660090e+05      -5.700962e+01 |       32
     44       6.659442e+05      -6.479107e+01 |       32
     45       6.658763e+05      -6.786844e+01 |       32
     46       6.658070e+05      -6.927848e+01 |       32
     47       6.657409e+05      -6.610075e+01 |       32
     48       6.656784e+05      -6.250144e+01 |       32
     49       6.656177e+05      -6.069743e+01 |       32
     50       6.655634e+05      -5.429446e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 665563.4334926703)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416827
[ Info: iteration 2, average log likelihood -1.411868
[ Info: iteration 3, average log likelihood -1.410654
[ Info: iteration 4, average log likelihood -1.409861
[ Info: iteration 5, average log likelihood -1.409008
[ Info: iteration 6, average log likelihood -1.408068
[ Info: iteration 7, average log likelihood -1.407246
[ Info: iteration 8, average log likelihood -1.406707
[ Info: iteration 9, average log likelihood -1.406407
[ Info: iteration 10, average log likelihood -1.406235
[ Info: iteration 11, average log likelihood -1.406123
[ Info: iteration 12, average log likelihood -1.406038
[ Info: iteration 13, average log likelihood -1.405970
[ Info: iteration 14, average log likelihood -1.405912
[ Info: iteration 15, average log likelihood -1.405860
[ Info: iteration 16, average log likelihood -1.405814
[ Info: iteration 17, average log likelihood -1.405771
[ Info: iteration 18, average log likelihood -1.405732
[ Info: iteration 19, average log likelihood -1.405695
[ Info: iteration 20, average log likelihood -1.405660
[ Info: iteration 21, average log likelihood -1.405627
[ Info: iteration 22, average log likelihood -1.405596
[ Info: iteration 23, average log likelihood -1.405566
[ Info: iteration 24, average log likelihood -1.405538
[ Info: iteration 25, average log likelihood -1.405511
[ Info: iteration 26, average log likelihood -1.405485
[ Info: iteration 27, average log likelihood -1.405460
[ Info: iteration 28, average log likelihood -1.405437
[ Info: iteration 29, average log likelihood -1.405415
[ Info: iteration 30, average log likelihood -1.405393
[ Info: iteration 31, average log likelihood -1.405373
[ Info: iteration 32, average log likelihood -1.405353
[ Info: iteration 33, average log likelihood -1.405334
[ Info: iteration 34, average log likelihood -1.405316
[ Info: iteration 35, average log likelihood -1.405299
[ Info: iteration 36, average log likelihood -1.405283
[ Info: iteration 37, average log likelihood -1.405267
[ Info: iteration 38, average log likelihood -1.405251
[ Info: iteration 39, average log likelihood -1.405236
[ Info: iteration 40, average log likelihood -1.405222
[ Info: iteration 41, average log likelihood -1.405208
[ Info: iteration 42, average log likelihood -1.405194
[ Info: iteration 43, average log likelihood -1.405181
[ Info: iteration 44, average log likelihood -1.405168
[ Info: iteration 45, average log likelihood -1.405155
[ Info: iteration 46, average log likelihood -1.405143
[ Info: iteration 47, average log likelihood -1.405131
[ Info: iteration 48, average log likelihood -1.405119
[ Info: iteration 49, average log likelihood -1.405107
[ Info: iteration 50, average log likelihood -1.405096
┌ Info: EM with 100000 data points 50 iterations avll -1.405096
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.239249    -0.161306    -0.00336852  -0.297066     0.0937313   0.274373   -0.314156    0.0346237   0.210721   -0.0439116   -0.097927    -0.434278   -0.419212   -0.265716    -0.250821   -0.264956   -0.0778207    0.00316092   0.0461218    0.160221      0.0491444   0.0476081   0.110533    0.0217851    0.0950726  -0.214645
 -0.164349     0.903115     0.375815    -0.158088    -0.0112729   0.33143    -0.345202   -0.143903   -0.447125   -0.0501605   -0.469815     0.337059    0.0217466   0.0710635    0.747916   -0.259123    0.039568    -0.044967     0.799508     0.209318     -0.309288    0.371245   -0.196003   -0.128343     0.489936   -0.221744
  0.291112    -0.90198      0.209826    -0.317202    -0.011506    0.0510602  -0.399978    0.470213    0.340458    0.746553     0.641197    -0.0523461  -0.0723675   0.00754219  -0.441978   -0.117807   -0.192603    -0.23508     -0.148667    -0.556649     -0.179811   -0.176013    0.146004   -0.472289    -0.669028   -0.660167
 -0.298926    -0.193178     0.271112    -0.321614     0.0325814  -0.440068    0.683464    0.359844    0.375029   -0.0643278    0.650562    -0.186061    0.219395   -0.0901911   -0.0521677  -0.244723    0.0747796   -0.458678     0.170882     0.152358     -0.529075    0.132793   -0.751164    0.0199747    0.0721877  -0.197755
 -0.517625     0.279793     0.672707    -0.126398    -0.213586   -0.353595    0.0738936  -0.0968559  -0.162731    0.496424     0.420055    -0.39737    -0.290686   -0.341438     0.132654    0.0594716   0.169963     0.0661966    0.201473     0.194338      0.378398   -0.203012   -0.294686    0.0939644    0.0512584   0.069332
  0.435606     0.0136524    0.350229     0.23782     -0.129579   -0.305574   -0.383159   -0.550661    0.574212    0.0173281    0.342767     0.384962   -0.14542    -0.296463    -0.169057    0.665878   -0.054746    -0.25379      0.704863     0.317267      0.148468    0.0996899  -0.807788    0.0323879   -0.477101   -0.00439555
  0.131515    -0.00400947   0.334387     0.00100785  -0.19449    -0.236359   -0.170634   -0.132511    0.14094     0.400178     0.0926238   -0.0498291  -0.289389   -0.244932     0.258275   -0.125156    0.0591623   -0.270486    -0.0404371   -0.0631649    -0.155701    0.15398     0.0298722  -0.0791266   -0.0769467   0.155435
  0.642401     0.034132     0.332392    -0.216863     0.296676   -0.6274     -0.0894574  -0.404624   -0.472014    0.349487     0.0411771    0.125056    0.297764   -0.566082    -0.0237816   0.635386   -0.114441    -0.0645231   -0.212831    -0.296471      0.0841958  -0.18088     0.450183   -0.156018     0.0423545   0.173004
  0.557879     0.0133622    0.127764    -0.213205    -0.445128   -0.170108   -0.284186   -0.0227638   0.450101    0.281057     0.137293     0.387686   -0.292832   -0.561839     0.446125   -0.0344634  -0.251534    -0.553796    -0.283665    -0.272137     -0.102505    0.239996    0.303114   -0.0879654    0.111137    0.052866
 -0.778364     0.39207     -0.0684771    0.492993    -0.224465    0.0103231   0.81422     0.0427374  -0.506838   -0.658311    -0.639358     0.163963    0.140201    0.0534264    0.308138    0.0903568   0.338568     0.466225    -0.201819     0.195387      0.769639   -0.171993    0.166475    0.53945      0.74117     0.512575
  0.0880435   -0.0323396   -0.0389659    0.0904784   -0.164911    0.0505935   0.295917   -0.0357442  -0.0718076  -0.113437     0.121257     0.0676745   0.136175    0.0163585   -0.112003    0.315495   -0.0154751   -0.116026     0.0426661   -0.153448      0.129519    0.0767285  -0.135941    0.122671    -0.117161    0.0732073
 -0.0740779    0.356454    -0.465945    -0.52259     -0.0350554   0.527154    0.547399   -0.563201    0.579022    0.00891212   0.00625472  -0.051764   -0.587217    0.622492    -0.155147   -0.351317    0.450582    -0.00863459  -0.00615369   0.412178     -0.194463    0.710261   -0.0800738   0.119633    -0.492936    0.102695
  0.647814     0.333352     0.353194    -0.477823    -0.112361    0.650096    0.19156    -0.0169693  -0.113532   -0.840605     0.119758    -0.255845    0.250811   -0.336386    -0.763282   -0.194333    0.30605      0.137505    -0.0113157   -0.192215      0.482388   -0.0235386  -0.4323      0.0733432    0.208792   -0.145426
 -0.0304129    0.0799832    0.218014     0.222818     0.0922222  -0.160139   -0.0702687  -0.123949   -0.0123823   0.072869    -0.0594268    0.0103117   0.161393   -0.0476619    0.27395    -0.151318    0.148549     0.0468785    0.0102033    0.246226     -0.217764   -0.0861425  -0.023286   -0.112614     0.225605   -0.204018
  0.488613    -0.271988    -0.0834303    0.129188     0.332209   -0.894327   -0.295711    0.630665    0.0128257  -0.135124     0.311693     0.0498238   0.736542   -0.377612     0.0980295   0.0658985  -0.501853     0.229827     0.0425885   -0.000334857   0.0964146  -0.276073   -0.136521   -0.0109211    0.503045   -0.00108773
  0.0627541    0.0314296    0.214786     0.375078    -0.301912   -0.126485    0.32974    -0.348302   -0.672415    0.172985    -0.0553074   -0.156673   -0.106826    0.683086     0.703323    0.312571   -0.143822    -0.0367765    0.487771    -0.243057      0.0338901   0.27185     0.06391    -0.157833    -0.227721    0.132559
 -0.621169    -0.190557    -0.140886     0.436064     0.144095   -0.273857    0.0274216   0.134007    0.183344    0.281204    -0.0312126   -0.344803   -0.688281   -0.19522     -0.248135   -0.0531184  -0.402558     0.11034     -0.23415      0.432529     -0.151073   -0.236382    0.469736    0.0725579   -0.398697    0.578822
 -0.257131    -0.642373    -0.0600221    0.180881    -0.517017   -0.139389    0.073928    0.137225   -0.129719   -0.0639563   -0.0247737    0.499075   -0.122682    0.652423     1.10196    -0.433594   -0.40447     -0.0337199   -0.183468    -0.313297     -0.302537   -0.295952    0.264698   -0.125066     0.267369   -0.699723
  0.122599    -0.333539    -0.146222    -0.0394921    0.351514   -0.0494115   0.385086    0.471869    0.57676    -0.482332     0.066592     0.563039    0.192209   -0.28256     -0.182012    0.155015    0.446159     0.137987    -1.06436     -0.267111     -0.22094     0.284658   -0.111328    0.167334    -0.0253307  -0.59482
  0.00840328   0.0334194   -0.70328      0.181631     0.359424    0.124019   -0.186576    0.194281   -0.066295   -0.215101    -0.153173     0.117759    0.17756     0.394773    -0.420581    0.0439145  -0.265245     0.369972     0.0520403   -0.0754327     0.0460276  -0.0850392  -0.146428    0.0285598   -0.0568005  -0.00180586
  0.14213     -0.248451     0.326823     0.392676    -0.02741     0.0708533   0.631029   -0.489318   -0.112946    0.0172155   -0.252558     0.141964   -0.0910443   0.253675    -0.293653   -0.113698    0.0534518   -0.647664    -0.420662    -0.159153     -0.872531   -0.0439338  -0.407257   -0.209475    -0.401923    0.0197874
 -0.567991     0.0212071   -0.314945    -0.170441     0.506393    0.325675    0.136233    0.114711   -0.0350089  -0.343408    -0.168861    -0.406682   -0.115803    0.0590557   -0.512726   -0.446572    0.111745     0.240891    -0.0584531    0.270879     -0.224288   -0.0939792  -0.476265    0.192077     0.223665   -0.120128
 -0.156683     0.192632    -0.101844    -0.540085     0.0608905  -0.0756326  -0.764502    0.207789   -0.370937    0.461774    -0.283185     0.287238   -0.0815623  -0.411649     0.236428   -0.651979    5.37681e-5   0.129428     0.0151295   -0.857952      0.212557    0.0496056   0.0186002   0.0930432    0.322129    0.27093
 -0.416932    -0.112805     0.706035     0.0671271    0.431459   -0.23793     0.0301957   0.152616   -0.731109   -0.121553     0.219693    -0.207388    0.432048   -0.23199      0.697847   -0.356096    0.392046    -0.701968    -0.164224    -0.932363     -0.671145   -0.45166     0.126972    0.359084     0.117497   -0.106807
 -0.281322    -0.179867    -0.357122    -0.566085    -0.0426123   0.31462     0.537559    0.211392   -0.286325   -0.00176607  -0.128629    -0.286637    0.0854257   0.254501     0.111409   -0.571794    0.0299977    0.16687     -0.631525    -0.323541     -0.172283   -0.235481    0.625981   -0.0756322    0.35624    -0.00949812
 -0.289539     0.416517     0.506564    -0.305552    -0.399309    0.751019   -0.58159    -0.289516    0.464161   -0.0880315    0.459863    -0.253806    0.22569    -0.248848     0.0711947   0.109156    0.816416    -0.547152    -0.029068     0.510969     -0.0143442   0.386638   -0.0182386   0.0892925    0.0776245  -0.827034
 -0.0560738    0.207128    -0.786431    -0.324868    -0.235768    0.150922   -0.419865    0.013241    0.0886896   0.164897     0.0373943   -0.134582   -0.113716    0.163441    -0.0304988   0.578439   -0.364042     0.567006     0.648473     0.370892      1.11187     0.011402    0.153305   -0.0831011    0.429866    0.277306
  0.724698    -0.0334795   -0.666961    -0.087281     0.117928    0.462352    0.0710685  -0.355262   -0.214735   -0.308036    -0.140323     0.375412    0.828101    0.597243     0.13419     0.0389684  -0.104357    -0.396688    -0.0373014   -0.400346     -0.373223    0.106152    0.246945    0.00533838   0.443286   -0.0704353
  0.133645    -0.412032     0.232053     0.53827     -0.312883    0.162722    0.592415   -0.544899    0.291024   -0.116078     0.130336    -0.668186    0.226469    0.258924    -0.192649    0.248682    0.237131     0.165797     0.00659354   0.863608     -0.209814    0.0218638  -0.0543771   0.0743898   -0.122094   -0.421497
  0.508789     0.243172    -0.0521744    0.229354     0.055907    0.512174   -0.0357926  -0.388686   -0.243222   -0.033695    -0.0301124    0.287637   -0.307261   -0.384983    -0.768399    0.699433    0.163261     0.0948845   -0.00215544  -0.464016      0.754004    0.123267    0.210184    0.0941548   -0.550177    0.469938
  0.154402     0.209708    -0.353694     0.677291     0.40445    -0.0671529  -0.425585   -0.703034   -0.233905    0.516646    -0.572        0.670407   -0.348393   -0.311219     0.482601   -0.343172    0.0686986    0.219854    -0.625028     0.221662     -0.372998    0.264435    0.273765   -0.161634     0.208239    0.392794
 -0.417003     0.0409085    0.174045    -0.274259     0.0420173   0.142451    0.278005    0.448353   -0.12981    -0.491269    -0.182418    -0.583558   -0.0364457  -0.0368882   -0.83243     0.889944   -0.0806188    0.2257       0.404689     0.114262      0.58454     0.205689   -0.12032    -0.14232     -0.739544   -0.350499[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405084
[ Info: iteration 2, average log likelihood -1.405073
[ Info: iteration 3, average log likelihood -1.405062
[ Info: iteration 4, average log likelihood -1.405052
[ Info: iteration 5, average log likelihood -1.405041
[ Info: iteration 6, average log likelihood -1.405030
[ Info: iteration 7, average log likelihood -1.405020
[ Info: iteration 8, average log likelihood -1.405010
[ Info: iteration 9, average log likelihood -1.405000
[ Info: iteration 10, average log likelihood -1.404990
┌ Info: EM with 100000 data points 10 iterations avll -1.404990
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
