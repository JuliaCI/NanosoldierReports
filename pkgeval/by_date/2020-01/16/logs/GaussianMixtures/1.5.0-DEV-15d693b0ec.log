Julia Version 1.5.0-DEV.71
Commit 15d693b0ec (2020-01-15 18:13 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed LegacyStrings ────── v0.4.1
 Installed GaussianMixtures ─── v0.3.0
 Installed PDMats ───────────── v0.9.10
 Installed URIParser ────────── v0.4.0
 Installed Compat ───────────── v2.2.0
 Installed Parameters ───────── v0.12.0
 Installed StatsFuns ────────── v0.9.3
 Installed Clustering ───────── v0.13.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed OrderedCollections ─ v1.1.0
 Installed BinaryProvider ───── v0.5.8
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed DataStructures ───── v0.17.9
 Installed Distances ────────── v0.8.2
 Installed FileIO ───────────── v1.2.1
 Installed Arpack ───────────── v0.4.0
 Installed SortingAlgorithms ── v0.3.1
 Installed Missings ─────────── v0.4.3
 Installed NearestNeighbors ─── v0.4.4
 Installed DataAPI ──────────── v1.1.0
 Installed JLD ──────────────── v0.9.1
 Installed QuadGK ───────────── v2.3.1
 Installed Blosc ────────────── v0.5.1
 Installed HDF5 ─────────────── v0.12.5
 Installed Rmath ────────────── v0.6.0
 Installed StaticArrays ─────── v0.12.1
 Installed SpecialFunctions ─── v0.9.0
 Installed FillArrays ───────── v0.8.4
 Installed CMake ────────────── v1.1.2
 Installed CMakeWrapper ─────── v0.2.3
 Installed Distributions ────── v0.22.3
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed BinDeps ──────────── v1.0.0
 Installed StatsBase ────────── v0.32.0
 Installed ScikitLearnBase ──── v0.5.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_Jmajm8/Project.toml`
 [no changes]
  Updating `/tmp/jl_Jmajm8/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_T5wA0Z/Project.toml`
 [no changes]
  Updating `/tmp/jl_T5wA0Z/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_J991rQ/Project.toml`
 [no changes]
  Updating `/tmp/jl_J991rQ/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_lCPQy2/Project.toml`
 [no changes]
  Updating `/tmp/jl_lCPQy2/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_R2nBlA/Project.toml`
 [no changes]
  Updating `/tmp/jl_R2nBlA/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_R2nBlA/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.4261186796797598e7, [99375.33406558164, 624.665934418359], [-316.8147653894624 1056.6271858802336 479.00785435433363; 691.6913715059284 -1180.227954808468 -296.1728788098959], [[97556.75505987747 675.2659020996712 518.1436187662304; 675.2659020996712 97317.49173182272 -67.87378045862272; 518.1436187662304 -67.87378045862269 98937.48514709034], [1194.1554510930732 -1049.5201331165558 -234.73804121616888; -1049.5201331165558 2516.3389159650064 325.79584950382963; -234.73804121616888 325.79584950382963 825.4648543845782]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.668543e+03
      1       8.119749e+02      -8.565684e+02 |        4
      2       8.038091e+02      -8.165794e+00 |        0
      3       8.038091e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 803.8090929826312)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.048838
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.816653
[ Info: iteration 2, lowerbound -3.717415
[ Info: iteration 3, lowerbound -3.607626
[ Info: iteration 4, lowerbound -3.476892
[ Info: iteration 5, lowerbound -3.335373
[ Info: iteration 6, lowerbound -3.194336
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.060492
[ Info: iteration 8, lowerbound -2.943276
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -2.853477
[ Info: dropping number of Gaussions to 5
[ Info: iteration 10, lowerbound -2.787621
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.742807
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.702386
[ Info: iteration 13, lowerbound -2.653188
[ Info: iteration 14, lowerbound -2.593707
[ Info: iteration 15, lowerbound -2.525565
[ Info: iteration 16, lowerbound -2.459476
[ Info: iteration 17, lowerbound -2.404567
[ Info: iteration 18, lowerbound -2.362871
[ Info: iteration 19, lowerbound -2.332369
[ Info: iteration 20, lowerbound -2.313089
[ Info: iteration 21, lowerbound -2.307461
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.302927
[ Info: iteration 23, lowerbound -2.299261
[ Info: iteration 24, lowerbound -2.299256
[ Info: iteration 25, lowerbound -2.299255
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan 16 19:22:56 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan 16 19:23:04 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Thu Jan 16 19:23:06 2020: EM with 272 data points 0 iterations avll -2.048838
5.8 data points per parameter
, Thu Jan 16 19:23:08 2020: GMM converted to Variational GMM
, Thu Jan 16 19:23:17 2020: iteration 1, lowerbound -3.816653
, Thu Jan 16 19:23:17 2020: iteration 2, lowerbound -3.717415
, Thu Jan 16 19:23:17 2020: iteration 3, lowerbound -3.607626
, Thu Jan 16 19:23:17 2020: iteration 4, lowerbound -3.476892
, Thu Jan 16 19:23:17 2020: iteration 5, lowerbound -3.335373
, Thu Jan 16 19:23:17 2020: iteration 6, lowerbound -3.194336
, Thu Jan 16 19:23:17 2020: dropping number of Gaussions to 7
, Thu Jan 16 19:23:17 2020: iteration 7, lowerbound -3.060492
, Thu Jan 16 19:23:17 2020: iteration 8, lowerbound -2.943276
, Thu Jan 16 19:23:17 2020: dropping number of Gaussions to 6
, Thu Jan 16 19:23:17 2020: iteration 9, lowerbound -2.853477
, Thu Jan 16 19:23:17 2020: dropping number of Gaussions to 5
, Thu Jan 16 19:23:17 2020: iteration 10, lowerbound -2.787621
, Thu Jan 16 19:23:17 2020: dropping number of Gaussions to 4
, Thu Jan 16 19:23:17 2020: iteration 11, lowerbound -2.742807
, Thu Jan 16 19:23:17 2020: dropping number of Gaussions to 3
, Thu Jan 16 19:23:17 2020: iteration 12, lowerbound -2.702386
, Thu Jan 16 19:23:17 2020: iteration 13, lowerbound -2.653188
, Thu Jan 16 19:23:17 2020: iteration 14, lowerbound -2.593707
, Thu Jan 16 19:23:17 2020: iteration 15, lowerbound -2.525565
, Thu Jan 16 19:23:17 2020: iteration 16, lowerbound -2.459476
, Thu Jan 16 19:23:17 2020: iteration 17, lowerbound -2.404567
, Thu Jan 16 19:23:17 2020: iteration 18, lowerbound -2.362871
, Thu Jan 16 19:23:17 2020: iteration 19, lowerbound -2.332369
, Thu Jan 16 19:23:17 2020: iteration 20, lowerbound -2.313089
, Thu Jan 16 19:23:17 2020: iteration 21, lowerbound -2.307461
, Thu Jan 16 19:23:17 2020: dropping number of Gaussions to 2
, Thu Jan 16 19:23:17 2020: iteration 22, lowerbound -2.302927
, Thu Jan 16 19:23:17 2020: iteration 23, lowerbound -2.299261
, Thu Jan 16 19:23:17 2020: iteration 24, lowerbound -2.299256
, Thu Jan 16 19:23:17 2020: iteration 25, lowerbound -2.299255
, Thu Jan 16 19:23:17 2020: iteration 26, lowerbound -2.299254
, Thu Jan 16 19:23:17 2020: iteration 27, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 28, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 29, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 30, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 31, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 32, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 33, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 34, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 35, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 36, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 37, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 38, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 39, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 40, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 41, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 42, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 43, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 44, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 45, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 46, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 47, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 48, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 49, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: iteration 50, lowerbound -2.299253
, Thu Jan 16 19:23:17 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601646, 95.9549077739835]
β = [178.04509222601646, 95.9549077739835]
m = [4.2503007332698886 79.28686694436155; 2.000229257775348 53.85198717246117]
ν = [180.04509222601646, 97.9549077739835]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554748416 -0.00764404904232772; 0.0 0.008581705166333286], [0.3758763611948799 -0.008953123827346726; 0.0 0.012748664777409487]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -1.0013715761252329
avll from llpg:  -1.0013715761252349
avll direct:     -1.0013715761252349
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.9799190522401943
avll from llpg:  -0.9799190522401943
avll direct:     -0.9799190522401943
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.13825     -0.0741642   -0.107307    0.0633345    0.0415096   0.149035    -0.0622759   -0.0524301    0.117713     0.109899     0.0944142    0.0569527   -0.12284      0.0477335   0.0813371     0.0923027   -0.225907    -0.035525    -0.0390161  -0.0194603     0.0489423    0.0887303  -0.0873619    0.105315    -0.127021    -0.137007
 -0.0170097   -0.128326    -0.100301   -0.302624    -0.166654    0.190158    -0.105959     0.107545     0.0318423    0.0399049    0.0997796   -0.0949363   -0.196009    -0.0967121   0.0295976     0.104334    -0.107676    -0.0690933    0.03429    -0.17046      -0.15817      0.093127   -0.142888    -0.0775138    0.0627636   -0.204815
  0.044025     0.035611     0.0556201  -0.0346742    0.127878    0.0380611    0.0285882    0.0890355    0.0377895    0.292612    -0.113427     0.141332     0.0218715    0.0933913   0.0181246     0.0868333    0.0788874   -0.0447564    0.135366    0.0719794    -0.0431268   -0.133083    0.0529975   -0.113509    -0.0542039   -0.0270955
  0.0805834   -0.0308024    0.0433322   0.276274    -0.0692828  -0.0690855   -0.209498    -0.00881959   0.0499827   -0.0858107    0.0632782   -0.00906454   0.0709307   -0.128409    0.181411     -0.0117338    0.0119698   -0.0420632   -0.0152531  -0.0021103    -0.114841     0.10077    -0.0781773   -0.243269    -0.0865921   -0.14886
  0.0600605   -0.00936994   0.0521164  -0.0615459    0.141234    0.154876    -0.0201538    0.0746377    0.0505463   -0.0274286    0.0383603    0.0803408    0.106328    -0.085254   -0.0490378     0.117905    -0.0410076   -0.114623     0.0253465   0.014428     -0.065336     0.0263078   0.0980165    0.149888     0.0284745   -0.0784351
 -0.0514724    0.0133975    0.0235781  -0.0778033   -0.0616269  -0.0340836    0.0266591   -0.0127107    0.0967596    0.0500012    0.121994    -0.0908815   -0.0214939    0.0730773   0.252096      0.0384048    0.0352829   -0.0143037    0.111039   -0.0807399    -0.0529105    0.0487183  -0.0516373    0.0648806   -0.0369285   -0.118457
 -0.075715     0.0553573    0.185872    0.0356079    0.0123606  -0.125909    -0.032681     0.0129652    0.011436    -0.00417368  -0.170069     0.0385059    0.209325     0.0399462  -0.00695463    0.0425838   -0.0801232   -0.0934376   -0.154427   -0.0892108     0.0127126    0.154322    0.0485033    0.0206767    0.0304813    0.0442989
  0.0273382   -0.0625611    0.178007    0.0187756    0.0736646  -0.0331095    0.0691669    0.0903901    0.0856472    0.120667    -0.0273587   -0.0118015   -0.187932     0.0208404  -0.0580672    -0.0580785    0.0952332    0.235885     0.183662   -0.038716      0.126228     0.14102     0.0526671    0.151869    -0.124274    -0.133623
  0.0317004    0.0970436   -0.104561   -0.0118233   -0.011188   -0.00629016  -0.0306771   -0.0104907   -0.0108343   -0.111462    -0.0146364    0.002233    -0.154532     0.178815   -0.079265     -0.252654     0.00252967   0.0829299    0.0443828   0.0671871     0.0713455    0.0512357  -0.0737285    0.113871    -0.0518035    0.0427564
 -0.0110417   -0.0566768   -0.0229898   0.0364133    0.136898   -0.0824934    0.0210714    0.0021446    0.0247057    0.0108061    0.0355966   -0.0381852    0.0293254   -0.139114    0.0113788    -0.0624643   -0.203405    -0.0215476    0.0562617  -0.0434867    -0.0995117    0.0806024  -0.00980673   0.0664198   -0.0427499    0.0866683
  0.0421002    0.0421169   -0.103792   -0.0790767   -0.0376634  -0.105381     0.111534    -0.1894       0.0321943   -0.0627646   -0.04622      0.116776    -0.134452     0.0700768   0.0298263     0.0780508    0.10539     -0.0746503   -0.0221313   0.0650591     0.0123251   -0.0364826  -0.091913    -0.0067928   -0.11186      0.0476756
  0.0963583   -0.0239031    0.229845    0.0381964   -0.0308673   0.141535     0.0482745    0.126442    -0.0746344    0.0855574   -0.116106    -0.0297306    0.0770298    0.0738915  -0.238398     -0.0527237    0.0467988    0.157502    -0.0222116   0.0434967     0.0501293    0.0847688  -0.0522177    0.0235707   -0.0336628    0.0489107
 -0.00583517  -0.102863     0.0873887   0.21295      0.0215093   0.15017     -0.111332     0.00364504  -0.0919222    0.18766     -0.00289544   0.0535498   -0.130916     0.0083149   0.125372      0.153312     0.0560848   -0.133907     0.020645   -0.000136425  -0.184544     0.0103403   0.153011     0.089399     0.113259    -0.000352054
 -0.0314062   -0.0538222    0.0263649   0.195563     0.0153762   0.0927817    0.00635435   0.232119     0.00297329  -0.0167948    0.120873     0.0375104    0.065456     0.125487    0.113861      0.110275    -0.119388     0.128225     0.0897217   0.0601794     0.107082    -0.109212    0.0687939    0.0203284    0.00119158  -0.0216077
  0.0587963   -0.080538     0.0750779  -0.0165081   -0.0810706   0.124409    -0.0511635   -0.0393724    0.0869402   -0.0977667    0.01478      0.109556    -0.205096     0.0136281   0.112984      0.028334     0.0522995    0.313748    -0.109916    0.0399676     0.0500962   -0.0324923   0.0724835   -0.0658254    0.0196691   -0.233859
  0.053125    -0.0425302    0.0656631  -0.0120779    0.12061     0.103074     0.119483     0.0370548    0.08485     -0.0267474   -0.195776    -0.0995801   -0.180244    -0.148624   -0.0454577     0.0785621    0.160516     0.0292049    0.0577051  -0.0581802    -0.0221483    0.0315669   0.218769    -0.00776879  -0.0102853    0.0121265
  0.13387     -0.0916483    0.110119    0.104256    -0.0312113   0.0874841    0.0110365    0.0320499   -0.257623    -0.0585621    0.0530144   -0.0656701    0.0134817    0.0995176   0.140692      0.080268     0.116363     0.0830434   -0.122296    0.115656     -0.0973434   -0.170468    0.0953365    0.00776365  -0.159684     0.0930855
  0.266709     0.170754    -0.0379974   0.0179793    0.0247763  -0.00340026   0.0638563    0.0254048    0.239392    -0.0721763   -0.151119     0.0215318    0.0788317    0.0581897   0.147995     -0.106153     0.00208329   0.106818    -0.0659055   0.0522764     0.114769     0.0455341  -0.161713    -0.00896591  -0.00212666   0.0871806
  0.0410419   -0.0408179    0.124776   -0.101289    -0.0347829   0.090421    -0.026813     0.199838    -0.042524    -0.0356552    0.21985     -0.0878275    0.0811042    0.0160755   0.101182     -0.0256458    0.0681344    0.130703     0.211833   -0.126892     -0.0442576    0.122118    0.0222741   -0.00868333  -0.0960148   -0.243676
  0.115902    -0.126242    -0.0239673   0.00181795  -0.0359707   0.0169487    0.0550968    0.0769554    0.0338271   -0.044821     0.131572     0.120836    -0.0668811   -0.119516    0.249741      0.21285     -0.0219464    0.0999794   -0.04083     0.0923763     0.0626242   -0.0308307  -0.0151635    0.0489073    0.0193657    0.0512341
  0.08262      0.051049     0.0326633  -0.0259626    0.0027269  -0.0206845   -0.0173559   -0.0358584    0.102025    -0.0154528    0.0193676   -0.0587879    0.0274697    0.0772387   0.216742      0.0931701    0.055277     0.00303291   0.0238189   0.123888     -0.0123957   -0.0740065  -0.0209086   -0.010045     0.0285239   -0.110224
  0.117098    -0.0800577   -0.0644894   0.13869     -0.0987528   0.0695268   -0.0518672   -0.176243     0.0806899    0.122552     0.107526     0.195191    -0.0389233    0.0299003   0.00177665    0.142389     0.137363     0.0616339    0.143635   -0.00474396    0.0905647    0.0654213  -0.191523    -0.0770444    0.220313     0.0436366
 -0.0356127   -0.0267105   -0.111677    0.0421644    0.131311   -0.0420795    0.216134    -0.12333      0.0654785   -0.10917     -0.104589    -0.282101     0.0810434   -0.0435774  -0.0848927     0.141984    -0.0844111   -0.0830799   -0.0307378   0.108825      0.110057     0.0616176  -0.0809039    0.172916    -0.0353867    0.0276176
 -0.00157855   0.117743    -0.080203   -0.0514852    0.083484   -0.0521895   -0.10407      0.154655     0.118686     0.0374931    0.244458    -0.187253     0.0297662   -0.0798607   0.00975049    0.163906     0.0600423   -0.0429951    0.0902329   0.0733241    -0.232864     0.134558   -0.0224288    0.144221     0.0605868    0.0309054
  0.268283     0.0491307   -0.0203626  -0.214771     0.117083    0.0483255    0.0357811   -0.0197232   -0.105452     0.0161184   -0.00517364   0.0334493    0.0521429    0.0348078   0.112863      0.0375433    0.127927     0.12203     -0.0618033   0.120085     -0.0425519    0.124618   -0.0015178   -0.152308     0.149727    -0.158567
 -0.0775786    0.0438171    0.051385    0.0561158    0.0359442   0.0293115   -0.0847634    0.0855152    0.0473029   -0.0370469    0.0686511   -0.0613638    0.00609778   0.157594   -0.0586778     0.0639769   -0.0267093   -0.166417     0.0270583  -0.0482499     0.0272949    0.22524     0.185002    -0.0622709    0.0692693    0.0231624
 -0.0860893   -0.0198235    0.0696709   0.0135619    0.0630462   0.0589175    0.0476069   -0.0879829    0.140216     0.0505915   -0.0591702   -0.161516    -0.100627    -0.0136214  -0.0440735     0.12435      0.318191    -0.100942    -0.0356843   0.0389766     0.21818     -0.175523    0.145066     0.0824848   -0.0556359    0.103032
 -0.122883    -0.0197867   -0.0745957   0.185552     0.236369   -0.197513    -0.186575    -0.091789    -0.0129929    0.0429008   -0.0114318   -0.0620513   -0.14347     -0.141876    0.000123199  -0.0452605    0.0647772   -0.0306904    0.187244   -0.0374327    -0.0638647   -0.116111    0.0616577    0.151888     0.105105     0.102411
  0.0390362   -0.116502    -0.0354903  -0.00866828   0.127904   -0.0260904   -0.189079     0.00941078  -0.0568003    0.062724     0.12626      0.0465317    0.147616     0.114175    0.0303021     0.0415457    0.00844281  -0.00795866  -0.0477569  -0.027522     -0.0192406   -0.0584953   0.00218578   0.00561885  -0.200436    -0.114769
  0.230335    -0.1442       0.079169   -0.0161138    0.0671111  -0.0715866    0.0486751    0.0259982    0.0623607   -0.0389065    0.0195724   -0.0123035    0.00348195  -0.0199875  -0.0121563    -0.0550819    0.0991575    0.0271967    0.0744012  -0.165099     -0.0735042    0.166944    0.202715    -0.199872     0.0139062   -0.030968
 -0.094776    -0.191356     0.157038    0.200078     0.0484978  -0.103396    -0.121185     0.0407946   -0.102409    -0.131851    -0.0413913   -0.0721906    0.0400822   -0.18172    -0.13138       0.0806501   -0.0812101   -0.00109298   0.172664   -0.0442544    -0.0871748    0.140318   -0.069993     0.0999899   -0.0491578    0.0754695
  0.0887384    0.010211     0.195244    0.114441    -0.018515    0.157111     0.0143666    0.0307038    0.0733155   -0.0463408   -0.0602101   -0.0361786   -0.0891752    0.0470326  -0.062366      0.00541516   0.0864323   -0.0864169   -0.189609    0.107485     -0.00260737   0.113328    0.150211    -0.0769696   -0.0911259   -0.0494439kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4022661557727738
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.402331
[ Info: iteration 2, average log likelihood -1.402252
[ Info: iteration 3, average log likelihood -1.401555
[ Info: iteration 4, average log likelihood -1.394616
[ Info: iteration 5, average log likelihood -1.379145
[ Info: iteration 6, average log likelihood -1.373353
[ Info: iteration 7, average log likelihood -1.372472
[ Info: iteration 8, average log likelihood -1.372106
[ Info: iteration 9, average log likelihood -1.371845
[ Info: iteration 10, average log likelihood -1.371614
[ Info: iteration 11, average log likelihood -1.371368
[ Info: iteration 12, average log likelihood -1.371054
[ Info: iteration 13, average log likelihood -1.370690
[ Info: iteration 14, average log likelihood -1.370425
[ Info: iteration 15, average log likelihood -1.370275
[ Info: iteration 16, average log likelihood -1.370184
[ Info: iteration 17, average log likelihood -1.370124
[ Info: iteration 18, average log likelihood -1.370083
[ Info: iteration 19, average log likelihood -1.370054
[ Info: iteration 20, average log likelihood -1.370033
[ Info: iteration 21, average log likelihood -1.370017
[ Info: iteration 22, average log likelihood -1.370005
[ Info: iteration 23, average log likelihood -1.369995
[ Info: iteration 24, average log likelihood -1.369987
[ Info: iteration 25, average log likelihood -1.369979
[ Info: iteration 26, average log likelihood -1.369973
[ Info: iteration 27, average log likelihood -1.369968
[ Info: iteration 28, average log likelihood -1.369962
[ Info: iteration 29, average log likelihood -1.369958
[ Info: iteration 30, average log likelihood -1.369953
[ Info: iteration 31, average log likelihood -1.369948
[ Info: iteration 32, average log likelihood -1.369944
[ Info: iteration 33, average log likelihood -1.369939
[ Info: iteration 34, average log likelihood -1.369935
[ Info: iteration 35, average log likelihood -1.369930
[ Info: iteration 36, average log likelihood -1.369926
[ Info: iteration 37, average log likelihood -1.369921
[ Info: iteration 38, average log likelihood -1.369916
[ Info: iteration 39, average log likelihood -1.369911
[ Info: iteration 40, average log likelihood -1.369906
[ Info: iteration 41, average log likelihood -1.369901
[ Info: iteration 42, average log likelihood -1.369895
[ Info: iteration 43, average log likelihood -1.369889
[ Info: iteration 44, average log likelihood -1.369883
[ Info: iteration 45, average log likelihood -1.369876
[ Info: iteration 46, average log likelihood -1.369868
[ Info: iteration 47, average log likelihood -1.369860
[ Info: iteration 48, average log likelihood -1.369849
[ Info: iteration 49, average log likelihood -1.369836
[ Info: iteration 50, average log likelihood -1.369819
┌ Info: EM with 100000 data points 50 iterations avll -1.369819
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.402331222623737
│     -1.4022516320455003
│      ⋮
└     -1.369819213398953
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.369905
[ Info: iteration 2, average log likelihood -1.369749
[ Info: iteration 3, average log likelihood -1.369166
[ Info: iteration 4, average log likelihood -1.365198
[ Info: iteration 5, average log likelihood -1.354223
[ Info: iteration 6, average log likelihood -1.344137
[ Info: iteration 7, average log likelihood -1.340101
[ Info: iteration 8, average log likelihood -1.338259
[ Info: iteration 9, average log likelihood -1.336824
[ Info: iteration 10, average log likelihood -1.335384
[ Info: iteration 11, average log likelihood -1.333951
[ Info: iteration 12, average log likelihood -1.332807
[ Info: iteration 13, average log likelihood -1.331945
[ Info: iteration 14, average log likelihood -1.331218
[ Info: iteration 15, average log likelihood -1.330529
[ Info: iteration 16, average log likelihood -1.329853
[ Info: iteration 17, average log likelihood -1.329237
[ Info: iteration 18, average log likelihood -1.328755
[ Info: iteration 19, average log likelihood -1.328412
[ Info: iteration 20, average log likelihood -1.328165
[ Info: iteration 21, average log likelihood -1.327974
[ Info: iteration 22, average log likelihood -1.327803
[ Info: iteration 23, average log likelihood -1.327631
[ Info: iteration 24, average log likelihood -1.327452
[ Info: iteration 25, average log likelihood -1.327258
[ Info: iteration 26, average log likelihood -1.327048
[ Info: iteration 27, average log likelihood -1.326817
[ Info: iteration 28, average log likelihood -1.326558
[ Info: iteration 29, average log likelihood -1.326261
[ Info: iteration 30, average log likelihood -1.325940
[ Info: iteration 31, average log likelihood -1.325601
[ Info: iteration 32, average log likelihood -1.325196
[ Info: iteration 33, average log likelihood -1.324548
[ Info: iteration 34, average log likelihood -1.323782
[ Info: iteration 35, average log likelihood -1.323281
[ Info: iteration 36, average log likelihood -1.323120
[ Info: iteration 37, average log likelihood -1.323071
[ Info: iteration 38, average log likelihood -1.323049
[ Info: iteration 39, average log likelihood -1.323037
[ Info: iteration 40, average log likelihood -1.323030
[ Info: iteration 41, average log likelihood -1.323025
[ Info: iteration 42, average log likelihood -1.323022
[ Info: iteration 43, average log likelihood -1.323021
[ Info: iteration 44, average log likelihood -1.323019
[ Info: iteration 45, average log likelihood -1.323019
[ Info: iteration 46, average log likelihood -1.323018
[ Info: iteration 47, average log likelihood -1.323018
[ Info: iteration 48, average log likelihood -1.323018
[ Info: iteration 49, average log likelihood -1.323018
[ Info: iteration 50, average log likelihood -1.323017
┌ Info: EM with 100000 data points 50 iterations avll -1.323017
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3699048727394532
│     -1.369748693750014
│      ⋮
└     -1.3230174157656687
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.323158
[ Info: iteration 2, average log likelihood -1.323028
[ Info: iteration 3, average log likelihood -1.322665
[ Info: iteration 4, average log likelihood -1.319420
[ Info: iteration 5, average log likelihood -1.305596
[ Info: iteration 6, average log likelihood -1.288433
[ Info: iteration 7, average log likelihood -1.280778
[ Info: iteration 8, average log likelihood -1.278105
[ Info: iteration 9, average log likelihood -1.276683
[ Info: iteration 10, average log likelihood -1.275554
[ Info: iteration 11, average log likelihood -1.274254
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.272452
[ Info: iteration 13, average log likelihood -1.281247
[ Info: iteration 14, average log likelihood -1.276033
[ Info: iteration 15, average log likelihood -1.273741
[ Info: iteration 16, average log likelihood -1.272093
[ Info: iteration 17, average log likelihood -1.270465
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.268505
[ Info: iteration 19, average log likelihood -1.277838
[ Info: iteration 20, average log likelihood -1.272899
[ Info: iteration 21, average log likelihood -1.271074
[ Info: iteration 22, average log likelihood -1.269829
[ Info: iteration 23, average log likelihood -1.268382
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.266483
[ Info: iteration 25, average log likelihood -1.276615
[ Info: iteration 26, average log likelihood -1.271817
[ Info: iteration 27, average log likelihood -1.270114
[ Info: iteration 28, average log likelihood -1.268969
[ Info: iteration 29, average log likelihood -1.267583
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.265745
[ Info: iteration 31, average log likelihood -1.276303
[ Info: iteration 32, average log likelihood -1.271570
[ Info: iteration 33, average log likelihood -1.269889
[ Info: iteration 34, average log likelihood -1.268735
[ Info: iteration 35, average log likelihood -1.267322
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.265485
[ Info: iteration 37, average log likelihood -1.276273
[ Info: iteration 38, average log likelihood -1.271537
[ Info: iteration 39, average log likelihood -1.269846
[ Info: iteration 40, average log likelihood -1.268671
[ Info: iteration 41, average log likelihood -1.267231
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.265386
[ Info: iteration 43, average log likelihood -1.276276
[ Info: iteration 44, average log likelihood -1.271533
[ Info: iteration 45, average log likelihood -1.269835
[ Info: iteration 46, average log likelihood -1.268652
[ Info: iteration 47, average log likelihood -1.267202
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.265354
[ Info: iteration 49, average log likelihood -1.276278
[ Info: iteration 50, average log likelihood -1.271532
┌ Info: EM with 100000 data points 50 iterations avll -1.271532
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3231582855444954
│     -1.323028449825452
│      ⋮
└     -1.2715321539005455
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.270047
[ Info: iteration 2, average log likelihood -1.268580
[ Info: iteration 3, average log likelihood -1.265678
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.248810
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.219364
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.217362
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.206204
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.204136
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.182913
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.190950
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.211239
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.215074
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.196413
[ Info: iteration 14, average log likelihood -1.194122
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.170787
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.206649
[ Info: iteration 17, average log likelihood -1.216837
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.185046
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.194502
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.185391
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.187581
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.189637
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.204911
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.187510
[ Info: iteration 25, average log likelihood -1.199745
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.180729
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.197583
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.193679
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.196909
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.179675
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.190158
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.186492
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.205150
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.193500
[ Info: iteration 35, average log likelihood -1.202168
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.175833
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.200553
[ Info: iteration 38, average log likelihood -1.201598
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.172283
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.189108
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.195996
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.195453
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.206883
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.190112
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.172599
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.182607
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.194672
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.212523
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.200462
[ Info: iteration 50, average log likelihood -1.193454
┌ Info: EM with 100000 data points 50 iterations avll -1.193454
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.270047110038216
│     -1.2685797423668672
│      ⋮
└     -1.1934542311090854
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.168453
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.160375
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.163878
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│     11
│     12
│     14
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.140175
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     13
│     21
│     22
│     23
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.108330
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      9
│     11
│     12
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.089889
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     10
│     21
│     22
│     23
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.094586
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.088324
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.087397
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.076871
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.092726
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.084987
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.079845
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.069696
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.090498
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.078233
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.082940
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.073744
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.090359
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.080072
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.080449
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.069624
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.086859
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.087799
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.080191
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.070043
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.091925
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.080716
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.077045
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.070431
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.094975
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.081246
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.081191
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.070737
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.088748
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.081899
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.076962
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.074647
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.093094
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.081372
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.078083
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.072240
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.089110
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.078082
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.085734
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.071894
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.089400
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.082932
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.078721
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.068833
┌ Info: EM with 100000 data points 50 iterations avll -1.068833
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1684534278487164
│     -1.1603752253961137
│      ⋮
└     -1.0688333188626142
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4022661557727738
│     -1.402331222623737
│     -1.4022516320455003
│     -1.401554535336225
│      ⋮
│     -1.0829321437560966
│     -1.0787207952076252
└     -1.0688333188626142
32×26 Array{Float64,2}:
  0.0876565  -0.0714858    0.0107587    0.128329   -0.043121    -0.030283    -0.0542506    0.035435     0.040619    -0.0494909     0.0955049    0.0554367    0.0172608   -0.107292     0.211444      0.102377   -0.00181052   0.0298571   -0.0268686     0.0475391   -0.0348039    0.0372062   -0.0491534   -0.0952438   -0.0426816   -0.0908897
  0.149386   -0.083859     0.156032     0.0202115   0.0138555    0.0549226    0.042352     0.0756442   -0.0130632    0.0477615    -0.0549272   -0.0177526    0.0498651    0.0443642   -0.124198     -0.0484223   0.0722192    0.0779996    0.020099     -0.0456073   -0.00361155   0.130609     0.052203    -0.0947616   -0.0286181   -0.018909
  0.0816986  -0.0156155    0.0693499   -0.0466867   0.136958     0.0987195    0.123585     0.0117143    0.0976304   -0.0244664    -0.119338    -0.0927944   -0.130115    -0.148995    -0.0517821     0.0728926   0.203991     0.0197165    0.0520708    -0.0685738   -0.00284137   0.0364858    0.192541     0.0284343   -0.0128614    0.00925199
  0.0755461  -0.0235905    0.053024    -0.0641849   0.140071     0.156411     0.00461598   0.0735144    0.0494685   -0.0214298     0.0238143    0.0948294    0.0956336   -0.0863445   -0.0444371     0.110684   -0.0673729   -0.0689738    0.0259229     0.0170286   -0.0709349    0.0272684    0.108916     0.132253     0.0359467   -0.0542249
 -0.0913237  -0.204901     0.1598       0.195469    0.0532529   -0.105978    -0.121272     0.0395994   -0.0976352   -0.122898     -0.0406589   -0.0716019    0.0711614   -0.201945    -0.112003      0.078331   -0.086064     0.00590441   0.197783     -0.044198    -0.0901639    0.141471    -0.111149     0.134345    -0.0491666    0.123779
  0.0436229  -0.078466     0.126677    -0.0971695  -0.034107     0.0814067   -0.0249048    0.195338    -0.0430511   -0.000981379   0.194538    -0.0650932    0.0766084   -0.00124371   0.100912     -0.0251401   0.0802315    0.145406     0.211562     -0.122073     0.00762012   0.141257     0.0211578   -0.00998653  -0.0947621   -0.245642
  0.0229462   0.110363    -0.0794462   -0.0332734   0.0297492   -0.0253949   -0.0612417    0.0799083    0.0514468   -0.0470393     0.124561    -0.0647998   -0.0629513    0.101872    -0.0423988    -0.0410513   0.0286162    0.0258622    0.0642547     0.065642    -0.0809809    0.0745057   -0.0478308    0.131654     0.00224907   0.0239507
  0.125682   -0.0639278    0.108723     0.0872776  -0.0319335    0.0844678    0.0152931    0.0554801   -0.260173    -0.0592456     0.0162384   -0.0715724    0.0530668    0.12595      0.112103      0.0846615   0.104231     0.0800389   -0.132293      0.111584    -0.0845766   -0.170092     0.127019    -0.0266885   -0.160043     0.0860091
  0.0421377   0.0218662   -0.0755376   -0.0822923  -0.0406226   -0.106865     0.115025    -0.203428     0.0225082   -0.0609684    -0.0492197    0.119164    -0.154558     0.0630156    0.0289675     0.0636173   0.120138    -0.0817811   -0.0235791     0.0652591    0.00554212  -0.0702438   -0.0916791   -0.00832707  -0.123092     0.05101
  0.277774    0.0559114    0.00916904  -0.213023    0.153931     0.0495454    0.0360448   -0.0140571   -0.11551      0.00594862    2.61735e-5   0.047302     0.0732818    0.00426657   0.131565      0.0417656   0.143604     0.106857    -0.0625599     0.0937583   -0.0186437    0.147402     0.00233585  -0.153079     0.147811    -0.157876
  0.117646    0.0200519   -0.267299     0.113461   -0.0451909    0.1586      -0.453905     0.0595736    0.0801751   -0.0448023    -0.054577    -0.0561182   -0.0905464    0.0420598    0.0238553    -0.0507052   0.116758    -0.0655734   -0.19018       0.120242     0.0932685   -0.0054994    0.162044    -0.0727024   -0.117817    -0.0503779
  0.0973841   0.00469557   0.690619     0.113209    0.0256529    0.153643     0.491558     0.00226629   0.0610664   -0.0450167    -0.0661612    0.00346528  -0.0866057    0.0581037   -0.0642799     0.0343142   0.0814375   -0.0889694   -0.19015       0.13208     -0.0823946    0.221215     0.149103    -0.087362    -0.0876836   -0.0496816
 -0.0751783   0.044693     0.00520881   0.0314057   0.101116     0.0334372   -0.0107948    0.0727379    0.0787556    0.0187863     0.0529292   -0.0587919   -0.068678     0.108184     0.0246885     0.0563958  -0.00353967  -0.167219     0.000427789  -0.0497616   -1.22189      0.338904     0.142955    -0.0740531    0.0794791   -0.013793
 -0.0865226   0.0469965    0.104594     0.087284   -0.0454374    0.020067    -0.148309     0.101147     0.00470014  -0.0721255     0.031745    -0.0743692    0.0855232    0.221925    -0.0790515     0.0695504  -0.0772109   -0.167412     0.0502493    -0.0453794    1.03839      0.239342     0.249415    -0.0898329    0.120933     0.0482417
 -0.0405191  -0.0249698   -0.266799    -0.0110203   0.144766    -0.0280337    0.293621     0.0843043    0.498077    -0.037177     -0.104326    -0.289099     0.101307    -0.0450124    0.0643994    -0.180983   -0.0794924   -0.0784171   -0.0292594     0.154098    -0.488038     0.0673252   -0.0917098    0.107311    -0.0390788    0.125653
 -0.0324443  -0.046988    -0.051678     0.179197    0.165665    -0.0720393    0.198209    -0.307187    -0.230195    -0.217185     -0.104473    -0.275612     0.0140683   -0.0542052   -0.157317      0.311278   -0.085947    -0.0612432   -0.0297195     0.00747754   0.6174       0.0663373   -0.0719264    0.152057    -0.0406336    0.0548824
 -0.0247346  -0.103036     0.0815966    0.216866    0.0207055    0.141194    -0.102555     1.53016e-5  -0.0759618    0.180071      0.0161272    0.0262122   -0.123113     0.0103097    0.125266      0.14732     0.0623978   -0.130336     0.0248563    -0.0182058   -0.204152     0.00815189   0.185147     0.0746007    0.123505    -0.00769948
 -0.0903586  -0.0137958    0.0683322    0.0112903   0.0651639    0.0739286    0.0432876   -0.0749748    0.132293     0.0444678    -0.0674101   -0.162146    -0.120805    -0.0165128   -0.0363557     0.100929    0.32424     -0.106988    -0.0347172     0.0485992    0.238051    -0.169648     0.13642      0.0724507   -0.0566715    0.0985903
 -0.0639572  -0.115299    -0.046266     0.0378558   0.129475     0.00329084  -0.20284     -0.0794949   -0.0589963    0.0484359     0.126698    -0.0197074    0.0918497    0.043594     0.00116869   -0.488668    0.0258859   -0.00264818  -0.0709758    -0.0329227   -0.00212126  -0.0451952   -0.0247566    0.0100136   -0.198722    -0.120623
  0.144164   -0.120208    -0.0214468   -0.077327    0.130049    -0.0833252   -0.209144     0.12787     -0.0478546    0.0752298     0.130671     0.0850459    0.183211     0.0977359    0.0572465     0.74127    -0.00423747  -0.0188114    0.00514222   -0.0206514   -0.0878111   -0.0722055   -0.0253918    0.0600442   -0.200344    -0.0690407
 -0.020474   -0.120033    -0.0126249   -0.85823    -0.165555    -0.0531196   -0.113951     0.105485     0.0319295    0.084169      0.091139    -0.0502836   -0.193555    -0.131473     0.334396      0.142913   -0.0424314   -0.0687742    0.0277251    -0.170773     0.0684395    0.0133722   -0.142453    -0.0797423    0.0602994   -0.210049
 -0.0126733  -0.131224    -0.165293     0.433865   -0.169202     0.546876    -0.0903151    0.104459     0.0316314    0.0431201     0.106189    -0.144786    -0.193614    -0.0265017   -0.295196      0.0931493  -0.145133    -0.0690929    0.043329     -0.164324    -0.32045      0.154545    -0.133545    -0.0585706    0.069415    -0.213733
 -0.132452   -0.0958155    0.0680414    0.0907182   0.0248815   -0.310605    -0.0254416   -0.0154573    0.0713734    0.0932561     0.00916538   0.108145    -0.221219    -0.0163685   -0.0261142     0.156887    0.0505302    0.309964    -0.0950533    -0.0168061    0.0565082   -0.049618     0.0768189   -0.165379     0.0282654   -0.23413
  0.254867   -0.0727794    0.0897676   -0.0938862  -0.0913333    0.546352    -0.0765274   -0.0161156    0.101406    -0.175682      0.0952687    0.111822    -0.179214     0.031534     0.235462     -0.105542    0.0568219    0.338145    -0.129258      0.00467682   0.0431343   -0.0311977    0.0868464   -0.0524369    0.0157814   -0.234261
 -0.14697    -0.403525    -0.0217218    0.0363858   0.0985855   -0.0570875   -0.0240341   -0.286228     0.158617     0.00560729    0.0293956   -0.0382414   -0.00440357  -0.1686       0.0217887    -0.0841376  -0.172984    -0.0246758    0.0660632    -0.0710392   -0.104448    -0.0280636   -0.098524     0.0663049   -0.0272432    0.0868427
  0.0828631   0.192748    -0.0229435    0.0351008   0.119728    -0.114158     0.0712465    0.309115    -0.168635    -0.00135358    0.0548245   -0.0378281    0.0708415   -0.1307      -0.00188895   -0.0188717  -0.200478    -0.0272706    0.00606869   -0.0220856   -0.0999307    0.140716     0.0831689    0.0663704   -0.0293757    0.0869991
 -0.0246869  -0.130889     0.0680442    0.20082     0.012163    -0.023709     0.00465579   0.208762     0.0915957   -0.0524593     0.0946506    0.0588558    0.0679852    0.124334     0.0584        0.110028   -0.130575     0.127724    -0.285386      0.0406497    0.102324    -0.101379     0.0667864    0.124947     0.00144957  -0.0212614
 -0.0223679   0.0490664   -0.0128105    0.180391    0.0118055    0.201591     0.00625206   0.214908    -0.0258122    0.0608108     0.159489     0.0212403    0.0607059    0.123252     0.177501      0.110185   -0.0712494    0.103459     0.545361      0.119036     0.108314    -0.0783431    0.0696917   -0.00178128  -0.00238734  -0.0216305
  0.130986   -0.0799633   -0.0603239    0.116458   -0.133107     0.0349671   -0.0527873   -0.17236      0.0759753    0.106546      0.110148     0.144838    -0.0402931    0.0493911   -0.000624062   0.133935    0.149632     0.0520517    0.130227     -0.0218011    0.0746293    0.0647607   -0.201304    -0.0726169    0.21435      0.0266229
 -0.107026   -0.0778731   -0.0873171    0.0287078   0.00373837   0.098765    -0.0747202   -0.0509796    0.0998375    0.0998115     0.0790195    0.036928    -0.0941971    0.0524263    0.127924      0.0767878  -0.156553    -0.0356424    0.0121668     0.00152331   0.0421999    0.0461053   -0.0835043    0.108172    -0.12862     -0.134601
 -0.0387607   0.0110325   -0.00375834   0.0630311   0.155509    -0.0482604   -0.0858871   -0.00259622  -0.00337412   0.16223      -0.0562535    0.0317498   -0.0617044   -0.0186437    0.0472182     0.0013385   0.0716466   -0.0415995    0.161871      0.00445486  -0.0453453   -0.103948     0.047339     0.023711     0.0318345    0.0160993
  0.0706914   0.0593298    0.114227     0.0100627   0.00773075  -0.0404082    0.0133989    0.0267021    0.10895      0.000547113  -0.0707098   -0.00561839   0.0402155    0.0725839    0.0931884     0.0124655   0.0144083    0.067186    -0.0113276     0.00338664   0.0466434    0.0812547   -0.0241307    0.0446559   -0.0217959   -0.0227105[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.089915
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.079069
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.076061
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.070578
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.088053
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.078084
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.078871
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.068725
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.087077
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.080883
┌ Info: EM with 100000 data points 10 iterations avll -1.080883
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.328504e+05
      1       6.717799e+05      -1.610705e+05 |       32
      2       6.428722e+05      -2.890772e+04 |       32
      3       6.250532e+05      -1.781893e+04 |       32
      4       6.139843e+05      -1.106892e+04 |       32
      5       6.066550e+05      -7.329328e+03 |       32
      6       6.017039e+05      -4.951099e+03 |       32
      7       5.990513e+05      -2.652547e+03 |       32
      8       5.978577e+05      -1.193648e+03 |       32
      9       5.971172e+05      -7.405111e+02 |       32
     10       5.963732e+05      -7.439902e+02 |       32
     11       5.955078e+05      -8.654278e+02 |       32
     12       5.946179e+05      -8.898811e+02 |       32
     13       5.937917e+05      -8.261623e+02 |       32
     14       5.931526e+05      -6.391333e+02 |       32
     15       5.928649e+05      -2.876457e+02 |       32
     16       5.927424e+05      -1.224982e+02 |       32
     17       5.926796e+05      -6.282643e+01 |       32
     18       5.926345e+05      -4.513565e+01 |       32
     19       5.926037e+05      -3.076654e+01 |       32
     20       5.925887e+05      -1.499849e+01 |       32
     21       5.925795e+05      -9.176477e+00 |       32
     22       5.925717e+05      -7.795221e+00 |       32
     23       5.925619e+05      -9.866780e+00 |       32
     24       5.925511e+05      -1.077918e+01 |       29
     25       5.925425e+05      -8.597847e+00 |       32
     26       5.925310e+05      -1.153566e+01 |       28
     27       5.925156e+05      -1.539941e+01 |       32
     28       5.924955e+05      -2.011099e+01 |       30
     29       5.924772e+05      -1.825739e+01 |       32
     30       5.924576e+05      -1.960380e+01 |       31
     31       5.924435e+05      -1.407169e+01 |       29
     32       5.924319e+05      -1.165118e+01 |       31
     33       5.924235e+05      -8.338851e+00 |       23
     34       5.924173e+05      -6.271959e+00 |       26
     35       5.924119e+05      -5.346874e+00 |       24
     36       5.924071e+05      -4.848556e+00 |       27
     37       5.923991e+05      -7.951520e+00 |       25
     38       5.923938e+05      -5.298647e+00 |       25
     39       5.923888e+05      -4.971314e+00 |       28
     40       5.923840e+05      -4.850914e+00 |       27
     41       5.923795e+05      -4.472877e+00 |       25
     42       5.923761e+05      -3.423367e+00 |       18
     43       5.923738e+05      -2.302801e+00 |       24
     44       5.923701e+05      -3.711974e+00 |       26
     45       5.923662e+05      -3.873842e+00 |       25
     46       5.923621e+05      -4.075963e+00 |       28
     47       5.923574e+05      -4.733960e+00 |       28
     48       5.923513e+05      -6.099077e+00 |       28
     49       5.923458e+05      -5.544272e+00 |       22
     50       5.923396e+05      -6.181900e+00 |       29
K-means terminated without convergence after 50 iterations (objv = 592339.5711137943)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.321506
[ Info: iteration 2, average log likelihood -1.297610
[ Info: iteration 3, average log likelihood -1.273278
[ Info: iteration 4, average log likelihood -1.247238
[ Info: iteration 5, average log likelihood -1.213016
[ Info: iteration 6, average log likelihood -1.163803
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     11
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.110885
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      5
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.112143
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     16
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.076395
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     10
│     22
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.098740
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.136513
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.096612
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│     13
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.054946
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.080187
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     22
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.113955
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.109746
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.095832
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.062438
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     10
│     15
│     16
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.065713
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.120462
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.088704
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     22
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.055265
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      7
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.099962
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.093270
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.088297
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.100870
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      7
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.072541
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     13
│     16
│     22
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.063398
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.101305
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.090138
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.100653
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.085877
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      7
│     13
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.067701
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     16
│     22
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.084169
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.114116
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.093149
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     13
│     15
│     16
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.059776
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.130012
[ Info: iteration 39, average log likelihood -1.096487
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│     10
│     22
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.050111
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.086148
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     11
│     13
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.074516
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.111328
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      7
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.083939
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.085010
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     25
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.052482
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      7
│     16
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.091296
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.111439
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.069150
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     10
│     13
│     16
│     22
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.057411
┌ Info: EM with 100000 data points 50 iterations avll -1.057411
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.123712    -0.0195163  -0.0759778    0.178295     0.240188     -0.177897    -0.19098     -0.0913922   -0.0561027    0.0463298    -0.0161187   -0.0658151   -0.148395    -0.156687     0.00317694  -0.0459887    0.0711695   -0.0471886    0.184717    -0.0327111   -0.0797662   -0.114606     0.0719136    0.141343     0.141252      0.104283
 -0.0534182    0.0117851   0.0333004   -0.0751577   -0.110844     -0.0263262    0.0155741   -0.00579068   0.0780623    0.0409864     0.116802    -0.0575841   -0.0199435    0.073075     0.247364     0.0480013    0.0331414   -0.0163157    0.130721    -0.0790962   -0.0508862    0.0614521   -0.0379546    0.0452244   -0.0420793    -0.115292
  0.126714    -0.0661467   0.108955     0.090508    -0.0309904     0.0858948    0.0140116    0.0576151   -0.260335    -0.059551      0.0142829   -0.0672432    0.0553767    0.129001     0.10811      0.0870423    0.102979     0.0807356   -0.134183     0.113755    -0.0890306   -0.17099      0.13043     -0.0297673   -0.160957      0.0876135
  0.0309842    0.0583998   0.00285073  -0.0521963    0.105334      0.0236801    0.00695973   0.0978092    0.10795      0.00127274    0.0634996   -0.135287    -0.034376    -0.119871    -0.0440527    0.123349     0.143228    -0.0168339    0.0668242    0.00186944  -0.152602     0.0903788    0.0956712    0.0884522    0.025091      0.0239758
  0.0535058    0.099371   -0.109869    -0.0185563   -0.00939558   -0.00653174  -0.0304301    0.00818148  -0.00386737  -0.10704       0.0102475    0.0465218   -0.148234     0.291748    -0.0761791   -0.234238    -0.0129704    0.0784079    0.0331043    0.0603671    0.06373      0.0205194   -0.067636     0.120188    -0.0455386     0.039616
  0.0765783   -0.0241851   0.0536567   -0.0633021    0.14011       0.157882     0.00620108   0.0734344    0.049526    -0.0216481     0.0249627    0.0980089    0.0961986   -0.0875733   -0.0454651    0.11124     -0.0662352   -0.0717328    0.026645     0.0175603   -0.0729616    0.0274401    0.11053      0.134123     0.038398     -0.0541608
  0.147987    -0.0916345  -0.0695992    0.14751     -0.117334      0.0424826   -0.0608602   -0.185863     0.0721009    0.116413      0.112165     0.162373    -0.0414566    0.0372311   -0.0246518    0.134116     0.167495     0.0576103    0.134233    -0.0192405    0.0853252    0.065335    -0.219982    -0.0771954    0.21861       0.0392684
 -0.0222136   -0.103232    0.0830855    0.224818     0.0218374     0.147901    -0.107147     0.00512526  -0.0766427    0.181091      0.0110064    0.0252999   -0.127746     0.00654042   0.119363     0.14828      0.06274     -0.133066     0.024144    -0.0141981   -0.20994      0.00457088   0.192948     0.0720891    0.12754      -0.00516037
  0.046624     0.0529845   0.0611672   -0.0313451    0.108758      0.0799442    0.00610398   0.0886498    0.0191403    0.294908     -0.123507     0.161385     0.0200102    0.0834116    0.0264204    0.0879364    0.0731398   -0.0442858    0.12978      0.0589391   -0.0308669   -0.134775     0.0391814   -0.108156    -0.0495524    -0.0271143
  0.0417922    0.0225777  -0.0788152   -0.0834062   -0.0388392    -0.106499     0.112246    -0.201897     0.0205471   -0.0591594    -0.0496807    0.118852    -0.154581     0.0612302    0.0276422    0.0648471    0.120551    -0.0818207   -0.0248831    0.0653887    0.00745647  -0.0730804   -0.0917401   -0.00987926  -0.119352      0.0488181
 -0.034066     0.0562138   0.130392     0.0233453    0.019161      0.0278338   -0.0940666    0.0774175    0.118527     0.0554904     0.102029    -0.0293555   -0.0796646   -0.422734     0.0132855    0.0691008    0.055812    -0.0925281    0.0312159   -0.0273032   -0.296357     0.55992      0.138098    -0.054419     0.137894      0.00848793
  0.280299     0.170515    0.00317616   0.0387573    0.00125802    0.0190901    0.0223392    0.0228827    0.220601    -0.0780532    -0.143479     0.0301725    0.0812608    0.0584299    0.181067    -0.0997472   -0.00924162   0.111603    -0.0271616    0.0566915    0.116886     0.0640268   -0.153248     0.00800275  -0.00707042    0.0936631
  0.0558756   -0.0824396   0.0802284    0.00842469  -0.0273707     0.104606    -0.0502665   -0.0147457    0.0857868   -0.0324006     0.0475817    0.109092    -0.20297      0.00597323   0.0972739    0.0330369    0.0536009    0.325782    -0.113804    -0.00495162   0.0499227   -0.0402205    0.0810842   -0.112303     0.0213604    -0.23407
  0.0436005   -0.0797689   0.12734     -0.0969962   -0.0338308     0.0811895   -0.0249966    0.19542     -0.0430813   -0.000213362   0.195056    -0.0663316    0.0764767   -0.00438794   0.101466    -0.0249691    0.0801847    0.142629     0.211926    -0.122188     0.00550681   0.140472     0.0220719   -0.0102619   -0.0947611    -0.245801
 -0.0563269    0.0592441   0.163528     0.0604261    0.0138527     0.0367386   -0.119499     0.089387     0.022741    -0.0168098     0.0275794   -0.0215103    0.0107497    0.299122    -0.0156296    0.040725    -0.0499308   -0.104536    -0.00868844  -0.0195415   -0.0720873    0.31806      0.126797    -0.117196     0.10755      -0.0346207
 -0.018107    -0.126324   -0.083826    -0.240855    -0.166119      0.239495    -0.104251     0.107318     0.0317375    0.0682905     0.0964866   -0.0967224   -0.197716    -0.0928542    0.0335032    0.121052    -0.0960517   -0.0693223    0.0324175   -0.166922    -0.122075     0.0825267   -0.140934    -0.0711049    0.0657615    -0.212275
  0.0964024   -0.045372    0.240983     0.0605763   -0.0283091     0.146348     0.0408426    0.125751    -0.0786174    0.121218     -0.111595    -0.0279963    0.0994207    0.0617355   -0.239513    -0.0503528    0.0588381    0.15128     -0.030296     0.0454554    0.0511846    0.0986622   -0.0725038    0.0177856   -0.0350441    -0.00520161
  0.0266805   -0.118251   -0.0361688   -0.00853155   0.129434     -0.0298085   -0.207855     0.0111515   -0.055136     0.0603692     0.129006     0.0244399    0.132627     0.0680688    0.0218112    0.0452167    0.0102472   -0.00975219  -0.0381454   -0.0277964   -0.0382046   -0.0546844   -0.0288694    0.0343177   -0.199684     -0.0967598
 -0.0917554   -0.205005    0.15602      0.195682     0.0524363    -0.105905    -0.12138      0.038769    -0.0976926   -0.125035     -0.0411041   -0.0717716    0.0677221   -0.204373    -0.111571     0.0777978   -0.0844582    0.004601     0.192835    -0.0438442   -0.0913346    0.139144    -0.109359     0.130638    -0.0510088     0.122494
 -0.117878    -0.10116    -0.106595     0.0513059    0.0388587     0.124348    -0.0913858   -0.0557926    0.0930849    0.104107      0.0708078    0.0626422   -0.108621     0.0472841    0.110954     0.0779512   -0.191426    -0.0356265   -0.0158642    0.0155189    0.0546516    0.05042     -0.0870736    0.11183     -0.138977     -0.135894
  0.226045    -0.128161    0.0687904   -0.0214753    0.0651636    -0.0426132    0.0491732    0.0194635    0.0567946   -0.0241335     0.0109681   -0.0116215    0.00794618   0.00955126  -0.01689     -0.0474696    0.0990107    0.00814763   0.0748859   -0.157887    -0.0653547    0.1752       0.203228    -0.238318    -0.00254598   -0.0320669
  0.107324    -0.131991   -0.0320455   -0.0195732   -0.0329304     0.00366781   0.0461537    0.0756867    0.0132093   -0.0158539     0.148264     0.120128    -0.0578706   -0.09494      0.249899     0.218028    -0.0223603    0.110135    -0.0668093    0.114597     0.0576465   -0.0201406   -0.00624537   0.0588036    0.0192964     0.0534647
  0.0835818   -0.0307837   0.0468266    0.292204    -0.0620295    -0.0612242   -0.158066    -0.0082078    0.0544141   -0.0915291     0.0374779   -0.00717261   0.0710499   -0.108514     0.175986     0.00643518   0.00905478  -0.0467068   -0.00418614  -0.0116614   -0.132693     0.0963261   -0.0784212   -0.240536    -0.0956573    -0.22187
 -0.0887546   -0.0138376   0.0678497    0.0104913    0.0651781     0.0776584    0.0429556   -0.0751873    0.132316     0.0436614    -0.0677846   -0.162782    -0.120613    -0.00926517  -0.036725     0.10471      0.327111    -0.107451    -0.0350477    0.0503158    0.235914    -0.169121     0.136254     0.0724128   -0.0559291     0.0988399
  0.0856955    0.0377447   0.0284307   -0.0252964   -0.000978154  -0.0177695   -0.0226926   -0.0373627    0.0853667   -0.0165261     0.0301221   -0.0566764    0.0344539    0.121036     0.205696     0.128824     0.053045     0.00585035  -0.0154575    0.115416    -0.0150055   -0.0406636   -0.0145056    0.00810827   0.0241978    -0.108359
 -0.0307243   -0.101158   -0.0223921    0.0356924    0.108725     -0.0858728    0.0247741    0.0159608   -0.00760141   0.00255368    0.0426165   -0.0381227    0.0342101   -0.1498       0.00927182  -0.0521202   -0.18665     -0.0265176    0.0362195   -0.0465384   -0.102436     0.0573686   -0.00701415   0.0661609   -0.0286468     0.0869774
  0.296179     0.096114    0.0881124   -0.533997     0.18698       0.0483583    0.0171193   -0.0102449   -0.197831     0.024138      0.00489664   0.0527232    0.0881305   -0.0365008    0.233931     0.0165533    0.253302     0.107727    -0.038808     0.0623874   -0.0624521    0.139551     0.0326908   -0.153251     0.131226     -0.164273
 -0.00619583  -0.0162543  -0.167132     0.123548     0.138992     -0.0150263    0.174181    -0.0729548    0.101774    -0.119963     -0.0604254   -0.206065     0.0551046   -0.0474546   -0.0447657    0.0676114   -0.071318    -0.0729454   -0.015339     0.0543342    0.1226       0.100351     0.00447142   0.0625927    0.0237868     0.0614194
 -0.022823    -0.0414041   0.0259644    0.19674      0.0148624     0.0944892    0.00587601   0.217371     0.0329317    0.00554654    0.130629     0.0406704    0.0654259    0.125595     0.117602     0.110396    -0.10426      0.11875      0.142814     0.084753     0.106866    -0.0946422    0.0675879    0.0597164    0.000434382  -0.0216597
  0.0270181   -0.0480214   0.20796      0.00913739   0.0804463    -0.0310163    0.0762056    0.0971825    0.0994535    0.111209     -0.0229657   -0.0506678   -0.175933     0.0773083   -0.101632    -0.0451228    0.0941354    0.271871     0.171346    -0.0154254    0.135051     0.14333      0.0166666    0.148656    -0.122021     -0.153819
  0.110421     0.0142696   0.214691     0.113177    -0.00810682    0.155423     0.0183033    0.0325096    0.0702037   -0.0448501    -0.0606937   -0.0259424   -0.0881443    0.0476498   -0.0168641   -0.00614064   0.0982965   -0.0769977   -0.188224     0.124476     0.0046833    0.107432     0.153606    -0.0814452   -0.098082     -0.0510012
 -0.0731511    0.065337    0.198704     0.0414244    0.00510366   -0.116342    -0.0295253    0.0163568    0.00656867   3.81785e-5   -0.163929     0.0348094    0.196353     0.0539302    0.0118961    0.0375303   -0.0642231   -0.11947     -0.154667    -0.096535     0.00854123   0.152999     0.0404057   -0.00817554   0.0227742     0.0437799[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.131233
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.082531
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      7
│     11
│     16
│     25
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.035512
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│     13
│     25
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.061990
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     10
│     15
│     22
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.049987
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      7
│     11
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.052844
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.095390
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│     13
│     25
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.039043
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│     11
│     15
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.028179
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│     10
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.097093
┌ Info: EM with 100000 data points 10 iterations avll -1.097093
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0575611    0.0160899    0.0527802   -0.136404    -0.0864305    0.116431     0.0759872   -0.0302456    0.10195      -0.119185     0.0783999   0.228864    -0.0702616   -0.129793    -0.181013     0.205506     0.120659      0.115123     0.0763353    0.11551       0.083659    0.213548     0.0630484   -0.0498829   -0.16856      0.0172528
  0.0539807   -0.123805    -0.0194512    0.0555026    0.0982577    0.074113     0.0416479   -0.0751526    0.0394736    -0.130287    -0.0493656  -0.0570682    0.139149    -0.017188    -0.169806    -0.0313167   -0.0451246     0.0208808   -0.043603     0.0958414    -0.0542457   0.0190077   -0.0981347   -0.0290739   -0.0654892    0.074489
  0.0346321   -0.0733578    0.173525    -0.108556     0.0230148    0.211064    -0.00403397   0.126707    -0.0456448    -0.178556    -0.0417408  -0.047208     0.104874    -0.0501083    0.0809111    0.0894932    0.0160862    -0.0401799    0.181695    -0.0292908    -0.178412    0.0596017   -0.0228367   -0.0752258   -0.0884143    0.121724
  0.0512123   -0.0910853    0.114597    -0.114228     0.0607449    0.145793    -0.0463024   -0.0717236    0.0242314    -0.00323017  -0.136629   -0.0189085   -0.146276    -0.139877     0.100958     0.0107304   -0.115858      0.00379671   0.0427253    0.0859496     0.128636   -0.0093404    0.035819    -0.0688034    0.00663964   0.0775313
  0.105223    -0.0997992    0.133784    -0.0696767    0.0464497    0.0281245    0.048809    -0.180085    -0.134596      0.0389404    0.0425251  -0.00843014   0.0679879    0.0287149    0.0508796    0.0949582    0.0420523    -0.0306741    0.127555    -0.0208449    -0.0307051   0.102111    -0.136343     0.0449282    0.0322412    0.14066
  0.147744     0.0661556    0.0890214   -0.0216144    0.117156    -0.186835     0.0679973    0.0593681    0.0266219     0.18651     -0.0591888   0.00830828   0.065182     0.179886     0.132706     0.0635611   -0.0606434    -0.0939665    0.132138     0.117259     -0.0594623   0.0837383   -0.00139712   0.0859998    0.160484     0.0495431
  0.0450961    0.0514287    0.0353557   -0.0113405    0.192108     0.0475594    0.248923     0.0202272    0.0439298    -0.0411188    0.17119    -0.027669    -0.138794     0.126493    -0.00648696  -0.0138088    0.103451     -0.216248    -0.191041    -0.120559      0.223175   -0.141599     0.0121468    0.125164     0.04226     -0.0350702
 -0.0569481   -0.122518     0.103095     0.0541477    0.0601342   -0.145547    -0.123649     0.00508613  -0.00675595    0.0072368   -0.0573139   0.033479    -0.0120175   -0.0394209   -0.0209339    0.00118752   0.0601815    -0.0372968   -0.027018     0.144247     -0.0773313   0.0180637   -0.0207784    0.171835    -0.183465    -0.098694
 -0.00262594  -0.160359     0.0703107   -0.0109542   -0.130858     0.0901174   -0.0015585    0.0825446    0.0502109     0.00144199  -0.126162   -0.119816    -0.0637113   -0.00170071  -0.0467507   -0.0924291    0.148914      0.0355918   -0.00396034   0.0973553    -0.19959    -0.0209041   -0.0727271    0.0419604   -0.113235    -0.0466432
 -0.0253671    0.0690974    0.101877     0.0603237   -0.226141     0.105214    -0.0187403    0.12799      0.00663042   -0.093199     0.0248963   0.0689459    0.1233      -0.198364     0.088471    -0.131316     0.0863208     0.0630766   -0.0505317    0.24161      -0.0104249  -0.00526865   0.0543142   -0.222636     0.145046     0.013969
 -0.0617053   -0.0443211   -0.0074723    0.116047     0.165814     0.100958     0.0526647    0.0913501   -0.2016        0.0676948   -0.0043811  -0.177157    -0.0608229   -0.118167    -0.0813492   -0.119802    -0.099724      0.0270035   -0.0121579    0.203833      0.0794274   0.0593618   -0.175008     0.0116442   -0.0310404    0.118818
 -0.150285     0.0559539   -0.0214781    0.0543162   -0.0370242   -0.070348    -0.0276178   -0.118426    -0.0371496     0.167642     0.0117795  -0.0582533   -0.206764    -0.2548      -0.0214198   -0.0607681   -0.0269456    -0.0471542    0.0475776    0.032786     -0.131472   -0.221612    -0.0728865    0.0144851    0.0218786    0.0184557
  0.0582834    0.00715096  -0.00579628   0.036976    -0.0242857    0.0162132    0.00673495  -0.0158441    0.137792      0.0482305   -0.113447    0.0567204    0.182445     0.106807     0.11985      0.0155385    0.0291701     0.0556983    0.0352688    0.151088     -0.134713    0.00771608   0.217259     0.0744445    0.0747815   -0.0220905
 -0.0240101    0.0658463    0.1098      -0.0353361    0.0377901    0.0519897    0.0673463    0.120949    -0.110611      0.0506375   -0.0681034   0.0175533    0.131595    -0.192449    -0.00673219   0.257927    -0.0161512     0.00543615  -0.0257887   -0.0280242     0.086269   -0.0828561   -0.104881    -0.0697714    0.119553    -0.0113459
  0.159921    -0.128623     0.0163797    0.0271754   -0.0753066    0.164577     0.098747    -0.0756164    0.0237512     0.00965482  -0.0610304   0.179725     0.123767    -0.0643729    0.0855207    0.119418    -0.129344      0.0411179   -0.0622821   -0.0591279     0.048941    0.110949     0.0269088   -0.0230437    0.0354062   -0.0585819
 -0.0312176   -0.03017     -0.110414    -0.210749     0.0669661    0.0940279   -0.170902     0.0933551   -0.0966262    -0.0281079   -0.187826    0.232132    -0.129546     0.0767017    0.177011    -0.01191     -0.000882346   0.135351     0.0583649    0.103252      0.274353    0.00486894  -0.0176306   -0.141782    -0.0850181    0.166391
  0.0357294    0.159369     0.183724     0.347765    -0.0550287    0.0225462   -0.159466    -0.164084    -0.0433568     0.237882     0.0289241   0.0788336    0.146558    -0.0916649    0.0371812    0.0424241   -0.165815      0.123318    -0.0812118    0.0242407    -0.157418    0.097562    -0.159852     0.0173695    0.0691428    0.129621
  0.0831336    0.0100306    0.0270989    0.0187267    0.113051     0.0457039   -0.0997542   -0.0254179   -0.121722      0.0225064    0.105519    0.0552253   -0.113388    -0.0112814    0.0660354    0.0115977   -0.067779     -0.17561     -0.0179312    0.175829      0.0217427  -0.0293329   -0.0688205   -0.174663    -0.114793    -0.0154139
  0.0283655   -0.0226446   -0.168377     0.0879923   -0.00245082  -0.0878856   -0.0454995   -0.132616    -0.115564      0.0276577   -0.108174   -0.00888831  -0.0918248    0.169992    -0.0315371   -0.128256     0.0600439    -0.065085    -0.103228    -0.0944589     0.0378462   0.0790289   -0.0736861   -0.0721901    0.0180477    0.0717139
 -0.0566708   -0.048338    -0.176785     0.113119     0.017974    -0.048755     0.0261874   -0.108137     0.217827     -0.0330781   -0.01144     0.135108    -0.0302376    0.108503    -0.0863975    0.105363    -0.192606      0.089659     0.127445     0.00877422   -0.0291687   0.103234    -0.171822     0.02136     -0.059868    -0.104011
  0.0256829   -0.142432     0.1353       0.0207991    0.0303287    0.056641    -0.00363298   0.193887     0.0182321     0.169922    -0.102885   -0.148945     0.015071     0.0978301    0.0518375   -0.0427401    0.176695     -0.127177     0.201653     0.169463      0.143948    0.143623    -0.0415431    0.0326646   -0.0901797   -0.0711618
  0.0499925    0.249629    -0.156564    -0.0171965   -0.0767211   -0.0174732   -0.155927     0.052712    -0.0552121    -0.0379467    0.105024    0.0185196   -0.0474904    0.0333242   -0.122378    -0.218504     0.00586386   -0.116543    -0.0270654   -0.00407291   -0.1683     -0.0191824    0.0243884    0.0789927   -0.0834934    0.109175
  0.0714018   -0.149262     0.00548161   0.0552725   -0.00815523  -0.0200761   -0.215889    -0.0257729    0.169286     -0.0392698   -0.0473345  -0.0120919    0.0452658    0.0869854   -0.0632922   -0.0563652   -0.054156     -0.0110727    0.0489827   -0.16719      -0.0188202  -0.0592088    0.0388485   -0.252978    -0.0446441    0.146493
 -0.0175851   -0.00121491   0.135374    -0.0851338   -0.0114517    0.173303     0.0394034   -0.0187686   -0.0137564    -0.167996    -0.0272656   0.115489    -0.0241557    0.0145393   -0.0233883   -0.0620425   -0.1784        0.159192    -0.0776771    0.264972      0.220114    0.0874081    0.117433     0.16528     -0.0463897   -0.0470369
  0.110727     0.0825322    0.297696     0.0524542   -0.0711802   -0.0630312   -0.167123     0.139589    -0.0171967    -0.0173282    0.151165   -0.0247504    0.00430737  -0.164372    -0.160307    -0.125431    -0.0794736     0.0319877    0.0556904   -0.000623361   0.0554742  -0.186122    -0.0251746   -0.0977776    0.0532692   -0.0684782
 -0.0197841    0.239089    -0.162657    -0.128573    -0.0778533   -0.00471884  -0.0103085   -0.0434315    0.031874     -0.0325108    0.0272884   0.0205804    0.0727563    0.128771    -0.155661     0.0717549    0.1462        0.0725303   -0.0856811   -0.0391059     0.14797     0.106282    -0.0938903   -0.0729739   -0.0117861    0.0562769
 -0.145357    -0.0751581    0.0826429   -0.00516054   0.00164261  -0.0257594   -0.0932275   -0.129854     0.0634162    -0.101184     0.0685507   0.115227    -0.0257677   -0.223526     0.0597826    0.085231     0.214858     -0.00822639  -0.210639    -0.0215977    -0.0589389   0.240259    -0.0868664    0.00158205  -0.0164862   -0.0846326
 -0.123472    -0.091032     0.0829906    0.108862     0.00631729  -0.173205     0.141502    -0.026146    -0.000464091  -0.197747     0.0506626   0.13933     -0.0216734   -0.0687408    0.192065    -0.034748    -0.0993978    -0.0121707   -0.0650781   -0.196585      0.0715477   0.194143    -0.142004    -0.150167    -0.0476936    0.189001
  0.0809285    0.058859    -0.0463261   -0.267473     0.051979    -0.153822    -0.0800886   -0.191061     0.0261716     0.0394143   -0.165913    0.03582     -0.00804533  -0.121965    -0.0852762    0.136814     0.0818284     0.00723673  -0.072035    -0.032921      0.0114229  -0.025043    -0.137896     0.0729216    0.0779274    0.0273317
 -0.105338    -0.00666607  -0.0175867   -0.0941956   -0.0327766    0.134915     0.0411786   -0.0118523   -0.217232     -0.0765624    0.0611055  -0.12253      0.11008     -0.0247659    0.0635333    0.170218    -0.0406063     0.307507     0.0278237    0.136103     -0.0576709  -0.0258243    0.014374     0.0130566   -0.0561262    0.114195
 -0.0906358    0.00654687   0.123483     0.05746      0.0357733    0.0934354    0.0779898    0.105756     0.0226327     0.0225555   -0.0388369  -0.00188711   0.0828984   -0.0193399   -0.0546577    0.08513     -0.00494157   -0.00325059   0.161144    -0.0252449    -0.219152    0.119144    -0.0142285   -0.122471    -0.022906    -0.127306
 -0.00692654  -0.0976149    0.00191201   0.00304849   0.237627    -0.00581079   0.00301481  -0.103966     0.1169        0.0573318   -0.0668441  -0.0150043    0.1779       0.0325011    0.141704    -0.0331141    0.112905      0.269373     0.127506    -0.0225781    -0.108327   -0.0684335    0.0568468    0.2233      -0.0834118   -0.0328796kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4252643556226043
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425285
[ Info: iteration 2, average log likelihood -1.425215
[ Info: iteration 3, average log likelihood -1.425162
[ Info: iteration 4, average log likelihood -1.425102
[ Info: iteration 5, average log likelihood -1.425033
[ Info: iteration 6, average log likelihood -1.424955
[ Info: iteration 7, average log likelihood -1.424873
[ Info: iteration 8, average log likelihood -1.424791
[ Info: iteration 9, average log likelihood -1.424707
[ Info: iteration 10, average log likelihood -1.424608
[ Info: iteration 11, average log likelihood -1.424457
[ Info: iteration 12, average log likelihood -1.424187
[ Info: iteration 13, average log likelihood -1.423696
[ Info: iteration 14, average log likelihood -1.422909
[ Info: iteration 15, average log likelihood -1.421909
[ Info: iteration 16, average log likelihood -1.420996
[ Info: iteration 17, average log likelihood -1.420405
[ Info: iteration 18, average log likelihood -1.420111
[ Info: iteration 19, average log likelihood -1.419983
[ Info: iteration 20, average log likelihood -1.419929
[ Info: iteration 21, average log likelihood -1.419907
[ Info: iteration 22, average log likelihood -1.419897
[ Info: iteration 23, average log likelihood -1.419893
[ Info: iteration 24, average log likelihood -1.419891
[ Info: iteration 25, average log likelihood -1.419890
[ Info: iteration 26, average log likelihood -1.419890
[ Info: iteration 27, average log likelihood -1.419889
[ Info: iteration 28, average log likelihood -1.419889
[ Info: iteration 29, average log likelihood -1.419888
[ Info: iteration 30, average log likelihood -1.419888
[ Info: iteration 31, average log likelihood -1.419888
[ Info: iteration 32, average log likelihood -1.419888
[ Info: iteration 33, average log likelihood -1.419888
[ Info: iteration 34, average log likelihood -1.419887
[ Info: iteration 35, average log likelihood -1.419887
[ Info: iteration 36, average log likelihood -1.419887
[ Info: iteration 37, average log likelihood -1.419887
[ Info: iteration 38, average log likelihood -1.419887
[ Info: iteration 39, average log likelihood -1.419887
[ Info: iteration 40, average log likelihood -1.419887
[ Info: iteration 41, average log likelihood -1.419887
[ Info: iteration 42, average log likelihood -1.419887
[ Info: iteration 43, average log likelihood -1.419887
[ Info: iteration 44, average log likelihood -1.419887
[ Info: iteration 45, average log likelihood -1.419886
[ Info: iteration 46, average log likelihood -1.419886
[ Info: iteration 47, average log likelihood -1.419886
[ Info: iteration 48, average log likelihood -1.419886
[ Info: iteration 49, average log likelihood -1.419886
[ Info: iteration 50, average log likelihood -1.419886
┌ Info: EM with 100000 data points 50 iterations avll -1.419886
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.425284841153122
│     -1.4252147572796123
│      ⋮
└     -1.4198862955524294
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419907
[ Info: iteration 2, average log likelihood -1.419835
[ Info: iteration 3, average log likelihood -1.419780
[ Info: iteration 4, average log likelihood -1.419719
[ Info: iteration 5, average log likelihood -1.419647
[ Info: iteration 6, average log likelihood -1.419568
[ Info: iteration 7, average log likelihood -1.419486
[ Info: iteration 8, average log likelihood -1.419409
[ Info: iteration 9, average log likelihood -1.419343
[ Info: iteration 10, average log likelihood -1.419290
[ Info: iteration 11, average log likelihood -1.419249
[ Info: iteration 12, average log likelihood -1.419216
[ Info: iteration 13, average log likelihood -1.419190
[ Info: iteration 14, average log likelihood -1.419167
[ Info: iteration 15, average log likelihood -1.419146
[ Info: iteration 16, average log likelihood -1.419126
[ Info: iteration 17, average log likelihood -1.419104
[ Info: iteration 18, average log likelihood -1.419081
[ Info: iteration 19, average log likelihood -1.419057
[ Info: iteration 20, average log likelihood -1.419030
[ Info: iteration 21, average log likelihood -1.419002
[ Info: iteration 22, average log likelihood -1.418972
[ Info: iteration 23, average log likelihood -1.418941
[ Info: iteration 24, average log likelihood -1.418909
[ Info: iteration 25, average log likelihood -1.418879
[ Info: iteration 26, average log likelihood -1.418850
[ Info: iteration 27, average log likelihood -1.418824
[ Info: iteration 28, average log likelihood -1.418800
[ Info: iteration 29, average log likelihood -1.418780
[ Info: iteration 30, average log likelihood -1.418762
[ Info: iteration 31, average log likelihood -1.418747
[ Info: iteration 32, average log likelihood -1.418735
[ Info: iteration 33, average log likelihood -1.418725
[ Info: iteration 34, average log likelihood -1.418716
[ Info: iteration 35, average log likelihood -1.418709
[ Info: iteration 36, average log likelihood -1.418702
[ Info: iteration 37, average log likelihood -1.418697
[ Info: iteration 38, average log likelihood -1.418692
[ Info: iteration 39, average log likelihood -1.418688
[ Info: iteration 40, average log likelihood -1.418685
[ Info: iteration 41, average log likelihood -1.418682
[ Info: iteration 42, average log likelihood -1.418680
[ Info: iteration 43, average log likelihood -1.418677
[ Info: iteration 44, average log likelihood -1.418675
[ Info: iteration 45, average log likelihood -1.418674
[ Info: iteration 46, average log likelihood -1.418672
[ Info: iteration 47, average log likelihood -1.418671
[ Info: iteration 48, average log likelihood -1.418670
[ Info: iteration 49, average log likelihood -1.418669
[ Info: iteration 50, average log likelihood -1.418668
┌ Info: EM with 100000 data points 50 iterations avll -1.418668
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.419906539783354
│     -1.4198345542681872
│      ⋮
└     -1.4186677537984305
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418683
[ Info: iteration 2, average log likelihood -1.418622
[ Info: iteration 3, average log likelihood -1.418575
[ Info: iteration 4, average log likelihood -1.418521
[ Info: iteration 5, average log likelihood -1.418459
[ Info: iteration 6, average log likelihood -1.418388
[ Info: iteration 7, average log likelihood -1.418312
[ Info: iteration 8, average log likelihood -1.418235
[ Info: iteration 9, average log likelihood -1.418163
[ Info: iteration 10, average log likelihood -1.418096
[ Info: iteration 11, average log likelihood -1.418036
[ Info: iteration 12, average log likelihood -1.417982
[ Info: iteration 13, average log likelihood -1.417931
[ Info: iteration 14, average log likelihood -1.417883
[ Info: iteration 15, average log likelihood -1.417839
[ Info: iteration 16, average log likelihood -1.417797
[ Info: iteration 17, average log likelihood -1.417758
[ Info: iteration 18, average log likelihood -1.417721
[ Info: iteration 19, average log likelihood -1.417686
[ Info: iteration 20, average log likelihood -1.417652
[ Info: iteration 21, average log likelihood -1.417620
[ Info: iteration 22, average log likelihood -1.417590
[ Info: iteration 23, average log likelihood -1.417561
[ Info: iteration 24, average log likelihood -1.417534
[ Info: iteration 25, average log likelihood -1.417509
[ Info: iteration 26, average log likelihood -1.417486
[ Info: iteration 27, average log likelihood -1.417465
[ Info: iteration 28, average log likelihood -1.417445
[ Info: iteration 29, average log likelihood -1.417428
[ Info: iteration 30, average log likelihood -1.417411
[ Info: iteration 31, average log likelihood -1.417396
[ Info: iteration 32, average log likelihood -1.417382
[ Info: iteration 33, average log likelihood -1.417369
[ Info: iteration 34, average log likelihood -1.417357
[ Info: iteration 35, average log likelihood -1.417346
[ Info: iteration 36, average log likelihood -1.417335
[ Info: iteration 37, average log likelihood -1.417325
[ Info: iteration 38, average log likelihood -1.417315
[ Info: iteration 39, average log likelihood -1.417306
[ Info: iteration 40, average log likelihood -1.417297
[ Info: iteration 41, average log likelihood -1.417288
[ Info: iteration 42, average log likelihood -1.417280
[ Info: iteration 43, average log likelihood -1.417272
[ Info: iteration 44, average log likelihood -1.417265
[ Info: iteration 45, average log likelihood -1.417257
[ Info: iteration 46, average log likelihood -1.417250
[ Info: iteration 47, average log likelihood -1.417243
[ Info: iteration 48, average log likelihood -1.417237
[ Info: iteration 49, average log likelihood -1.417231
[ Info: iteration 50, average log likelihood -1.417224
┌ Info: EM with 100000 data points 50 iterations avll -1.417224
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4186829687179905
│     -1.4186221164457915
│      ⋮
└     -1.41722436672065
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417227
[ Info: iteration 2, average log likelihood -1.417176
[ Info: iteration 3, average log likelihood -1.417130
[ Info: iteration 4, average log likelihood -1.417080
[ Info: iteration 5, average log likelihood -1.417022
[ Info: iteration 6, average log likelihood -1.416952
[ Info: iteration 7, average log likelihood -1.416871
[ Info: iteration 8, average log likelihood -1.416781
[ Info: iteration 9, average log likelihood -1.416684
[ Info: iteration 10, average log likelihood -1.416587
[ Info: iteration 11, average log likelihood -1.416494
[ Info: iteration 12, average log likelihood -1.416407
[ Info: iteration 13, average log likelihood -1.416328
[ Info: iteration 14, average log likelihood -1.416257
[ Info: iteration 15, average log likelihood -1.416193
[ Info: iteration 16, average log likelihood -1.416134
[ Info: iteration 17, average log likelihood -1.416081
[ Info: iteration 18, average log likelihood -1.416032
[ Info: iteration 19, average log likelihood -1.415988
[ Info: iteration 20, average log likelihood -1.415947
[ Info: iteration 21, average log likelihood -1.415909
[ Info: iteration 22, average log likelihood -1.415873
[ Info: iteration 23, average log likelihood -1.415840
[ Info: iteration 24, average log likelihood -1.415809
[ Info: iteration 25, average log likelihood -1.415780
[ Info: iteration 26, average log likelihood -1.415752
[ Info: iteration 27, average log likelihood -1.415726
[ Info: iteration 28, average log likelihood -1.415700
[ Info: iteration 29, average log likelihood -1.415675
[ Info: iteration 30, average log likelihood -1.415652
[ Info: iteration 31, average log likelihood -1.415629
[ Info: iteration 32, average log likelihood -1.415606
[ Info: iteration 33, average log likelihood -1.415585
[ Info: iteration 34, average log likelihood -1.415564
[ Info: iteration 35, average log likelihood -1.415543
[ Info: iteration 36, average log likelihood -1.415524
[ Info: iteration 37, average log likelihood -1.415506
[ Info: iteration 38, average log likelihood -1.415488
[ Info: iteration 39, average log likelihood -1.415472
[ Info: iteration 40, average log likelihood -1.415456
[ Info: iteration 41, average log likelihood -1.415441
[ Info: iteration 42, average log likelihood -1.415428
[ Info: iteration 43, average log likelihood -1.415415
[ Info: iteration 44, average log likelihood -1.415403
[ Info: iteration 45, average log likelihood -1.415392
[ Info: iteration 46, average log likelihood -1.415381
[ Info: iteration 47, average log likelihood -1.415371
[ Info: iteration 48, average log likelihood -1.415362
[ Info: iteration 49, average log likelihood -1.415353
[ Info: iteration 50, average log likelihood -1.415345
┌ Info: EM with 100000 data points 50 iterations avll -1.415345
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4172274918579564
│     -1.4171757462200838
│      ⋮
└     -1.4153449984987923
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415345
[ Info: iteration 2, average log likelihood -1.415286
[ Info: iteration 3, average log likelihood -1.415230
[ Info: iteration 4, average log likelihood -1.415167
[ Info: iteration 5, average log likelihood -1.415091
[ Info: iteration 6, average log likelihood -1.414997
[ Info: iteration 7, average log likelihood -1.414885
[ Info: iteration 8, average log likelihood -1.414757
[ Info: iteration 9, average log likelihood -1.414619
[ Info: iteration 10, average log likelihood -1.414476
[ Info: iteration 11, average log likelihood -1.414335
[ Info: iteration 12, average log likelihood -1.414200
[ Info: iteration 13, average log likelihood -1.414076
[ Info: iteration 14, average log likelihood -1.413963
[ Info: iteration 15, average log likelihood -1.413863
[ Info: iteration 16, average log likelihood -1.413773
[ Info: iteration 17, average log likelihood -1.413694
[ Info: iteration 18, average log likelihood -1.413623
[ Info: iteration 19, average log likelihood -1.413560
[ Info: iteration 20, average log likelihood -1.413504
[ Info: iteration 21, average log likelihood -1.413452
[ Info: iteration 22, average log likelihood -1.413405
[ Info: iteration 23, average log likelihood -1.413362
[ Info: iteration 24, average log likelihood -1.413321
[ Info: iteration 25, average log likelihood -1.413284
[ Info: iteration 26, average log likelihood -1.413248
[ Info: iteration 27, average log likelihood -1.413215
[ Info: iteration 28, average log likelihood -1.413184
[ Info: iteration 29, average log likelihood -1.413155
[ Info: iteration 30, average log likelihood -1.413127
[ Info: iteration 31, average log likelihood -1.413100
[ Info: iteration 32, average log likelihood -1.413075
[ Info: iteration 33, average log likelihood -1.413051
[ Info: iteration 34, average log likelihood -1.413027
[ Info: iteration 35, average log likelihood -1.413005
[ Info: iteration 36, average log likelihood -1.412983
[ Info: iteration 37, average log likelihood -1.412962
[ Info: iteration 38, average log likelihood -1.412942
[ Info: iteration 39, average log likelihood -1.412922
[ Info: iteration 40, average log likelihood -1.412902
[ Info: iteration 41, average log likelihood -1.412884
[ Info: iteration 42, average log likelihood -1.412865
[ Info: iteration 43, average log likelihood -1.412848
[ Info: iteration 44, average log likelihood -1.412830
[ Info: iteration 45, average log likelihood -1.412814
[ Info: iteration 46, average log likelihood -1.412798
[ Info: iteration 47, average log likelihood -1.412782
[ Info: iteration 48, average log likelihood -1.412767
[ Info: iteration 49, average log likelihood -1.412753
[ Info: iteration 50, average log likelihood -1.412739
┌ Info: EM with 100000 data points 50 iterations avll -1.412739
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4153454327398685
│     -1.4152858046162458
│      ⋮
└     -1.4127387820447244
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4252643556226043
│     -1.425284841153122
│     -1.4252147572796123
│     -1.4251619915807403
│      ⋮
│     -1.4127669815494883
│     -1.4127525918600607
└     -1.4127387820447244
32×26 Array{Float64,2}:
  0.552405     0.683186      0.0153935   -0.0774821   -0.31711      0.178131     -0.415257      0.0132273   0.0342738  -0.150032    -0.76318     0.421465    -0.45888     0.142425     0.0677088   0.127985   -0.124566    -0.69141     0.196504     0.208348   -0.710511      0.224941    -0.265697    0.115387   -0.739424   -0.365068
 -0.0323322    0.198385     -0.211445    -0.0396382   -1.0523       0.274429      0.16149       0.523689    0.0641056   0.218001     0.295577    0.0705488   -0.36541     0.0242131   -0.3715     -0.0673365   0.30211     -0.0288166  -0.0365119    0.208788   -0.20066       0.196485    -0.616223   -0.352381    0.136353    0.794895
 -0.0104195    0.543198     -0.2723      -0.732729     0.0342577    0.184531     -0.330966     -0.574912    0.155567   -0.474897     0.0873133  -0.0613337   -0.10378    -1.19748     -0.298952    0.330283   -0.351798     0.335478   -1.18247      0.0561572  -0.386118     -0.413207    -0.210312    0.0900155  -0.488396   -0.0165674
  0.0171352    0.430699      0.0280002    0.0965981    0.295646     0.305831     -0.0150366     0.22279    -0.022735   -0.0900301    0.0387597   0.0916727    0.124087    0.265507    -0.0168355   0.740559    0.216081    -0.221248   -0.215847    -0.530363   -0.395703      0.161401    -0.0450178   0.196232    0.0840409  -0.205732
 -0.367722    -0.0447215     0.235914     0.604455    -0.0878738    0.354288      0.261167     -0.203695    0.491149    0.323109     0.592767   -0.436355     0.238706    0.30052      0.223368    0.264945   -0.171043    -0.676611   -0.38367     -0.463736    0.520064      0.0848659   -0.563948    0.609341    0.0937373  -0.344746
 -0.237764     0.0906687     0.0517221    0.490469    -0.133333     0.440235     -0.343789      0.0488427  -0.291732    0.497043     0.957398    0.112265     0.542341    0.0441243    0.0191362   0.307326   -0.00956344   0.343109    0.261361    -0.566513    0.202031      0.47263      0.0835295   0.0101224   0.220785    0.209433
  0.460401     0.33307      -0.145877     0.263609    -0.0813564   -0.583338     -0.163506     -0.432668    0.248115    0.108164     0.706375   -0.321634     0.605886   -0.101179    -0.489434   -0.554073    0.0404666   -0.588057    0.158423    -0.485393   -0.110925     -0.40507      0.191686   -0.0554657  -0.233113    0.0813315
  0.177942    -0.311762      0.265628     0.463114    -0.00721887  -0.657683      0.36637      -0.0169921  -0.228227    0.654176    -0.130371    0.224745     0.359839    0.63842      0.360661   -0.018633    0.623527    -0.401203    0.543152    -0.240906    0.0647417    -0.009193     0.141232    0.24869     0.127954   -0.0518096
 -0.550936    -0.680474      0.757722    -0.0946276   -0.0298757    0.178919     -0.52451      -0.261922   -0.0629343   0.0143403   -0.0142236   0.192273    -0.0604442  -0.145297    -0.769866   -0.262718   -0.143086     0.27613     0.236902     0.371168   -0.195806     -0.325616    -0.34742    -0.1286      0.217851   -0.110478
 -0.0567225   -0.380124      0.0471291   -0.193876     0.102121    -0.0988432     0.276921      0.0420134  -0.101073   -0.347055    -0.275008   -0.0574253   -0.245251   -0.225437     0.296627   -0.343775   -0.306775     0.512601    0.0841126    0.540635    0.396465      0.0406901    0.0473061  -0.21259     0.0945116   0.229407
 -0.436412    -0.133851     -0.680238    -0.236212    -0.0895005   -0.243221     -0.760135     -0.465572    0.882902    0.910563    -0.161436   -0.269484    -0.296995   -0.361643     0.156829   -0.167973    0.850439    -0.235331    0.0256986    0.446907    0.418359      0.0547495    0.0208742  -0.094651   -0.0551328  -0.0426882
 -0.876293    -0.0162365     0.641004     0.365809    -0.0725868    0.549264     -0.280099      0.0400913  -0.3663      0.376395     0.0939925   0.277622    -0.320869    0.0980303    0.280964   -0.0483938   0.622515     0.15637    -0.381164     0.666397    0.258588      0.133132    -0.240817    0.0351439   0.0214928  -0.562274
  0.422263    -0.101296      0.120866    -0.644886    -0.420307    -0.0185021    -0.0682768    -0.194212   -0.05143    -0.176776     0.0978502  -0.160901     0.0942586  -0.0497577   -0.0360237  -0.50113    -0.53475      0.269919    0.0111909    0.320477    0.213323      0.165703    -0.0404512  -0.161234   -0.713652    0.255286
  0.18832     -0.273077     -0.386113    -0.219444     1.05452     -0.0174533    -0.267988     -0.540037   -0.128125   -0.165483    -0.0718046  -0.067289     0.284138    0.178236    -0.181335   -0.0302575  -0.0584041    0.752324   -0.20074      0.148981    0.116106      0.20958      0.294222    0.303882   -0.290643    0.238315
  0.313818     0.647262     -0.983229    -0.120875     0.0952957   -0.10754       0.399071      0.392092    0.221041   -0.0907174   -0.105864   -0.292195    -0.443093   -0.18348      1.11011     0.266487   -0.0468608   -0.0504216  -0.0903298   -0.405095    0.312195      0.389922     0.459122    0.0487377  -0.214632    0.494205
  0.0719255    0.121229      0.00257132   0.0444437   -0.105852    -0.114371      0.225895     -0.300482    0.092006   -0.106532    -0.0807938  -0.239549    -0.183508    0.182316     0.968372   -0.772999   -0.212886     0.0906028   0.881799     0.234177    0.766775     -0.0417263    0.260579   -0.358517   -0.0949146   0.272225
 -0.163031     0.0934441    -0.039712    -0.1377       0.0151231    0.102176     -0.625634     -0.0672055   0.383777    0.212091    -0.0786296   0.0798575    0.23081     0.102113    -0.524284    0.227633    0.435694    -0.215475   -0.0228451   -0.191858   -0.327838     -0.399749    -0.0876173  -0.12507    -0.0635551  -0.486022
  0.473562     0.469238     -0.18874     -0.166764    -0.0280391   -0.330869      0.320616     -0.0520554   0.0730327   0.17075      0.0775852   0.112737     0.39204     0.0553535    0.0364555   0.242825    0.169177    -0.260925   -0.0244199   -0.49444    -0.179247     -0.00121547   0.18444    -0.152324   -0.370142    0.0959731
 -0.223718    -0.458489      0.584366    -0.0322067   -0.0592096   -0.425868     -0.000424849  -0.184856    0.0596299   0.00267324   0.451001   -0.489156     0.1117     -0.314209    -0.423033   -0.368097   -0.256805     0.172282   -0.0777884    0.507048    0.687612     -0.232861     0.298913   -0.205854    0.307927   -0.0759474
 -0.00396833  -0.23544       0.213703     0.266716     0.131829    -0.02447      -0.187361     -0.805229    0.0582146   0.20769      0.539294    0.135541    -0.094439   -0.409096    -0.711197   -0.23448     0.861835    -0.401119   -0.115711     0.0151327  -0.376446      0.450086    -0.0963381  -0.312056    0.254815    0.15268
 -0.0474848    0.476567      0.438727    -0.0320211    0.149613     0.595392      0.178654     -0.230943   -0.154657   -0.0494352    0.352463   -0.450248    -0.442322   -0.18949     -0.0348851  -0.130804   -0.324772    -0.243987    0.282267    -0.20345     0.081902      0.0758833   -0.401263   -0.282379   -0.383631    0.142077
 -0.0695342   -0.000702278   0.333415     0.473938     0.232571     0.0784675     0.603434     -0.169649   -0.0876389  -0.112907     0.21074     0.0147269   -0.508946   -0.774318     0.172963    0.0508965  -0.156944    -0.0632634   0.317234    -0.0567596  -0.00567151    0.374746     0.207455   -0.0573161   0.690034    0.329822
  0.120744    -0.420865      0.244426     0.443234     0.0937153   -0.578622      0.032834     -0.374255    0.560702    0.0271753   -0.562312    0.245341     0.0967925  -0.0146001   -0.0275201  -0.278782   -0.214765    -0.178356    0.232106     0.294396   -0.236688      0.00618428  -0.227479    0.383249    0.248232   -0.137032
  0.0700486   -0.0506555     0.187661    -0.0639015    0.0609391   -0.212807      0.110288      0.0448498   0.019054   -0.208835    -0.462981    0.398488    -0.39438    -0.52867      0.122296   -0.11592     0.397836    -0.203386    0.457033    -0.0349315  -0.721568     -0.339542     0.460125   -0.100876    0.212343    0.0553004
  0.226037    -0.220125     -0.0437696   -0.339297     0.101179     0.0186599    -0.0472411     0.248962   -0.147789   -0.0508682   -0.471906   -0.113197    -0.773745    0.0742529    0.151662    0.122305   -0.287883     0.2507     -0.564599     1.02384     0.0946758     0.21991     -0.454645    0.0305295   0.21537     0.225453
  0.379738     0.10705      -0.11429     -0.0685003   -0.372149    -0.0193284    -0.121143      0.270946   -0.131779    0.330987    -0.21314     0.0244306    0.635677    0.759881     0.321274    0.185138   -0.244348     0.33275    -0.589931     0.409456    0.282849     -0.0843613   -0.340433   -0.161668   -0.316427   -0.327777
  0.0364808   -0.260131      0.183609    -0.0451835   -0.0393248    0.000148417  -0.00614435   -0.168599    0.0487684  -0.0240841    0.0397602  -0.00331597   0.0357801  -0.104439    -0.263352   -0.0323926  -0.0773911    0.0897045   0.0184161    0.0536698   0.000397203   0.0687668   -0.113889    0.0250397   0.0369556   0.0584546
 -0.0762418    0.185263     -0.169075    -0.00175418   0.0962495    0.0861852    -0.036147      0.233731   -0.138351    0.0368771   -0.128912    0.0854684   -0.0046211   0.0834337    0.371423    0.0385838   0.00675093   0.0725553   0.00608137   0.0487599   0.0570492    -0.00560517   0.0659805  -0.0907388  -0.0753596   0.0725965
 -0.143201    -0.0247969     0.397127     0.0773103    0.128163     0.315549      0.212853      0.353475   -0.384923   -0.340383    -0.0212613   0.218138     0.451107    0.00528173  -0.740309    0.623334   -0.034816     0.215423   -0.671388    -0.347403   -0.759176      0.00424231  -0.279809    0.285363    0.21268    -0.346966
 -0.142288     0.0437257    -0.547514    -0.154485     0.193545     0.586512     -0.0629172     0.531734   -0.237042   -0.315906    -0.0491666   0.337192    -0.279407    0.0928068    0.0276729   0.458693    0.122158     0.0903328  -0.156109    -0.386144   -0.254248      0.267329    -0.351242    0.237722    0.169282    0.438207
 -0.177612    -0.290331     -0.0283765   -0.116043     0.150878    -0.0964486     0.269903      0.494539   -0.191976   -0.493666    -0.36912    -0.235335     0.780949    0.286877     0.258766    0.746409   -0.540971     0.346267    0.359021    -0.460345    0.448471     -0.269364     0.0106474  -0.402914   -0.169841   -0.301078
 -0.534024    -0.280235      0.0910883    0.171092     0.170608     0.240788     -0.0147271     0.78635    -0.36543    -0.640543    -0.501181    0.418589     0.114024    0.0875544    0.380447   -0.0234397  -0.196904     0.331624    0.251894     0.3511      0.128323      0.050157     0.473194    0.279921    0.210051   -0.295402[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412726
[ Info: iteration 2, average log likelihood -1.412713
[ Info: iteration 3, average log likelihood -1.412701
[ Info: iteration 4, average log likelihood -1.412689
[ Info: iteration 5, average log likelihood -1.412678
[ Info: iteration 6, average log likelihood -1.412667
[ Info: iteration 7, average log likelihood -1.412657
[ Info: iteration 8, average log likelihood -1.412647
[ Info: iteration 9, average log likelihood -1.412637
[ Info: iteration 10, average log likelihood -1.412628
┌ Info: EM with 100000 data points 10 iterations avll -1.412628
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.436776e+05
      1       7.087341e+05      -2.349435e+05 |       32
      2       6.963413e+05      -1.239278e+04 |       32
      3       6.910105e+05      -5.330834e+03 |       32
      4       6.881612e+05      -2.849322e+03 |       32
      5       6.864325e+05      -1.728679e+03 |       32
      6       6.852185e+05      -1.213947e+03 |       32
      7       6.842717e+05      -9.468816e+02 |       32
      8       6.834811e+05      -7.905799e+02 |       32
      9       6.828420e+05      -6.391005e+02 |       32
     10       6.823052e+05      -5.368018e+02 |       32
     11       6.818615e+05      -4.436987e+02 |       32
     12       6.814714e+05      -3.901085e+02 |       32
     13       6.811469e+05      -3.245155e+02 |       32
     14       6.808437e+05      -3.032061e+02 |       32
     15       6.805705e+05      -2.731499e+02 |       32
     16       6.803131e+05      -2.574392e+02 |       32
     17       6.800774e+05      -2.356811e+02 |       32
     18       6.798797e+05      -1.976941e+02 |       32
     19       6.796922e+05      -1.874475e+02 |       32
     20       6.795304e+05      -1.618279e+02 |       32
     21       6.793933e+05      -1.371136e+02 |       32
     22       6.792791e+05      -1.141801e+02 |       32
     23       6.791712e+05      -1.078699e+02 |       32
     24       6.790837e+05      -8.757860e+01 |       32
     25       6.790048e+05      -7.883749e+01 |       32
     26       6.789340e+05      -7.085713e+01 |       32
     27       6.788692e+05      -6.475824e+01 |       32
     28       6.788083e+05      -6.095383e+01 |       32
     29       6.787491e+05      -5.914731e+01 |       32
     30       6.786867e+05      -6.243459e+01 |       32
     31       6.786269e+05      -5.973543e+01 |       32
     32       6.785563e+05      -7.064291e+01 |       32
     33       6.785016e+05      -5.472516e+01 |       32
     34       6.784489e+05      -5.266970e+01 |       32
     35       6.784002e+05      -4.874613e+01 |       32
     36       6.783574e+05      -4.277017e+01 |       32
     37       6.783134e+05      -4.394708e+01 |       32
     38       6.782657e+05      -4.770139e+01 |       32
     39       6.782179e+05      -4.786039e+01 |       32
     40       6.781671e+05      -5.078168e+01 |       32
     41       6.781246e+05      -4.245852e+01 |       32
     42       6.780919e+05      -3.273985e+01 |       32
     43       6.780624e+05      -2.949433e+01 |       32
     44       6.780351e+05      -2.728339e+01 |       32
     45       6.780089e+05      -2.621128e+01 |       32
     46       6.779876e+05      -2.129907e+01 |       32
     47       6.779658e+05      -2.180030e+01 |       32
     48       6.779441e+05      -2.167420e+01 |       32
     49       6.779224e+05      -2.175415e+01 |       32
     50       6.779000e+05      -2.236349e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 677900.0214118669)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424531
[ Info: iteration 2, average log likelihood -1.419472
[ Info: iteration 3, average log likelihood -1.418022
[ Info: iteration 4, average log likelihood -1.416913
[ Info: iteration 5, average log likelihood -1.415831
[ Info: iteration 6, average log likelihood -1.414951
[ Info: iteration 7, average log likelihood -1.414398
[ Info: iteration 8, average log likelihood -1.414095
[ Info: iteration 9, average log likelihood -1.413923
[ Info: iteration 10, average log likelihood -1.413810
[ Info: iteration 11, average log likelihood -1.413727
[ Info: iteration 12, average log likelihood -1.413659
[ Info: iteration 13, average log likelihood -1.413602
[ Info: iteration 14, average log likelihood -1.413551
[ Info: iteration 15, average log likelihood -1.413506
[ Info: iteration 16, average log likelihood -1.413464
[ Info: iteration 17, average log likelihood -1.413426
[ Info: iteration 18, average log likelihood -1.413391
[ Info: iteration 19, average log likelihood -1.413358
[ Info: iteration 20, average log likelihood -1.413326
[ Info: iteration 21, average log likelihood -1.413297
[ Info: iteration 22, average log likelihood -1.413269
[ Info: iteration 23, average log likelihood -1.413241
[ Info: iteration 24, average log likelihood -1.413215
[ Info: iteration 25, average log likelihood -1.413190
[ Info: iteration 26, average log likelihood -1.413166
[ Info: iteration 27, average log likelihood -1.413142
[ Info: iteration 28, average log likelihood -1.413119
[ Info: iteration 29, average log likelihood -1.413096
[ Info: iteration 30, average log likelihood -1.413074
[ Info: iteration 31, average log likelihood -1.413053
[ Info: iteration 32, average log likelihood -1.413032
[ Info: iteration 33, average log likelihood -1.413011
[ Info: iteration 34, average log likelihood -1.412991
[ Info: iteration 35, average log likelihood -1.412972
[ Info: iteration 36, average log likelihood -1.412952
[ Info: iteration 37, average log likelihood -1.412934
[ Info: iteration 38, average log likelihood -1.412915
[ Info: iteration 39, average log likelihood -1.412897
[ Info: iteration 40, average log likelihood -1.412880
[ Info: iteration 41, average log likelihood -1.412863
[ Info: iteration 42, average log likelihood -1.412846
[ Info: iteration 43, average log likelihood -1.412830
[ Info: iteration 44, average log likelihood -1.412814
[ Info: iteration 45, average log likelihood -1.412798
[ Info: iteration 46, average log likelihood -1.412783
[ Info: iteration 47, average log likelihood -1.412768
[ Info: iteration 48, average log likelihood -1.412753
[ Info: iteration 49, average log likelihood -1.412738
[ Info: iteration 50, average log likelihood -1.412724
┌ Info: EM with 100000 data points 50 iterations avll -1.412724
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.137504      0.154125     0.396896   -0.0419716  -0.266608     0.311484    0.277003   -0.138677    0.152894    -0.00106816   0.446789    -0.354297   -0.215431     -0.209205     0.16155    -0.137618    -0.629646     -0.248737     0.0820106   -0.0831218   0.509405     0.282704   -0.258757    -0.101292   -0.217307     0.134341
 -0.083965      0.43337     -0.595438   -0.417404   -0.187122     0.814495   -0.249008    0.757482   -0.448582    -0.111362     0.303782    -0.126671   -0.225808      0.201385    -0.107498    0.251027     0.31984       0.00605521  -0.301572    -0.26435    -0.040863     0.173488   -0.341783    -0.230658    0.0368074    0.4505
  0.220647      0.0888989   -0.106666   -0.168402   -0.112308    -0.166773   -0.030606   -0.196605    0.237144     0.245473     0.0144663    0.0292963   0.0960632     0.00400778  -0.121881    0.0359081    0.178229     -0.161296     0.00884653  -0.0555689  -0.107396    -0.0310324  -0.00835324  -0.217778   -0.157384     0.066057
 -0.315909     -0.390778     0.932614    0.0579193  -0.290221    -0.0363706   0.103979   -0.310226   -0.454493     0.306401     0.351876    -0.132249    0.0448442     0.0467122   -0.267541   -0.570792     0.0105255     0.0558569    0.57964      0.346216    0.563218    -0.406502   -0.0582297   -0.339235    0.180882     0.0335567
  0.000510333   0.0341438    0.292933   -0.279002    0.137028     0.155884   -0.171365    0.126872   -0.0728805   -0.219308    -0.285629    -0.136198    0.472868      0.499986    -0.278883    0.323596    -0.0430304    -0.0815136   -0.104724    -0.151191   -0.0771038   -0.447075   -0.242662    -0.320623   -0.253234    -0.796228
  0.184255     -0.0921846    0.0258247  -0.353241    0.356156     0.37747    -0.32702    -0.783301    0.187121     0.0135367    0.0963888   -0.315       0.0510326    -0.376595    -0.484253   -0.00236696  -0.217716      0.542534    -0.340642     0.163191   -0.21442     -0.114082   -0.370744     0.187378   -0.445144     0.241783
 -0.0938622     0.0324749    0.37101     0.0136662   0.00972982   0.153432   -0.0639597  -0.405048    0.395318    -0.0381494   -0.204815    -0.0248953  -0.533089     -0.65496     -0.42669    -0.413412     0.555916     -0.987493     0.473241    -0.329619   -0.761453    -0.137834   -0.0535645   -0.156664    0.144107    -0.0775124
  0.108132     -0.0182451   -0.44609    -0.163595   -0.626916    -0.271572   -0.12381    -0.148237    0.800174     0.774678     0.0456474   -0.0119435  -0.375527     -0.219568     0.042395   -0.147743     0.513483     -0.162195     0.193509     0.370122   -0.00174863   0.306205   -0.28369     -0.239699   -0.0491794    0.585812
 -0.267011     -0.412167     0.170052   -0.163335   -0.136013     0.191338   -0.778167    0.0789377  -0.240084    -0.222646    -0.563753     0.421606   -0.340614      0.136855    -0.240271   -0.141744    -0.152552      0.502846    -0.0451203    0.772634    0.00114868  -0.0633214  -0.204837    -0.188198   -0.055709    -0.175576
 -0.343014     -0.423157     0.2446      0.155649    0.235427     0.0808325  -0.245576   -0.406471   -0.0810291    0.0483584    0.928414     0.101715   -0.173271     -0.712238    -0.533039   -0.055013     0.000100331   0.437244     0.251814     0.0607541  -0.0637133    0.569602    0.4787      -0.251489    0.894275     0.245436
  0.345032      0.805536    -0.210306    0.0583642  -0.0182129    0.0799455   0.419411    0.248284    0.12937     -0.190797    -0.593072     0.189543   -0.408817      0.11641      0.545483    0.411012    -0.0686064    -0.951222    -0.0570627   -0.0641903  -0.236659     0.117889   -0.500881     0.164995   -0.513271     0.0408734
  0.0438034     0.17446     -0.0265224  -0.659258   -0.229334    -0.234782   -0.0699783  -0.186059   -0.122188    -0.501972     0.0136699   -0.0318033  -0.443392     -0.923016     0.319369   -0.654536    -0.32211       0.6318      -0.276036     0.649608    0.373751    -0.247584    0.0560003   -0.433298   -0.37369      0.270586
  0.153664      0.383075     0.264426    0.487961   -0.161341     0.22485    -0.100359   -0.156344   -0.170342     0.33586      0.586165    -0.142524    0.332713      0.296598    -0.214593    0.248338     0.206839     -0.534877    -0.0101809   -0.534515   -0.0860299    0.100802   -0.185702     0.0117749   0.0239216   -0.0681037
  0.1982       -0.280486    -0.0222258  -0.236987    0.118492     0.0568253   0.0719262   0.25831    -0.177197    -0.0808587   -0.481577    -0.17528    -0.705471      0.0404428    0.283975    0.0500149   -0.363078      0.224593    -0.49336      0.996526    0.116798     0.361211   -0.374834     0.113853    0.255849     0.268152
 -0.796695     -0.103612     0.17821     0.213726    0.123344     0.17653    -0.493421   -0.102015    0.402707     0.541826     0.158882    -0.0228364  -0.000746635   0.157458     0.0412691   0.383899     0.635127     -0.207258    -0.441929     0.254722    0.146814    -0.132907    0.105389     0.744971    0.234737    -0.896212
 -0.473745     -0.254827     0.428418    0.305841   -0.204637     0.15516    -0.0989966  -0.0917207  -0.490977     0.230016     0.283188     0.121998   -0.0415891     0.312752    -0.381001   -0.275547     0.827029     -0.12288     -0.675946     0.693837   -0.23816      0.330079   -0.757618    -0.322694   -0.0177768   -0.1278
  0.116759     -0.449656     0.497774    0.581083    0.0313447   -0.870157    0.138423   -0.361764    0.502516    -0.0656526   -0.397128     0.0802225   0.0660946    -0.149491    -0.13215    -0.252324    -0.272513     -0.187281     0.140998     0.313816   -0.0148497   -0.0927126  -0.106936     0.273051    0.34312     -0.199409
  1.1311        0.183513     0.183155   -0.422025   -0.231773    -0.38859     0.32933    -0.153      -0.357457    -0.555911    -0.0751923    0.0235824   0.271657      0.294156    -0.539353   -0.0162446   -0.547681      0.07488      0.133348     0.113268   -0.255098     0.33014     0.364282    -0.109853   -0.454883     0.240881
 -0.20485       0.0362598   -0.0362264   0.627948    0.0579585    0.309542    0.0790504  -0.182254    0.0880725    0.360219     0.55866      0.126627    0.376439      0.0869165   -0.0134037   0.343815     0.157954     -0.166506     0.0020135   -0.747899    0.203607     0.244194   -0.257625     0.367059    0.178306     0.224972
  0.358147      0.184864    -0.759583   -0.0159668   0.0476869   -0.710704   -0.19394    -0.0180243   0.33292      0.171781     0.960877    -0.528366    0.715461     -0.0165894   -0.554259   -0.797858    -0.105282     -0.431872    -0.149059    -0.454887   -0.145673    -0.303256    0.15642      0.119931   -0.435387     0.260226
 -0.167379     -0.523578    -0.0105241   0.0398251   0.523174    -0.158226    0.628165    0.0353001   0.0170251   -0.103516    -0.183772    -0.282251    0.158041      0.0215297    0.264142    0.0356782   -0.177604      0.273284     0.159972     0.0217584   0.555478     0.0876764   0.0971395   -0.0153655   0.163617     0.199912
  0.318821      0.520631    -0.369748   -0.0767623   0.0499427   -0.0274235   0.51545     0.41816     0.00815375  -0.250703    -0.151392    -0.0736703   0.171372     -0.217771     0.968734    0.248407    -0.15283       0.13587      0.407551    -0.674303    0.21812      0.0399801   0.698467    -0.40328    -0.0965412   -0.0221143
 -0.724533     -0.0507425    0.451654    0.424729   -0.128311     0.483712    0.438861    1.10754    -0.433289    -0.482294    -0.0486805    0.241996    0.0661494     0.0620008    0.239175    0.325882    -0.2393        0.313153     0.164475     0.0503405  -0.157827     0.160666    0.0187841    0.163749    0.41796     -0.210648
  0.690866      0.394797     0.115562    0.771801    0.025586    -0.0966793  -0.461257   -0.0805696  -0.132599     0.528801    -0.0977794    0.70811     0.102372     -0.00547908   0.281311   -0.142454     0.326629     -0.379926    -0.0903199   -0.106374   -0.76782      0.394862    0.314578    -0.264971    0.0459712   -0.487158
  0.193832      0.136281    -0.241734    0.128437    0.178282     0.0309077  -0.0718231  -0.378776    0.0713048   -0.164265    -0.0827642   -0.44797    -0.264591      0.245892     0.810207   -0.680683    -0.121274      0.060565     0.865284     0.470492    0.887379     0.101386    0.531663    -0.062936   -0.239576     0.471611
 -0.184379     -0.494621    -0.335218   -0.206999    0.185927     0.10352    -0.287008    0.247944    0.205965    -0.326252    -0.731456     0.6967      0.228692      0.090822     0.223856   -0.0704934    0.0154219     0.387035     0.489163    -0.0314413  -0.121248    -0.115462    0.224765     0.257491    0.0585844    0.0563253
  0.419257     -0.0388626    0.441982   -0.0889522   0.143826    -0.922129   -0.13202    -0.685573    0.577759     0.426717     0.0524284   -0.238475    0.876552      0.265059     0.402614   -0.335915     0.355326     -0.306139     0.148452     0.0428181  -0.148471    -0.408549    0.602776     0.0409171  -0.00229375  -0.817878
  0.213608      0.0298597   -0.266263   -0.0618422  -0.247073    -0.0159102  -0.134412    0.272563   -0.170327     0.462745    -0.17924      0.0706271   0.494477      0.77752      0.436263    0.24379     -0.446773      0.565089    -0.368502     0.275603    0.472574     0.0663607  -0.303363    -0.0452266  -0.369847    -0.0146969
 -0.0600221    -0.297531    -0.0753418  -0.141736    0.268223    -0.0670002   0.0409919   0.192363   -0.216076    -0.442106    -0.00881734  -0.156047    0.289414      0.0633469   -0.112149    0.128524    -0.162461      0.424124    -0.288862     0.042112    0.262626     0.145577    0.106769     0.1657      0.065178    -0.0681208
  0.0616446     0.427005    -0.296255   -0.292087    0.22682      0.25433    -0.263328    0.0607138   0.0560778   -0.458909    -0.0394338    0.312356    0.0754881    -0.352936    -0.354423    0.644791    -0.0465944     0.175912    -0.674501    -0.433669   -0.752383    -0.0221812  -0.155101     0.229027   -0.100733    -0.0692287
  0.0640915    -0.00100494  -0.122068    0.184171    0.210123    -0.825948    0.315631    0.115827   -0.706208     0.327582    -0.181238     0.355862   -0.0606334     0.283393     0.276407    0.248199     0.649015     -0.0666782    0.43793     -0.334899   -0.134983    -0.0502138   0.519199     0.104376   -0.10888      0.453481
 -0.143844      0.0216762    0.203299    0.179388    0.152558     0.240355    0.0388576   0.0557971  -0.131384    -0.136853    -0.14541      0.21058    -0.32163      -0.391896     0.0637767  -0.0368918    0.0222518     0.0275659    0.159314     0.126732   -0.308134    -0.0386789   0.0257471    0.0239208   0.175818     0.0983216[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412710
[ Info: iteration 2, average log likelihood -1.412696
[ Info: iteration 3, average log likelihood -1.412683
[ Info: iteration 4, average log likelihood -1.412669
[ Info: iteration 5, average log likelihood -1.412656
[ Info: iteration 6, average log likelihood -1.412643
[ Info: iteration 7, average log likelihood -1.412631
[ Info: iteration 8, average log likelihood -1.412618
[ Info: iteration 9, average log likelihood -1.412606
[ Info: iteration 10, average log likelihood -1.412594
┌ Info: EM with 100000 data points 10 iterations avll -1.412594
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
