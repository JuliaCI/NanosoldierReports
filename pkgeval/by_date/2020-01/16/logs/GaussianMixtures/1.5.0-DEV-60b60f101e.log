Julia Version 1.5.0-DEV.77
Commit 60b60f101e (2020-01-16 15:44 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed GaussianMixtures ─── v0.3.0
 Installed LegacyStrings ────── v0.4.1
 Installed Rmath ────────────── v0.6.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed Arpack ───────────── v0.4.0
 Installed QuadGK ───────────── v2.3.1
 Installed SpecialFunctions ─── v0.9.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Distances ────────── v0.8.2
 Installed BinaryProvider ───── v0.5.8
 Installed CMake ────────────── v1.1.2
 Installed BinDeps ──────────── v1.0.0
 Installed JLD ──────────────── v0.9.1
 Installed StaticArrays ─────── v0.12.1
 Installed URIParser ────────── v0.4.0
 Installed Parameters ───────── v0.12.0
 Installed HDF5 ─────────────── v0.12.5
 Installed DataAPI ──────────── v1.1.0
 Installed FileIO ───────────── v1.2.1
 Installed StatsFuns ────────── v0.9.3
 Installed DataStructures ───── v0.17.9
 Installed NearestNeighbors ─── v0.4.4
 Installed StatsBase ────────── v0.32.0
 Installed FillArrays ───────── v0.8.4
 Installed OrderedCollections ─ v1.1.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed Blosc ────────────── v0.5.1
 Installed SortingAlgorithms ── v0.3.1
 Installed Missings ─────────── v0.4.3
 Installed Compat ───────────── v2.2.0
 Installed Clustering ───────── v0.13.3
 Installed PDMats ───────────── v0.9.10
 Installed Distributions ────── v0.22.3
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_9S8njN/Project.toml`
 [no changes]
  Updating `/tmp/jl_9S8njN/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_Qfezui/Project.toml`
 [no changes]
  Updating `/tmp/jl_Qfezui/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_71tqUj/Project.toml`
 [no changes]
  Updating `/tmp/jl_71tqUj/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_wYSYS5/Project.toml`
 [no changes]
  Updating `/tmp/jl_wYSYS5/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_VcIIhh/Project.toml`
 [no changes]
  Updating `/tmp/jl_VcIIhh/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_VcIIhh/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.5796654548858625e6, [692.4142808555978, 99307.58571914442], [1761.1209073279697 594.2273203218003 355.5970300551879; -1663.2905326067157 -68.09388646483006 -587.7614592147178], [[4572.282495095029 1469.5038105489805 851.0801032878187; 1469.5038105489805 843.1611458999485 154.84142996990516; 851.0801032878187 154.84142996990516 782.522838642594], [94692.21274503833 -1223.4846383788872 -691.4744289813302; -1223.4846383788872 99006.63173823882 -296.2605105697944; -691.4744289813302 -296.2605105697943 98294.70841979819]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.327816e+03
      1       9.745299e+02      -3.532859e+02 |        5
      2       9.628177e+02      -1.171213e+01 |        2
      3       9.395805e+02      -2.323724e+01 |        2
      4       9.216823e+02      -1.789822e+01 |        2
      5       9.199418e+02      -1.740498e+00 |        0
      6       9.199418e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 919.9417853547948)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.072306
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.911683
[ Info: iteration 2, lowerbound -3.812144
[ Info: iteration 3, lowerbound -3.695025
[ Info: iteration 4, lowerbound -3.536094
[ Info: iteration 5, lowerbound -3.340282
[ Info: iteration 6, lowerbound -3.131891
[ Info: iteration 7, lowerbound -2.944574
[ Info: dropping number of Gaussions to 7
[ Info: iteration 8, lowerbound -2.787574
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.658588
[ Info: iteration 10, lowerbound -2.556775
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.483233
[ Info: iteration 12, lowerbound -2.426581
[ Info: iteration 13, lowerbound -2.391428
[ Info: dropping number of Gaussions to 3
[ Info: iteration 14, lowerbound -2.355855
[ Info: iteration 15, lowerbound -2.326419
[ Info: iteration 16, lowerbound -2.310455
[ Info: iteration 17, lowerbound -2.308134
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302915
[ Info: iteration 19, lowerbound -2.299259
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan 17 00:54:42 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan 17 00:54:50 2020: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Fri Jan 17 00:54:52 2020: EM with 272 data points 0 iterations avll -2.072306
5.8 data points per parameter
, Fri Jan 17 00:54:54 2020: GMM converted to Variational GMM
, Fri Jan 17 00:55:02 2020: iteration 1, lowerbound -3.911683
, Fri Jan 17 00:55:02 2020: iteration 2, lowerbound -3.812144
, Fri Jan 17 00:55:02 2020: iteration 3, lowerbound -3.695025
, Fri Jan 17 00:55:02 2020: iteration 4, lowerbound -3.536094
, Fri Jan 17 00:55:02 2020: iteration 5, lowerbound -3.340282
, Fri Jan 17 00:55:02 2020: iteration 6, lowerbound -3.131891
, Fri Jan 17 00:55:02 2020: iteration 7, lowerbound -2.944574
, Fri Jan 17 00:55:03 2020: dropping number of Gaussions to 7
, Fri Jan 17 00:55:03 2020: iteration 8, lowerbound -2.787574
, Fri Jan 17 00:55:03 2020: dropping number of Gaussions to 5
, Fri Jan 17 00:55:03 2020: iteration 9, lowerbound -2.658588
, Fri Jan 17 00:55:03 2020: iteration 10, lowerbound -2.556775
, Fri Jan 17 00:55:03 2020: dropping number of Gaussions to 4
, Fri Jan 17 00:55:03 2020: iteration 11, lowerbound -2.483233
, Fri Jan 17 00:55:03 2020: iteration 12, lowerbound -2.426581
, Fri Jan 17 00:55:03 2020: iteration 13, lowerbound -2.391428
, Fri Jan 17 00:55:03 2020: dropping number of Gaussions to 3
, Fri Jan 17 00:55:03 2020: iteration 14, lowerbound -2.355855
, Fri Jan 17 00:55:03 2020: iteration 15, lowerbound -2.326419
, Fri Jan 17 00:55:03 2020: iteration 16, lowerbound -2.310455
, Fri Jan 17 00:55:03 2020: iteration 17, lowerbound -2.308134
, Fri Jan 17 00:55:03 2020: dropping number of Gaussions to 2
, Fri Jan 17 00:55:03 2020: iteration 18, lowerbound -2.302915
, Fri Jan 17 00:55:03 2020: iteration 19, lowerbound -2.299259
, Fri Jan 17 00:55:03 2020: iteration 20, lowerbound -2.299256
, Fri Jan 17 00:55:03 2020: iteration 21, lowerbound -2.299254
, Fri Jan 17 00:55:03 2020: iteration 22, lowerbound -2.299254
, Fri Jan 17 00:55:03 2020: iteration 23, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 24, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 25, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 26, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 27, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 28, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 29, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 30, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 31, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 32, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 33, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 34, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 35, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 36, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 37, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 38, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 39, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 40, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 41, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 42, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 43, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 44, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 45, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 46, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 47, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 48, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 49, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: iteration 50, lowerbound -2.299253
, Fri Jan 17 00:55:03 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398614, 178.04509222601388]
β = [95.95490777398614, 178.04509222601388]
m = [2.00022925777537 53.8519871724613; 4.25030073326991 79.28686694436183]
ν = [97.95490777398614, 180.04509222601388]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119484 -0.008953123827346173; 0.0 0.012748664777409427], [0.18404155547484383 -0.0076440490423270654; 0.0 0.008581705166333409]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -1.011424429187932
avll from llpg:  -1.0114244291879315
avll direct:     -1.0114244291879315
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9702578194792731
avll from llpg:  -0.970257819479273
avll direct:     -0.9702578194792729
sum posterior: 99999.99999999999
32×26 Array{Float64,2}:
  0.0686177    0.00484487  -0.0301543    0.113105    -0.0619135    0.0352285   -0.136129     0.0139138    0.0343672    0.0478294   -0.0663735   -0.0364497   -0.115819     -0.0467905   -0.0919013   0.00744999   0.130106     0.106882    -0.0186212    0.043431     0.000134136  -0.209253    -0.0826211   -0.0843172     0.123106     0.134511
 -0.103783    -0.0408445    0.117186    -0.0791359   -0.0449652   -0.0179057   -0.0288344    0.0868703    0.143312    -0.110031    -0.0982601    0.037764    -0.0925081     0.107995     0.0996076   0.0515826   -0.110414     0.202285    -0.0315695    0.0262665    0.13074       0.167232    -0.030546    -0.0548699    -0.00776579  -0.000152349
  0.0139805   -0.227699     0.0496457    0.0420434   -0.0101764   -0.0421356   -0.0506206    0.00120743   0.0417568    0.0216107   -0.124399     0.0189382    0.147567     -0.021857    -0.19017    -0.246954    -0.0218256    0.0817994   -0.115561    -0.01573      0.129781     -0.338778     0.0240631    0.111624     -0.0535151   -0.0549757
  0.0778814    0.0613807    0.105186     0.0384401   -0.0889794   -0.0201317    0.037246     0.172999     0.0819051   -0.190248    -0.13013     -0.089996     0.133951      0.036033    -0.182723   -0.225991    -0.144338    -0.0363796   -0.114917    -0.0110702   -0.0271323    -0.0827441    0.0738894   -0.0101317    -0.0110982   -0.139888
 -0.0165627   -0.028773    -0.158632    -0.0707946   -0.0745299    0.136931    -0.0952669    0.182674     0.108235    -0.0956925   -0.0749922   -0.197232    -0.13901      -0.0474136   -0.0827809  -0.00963686  -0.0398156    0.0189856   -0.0550405    0.0953664    0.0479138     0.0536575   -0.0787367    0.12551       0.0383191   -0.182423
 -0.100126     0.0869699    0.0180532    0.150582     0.0748577   -0.111285    -0.338785    -0.0309694    0.146263    -0.0195521   -0.121195     0.0655002   -0.0339908    -0.0506998    0.121375   -0.207323    -0.0963039    0.0758122   -0.0518393    0.0468151    0.200408     -0.089886     0.0453107    0.00810995    0.0799957    0.0070551
  0.0128314    0.088735    -0.150126    -0.128676     0.0916323   -0.0678376   -0.115542    -0.0922452    0.250512     0.00707882  -0.112723     0.00802462  -0.0656224    -0.102261    -0.0978941  -0.0570115    0.0345205   -0.0499119    0.0706359    0.0374404    0.0543369     0.106071     0.00389263  -0.018022      0.0426071    0.036235
  0.0930346    0.120336     0.146496     0.0481656   -0.103239     0.072601    -0.0899691    0.0536882    0.0254922    0.131454     0.116924     0.0611618   -0.122465     -0.102395    -0.158185    0.0706806   -0.042106     0.0175849    0.136298    -0.07027     -0.034108      0.0408869    0.0277973   -0.230735      0.00763347   0.141576
 -0.157965     0.265242     0.110712    -0.0618842    0.0738398   -0.0013372   -0.0440285   -0.0527675   -0.0422428   -0.314346    -0.0902842   -0.123833    -0.108084     -0.0464627    0.0474776   0.0769795   -0.0780728    0.0270983    0.081493     0.187727    -0.103315     -0.0845021    0.14156     -0.0373395     0.023739    -0.0417014
  0.0265236   -0.0348429   -0.0452451   -0.143477     0.0502271   -0.013464     0.0338041    0.0223902   -0.126229     0.0497496   -0.0371268   -0.203484    -0.0570693     0.0483299    0.0263375   0.0525451   -0.0574012    0.0164251   -0.0051087   -0.164911     0.0708533    -0.135547     0.0212793   -0.0293438    -0.0836898   -0.0377172
 -0.00412398   0.0816489   -0.137162    -0.00219048  -0.048994    -0.0730519   -0.00450351  -0.0728004   -0.0438987    0.140733     0.135423    -0.0173792   -0.2087        0.175643    -0.0469446  -0.178982     0.0586462    0.110827     0.0108986    0.184101     0.0575548    -0.090695     0.0702172    0.0507858    -0.0593458   -0.162279
 -0.163507    -0.0433034    0.00686462  -0.0198868   -0.0597905    0.0209498   -0.022645    -0.027638     0.039987     0.13799      0.0733191   -0.0125117   -0.206768      0.0262508   -0.0906133   0.0450916    0.172458    -0.0591545   -0.0285702    0.151246    -0.0350248    -0.0162323    0.102734    -0.0787604    -0.103791     0.0958573
 -0.00713056   0.102979     0.0240516   -0.148019    -0.0253735   -0.140385     0.0989543    0.199613    -0.017894    -0.00949406  -0.113357    -0.00764627   0.233633      0.0281265   -0.156623    0.0669373   -0.160942    -0.0159443   -0.0222143    0.0358619    0.0800492     0.139502    -0.0588988    0.0770456    -0.009843    -0.0048403
  0.0654672   -0.0157188   -0.0737191    0.127029    -0.0451043   -0.00245623  -0.041875    -0.216107    -0.060982     0.0163654    0.0800441    0.0435463   -0.0678149    -0.0901774   -0.0803468  -0.0757366    0.0546591   -0.0462792    0.0698331    0.138006    -0.0830133     0.00744679  -0.00891748  -0.200564     -0.0668853   -0.0585245
 -0.0897304    0.0849907    0.0973047   -0.00671376   0.0498782   -0.0199772    0.0515294    0.0690796    0.0581161   -0.111888    -0.0668047    0.0941505    0.0122316    -0.183866     0.0729018  -0.0400274    0.0691304    0.00540526   0.079878    -0.0422382   -0.0467104    -0.035295     0.0223384    0.0390957    -0.0647437    0.134126
  0.121901     0.166168     0.0200283    0.0246627   -0.0379918   -0.0484232   -0.0208176   -0.105623    -0.00366529   0.161142     0.0472765    0.0393567    0.0658288     0.0637551    0.051825    0.0519406   -0.0436434    0.23039     -0.0578747   -0.111834    -0.0109544     0.0577543   -0.0265006    0.00502333    0.0195399    0.0548743
  0.0199191    0.0606681   -0.112203    -0.0914358    0.042892    -0.115726    -0.0969929    0.0350794   -0.040343    -0.0685416    0.116818    -0.170261     0.0307263     0.200489    -0.0373736  -0.168341     0.191743     0.0213746    0.125788     0.00167651  -0.00333928    0.0578547   -0.1766      -0.0456389     0.0656289    0.0304488
  0.0421327   -0.00528656  -0.0393807   -0.072459     0.142215     0.0764679   -0.002338     0.119447     0.208751    -0.0302509   -0.103471    -0.0132463   -0.103529     -0.0543874    0.0295371   0.0495075    0.211987    -0.12442      0.190865    -0.066751    -0.0289737    -0.068509     0.114468    -0.0269059     0.0313442   -0.0715016
 -0.0245757    0.0471538    0.0349915    0.0164909    0.0533205    0.00115598   0.0128812   -0.0839289    0.0584186   -0.0387573   -0.042448     0.0650329    0.0398304    -0.0183595   -0.0683741   0.00608485   0.141897     0.0863916   -0.0340887    0.0980453    0.0136372    -0.120296     0.011117    -0.0913751    -0.0272698   -0.0481934
 -0.10011      0.093152    -0.0731661   -0.0135892   -0.196327     0.0863203   -0.118225    -0.0619858   -0.0585235   -0.0154595   -0.155636     0.0682049   -0.039168      0.00443678   0.217849   -0.135768     0.0691931   -0.00199942   0.00262294  -0.0167926   -0.124349      0.118686    -0.009941    -0.147291     -0.189185    -0.00732407
  0.0355016    0.11176     -0.0920165   -0.0194515   -0.112173     0.113132    -0.0142183    0.0235413    0.214728     0.121623     0.102649     0.0151108    0.0643072    -0.126624    -0.0625777  -0.00223989   0.0137888   -0.0464014    0.0686479    0.124258    -0.00620742   -0.0172884   -0.0661073   -0.189247     -0.030441    -0.118662
 -0.0101493   -0.210052     0.0965107    0.083776    -0.0683612   -0.252993    -0.0949623   -0.0371283   -0.131792     0.312616     0.00445457   0.0781457   -0.050039      0.0544402   -0.129951    0.00530382  -0.0489945    0.147179    -0.0678784    0.108912    -0.0319788     0.104547    -0.0529904    0.0313547     0.036789     0.00541478
  0.0487799    0.0185722   -0.0591376    0.0428866   -0.0449038   -0.0510475    0.00949952   0.27141      0.0303707    0.062253     0.0524524    0.0864254   -0.000243464  -0.0599053    0.0017724   0.0483003   -0.00305207   0.132107    -0.106922     0.0132952    0.321933     -0.146662     0.0411163   -0.122507     -0.174906    -0.0104403
 -0.115239     0.152229    -0.00701423  -0.184829     0.0292863    0.016533    -0.1639      -0.0309448    0.0968491   -0.107931    -0.0586048   -0.0820152    0.0270242     0.0601046    0.0243173  -0.040308    -0.204223     0.118609    -0.0533468   -0.0475087   -0.0347573     0.0377439   -0.152304     0.0227777    -0.0458726    0.0928252
 -0.19332     -0.0404176    0.0163583    0.122076    -0.12915     -0.00779438   0.042302     0.0243519    0.0697351    0.0605727   -0.00716331   0.157623     0.0106317     0.130204     0.0416459  -0.0154248    0.051443     0.0453018    0.0240274   -0.213566    -0.128073     -0.00167465   0.0513805    0.000732292  -0.0630755   -0.0683229
 -0.143565     0.106793    -0.052988     0.104628    -0.134438    -0.0366954    0.0888271   -0.00453907   0.0236747   -0.0549428   -0.111291     0.0310647    0.0817766     0.159995    -0.145802   -0.115249     0.0765838    0.0142069   -0.054888    -0.0413095   -0.158561     -0.00621368  -0.0695469   -0.0167462    -0.00627978   0.00658598
  0.0146709    0.0039484   -0.0451484   -0.0612632    0.151939     0.142316    -0.0553654    0.0296709   -0.165934     0.0569466    0.0651431   -0.126094    -0.00618552   -0.0156987   -0.0165201  -0.151386    -0.051751     0.0701217   -0.021024     0.0112082    0.127107     -0.235817     0.0503683    0.0770418     0.17643     -0.0162257
 -0.00151186  -0.00989754  -0.0803505    0.156235    -0.0630318    0.0551699   -0.116976     0.0813906    0.0194851   -0.0714368   -0.116212     0.0258893    0.261254      0.0339131   -0.0415055   0.0668022   -0.123501     0.0528002    0.174628     0.0200781   -0.0824718     0.0655632    0.126124    -0.0185717     0.381517     0.0178609
  0.0251494   -0.00587385  -0.0348342   -0.0929276    0.0253985   -0.0873562    0.0125565   -0.107328    -0.00827102   0.00329047  -0.0103553   -0.170263     0.0972792    -0.213413    -0.111038    0.0757591   -0.179154     0.0870135   -0.0335053    0.114564    -0.0829087    -0.0638468    0.082034    -0.0846074     0.0167475    0.0521867
 -0.0957644    0.0423024    0.128915    -0.0223628   -0.00495379   0.158486     0.00580532  -0.027499     0.223163    -0.0931564   -0.00688627   0.0467684    0.053056      0.128612     0.0130268   0.156731     0.113576     0.215076     0.0289412    0.0912256    0.0204409    -0.134948     0.0215442   -0.0238483    -0.150037     0.0312369
 -0.0590687    0.0206084    0.0813589    0.113163     0.0447604    0.165326     0.189307    -0.0290202   -0.234132    -0.02543     -0.149266     0.237174    -0.0798659    -0.113704     0.0881793   0.0836801    0.0979104    0.194285    -0.0951497   -0.0695086    0.194925      0.10737     -0.0333      -0.166089      0.179997     0.0278756
  0.0347246    0.0254617    0.00526682   0.121265     0.133257     0.00736596   0.0765155    0.178552    -0.0457963    0.133476     0.143721    -0.0614665    0.245345     -0.039853    -0.125599   -0.136192     0.152831     0.0754778    0.130557     0.0268273   -0.0153447    -0.0525158   -0.109576     0.0824615    -0.178904    -0.0485235kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3855516215977501
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.385620
[ Info: iteration 2, average log likelihood -1.385565
[ Info: iteration 3, average log likelihood -1.385269
[ Info: iteration 4, average log likelihood -1.381162
[ Info: iteration 5, average log likelihood -1.363258
[ Info: iteration 6, average log likelihood -1.353188
[ Info: iteration 7, average log likelihood -1.352121
[ Info: iteration 8, average log likelihood -1.351700
[ Info: iteration 9, average log likelihood -1.351337
[ Info: iteration 10, average log likelihood -1.350994
[ Info: iteration 11, average log likelihood -1.350685
[ Info: iteration 12, average log likelihood -1.350410
[ Info: iteration 13, average log likelihood -1.350169
[ Info: iteration 14, average log likelihood -1.349965
[ Info: iteration 15, average log likelihood -1.349802
[ Info: iteration 16, average log likelihood -1.349679
[ Info: iteration 17, average log likelihood -1.349588
[ Info: iteration 18, average log likelihood -1.349520
[ Info: iteration 19, average log likelihood -1.349470
[ Info: iteration 20, average log likelihood -1.349431
[ Info: iteration 21, average log likelihood -1.349402
[ Info: iteration 22, average log likelihood -1.349379
[ Info: iteration 23, average log likelihood -1.349359
[ Info: iteration 24, average log likelihood -1.349343
[ Info: iteration 25, average log likelihood -1.349329
[ Info: iteration 26, average log likelihood -1.349316
[ Info: iteration 27, average log likelihood -1.349305
[ Info: iteration 28, average log likelihood -1.349293
[ Info: iteration 29, average log likelihood -1.349281
[ Info: iteration 30, average log likelihood -1.349269
[ Info: iteration 31, average log likelihood -1.349255
[ Info: iteration 32, average log likelihood -1.349238
[ Info: iteration 33, average log likelihood -1.349214
[ Info: iteration 34, average log likelihood -1.349175
[ Info: iteration 35, average log likelihood -1.349104
[ Info: iteration 36, average log likelihood -1.348978
[ Info: iteration 37, average log likelihood -1.348809
[ Info: iteration 38, average log likelihood -1.348651
[ Info: iteration 39, average log likelihood -1.348533
[ Info: iteration 40, average log likelihood -1.348443
[ Info: iteration 41, average log likelihood -1.348364
[ Info: iteration 42, average log likelihood -1.348279
[ Info: iteration 43, average log likelihood -1.348177
[ Info: iteration 44, average log likelihood -1.348067
[ Info: iteration 45, average log likelihood -1.347967
[ Info: iteration 46, average log likelihood -1.347893
[ Info: iteration 47, average log likelihood -1.347843
[ Info: iteration 48, average log likelihood -1.347812
[ Info: iteration 49, average log likelihood -1.347792
[ Info: iteration 50, average log likelihood -1.347780
┌ Info: EM with 100000 data points 50 iterations avll -1.347780
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3856197747784025
│     -1.3855646559468149
│      ⋮
└     -1.3477799585563213
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.347894
[ Info: iteration 2, average log likelihood -1.347789
[ Info: iteration 3, average log likelihood -1.347549
[ Info: iteration 4, average log likelihood -1.345234
[ Info: iteration 5, average log likelihood -1.334462
[ Info: iteration 6, average log likelihood -1.320849
[ Info: iteration 7, average log likelihood -1.314942
[ Info: iteration 8, average log likelihood -1.311854
[ Info: iteration 9, average log likelihood -1.309084
[ Info: iteration 10, average log likelihood -1.306470
[ Info: iteration 11, average log likelihood -1.304217
[ Info: iteration 12, average log likelihood -1.302357
[ Info: iteration 13, average log likelihood -1.301006
[ Info: iteration 14, average log likelihood -1.300118
[ Info: iteration 15, average log likelihood -1.299540
[ Info: iteration 16, average log likelihood -1.299155
[ Info: iteration 17, average log likelihood -1.298888
[ Info: iteration 18, average log likelihood -1.298694
[ Info: iteration 19, average log likelihood -1.298546
[ Info: iteration 20, average log likelihood -1.298428
[ Info: iteration 21, average log likelihood -1.298335
[ Info: iteration 22, average log likelihood -1.298263
[ Info: iteration 23, average log likelihood -1.298210
[ Info: iteration 24, average log likelihood -1.298172
[ Info: iteration 25, average log likelihood -1.298145
[ Info: iteration 26, average log likelihood -1.298125
[ Info: iteration 27, average log likelihood -1.298110
[ Info: iteration 28, average log likelihood -1.298099
[ Info: iteration 29, average log likelihood -1.298091
[ Info: iteration 30, average log likelihood -1.298084
[ Info: iteration 31, average log likelihood -1.298078
[ Info: iteration 32, average log likelihood -1.298073
[ Info: iteration 33, average log likelihood -1.298069
[ Info: iteration 34, average log likelihood -1.298064
[ Info: iteration 35, average log likelihood -1.298060
[ Info: iteration 36, average log likelihood -1.298055
[ Info: iteration 37, average log likelihood -1.298051
[ Info: iteration 38, average log likelihood -1.298045
[ Info: iteration 39, average log likelihood -1.298040
[ Info: iteration 40, average log likelihood -1.298033
[ Info: iteration 41, average log likelihood -1.298027
[ Info: iteration 42, average log likelihood -1.298019
[ Info: iteration 43, average log likelihood -1.298011
[ Info: iteration 44, average log likelihood -1.298002
[ Info: iteration 45, average log likelihood -1.297991
[ Info: iteration 46, average log likelihood -1.297978
[ Info: iteration 47, average log likelihood -1.297963
[ Info: iteration 48, average log likelihood -1.297947
[ Info: iteration 49, average log likelihood -1.297930
[ Info: iteration 50, average log likelihood -1.297912
┌ Info: EM with 100000 data points 50 iterations avll -1.297912
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3478939171509259
│     -1.347788722374018
│      ⋮
└     -1.297912406885635
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.298030
[ Info: iteration 2, average log likelihood -1.297884
[ Info: iteration 3, average log likelihood -1.297537
[ Info: iteration 4, average log likelihood -1.294037
[ Info: iteration 5, average log likelihood -1.277117
[ Info: iteration 6, average log likelihood -1.258877
[ Info: iteration 7, average log likelihood -1.251659
[ Info: iteration 8, average log likelihood -1.247999
[ Info: iteration 9, average log likelihood -1.245640
[ Info: iteration 10, average log likelihood -1.243919
[ Info: iteration 11, average log likelihood -1.242556
[ Info: iteration 12, average log likelihood -1.241310
[ Info: iteration 13, average log likelihood -1.240126
[ Info: iteration 14, average log likelihood -1.239082
[ Info: iteration 15, average log likelihood -1.238421
[ Info: iteration 16, average log likelihood -1.238001
[ Info: iteration 17, average log likelihood -1.237603
[ Info: iteration 18, average log likelihood -1.237159
[ Info: iteration 19, average log likelihood -1.236660
[ Info: iteration 20, average log likelihood -1.236163
[ Info: iteration 21, average log likelihood -1.235821
[ Info: iteration 22, average log likelihood -1.235662
[ Info: iteration 23, average log likelihood -1.235590
[ Info: iteration 24, average log likelihood -1.235550
[ Info: iteration 25, average log likelihood -1.235520
[ Info: iteration 26, average log likelihood -1.235492
[ Info: iteration 27, average log likelihood -1.235460
[ Info: iteration 28, average log likelihood -1.235420
[ Info: iteration 29, average log likelihood -1.235367
[ Info: iteration 30, average log likelihood -1.235295
[ Info: iteration 31, average log likelihood -1.235195
[ Info: iteration 32, average log likelihood -1.235063
[ Info: iteration 33, average log likelihood -1.234899
[ Info: iteration 34, average log likelihood -1.234705
[ Info: iteration 35, average log likelihood -1.234493
[ Info: iteration 36, average log likelihood -1.234269
[ Info: iteration 37, average log likelihood -1.234074
[ Info: iteration 38, average log likelihood -1.233879
[ Info: iteration 39, average log likelihood -1.233647
[ Info: iteration 40, average log likelihood -1.233358
[ Info: iteration 41, average log likelihood -1.232996
[ Info: iteration 42, average log likelihood -1.232569
[ Info: iteration 43, average log likelihood -1.232175
[ Info: iteration 44, average log likelihood -1.231948
[ Info: iteration 45, average log likelihood -1.231865
[ Info: iteration 46, average log likelihood -1.231841
[ Info: iteration 47, average log likelihood -1.231833
[ Info: iteration 48, average log likelihood -1.231830
[ Info: iteration 49, average log likelihood -1.231829
[ Info: iteration 50, average log likelihood -1.231829
┌ Info: EM with 100000 data points 50 iterations avll -1.231829
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2980303865910325
│     -1.2978842113420905
│      ⋮
└     -1.2318286062165038
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.232002
[ Info: iteration 2, average log likelihood -1.231769
[ Info: iteration 3, average log likelihood -1.229992
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.209440
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.170632
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.148597
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.130428
[ Info: iteration 8, average log likelihood -1.143269
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.120102
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.140046
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.123607
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.132403
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.122858
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.131366
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.120777
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.127586
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.117192
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.125637
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.116006
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.125075
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.115786
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.124779
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.115266
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.123798
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.113497
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.121494
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.111634
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.120642
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.111314
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.120426
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.111255
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.126589
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.111239
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.126578
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.111239
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.126574
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.111240
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.126573
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.111240
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.126572
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.111241
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.126572
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.111241
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.126572
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.111241
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.126572
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.111241
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.126572
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.111241
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.126572
┌ Info: EM with 100000 data points 50 iterations avll -1.126572
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.232001764757987
│     -1.2317686686955651
│      ⋮
└     -1.1265720393993497
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     17
│     18
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.111474
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     17
│     18
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.105781
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     17
│     18
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.109893
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.091273
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      9
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.043676
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      8
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.041075
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.031204
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      8
│      9
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.023666
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.030289
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.023375
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.034716
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.025743
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.031884
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.023747
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.030253
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.021948
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.036850
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.024987
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.031623
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.024041
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.031019
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.023074
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│     10
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.029454
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.029375
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.032139
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.024232
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.031516
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.024128
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.031315
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.023960
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.030910
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.023394
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│     10
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.029920
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.028707
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.030479
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│      8
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.021622
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.037560
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.025150
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.031783
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.024221
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.031478
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.024100
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.031269
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.023929
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.030912
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.023381
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│     10
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.029803
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.028336
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│     10
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.029500
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.029464
┌ Info: EM with 100000 data points 50 iterations avll -1.029464
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1114738108686049
│     -1.1057812876162971
│      ⋮
└     -1.0294643607647809
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3855516215977501
│     -1.3856197747784025
│     -1.3855646559468149
│     -1.3852693313390914
│      ⋮
│     -1.0283356230971394
│     -1.0295001070084366
└     -1.0294643607647809
32×26 Array{Float64,2}:
  0.0767478    -0.0957595    0.00867912   0.120612     0.147503    -0.449459     0.0781409   -0.720103    -0.0439434    0.00279708    0.145691    -0.0742419     0.546346   -0.0367313    -0.124169   -0.267229    0.152586    0.249058     0.132349     0.0277417    0.00486107  -0.0544808  -0.0652325     0.207058    -0.170337    -0.0808975
  0.0546251     0.172507     0.00880748   0.121387     0.113804     0.491665     0.0490837    1.24058     -0.0494444    0.158344      0.124238    -0.0544528    -0.09809    -0.039902     -0.124409   -0.0573477   0.153369   -0.0975013    0.135257     0.0215454   -0.0166104   -0.176422   -0.119276     -0.0312532   -0.172463    -0.0270859
 -0.108045      0.0474437   -0.0170596   -0.00324147   0.0131234    0.0108622    0.00331568  -0.140001     0.0776214   -0.0516816    -0.117654     0.0281524     0.0401823  -0.0181849    -0.0533      0.128542    0.15688     0.109199     0.029766     0.0988863    0.103746     0.0469138   0.0225092    -0.169107    -0.14471     -0.442669
  0.0544448     0.048811     0.0897538    0.022633     0.0840699   -0.00845878   0.0174675   -0.0495642    0.0412933   -0.0265555     0.00676137   0.0791885     0.0393901  -0.0793388    -0.0817936  -0.0912806   0.131752    0.0588327   -0.1238       0.0932915   -0.021918    -0.260537   -0.00167359   -0.0270502    0.102726     0.291939
 -0.0163176     0.0148421    0.0314482    0.0746872   -0.00552732   0.112654     0.1564       0.0997184   -0.162508     0.000947187  -0.0902515    0.189775     -0.0649656  -0.104768      0.0983139   0.0746574   0.0576566   0.178537    -0.114289    -0.0436467    0.234509     0.0303119   0.00529718   -0.14573      0.0451868   -0.017574
  0.0241697     0.0899671   -0.133433    -0.0905641    0.0670772   -0.0709378   -0.0989315   -0.0274727    0.250394     0.0079465    -0.0738674    0.0186131    -0.0606241  -0.0906065    -0.0997539  -0.0195264   0.0237035  -0.0133168    0.0627092    0.0395994    0.0994381    0.0258033   0.0276161    -0.0799912   -0.0455211    0.00415034
  0.000764425  -0.210601     0.095954     0.0817739   -0.0749354   -0.263662    -0.0747075   -0.0295607   -0.125198     0.303499      0.0234794    0.058733     -0.0741208   0.0601727    -0.146016   -0.0107471  -0.0595757   0.147331    -0.0651622    0.119903    -0.0347742    0.10394    -0.0556047     0.0209941    0.0579712    0.0122675
 -0.144281      0.106202    -0.0547005    0.116576    -0.138284    -0.0498494    0.101018    -0.00630187   0.0225541   -0.0377728    -0.0898794   -0.00362205    0.0855886   0.181035     -0.148449   -0.106931    0.0689481   0.00899394  -0.0523768   -0.0555467   -0.157969    -0.0366087  -0.0618105    -0.0128959   -0.00691929  -0.00560073
  0.0363965     0.133911    -0.118613    -0.0145477   -0.118542     0.109922    -0.0393473    0.0384185    0.215603     0.12431       0.100807     0.00511724    0.0118667  -0.142453     -0.0690956  -0.0430874   0.0171888  -0.0456611    0.0748777    0.121361     0.0060192   -0.0188862  -0.0587095    -0.16046     -0.063324    -0.112196
 -0.0997973     0.0859635   -0.0649775   -0.0209471   -0.199378     0.0795307   -0.140989    -0.0737499   -0.0633474    0.0176929    -0.154007     0.0709948    -0.03895     0.0100018     0.211038   -0.135608    0.0876717   0.00669689   0.0228479   -0.0375646   -0.17043      0.117084   -0.0112811    -0.0414644   -0.181961    -0.0186491
 -0.114254      0.130816     0.038494    -0.209669     0.0256679    0.0217899   -0.164851    -0.0373351    0.096392    -0.0790619    -0.0508534   -0.0801821     0.0321879   0.0573239     0.0279847  -0.0120421  -0.206714    0.111439    -0.0293823   -0.0545494   -0.0333452    0.0252837  -0.137022      0.0308947   -0.0436867    0.0937628
  0.117923      0.161282     0.019958     0.0154455   -0.0485798   -0.0519662   -0.0326335   -0.0860171    0.00255693   0.161119      0.0510358    0.0368216     0.0651231   0.0637704     0.0512071   0.0615732  -0.0658725   0.227359    -0.0504191   -0.120137    -0.0292739    0.0550075  -0.022549      0.00508529   0.0373775    0.0569863
  0.0140721     0.0387037   -0.0991573   -0.0657765    0.170628     0.144515    -0.0610757    0.0352812   -0.167367     0.0561529     0.0638742   -0.193154     -0.0145159  -0.00609419   -0.0406067  -0.144927   -0.0878654   0.0609856   -0.0228696   -0.00317341   0.150435    -0.244176    0.0429958     0.111444     0.168224    -0.0305198
 -0.0362677     0.0885015    0.00243569  -0.0390644    0.0449763   -0.0554173   -0.0202135    0.0368837    0.00171866  -0.125073      0.0101566   -0.0361585     0.0110759  -0.00651129    0.0257701  -0.0747187   0.104122    0.0189147    0.0941222   -0.0259546   -0.00600977   0.012651   -0.0570485     0.00694942   0.00581069   0.0429687
 -0.0498189     0.0354432   -0.0246164    0.151568    -0.0208114   -0.0282618   -0.235304     0.0340982    0.0815936    0.00704347   -0.0971848    0.0499825     0.12228     0.000296784   0.0194111  -0.0801903  -0.108952    0.0625549    0.0583987    0.0425492    0.0645483   -0.014865    0.0667        0.0142335    0.225108     0.0293375
 -0.00405632    0.0776942   -0.139067     0.00318771  -0.0452361   -0.0679994   -0.0291523   -0.0825253    0.0693072    0.140656      0.110419    -0.0221958    -0.210637    0.15863      -0.0567004  -0.151454    0.0639969   0.110032     0.00742284   0.186646     0.0590917   -0.0660702   0.0796227     0.0519875   -0.0451813   -0.173027
  0.0363235    -0.0105133    0.02855      0.0896249   -0.0230544   -0.0288047   -0.388745    -0.216036    -0.0551592   -0.0461298     0.126708     0.0473485    -0.0677793  -0.0886313     0.144461   -0.0721406   0.147829   -0.00316265   0.0714748    0.139345     0.0757359    0.159972   -0.00761616   -0.220463     0.281653    -0.0580595
  0.0530889    -0.0175172   -0.119348     0.176771    -0.0887136    0.0347303    0.260918    -0.216352    -0.0793443    0.0525478     0.0660326    0.0345304    -0.0679337  -0.088797     -0.27746    -0.0864341  -0.0704948  -0.0933447    0.0639227    0.139528    -0.181424    -0.117688   -0.0110866    -0.204249    -0.405139    -0.0580826
  0.00696288    0.00372571  -0.0258157   -0.204117    -0.464219    -0.0918579    0.0394127   -0.117206    -0.150997     0.00631792   -0.083147    -0.180024      0.108225   -0.203416     -0.185163    0.189801   -0.183993    0.105097    -0.01685      0.141678    -0.0915018   -0.0694391   0.0735667    -0.0259732   -0.018844     0.043101
  0.0378883    -0.0233966   -0.0498902    0.0138455    0.527368    -0.0892196   -0.00740785  -0.0981043    0.166538     0.000795908   0.0305833   -0.1619        0.0950023  -0.222793     -0.0359833  -0.0193792  -0.178049    0.0699996   -0.0426243    0.0956897   -0.0714667   -0.0618429   0.0959952    -0.137189     0.0185105    0.0711514
 -0.0946651     0.0465597    0.0153082    0.0661614   -0.0549236    0.0064259   -0.0440979    0.0134603    0.0163539   -0.0508842    -0.0548172    0.0037908    -0.0600736   0.00671086    0.0027217   0.0179912   0.0284549   0.0543496    0.0253969   -0.00586356  -0.0652147   -0.0834086   0.0203222    -0.0407571    0.0299666    0.0139187
 -0.078017     -0.0375591   -0.0764702   -0.0448525   -0.0623807    0.0649163   -0.0664951    0.082724     0.0901388    0.013194     -0.00323866  -0.10753      -0.137945   -0.00771482   -0.0820687   0.0294084   0.0665585  -0.0302746   -0.0373724    0.122645     0.00826586   0.0181824   0.0154779     0.0226677   -0.0274134   -0.0494561
  0.0072657     0.108154     0.00268051  -0.146154    -0.0283527   -0.139601     0.0928761    0.191619    -0.0123087    0.00485733   -0.112545     0.000919401   0.240873    0.0269821    -0.1604      0.0649893  -0.0795123  -0.0259543   -0.0203081    0.0376992    0.0326569    0.133237   -0.058285      0.0751237   -0.00232279  -0.00778254
  0.0104181    -0.236928     0.0635718    0.0420383    0.0296918   -0.0494864   -0.0502605   -0.0112827    0.0330808    0.0194928    -0.125464     0.0146656     0.159233   -0.0244474    -0.193047   -0.253238   -0.0241144   0.0870307   -0.155508    -0.018797     0.144729    -0.373867    0.0246162     0.106561    -0.0558675   -0.0465613
 -0.10301      -0.0539022    0.119092    -0.114669    -0.0449892   -0.0148779   -0.0731756    0.116474     0.14837     -0.0127276    -0.209628     0.0215222    -0.0653933   0.157177      0.0639953   0.0549149  -0.103022    0.122995    -0.0553671    0.0398982    0.188575     0.17418    -0.0419166    -0.0684837   -0.00985519  -0.691871
 -0.11539       0.0161956    0.116473    -0.0943442   -0.0420555    0.05502      0.0112286    0.134007     0.146878    -0.125996     -0.0141927    0.0491347    -0.133656    0.0787842     0.119099    0.0512593  -0.120492    0.257518     0.00708438   0.00862404   0.081933     0.163947   -0.000577798  -0.0351478   -0.00427626   0.669882
  0.202382     -0.0344815   -0.135279    -0.143254     0.0480316   -0.0289217    0.129007     0.145079    -0.199755     0.118622     -0.0385306   -0.201118     -0.0180625  -0.152782     -0.376177   -0.0370994  -0.0574329   0.0181934    0.00287618  -0.0514673    0.0735587   -0.065133    0.170764     -0.0142918   -0.0804885   -0.0831407
 -0.167684     -0.0342537    0.0124638   -0.142617     0.0556164   -0.0176552   -0.075948    -0.0534583   -0.0879126   -0.00689946   -0.0393605   -0.202599     -0.119006    0.244922      0.338859    0.131038   -0.0571919   0.0177753   -0.00598678  -0.300725     0.070365    -0.22729    -0.121774     -0.0356672   -0.0805662    0.000533582
 -0.0278702     0.0702817    0.106497    -0.00471638  -0.0384414    0.089926     0.0305651    0.0577506    0.163359    -0.156843     -0.0606622   -0.0232738     0.093868    0.0927613    -0.106565   -0.0358524   0.0011045   0.127391    -0.0474851    0.0490031    0.0209118   -0.10011     0.0379494    -0.0148015   -0.0710026   -0.0411996
  0.0535312     0.0203817   -0.0446701   -0.0762449    0.149202     0.0702241   -0.00184619   0.113531     0.201874    -0.0475335    -0.125918    -0.0240448    -0.0915541  -0.0662956    -0.0329777   0.0362674   0.178208   -0.108416     0.207165    -0.0539909   -0.0647505   -0.134388    0.111586     -0.0310877    0.0253205   -0.0838242
  0.138063     -0.523088     0.15692      0.0519462   -0.0939387    0.0599921    0.00291164  -0.028025    -0.0541432    0.129671      0.130524     0.167894     -0.128447   -0.100573     -0.23857     0.0846628  -0.0436369   0.0577761    0.144718    -0.110797    -0.0136093    0.0562047   0.0391252    -0.22613     -0.0549829    0.227491
  0.107301      0.806998     0.126289     0.040367    -0.100946     0.0970563   -0.245004     0.078999     0.088112     0.128245      0.158004     0.0143203    -0.101094   -0.104976     -0.020497    0.0798611  -0.0464445   0.0319982    0.164826    -0.00736893  -0.0640031    0.0625033   0.0180634    -0.234705     0.0497272    0.0412539[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.032132
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.016801
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.031247
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.016341
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.030205
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.014831
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.032396
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.016427
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     17
│     18
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.030527
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.014964
┌ Info: EM with 100000 data points 10 iterations avll -1.014964
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.738211e+05
      1       6.502236e+05      -2.235975e+05 |       32
      2       6.278374e+05      -2.238613e+04 |       32
      3       6.141031e+05      -1.373430e+04 |       32
      4       6.038060e+05      -1.029710e+04 |       32
      5       5.959218e+05      -7.884213e+03 |       32
      6       5.911545e+05      -4.767367e+03 |       32
      7       5.885511e+05      -2.603407e+03 |       32
      8       5.870160e+05      -1.535022e+03 |       32
      9       5.861130e+05      -9.029941e+02 |       32
     10       5.855897e+05      -5.233194e+02 |       32
     11       5.852844e+05      -3.053382e+02 |       32
     12       5.850799e+05      -2.044542e+02 |       32
     13       5.849303e+05      -1.495856e+02 |       32
     14       5.848370e+05      -9.334687e+01 |       32
     15       5.847774e+05      -5.962463e+01 |       32
     16       5.847219e+05      -5.545493e+01 |       32
     17       5.846764e+05      -4.546829e+01 |       31
     18       5.846318e+05      -4.462403e+01 |       32
     19       5.845800e+05      -5.181881e+01 |       32
     20       5.844985e+05      -8.146415e+01 |       32
     21       5.843536e+05      -1.449423e+02 |       32
     22       5.840603e+05      -2.933074e+02 |       32
     23       5.834833e+05      -5.770056e+02 |       32
     24       5.829049e+05      -5.783888e+02 |       32
     25       5.826271e+05      -2.777680e+02 |       32
     26       5.824571e+05      -1.700146e+02 |       32
     27       5.822829e+05      -1.742652e+02 |       32
     28       5.820018e+05      -2.810295e+02 |       32
     29       5.815493e+05      -4.525403e+02 |       32
     30       5.808067e+05      -7.426002e+02 |       32
     31       5.795297e+05      -1.276960e+03 |       32
     32       5.781853e+05      -1.344463e+03 |       32
     33       5.774710e+05      -7.142496e+02 |       32
     34       5.772040e+05      -2.670065e+02 |       32
     35       5.770566e+05      -1.473563e+02 |       32
     36       5.769455e+05      -1.111510e+02 |       32
     37       5.768585e+05      -8.698798e+01 |       32
     38       5.767812e+05      -7.734702e+01 |       32
     39       5.766745e+05      -1.066528e+02 |       32
     40       5.765484e+05      -1.260702e+02 |       32
     41       5.763991e+05      -1.493235e+02 |       32
     42       5.762757e+05      -1.233689e+02 |       32
     43       5.761630e+05      -1.127311e+02 |       32
     44       5.760313e+05      -1.316778e+02 |       32
     45       5.759200e+05      -1.113444e+02 |       32
     46       5.758504e+05      -6.958217e+01 |       31
     47       5.757981e+05      -5.231835e+01 |       32
     48       5.757530e+05      -4.513831e+01 |       31
     49       5.757285e+05      -2.446147e+01 |       32
     50       5.757104e+05      -1.807528e+01 |       28
K-means terminated without convergence after 50 iterations (objv = 575710.4153355086)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.297026
[ Info: iteration 2, average log likelihood -1.261487
[ Info: iteration 3, average log likelihood -1.228105
[ Info: iteration 4, average log likelihood -1.187067
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.140554
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.113097
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.054453
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     12
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.036943
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.081026
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.040034
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.012154
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.048938
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.045217
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     14
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.013156
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.035025
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.042618
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.040923
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     10
│     27
│     28
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.014494
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     14
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.060740
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.047026
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.051763
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.027563
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     12
│     14
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.015638
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.074155
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     10
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.024415
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.023581
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     12
│     14
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.035421
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.045463
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.036507
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     12
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.036465
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.051546
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.014690
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     19
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.041134
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.052621
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.023059
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     14
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.025128
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     12
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.042694
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     19
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.025751
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.034749
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.047875
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.009634
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      6
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.036826
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     14
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.030739
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.029932
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.041450
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.037464
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     14
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.032907
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│     10
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.044858
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.060949
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.021347
┌ Info: EM with 100000 data points 50 iterations avll -1.021347
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0267325    0.0482614   0.0347353    0.00989735   0.0486273    0.000903036   0.0110895  -0.0942651   0.0594917   -0.0375404   -0.0582516    0.0542384    0.039927    -0.0500191   -0.0680842     0.0188374   0.142774     0.0834119   -0.0474238     0.0958582    0.0392935   -0.109285     0.0101688   -0.0961359   -0.0204752   -0.0692586
  0.0665421    0.0275345   0.00741214   0.121164     0.129979    -0.0101091     0.0642553   0.197506   -0.0470303    0.0761257    0.135657    -0.0669477    0.247167    -0.0383655   -0.123531     -0.165817    0.153508     0.0877895    0.132188      0.0252104   -0.00862755  -0.105145    -0.0937345    0.0991612   -0.174192    -0.0592638
  0.0526398    0.0185384  -0.0554972   -0.0628017    0.165682     0.0731268    -0.0091779   0.10003     0.218092    -0.0328867   -0.131454    -0.0184774   -0.100742    -0.0712218    0.00367222    0.0349715   0.205083    -0.104466     0.221532     -0.0516895   -0.0707625   -0.130238     0.107926    -0.0278461    0.0217984   -0.0759533
 -0.105148     0.0120788   0.132389    -0.0220403    0.00187481   0.178896      0.0138544  -0.0262368   0.242344    -0.127536     0.00394597   0.0373288    0.0614401    0.126518     0.000702567   0.146158    0.130855     0.242841    -0.000811792   0.0884842    0.0433502   -0.13551      0.014032    -0.0214999   -0.162287     0.0374577
 -0.0234967    0.072563   -0.0183402    0.039886    -0.0514222    0.149014      0.078689    0.0161525  -0.0129808    0.0483858   -0.0250172    0.121852    -0.043432    -0.135144     0.0147501     0.0193261   0.0529553    0.072303    -0.00645567    0.0257136    0.0967805    0.0475999   -0.0382181   -0.162697     0.0446764   -0.0524766
 -0.148549     0.286742    0.0970621   -0.0611242    0.0703409    0.0020797    -0.0462032  -0.0726606  -0.0463686   -0.303535    -0.086193    -0.129044    -0.104506    -0.0457428    0.0523026     0.0685928  -0.139653     0.0250958    0.079719      0.182232    -0.102553    -0.0959831    0.156707    -0.0503112    0.0207261   -0.0462031
 -0.00259772   0.0764064  -0.134641     0.00713369  -0.0354565   -0.069996     -0.03863    -0.085452    0.0718222    0.135449     0.111836    -0.0265099   -0.199493     0.144963    -0.052249     -0.155666    0.0559467    0.108739     0.00189595    0.185195     0.0558668   -0.0640299    0.0825613    0.0504069   -0.0517542   -0.163487
 -0.113985     0.12966     0.0381022   -0.209492     0.0261958    0.0201049    -0.164523   -0.0366661   0.0968955   -0.0769038   -0.0485388   -0.0805034    0.0301611    0.0569576    0.0294445    -0.0124986  -0.206305     0.112302    -0.0301732    -0.0545049   -0.0331432    0.025302    -0.139125     0.0345405   -0.0428459    0.0937449
  0.0148205   -0.0348878  -0.0593458   -0.1434       0.0518736   -0.0229722     0.0266089   0.0442151  -0.143396     0.0545457   -0.0397059   -0.20195     -0.066725     0.0479389   -0.0158804     0.0486722  -0.0574091    0.0177958   -0.00143355   -0.178595     0.0716416   -0.147843     0.0212414   -0.0248737   -0.0808155   -0.039164
 -0.0180687    0.0213711  -0.1185       0.01145     -0.0486755   -0.0543357    -0.134921   -0.184208   -0.0382506   -0.0191235    0.0949858   -0.00164384  -0.0644761   -0.0675803    0.169856     -0.0713896   0.0120324   -0.0380255    0.0583794     0.136265    -0.0926834   -0.00534838  -0.0122065   -0.166463     0.0475239   -0.0448969
  0.0153511   -0.0286462  -0.178681    -0.0722888   -0.0566213    0.114601     -0.0989562   0.185392    0.124585    -0.119643    -0.0772742   -0.213266    -0.0800061   -0.0443458   -0.0920309    -0.017756   -0.039938    -9.61527e-5  -0.0437311     0.0948877    0.0623937    0.060444    -0.0750245    0.123241     0.0621645   -0.178972
 -0.0973769    0.0837843   0.015164     0.165589     0.028331    -0.108373     -0.344353   -0.0188405   0.141924     0.024928    -0.162472     0.0746479   -0.0336798   -0.0597642    0.162192     -0.219666   -0.107286     0.0859464   -0.0462438     0.00492154   0.222402    -0.0952109    0.0789811    0.0598578    0.0935763    0.00874281
  0.017169    -0.12571     0.01553     -0.0310164    0.0378875   -0.0685513    -0.0206614  -0.0596167   0.0218301    0.0105293   -0.0796699   -0.0753862    0.129197    -0.113869    -0.148769     -0.0852433  -0.0962997    0.0864387   -0.0950456     0.0466442    0.0328587   -0.219337     0.0527549    0.0120967   -0.0266135    0.00360243
  0.0140291    0.0935752  -0.172319    -0.1077       0.0999253   -0.0702795    -0.106602   -0.102236    0.282354     0.00650222  -0.115231     0.00764162  -0.0673054   -0.0927393   -0.104918     -0.0371315   0.0335996   -0.0403571    0.0862411     0.0333816    0.0615419    0.082498     0.022426    -0.0921311   -0.0113549    0.0285479
  0.0717282    0.0238775  -0.0585561    0.0294782   -0.0389366   -0.0570003     0.0280878   0.268687    0.0312745    0.0665807    0.0407556    0.102756    -0.0212185   -0.0651853    0.021774      0.0490169  -0.00493189   0.128981    -0.105586      0.0187726    0.312656    -0.130454     0.0320093   -0.0941556   -0.121539    -0.0403726
 -0.160176    -0.0490592   0.0213525   -0.0216724   -0.0722703    0.0211821    -0.0376146  -0.0117691   0.0564611    0.133924     0.0700001   -0.0250545   -0.191752     0.0185034   -0.0871856     0.0856773   0.173752    -0.0607044   -0.0372293     0.161911    -0.0390792   -0.0187447    0.100504    -0.0787085   -0.102872     0.0909714
  0.118167     0.1612      0.0196368    0.0161665   -0.0485621   -0.0516992    -0.0321898  -0.0862749   0.00191193   0.161755     0.0518824    0.0368355    0.0632978    0.0640034    0.0506786     0.061977   -0.0607878    0.227425    -0.0505846    -0.119939    -0.0293826    0.0550116   -0.0234077    0.00510911   0.0380446    0.056558
 -0.221828    -0.061368    0.016342     0.106128    -0.130053    -0.00892467    0.0545054   0.0266654   0.065198     0.064215    -0.0064007    0.158202    -0.00138267   0.130347     0.0416553    -0.0174995   0.0519336    0.0488404    0.0296894    -0.201755    -0.155586    -0.00676563   0.0499605    0.00459353  -0.0560071   -0.0656415
  0.0535181    0.016044    0.107279     0.273195    -0.0764456   -0.00431999    0.076923   -0.219016   -0.164474     0.0345075    0.0984662    0.0134161   -0.0662927   -0.088187    -0.381292     -0.0913039   0.128261    -0.0437565    0.0674057     0.136111     0.101544     0.0636067   -0.00920457  -0.221512     0.0710849   -0.0572732
  0.0577908   -0.0462734  -0.116548     0.125078    -0.0589058    0.0145887    -0.0941741  -0.198102   -0.0691639    0.00284102   0.0952112    0.0604458   -0.0649857   -0.0960224   -0.0348325    -0.0643418   0.0287849   -0.0505969    0.0615917     0.139789    -0.0996375    0.0208069   -0.00660734  -0.230868    -0.148175    -0.0507442
  0.0349444   -0.0192614  -0.0513203    0.132274    -0.0641831    0.0479725    -0.11396     0.0512773   0.0159065    0.018196    -0.0985998    0.0138206    0.0962323   -0.0109402   -0.0741042     0.037237    0.00684708   0.0649721    0.0842196     0.0314142   -0.0442162   -0.0299254   -0.00417875  -0.0487326    0.255521     0.0866259
  0.124286     0.0919823   0.144204     0.046411    -0.0986187    0.0777636    -0.111702    0.0192665   0.0150231    0.130021     0.142992     0.0962791   -0.116382    -0.102844    -0.138851      0.0813177  -0.044667     0.0459515    0.151936     -0.0643518   -0.0363549    0.0577282    0.0294338   -0.230377    -0.00804747   0.140823
  0.0685239    0.123869    0.102156     0.0103305   -0.0883231    0.0156658     0.0446091   0.147811    0.0920978   -0.192578    -0.130676    -0.0925501    0.129435     0.0379402   -0.227481     -0.236342   -0.140288    -0.0184637   -0.0938351    -0.00648275  -0.00045342  -0.0578674    0.0693021   -0.0117237    0.0169893   -0.137631
 -0.108656    -0.0402184   0.120269    -0.114889    -0.044773    -0.0245012    -0.0631911   0.0997221   0.156803    -0.0305444   -0.166798     0.0279068   -0.0709862    0.156073     0.0861111     0.0529387  -0.108217     0.143491    -0.0454064     0.0355419    0.155634     0.171547    -0.0487679   -0.0580362   -0.00998121  -0.731773
  0.0145034    0.0338479  -0.102194    -0.0653229    0.170216     0.143974     -0.0601292   0.0354022  -0.167249     0.0568748    0.0633093   -0.195914    -0.0149923   -0.0068808   -0.0399644    -0.140737   -0.093505     0.0643802   -0.022048     -0.00305122   0.149559    -0.244193     0.04121      0.113791     0.172044    -0.0310767
 -0.107433     0.0212973   0.112987    -0.0910149   -0.040516     0.100605      0.0323419   0.174575    0.127287    -0.139877    -0.0121121    0.0476588   -0.157299     0.0490607    0.0983579     0.0535345  -0.117476     0.277964     0.0151672     4.15625e-5   0.1014       0.164468     0.0348011   -0.042747    -0.00112523   1.39203
 -0.0292073    0.10912     0.0110228    0.0571112   -0.0605004   -0.108049     -0.227152    0.045337    0.125344     0.0495675   -0.017106    -0.0180708    0.153104    -0.0249296   -0.115278     -0.100502   -0.0880839    0.0240283   -0.037083      0.0851199    0.207173    -0.0242107   -0.04342      0.0954762   -0.0102777    0.0109715
 -0.0544259    0.0558141   0.0277316   -0.0336367   -0.11149      0.0039993    -0.110928   -0.0537387  -0.00161911   0.116105    -0.080293     0.0306338    0.0302733   -0.0142942   -0.02108      -0.0357509   0.0247132    0.0171367    0.0826561     0.193187    -0.00605205   0.0205578   -0.00393251  -0.0913643   -0.026785    -0.0397168
 -0.0812952   -0.0434045   0.0168786    0.101549    -0.107472    -0.158331      0.0150571  -0.0169071  -0.0452081    0.12503     -0.0335881    0.0271145    0.00868421   0.12058     -0.14986      -0.0596885   0.00511839   0.0736587   -0.0581882     0.0271686   -0.100275     0.0320882   -0.0593496    0.00227125   0.0316851    0.00650107
 -0.0491697    0.087764    0.0645978   -0.0714466    0.012694    -0.0671025     0.0668201   0.114294    0.0202614   -0.0673422   -0.0936931    0.0656815    0.0986789   -0.0923609   -0.0182768     0.0215152   0.00294575  -0.00122958   0.0245574    -0.00511501  -0.0187111    0.036408    -0.0164518    0.0619893   -0.0250892    0.023794
 -0.100019     0.0931333  -0.0674332   -0.0224591   -0.201525     0.0816667    -0.15131    -0.0760575  -0.0609284    0.0132132   -0.156475     0.0715212   -0.0380914    0.00842087   0.198846     -0.133363    0.0864813    0.00578258   0.0224958    -0.0323247   -0.170304     0.119298    -0.0124464   -0.0451218   -0.187631    -0.0208211
  0.0206238    0.0595517  -0.117532    -0.0813109    0.0434427   -0.106622     -0.0920611   0.0345113  -0.0525703   -0.113824     0.115811    -0.176951     0.0269976    0.200583    -0.0262255    -0.160943    0.150451     0.018614     0.130059     -0.0145112    0.00833702   0.0606133   -0.165877    -0.0384713    0.0611956    0.0340566[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│     14
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.041763
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│     14
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.001862
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│      9
│     12
│     14
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.992816
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│     14
│     19
│     20
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.025216
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│     14
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.003064
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│      9
│     12
│     14
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.994662
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│     14
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.026302
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      6
│     14
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.998518
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│      9
│     12
│     14
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.992899
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│     14
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.019356
┌ Info: EM with 100000 data points 10 iterations avll -1.019356
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.120222      0.0292831   -0.0976804    0.0977874   -0.0910366   -0.145119     0.0632597   -0.125136     0.134121     0.142385     0.189103     0.00572662   0.0753897    -0.0128046    0.00420284  -0.00462352  -0.144298     0.11365     -0.0582375  -0.0171291    -0.0575235   -0.0460441   -0.0881065   -0.0404513    0.0686463   -0.00133132
  0.0474427     0.00777501  -0.0216226   -0.17459     -0.0768884    0.0487548    0.164866    -0.100829     0.0567811    0.0206319    0.0873513   -0.223396     0.120595      0.0363836    0.0274532    0.138849     0.120666     0.131403     0.0855287  -0.0371555     0.155917     0.0108453    0.0510238   -0.179534     0.149854     0.168469
 -0.0300261    -0.155155     0.0290166   -0.025845     0.00320435   0.0414917    0.0953589    0.0129987    0.0102019    0.146789    -0.16177      0.192224    -0.0723295    -0.0145207    0.0318789    0.00539476  -0.123216    -0.137778    -0.200588   -0.0116506    -0.0464796    0.0546534    0.0485547   -0.0141896    0.0145483   -0.071587
  0.0195402     0.0166223    0.10632     -0.10545      0.164997     0.00605523   0.0912677    0.0883279    0.057867    -0.00853025   0.0683148   -0.002899    -0.0175489    -0.0133022   -0.0458361   -0.0644547   -0.115715     0.01394     -0.0140383  -0.0567331     0.320656     0.0784709   -0.250728    -0.0457712    0.0218311    0.0978929
  0.114061     -0.0207673    0.0610705    0.218334     0.206991     0.0167683    0.244545     0.015906     0.0236837    0.0705421   -0.0656643   -0.0953104   -0.096089     -0.020896     0.0484482   -0.0628961    0.0193001    0.105696    -0.101614   -0.0240116    -0.200255     0.0100679   -0.100158     0.045112     0.00666728  -0.00690178
 -0.260055     -0.0583093   -0.276106    -0.0535544   -0.00711092  -0.0324728    0.182228    -0.0438425   -0.00676977   0.0505061    0.0904322   -0.00554655   0.172204      0.184923    -0.124797     0.10761      0.0327208    0.0524234   -0.0292344   0.000192666   0.0782246   -0.0376728    0.0138499   -0.0809126    0.0740336    0.266934
  0.072631      0.0610516   -0.13186      0.044725    -0.0293075    0.0764744    0.0304653    0.00439911  -0.0773167    0.0646187    0.0764081   -0.111577     0.224605     -0.0202476    0.0207461   -0.278629    -0.110344     0.0392498   -0.111406    0.000589791  -0.0658043    0.109841     0.0111438   -0.0786606   -0.143196     0.0546147
  0.0121814     0.227579     0.0426158    0.15569      0.0359958    0.0483833    0.113288    -0.0546056    0.129069     0.0126886   -0.0778665   -0.00251523  -0.0215465    -0.0969562    0.0616539    0.0306885    0.155066     0.158823    -0.0738222  -0.0157046     0.222961    -0.0520612    0.0491005    0.0260345    0.0682719    0.191465
  0.118762     -0.0503922    0.00425333   0.0756537    0.14257      0.0698052    0.102683     0.133176     0.349352     0.0607786    0.0114703    0.17731     -0.0865783     0.0117144    0.128493    -0.0268981   -0.0574541   -0.0816331    0.126258    0.00752968   -0.046121     0.024458     0.019998    -0.175677    -0.119868     0.152742
 -0.00233099    0.088516     0.0883448    0.0283691   -0.0868036   -0.160492     0.0974329    0.116407    -0.0602543   -0.11696      0.0909399   -0.213514     0.0314931     0.119492    -0.0362035    0.0994759   -0.02543     -0.0336716    0.0951677  -0.0705907    -0.215335     0.212603     0.117755    -0.103181     0.00522978  -0.159203
 -0.0284943    -0.0379948    0.0837391    0.117702    -0.108805    -0.165622    -0.00989213   0.0822136   -0.022933    -0.152983    -0.0466982   -0.0179882    0.212093      0.0305417   -0.0696557   -0.138889     0.0601055    0.114229     0.145217   -0.138668      0.032238    -0.102427     0.0309495    0.0428294    0.20295     -0.0634405
  0.0506668     0.094458    -0.108528     0.256083     0.0130757   -0.0833925   -0.129088    -0.035718    -0.0598466    0.0522119   -0.252696     0.0761685   -0.0425956    -0.0143726   -0.0686356   -0.0922167    0.0495262   -0.091563     0.0687816  -0.0938778     0.0755141   -0.0605069    0.0539029    0.0312452   -0.0131554   -0.221472
  0.022811      0.103168     0.145399    -0.00435073   0.131953    -0.0227783   -0.0218438    0.0713251    0.0105073   -0.0650786    0.00568733  -0.148222     0.0336669     0.12221      0.0812812   -0.0141413   -0.0614257   -0.169631     0.0720238   0.0932854     0.0610632    0.0308807    0.12819     -0.00410262   0.0539035   -0.0383062
 -0.12904      -0.0100839   -0.118922    -0.105893    -0.240182    -0.160394     0.118518    -0.00107558   0.176962    -0.111584     0.0299479   -0.132653     0.0875195    -0.0725475    0.117531    -0.0218797   -0.0430006    0.0618407    0.0158655  -0.105935      0.0351335    0.135822     0.0658016    0.0668348   -0.073261     0.0209801
 -0.117566     -0.0458695   -0.0511639    0.140033     0.00601651   0.00774663  -0.0236077   -0.180081     0.0290393   -0.0478833   -0.117018     0.117237    -0.000108613   0.064142     0.151722     0.101659     0.0144185    0.0290097    0.0289566   0.060566     -0.0964238   -0.060413     0.0525451    0.0266361    0.00519361   0.1119
  0.0390878    -0.126109     0.0430654   -0.25882     -0.189999    -0.092782    -0.057139    -0.0332334    0.0244058    0.0980946    0.0647986   -0.0252603    0.0194759     0.0715562   -0.0103177    0.0234101    0.0242876    0.225784    -0.184657    0.0976329     0.0865993    0.066586    -0.0271952   -0.0173795    0.0281343    0.0488966
  0.13338      -0.0538267   -0.103162    -0.00536206  -0.0649172   -0.0921286   -0.0448099    0.0197785    0.0524507    0.142181    -0.0172899   -0.0030665   -0.0507749    -0.18268      0.0192708    0.0894267    0.0293268   -0.0380004   -0.0108168   0.0185676    -0.00515084  -0.114703     0.0497249   -0.0210685    0.0235674   -0.0140756
  0.00244231   -0.0198119   -0.0370008   -0.0424657   -0.1201      -0.0779276   -0.0442894    0.0924115    0.140411    -0.0551324   -0.0703564    0.107597     0.114553      0.04741     -0.0362364   -0.0496478   -0.0239583   -0.0223432    0.0526887   0.164775      0.120247     0.16456     -0.0902656   -0.138976     0.0957547    0.0911553
 -0.0804663     0.0474856    0.0322829   -0.221019     0.00949435  -0.113354     0.0327712    0.108557    -0.0131163   -0.00102237  -0.0912436    0.098569    -0.059683     -0.145156     0.00290956  -0.12942      0.100604    -0.084682    -0.193645   -0.0283945    -0.0586486   -0.157111    -0.0642217    0.00765237   0.193543     0.0853537
  0.0305487    -0.257829     0.0212629   -0.0217024    0.046018    -0.149499     0.00248861  -0.161458    -0.00474653   0.00849146  -0.0160435   -0.00801072   0.0854157     0.00884566  -0.0134852   -0.164605     0.0670762    0.196443     0.039164   -0.0174895     0.103631     0.16558      0.0639081   -0.0992715    0.106092     0.0641154
  0.0379951    -0.0264404   -0.0940719   -0.102353     0.181909     0.159529     0.035191     0.185836    -0.100831     0.00527955   0.0245633   -0.169152    -0.0700033     0.0429307   -0.189281    -0.0901749    0.00211154   0.00889454  -0.0540684   0.127046     -0.0759676   -0.0582018   -0.00906327   0.125917    -0.116068     0.0365934
 -0.224581     -0.151226    -0.126983    -0.0624586    0.0968166    0.118182    -0.0986385   -0.0408124    0.0600858   -0.115055     0.0774621   -0.165685     0.0869794    -0.0881833    0.0857958   -0.0455778    0.0625693   -0.0424527    0.0283485   0.0817827    -0.0954309   -0.00436278   0.0856819    0.0247535    0.0152538   -0.0301583
  0.130449      0.0208106    0.0702767   -0.0544915    0.0119354    0.0151188   -0.126008    -0.0385316    0.0198024    0.0734059   -0.292971     0.00766923   0.190768      0.027566    -0.0889365    0.0371886    0.183609    -0.153419     0.113445   -0.117839      0.121496     0.0309922    0.09909     -0.0469534    0.0340782   -0.0869018
  0.0256532    -0.0315149   -0.00232267   0.0156763    0.0840104    0.107651     0.0612801   -0.0873575   -0.178835     0.0319598    0.081742    -0.134669     0.126693     -0.0674185    0.0548936   -0.170537    -0.117673     0.0691972    0.0876059   0.138185      0.0640479   -0.0648923   -0.196645    -0.127261     0.0778747    0.0103748
  0.0384621     0.0379831   -0.228889    -0.0639451   -0.0026412    0.152804     0.323171    -0.0694986   -0.133694    -0.223372     0.112826     0.0319555    0.10904      -0.0141765   -0.22921     -0.115689    -0.0688624    0.0651865    0.0609248   0.0315872     0.00737522  -0.0579944   -0.0623344    0.102007    -0.0308479   -0.00718184
  0.0299916     0.0177536    0.0870165    0.084231    -0.0278935   -0.0591005   -0.120212    -0.0133796    0.0801326   -0.228974     0.0943733    0.0058469    0.0272798     0.0527801   -0.00267734   0.184251     0.0170218   -0.0830002    0.0472022  -0.160536      0.230004    -0.0925484   -0.0319665   -0.0194241    0.0677777    0.038186
 -0.000639803  -0.107508    -0.0662397   -0.0756723   -0.0897972    0.224404     0.237913     0.00201129   0.0247811   -0.0578697    0.0605842    0.133718     0.0784798    -0.117519    -0.0171051   -0.0152918   -0.135387     0.259574    -0.0237183  -0.0566623    -0.0460913   -0.00472     -0.145577    -0.0809461    0.19458      0.0561063
 -0.0253569    -0.0415015    0.110455    -0.0806585    0.033219    -0.140286     0.0925682    0.00590648  -0.193553     0.166173    -0.0295032   -0.0514874    0.0340102    -0.124316    -0.133878    -0.0746024   -0.0200421    0.0592497    0.0232636   0.211626     -0.0414896    0.0646833    0.111617    -0.177436    -0.0527917   -0.0940431
 -0.0079641    -0.0824632    0.0516209   -0.0861139   -0.00384144   0.0001378   -0.0757439    0.0552549   -0.10588     -0.0242237    0.014278    -0.048775     0.138965      0.142744     0.0296182   -0.0414066   -0.115475    -0.104398    -0.024309    0.19306       0.116314    -0.0820557   -0.332499    -0.19274     -0.0349478    0.147509
 -0.145915      0.124398    -0.103105     0.0387434    0.110029     0.0678378    0.149524    -0.124278    -0.211654    -0.0324003   -0.0871237   -0.0647451    0.0716031    -0.0693483    0.0237595   -0.0401808    0.161852    -0.103507     0.0310295   0.213045     -0.0372957   -0.0913618    0.0488988   -0.0515849    0.12018     -0.102284
 -0.044445      0.0246591    0.0690768    0.00913417   0.0595919   -0.168935    -0.140806    -0.336255     0.0669354   -0.0641232    0.005009    -0.144232    -0.119762      0.157071     0.172338     0.0234834    0.213599    -0.028355     0.0378067   0.100111      0.0626814   -0.00764051   0.109803    -0.0906951   -0.0915294   -0.0366922
  0.057358     -0.0463958    0.0653907    0.0498524    0.0760062   -0.0371211    0.158494    -0.169855    -0.0752795   -0.0742251   -0.00576831  -0.0135274    0.0528145    -0.166127     0.109783     0.0422859   -0.0384257    0.0622964   -0.0866976   0.0261827    -0.0103682    0.162311    -0.103676     0.0758926   -0.106131     0.216989kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.420074763922055
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420093
[ Info: iteration 2, average log likelihood -1.420022
[ Info: iteration 3, average log likelihood -1.419968
[ Info: iteration 4, average log likelihood -1.419908
[ Info: iteration 5, average log likelihood -1.419836
[ Info: iteration 6, average log likelihood -1.419751
[ Info: iteration 7, average log likelihood -1.419648
[ Info: iteration 8, average log likelihood -1.419506
[ Info: iteration 9, average log likelihood -1.419275
[ Info: iteration 10, average log likelihood -1.418856
[ Info: iteration 11, average log likelihood -1.418134
[ Info: iteration 12, average log likelihood -1.417123
[ Info: iteration 13, average log likelihood -1.416110
[ Info: iteration 14, average log likelihood -1.415415
[ Info: iteration 15, average log likelihood -1.415065
[ Info: iteration 16, average log likelihood -1.414915
[ Info: iteration 17, average log likelihood -1.414854
[ Info: iteration 18, average log likelihood -1.414829
[ Info: iteration 19, average log likelihood -1.414819
[ Info: iteration 20, average log likelihood -1.414814
[ Info: iteration 21, average log likelihood -1.414813
[ Info: iteration 22, average log likelihood -1.414812
[ Info: iteration 23, average log likelihood -1.414811
[ Info: iteration 24, average log likelihood -1.414811
[ Info: iteration 25, average log likelihood -1.414811
[ Info: iteration 26, average log likelihood -1.414810
[ Info: iteration 27, average log likelihood -1.414810
[ Info: iteration 28, average log likelihood -1.414810
[ Info: iteration 29, average log likelihood -1.414810
[ Info: iteration 30, average log likelihood -1.414810
[ Info: iteration 31, average log likelihood -1.414810
[ Info: iteration 32, average log likelihood -1.414810
[ Info: iteration 33, average log likelihood -1.414810
[ Info: iteration 34, average log likelihood -1.414810
[ Info: iteration 35, average log likelihood -1.414810
[ Info: iteration 36, average log likelihood -1.414810
[ Info: iteration 37, average log likelihood -1.414810
[ Info: iteration 38, average log likelihood -1.414810
[ Info: iteration 39, average log likelihood -1.414810
[ Info: iteration 40, average log likelihood -1.414810
[ Info: iteration 41, average log likelihood -1.414810
[ Info: iteration 42, average log likelihood -1.414810
[ Info: iteration 43, average log likelihood -1.414809
[ Info: iteration 44, average log likelihood -1.414809
[ Info: iteration 45, average log likelihood -1.414809
[ Info: iteration 46, average log likelihood -1.414809
[ Info: iteration 47, average log likelihood -1.414809
[ Info: iteration 48, average log likelihood -1.414809
[ Info: iteration 49, average log likelihood -1.414809
[ Info: iteration 50, average log likelihood -1.414809
┌ Info: EM with 100000 data points 50 iterations avll -1.414809
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4200928058144267
│     -1.4200222306434933
│      ⋮
└     -1.4148093699554227
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414827
[ Info: iteration 2, average log likelihood -1.414754
[ Info: iteration 3, average log likelihood -1.414699
[ Info: iteration 4, average log likelihood -1.414636
[ Info: iteration 5, average log likelihood -1.414563
[ Info: iteration 6, average log likelihood -1.414482
[ Info: iteration 7, average log likelihood -1.414398
[ Info: iteration 8, average log likelihood -1.414318
[ Info: iteration 9, average log likelihood -1.414246
[ Info: iteration 10, average log likelihood -1.414185
[ Info: iteration 11, average log likelihood -1.414135
[ Info: iteration 12, average log likelihood -1.414093
[ Info: iteration 13, average log likelihood -1.414057
[ Info: iteration 14, average log likelihood -1.414024
[ Info: iteration 15, average log likelihood -1.413994
[ Info: iteration 16, average log likelihood -1.413965
[ Info: iteration 17, average log likelihood -1.413937
[ Info: iteration 18, average log likelihood -1.413910
[ Info: iteration 19, average log likelihood -1.413884
[ Info: iteration 20, average log likelihood -1.413861
[ Info: iteration 21, average log likelihood -1.413839
[ Info: iteration 22, average log likelihood -1.413820
[ Info: iteration 23, average log likelihood -1.413803
[ Info: iteration 24, average log likelihood -1.413789
[ Info: iteration 25, average log likelihood -1.413777
[ Info: iteration 26, average log likelihood -1.413767
[ Info: iteration 27, average log likelihood -1.413759
[ Info: iteration 28, average log likelihood -1.413752
[ Info: iteration 29, average log likelihood -1.413746
[ Info: iteration 30, average log likelihood -1.413741
[ Info: iteration 31, average log likelihood -1.413736
[ Info: iteration 32, average log likelihood -1.413733
[ Info: iteration 33, average log likelihood -1.413729
[ Info: iteration 34, average log likelihood -1.413727
[ Info: iteration 35, average log likelihood -1.413724
[ Info: iteration 36, average log likelihood -1.413722
[ Info: iteration 37, average log likelihood -1.413720
[ Info: iteration 38, average log likelihood -1.413718
[ Info: iteration 39, average log likelihood -1.413717
[ Info: iteration 40, average log likelihood -1.413715
[ Info: iteration 41, average log likelihood -1.413714
[ Info: iteration 42, average log likelihood -1.413713
[ Info: iteration 43, average log likelihood -1.413711
[ Info: iteration 44, average log likelihood -1.413710
[ Info: iteration 45, average log likelihood -1.413709
[ Info: iteration 46, average log likelihood -1.413709
[ Info: iteration 47, average log likelihood -1.413708
[ Info: iteration 48, average log likelihood -1.413707
[ Info: iteration 49, average log likelihood -1.413706
[ Info: iteration 50, average log likelihood -1.413705
┌ Info: EM with 100000 data points 50 iterations avll -1.413705
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4148271634004685
│     -1.414754393897741
│      ⋮
└     -1.413705434841857
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413714
[ Info: iteration 2, average log likelihood -1.413660
[ Info: iteration 3, average log likelihood -1.413610
[ Info: iteration 4, average log likelihood -1.413550
[ Info: iteration 5, average log likelihood -1.413473
[ Info: iteration 6, average log likelihood -1.413377
[ Info: iteration 7, average log likelihood -1.413264
[ Info: iteration 8, average log likelihood -1.413141
[ Info: iteration 9, average log likelihood -1.413017
[ Info: iteration 10, average log likelihood -1.412904
[ Info: iteration 11, average log likelihood -1.412808
[ Info: iteration 12, average log likelihood -1.412729
[ Info: iteration 13, average log likelihood -1.412668
[ Info: iteration 14, average log likelihood -1.412622
[ Info: iteration 15, average log likelihood -1.412586
[ Info: iteration 16, average log likelihood -1.412558
[ Info: iteration 17, average log likelihood -1.412536
[ Info: iteration 18, average log likelihood -1.412519
[ Info: iteration 19, average log likelihood -1.412504
[ Info: iteration 20, average log likelihood -1.412492
[ Info: iteration 21, average log likelihood -1.412482
[ Info: iteration 22, average log likelihood -1.412473
[ Info: iteration 23, average log likelihood -1.412465
[ Info: iteration 24, average log likelihood -1.412458
[ Info: iteration 25, average log likelihood -1.412452
[ Info: iteration 26, average log likelihood -1.412446
[ Info: iteration 27, average log likelihood -1.412440
[ Info: iteration 28, average log likelihood -1.412435
[ Info: iteration 29, average log likelihood -1.412431
[ Info: iteration 30, average log likelihood -1.412426
[ Info: iteration 31, average log likelihood -1.412422
[ Info: iteration 32, average log likelihood -1.412418
[ Info: iteration 33, average log likelihood -1.412414
[ Info: iteration 34, average log likelihood -1.412410
[ Info: iteration 35, average log likelihood -1.412406
[ Info: iteration 36, average log likelihood -1.412402
[ Info: iteration 37, average log likelihood -1.412399
[ Info: iteration 38, average log likelihood -1.412395
[ Info: iteration 39, average log likelihood -1.412392
[ Info: iteration 40, average log likelihood -1.412389
[ Info: iteration 41, average log likelihood -1.412385
[ Info: iteration 42, average log likelihood -1.412382
[ Info: iteration 43, average log likelihood -1.412379
[ Info: iteration 44, average log likelihood -1.412376
[ Info: iteration 45, average log likelihood -1.412373
[ Info: iteration 46, average log likelihood -1.412369
[ Info: iteration 47, average log likelihood -1.412366
[ Info: iteration 48, average log likelihood -1.412363
[ Info: iteration 49, average log likelihood -1.412360
[ Info: iteration 50, average log likelihood -1.412357
┌ Info: EM with 100000 data points 50 iterations avll -1.412357
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4137140852077885
│     -1.413660324987543
│      ⋮
└     -1.4123571663020247
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412362
[ Info: iteration 2, average log likelihood -1.412311
[ Info: iteration 3, average log likelihood -1.412265
[ Info: iteration 4, average log likelihood -1.412211
[ Info: iteration 5, average log likelihood -1.412145
[ Info: iteration 6, average log likelihood -1.412065
[ Info: iteration 7, average log likelihood -1.411970
[ Info: iteration 8, average log likelihood -1.411862
[ Info: iteration 9, average log likelihood -1.411747
[ Info: iteration 10, average log likelihood -1.411630
[ Info: iteration 11, average log likelihood -1.411517
[ Info: iteration 12, average log likelihood -1.411410
[ Info: iteration 13, average log likelihood -1.411313
[ Info: iteration 14, average log likelihood -1.411226
[ Info: iteration 15, average log likelihood -1.411151
[ Info: iteration 16, average log likelihood -1.411086
[ Info: iteration 17, average log likelihood -1.411031
[ Info: iteration 18, average log likelihood -1.410985
[ Info: iteration 19, average log likelihood -1.410945
[ Info: iteration 20, average log likelihood -1.410911
[ Info: iteration 21, average log likelihood -1.410882
[ Info: iteration 22, average log likelihood -1.410855
[ Info: iteration 23, average log likelihood -1.410831
[ Info: iteration 24, average log likelihood -1.410808
[ Info: iteration 25, average log likelihood -1.410787
[ Info: iteration 26, average log likelihood -1.410767
[ Info: iteration 27, average log likelihood -1.410747
[ Info: iteration 28, average log likelihood -1.410728
[ Info: iteration 29, average log likelihood -1.410710
[ Info: iteration 30, average log likelihood -1.410692
[ Info: iteration 31, average log likelihood -1.410675
[ Info: iteration 32, average log likelihood -1.410658
[ Info: iteration 33, average log likelihood -1.410641
[ Info: iteration 34, average log likelihood -1.410624
[ Info: iteration 35, average log likelihood -1.410608
[ Info: iteration 36, average log likelihood -1.410592
[ Info: iteration 37, average log likelihood -1.410577
[ Info: iteration 38, average log likelihood -1.410561
[ Info: iteration 39, average log likelihood -1.410546
[ Info: iteration 40, average log likelihood -1.410531
[ Info: iteration 41, average log likelihood -1.410517
[ Info: iteration 42, average log likelihood -1.410502
[ Info: iteration 43, average log likelihood -1.410488
[ Info: iteration 44, average log likelihood -1.410475
[ Info: iteration 45, average log likelihood -1.410461
[ Info: iteration 46, average log likelihood -1.410448
[ Info: iteration 47, average log likelihood -1.410435
[ Info: iteration 48, average log likelihood -1.410422
[ Info: iteration 49, average log likelihood -1.410409
[ Info: iteration 50, average log likelihood -1.410397
┌ Info: EM with 100000 data points 50 iterations avll -1.410397
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412361947060649
│     -1.4123111761258824
│      ⋮
└     -1.4103971620207292
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410393
[ Info: iteration 2, average log likelihood -1.410332
[ Info: iteration 3, average log likelihood -1.410275
[ Info: iteration 4, average log likelihood -1.410210
[ Info: iteration 5, average log likelihood -1.410133
[ Info: iteration 6, average log likelihood -1.410040
[ Info: iteration 7, average log likelihood -1.409929
[ Info: iteration 8, average log likelihood -1.409802
[ Info: iteration 9, average log likelihood -1.409663
[ Info: iteration 10, average log likelihood -1.409520
[ Info: iteration 11, average log likelihood -1.409377
[ Info: iteration 12, average log likelihood -1.409241
[ Info: iteration 13, average log likelihood -1.409114
[ Info: iteration 14, average log likelihood -1.408998
[ Info: iteration 15, average log likelihood -1.408894
[ Info: iteration 16, average log likelihood -1.408802
[ Info: iteration 17, average log likelihood -1.408722
[ Info: iteration 18, average log likelihood -1.408651
[ Info: iteration 19, average log likelihood -1.408590
[ Info: iteration 20, average log likelihood -1.408537
[ Info: iteration 21, average log likelihood -1.408490
[ Info: iteration 22, average log likelihood -1.408448
[ Info: iteration 23, average log likelihood -1.408411
[ Info: iteration 24, average log likelihood -1.408377
[ Info: iteration 25, average log likelihood -1.408346
[ Info: iteration 26, average log likelihood -1.408318
[ Info: iteration 27, average log likelihood -1.408291
[ Info: iteration 28, average log likelihood -1.408266
[ Info: iteration 29, average log likelihood -1.408243
[ Info: iteration 30, average log likelihood -1.408220
[ Info: iteration 31, average log likelihood -1.408199
[ Info: iteration 32, average log likelihood -1.408178
[ Info: iteration 33, average log likelihood -1.408159
[ Info: iteration 34, average log likelihood -1.408140
[ Info: iteration 35, average log likelihood -1.408121
[ Info: iteration 36, average log likelihood -1.408104
[ Info: iteration 37, average log likelihood -1.408087
[ Info: iteration 38, average log likelihood -1.408071
[ Info: iteration 39, average log likelihood -1.408055
[ Info: iteration 40, average log likelihood -1.408040
[ Info: iteration 41, average log likelihood -1.408026
[ Info: iteration 42, average log likelihood -1.408012
[ Info: iteration 43, average log likelihood -1.407998
[ Info: iteration 44, average log likelihood -1.407985
[ Info: iteration 45, average log likelihood -1.407972
[ Info: iteration 46, average log likelihood -1.407960
[ Info: iteration 47, average log likelihood -1.407948
[ Info: iteration 48, average log likelihood -1.407937
[ Info: iteration 49, average log likelihood -1.407925
[ Info: iteration 50, average log likelihood -1.407915
┌ Info: EM with 100000 data points 50 iterations avll -1.407915
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.410393430434477
│     -1.410331888092258
│      ⋮
└     -1.4079145524219234
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.420074763922055
│     -1.4200928058144267
│     -1.4200222306434933
│     -1.4199684570286162
│      ⋮
│     -1.4079367309217077
│     -1.4079254975681723
└     -1.4079145524219234
32×26 Array{Float64,2}:
 -0.178151     0.125901    -0.27756     -0.879006     0.59006      0.123964    0.278562    -0.0560198    0.0371146     0.440251    -0.344428   -0.475166    0.201125     0.427514    0.0662676    0.0610761  -0.0502557   -0.607012    0.433471   -0.822909    -0.40617     0.10521      0.211908     0.235349    -0.562928    0.433117
 -0.224987     0.3072       0.129931     0.0721616    0.74823     -0.0766647  -0.0209566    0.562915    -0.13946      -0.541853    -0.16347    -0.0906965  -0.0128928   -0.274713    0.151921     0.17462     0.528375    -1.00592    -0.1914     -0.266719     0.0559748   0.0620868   -0.174695     0.299563    -0.378785    0.415282
  0.262287    -0.0407225    0.139716     0.291294    -0.0739512    0.154348   -0.097543    -0.0307467    0.439787     -0.885007     0.0114514   0.353144    0.361039    -0.291661   -0.266428     0.218452   -0.184783     0.588216   -0.602056    0.0393462    0.113773    0.277976    -0.367154    -0.00261289  -0.15488     0.0625713
  0.043194     0.109035     0.00906537  -0.308722     0.110469    -0.030189    0.168216    -0.00203634   0.0453505     0.303242     0.0550757  -0.18782     0.103492     0.023246   -0.0375646   -0.145385    0.0228438    0.314746    0.0195227  -0.116652    -0.226752   -0.0300021    0.0123785    0.0732417    0.169039    0.19924
  0.313411     0.492108     0.316641     0.327022     0.726917    -0.323486    0.00202651  -0.693133    -0.373472     -0.341233     0.462802    0.0364767  -0.220915     0.574637   -0.0472813    0.287523    0.101913    -0.030342    0.214081    0.321425     0.173786   -0.0074083   -0.00742481  -0.209961    -0.236911    0.126217
  0.25219      0.498855     0.273382     0.479373     0.0126978   -0.309208   -0.138819    -0.0537592   -0.141384      0.00297339   0.073708    0.482848   -0.360483    -0.0248607  -0.788147     0.371483    0.491392     0.0536863  -0.0689815   0.0164828    0.375304    0.336492     0.0971994    0.379096    -0.0621196   0.196688
 -0.870323     0.46966      0.316599     0.00232329  -0.141751     0.32803     0.137827     0.238474    -0.493719     -0.234689     0.576889    0.330655   -0.424628     0.353342   -0.0897074   -0.350687   -0.789023    -0.173267    0.108526    0.364008    -0.0389104   0.407292    -0.210034     0.0596561   -0.269408   -0.578345
  0.285202    -0.182315     0.462104    -0.486566    -0.3381      -0.0224049   0.0511165    0.344144     0.0364359     0.602825     0.210328    0.0530565  -0.371168     0.528107   -0.251188     0.230286   -0.00696032  -0.0135246   0.492577    0.506757     0.664758    0.536858    -0.167783     0.339786     0.0720117  -0.26094
 -0.304198     0.356103    -0.398315    -0.312479    -0.0647064    0.0260487   0.401371    -0.820271     0.0572774    -0.311986    -0.0628431  -0.356052    0.463272    -0.172213    0.561991    -0.209801    0.032055     0.222459   -0.654577    0.0166531   -0.703382   -0.192497     0.0661052   -0.484581    -0.567251   -0.393505
  0.279656    -0.719953    -0.0456007    0.162202    -0.0379719   -0.637539    0.191198    -1.14202     -0.013166      0.241359     0.306019    0.104925    0.485239     0.320676    0.522628    -0.461698    0.0647895   -0.232092   -0.259027    1.18103     -0.0420821   0.493911     0.41094     -0.445082    -0.503379   -0.470329
  0.102079    -0.58159     -0.631236     0.349879    -0.828893     0.0856068  -0.24154     -0.400065    -0.000798678  -0.134454    -0.056818   -0.359518    0.695942     0.0792088  -0.525083    -0.197028   -0.597414    -0.354538   -0.0308749  -0.534531     0.511813   -0.271203     0.0525507   -0.320606    -0.378272   -0.139112
 -0.54929     -0.524324     0.248009     0.296938    -0.0835057    0.191857    0.273262    -0.329271    -0.711621     -0.168356    -0.368573    0.137085    0.430876    -0.0012326  -0.626274     0.147045    0.196523    -0.620382    0.518511   -0.128724     0.691079    0.0559609    0.539679    -0.322493    -0.410166    0.174731
 -0.290685    -0.322581     0.174834     0.0268786   -0.0110419   -0.195829   -0.237761     0.047655    -0.550156      0.114981    -0.559015    0.10954     0.103748     0.43377     0.39699     -0.80912     0.213266    -0.259932    0.0601607  -0.00423982  -0.296892   -0.518155    -0.389385    -0.401504     0.728135   -0.0402069
 -0.284636     0.115862    -0.377431    -0.145132    -0.408881    -0.485618    0.0897399   -0.107531    -1.12515       0.523357     0.37288    -0.508803    0.237031     0.129222    0.401797    -0.385527    0.842916     0.0413735   0.429751    0.343873     0.872069    0.355568    -0.0888423   -0.29568      0.40027    -0.0744662
  0.0636938    0.219217    -0.586414     0.583183    -0.102219    -0.0110446  -0.24283      0.027942     0.349625     -0.234146     0.236053   -0.0726659  -0.664573    -0.179111    0.235298     0.172186   -0.128543     0.0889615  -0.109992    0.499304     0.336308   -0.687886     0.436443    -0.626362     0.419462   -0.455782
  0.186908    -0.574968    -0.260355     0.264922    -0.327194    -0.171328   -0.316217     0.115867     0.0640998     0.216244    -0.405486   -0.141932    0.475101    -0.215041    0.0253183    0.180335    0.111231     0.213214   -0.271206    0.183014     0.0217168  -0.245618     0.627944    -0.120609     0.77934    -0.35147
 -0.0906291    0.217807     0.0922107   -0.127377     0.031636     0.288196    0.0287294   -0.289991     0.672151      0.242786    -0.135237   -0.162585    0.192281    -0.79301     0.00231226   0.130926    0.370504     0.238129   -0.631031   -0.365586    -0.262322   -0.218369     0.289064     0.0195109   -0.127908    0.433293
 -0.656199     0.0143085   -0.0367919   -0.109181    -0.407667     0.779596    0.178503     0.589193    -0.149714     -0.150493    -0.136846   -0.160375   -0.297558    -0.597854   -0.033047     0.160102    0.0170457    0.304215    0.174742   -0.501601    -0.0744342  -0.370092    -0.136469     0.321995     0.485792    0.286774
 -0.591907    -0.081658     0.872866    -0.817369     0.428867     0.0304566  -0.350652     0.099133    -0.203714      0.0600254   -0.107528   -0.505069    0.57        -0.518126    0.904043     0.0148157   0.223726     0.195463   -0.017783    0.814529    -0.479253   -0.0628657    0.105708     0.120784     0.236181    0.613975
 -0.636435    -0.16695      0.292061     0.155036     0.372903     0.0998594  -0.761375     0.216796    -0.312927     -0.295993    -0.485074   -0.106196    0.566148     0.0397593   0.333141     0.396751    0.574942    -0.378561   -0.145509    0.039599    -0.267074    0.1826       0.0172221    0.271259     0.257545   -0.0618697
  0.40407      0.533664     0.0497668   -0.084103     0.305995    -0.31028    -0.308791     0.0789186    0.0581593    -0.0205494    0.259598   -0.175665   -0.420274     0.195488    0.364014    -0.0748796   0.128566     0.330461   -0.522857    0.0219323   -0.438672   -0.0950487   -0.470152     0.42286      0.560065    0.0258381
  0.358346    -0.0956186    0.145455     0.133953     0.123611    -0.106002   -0.244324     0.00760062   0.416586      0.0783641    0.0946615  -0.22003     0.708248    -0.130891   -0.149181    -0.532914   -0.124202     0.469044   -0.340269   -0.208641    -0.270905   -0.0240655   -0.76988      0.596025     0.0501144   0.140748
 -0.0375993   -0.27501      0.0485494    0.458326    -0.563382    -0.260583   -0.285014    -0.515967    -0.244148     -0.207356     0.257386   -0.214429    0.183883    -0.364535    0.0753217   -0.0899665  -0.0348623    0.306442   -0.213643    0.298365     0.382626    0.399073    -0.301346    -0.0574557    0.060098    0.229117
 -0.0262538   -0.179887     0.0721253   -0.243601    -0.196835    -0.305322   -0.189052     0.402035    -0.279511     -0.193351     0.132842    0.165508   -0.0610783    0.0746894   0.0439281   -0.2868      0.226984    -0.0997289  -0.245419    0.0140265    0.147385   -0.00267977  -0.482265     0.138991    -0.0444776  -0.319319
 -0.183328    -0.095578    -0.198533     0.021224     0.356217     0.109529   -0.0116221    0.260859    -0.202352     -0.0881065   -0.0993503   0.313388   -0.13395      0.292065   -0.295626     0.0390856  -0.268234    -0.349667    0.369729   -0.0211125    0.66353    -0.177719     0.557951    -0.257249    -0.198101   -0.411754
  0.183546     0.273569     0.280241     0.0903374    0.396493     0.150261    0.0765241   -0.114075     0.445437      0.388354    -0.387129    0.473702   -0.0324439    0.287653   -0.0448608    0.0111316  -0.186336    -0.347174    0.373766    0.22621     -0.621051   -0.120759     0.387358    -0.275366    -0.207703   -0.286451
  0.113883     0.0592964   -0.0818891    0.0536529   -0.0601806   -0.0131848  -0.0748395   -0.0546122    0.151699     -0.117697    -0.0783616   0.0506033  -0.00632927   0.0702891   0.0901906    0.119075   -0.116463     0.174882   -0.130864    0.193409    -0.0518468  -0.311564     0.103307    -0.119025     0.243542   -0.201167
 -0.0389273    0.00030398   0.044423    -0.0143096    0.142376     0.0476883   0.228606     0.0116007   -0.078672      0.114097     0.018165   -0.138323    0.0359481   -0.0955852  -0.0239699   -0.0258251   0.0738103   -0.0962792   0.167677   -0.100745     0.0274611   0.192649    -0.00365344   0.016216    -0.0930036   0.378424
  0.531803    -0.432677     0.157749    -0.774202    -0.00219042   0.0343143   0.656468     0.211505     0.229612      0.322813    -0.108671    0.402908    0.151913     0.129311   -0.542977    -0.210079    0.0948332    0.212168    0.113773   -0.439964     0.0438856   0.317838    -0.698173     0.168553    -0.188108    0.610501
  0.597321    -0.0893121   -0.539764     0.260825    -0.522541    -0.521749    0.272061     0.0820531    0.371219      0.014032    -0.102598    0.74045    -0.456747     0.160655   -0.644485    -0.284048    0.00385564  -0.152311    0.231389   -0.313172     0.462513   -0.0176543   -0.492967    -0.265178     0.0703906  -0.10696
 -0.126831    -0.469235    -0.450705    -0.181606    -0.103269     0.0401877   0.52133      0.0431236    0.263604     -0.00332777   0.0481256  -0.469505    0.350976     0.0433167   0.288519    -0.345177   -0.541232     0.211631    0.265623   -0.119451    -0.226116   -0.181824     0.154431    -0.267168     0.299366    0.0296062
 -0.00534219   0.0134182   -0.175783    -0.20521     -0.185412     0.330742    0.838082    -0.00359616   0.204922      0.0861978    0.220079   -0.11329    -0.263699    -0.100835    0.0449847    0.291031   -0.309069     0.140834    0.425315    0.281742     0.363699    0.5609       0.19568     -0.232998    -0.395292    0.438328[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407904
[ Info: iteration 2, average log likelihood -1.407893
[ Info: iteration 3, average log likelihood -1.407883
[ Info: iteration 4, average log likelihood -1.407873
[ Info: iteration 5, average log likelihood -1.407863
[ Info: iteration 6, average log likelihood -1.407854
[ Info: iteration 7, average log likelihood -1.407844
[ Info: iteration 8, average log likelihood -1.407835
[ Info: iteration 9, average log likelihood -1.407826
[ Info: iteration 10, average log likelihood -1.407817
┌ Info: EM with 100000 data points 10 iterations avll -1.407817
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.833041e+05
      1       6.981378e+05      -2.851664e+05 |       32
      2       6.887058e+05      -9.431908e+03 |       32
      3       6.847984e+05      -3.907476e+03 |       32
      4       6.823729e+05      -2.425427e+03 |       32
      5       6.807881e+05      -1.584823e+03 |       32
      6       6.796397e+05      -1.148455e+03 |       32
      7       6.787343e+05      -9.053727e+02 |       32
      8       6.779720e+05      -7.622871e+02 |       32
      9       6.772626e+05      -7.094236e+02 |       32
     10       6.766201e+05      -6.424699e+02 |       32
     11       6.760741e+05      -5.459616e+02 |       32
     12       6.755769e+05      -4.972805e+02 |       32
     13       6.751364e+05      -4.404195e+02 |       32
     14       6.747234e+05      -4.130496e+02 |       32
     15       6.743603e+05      -3.631092e+02 |       32
     16       6.740639e+05      -2.964228e+02 |       32
     17       6.738173e+05      -2.466031e+02 |       32
     18       6.736004e+05      -2.168140e+02 |       32
     19       6.734070e+05      -1.934722e+02 |       32
     20       6.732365e+05      -1.704657e+02 |       32
     21       6.730951e+05      -1.413628e+02 |       32
     22       6.729739e+05      -1.212305e+02 |       32
     23       6.728743e+05      -9.964196e+01 |       32
     24       6.727898e+05      -8.447482e+01 |       32
     25       6.727005e+05      -8.929809e+01 |       32
     26       6.726032e+05      -9.727171e+01 |       32
     27       6.725177e+05      -8.556407e+01 |       32
     28       6.724358e+05      -8.185001e+01 |       32
     29       6.723689e+05      -6.689767e+01 |       32
     30       6.723071e+05      -6.182804e+01 |       32
     31       6.722473e+05      -5.979007e+01 |       32
     32       6.721910e+05      -5.632599e+01 |       32
     33       6.721409e+05      -5.010007e+01 |       32
     34       6.720958e+05      -4.509727e+01 |       32
     35       6.720497e+05      -4.611106e+01 |       32
     36       6.720060e+05      -4.364258e+01 |       32
     37       6.719676e+05      -3.844829e+01 |       32
     38       6.719278e+05      -3.977363e+01 |       32
     39       6.718910e+05      -3.683951e+01 |       32
     40       6.718567e+05      -3.430517e+01 |       32
     41       6.718245e+05      -3.217594e+01 |       32
     42       6.717975e+05      -2.701523e+01 |       32
     43       6.717723e+05      -2.513695e+01 |       32
     44       6.717471e+05      -2.525318e+01 |       32
     45       6.717195e+05      -2.758021e+01 |       32
     46       6.716912e+05      -2.829845e+01 |       32
     47       6.716562e+05      -3.503750e+01 |       32
     48       6.716141e+05      -4.207097e+01 |       32
     49       6.715706e+05      -4.347833e+01 |       32
     50       6.715300e+05      -4.063423e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 671529.9775141012)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419538
[ Info: iteration 2, average log likelihood -1.414493
[ Info: iteration 3, average log likelihood -1.413052
[ Info: iteration 4, average log likelihood -1.411907
[ Info: iteration 5, average log likelihood -1.410745
[ Info: iteration 6, average log likelihood -1.409808
[ Info: iteration 7, average log likelihood -1.409259
[ Info: iteration 8, average log likelihood -1.408981
[ Info: iteration 9, average log likelihood -1.408828
[ Info: iteration 10, average log likelihood -1.408727
[ Info: iteration 11, average log likelihood -1.408651
[ Info: iteration 12, average log likelihood -1.408589
[ Info: iteration 13, average log likelihood -1.408536
[ Info: iteration 14, average log likelihood -1.408490
[ Info: iteration 15, average log likelihood -1.408449
[ Info: iteration 16, average log likelihood -1.408412
[ Info: iteration 17, average log likelihood -1.408378
[ Info: iteration 18, average log likelihood -1.408346
[ Info: iteration 19, average log likelihood -1.408317
[ Info: iteration 20, average log likelihood -1.408289
[ Info: iteration 21, average log likelihood -1.408263
[ Info: iteration 22, average log likelihood -1.408237
[ Info: iteration 23, average log likelihood -1.408213
[ Info: iteration 24, average log likelihood -1.408189
[ Info: iteration 25, average log likelihood -1.408165
[ Info: iteration 26, average log likelihood -1.408142
[ Info: iteration 27, average log likelihood -1.408120
[ Info: iteration 28, average log likelihood -1.408097
[ Info: iteration 29, average log likelihood -1.408075
[ Info: iteration 30, average log likelihood -1.408053
[ Info: iteration 31, average log likelihood -1.408031
[ Info: iteration 32, average log likelihood -1.408010
[ Info: iteration 33, average log likelihood -1.407989
[ Info: iteration 34, average log likelihood -1.407968
[ Info: iteration 35, average log likelihood -1.407949
[ Info: iteration 36, average log likelihood -1.407929
[ Info: iteration 37, average log likelihood -1.407911
[ Info: iteration 38, average log likelihood -1.407893
[ Info: iteration 39, average log likelihood -1.407876
[ Info: iteration 40, average log likelihood -1.407860
[ Info: iteration 41, average log likelihood -1.407845
[ Info: iteration 42, average log likelihood -1.407830
[ Info: iteration 43, average log likelihood -1.407816
[ Info: iteration 44, average log likelihood -1.407802
[ Info: iteration 45, average log likelihood -1.407789
[ Info: iteration 46, average log likelihood -1.407777
[ Info: iteration 47, average log likelihood -1.407765
[ Info: iteration 48, average log likelihood -1.407753
[ Info: iteration 49, average log likelihood -1.407742
[ Info: iteration 50, average log likelihood -1.407731
┌ Info: EM with 100000 data points 50 iterations avll -1.407731
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.133323     0.252238   -0.265712     0.625      -0.319902   -0.293804    -0.328754    0.175068    0.300203    -0.111984   -0.439466     1.05798    -0.456905      0.45063    -0.0610081   -0.29416     0.0334708  -0.649828    0.366079    0.097865   -0.0980255  -0.229031    -0.306877   -0.665018    -0.261763   -0.589619
 -0.376004     0.152152   -0.304926     0.47427     0.128861   -0.0387894   -0.218441   -0.52632     0.0703462   -0.18172     0.24897     -0.352389    0.304566     -0.375552    0.318199    -0.0850959   0.0164932   0.102624   -0.387851    0.267889   -0.230862   -0.588919     0.944527   -0.787884    -0.0423994  -0.549625
  0.0078019    0.0882753   0.192897    -0.10101     0.269483    0.0166252   -0.315284    0.221585    0.325634     1.09795    -0.58106      0.018121    0.158019      0.311788   -0.214359    -0.547085    0.444586   -0.219239    0.271457   -0.289707   -0.588725   -0.478058     0.290938    0.0414973    0.624119    0.0358855
 -0.163368     0.188619    0.149863    -0.056096    0.111561    0.0976982    0.0848332   0.136126   -0.145338    -0.13399     0.0590323    0.0762578  -0.0400139    -0.0266371   0.0607635   -0.0265775   0.0972854  -0.0179385  -0.010072   -0.026425   -0.0173993   0.0117519   -0.246488    0.0834314    0.0182105   0.0710224
 -0.544113     0.564521   -0.18993     -0.155659    0.0556809   0.685834    -0.061541    0.371732   -0.135881    -0.411489   -0.0136121    0.0301658  -0.620288     -0.13291     0.0592089    0.299059   -0.060778    0.0563551  -0.121069    0.0397071   0.0206009  -0.578125    -0.0427706   0.111218     0.395509   -0.11411
 -0.607437    -0.0275896  -0.0823425    0.750156    0.085326    0.0840999    0.0878943  -0.0167866  -0.593222    -0.429068   -0.00955177  -0.0783388  -0.00448146    0.0846748  -0.232434     0.176221   -0.0566694  -0.478702    0.646605    0.269468    0.558317    0.471373     0.262845    0.0346264   -0.19832     0.230989
  0.137519    -0.076808   -0.371867     0.50548    -0.227781   -0.619673     0.129708   -0.641739   -0.0825079   -0.528945    0.129272    -0.510899    0.0254386    -0.383761    0.680311    -0.463472   -0.212329    0.0227227  -0.395477    0.235522   -0.41135     0.373433    -0.637824    0.123495    -0.077823    0.177086
  0.0924559   -0.0131116  -0.0522159   -0.423976   -0.138379   -0.00121312   0.282428   -0.553089    0.253861    -0.0222917   0.0557874   -0.159243    0.32283       0.251437    0.436339     0.0409904  -0.287752    0.264004   -0.135355    0.372006   -0.446136   -0.234121     0.0631415  -0.336785    -0.0949298  -0.288359
 -0.0214692   -0.13068    -0.0343828   -0.0273484  -0.0506044   0.169178     0.241283    0.0035001   0.069824     0.0665013   0.152367    -0.286558    0.134172     -0.218638   -0.00112518  -0.0175154  -0.0942634   0.14741     0.134495   -0.0396178   0.085506    0.138549    -0.07122    -0.00455264   0.0389714   0.485121
 -0.397036    -0.370861   -0.265042    -0.166427   -0.539805    0.753199     0.620557    0.0927328   0.43687      0.0624059  -0.430776    -0.0153215   0.318509     -0.665327    0.246585     0.161617   -0.344234    0.0633355   0.315529   -0.167385   -0.0506855   0.204092     0.178105   -0.310208    -0.233432    0.280138
  0.039078     0.136791    0.38338      0.28429     0.164464   -0.183543    -0.53941     0.117502   -0.11134     -0.0681553  -0.171872    -0.0489136   0.242088     -0.0172191   0.253543     0.147334    0.389141    0.112573   -0.386855    0.0511041  -0.388972   -0.0286172   -0.258473    0.333131     0.56043    -0.0227121
 -0.344028    -0.367186    0.258502    -0.58573    -0.372304   -0.0957088    0.361552    0.414403   -0.398236     0.0876442   0.321665     0.088165   -0.527864      0.18737     0.21399     -0.0980605  -0.0146036   0.0264451   0.385561    0.275358    0.620215    0.401318    -0.440386    0.0938478    0.170514   -0.217687
 -0.814237    -0.280165    0.664154    -0.381323    0.473565   -0.162829    -0.729536    0.31271    -0.557521    -0.208889   -0.538649    -0.224515    0.655995      0.26153     0.497258     0.0116696   0.498245   -0.523223   -0.021985    0.289823   -0.0345363   0.0456234   -0.0201192  -0.00200968   0.063967   -0.00249511
 -0.0437912    0.603602    0.366713    -0.105658   -0.416692    0.183421     0.472585    0.274393   -0.017978     0.412699    0.67607      0.0581115  -0.304852     -0.0742538  -0.565898     0.26136    -0.0124393   0.369577    0.348517    0.531819    0.220223    0.593887     0.417168    0.208395    -0.309272   -0.09472
 -0.23002      0.0696095  -0.488547    -0.0610788  -0.527767   -0.472832    -0.0249074  -0.334106   -1.07593      0.632716    0.414537    -0.576857    0.413186      0.0488527   0.480163    -0.502988    0.840941    0.160699    0.242049    0.372967    0.717433    0.179868    -0.0928865  -0.364303     0.394602   -0.0368239
  0.320746    -0.344574   -0.146451     0.445002   -0.598062    0.046807    -0.957896   -0.190663    0.05879     -0.147545   -0.0423934   -0.0933193   0.588628     -0.116803   -0.370258     0.0994501  -0.22085     0.0774752  -0.539582   -0.0522449   0.478649   -0.0169071   -0.32452     0.241133     0.0864113  -0.329007
  0.192699    -0.854622   -0.173327     0.380075   -0.525152   -0.308049     0.118723   -0.0375689   0.00541925   0.199078   -0.28304      0.120044    0.0814903    -0.022346   -0.0965502    0.162352   -0.0607639   0.302438    0.166027    0.683278    0.311557   -0.209231     0.561568   -0.431383     0.901987   -0.283041
 -0.00721036  -0.160423    0.372869    -0.417658   -0.131958   -0.105529     0.157623   -0.0347631   0.127306     0.257268    0.225987     0.0677598   0.647516      0.214644   -0.613644    -0.59099    -0.161328    0.487928   -0.148354   -0.118698   -0.33265     0.392365    -1.20943     0.717115    -0.304029    0.318349
 -0.0845029   -0.204414    0.0690713    0.143083   -0.181971   -0.262865     0.232141   -0.203221   -0.401187    -0.0783447  -0.176349     0.310954    0.0773273    -0.360577   -0.681058     0.0595074   0.632863   -0.418959    0.0443409  -0.510663    0.550959    0.102408    -0.0597993  -0.0698513   -0.457908    0.366314
  0.0577902    0.30651     0.176081    -0.383535    0.559068    0.0720666    0.0759006   0.0851706   0.187191     0.152238    0.0384028   -0.218784   -0.0419325    -0.253434    0.606851     0.0225232   0.21085    -0.526212   -0.169304   -0.18025    -0.349172    0.153629    -0.0383627   0.270095    -0.533408    0.445862
  0.400826    -0.396065    0.275586    -0.202128    0.11075    -0.39387      0.357114   -0.867802    0.180067     0.289095    0.27726      0.180858    0.353504      0.550218    0.118564    -0.187774   -0.193982   -0.0945063   0.0500715   0.663272    0.219428    0.623502     0.437455   -0.556961    -0.70694    -0.286514
 -0.321064     0.0137131  -0.343964    -0.718614    0.361904    0.0434103    0.53555    -0.248721   -0.159285     0.233543   -0.128131    -0.411646    0.339681      0.695315   -0.18267     -0.0631285  -0.208052   -0.313763    0.664569   -0.723939   -0.253066    0.101797     0.248191   -0.0209835   -0.427918    0.307617
  0.475104     0.482578    0.356684     0.30723     0.520799   -0.515716    -0.352386   -0.264321   -0.338304    -0.409859    0.533237     0.210945   -0.431442      0.49773    -0.172068     0.109121    0.356259    0.0280687  -0.155019    0.208544    0.291751   -0.0255444   -0.306801    0.107918     0.0630446  -0.0474747
  1.07374     -0.324115   -0.25747     -0.345502   -0.13873    -0.192112     0.355488    0.504896    0.346462     0.183995   -0.273021     0.331952   -0.330817      0.257964   -0.506734     0.179525    0.400803    0.0682042   0.100639   -0.430093    0.467665    0.356834    -0.718975    0.0620589    0.343036    0.706462
  0.199792     0.162632    0.0706433    0.0618299   0.43119     0.159529     0.215014   -0.183284    0.0350651    0.332922   -0.216602     0.263761   -0.215204      0.405151   -0.249986     0.258731   -0.285028   -0.21289     0.442996    0.159922    0.155677    0.0144089    0.614766   -0.203676    -0.162674   -0.0355895
  0.362049     0.0324649   0.649914     0.187817    0.654416    0.683785     0.204015    0.0462804   0.582375    -0.455266   -0.421851     0.440272    0.185015     -0.241931   -0.722953     0.116597   -0.813758    0.163065   -0.295298   -0.266966   -0.350733   -0.113602     0.15366     0.102887    -0.525385    0.355098
  0.559729     0.0821842  -1.07372      0.303382   -0.254986   -0.255192     0.515063    0.14004     0.567224     0.0310357   0.513918    -0.0480369  -0.387181      0.0100294  -0.517874    -0.352665   -0.686218    0.326448    0.145821   -0.145765    0.584332   -0.235003     0.0120238  -0.220561    -0.0359652  -0.191558
 -0.138511     0.305972   -0.00380303   0.0300431  -0.0140897   0.0191611    0.0242249  -0.515276    0.591945     0.0651915  -0.192161     0.124271    0.130832     -0.570145   -0.245702     0.160687    0.629688    0.564105   -0.754003   -0.250822   -0.245666    0.00695984   0.160453   -0.0352211   -0.0288328   0.395952
 -0.255026    -0.284351   -0.21727     -0.384115   -0.139909    0.407532    -0.0423559   0.543865    0.0511936    0.098118   -0.352753    -0.99469     0.000131119  -0.834664   -0.166161     0.0385188   0.0430219   0.148201   -0.379756   -0.811607   -0.104994   -0.260202     0.486508    0.626929     0.449037    0.558907
  0.045782     0.0194141  -0.0681034    0.083232   -0.0289733  -0.187472    -0.0806792   0.138802   -0.0189485   -0.112949    0.00492079   0.152769   -0.0866521     0.0534105  -0.061108    -0.0489445   0.038128   -0.0263899  -0.0549458   0.0763804   0.126472   -0.0840334    0.0330333  -0.0443409    0.0469075  -0.242327
  0.407605     0.276996   -0.0767338   -0.312352    0.128556   -0.182271    -0.0224357   0.142452    0.609156     0.0872434   0.435077    -0.210812    0.0563787    -0.0923956   0.628376    -0.199052   -0.119309    0.798163   -0.496354    0.118266   -0.659782   -0.260546    -0.348372    0.23638      0.688163   -0.00292477
 -0.0753708   -0.549304   -0.298796    -0.208566    0.0577596   0.0297937    0.23147     0.277136   -0.10144     -0.222455   -0.37472     -0.102082    0.391343      0.0900962   0.329991    -0.653651   -0.298123    0.0809379  -0.0065525  -0.346004   -0.261499   -0.446357    -0.266975   -0.365751     0.479637   -0.203085[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407721
[ Info: iteration 2, average log likelihood -1.407710
[ Info: iteration 3, average log likelihood -1.407701
[ Info: iteration 4, average log likelihood -1.407691
[ Info: iteration 5, average log likelihood -1.407681
[ Info: iteration 6, average log likelihood -1.407672
[ Info: iteration 7, average log likelihood -1.407663
[ Info: iteration 8, average log likelihood -1.407654
[ Info: iteration 9, average log likelihood -1.407645
[ Info: iteration 10, average log likelihood -1.407636
┌ Info: EM with 100000 data points 10 iterations avll -1.407636
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
