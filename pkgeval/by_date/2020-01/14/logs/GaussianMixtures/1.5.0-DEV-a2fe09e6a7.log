Julia Version 1.5.0-DEV.57
Commit a2fe09e6a7 (2020-01-13 17:14 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed Rmath ────────────── v0.6.0
 Installed Distances ────────── v0.8.2
 Installed OrderedCollections ─ v1.1.0
 Installed SpecialFunctions ─── v0.9.0
 Installed FileIO ───────────── v1.2.1
 Installed Parameters ───────── v0.12.0
 Installed Clustering ───────── v0.13.3
 Installed StatsFuns ────────── v0.9.3
 Installed FillArrays ───────── v0.8.4
 Installed URIParser ────────── v0.4.0
 Installed Blosc ────────────── v0.5.1
 Installed CMake ────────────── v1.1.2
 Installed NearestNeighbors ─── v0.4.4
 Installed HDF5 ─────────────── v0.12.5
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed BinaryProvider ───── v0.5.8
 Installed SortingAlgorithms ── v0.3.1
 Installed Distributions ────── v0.22.2
 Installed Arpack_jll ───────── v3.5.0+2
 Installed JLD ──────────────── v0.9.1
 Installed BinDeps ──────────── v1.0.0
 Installed DataStructures ───── v0.17.7
 Installed ScikitLearnBase ──── v0.5.0
 Installed Compat ───────────── v2.2.0
 Installed DataAPI ──────────── v1.1.0
 Installed StaticArrays ─────── v0.12.1
 Installed Missings ─────────── v0.4.3
 Installed QuadGK ───────────── v2.3.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed Arpack ───────────── v0.4.0
 Installed StatsBase ────────── v0.32.0
 Installed LegacyStrings ────── v0.4.1
 Installed PDMats ───────────── v0.9.10
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.2
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_MQNk38/Project.toml`
 [no changes]
  Updating `/tmp/jl_MQNk38/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_CPN3wM/Project.toml`
 [no changes]
  Updating `/tmp/jl_CPN3wM/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_C6WeB0/Project.toml`
 [no changes]
  Updating `/tmp/jl_C6WeB0/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_yG27AZ/Project.toml`
 [no changes]
  Updating `/tmp/jl_yG27AZ/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_kRAGMq/Project.toml`
 [no changes]
  Updating `/tmp/jl_kRAGMq/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_kRAGMq/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.2
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.1540325167065612e6, [99744.09965312576, 255.90034687424088], [-161.4673768691949 -818.3295729489136 -418.74888276332206; 9.25747381223397 719.3793352029188 -214.45626665126454], [[99751.45831033177 -139.38667541314663 16.696390688175246; -139.3866754131467 97912.55460290605 1161.7262159157085; 16.696390688175207 1161.7262159157085 100240.58190904943], [376.22692791643374 23.291842937185706 -157.69829299013657; 23.291842937185706 2053.833183775007 -563.5667294124269; -157.69829299013657 -563.5667294124269 471.15154415157633]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.794299e+03
      1       1.404573e+03      -3.897263e+02 |        7
      2       1.301706e+03      -1.028663e+02 |        4
      3       1.224677e+03      -7.702923e+01 |        5
      4       1.200455e+03      -2.422219e+01 |        2
      5       1.182346e+03      -1.810856e+01 |        2
      6       1.176290e+03      -6.056046e+00 |        0
      7       1.176290e+03       0.000000e+00 |        0
K-means converged with 7 iterations (objv = 1176.290225645006)
┌ Info: K-means with 272 data points using 7 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.074060
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.792936
[ Info: iteration 2, lowerbound -3.659785
[ Info: iteration 3, lowerbound -3.525302
[ Info: iteration 4, lowerbound -3.372816
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.196979
[ Info: iteration 6, lowerbound -3.008594
[ Info: iteration 7, lowerbound -2.839817
[ Info: iteration 8, lowerbound -2.711721
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.620735
[ Info: iteration 10, lowerbound -2.556278
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.509385
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.461791
[ Info: iteration 13, lowerbound -2.421771
[ Info: iteration 14, lowerbound -2.388142
[ Info: iteration 15, lowerbound -2.357063
[ Info: iteration 16, lowerbound -2.330196
[ Info: iteration 17, lowerbound -2.312210
[ Info: iteration 18, lowerbound -2.307616
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302920
[ Info: iteration 20, lowerbound -2.299260
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Jan 15 03:42:25 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Jan 15 03:42:33 2020: K-means with 272 data points using 7 iterations
11.3 data points per parameter
, Wed Jan 15 03:42:35 2020: EM with 272 data points 0 iterations avll -2.074060
5.8 data points per parameter
, Wed Jan 15 03:42:37 2020: GMM converted to Variational GMM
, Wed Jan 15 03:42:46 2020: iteration 1, lowerbound -3.792936
, Wed Jan 15 03:42:46 2020: iteration 2, lowerbound -3.659785
, Wed Jan 15 03:42:46 2020: iteration 3, lowerbound -3.525302
, Wed Jan 15 03:42:46 2020: iteration 4, lowerbound -3.372816
, Wed Jan 15 03:42:46 2020: dropping number of Gaussions to 7
, Wed Jan 15 03:42:46 2020: iteration 5, lowerbound -3.196979
, Wed Jan 15 03:42:46 2020: iteration 6, lowerbound -3.008594
, Wed Jan 15 03:42:46 2020: iteration 7, lowerbound -2.839817
, Wed Jan 15 03:42:46 2020: iteration 8, lowerbound -2.711721
, Wed Jan 15 03:42:46 2020: dropping number of Gaussions to 5
, Wed Jan 15 03:42:46 2020: iteration 9, lowerbound -2.620735
, Wed Jan 15 03:42:46 2020: iteration 10, lowerbound -2.556278
, Wed Jan 15 03:42:46 2020: dropping number of Gaussions to 4
, Wed Jan 15 03:42:46 2020: iteration 11, lowerbound -2.509385
, Wed Jan 15 03:42:46 2020: dropping number of Gaussions to 3
, Wed Jan 15 03:42:46 2020: iteration 12, lowerbound -2.461791
, Wed Jan 15 03:42:47 2020: iteration 13, lowerbound -2.421771
, Wed Jan 15 03:42:47 2020: iteration 14, lowerbound -2.388142
, Wed Jan 15 03:42:47 2020: iteration 15, lowerbound -2.357063
, Wed Jan 15 03:42:47 2020: iteration 16, lowerbound -2.330196
, Wed Jan 15 03:42:47 2020: iteration 17, lowerbound -2.312210
, Wed Jan 15 03:42:47 2020: iteration 18, lowerbound -2.307616
, Wed Jan 15 03:42:47 2020: dropping number of Gaussions to 2
, Wed Jan 15 03:42:47 2020: iteration 19, lowerbound -2.302920
, Wed Jan 15 03:42:47 2020: iteration 20, lowerbound -2.299260
, Wed Jan 15 03:42:47 2020: iteration 21, lowerbound -2.299256
, Wed Jan 15 03:42:47 2020: iteration 22, lowerbound -2.299254
, Wed Jan 15 03:42:47 2020: iteration 23, lowerbound -2.299254
, Wed Jan 15 03:42:47 2020: iteration 24, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 25, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 26, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 27, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 28, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 29, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 30, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 31, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 32, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 33, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 34, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 35, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 36, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 37, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 38, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 39, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 40, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 41, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 42, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 43, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 44, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 45, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 46, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 47, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 48, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 49, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: iteration 50, lowerbound -2.299253
, Wed Jan 15 03:42:47 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601402, 95.954907773986]
β = [178.04509222601402, 95.954907773986]
m = [4.250300733269907 79.28686694436182; 2.000229257775369 53.85198717246129]
ν = [180.04509222601402, 97.954907773986]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484466 -0.007644049042327731; 0.0 0.00858170516633361], [0.3758763611948442 -0.008953123827346168; 0.0 0.012748664777409477]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9814006384304388
avll from llpg:  -0.9814006384304376
avll direct:     -0.9814006384304376
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -1.003905064254006
avll from llpg:  -1.0039050642540057
avll direct:     -1.0039050642540057
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0964561   -0.0764299   -0.0351222  -0.0667017    0.0566915   -0.0555127    0.0226328     0.0820065   0.0591033   -0.198736    -0.0187525     0.112019     0.0230196   -0.0651526    0.0612758   -0.0806285   -0.092657     0.083395    -0.0687339     0.070933     0.0560683     0.127333      0.156359      0.118283     0.099426     -0.135138
  0.0577005    0.0575818    0.146516   -0.126584     0.0300648   -0.0964391   -0.0435123     0.0866907  -0.0644573    0.126274    -0.0399176     0.0964042    0.0877326   -0.0376704    0.0278476   -0.0457017    0.124158     0.195187     0.000826484  -0.160781    -0.0683908    -0.16818      -0.140049      0.049519     0.102504     -0.00434264
  0.0329241   -0.150202     0.0757802  -0.0691143   -0.08514     -0.125893    -0.055838     -0.0389683  -0.0888199    0.167155     0.0687764    -0.0483309    0.0754181   -0.0932755    0.21646      0.0916342    0.00349706   0.0616974    0.114641     -0.220037     0.0268641    -0.0786485    -0.00978111    0.0614611   -0.0243989     0.186478
 -0.0308793    0.035056     0.0803922  -0.00818882   0.0104971    0.0369113   -0.161746      0.0250719  -0.0627311    0.181852    -0.123735     -0.218772     0.148106    -0.196644     0.0589786   -0.0348247   -0.00221378  -0.125972     0.0305836     0.0328232    0.000620338  -0.0849932    -0.0719157    -0.171115    -0.0206503     0.0404515
  0.0822679   -0.182628    -0.0958284   0.136612    -0.056934     0.10034      0.0307735    -0.0297177   0.053127     0.10083     -0.000791338   0.0402962    0.0594777   -0.0101696   -0.0869903    0.102534     0.0437687    0.028687    -0.00745481   -0.0257415   -0.138383     -0.00571713    0.0418798     0.150353    -0.0804323     0.0338057
  0.0670966   -0.0352021   -0.153       0.0492062    0.0836157    0.116069    -0.0256233    -0.0611943   0.00167542  -0.0794438    0.088987      0.212923    -0.109623    -0.0464761    0.124594    -0.168529     0.138625     0.264009     0.00628378   -0.0115387   -0.0336044    -0.135053     -0.14511      -0.0672479   -0.0630698     0.0331261
  0.0601855    0.0212335    0.043926    0.229825     0.12087      0.0501805   -0.102339      0.187188    0.0316278   -0.0235706    0.0641959     0.0359088    0.146254    -0.0471333    0.0212637    0.00978397   0.0784983   -0.167596     0.0470451    -0.0101402    0.0272227     0.0855714     0.211464     -0.0162852   -0.138515      0.191497
 -0.102785    -0.131004    -0.162676    0.0222569    0.0260964    0.292464    -0.234408     -0.12904    -0.0912496   -0.0547633   -0.0324118    -0.0679734   -0.0293577   -0.0230573   -0.0583046   -0.0259849    0.0181608   -0.00129569   0.0838756     0.191593    -0.0792441     0.145078      0.225498      0.131975     0.0595361    -0.0164082
  0.0429415   -0.102334    -0.0166983   0.00557971   0.0620765   -0.114888     0.178914     -0.0662792   0.0347418   -0.0805791   -0.171553      0.0792024   -0.0958793    0.13606     -0.111254    -0.091049    -0.0115623   -0.0206412   -0.123377     -0.0669431    0.0467385    -0.0554142     0.0414216     0.0619281   -0.149884      0.0458037
 -0.134342    -0.0675575    0.0917964  -0.177532     0.0515804    0.0665589   -0.163881      0.127545   -0.0566271    0.12827      0.137244      0.0840962   -0.0480311   -0.0263631    0.0417381   -0.0292238   -0.0391755    0.195599    -0.00349668    0.00138502   0.124853      0.18457      -0.0247399     0.0643076    0.0966145     0.140046
  0.168067    -0.030499    -0.309165   -0.0374586    0.130415    -0.0512862    0.0719503    -0.0651946   0.0952987    0.00770821  -0.00526148    0.0253461   -0.074919     0.0552381    0.116387    -0.081876     0.105987     0.0527352    0.0727593     0.0368796   -0.00196143   -0.012018     -0.0145944     0.0294212    0.0377332     0.0791644
 -0.0362384    0.0984705   -0.102541    0.0429641   -0.154195    -0.0765564   -0.0283695     0.170135    0.0380085   -0.0724199   -0.0095676     0.152239     0.053576    -0.146304     0.155097     0.200876    -0.0666802   -0.167232     0.0529812    -0.0853462   -0.0133004     0.171864     -0.0428241    -0.00194468   0.0144404    -0.00484894
  0.0351641    0.104427     0.131879    0.129167    -0.11932      0.0545888    0.151789     -0.001843   -0.0365087   -0.0285691   -0.146486     -0.0870089   -0.00812814   0.0236109   -0.00950219  -0.016969    -0.0733905   -0.101268     0.00688735   -0.226019     0.0897441    -0.136869      0.0623648     0.083422     0.0369076     0.216969
 -0.0202597    0.0896012   -0.0359839  -0.0621416   -0.115088    -0.0689109   -0.272922     -0.0175713   0.160496    -0.111237     0.115437      0.0151556   -0.0461893    0.0258378   -0.0403497   -0.0576846    0.00330564  -0.0250853   -0.0583204    -0.0972135   -0.071845      0.142173      0.0919751     0.101475    -0.000658557   0.0309006
 -0.0717565    0.0358114   -0.085632    0.169168    -0.0234369   -0.0487136   -0.135425      0.0669581  -0.0579657   -0.105964     0.0428467     0.100471    -0.0989378    0.00653544   0.0784856   -0.0113807   -0.1164      -0.157477     0.048032     -0.136409     0.143717      0.112636     -0.055398      0.0460678   -0.153954     -0.169626
 -0.0349655    0.144435    -0.15803    -0.0406202    0.0836522   -0.0770863   -0.0927381     0.0611995  -0.0271442   -0.0894831   -0.0246962     0.00112712  -0.192988     0.0520792   -0.0331135   -0.104608    -0.0158151   -0.0263585    0.0508133    -0.125789     0.0359937     0.06174       0.114622     -0.0333743    0.00299412    0.00679703
  0.0769569   -0.145716     0.121065   -0.166368    -0.216178    -0.0442173   -0.12388      -0.0462991   0.00290489  -0.209243    -0.0239636     0.0296404   -0.0707636    0.0979538   -0.058774    -0.0591657    0.0467613   -0.0509717    0.149308     -0.0152083   -0.130024     -0.133878     -0.0518884     0.0872669   -0.00140254   -0.0613099
 -0.0654002   -0.272857     0.029569   -0.0423019    0.024026     0.109326    -0.022768      0.140767    0.0159174   -0.0404833   -0.098265     -0.0542793    0.154937    -0.0858347    0.0250396   -0.162634     0.0135756   -0.12804     -0.077352      0.142112    -0.0446887     0.0941122     0.0126305     0.106683     0.128071      0.0193995
 -0.0259204    0.153825     0.0182741   0.0782756    0.0193735   -0.0346794    0.0711092     0.126388    0.113836    -0.0150873    0.0807919    -0.0181945   -0.0324818   -0.134254    -0.0656664    0.0362713   -0.130823     0.127474    -0.0205648    -0.0365899   -0.036435      0.00147507    0.0414894     0.0607535   -0.082732     -0.123592
  0.0317686    0.0137373    0.112215   -0.0819138   -0.205099     0.110155    -0.0170414     0.0946061  -0.022287     0.0221136    0.144134     -0.0376309   -0.0886135    0.0475192   -0.043146    -0.112923     0.0835158   -0.0591482    0.150774      0.0184235    0.117962      0.125496      0.0188459    -0.207802    -0.00382241    0.12389
  0.00371049  -0.00942326  -0.110811    0.0316784   -0.139062     0.178773     0.0364432    -0.0929285   0.0445756   -0.182893    -0.033147      0.0246049   -0.0460888    0.176865    -0.00649795   0.00438855   0.0156701   -0.0618148    0.0306353    -0.259132     0.0405838    -0.101763      0.000419324  -0.0409439    0.0526811    -0.0656112
  0.153531    -0.10993     -0.0115783   0.0279877    0.09966     -0.0116864    0.0159935     0.0657326  -0.00946072  -0.047885    -0.0470443    -0.166991     0.0211146    0.0115022    0.143107    -0.0746765   -0.119941    -0.0234351    0.0794799    -0.0934356    0.00405824    0.108292      0.00193886   -0.056131     0.0760988    -0.0801632
 -0.0196996   -0.112057    -0.0404425  -0.0315496   -0.00132025  -0.00747621  -0.197772      0.0444068   0.164876     0.0909876    0.104418      0.0797627    0.135171     0.0161968    0.113115    -0.0191216    0.0711559   -0.0876651    0.0796941     0.165905     0.115613      0.126275      0.0747869     0.23566     -0.00690773   -0.0677153
  0.00472426   0.0579829    0.0895148   0.144816     0.1912      -0.0345703   -0.0155226     0.099486   -0.0164208   -0.0854362   -0.00476108    0.0277604    0.0336948   -0.0361954   -0.0467828   -0.0395768    0.0598839    0.135887     0.16769       0.0326293    0.124697     -0.0805862     0.195951      0.0142156   -0.182817      0.0545979
 -0.133565    -0.0393211    0.168455   -0.102401    -0.157075    -0.0427328    0.0246286    -0.110364   -0.0100193    0.251026    -0.035075      0.0835054    0.118553     0.0728958   -0.0108996    0.103552     0.0223146   -0.0823563   -0.084881      0.152112    -0.0321948    -0.137564     -0.0477706     0.0964692    0.0848647    -0.139355
 -0.0216513   -0.108279    -0.0268058  -0.194835    -0.0427687    0.11871      0.000786153   0.152743   -0.175571    -0.176329    -0.00476758    0.0965109    0.0760914    0.163683     0.017693     0.0147506    0.128668    -0.050679    -0.0234208    -0.157726     0.00876       0.0690037     0.0231918    -0.09404     -0.114605     -0.0374974
 -0.216912     0.0586844    0.0453826  -0.00242472   0.0784808   -0.0873206   -0.124661     -0.163511   -0.0289901   -0.113452     0.0709488     0.0819269    0.128042    -0.0234703   -0.0838106   -0.0230596    0.0629512   -0.00784375  -0.00671554   -0.0327063   -0.0309606     0.0955979    -0.0513629    -0.0848767    0.107328      0.0209879
 -0.0512402   -0.0671037   -0.0455501  -0.00649552   0.068404     0.166276     0.0563846     0.014007    0.167433    -0.134614     0.0367857    -0.192932     0.220209    -0.0093756    0.0730833   -0.0383293   -7.00795e-6   0.138649    -0.0317463     0.0623614   -0.0785586    -0.103286      0.0590283    -0.075862     0.147044     -0.110657
  0.0276556    0.0328364    0.0305999   0.17306      0.0471066    0.187002    -0.0672882    -0.0787323   0.0494856    0.00302879   0.00465525    0.153334    -0.110312     0.0579451   -0.0727084    0.0913398   -0.113261    -0.0104288   -0.046224     -0.176622    -0.100359      0.000430412  -0.159053     -0.0705124   -0.0459998     0.265019
 -0.0131025   -0.0636751   -0.0238415   0.0158453    0.0415438    0.0837798   -0.0930729     0.0234823  -0.0715371   -0.0850902    0.0447448     0.0958461   -0.0471171    0.0435463    0.0518152    0.0213849    0.0354308    0.103004     0.00963341   -0.099634     0.120468     -0.0366187     0.0173201    -0.11113     -0.045405      0.102812
  0.18012      0.102931    -0.0767951   0.0518681    0.0499044   -0.0380256   -0.0877014     0.0224322   0.0168237    0.267874     0.038007     -0.0522865    0.192641    -0.0438529   -0.0579105    0.0132206   -0.0273192   -0.00928109  -0.0082967    -0.0363709   -0.113752      0.161163      0.0621089    -0.0445642    0.0254334    -0.183744
 -0.128305    -0.101769     0.0103024  -0.186711    -0.00482897  -0.0119141    0.0672874     0.0114618  -0.104414     0.096461     0.132984      0.0732396    0.105432     0.0121555    0.116663    -0.0455626    0.226286    -0.0312223    0.015372      0.0764603   -0.0230754     0.0549359    -0.0768284     0.17084     -0.0859049    -0.201117kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4262894925914429
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426384
[ Info: iteration 2, average log likelihood -1.426296
[ Info: iteration 3, average log likelihood -1.425579
[ Info: iteration 4, average log likelihood -1.416020
[ Info: iteration 5, average log likelihood -1.393566
[ Info: iteration 6, average log likelihood -1.386769
[ Info: iteration 7, average log likelihood -1.385610
[ Info: iteration 8, average log likelihood -1.385040
[ Info: iteration 9, average log likelihood -1.384708
[ Info: iteration 10, average log likelihood -1.384510
[ Info: iteration 11, average log likelihood -1.384386
[ Info: iteration 12, average log likelihood -1.384302
[ Info: iteration 13, average log likelihood -1.384239
[ Info: iteration 14, average log likelihood -1.384187
[ Info: iteration 15, average log likelihood -1.384142
[ Info: iteration 16, average log likelihood -1.384106
[ Info: iteration 17, average log likelihood -1.384079
[ Info: iteration 18, average log likelihood -1.384061
[ Info: iteration 19, average log likelihood -1.384049
[ Info: iteration 20, average log likelihood -1.384041
[ Info: iteration 21, average log likelihood -1.384036
[ Info: iteration 22, average log likelihood -1.384032
[ Info: iteration 23, average log likelihood -1.384030
[ Info: iteration 24, average log likelihood -1.384028
[ Info: iteration 25, average log likelihood -1.384027
[ Info: iteration 26, average log likelihood -1.384026
[ Info: iteration 27, average log likelihood -1.384025
[ Info: iteration 28, average log likelihood -1.384025
[ Info: iteration 29, average log likelihood -1.384025
[ Info: iteration 30, average log likelihood -1.384025
[ Info: iteration 31, average log likelihood -1.384025
[ Info: iteration 32, average log likelihood -1.384024
[ Info: iteration 33, average log likelihood -1.384024
[ Info: iteration 34, average log likelihood -1.384024
[ Info: iteration 35, average log likelihood -1.384024
[ Info: iteration 36, average log likelihood -1.384024
[ Info: iteration 37, average log likelihood -1.384024
[ Info: iteration 38, average log likelihood -1.384024
[ Info: iteration 39, average log likelihood -1.384024
[ Info: iteration 40, average log likelihood -1.384024
[ Info: iteration 41, average log likelihood -1.384024
[ Info: iteration 42, average log likelihood -1.384024
[ Info: iteration 43, average log likelihood -1.384024
[ Info: iteration 44, average log likelihood -1.384024
[ Info: iteration 45, average log likelihood -1.384024
[ Info: iteration 46, average log likelihood -1.384024
[ Info: iteration 47, average log likelihood -1.384024
[ Info: iteration 48, average log likelihood -1.384024
[ Info: iteration 49, average log likelihood -1.384024
[ Info: iteration 50, average log likelihood -1.384024
┌ Info: EM with 100000 data points 50 iterations avll -1.384024
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4263838037456527
│     -1.4262958111267543
│      ⋮
└     -1.3840242514085286
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.384169
[ Info: iteration 2, average log likelihood -1.384052
[ Info: iteration 3, average log likelihood -1.383828
[ Info: iteration 4, average log likelihood -1.381352
[ Info: iteration 5, average log likelihood -1.370076
[ Info: iteration 6, average log likelihood -1.357800
[ Info: iteration 7, average log likelihood -1.353183
[ Info: iteration 8, average log likelihood -1.351415
[ Info: iteration 9, average log likelihood -1.350456
[ Info: iteration 10, average log likelihood -1.349889
[ Info: iteration 11, average log likelihood -1.349469
[ Info: iteration 12, average log likelihood -1.349088
[ Info: iteration 13, average log likelihood -1.348719
[ Info: iteration 14, average log likelihood -1.348398
[ Info: iteration 15, average log likelihood -1.348146
[ Info: iteration 16, average log likelihood -1.347947
[ Info: iteration 17, average log likelihood -1.347787
[ Info: iteration 18, average log likelihood -1.347653
[ Info: iteration 19, average log likelihood -1.347537
[ Info: iteration 20, average log likelihood -1.347433
[ Info: iteration 21, average log likelihood -1.347338
[ Info: iteration 22, average log likelihood -1.347251
[ Info: iteration 23, average log likelihood -1.347172
[ Info: iteration 24, average log likelihood -1.347098
[ Info: iteration 25, average log likelihood -1.347029
[ Info: iteration 26, average log likelihood -1.346967
[ Info: iteration 27, average log likelihood -1.346911
[ Info: iteration 28, average log likelihood -1.346863
[ Info: iteration 29, average log likelihood -1.346822
[ Info: iteration 30, average log likelihood -1.346789
[ Info: iteration 31, average log likelihood -1.346762
[ Info: iteration 32, average log likelihood -1.346740
[ Info: iteration 33, average log likelihood -1.346722
[ Info: iteration 34, average log likelihood -1.346708
[ Info: iteration 35, average log likelihood -1.346697
[ Info: iteration 36, average log likelihood -1.346687
[ Info: iteration 37, average log likelihood -1.346679
[ Info: iteration 38, average log likelihood -1.346673
[ Info: iteration 39, average log likelihood -1.346667
[ Info: iteration 40, average log likelihood -1.346663
[ Info: iteration 41, average log likelihood -1.346658
[ Info: iteration 42, average log likelihood -1.346655
[ Info: iteration 43, average log likelihood -1.346651
[ Info: iteration 44, average log likelihood -1.346648
[ Info: iteration 45, average log likelihood -1.346645
[ Info: iteration 46, average log likelihood -1.346642
[ Info: iteration 47, average log likelihood -1.346639
[ Info: iteration 48, average log likelihood -1.346636
[ Info: iteration 49, average log likelihood -1.346634
[ Info: iteration 50, average log likelihood -1.346631
┌ Info: EM with 100000 data points 50 iterations avll -1.346631
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.384169265264766
│     -1.38405240753666
│      ⋮
└     -1.3466312584066202
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.346850
[ Info: iteration 2, average log likelihood -1.346648
[ Info: iteration 3, average log likelihood -1.346095
[ Info: iteration 4, average log likelihood -1.340794
[ Info: iteration 5, average log likelihood -1.322472
[ Info: iteration 6, average log likelihood -1.308321
[ Info: iteration 7, average log likelihood -1.303046
[ Info: iteration 8, average log likelihood -1.300259
[ Info: iteration 9, average log likelihood -1.298506
[ Info: iteration 10, average log likelihood -1.297345
[ Info: iteration 11, average log likelihood -1.296472
[ Info: iteration 12, average log likelihood -1.295758
[ Info: iteration 13, average log likelihood -1.295132
[ Info: iteration 14, average log likelihood -1.294513
[ Info: iteration 15, average log likelihood -1.293839
[ Info: iteration 16, average log likelihood -1.293088
[ Info: iteration 17, average log likelihood -1.292304
[ Info: iteration 18, average log likelihood -1.291622
[ Info: iteration 19, average log likelihood -1.291087
[ Info: iteration 20, average log likelihood -1.290611
[ Info: iteration 21, average log likelihood -1.290247
[ Info: iteration 22, average log likelihood -1.290034
[ Info: iteration 23, average log likelihood -1.289924
[ Info: iteration 24, average log likelihood -1.289870
[ Info: iteration 25, average log likelihood -1.289846
[ Info: iteration 26, average log likelihood -1.289836
[ Info: iteration 27, average log likelihood -1.289830
[ Info: iteration 28, average log likelihood -1.289826
[ Info: iteration 29, average log likelihood -1.289822
[ Info: iteration 30, average log likelihood -1.289819
[ Info: iteration 31, average log likelihood -1.289816
[ Info: iteration 32, average log likelihood -1.289813
[ Info: iteration 33, average log likelihood -1.289811
[ Info: iteration 34, average log likelihood -1.289809
[ Info: iteration 35, average log likelihood -1.289807
[ Info: iteration 36, average log likelihood -1.289805
[ Info: iteration 37, average log likelihood -1.289803
[ Info: iteration 38, average log likelihood -1.289802
[ Info: iteration 39, average log likelihood -1.289800
[ Info: iteration 40, average log likelihood -1.289799
[ Info: iteration 41, average log likelihood -1.289797
[ Info: iteration 42, average log likelihood -1.289796
[ Info: iteration 43, average log likelihood -1.289795
[ Info: iteration 44, average log likelihood -1.289794
[ Info: iteration 45, average log likelihood -1.289792
[ Info: iteration 46, average log likelihood -1.289791
[ Info: iteration 47, average log likelihood -1.289790
[ Info: iteration 48, average log likelihood -1.289788
[ Info: iteration 49, average log likelihood -1.289786
[ Info: iteration 50, average log likelihood -1.289785
┌ Info: EM with 100000 data points 50 iterations avll -1.289785
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3468504032714186
│     -1.3466483841605825
│      ⋮
└     -1.2897847076351658
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.290072
[ Info: iteration 2, average log likelihood -1.289764
[ Info: iteration 3, average log likelihood -1.288526
[ Info: iteration 4, average log likelihood -1.274959
[ Info: iteration 5, average log likelihood -1.242580
[ Info: iteration 6, average log likelihood -1.220417
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.205102
[ Info: iteration 8, average log likelihood -1.224064
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.210470
[ Info: iteration 10, average log likelihood -1.213381
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.202231
[ Info: iteration 12, average log likelihood -1.218725
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.207695
[ Info: iteration 14, average log likelihood -1.210018
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.198072
[ Info: iteration 16, average log likelihood -1.212021
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.200231
[ Info: iteration 18, average log likelihood -1.215299
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.200773
[ Info: iteration 20, average log likelihood -1.214895
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.202953
[ Info: iteration 22, average log likelihood -1.202291
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.189945
[ Info: iteration 24, average log likelihood -1.215974
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.202096
[ Info: iteration 26, average log likelihood -1.202233
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     4
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.190887
[ Info: iteration 28, average log likelihood -1.213514
[ Info: iteration 29, average log likelihood -1.204872
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.195451
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.205061
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.202835
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.199879
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.205766
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.198230
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.197736
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.205045
[ Info: iteration 38, average log likelihood -1.212344
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.198860
[ Info: iteration 40, average log likelihood -1.209376
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.196384
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.193286
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.208933
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.209823
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.205334
[ Info: iteration 46, average log likelihood -1.210995
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.203911
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.208187
[ Info: iteration 49, average log likelihood -1.204137
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.191598
┌ Info: EM with 100000 data points 50 iterations avll -1.191598
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2900715790709967
│     -1.2897643745077638
│      ⋮
└     -1.1915977977194365
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.199411
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.196829
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.190452
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.180620
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     12
│     13
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.139698
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│      8
│     15
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.144213
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.132748
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     14
│     15
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.116217
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      8
│     21
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.120664
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     12
│     13
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.132845
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     11
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.125381
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      8
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.104962
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.147107
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.124249
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│     13
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.102743
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.147523
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     12
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.119371
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.097787
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     12
│     13
│     16
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.128577
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     14
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.139002
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.113077
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     14
│     15
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.135184
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.136032
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.105325
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.139283
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     12
│     13
│     14
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.114167
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.126374
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     12
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.138451
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     13
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.123150
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.109404
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     14
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.144248
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     12
│     13
│     15
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.109414
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.126547
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     12
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.143144
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     13
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.118102
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.107439
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     13
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.147567
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.130795
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.097741
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.153903
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.133669
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.093381
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.153561
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     12
│     14
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.128028
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.116428
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     12
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.141161
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.120976
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.117222
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     13
│     15
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.138136
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     14
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.133551
┌ Info: EM with 100000 data points 50 iterations avll -1.133551
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1994114844017143
│     -1.1968288946314665
│      ⋮
└     -1.13355109636478
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4262894925914429
│     -1.4263838037456527
│     -1.4262958111267543
│     -1.4255788231469864
│      ⋮
│     -1.117222382447099
│     -1.1381356418857773
└     -1.13355109636478
32×26 Array{Float64,2}:
  0.07601      0.00161644  -0.0966279   -0.00715601    0.0911086    0.0143406   -0.0324303    0.0677177    -0.0200345   -0.0806617   -0.0456969   -0.104979    -0.0633477   0.0411165    0.108871    -0.125063     -0.0729368   -0.0296057     0.0751909   -0.118148     0.00843855    0.0911054     0.0480357  -0.0479802    0.0624073   -0.0375182
  0.174047    -0.010809    -0.293552    -0.0378481     0.125453    -0.0524653    0.0668019   -0.0646928     0.0902979   -0.0014754   -0.0058747    0.0270337   -0.0706995   0.039402     0.105372    -0.0802981     0.10855      0.0525007     0.0687306    0.037736     0.000439895   0.0148695    -0.0269636   0.0264153    0.0141756    0.0745568
  0.0194346   -0.154367     0.0673725   -0.0914335    -0.0828747   -0.0876877   -0.0531977   -0.0490258    -0.0485215    0.180524     0.054779    -0.0446192    0.069305   -0.0918704    0.217637     0.0897526     0.00254245   0.0675789     0.112927    -0.214551     0.026955     -0.0989817    -0.0537675   0.0644843   -0.0643515    0.182897
 -0.0258988    0.169922     0.039201     0.0848929     0.0603136   -0.0839164    0.0747183    0.0732965     0.113735    -0.0216528    0.0672301   -0.0129761   -0.0116202  -0.13391     -0.0246809    0.000482709  -0.131834     0.162225     -0.0242908   -0.0335069   -0.0249371    -0.00837487    0.053444    0.0591185   -0.0902851   -0.123964
  0.169841     0.226222    -0.0721527    0.0431748     0.0450439   -0.00653318  -0.00724653  -1.18008       0.0279907    0.290924     0.0593271   -0.158795     0.0843123   0.06777      0.0453024    0.0166853    -0.0250233    0.0348556    -0.0321474   -0.0258128   -0.108163      0.154092      0.0348486  -0.0486164    0.0130375   -0.117311
  0.17578     -0.0638118   -0.0650877    0.0564702     0.0478934   -0.0432353   -0.189832     1.20459       0.0173029    0.248835     0.0401417    0.0814407    0.287343   -0.144559    -0.115246     0.0430561    -0.0977909   -0.0915621    -0.00300033  -0.0323423   -0.12298       0.162588      0.0262113  -0.0419237    0.0351731   -0.287982
  0.0577186   -0.304402     0.107828    -0.126184     -0.018513    -0.0980809   -0.0430409   -0.0059138     0.0192412    0.10476     -0.0399783    0.0296624    0.142038   -0.0695459    0.00579767  -0.107551     -0.0545927    0.199131     -0.0663972   -0.156627    -0.117148     -0.215943     -0.140452    0.0602946    0.0829391   -0.0051315
  0.0578164    0.589289     0.184942    -0.12621       0.0809263    0.0210514   -0.0317356    0.312319     -0.171093     0.157043    -0.039963     0.199852     0.0561336   0.0262625    0.0360897   -0.00917443    0.300995     0.221666      0.126184    -0.162692    -0.0166307    -0.176156     -0.140343    0.032589     0.167465    -0.00405045
 -0.0412052    0.0512904   -0.00377829   0.0180236    -0.079931    -0.0312886   -0.0927526    0.0956467    -0.0529882    0.0709249   -0.0740309   -0.0301358    0.107635   -0.209728     0.105603     0.0892372    -0.0498319   -0.150139      0.0424159   -0.0257026   -0.0249032     0.0158909    -0.0502692  -0.0654309   -0.00171557   0.0426115
 -0.00678469  -0.15327     -0.114113     0.0632156    -0.0159858    0.171781    -0.0918672   -0.0597442    -0.0145594    0.0263257   -0.00561908  -0.0146241    0.033747   -0.0283278   -0.0536076    0.050734      0.0103996    0.000830436   0.031718     0.0767112   -0.108372      0.0573128     0.108509    0.13394     -0.0090664    0.0136965
  0.0221334    0.0325472    0.0352794    0.157595      0.0404665    0.162625    -0.0760415   -0.081112      0.0646995    0.00800312   0.00354574   0.151565    -0.0903954   0.0500174   -0.063757     0.098217     -0.0874264   -0.0108503    -0.0224301   -0.204974    -0.0993928     0.000565674  -0.169515   -0.0520982   -0.0374764    0.247246
 -0.0748967    0.0349453   -0.105532     0.140762     -0.0217952   -0.0463709   -0.143405     0.0704378    -0.0559313   -0.0871477    0.0372175    0.106304    -0.0886278   0.0676648    0.0634215   -0.0141975    -0.0850354   -0.158197      0.0191557   -0.11657      0.13546       0.112246     -0.0269933   0.0412207   -0.154116    -0.167374
 -0.0372933   -0.0340371   -0.012341     0.000635613   0.0152162    0.156206     0.0600184    0.000510051   0.286492    -0.126018     0.0312763   -0.266976     0.259562   -0.0441126    0.0631691    0.00168488   -0.0738788    0.167797     -0.0416662    0.0640594   -0.0942195    -0.126898      0.0525449  -0.174183     0.177966    -0.101463
 -0.130231    -0.10546      0.00421751  -0.146012      0.00168538  -0.0120069    0.0670685    0.0103541    -0.110795     0.0934373    0.129691     0.0758331    0.0493747   0.00859326   0.123923    -0.0438542     0.221613    -0.0438635     0.0148113    0.0456481   -0.0230292     0.053325     -0.0715822   0.1693      -0.081194    -0.19212
 -0.124765    -0.027939     0.124765    -0.0630585    -0.106462    -0.0178971    0.00292898  -0.100696     -0.0164494    0.249836    -0.044669     0.0715763    0.153166    0.120264    -0.00690514   0.132666      0.0117682   -0.108724     -0.110444     0.228162    -0.0292055    -0.212149     -0.0253125   0.0862044    0.158302    -0.126177
 -0.115574    -0.0622711    0.0109261   -0.0932967    -0.0125945    0.0491735    0.0739594    0.00371677   -0.152996     0.00378284   0.142303     0.0735251    0.0491834   0.0273196    0.0943138   -0.0463154     0.207005     0.00240513    0.0116287    0.0828699   -0.0325634     0.0452209    -0.015054    0.129012    -0.0726795   -0.129887
  0.0550282   -0.18484      0.118635    -1.35164      -0.129302    -0.0430585   -0.136882    -0.054007     -0.0265237   -0.199062    -0.105017     0.0242376   -0.060033    0.0831182   -0.0346645   -0.0685751     0.0728277   -0.0420225     0.191448    -0.0657589   -0.106285     -0.097591     -0.053327    0.140874     0.00574105  -0.0660728
  0.092688    -0.146572     0.119308     0.953003     -0.26597     -0.0441981   -0.158982    -0.0468896     0.00833002  -0.298714     0.0343522    0.00165708  -0.0798042   0.109668    -0.0914505   -0.0484294     0.0428919   -0.0618416     0.0844447    0.0311903   -0.188197     -0.168533     -0.0643372   0.0911354    0.024379    -0.0915637
 -0.172356     0.0477534    0.0112111    0.19533       0.107669     0.00451489  -0.384085     0.115241     -0.0703444   -0.0837628    0.0281285   -0.0217733    0.0361788  -0.0405397    0.0117353    0.0581674     0.130492     0.135201      0.221385     0.0485183    0.133523     -0.0917774     0.223279    0.021511    -0.178034     0.0637915
  0.170509     0.103373     0.123458     0.0439901     0.281977    -0.0865316    0.30527      0.118061      0.0165842   -0.081058    -0.0213279    0.066769     0.0320183  -0.0320122   -0.15108     -0.152981     -0.00210085   0.143484      0.136665    -0.0164381    0.19018      -0.0668555     0.16275     0.00887229  -0.186222     0.0136124
  0.0632734   -0.0111793    0.059926     0.0346409    -0.0262372   -0.0196923    0.149962    -0.0156066     0.0144539   -0.0775194   -0.161482     0.0014088   -0.0576259   0.081003    -0.0472001   -0.0599523    -0.0457397   -0.0609792    -0.0493458   -0.115596     0.0660818    -0.0902906     0.051706    0.0679443   -0.0568821    0.129786
 -0.00447127  -0.0487779   -0.0575171   -0.0197438    -0.0336142    0.0509501    0.0388112   -0.0144194     0.0441286   -0.182262    -0.0274156    0.0542757   -0.0315327   0.0598352    0.0176579   -0.0337957    -0.0283952    0.00981521   -0.032788    -0.0869764    0.0598008     0.00968635    0.0748789   0.039131     0.0390047   -0.110114
 -0.037934    -0.109684    -0.0126615   -0.0692733    -0.00698568   0.0806535   -0.0706893    0.0981183    -0.0658921   -0.108543     0.0124437    0.0509942    0.0445019   0.0509849    0.0353068   -0.050046      0.0627839   -0.0165856    -0.0295414   -0.0527128    0.023771      0.039727      0.0286622  -0.0217325   -0.0188155    0.0204868
 -0.0889425    0.0120245   -0.0120317   -0.0360716     0.0049758   -0.049959    -0.147957    -0.0598191     0.0742886   -0.0336514    0.0852354    0.0493818    0.0890433  -0.0101973   -0.00602248  -0.0366145     0.0604435   -0.0554168     0.00697366   0.0111102    0.0126034     0.120999      0.0434104   0.0813648    0.0264483   -0.00554245
  0.0227907   -0.0165705    0.220528    -0.167596     -0.199648     0.369453    -0.0569213   -0.0115155    -0.0267093   -0.38443     -0.0427285   -0.00578773  -0.0639941   0.0468432   -0.0729204   -0.17326       0.109507    -0.0608199     0.174995     0.190446     0.168082      0.123243      0.0241045  -0.149032    -0.00350744   0.0168342
  0.0352321    0.0430741    0.049363     0.0179938    -0.20548     -0.193829     0.0403601    0.199174     -0.0236554    0.614034     0.263657    -0.0914499   -0.119031    0.0484062   -0.0225125   -0.0502261     0.0448485   -0.0619239     0.130707    -0.0829401    0.0971952     0.126986      0.0230606  -0.291124    -0.00367508   0.21612
  0.0919307   -0.0221147   -0.157758     0.0597267     0.0774783    0.124474    -0.0430081   -0.0566911     0.00683101  -0.0804664    0.0957951    0.248483    -0.0519599  -0.0386119    0.0936985   -0.117862      0.135891     0.256719      0.00696286  -0.0043573   -0.0351488    -0.129224     -0.134277   -0.0678126   -0.103667     0.0351222
  0.0393769    0.0134719    0.0312165    0.199707      0.112499     0.0703683   -0.100078     0.177264      0.0340272   -0.0241204    0.0632042    0.0243339    0.117753   -0.0471565    0.0310786    0.0568317     0.0745861   -0.174887      0.0824966   -0.00865054   0.0222339     0.0911427     0.243339    0.0228917   -0.137602     0.191752
  0.0524957   -0.0584285    0.279276    -0.041323      0.0607601    0.0389477   -0.2053       0.223751     -0.0400757    0.168392    -0.12537      0.117032    -0.0907144  -0.0581609    0.0149864   -0.00355338    0.0388417    0.247902     -0.034731    -0.879154     0.170911      0.17515      -0.0096836  -0.0192647    0.360787     0.186509
 -0.186633    -0.0734554   -0.00646822  -0.375042      0.0522193    0.185387    -0.085743     0.0903822     0.0147635    0.188125     0.156533     0.0143888   -0.0539708  -0.0445836   -0.0434933   -0.135511     -0.0217554    0.097186      0.140271     0.325533     0.0700287     0.208007      0.0217078   0.229331     0.0955678    0.211185
 -0.328559    -0.0627945   -0.0371292   -0.18619       0.0206038    0.0808246   -0.0926744    0.359435     -0.103953     0.0329922    0.510214     0.138146    -0.345873    0.0267035    0.0969314   -0.141012     -0.0476461    0.243334     -0.0298709   -0.048957     0.0890673     0.138353     -0.18863     0.128362    -0.15727      0.131964
  0.0816751   -0.0689756   -0.0300368    0.153552      0.083436    -0.0357929   -0.250661    -0.263736     -0.119221     0.191609     0.0328009    0.0766087    0.0420206  -0.0203075    0.0834556    0.0822373    -0.0952755    0.222572     -0.0694396    0.860715     0.144863      0.188733      0.014186    0.0780809    0.0441871   -0.0904128[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.108135
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.087021
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.107532
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.086997
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.107505
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.086943
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.107137
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.081693
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.109457
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.087839
┌ Info: EM with 100000 data points 10 iterations avll -1.087839
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.217396e+05
      1       6.913968e+05      -2.303429e+05 |       32
      2       6.620125e+05      -2.938427e+04 |       32
      3       6.452052e+05      -1.680735e+04 |       32
      4       6.352536e+05      -9.951605e+03 |       32
      5       6.309266e+05      -4.326967e+03 |       32
      6       6.289745e+05      -1.952126e+03 |       32
      7       6.277251e+05      -1.249326e+03 |       32
      8       6.266655e+05      -1.059658e+03 |       32
      9       6.255978e+05      -1.067628e+03 |       32
     10       6.245613e+05      -1.036572e+03 |       32
     11       6.237474e+05      -8.138865e+02 |       32
     12       6.232007e+05      -5.467318e+02 |       32
     13       6.227651e+05      -4.355714e+02 |       32
     14       6.222983e+05      -4.667646e+02 |       31
     15       6.215666e+05      -7.316898e+02 |       32
     16       6.208487e+05      -7.178847e+02 |       32
     17       6.202166e+05      -6.321215e+02 |       32
     18       6.197249e+05      -4.917581e+02 |       32
     19       6.195031e+05      -2.217636e+02 |       32
     20       6.194172e+05      -8.594526e+01 |       31
     21       6.193797e+05      -3.745866e+01 |       32
     22       6.193623e+05      -1.738922e+01 |       31
     23       6.193522e+05      -1.008817e+01 |       30
     24       6.193439e+05      -8.347464e+00 |       30
     25       6.193371e+05      -6.732648e+00 |       28
     26       6.193312e+05      -5.936059e+00 |       27
     27       6.193250e+05      -6.214773e+00 |       26
     28       6.193210e+05      -3.982985e+00 |       24
     29       6.193182e+05      -2.827268e+00 |       19
     30       6.193166e+05      -1.619057e+00 |       17
     31       6.193151e+05      -1.466199e+00 |       17
     32       6.193140e+05      -1.112216e+00 |       12
     33       6.193135e+05      -5.155354e-01 |        5
     34       6.193134e+05      -1.120790e-01 |        7
     35       6.193132e+05      -2.047741e-01 |        7
     36       6.193128e+05      -3.183740e-01 |        8
     37       6.193127e+05      -1.418353e-01 |        5
     38       6.193126e+05      -1.116665e-01 |        2
     39       6.193126e+05      -1.425674e-02 |        2
     40       6.193125e+05      -2.878567e-02 |        2
     41       6.193125e+05      -4.334633e-02 |        3
     42       6.193124e+05      -6.556182e-02 |        5
     43       6.193122e+05      -2.528678e-01 |       11
     44       6.193114e+05      -8.086862e-01 |       15
     45       6.193099e+05      -1.417707e+00 |       16
     46       6.193079e+05      -2.011390e+00 |       17
     47       6.193058e+05      -2.146105e+00 |       11
     48       6.193047e+05      -1.106742e+00 |       12
     49       6.193039e+05      -7.535040e-01 |       13
     50       6.193031e+05      -8.104859e-01 |       15
K-means terminated without convergence after 50 iterations (objv = 619303.1201557633)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.336753
[ Info: iteration 2, average log likelihood -1.306662
[ Info: iteration 3, average log likelihood -1.276784
[ Info: iteration 4, average log likelihood -1.235616
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.184951
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     2
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.138919
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.141584
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.107223
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.086935
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│     14
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.082637
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.131178
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     23
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.095168
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.118225
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      8
│     13
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.091671
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     10
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.115297
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.107322
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.100390
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     10
│     13
│     14
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.083294
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.118659
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      4
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.104501
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.100904
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      8
│     13
│     16
│     22
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.072242
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.133517
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     10
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.083100
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      6
│     13
│     23
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.077255
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.141026
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     16
│     22
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.087890
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.103329
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      6
│     13
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.087158
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.136066
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.101063
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.098505
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      4
│      8
│     13
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.075270
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.146931
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     16
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.108102
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.095439
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      8
│     13
│     22
│     23
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.073544
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.152751
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     10
│     16
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.086296
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.118592
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      8
│     13
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.078991
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.130827
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     10
│     16
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.091423
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.109307
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      8
│     13
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.073119
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.128922
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.106290
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     18
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.065644
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      4
│      8
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.060127
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.164362
┌ Info: EM with 100000 data points 50 iterations avll -1.164362
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0479467    0.00278054   0.111905     -0.0474795    -0.135308      0.127701    -0.00794158   0.114672    -0.0243079     0.124062      0.0992052    -0.0533251  -0.069321    0.0282013   -0.0283702   -0.12199      0.0652366   -0.0630204    0.153474     0.0506944    0.12053       0.124804     0.0379987    -0.202411    -0.0148788   0.101353
 -0.0418006    0.0217643    0.00686314    0.117899      0.107813      0.0577096   -0.00339615   0.108131     0.0196195    -9.17649e-5    0.0860008     0.0119875   0.175335   -0.0336953    0.0548854    0.0695826    0.118697    -0.197711     0.0428684    0.0172144   -0.0105716     0.0852663    0.161981      0.0513658   -0.0859313   0.0660538
 -0.00171249  -0.0237743   -0.0963496     0.0326589    -0.122963      0.168237     0.0371522   -0.120199     0.034418     -0.163039     -0.0269137     0.0408751  -0.0482433   0.18652     -0.013734     0.00483719   0.0244038   -0.0620165    0.00413762  -0.235241     0.0456721    -0.0989053   -0.000187915  -0.0292649    0.0515787  -0.0457182
 -0.111843    -0.13341      0.00271822   -0.192789     -0.0334357     0.00234363   0.0414937    0.0102764   -0.127326      0.0800142     0.145354      0.0455266   0.0248958  -0.00507032   0.129499    -0.0398709    0.224262    -0.00238105   0.00143419   0.111893    -0.0349354     0.0590702   -0.0866457     0.258962    -0.0665973  -0.245177
  0.073173    -0.163934     0.11959      -0.180035     -0.198387     -0.0433269   -0.146857    -0.0496499   -0.0087222    -0.248373     -0.032354      0.0128456  -0.0702547   0.0958833   -0.0623102   -0.0581299    0.0574352   -0.0529657    0.137088    -0.0159616   -0.150333     -0.132743    -0.0585804     0.114415     0.0141472  -0.0808913
  0.0179108   -0.332045     0.0584336    -0.0524129     0.00401005    0.118228    -0.0150967    0.140251     0.0630255     0.0312665    -0.0788691    -0.0491639   0.265448   -0.144771     0.0225752   -0.109794     0.108234    -0.0492363   -0.0599941    0.0715255   -0.168944     -0.052881    -0.0445545     0.164521     0.0949584   0.0491303
 -0.00505212  -0.0723682   -0.0212068     0.0273953     0.0434514     0.0672873   -0.086965     0.0341181   -0.0546841    -0.0936532     0.0450607     0.0655006  -0.0229881   0.0350495    0.0768593   -0.00640576   0.0390669    0.0504327    0.0508473   -0.0879885    0.113798     -0.0205367    0.0768621    -0.0708011   -0.0188004   0.092686
 -0.107661    -0.0368119    0.143699     -0.0928175    -0.132101     -0.0386451    0.0145481   -0.0902256   -0.0122497     0.257816      0.00232955    0.0536424   0.135336    0.130936    -0.00990339   0.106419     0.0250463   -0.131849    -0.0740136    0.330767    -0.0333415    -0.173812    -0.0482267     0.164123     0.138448   -0.0967315
  0.169428     0.0800206   -0.0632993     0.0448369     0.0466894    -0.0378149   -0.0984719    0.06291      0.0224646     0.265507      0.0449837    -0.0308558   0.186673   -0.0450229   -0.0343062    0.0322126   -0.0744683   -0.0251834   -0.018629    -0.0323673   -0.115701      0.15887      0.0258099    -0.0453446    0.0284702  -0.202176
  0.100145    -0.0223595   -0.152395      0.0767374     0.081404      0.125821    -0.0375595   -0.0627351    0.0115699    -0.07943       0.096883      0.246226   -0.0563843  -0.044001     0.100564    -0.122485     0.137576     0.263974     0.00694263  -0.00463683  -0.0335849    -0.136772    -0.143975     -0.0701531   -0.0946158   0.0330623
 -0.0154365   -0.106328    -0.0512863    -0.0268169    -0.000531662  -0.0157906   -0.194001     0.0308094    0.108343      0.089408      0.106129      0.0710258   0.144932   -0.0343702    0.115281    -0.0325796    0.0805314   -0.0921722    0.0830683    0.144208     0.120674      0.111372     0.0869649     0.242532    -0.0120261  -0.0838278
 -0.0202106   -0.132188    -0.0260968    -0.154532     -0.0434391     0.131223     0.00791521   0.162296    -0.180237     -0.170207      0.015092      0.101714    0.107805    0.163763     0.025312     0.0183356    0.121494    -0.0190945   -0.034673    -0.163855     0.00436703    0.0629301    0.0260643    -0.0968494   -0.146003   -0.0449829
 -0.0648333    0.0292068   -0.0690581     0.137229     -0.0244244    -0.0272817   -0.121087     0.052343    -0.0483129    -0.0508613     0.0348846     0.08398    -0.0711492   0.0665743    0.0684771   -0.011149    -0.105149    -0.134811     0.0167701   -0.124821     0.128048      0.0925616   -0.0440028     0.0498612   -0.128547   -0.115853
  0.0584558    0.0681721    0.101387      0.0922767    -0.0763286     0.0214159    0.145288    -0.00526793   0.00334546   -0.0399663    -0.148548     -0.0249955  -0.0445144   0.0685535   -0.0146161   -0.0417226   -0.0490119   -0.0697912   -0.0170759   -0.154921     0.0745213    -0.135215     0.0497797     0.050061    -0.0261325   0.158076
 -0.00568713   0.0125387    0.0581445     0.00124269   -0.00897313   -0.0980784    0.0149892    0.00506745   0.0379178     0.0761457     0.0560964    -0.0300127   0.0257443  -0.114556     0.0952716    0.0436686   -0.0674185    0.11731      0.0421955   -0.117155    -0.00184908   -0.0492474    0.00217415    0.0609438   -0.0785138   0.0237481
 -0.0011602   -0.0728805   -0.0189172    -0.0809622     0.0722786    -0.0647998    0.0416139    0.0838205    0.060268     -0.195704     -0.0247546     0.09171    -0.0176249  -0.0663814    0.054344    -0.0786038   -0.084781     0.0846032   -0.0668574    0.0755237    0.0717794     0.136933     0.152375      0.132655     0.0248338  -0.175134
 -0.101421    -0.120253    -0.160414      0.00218082    0.047188      0.287473    -0.204341    -0.12238     -0.0969621    -0.0557893    -0.0250155    -0.0877666  -0.0281569  -0.0281564   -0.045365    -0.0259437   -0.00693995  -0.00674137   0.0692079    0.196892    -0.0978844     0.142193     0.233167      0.115535     0.0540053  -0.00826213
  0.0669334   -0.170512    -0.0631042     0.127743     -0.0504749     0.0695315    0.0245681   -0.02377      0.0468162     0.0922419     0.0127269     0.0415852   0.0777492  -0.02143     -0.0798281    0.11123      0.0248603    0.0558885   -0.00950198  -0.0461351   -0.141467     -0.0643068   -0.0256122     0.13732     -0.0641351   0.0466606
 -0.0501143    0.0396086   -0.111589     -0.0391259     0.0776481    -0.0115638   -0.0793056    0.0742208   -0.0238614    -0.0654094    -0.0747694    -0.0377864  -0.104154    0.0231992   -0.0152574   -0.126179    -0.00301342  -0.0520628    0.0137511   -0.0487685    0.0431073     0.0651341    0.0608696     0.00444193   0.0424134  -0.00112508
 -0.0274959    0.0928607   -0.0579596    -0.0897459    -0.108585     -0.0300375   -0.208006    -0.0183646    0.151925     -0.112596      0.112959     -0.0115984  -0.0286667   0.00958802  -0.0514271   -0.0510594    0.00476791  -0.0357698   -0.0364464   -0.086651    -0.063883      0.142545     0.0952053     0.0734806   -0.0148594   0.038306
 -0.0335387    0.0848548   -0.0919813     0.0384344    -0.144321     -0.105751    -0.053572     0.151345     0.0193377    -0.0629407    -0.015815      0.141194    0.0547969  -0.209548     0.156612     0.198056    -0.0515076   -0.168991     0.0548978   -0.084231    -0.0277689     0.14367     -0.0420276     0.0208844    0.010089    0.0357957
  0.00368655   0.0420082    0.0470479     0.166998      0.0288126     0.159509    -0.0692644   -0.0610807    0.0625243     0.0196444    -0.000478906   0.131272   -0.120902    0.0541895   -0.0568374    0.106561    -0.0935501   -0.0263273   -0.0423365   -0.259865    -0.122179     -0.00257159  -0.186195     -0.138556    -0.0386038   0.18908
 -0.0395039    0.030565     0.0473537     0.00230538   -0.00406355    0.0664651   -0.0857642    0.0163749   -0.241866      0.190746     -0.0948033    -0.197636    0.168936   -0.236657     0.0579617   -0.0119439   -0.046403    -0.112342     0.0100588    0.0103986   -0.0157212    -0.156879    -0.04158      -0.260495     0.0171778   0.0375445
  0.173656    -0.00990553  -0.29085      -0.0383361     0.125394     -0.051396     0.0662945   -0.0650009    0.0889252    -0.000871399  -0.00267675    0.0266633  -0.068845    0.0367243    0.106429    -0.077675     0.109061     0.0523176    0.0683146    0.0379595    0.000176234   0.0109133   -0.0267552     0.0260124    0.0155391   0.074903
  0.0525043    0.195198     0.13779      -0.107773      0.0334994    -0.0728873   -0.038223     0.16206     -0.064643      0.123753     -0.0267563     0.0648508   0.0879572  -0.00936649   0.0683381   -0.0725574    0.0995869    0.263656     0.0404905   -0.170966    -0.0636127    -0.171377    -0.135939      0.0376073    0.132516   -0.0240484
 -0.204124     0.0577099    0.0594975    -0.0232364     0.0700982    -0.0981164   -0.0985043   -0.152873     0.000886708  -0.0772587     0.0589773     0.0946716   0.122622   -0.0240442   -0.0765375   -0.025571     0.0763827   -0.0226241   -0.0270134   -0.0211197   -0.0400665     0.1221      -0.0448543    -0.0765109    0.0810564   0.0275189
 -0.0353349   -0.0415499    0.000706507   0.000945914   0.0513915     0.147281     0.0106333    0.01943      0.376052     -0.132697     -0.00712138   -0.223198    0.30172     0.0241909    0.0747937   -0.0338983   -0.0282554    0.172492    -0.017008     0.0380887   -0.0950128    -0.0936915    0.0467553    -0.178347     0.126491   -0.0475657
  0.0735808   -0.206255    -0.0202464    -0.0954633     0.0812166    -0.163769     0.129651    -0.0462934    0.0271168    -0.180074     -0.156935      0.0826823  -0.0798758   0.126459    -0.126725    -0.101746    -0.0156241   -0.0297342   -0.117401    -0.0512453    0.0232159    -0.0389238    0.0375069     0.12938     -0.143298    0.0508446
  0.191773    -0.155304    -0.0643715     0.0468716     0.0982677     0.0977259   -0.00730493   0.10508     -0.00155479   -0.132695     -0.0471591    -0.173013    0.0285402  -0.0163892    0.314257    -0.131648    -0.0993853   -0.0653427    0.0898757   -0.183386    -0.0120195     0.137131     0.00570669   -0.0496585    0.0792531  -0.0107402
 -0.0993054   -0.06584      0.0602686    -0.124886      0.0504387     0.0722581   -0.151985     0.114164    -0.0572327     0.146261      0.142786      0.0786443  -0.103736   -0.0248651    0.0330352   -0.0571329   -0.0292137    0.191451     0.0128544    0.0457002    0.115945      0.177415    -0.0457395     0.0986606    0.093761    0.115109
  0.0846806   -0.0689477   -0.0243712     0.161138      0.073412      0.0476103   -0.0575062    0.0616449   -0.0276091    -0.0861047     0.0315123     0.0714135   0.0793096  -0.0480146    0.0490312   -0.00121441  -0.0567646   -0.1357       0.0285469   -0.0628668   -0.0340095     0.128062     0.378004      0.063283    -0.12717     0.00422397
  0.00607966   0.076271     0.0695896     0.1166        0.195539     -0.0420243   -0.0287495    0.118131    -0.0239519    -0.0820772     0.00285243    0.0240105   0.033892   -0.0365698   -0.0708846   -0.0511399    0.0631753    0.138213     0.17562      0.0147384    0.162476     -0.0774898    0.191271      0.013361    -0.182186    0.0400639[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.124571
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     13
│     16
│     18
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.063400
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      8
│     10
│     16
│     22
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.045997
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│     13
│     16
│      ⋮
│     25
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.047752
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.088702
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      4
│      8
│     10
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.016133
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.096494
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     13
│     16
│     18
│     25
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.045027
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      8
│     10
│     16
│     22
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.050795
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│     13
│     16
│     18
│     19
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.065185
┌ Info: EM with 100000 data points 10 iterations avll -1.065185
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0681594   -0.0463333    0.0896667   -0.11052     -0.0596471    0.0903941    0.0171843   0.239008      0.0592303   -0.208426     0.00598345   0.112264    -0.0747169    0.0774458   -0.124955      0.024551     -0.146267      0.0536821   -0.242376     -0.0323189   -0.0764932   0.051971     0.0150664    0.0796341     0.0447294   -0.0463439
  0.162809     0.0811407    0.0164126   -0.104792     0.0564103   -0.0921367   -0.0875498  -0.138222      0.145091    -0.0557449   -0.0943977   -0.103141     0.0767648   -0.119315    -0.0703232     0.127725      0.010163      0.0447447   -0.0524381    -0.050615     0.198749    0.167062    -0.2244      -0.112913     -0.100303     0.0454093
 -0.0169108   -0.067664    -0.209787    -0.0145008   -0.0432618   -0.0743392    0.0616533   0.0787867    -0.0116093    0.0316059    0.161858     0.037168     0.016565    -0.0170458   -0.0336263    -0.161836      0.104505      0.122393    -0.0697477     0.0230766   -0.220489   -0.0912574    0.0279033   -0.0327745    -0.16413     -0.0322366
 -0.0420453   -0.00450504  -0.0045048   -0.00618512   0.0257614    0.0659768   -0.130217    0.0587253    -0.0197706   -0.0278158    0.0935952    0.212029     0.00271528  -0.142769    -0.178627     -0.115632      0.102018      0.0846555    0.0166988     0.248446     0.113234    0.0409291   -0.141697     0.0360223     0.0785547    0.0236449
 -0.0374765    0.125846     0.218764    -0.156219    -0.091964     0.090544     0.0752404  -0.0132251     0.187736    -0.095829    -0.0893593   -0.249261     0.144277    -0.136069     0.0738672     0.120047     -0.0990825     0.156453     0.0389704     0.047071    -0.140381    0.0428634   -0.014273     0.0965809     0.0763447   -0.0540588
 -0.0665938    0.140615    -0.0890996    0.0719288   -0.0913314   -0.0161695   -0.016489    0.00632768   -0.0419321    0.0787226   -0.0376397    0.108536     0.00192156   0.280228     0.0302573    -0.0254181    -0.058125     -0.0612199    0.0640502    -0.287535     0.0785946   0.069781    -0.0379479    0.0907545    -0.127174    -0.0505673
 -0.0184995   -0.0285921   -0.0262034    0.0568846   -0.0750561    0.292829    -0.151805   -0.11472      -0.0260458   -0.0564431    0.102885     0.247353    -0.00131328   0.0768085    0.131872      0.000506902  -0.00248359    0.121295     0.00800717    0.0396437   -0.0106905  -0.0981466   -0.0610786    0.114383      0.12782      0.0226593
  0.133385     0.0117092   -0.165997    -0.0353579    0.0566942    0.138209    -0.0257233  -0.037317     -0.0263653    0.0124032   -0.0786009   -0.192379     0.0626178    0.0418732   -0.0211297    -0.027013      0.145598     -0.106378    -0.0154136     0.0370815   -0.0737881  -0.0242205   -0.0592307    0.0136942     0.157629    -0.100761
 -0.113059    -0.0610115    0.0103829   -0.227239    -0.0731161    0.00717339  -0.0801861   0.067361      0.0675439   -0.203277     0.164703    -0.124699     0.16409     -0.0255163    0.0576047     0.160772      0.0831815    -0.1247       0.117995      0.176491     0.0739632   0.0876105    0.0796645    0.104482     -0.0769682    0.0600612
 -0.0178267    0.0371898   -0.0518336    0.113746    -0.0451532    0.0381768   -0.0770053  -0.173545     -0.133581    -0.0451813    0.156615     0.00559552   0.162932     0.00147334  -0.0906349     0.1356        0.17231      -0.0212356    0.0800727    -0.158793     0.05679     0.0131243   -0.0487692   -0.109275     -0.090764     0.0343099
 -0.0167542    0.0850292   -0.142463    -0.0169709   -0.086089     0.0119996   -0.0185009   0.0862582     0.0974895   -0.0102572    0.00529618   0.0175938    0.271189     0.0478549   -0.0315437     0.00894847    0.0318413     0.0649205   -0.0333872     0.091961    -0.0441067  -0.248692    -0.0523223   -0.052804     -0.0826972    0.00292768
 -0.0962078   -0.0599519   -0.143943     0.123633    -0.186006     0.0286748    0.0133285  -0.0818153    -0.0559025   -0.00662581  -0.30354     -0.0862472    0.042071    -0.110274     0.073984     -0.0837536     0.195522     -0.0810309   -0.0754363    -0.143293    -0.0541551  -0.0131097   -0.104542     0.148827     -0.0774572   -0.0560767
  0.0110091    0.0804838    0.0906607   -0.00683296  -0.0687112    0.0802654   -0.0243306   0.0137816     0.121388     0.0138405   -0.0930729    0.04527     -0.0278159    0.0726651   -0.0323388    -0.0981908     0.0927428     0.0163353   -0.208525     -0.189753    -0.0151248   0.0255957    0.0402645    0.00392946   -0.0815748    0.0196731
 -0.0449447   -0.0556344    0.0230282   -0.10424      0.245559     0.163406     0.0281423  -0.0120883    -0.0675588   -0.0635553   -0.0779927   -0.206843    -0.0537206   -0.245528     0.122048      0.0202294     0.000550239  -0.0126155    0.116159     -0.0651858    0.0103102   0.0529927    0.0185177   -0.073502     -8.21868e-6  -0.132665
  0.160438     0.109856     0.0482356    0.0273985    0.18195      0.0941432    0.0773114   0.095702      0.00952951   0.0762957   -0.00584376  -0.0715688   -0.00372534  -0.0640512    0.119496     -0.0704387     0.222228      0.014009     0.000303866   0.1311       0.0377672  -0.103119    -0.0661119   -0.205966      0.0681966   -0.041085
 -0.206253     0.0978273   -0.133772     0.0528932    0.0648535    0.0456531    0.0452253  -0.0187362     0.175634     0.0665116    0.161167     0.163775     0.0269443    0.0085079    0.025798      0.0639265    -0.14773      -0.0232824   -0.0981176    -0.107286    -0.0256445   0.00416625  -0.00630892   0.151377     -0.232609     0.0277613
 -0.166589     0.157349    -0.0769892   -0.0793407   -0.114765    -0.0441716   -0.0810285   0.0454145     0.0422771   -0.189925     0.0270341   -0.130173     0.00877579   0.0416156    0.00858668    0.0209376     0.00863246    0.0879539   -0.0385843     0.142336    -0.0138534   0.21624     -0.0783848    0.0685331     0.0379856    0.0495017
  0.0972963   -0.0562733   -0.133812     0.12838     -0.119208     0.12658     -0.0950731   0.0221224     0.0321753   -0.0434894    0.0696627   -0.0270462    0.0761398   -0.162844     0.00651599    0.0704153     0.0173483     0.0433416   -0.0288648     0.0358258    0.138751   -0.128315     0.0706595    0.0803004     0.0369253   -0.102766
 -0.0221131   -0.182105     0.132289    -0.222969    -0.214074    -0.063683     0.103998   -0.0286443    -0.00896087   0.0919979    0.060337     0.0556137   -0.082979    -0.0869731    0.000748498   0.113728      0.201845      0.219959    -0.0927323     0.105123     0.157991   -0.106551    -0.0960954   -0.113011      0.0214854    0.000662364
 -0.0916113   -0.0399741   -0.00574073  -0.0336745   -0.0624324    0.144138    -0.137558    0.0307017     0.0321736   -0.0815663    0.0401757    0.0722968   -0.053748    -0.0832187   -0.141198      0.0243267     0.0812439     0.00165479   0.0542895     0.0197182   -0.0356065   0.194275     0.0538527   -0.184268      0.116676    -0.113837
  0.0827411    0.192212    -0.0618609   -0.034942    -0.246179     0.0592885    0.0329221   0.0551427     0.0317027   -0.0377903    0.135763    -0.0458327    0.12755     -0.0416273    0.0761538     0.106413     -0.00793153   -0.157406    -0.0271224    -0.0641795    0.0370265  -0.132309    -0.264233    -0.0992658     0.0468164    0.0775594
 -0.0574999    0.00441416   0.0493418   -0.0313879    0.00202182  -0.10123     -0.225267   -0.0989913    -0.0438389    0.196594     0.0870354    0.00401485   0.0296237    0.00397512   0.0108556    -0.183318      0.0158414     0.0717407    0.098519      0.0622414    0.0294028  -0.0633911   -0.0404557   -0.034887      0.0912339   -0.0064898
  0.0418614    0.128455    -0.0141416    0.0641446    0.0489804    0.0803014   -0.0900902  -0.140895     -0.0482192   -0.00282114   0.0313176    0.0294158    0.198372     0.148179     0.0530509     0.124914     -0.000926371  -0.196227    -0.0944899    -0.0770605    0.077426   -0.0801253    0.122293    -0.049901      0.0603017   -0.0989114
 -0.0807037   -0.0727544   -0.0190109    0.19945      0.0957059    0.0718975   -0.0564998  -0.0334429    -0.112782    -0.0477365   -0.0748427    0.0872926   -0.253835    -0.101965     0.122929      0.050129     -0.00845812    0.185923     0.0975488     0.0741896    0.0336882  -0.0121037   -0.192489    -0.152107     -0.091759     0.00043213
  0.0112949   -0.0839392    0.0746905    0.0117272    0.0239       0.107912     0.120323    0.131231      0.04965     -0.0134911   -0.074696    -0.0698951    0.222248    -0.158139     0.089505     -0.012839      0.0536282     0.18087      0.148938     -0.00130918   0.016099    0.0186903    0.0253      -0.0816466     0.07713      0.0637941
  0.0449599   -0.0088084    0.0101506   -0.0341859   -0.080281    -0.163894     0.045571    0.000826441   0.0920804    0.163648     0.126635    -0.0497533    0.132025     0.225714     0.0661154    -0.120425     -0.0191396    -0.0633532    0.0125067     0.0419241   -0.121291    0.136096     0.112634    -0.000225906  -0.0520866   -0.0865117
 -0.140067    -0.157572    -0.0713268   -0.171771     0.156962    -0.0251903   -0.0448487  -0.0560711    -0.283598     0.0933705    0.0013576    0.0581305   -0.0410158    0.0425865    0.111101      0.172887     -0.0531845     0.0798163   -0.119096     -0.0895517   -0.080083   -0.125907    -0.0324755    0.147144     -0.153583    -0.072334
  0.0308474    0.159463     0.0222374    0.0162678    0.169707     0.0307712    0.182177   -0.195927      0.0969251    0.153058     0.0289591   -0.0519648   -0.104295     0.0688063   -0.186414     -0.0176576     0.0273975    -0.106512    -0.152133     -0.142417    -0.0180357  -0.0046768    0.166588     0.0835715     0.0719787    0.0278898
  0.144266     0.123447    -0.113284    -0.170698    -0.0458095    0.0746078   -0.101498   -0.0116554     0.0785377    0.0724059    0.0732089    0.0658879    0.0959028    0.0711038    0.0632142     0.1599       -0.154816     -0.0946663    0.130263      0.0472278   -0.0899694  -0.00773603   0.0101685   -0.159144     -0.0549515    0.0844142
 -0.00993013  -0.111834     0.00363781   0.17547     -0.0648339   -0.0260624   -0.0772448   0.104978      0.0744402   -0.058233    -0.0112495   -0.131153     0.0682707    0.123131    -0.00879821   -0.0118822    -0.0408286    -0.0730301    0.155361     -0.0683736   -0.103388    0.0848763    0.103094     0.00182135    0.129958     0.00513498
  0.10497     -0.119503    -0.0767798   -0.0466241    0.017805     0.136342    -0.174655    0.11177      -0.119265    -0.0793658   -0.0617654    0.0028648    0.0487558   -0.00940659  -0.15069      -0.00324796   -0.0224504    -0.0237627   -0.177211     -0.0718231    0.116796   -0.143939     0.0265382    0.0418862     0.0319165    0.0640647
  0.154691     0.0531772   -0.137828    -0.113962    -0.0329741   -0.0536032    0.188055    0.0875013     0.0372733   -0.0660515   -0.0210451    0.063232     0.0846642    0.090239    -0.0897692     0.0732848     0.0196684     0.0833391    0.138031     -0.0843197    0.0196559  -0.214518    -0.0492325   -0.0514168     0.0708952    0.0273023kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.41980159869809
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419821
[ Info: iteration 2, average log likelihood -1.419740
[ Info: iteration 3, average log likelihood -1.419664
[ Info: iteration 4, average log likelihood -1.419564
[ Info: iteration 5, average log likelihood -1.419434
[ Info: iteration 6, average log likelihood -1.419276
[ Info: iteration 7, average log likelihood -1.419094
[ Info: iteration 8, average log likelihood -1.418884
[ Info: iteration 9, average log likelihood -1.418606
[ Info: iteration 10, average log likelihood -1.418187
[ Info: iteration 11, average log likelihood -1.417553
[ Info: iteration 12, average log likelihood -1.416719
[ Info: iteration 13, average log likelihood -1.415858
[ Info: iteration 14, average log likelihood -1.415196
[ Info: iteration 15, average log likelihood -1.414809
[ Info: iteration 16, average log likelihood -1.414619
[ Info: iteration 17, average log likelihood -1.414532
[ Info: iteration 18, average log likelihood -1.414494
[ Info: iteration 19, average log likelihood -1.414476
[ Info: iteration 20, average log likelihood -1.414469
[ Info: iteration 21, average log likelihood -1.414465
[ Info: iteration 22, average log likelihood -1.414463
[ Info: iteration 23, average log likelihood -1.414462
[ Info: iteration 24, average log likelihood -1.414461
[ Info: iteration 25, average log likelihood -1.414461
[ Info: iteration 26, average log likelihood -1.414460
[ Info: iteration 27, average log likelihood -1.414460
[ Info: iteration 28, average log likelihood -1.414460
[ Info: iteration 29, average log likelihood -1.414460
[ Info: iteration 30, average log likelihood -1.414459
[ Info: iteration 31, average log likelihood -1.414459
[ Info: iteration 32, average log likelihood -1.414459
[ Info: iteration 33, average log likelihood -1.414459
[ Info: iteration 34, average log likelihood -1.414459
[ Info: iteration 35, average log likelihood -1.414459
[ Info: iteration 36, average log likelihood -1.414458
[ Info: iteration 37, average log likelihood -1.414458
[ Info: iteration 38, average log likelihood -1.414458
[ Info: iteration 39, average log likelihood -1.414458
[ Info: iteration 40, average log likelihood -1.414458
[ Info: iteration 41, average log likelihood -1.414458
[ Info: iteration 42, average log likelihood -1.414458
[ Info: iteration 43, average log likelihood -1.414458
[ Info: iteration 44, average log likelihood -1.414458
[ Info: iteration 45, average log likelihood -1.414458
[ Info: iteration 46, average log likelihood -1.414458
[ Info: iteration 47, average log likelihood -1.414458
[ Info: iteration 48, average log likelihood -1.414458
[ Info: iteration 49, average log likelihood -1.414458
[ Info: iteration 50, average log likelihood -1.414458
┌ Info: EM with 100000 data points 50 iterations avll -1.414458
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4198207193747336
│     -1.419739517763206
│      ⋮
└     -1.4144577021086133
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414477
[ Info: iteration 2, average log likelihood -1.414393
[ Info: iteration 3, average log likelihood -1.414315
[ Info: iteration 4, average log likelihood -1.414211
[ Info: iteration 5, average log likelihood -1.414081
[ Info: iteration 6, average log likelihood -1.413937
[ Info: iteration 7, average log likelihood -1.413800
[ Info: iteration 8, average log likelihood -1.413690
[ Info: iteration 9, average log likelihood -1.413613
[ Info: iteration 10, average log likelihood -1.413562
[ Info: iteration 11, average log likelihood -1.413527
[ Info: iteration 12, average log likelihood -1.413501
[ Info: iteration 13, average log likelihood -1.413481
[ Info: iteration 14, average log likelihood -1.413466
[ Info: iteration 15, average log likelihood -1.413452
[ Info: iteration 16, average log likelihood -1.413440
[ Info: iteration 17, average log likelihood -1.413430
[ Info: iteration 18, average log likelihood -1.413421
[ Info: iteration 19, average log likelihood -1.413412
[ Info: iteration 20, average log likelihood -1.413403
[ Info: iteration 21, average log likelihood -1.413396
[ Info: iteration 22, average log likelihood -1.413388
[ Info: iteration 23, average log likelihood -1.413381
[ Info: iteration 24, average log likelihood -1.413374
[ Info: iteration 25, average log likelihood -1.413368
[ Info: iteration 26, average log likelihood -1.413362
[ Info: iteration 27, average log likelihood -1.413356
[ Info: iteration 28, average log likelihood -1.413351
[ Info: iteration 29, average log likelihood -1.413346
[ Info: iteration 30, average log likelihood -1.413341
[ Info: iteration 31, average log likelihood -1.413337
[ Info: iteration 32, average log likelihood -1.413333
[ Info: iteration 33, average log likelihood -1.413329
[ Info: iteration 34, average log likelihood -1.413326
[ Info: iteration 35, average log likelihood -1.413322
[ Info: iteration 36, average log likelihood -1.413319
[ Info: iteration 37, average log likelihood -1.413317
[ Info: iteration 38, average log likelihood -1.413314
[ Info: iteration 39, average log likelihood -1.413311
[ Info: iteration 40, average log likelihood -1.413309
[ Info: iteration 41, average log likelihood -1.413306
[ Info: iteration 42, average log likelihood -1.413304
[ Info: iteration 43, average log likelihood -1.413302
[ Info: iteration 44, average log likelihood -1.413300
[ Info: iteration 45, average log likelihood -1.413297
[ Info: iteration 46, average log likelihood -1.413295
[ Info: iteration 47, average log likelihood -1.413293
[ Info: iteration 48, average log likelihood -1.413291
[ Info: iteration 49, average log likelihood -1.413290
[ Info: iteration 50, average log likelihood -1.413288
┌ Info: EM with 100000 data points 50 iterations avll -1.413288
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4144766397330053
│     -1.4143931789568718
│      ⋮
└     -1.4132876227466147
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413297
[ Info: iteration 2, average log likelihood -1.413247
[ Info: iteration 3, average log likelihood -1.413209
[ Info: iteration 4, average log likelihood -1.413168
[ Info: iteration 5, average log likelihood -1.413121
[ Info: iteration 6, average log likelihood -1.413066
[ Info: iteration 7, average log likelihood -1.413003
[ Info: iteration 8, average log likelihood -1.412933
[ Info: iteration 9, average log likelihood -1.412858
[ Info: iteration 10, average log likelihood -1.412781
[ Info: iteration 11, average log likelihood -1.412705
[ Info: iteration 12, average log likelihood -1.412633
[ Info: iteration 13, average log likelihood -1.412565
[ Info: iteration 14, average log likelihood -1.412503
[ Info: iteration 15, average log likelihood -1.412447
[ Info: iteration 16, average log likelihood -1.412398
[ Info: iteration 17, average log likelihood -1.412355
[ Info: iteration 18, average log likelihood -1.412318
[ Info: iteration 19, average log likelihood -1.412285
[ Info: iteration 20, average log likelihood -1.412257
[ Info: iteration 21, average log likelihood -1.412231
[ Info: iteration 22, average log likelihood -1.412208
[ Info: iteration 23, average log likelihood -1.412187
[ Info: iteration 24, average log likelihood -1.412167
[ Info: iteration 25, average log likelihood -1.412149
[ Info: iteration 26, average log likelihood -1.412131
[ Info: iteration 27, average log likelihood -1.412115
[ Info: iteration 28, average log likelihood -1.412099
[ Info: iteration 29, average log likelihood -1.412085
[ Info: iteration 30, average log likelihood -1.412071
[ Info: iteration 31, average log likelihood -1.412058
[ Info: iteration 32, average log likelihood -1.412046
[ Info: iteration 33, average log likelihood -1.412035
[ Info: iteration 34, average log likelihood -1.412025
[ Info: iteration 35, average log likelihood -1.412015
[ Info: iteration 36, average log likelihood -1.412006
[ Info: iteration 37, average log likelihood -1.411997
[ Info: iteration 38, average log likelihood -1.411989
[ Info: iteration 39, average log likelihood -1.411982
[ Info: iteration 40, average log likelihood -1.411974
[ Info: iteration 41, average log likelihood -1.411967
[ Info: iteration 42, average log likelihood -1.411960
[ Info: iteration 43, average log likelihood -1.411954
[ Info: iteration 44, average log likelihood -1.411947
[ Info: iteration 45, average log likelihood -1.411940
[ Info: iteration 46, average log likelihood -1.411934
[ Info: iteration 47, average log likelihood -1.411928
[ Info: iteration 48, average log likelihood -1.411921
[ Info: iteration 49, average log likelihood -1.411915
[ Info: iteration 50, average log likelihood -1.411908
┌ Info: EM with 100000 data points 50 iterations avll -1.411908
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4132973189193216
│     -1.4132467701184126
│      ⋮
└     -1.4119081922827643
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411910
[ Info: iteration 2, average log likelihood -1.411851
[ Info: iteration 3, average log likelihood -1.411797
[ Info: iteration 4, average log likelihood -1.411734
[ Info: iteration 5, average log likelihood -1.411657
[ Info: iteration 6, average log likelihood -1.411566
[ Info: iteration 7, average log likelihood -1.411459
[ Info: iteration 8, average log likelihood -1.411344
[ Info: iteration 9, average log likelihood -1.411227
[ Info: iteration 10, average log likelihood -1.411115
[ Info: iteration 11, average log likelihood -1.411012
[ Info: iteration 12, average log likelihood -1.410920
[ Info: iteration 13, average log likelihood -1.410839
[ Info: iteration 14, average log likelihood -1.410768
[ Info: iteration 15, average log likelihood -1.410706
[ Info: iteration 16, average log likelihood -1.410652
[ Info: iteration 17, average log likelihood -1.410605
[ Info: iteration 18, average log likelihood -1.410564
[ Info: iteration 19, average log likelihood -1.410528
[ Info: iteration 20, average log likelihood -1.410495
[ Info: iteration 21, average log likelihood -1.410466
[ Info: iteration 22, average log likelihood -1.410440
[ Info: iteration 23, average log likelihood -1.410416
[ Info: iteration 24, average log likelihood -1.410393
[ Info: iteration 25, average log likelihood -1.410372
[ Info: iteration 26, average log likelihood -1.410352
[ Info: iteration 27, average log likelihood -1.410332
[ Info: iteration 28, average log likelihood -1.410313
[ Info: iteration 29, average log likelihood -1.410295
[ Info: iteration 30, average log likelihood -1.410277
[ Info: iteration 31, average log likelihood -1.410259
[ Info: iteration 32, average log likelihood -1.410241
[ Info: iteration 33, average log likelihood -1.410224
[ Info: iteration 34, average log likelihood -1.410207
[ Info: iteration 35, average log likelihood -1.410190
[ Info: iteration 36, average log likelihood -1.410174
[ Info: iteration 37, average log likelihood -1.410157
[ Info: iteration 38, average log likelihood -1.410141
[ Info: iteration 39, average log likelihood -1.410125
[ Info: iteration 40, average log likelihood -1.410109
[ Info: iteration 41, average log likelihood -1.410094
[ Info: iteration 42, average log likelihood -1.410079
[ Info: iteration 43, average log likelihood -1.410064
[ Info: iteration 44, average log likelihood -1.410049
[ Info: iteration 45, average log likelihood -1.410035
[ Info: iteration 46, average log likelihood -1.410021
[ Info: iteration 47, average log likelihood -1.410007
[ Info: iteration 48, average log likelihood -1.409994
[ Info: iteration 49, average log likelihood -1.409981
[ Info: iteration 50, average log likelihood -1.409968
┌ Info: EM with 100000 data points 50 iterations avll -1.409968
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4119096666943944
│     -1.4118513399769717
│      ⋮
└     -1.409968183323884
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409964
[ Info: iteration 2, average log likelihood -1.409895
[ Info: iteration 3, average log likelihood -1.409831
[ Info: iteration 4, average log likelihood -1.409758
[ Info: iteration 5, average log likelihood -1.409667
[ Info: iteration 6, average log likelihood -1.409555
[ Info: iteration 7, average log likelihood -1.409422
[ Info: iteration 8, average log likelihood -1.409274
[ Info: iteration 9, average log likelihood -1.409119
[ Info: iteration 10, average log likelihood -1.408965
[ Info: iteration 11, average log likelihood -1.408818
[ Info: iteration 12, average log likelihood -1.408680
[ Info: iteration 13, average log likelihood -1.408554
[ Info: iteration 14, average log likelihood -1.408439
[ Info: iteration 15, average log likelihood -1.408335
[ Info: iteration 16, average log likelihood -1.408243
[ Info: iteration 17, average log likelihood -1.408160
[ Info: iteration 18, average log likelihood -1.408086
[ Info: iteration 19, average log likelihood -1.408018
[ Info: iteration 20, average log likelihood -1.407957
[ Info: iteration 21, average log likelihood -1.407901
[ Info: iteration 22, average log likelihood -1.407848
[ Info: iteration 23, average log likelihood -1.407799
[ Info: iteration 24, average log likelihood -1.407753
[ Info: iteration 25, average log likelihood -1.407709
[ Info: iteration 26, average log likelihood -1.407668
[ Info: iteration 27, average log likelihood -1.407629
[ Info: iteration 28, average log likelihood -1.407592
[ Info: iteration 29, average log likelihood -1.407558
[ Info: iteration 30, average log likelihood -1.407525
[ Info: iteration 31, average log likelihood -1.407494
[ Info: iteration 32, average log likelihood -1.407464
[ Info: iteration 33, average log likelihood -1.407436
[ Info: iteration 34, average log likelihood -1.407410
[ Info: iteration 35, average log likelihood -1.407384
[ Info: iteration 36, average log likelihood -1.407360
[ Info: iteration 37, average log likelihood -1.407337
[ Info: iteration 38, average log likelihood -1.407316
[ Info: iteration 39, average log likelihood -1.407295
[ Info: iteration 40, average log likelihood -1.407275
[ Info: iteration 41, average log likelihood -1.407256
[ Info: iteration 42, average log likelihood -1.407237
[ Info: iteration 43, average log likelihood -1.407220
[ Info: iteration 44, average log likelihood -1.407203
[ Info: iteration 45, average log likelihood -1.407187
[ Info: iteration 46, average log likelihood -1.407171
[ Info: iteration 47, average log likelihood -1.407156
[ Info: iteration 48, average log likelihood -1.407141
[ Info: iteration 49, average log likelihood -1.407127
[ Info: iteration 50, average log likelihood -1.407113
┌ Info: EM with 100000 data points 50 iterations avll -1.407113
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.40996423401081
│     -1.4098953584127607
│      ⋮
└     -1.4071129462694165
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.41980159869809
│     -1.4198207193747336
│     -1.419739517763206
│     -1.4196637678650483
│      ⋮
│     -1.4071409285698162
│     -1.4071267123822915
└     -1.4071129462694165
32×26 Array{Float64,2}:
 -0.0687787    0.395531   -0.409579     0.06243    -0.466741    0.801487    0.218758      0.274587    0.61291     -0.499729     0.154396    -0.508903    -0.0857927    0.0380225    0.0790144   -0.103967     0.533311    0.0533688   0.0202601    -0.165494   -0.035705    0.0792442  -0.0328776  -0.0801538    1.0236      0.0742956
  0.00959647   0.499456   -0.634499     0.261569   -0.132113   -0.0064963  -0.677529     -0.0737704  -0.177217     0.363111     0.174526    -0.436763    -0.37384     -0.0702887   -0.156844     0.0675175   -0.339309   -0.0684158  -0.345484     -0.0216747  -0.271068   -0.060973   -0.200897   -0.312226     0.702863    0.0469128
 -0.0626879   -0.0681158   0.202232    -0.279349   -0.410741    0.820777    0.253259     -0.416613   -0.044044     0.387144     0.554753    -0.19293      0.566976     0.611264     0.125019     0.0268368    0.10787     0.173499   -0.546852      0.0971877  -0.142821   -0.536026   -0.153178    0.0947527    0.381749   -0.06451
 -0.0691709   -0.494527    0.6762       0.309562   -0.335129    0.0519972  -0.174926      0.193434    0.113217     0.108501    -0.00641532  -0.0986347   -0.366192     0.714667    -0.147095    -0.428124     0.0616937  -0.0246499   0.126834     -0.0805277  -0.320002   -0.145388   -0.15603     0.246824     0.45163     0.101586
 -0.403226     0.215088   -0.0663957    0.212181   -0.180977    0.444144    0.385306      0.251485   -0.096519    -0.079013    -0.0255753    0.196466     0.0354853    0.126822     0.0835973   -0.348415     0.51614    -0.280388   -0.0746495     0.27942     0.323944    0.0655307  -0.649931   -0.268214    -0.0726087  -0.209723
  0.335281     0.431049   -0.0111489   -0.180694    0.0437194   0.216846    0.239434      0.169592    0.120205    -0.0944532   -0.256467     0.180554    -0.122768     0.383399    -0.11623     -0.0378993    0.186406    0.2528     -0.0757679     0.231304    0.036262   -0.875268   -0.652039   -0.29747      0.106233   -0.283882
  0.242803    -0.0902908  -0.103858     0.461688   -0.652466   -0.293694    0.59705       0.0255643  -0.242471     0.0604909   -0.446261     0.0954886    0.457964     0.0776462    0.333893    -0.374011     0.28463     0.0780053   0.19893       0.0981762  -0.0790405  -0.263327   -0.0336938   0.703415    -0.521269   -0.215073
  0.177946     0.192133    0.19016     -0.0692264   0.323965   -0.253078    0.155431     -0.198134    0.309362    -0.0429428   -0.191771     0.340497     0.263273    -0.241662     0.293493     0.0595049    0.112027   -0.379285    0.653414     -0.243572    0.306468   -0.14006    -0.155332    0.0382743   -0.466376   -0.0412735
 -0.0207848   -0.309171    0.117424     0.0658359  -0.215572    0.0595626  -0.283316     -0.0518803   0.0820239   -0.0630591    0.0715501   -0.088862     0.0897745    0.018467    -0.023975    -0.162577    -0.147929    0.0268199  -0.037499      0.161006    0.115947    0.166877    0.0156175  -0.191232     0.224732   -0.0521601
  0.0621657    0.204935   -0.108816    -0.0770639   0.0493758   0.0465412   0.0705249    -0.0246721  -0.0325888   -0.00634613   0.0284828   -0.0281169    0.0842776   -0.0291912    0.0293568    0.10406      0.0767181   0.0486171  -0.0320476    -0.0628828  -0.0428704  -0.107267    0.0129104   0.0273636   -0.0912077   0.0105867
  0.26968     -0.659942    0.0142459    0.283171    0.403687   -0.896395   -0.668454     -0.131573   -0.30553      0.245721    -0.040633    -0.128669     0.0146248   -0.242364    -0.19237      0.19432     -0.449923    0.105265    0.238798     -0.172785   -0.0939315   0.158284    0.356127    0.0468708   -0.3176      0.198369
  0.0226261   -0.282067   -0.0787009   -0.0989472   0.632173    0.513502   -0.426347     -0.0438074   0.275273    -0.0898006    0.128618     0.270303    -0.0375639   -0.0402803   -0.123534     0.442083    -0.127438   -0.11426     0.02254      -0.173064    0.210263    0.412878    0.355855   -0.506654     0.133936    0.410227
 -0.16464     -0.397213   -0.481454    -0.34798     0.175218   -0.0199708   0.469177      0.0171379  -0.12085     -0.221244     0.351277     0.352021    -0.216641    -0.197705    -0.240533     0.297117    -0.289931    0.164164   -0.175048     -0.115935   -0.328956    0.0738455   0.333145    0.353179    -0.41414     0.0316282
 -0.391086     0.151065    0.0395105    0.198169   -0.1723      0.0100444  -0.0125863     0.357095    0.00789852   0.389132     0.0617178    0.0572359    0.0363269   -0.0649401    0.202201     0.241382     0.728665    0.324334    0.109381     -0.440864   -0.686306    0.29141     0.042299    0.631755     0.0244693  -0.0296448
 -0.0490259    0.0899553  -0.0327588   -0.469943   -0.600495   -0.09054    -0.282228      0.448469   -0.322189     0.162669     0.123286     0.0223283    0.0246815   -0.00508219   0.276902     0.694199     0.158642    0.414427   -0.652856      0.0128084   0.51602     0.445209    0.0869375  -0.376771    -0.467698   -0.246519
  0.218878     1.16034    -0.176602    -0.398009   -0.373673   -0.0801019   0.080024      0.20862    -0.23154      0.286495    -0.348639     0.184825    -0.421644     0.0894334    0.0343328    0.34833      0.0337779   0.312491   -0.441429     -0.421366    0.482915   -0.134568   -0.0396851   0.457354    -0.662472    0.0850071
  0.0851985    0.235397   -0.0292492   -0.141548   -0.526679    0.155346    0.13336       0.108865   -0.422351     0.0775788   -0.0402722   -0.129481     0.0288017    0.150152     0.014451    -0.0982317    0.225242    0.395519   -0.268056      0.263548   -0.112153   -0.0990486  -0.107712    0.129955    -0.101761   -0.562185
 -0.119704    -0.369263   -0.304071     0.252783    0.46558     0.35889     0.224812      0.431395   -0.285372     0.0697573   -0.0261013    0.15721     -0.048949     0.250838    -1.07248     -0.327696     0.412957    0.641422   -0.720068      0.363347   -0.775855    0.170094    0.19709    -0.342289     0.0355249   0.0116625
 -0.340761    -0.316838    0.106541     0.24076    -0.315234    0.364841   -0.536719      0.155365    0.27143      0.106367    -0.0753742   -0.186248    -0.178234    -0.318867     0.100524    -0.479702     0.402381   -0.373847   -0.0516165    -0.314749    0.232785    1.01398    -0.0732042  -0.0376823    0.496629    0.0783715
  0.301665     0.374832    0.461654     0.145224   -0.0604848   0.218167   -0.00302319    0.258962    0.422494     0.219886    -0.283231    -0.0279231    0.183348     0.212192     0.321635    -0.00401124   0.901276   -0.193724    0.422905     -0.0919308   0.149735   -0.177865   -0.28307     0.0245266    0.186973    0.205041
 -0.236253     0.125373    0.112302     0.071401   -0.203603   -0.294682    0.375257     -1.17918     0.14562      0.772696    -0.106169     0.0206115    0.498206    -0.169119    -0.0608353    0.236383    -0.52575     0.0260252  -0.289092     -0.917734   -0.0666301  -0.184124    0.114702    0.652538     0.0739334   0.624075
 -1.03778      0.0820022   0.301923    -0.144697   -0.241627    0.630441    0.18523      -0.210953   -0.170381     0.244933     0.234206     0.571461    -0.0766053    0.28411      0.534872     0.354385    -0.348304    0.14388     0.332326     -0.041322    0.12603     0.246974    0.516077    0.667179     0.045592   -0.209329
 -0.184872    -0.334501    0.321951    -0.674374    0.16719     0.417121   -0.128827     -0.380325   -0.535933     0.0169137   -0.00924357  -0.175353     0.602533    -0.467657    -0.00329773  -0.270024    -0.0857922   0.301072    0.193295      0.254831    0.0306348   0.376061    0.178821   -0.408912    -0.282109   -0.846488
  0.423281     0.551228    0.310438    -0.412096   -0.257685    0.19628    -0.498131     -0.367522    0.208883     0.117466    -0.138839    -0.551168     0.418621    -0.416673     0.170177     0.170784     0.264446    0.344383   -0.000548791  -0.0758756   0.357281    0.279518    0.644397   -0.154497     0.269623   -0.332026
  0.0272857   -0.510646   -0.468021    -0.107729    0.636736   -0.197519   -0.148617     -0.117257    0.223981    -0.227836     0.138151     0.247534    -0.112497    -0.43357     -0.159236     0.338385    -0.504689   -0.17367    -0.0099823    -0.0590573  -0.0926973  -0.0783414   0.0170723  -0.148021     0.0441644   0.431335
 -0.315678     0.522098   -0.341357    -0.150514    0.792618   -0.505243    0.207192     -0.458275   -0.254488    -0.0412069   -0.15774     -0.128666     0.285591    -0.645587    -0.909019     0.302469    -0.343557    0.234596    0.0989917     0.0699538  -0.175694    0.147093    0.148987   -0.182729    -0.384722    0.0892573
  0.337984    -0.121951   -0.516494     0.204813    0.500993   -0.131244    0.00956994    0.743075    0.359567    -0.843834    -0.318345     0.0366899   -0.392234    -0.748505     0.192224    -0.00561149   0.358662   -0.187228   -0.423829     -0.1932     -0.108216    0.051119   -0.0356624  -0.202572    -0.29797     0.0782661
  0.0844919   -0.326963    0.279215    -0.0881947   0.411936   -0.138764    0.000349729   0.835466    0.163529    -0.679803    -0.134342     5.20368e-5  -0.00716042  -0.0509952   -0.0310478   -0.178338     0.302034    0.0436445   0.890109      0.543068   -0.0628354   0.350565    0.141758   -0.445324    -0.424184   -0.419851
  0.399165     0.0749964  -0.268996     0.105989   -0.0154961  -0.235896    0.161634     -0.499494    0.118198    -0.62131      0.114142    -0.434601     0.478871    -0.419874    -0.144443    -0.474868    -0.531224   -0.493199    0.0218368     0.49977     0.0725748  -0.307412    0.118401    0.00917535   0.298226    0.272708
  0.145024    -0.276479   -0.192043    -0.0394423  -0.021712   -0.0974807  -0.233351     -0.718626   -0.0863884   -0.0600369    0.131213     0.220136    -0.0275543    0.452896     0.0182089   -0.437017    -0.9398     -0.488686   -0.140804     -0.0240312   0.819268   -0.26501    -0.359695   -0.515782    -0.1523     -0.218164
  0.117565     0.168477    0.00467899  -0.354552   -0.135212   -0.355386    0.0621149     0.0428568   0.078997    -0.326144     0.80785     -0.403486    -0.0598321    0.609941     0.227175     0.324222    -0.366099   -0.113641    0.254973     -0.383684   -0.290973   -0.796396   -0.382492    0.364789     0.167947    0.495952
  0.130454    -0.120963   -0.328302     0.628652    0.0283107  -0.802019    0.107574      0.394111    0.236052    -0.202937    -0.119515     0.499313    -0.298688     0.360355     0.101768     0.91619     -0.178757   -0.495868   -0.141838      0.581847    0.233772   -0.684343   -0.457732    0.19145     -0.665187    0.671301[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407100
[ Info: iteration 2, average log likelihood -1.407087
[ Info: iteration 3, average log likelihood -1.407074
[ Info: iteration 4, average log likelihood -1.407062
[ Info: iteration 5, average log likelihood -1.407050
[ Info: iteration 6, average log likelihood -1.407039
[ Info: iteration 7, average log likelihood -1.407028
[ Info: iteration 8, average log likelihood -1.407017
[ Info: iteration 9, average log likelihood -1.407006
[ Info: iteration 10, average log likelihood -1.406996
┌ Info: EM with 100000 data points 10 iterations avll -1.406996
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.147007e+05
      1       7.028162e+05      -2.118844e+05 |       32
      2       6.890687e+05      -1.374751e+04 |       32
      3       6.838369e+05      -5.231861e+03 |       32
      4       6.810043e+05      -2.832546e+03 |       32
      5       6.791541e+05      -1.850270e+03 |       32
      6       6.778267e+05      -1.327379e+03 |       32
      7       6.767927e+05      -1.033935e+03 |       32
      8       6.759870e+05      -8.057560e+02 |       32
      9       6.753108e+05      -6.761761e+02 |       32
     10       6.747212e+05      -5.896149e+02 |       32
     11       6.742509e+05      -4.702831e+02 |       32
     12       6.738624e+05      -3.884720e+02 |       32
     13       6.735158e+05      -3.466371e+02 |       32
     14       6.732019e+05      -3.139124e+02 |       32
     15       6.729352e+05      -2.666907e+02 |       32
     16       6.727103e+05      -2.248924e+02 |       32
     17       6.724960e+05      -2.143269e+02 |       32
     18       6.722946e+05      -2.014076e+02 |       32
     19       6.721000e+05      -1.946051e+02 |       32
     20       6.719280e+05      -1.719485e+02 |       32
     21       6.717875e+05      -1.405316e+02 |       32
     22       6.716575e+05      -1.300333e+02 |       32
     23       6.715414e+05      -1.160661e+02 |       32
     24       6.714288e+05      -1.126121e+02 |       32
     25       6.713305e+05      -9.832223e+01 |       32
     26       6.712407e+05      -8.971756e+01 |       32
     27       6.711613e+05      -7.940238e+01 |       32
     28       6.710891e+05      -7.221048e+01 |       32
     29       6.710190e+05      -7.014415e+01 |       32
     30       6.709477e+05      -7.131919e+01 |       32
     31       6.708819e+05      -6.573702e+01 |       32
     32       6.708159e+05      -6.597799e+01 |       32
     33       6.707571e+05      -5.881992e+01 |       32
     34       6.706941e+05      -6.304871e+01 |       32
     35       6.706369e+05      -5.712568e+01 |       32
     36       6.705831e+05      -5.383914e+01 |       32
     37       6.705309e+05      -5.225030e+01 |       32
     38       6.704837e+05      -4.713999e+01 |       32
     39       6.704437e+05      -3.999498e+01 |       32
     40       6.704082e+05      -3.550178e+01 |       32
     41       6.703753e+05      -3.289645e+01 |       32
     42       6.703407e+05      -3.461698e+01 |       32
     43       6.703073e+05      -3.337601e+01 |       32
     44       6.702767e+05      -3.060712e+01 |       32
     45       6.702469e+05      -2.980512e+01 |       32
     46       6.702210e+05      -2.595592e+01 |       32
     47       6.701966e+05      -2.435337e+01 |       32
     48       6.701743e+05      -2.231383e+01 |       32
     49       6.701558e+05      -1.853723e+01 |       32
     50       6.701364e+05      -1.939639e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 670136.3643932069)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418809
[ Info: iteration 2, average log likelihood -1.413830
[ Info: iteration 3, average log likelihood -1.412520
[ Info: iteration 4, average log likelihood -1.411591
[ Info: iteration 5, average log likelihood -1.410618
[ Info: iteration 6, average log likelihood -1.409665
[ Info: iteration 7, average log likelihood -1.408941
[ Info: iteration 8, average log likelihood -1.408499
[ Info: iteration 9, average log likelihood -1.408241
[ Info: iteration 10, average log likelihood -1.408074
[ Info: iteration 11, average log likelihood -1.407953
[ Info: iteration 12, average log likelihood -1.407855
[ Info: iteration 13, average log likelihood -1.407773
[ Info: iteration 14, average log likelihood -1.407702
[ Info: iteration 15, average log likelihood -1.407639
[ Info: iteration 16, average log likelihood -1.407583
[ Info: iteration 17, average log likelihood -1.407532
[ Info: iteration 18, average log likelihood -1.407485
[ Info: iteration 19, average log likelihood -1.407442
[ Info: iteration 20, average log likelihood -1.407402
[ Info: iteration 21, average log likelihood -1.407365
[ Info: iteration 22, average log likelihood -1.407330
[ Info: iteration 23, average log likelihood -1.407297
[ Info: iteration 24, average log likelihood -1.407266
[ Info: iteration 25, average log likelihood -1.407237
[ Info: iteration 26, average log likelihood -1.407209
[ Info: iteration 27, average log likelihood -1.407182
[ Info: iteration 28, average log likelihood -1.407157
[ Info: iteration 29, average log likelihood -1.407132
[ Info: iteration 30, average log likelihood -1.407109
[ Info: iteration 31, average log likelihood -1.407086
[ Info: iteration 32, average log likelihood -1.407064
[ Info: iteration 33, average log likelihood -1.407044
[ Info: iteration 34, average log likelihood -1.407024
[ Info: iteration 35, average log likelihood -1.407004
[ Info: iteration 36, average log likelihood -1.406985
[ Info: iteration 37, average log likelihood -1.406967
[ Info: iteration 38, average log likelihood -1.406950
[ Info: iteration 39, average log likelihood -1.406933
[ Info: iteration 40, average log likelihood -1.406917
[ Info: iteration 41, average log likelihood -1.406901
[ Info: iteration 42, average log likelihood -1.406885
[ Info: iteration 43, average log likelihood -1.406870
[ Info: iteration 44, average log likelihood -1.406856
[ Info: iteration 45, average log likelihood -1.406842
[ Info: iteration 46, average log likelihood -1.406828
[ Info: iteration 47, average log likelihood -1.406815
[ Info: iteration 48, average log likelihood -1.406802
[ Info: iteration 49, average log likelihood -1.406789
[ Info: iteration 50, average log likelihood -1.406777
┌ Info: EM with 100000 data points 50 iterations avll -1.406777
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0148079  -0.103699     0.711703    -0.759153    0.245903   -0.484158    0.0720567  -0.454681    -0.490269      0.149344    -0.275919     -0.208597     0.507965   -0.422985   -0.249665    0.184776   -0.427205    0.884417    -0.181553     0.139763    -0.141043    -0.235684   -0.0443188    0.0558415   -0.615197   -0.585605
 -0.0930769   0.103418    -0.0392548    0.021678   -0.0833946   0.0778283   0.0850453   0.099745    -0.0422625     0.105008     0.0567275     0.0377171   -0.0230716   0.0308142   0.140676    0.0113185   0.328664    0.149121    -0.00307206  -0.225254    -0.243485    -0.102189   -0.140659     0.26511     -0.0430964  -0.0632662
  0.0246338   0.0496357   -0.337287    -0.148947    0.218808   -0.131958    0.0187179  -0.40842      0.0382327     0.265574     0.196952      0.142462     0.0747737  -0.218388   -0.192004    0.745172   -0.330297    0.129221    -0.329491    -0.62075     -0.169253     0.227553    0.464076     0.121273    -0.186138    0.443624
  0.186756   -0.00782128  -0.498522     0.177891    0.365575    0.255054   -0.163339    0.663395     0.517125     -0.722389    -0.0999311    -0.097311    -0.517394   -0.324272    0.081157    0.155812    0.461216   -0.154783    -0.416891    -0.266871     0.0109868    0.0545736  -0.0127364   -0.360535     0.161527    0.165793
 -0.213011   -0.218769     0.285264    -0.395427   -0.0637108   0.372188   -0.245769   -0.582838     0.016766     -0.0257722    0.32737      -0.466563     0.954214   -0.385952    0.25301    -0.275987   -0.115403   -0.104108     0.268199     0.443059     0.365944     0.439375    0.359844    -0.707755     0.195094   -0.428212
  0.153324    0.840578    -0.600061    -0.0514981  -0.26872    -0.184759   -0.156846   -0.0859269   -0.0443012    -0.0480878    0.124227     -0.323948     0.184028   -0.488233    0.41606     0.439594   -0.435822    0.159622    -0.208019     0.0753068    0.553775     0.0425223   0.537167    -0.119705     0.187367   -0.358135
 -0.339368   -0.103894     0.492744    -0.168016    0.219741    0.0107572   0.234048    0.200215     0.159736     -0.261104     0.092099      0.188474     0.410127   -0.0595304   0.349261    0.101026    0.247558   -0.260355     0.636852    -0.0200394    0.334488     0.172822    0.00363792   0.0522209   -0.374031   -0.0299393
  0.597385    0.273402     0.658156     0.209027   -0.422296    0.156997   -0.274549   -0.0769334    0.550183      0.52338     -0.334019     -0.0548757    0.111367   -0.232905    0.579953   -0.0747658   0.679515   -0.259624     0.153551     0.0143054    0.410634     0.192645    0.0614193   -0.416388     0.296104    0.0337802
  0.0512778  -0.503539    -0.0771223   -0.356686    0.234848    0.0803607  -0.511213   -0.578929    -0.0240332    -0.179926     0.221583      0.17649     -0.222348    0.0773175  -0.0565988  -0.0509253  -1.19441    -0.332038    -0.228639    -0.0192152    0.564969    -0.281755   -0.0567393   -0.592213     0.129882    0.0435633
 -0.0759298   0.0711398   -0.0872813    0.379486   -0.541295   -0.134424    0.430477    0.406466    -0.188422      0.00104255  -0.350872     -0.0300041    0.598269   -0.198371    0.336839   -0.219373    0.890867    0.234797     0.205593    -0.00702174  -0.376448     0.197754    0.0803665    0.746372    -0.44398    -0.243485
 -0.638497    0.0784288    0.204912     0.158684   -0.457862    0.0994724   0.185739   -0.927256    -0.168098      0.70159      0.169635      0.207919     0.443807    0.314082    0.253894    0.020446   -0.406263    0.0931705   -0.0577462   -0.583282    -0.00206948  -0.0744104   0.180445     0.927105     0.16257     0.216032
  0.0955745   0.0855963   -0.387347     0.0753474   0.386336   -0.562157   -0.0983688  -0.267137     0.0303336    -0.00843924  -0.421012      0.220012     0.0712116  -0.640588   -0.252543    0.229502   -0.276063   -0.15982     -0.0241483   -0.172937     0.197066     0.0720305   0.0499044    0.124484    -0.354009    0.249345
  0.743108    0.770079    -0.18077     -0.61286    -0.124978    0.385178    0.268307   -0.51487      0.000601803   0.104365    -0.328804      0.136815     0.759056    0.193849   -0.0509799   0.0754255   0.497229   -0.166253     0.216368    -0.17341      0.382153    -0.425641   -0.457942     0.0697557   -0.446499   -0.171745
 -0.116574    0.55458     -0.101317    -0.186443   -0.368873    0.43266     0.609206    0.18856      0.0355268    -0.440336    -0.405287      0.148597    -0.0489045   0.173157   -0.0225448  -0.0492923   0.143575    0.145321    -0.2516       0.630212     0.546655    -0.369536   -0.457168    -0.284052    -0.0415928  -0.453021
  0.0975997   0.104833    -0.510827    -0.161991    0.184278    0.0802328   0.275648    0.233273    -0.237196     -0.111186     0.679555     -0.149495    -0.0582687   0.453051   -0.263645    0.237485   -0.272804    0.00135331  -0.0680082    0.300508    -0.48153     -0.752184   -0.361034    -0.0519759    0.274167    0.441667
 -0.85513     0.00993517  -0.300415     0.277677   -0.0818906   0.308721   -0.18331     0.251796     0.134865      0.220263     0.38417       0.194221    -0.417268   -0.0546272   0.158125   -0.434252    0.0198247  -0.767949     0.460053    -0.0321111   -0.237557     0.663674   -0.506687     0.0550294    0.497383    0.0624786
 -0.122229    0.137176     0.351587    -0.591869    0.0593639   0.603206   -0.523985   -0.00970391  -0.00462188   -0.178825    -0.0844719    -0.449819    -0.0564369  -0.510851   -0.384479    0.154026    0.415102    0.700786     0.0484108   -0.547548     0.0837285    0.733617    0.542019     0.00228203   0.394339   -0.215108
  0.0191771   0.279493    -0.0631052    0.469384   -0.375303   -0.213353   -0.36113    -0.0700626   -0.228344      0.119992    -0.0464       -0.362918    -0.179509    0.574025   -0.242704   -0.392024    0.208569   -0.0810947   -0.256215    -0.0185752    0.0517387   -0.29414    -0.966979    -0.527846     0.312436   -0.191973
 -0.0107414  -0.0751891    0.0592418   -0.122921   -0.478398    0.808002    0.0152592  -0.0798715    0.185206      0.172102     0.44305      -0.289188     0.294317    0.471669    0.118858   -0.0960067   0.179192    0.162993    -0.421325     0.106811    -0.219559    -0.253274   -0.129747    -0.099641     0.706878   -0.0980516
 -0.383625   -0.112328     0.351468     0.662988   -0.0818464   0.292782    0.101649    0.460917     0.0762584     0.221593    -0.625958      0.380762    -0.783872    0.0727767  -0.235159   -0.213128    0.291898    0.438466    -0.2054       0.169527    -0.45727      0.0664223   0.122658     0.26456      0.658369   -0.177748
 -0.196707   -0.20771     -0.579545     0.252733    0.481355    0.374469    0.179566    0.0107546   -0.447955      0.107916     0.171843     -0.047291     0.583047    0.0221276  -0.976796   -0.24778     0.36724     0.421465    -0.420593     0.526973    -0.537154     0.352312    0.235353    -0.626878    -0.156707   -0.0209128
  0.172942   -0.838819     0.136908     0.626241   -0.0565391  -0.59192    -0.666558    0.103129    -0.366354      0.238931     0.255425     -0.597704    -0.261879   -0.0244383  -0.123897   -0.0134508  -0.406255    0.226179    -0.0887878   -0.16373     -0.232796     0.368231    0.487463     0.180577     0.174023    0.310196
  0.0586397   0.0792214    0.273073     0.0313128  -0.303362    0.495686   -0.047064    0.276609     0.238384      0.0467903   -0.0141829    -0.203747     0.0884568   0.286482    0.215765   -0.180335    0.700428    0.0963357    0.00485699  -0.101463     0.0332557    0.128244   -0.203695    -0.0491994    0.293852   -0.116905
  0.2896     -0.519879     0.586276     0.172037    0.233238    0.167843    0.194973   -0.185458     0.206427     -0.305415    -0.188878     -0.0655808    0.0829765   0.589212   -0.468081   -0.76787    -0.207268   -0.311874     0.507641     0.240202    -0.0349882   -0.305109    0.135354     0.352165     0.0565921   0.233891
 -0.395498    0.249293     0.296958    -0.457947   -0.522646    0.391475   -0.186841    0.542243    -0.800482      0.355724     0.203835      0.120105    -0.336628    0.550217    0.303939    0.485944    0.331431    0.34652     -0.204333     0.110143     0.322839     0.360721    0.235986    -0.107755    -0.617003   -0.459798
  0.284582   -0.46045      0.0463793    0.0180167   0.748509   -0.425381   -0.285328    0.456344     0.312104     -0.380731    -0.197145      0.148538    -0.0220798  -0.318152   -0.205769    0.0727209   0.07746     0.0465651    0.843457     0.150238    -0.167817     0.327396    0.143262    -0.582116    -0.451735   -0.108462
  0.322919    0.18014     -0.527589     0.135904    0.133772   -0.381764    0.118061   -0.373551     0.120283     -0.431462     0.0866945    -0.389795     0.333941   -0.572211   -0.141456   -0.334625   -0.427257   -0.461908     0.00708701   0.227561    -0.213626    -0.328876   -0.0755561    0.0887263    0.283752    0.308813
  0.22322    -0.047777    -0.277113     0.70823     0.127976   -0.730131    0.223073    0.0947674    0.104866     -0.0524919   -0.338294      0.434815    -0.0425831   0.272859    0.162446    0.293145   -0.152557   -0.383572     0.0329524    0.266371     0.32583     -0.496394   -0.388812     0.136427    -0.72518     0.350932
  0.0798164  -0.0924795   -0.00955099  -0.0821948   0.0482575   0.02908    -0.227699   -0.0698915    0.0250006    -0.0672881    0.000709424   0.00492246   0.0694477  -0.0484657  -0.117387    0.0156328  -0.205604   -0.0130902   -0.0300837    0.145736     0.17675      0.0841194   0.0883394   -0.272486     0.0371766  -0.0307542
  0.176915    0.274606     0.299482    -0.445609   -0.436955   -0.189768    0.0901405   0.137993     0.302588     -0.112428     0.427918     -0.220213    -0.366939    0.422822    0.531769    0.26552    -0.138589   -0.10347      0.275047    -0.356635    -0.16533     -0.762242   -0.212591     0.703164     0.0743495   0.177135
  0.247109   -0.166322    -0.772582    -0.668959    0.161801    0.114246    0.292508    0.0514331   -0.218772     -0.184073    -0.015316      0.799079    -0.37175    -0.657584   -0.116459   -0.0479151  -0.396213    0.286023    -0.210234     0.362291    -0.37966      0.418051    0.388651    -0.0634686   -0.405579   -0.520488
 -0.376229   -0.490109    -0.314806    -0.277627    0.214891   -0.0230328   0.359355    0.784486    -0.262763     -0.193449     0.176006      0.59053     -0.781795    0.57576    -0.824811    0.131842    0.121311    0.411175    -0.548601    -0.193885    -0.486562    -0.310854   -0.470401     0.28083     -0.694289    0.111802[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406765
[ Info: iteration 2, average log likelihood -1.406753
[ Info: iteration 3, average log likelihood -1.406741
[ Info: iteration 4, average log likelihood -1.406730
[ Info: iteration 5, average log likelihood -1.406719
[ Info: iteration 6, average log likelihood -1.406709
[ Info: iteration 7, average log likelihood -1.406698
[ Info: iteration 8, average log likelihood -1.406688
[ Info: iteration 9, average log likelihood -1.406679
[ Info: iteration 10, average log likelihood -1.406669
┌ Info: EM with 100000 data points 10 iterations avll -1.406669
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
