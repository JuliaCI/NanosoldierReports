Julia Version 1.5.0-DEV.62
Commit 756891d910 (2020-01-14 06:58 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed DataAPI ──────────── v1.1.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Blosc ────────────── v0.5.1
 Installed Distances ────────── v0.8.2
 Installed SpecialFunctions ─── v0.9.0
 Installed HDF5 ─────────────── v0.12.5
 Installed BinaryProvider ───── v0.5.8
 Installed Missings ─────────── v0.4.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Parameters ───────── v0.12.0
 Installed URIParser ────────── v0.4.0
 Installed SortingAlgorithms ── v0.3.1
 Installed FileIO ───────────── v1.2.1
 Installed NearestNeighbors ─── v0.4.4
 Installed QuadGK ───────────── v2.3.1
 Installed BinDeps ──────────── v1.0.0
 Installed OrderedCollections ─ v1.1.0
 Installed PDMats ───────────── v0.9.10
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed Rmath ────────────── v0.6.0
 Installed Compat ───────────── v2.2.0
 Installed StaticArrays ─────── v0.12.1
 Installed FillArrays ───────── v0.8.4
 Installed StatsFuns ────────── v0.9.3
 Installed CMake ────────────── v1.1.2
 Installed Clustering ───────── v0.13.3
 Installed StatsBase ────────── v0.32.0
 Installed LegacyStrings ────── v0.4.1
 Installed DataStructures ───── v0.17.7
 Installed ScikitLearnBase ──── v0.5.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed JLD ──────────────── v0.9.1
 Installed Arpack ───────────── v0.4.0
 Installed Distributions ────── v0.22.2
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.2
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_WtLEN4/Project.toml`
 [no changes]
  Updating `/tmp/jl_WtLEN4/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_58llwM/Project.toml`
 [no changes]
  Updating `/tmp/jl_58llwM/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_6VRpJq/Project.toml`
 [no changes]
  Updating `/tmp/jl_6VRpJq/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_hHtjap/Project.toml`
 [no changes]
  Updating `/tmp/jl_hHtjap/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_mEq8YH/Project.toml`
 [no changes]
  Updating `/tmp/jl_mEq8YH/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_mEq8YH/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.2
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -6.607676945736882e7, [98.4443623353629, 99901.55563766464], [-195.8052637373138 -127.26382789561933 235.68709114010346; 50.204229067427406 -242.40600753001513 -579.0753471383571], [[450.5305465784184 244.97470791638335 -430.3714946995555; 244.97470791638335 232.68093507927446 -279.9912753158417; -430.3714946995555 -279.9912753158417 615.6300930116764], [99945.02915244004 -260.44045427289296 296.3127199332182; -260.44045427289296 99560.21590304619 469.28951162677026; 296.3127199332182 469.28951162677026 100006.63515259]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.638780e+03
      1       1.042197e+03      -5.965825e+02 |        8
      2       9.814030e+02      -6.079407e+01 |        2
      3       9.702767e+02      -1.112629e+01 |        2
      4       9.664223e+02      -3.854456e+00 |        3
      5       9.263774e+02      -4.004485e+01 |        2
      6       9.209464e+02      -5.431050e+00 |        0
      7       9.209464e+02       0.000000e+00 |        0
K-means converged with 7 iterations (objv = 920.9463610395724)
┌ Info: K-means with 272 data points using 7 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.067069
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.807835
[ Info: iteration 2, lowerbound -3.706865
[ Info: iteration 3, lowerbound -3.608963
[ Info: iteration 4, lowerbound -3.503898
[ Info: iteration 5, lowerbound -3.401215
[ Info: iteration 6, lowerbound -3.310735
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.232013
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -3.154389
[ Info: iteration 9, lowerbound -3.084393
[ Info: iteration 10, lowerbound -3.032103
[ Info: dropping number of Gaussions to 5
[ Info: iteration 11, lowerbound -2.980760
[ Info: dropping number of Gaussions to 4
[ Info: iteration 12, lowerbound -2.916011
[ Info: iteration 13, lowerbound -2.836061
[ Info: iteration 14, lowerbound -2.747639
[ Info: iteration 15, lowerbound -2.656999
[ Info: iteration 16, lowerbound -2.572818
[ Info: iteration 17, lowerbound -2.502526
[ Info: dropping number of Gaussions to 3
[ Info: iteration 18, lowerbound -2.436013
[ Info: iteration 19, lowerbound -2.383684
[ Info: iteration 20, lowerbound -2.347382
[ Info: iteration 21, lowerbound -2.321836
[ Info: iteration 22, lowerbound -2.308695
[ Info: dropping number of Gaussions to 2
[ Info: iteration 23, lowerbound -2.303158
[ Info: iteration 24, lowerbound -2.299265
[ Info: iteration 25, lowerbound -2.299258
[ Info: iteration 26, lowerbound -2.299255
[ Info: iteration 27, lowerbound -2.299254
[ Info: iteration 28, lowerbound -2.299254
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Jan 15 01:30:06 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Jan 15 01:30:14 2020: K-means with 272 data points using 7 iterations
11.3 data points per parameter
, Wed Jan 15 01:30:16 2020: EM with 272 data points 0 iterations avll -2.067069
5.8 data points per parameter
, Wed Jan 15 01:30:18 2020: GMM converted to Variational GMM
, Wed Jan 15 01:30:26 2020: iteration 1, lowerbound -3.807835
, Wed Jan 15 01:30:26 2020: iteration 2, lowerbound -3.706865
, Wed Jan 15 01:30:26 2020: iteration 3, lowerbound -3.608963
, Wed Jan 15 01:30:26 2020: iteration 4, lowerbound -3.503898
, Wed Jan 15 01:30:26 2020: iteration 5, lowerbound -3.401215
, Wed Jan 15 01:30:26 2020: iteration 6, lowerbound -3.310735
, Wed Jan 15 01:30:27 2020: dropping number of Gaussions to 7
, Wed Jan 15 01:30:27 2020: iteration 7, lowerbound -3.232013
, Wed Jan 15 01:30:27 2020: dropping number of Gaussions to 6
, Wed Jan 15 01:30:27 2020: iteration 8, lowerbound -3.154389
, Wed Jan 15 01:30:27 2020: iteration 9, lowerbound -3.084393
, Wed Jan 15 01:30:27 2020: iteration 10, lowerbound -3.032103
, Wed Jan 15 01:30:27 2020: dropping number of Gaussions to 5
, Wed Jan 15 01:30:27 2020: iteration 11, lowerbound -2.980760
, Wed Jan 15 01:30:27 2020: dropping number of Gaussions to 4
, Wed Jan 15 01:30:27 2020: iteration 12, lowerbound -2.916011
, Wed Jan 15 01:30:27 2020: iteration 13, lowerbound -2.836061
, Wed Jan 15 01:30:27 2020: iteration 14, lowerbound -2.747639
, Wed Jan 15 01:30:27 2020: iteration 15, lowerbound -2.656999
, Wed Jan 15 01:30:27 2020: iteration 16, lowerbound -2.572818
, Wed Jan 15 01:30:27 2020: iteration 17, lowerbound -2.502526
, Wed Jan 15 01:30:27 2020: dropping number of Gaussions to 3
, Wed Jan 15 01:30:27 2020: iteration 18, lowerbound -2.436013
, Wed Jan 15 01:30:27 2020: iteration 19, lowerbound -2.383684
, Wed Jan 15 01:30:27 2020: iteration 20, lowerbound -2.347382
, Wed Jan 15 01:30:27 2020: iteration 21, lowerbound -2.321836
, Wed Jan 15 01:30:27 2020: iteration 22, lowerbound -2.308695
, Wed Jan 15 01:30:27 2020: dropping number of Gaussions to 2
, Wed Jan 15 01:30:27 2020: iteration 23, lowerbound -2.303158
, Wed Jan 15 01:30:27 2020: iteration 24, lowerbound -2.299265
, Wed Jan 15 01:30:27 2020: iteration 25, lowerbound -2.299258
, Wed Jan 15 01:30:27 2020: iteration 26, lowerbound -2.299255
, Wed Jan 15 01:30:27 2020: iteration 27, lowerbound -2.299254
, Wed Jan 15 01:30:27 2020: iteration 28, lowerbound -2.299254
, Wed Jan 15 01:30:27 2020: iteration 29, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 30, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 31, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 32, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 33, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 34, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 35, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 36, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 37, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 38, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 39, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 40, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 41, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 42, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 43, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 44, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 45, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 46, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 47, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 48, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 49, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: iteration 50, lowerbound -2.299253
, Wed Jan 15 01:30:27 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222602425, 95.95490777397573]
β = [178.04509222602425, 95.95490777397573]
m = [4.250300733269826 79.2868669443606; 2.000229257775283 53.85198717246082]
ν = [180.04509222602425, 97.95490777397573]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554748383 -0.007644049042328645; 0.0 0.008581705166331962], [0.3758763611949811 -0.008953123827347335; 0.0 0.012748664777409576]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -0.9923806715170272
avll from llpg:  -0.9923806715170272
avll direct:     -0.9923806715170274
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9931731616379801
avll from llpg:  -0.9931731616379801
avll direct:     -0.9931731616379801
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0483064   -0.00418717   0.21214     -0.0252789   -0.088329     0.188053      0.119963     0.0302731    0.0060435   -0.0510994   -0.00287043   0.0765004    0.060055     0.1191       -0.0441123   -0.0126577   -0.0757398    -0.00134465  -0.0601981    -0.0238475    0.201201    -0.005627    -0.068744    0.0565075  -0.0481752   -0.123982
  0.0736591   -0.147426     0.0241357   -0.117298     0.140705     0.184453     -0.0420004   -0.0148495   -0.0480259    0.0735088   -0.0709221   -0.00160484   0.125979    -0.030026     -0.14586      0.0775036    0.347507      0.069435    -0.0775957    -0.115673    -0.0927478    0.0491593   -0.0193093  -0.0436149  -0.0724922    0.0977955
 -0.132481    -0.0703177    0.0265119   -0.0645264   -0.166912     0.0511516    -0.0444517    0.06701      0.0203205    0.0657169    0.0785385   -0.0678824    0.0540467   -0.0287974     0.0769561   -0.0180113    0.104888      0.0594116   -0.0487528     0.0629238   -0.0437623    0.222046    -0.234808    0.0548541  -0.171156     0.0271671
 -0.116255     0.00189415  -0.172343    -0.0022099   -0.0485373    0.0409469     0.0746471    0.0421632    0.0471154   -0.0605809   -0.0507583   -0.167652     0.00395747  -0.000426762  -0.140428    -0.147359    -0.133647      0.11189     -0.10221       0.00779198  -0.0414928   -0.0549237   -0.085506    0.0996417  -0.112655     0.0767733
  0.179697    -0.0110047    0.0652587    0.141421    -0.0321735   -0.0553777     0.0499995   -0.223525     0.13969     -0.210006    -0.094269     0.105705     0.182972    -0.0355253     0.0561151   -0.0982356    0.133395      0.0132523   -0.0432547    -0.181655    -0.032372    -0.123425     0.0666138   0.134222   -0.0617589   -0.0272019
 -0.0130323    0.0782841    0.120791     0.0472273   -0.0641835   -0.000186251  -0.107581    -0.17068     -0.0147774    0.173573     0.0704448    0.0302206    0.0297992   -0.156725      0.139391    -0.180331    -0.191063     -0.00937427   0.0228326    -0.0189213    0.00602581  -0.0062625   -0.103752    0.0566239   0.0741374   -0.045162
 -0.182082     0.0665125   -0.118437     0.0290133   -0.0312432    0.058491      0.0648132    0.132342    -0.132639    -0.143241     0.0862311   -0.028321     0.129631     0.0668594    -0.111502    -0.0331509   -0.0710954    -0.0234101   -0.135616      0.0287005   -0.103525    -0.00609963   0.0124713  -0.0865936  -0.00477316   0.0287111
  0.129779    -0.0782317   -0.0284293   -0.114617    -0.0966307   -0.03077      -0.0298541   -0.0533639    0.206658    -0.073917     0.114528     0.00616185   0.113769    -0.0658265     0.0388723   -0.0579004    0.0255753     0.0192291   -0.194015     -0.103815     0.0415081    0.00318128  -0.0137876   0.0515128   0.0372586    0.0513782
 -0.0572568   -0.103765     0.187426     0.144427     0.232119    -0.0839207    -0.109054    -0.1018      -0.0985369    0.0715763   -0.111691    -0.27662     -0.268494     0.105208      0.0574275    0.143315     0.000175534   0.0687952    0.0467116    -0.146862    -0.013622     0.13441      0.0532572  -0.0190155  -0.0734875   -0.0741472
  0.152023     0.0901686   -0.0974352    0.0689748    0.0971845   -0.126003     -0.168234    -0.00692789  -0.0305095    0.18563      0.0842285    0.149597    -0.00673179   0.0734816    -0.016281     0.0344325    0.0179326     0.0927016    0.000138517   0.172576    -0.0973285    0.171826    -0.181812   -0.0812467   0.0383929    0.12011
 -0.0784553    0.227991    -0.031212     0.0824172    0.0224677    0.0195902     0.0752788   -0.126358    -0.0217424   -0.0011888    0.0172642    0.138715    -0.0504295    0.179054     -0.0262577   -0.0761032    0.034146      0.11978     -0.0523155     0.0167101    0.147087     0.153735     0.0883636  -0.170502    0.00614364  -0.0169704
  0.0887385    0.0432299   -0.209868    -0.132407     0.0737038    0.06027       0.0339168   -0.113505     0.103087    -0.129649    -0.260511    -0.118194     0.027537     0.179722      0.104898     0.107076    -0.0367031    -0.0269911    0.167568      0.0829964    0.0389902   -0.0970137    0.0850456   0.145077   -0.100503    -0.0586766
 -0.101531     0.0550192   -0.0430361   -0.0174456    0.113642    -0.0108244     0.00714049  -0.0425961    0.073343    -0.0151368    0.145883     0.084048    -0.0203777   -0.0316686     0.00722174  -0.0626968    0.00618793   -0.00165932   0.0874082    -0.0171246   -0.0680218   -0.0328543   -0.144248    0.022775    0.0850701   -0.0673441
 -0.019164    -0.0275274    0.0794347    0.0076409    0.0343635    0.0916935    -0.141889     0.160398    -0.11247      0.0975187    0.00536889  -0.06921      0.0223173    0.204457     -0.0714969   -0.0726228    0.0072931     0.243915     0.0228665    -0.0149511    0.0274761    0.0988026    0.0110388  -0.0263077   0.164598    -0.144803
 -0.0427489    0.094315    -0.102724    -0.11979     -0.0438472   -0.150325      0.141501    -0.0268405   -0.135643    -0.113515    -0.0746391   -0.00113051  -0.0705651   -0.0560441     0.0601641    0.138617    -0.144729      0.0299638   -0.0730787     0.0829597    0.109507    -0.0848991    0.0357441  -0.0968775   0.0541875    0.0587434
  0.158541     0.235939    -0.0577533   -0.0578312   -0.0491126   -0.0557405    -0.152394     0.0118813   -0.00850756   0.0424849   -0.118871    -0.0866629   -0.106957    -0.00148217   -0.0620201    0.0760956    0.0602583     0.021179    -0.177492      0.0474191   -0.163565    -0.0240998   -0.302183   -0.0341483  -0.0308467    0.167577
  0.0280502   -0.10004     -0.0412538   -0.0181412    0.0799711    0.132493      0.0115152    0.0433513   -0.0733735    0.0668823    0.11406     -0.119826    -0.0852855    0.0264176     0.0105618    0.24583     -0.0236935     0.0668536   -0.0145381    -0.0446619    0.0783       0.00323955  -0.13009     0.074498    0.0612991    0.0141212
  0.00476586  -0.0204121    0.00541246  -0.180055     0.0121847   -0.11482      -0.0781219   -0.0598691    0.0336197   -0.177177     0.132826    -0.0692621   -0.160098     0.0450881    -0.0642328   -0.030316     0.0388595     0.0336843    0.226977      0.276217    -0.0337259    0.0760234   -0.0644839  -0.0195185  -0.187996     0.152055
 -0.0254583    0.0956658   -0.182215    -0.0653175    0.00689137   0.0454249     0.0600744    0.0685429    0.0220405    0.00534624  -0.0642512    0.0817827   -0.0931156   -0.0365737     0.0282796    0.0890248    0.168253      0.0285174   -0.0620355     0.0919197   -0.174282     0.0299738   -0.0365009   0.064829   -0.018846     0.0171752
  0.0155791    0.0655295   -0.0280629    0.0313319    0.0295251    0.0176226    -0.0167474    0.12808      0.0418658   -0.0552752   -0.0527661   -0.0270887   -0.0128632   -0.0898253     0.0289509    0.13208     -0.0889073    -0.0275275   -0.096997      0.061458    -0.0342871   -0.161086     0.0144928   0.179963    0.00724581   0.00951199
 -0.0350104   -0.170287     0.00103735   0.107026     0.0605829    0.0585513    -0.141546     0.0272539    0.0555943    0.00585783  -0.00799429  -0.0090073   -0.0848985    0.154884     -0.042051     0.0639425    0.0149569     0.214809    -0.0372363     0.0307699    0.0991943    0.221558    -0.0478959  -0.126748   -0.0669813   -0.110787
 -0.0709914   -0.0127787   -0.0799085    0.0432022    0.207268     0.0281781    -0.00470336   0.0875592   -0.157041    -0.0947637   -0.13176     -0.176276    -0.0584855    0.104622      0.108934     0.0821565    0.104268      0.0731684   -0.0895956     0.0548508   -0.114879     0.152779    -0.002472    0.0987745  -0.0916666    0.00859851
 -0.00875036   0.0358115    0.0342814    0.0294226   -0.175089     0.108629     -0.0142556    0.0459235   -0.0790997   -0.0291285   -0.0494283    0.107566    -0.0582181   -0.0507048    -0.0763002   -0.211605    -0.0437154    -0.0766295    0.0548304     0.0801208    0.0130281    0.131444    -0.11401    -0.110861   -0.0238008    0.0724407
  0.0164295    0.146684     0.0580171   -0.127597    -0.0573813   -0.0916067    -0.00479915  -0.154494     0.14345     -0.0144563   -0.125372    -0.0691299    0.0130798    0.0455665     0.043809     0.22639     -0.00837234   -0.00753546   0.159728     -0.152748    -0.0924765   -0.177551    -0.0398075  -0.0865402   0.0363306    0.194787
 -0.124549     0.0561036    0.0764052   -0.00934963  -0.0388299    0.0338291     0.0652048   -0.0578882   -0.128825     0.0318549   -0.00872918   0.0247349    0.121845     0.00621547    0.0191975   -0.0108782    0.125121     -0.0611092   -0.0454888    -0.00247721  -0.0229466    0.0120665   -0.0393964  -0.0319041   0.0165333    0.0772284
 -0.0157295   -0.0540203    0.152412    -0.0187853   -0.0156006    0.255944     -0.041166     0.0136621   -0.103185    -0.0475568    0.0186666   -0.0770529    0.0552544   -0.0436902     0.0100311    0.017933     0.0906253    -0.182922     0.0864407     0.0215757   -0.0353839    0.05703     -0.146472    0.0213269   0.0469309    0.0320598
 -0.177634    -0.16474     -0.0903551    0.00371831  -0.123359    -0.282433     -0.0514474    0.254375     0.0451676    0.0236783   -0.0613373   -0.0974446    0.154656     0.11508       0.123148     0.00762854   0.0901144    -0.00744218   0.040689      0.077683     0.132883     0.00155145   0.031832    0.0172917   0.0363344   -0.0333606
 -0.0809561   -0.0881333    0.0940073    0.0432759   -0.0648215   -0.0148155    -0.0210411    0.0427351   -0.120215    -0.0507013    0.00708979  -0.125999     0.0575622    0.0734747     0.062921     0.107706     0.0189661    -0.0671003   -0.0569391     0.161613    -0.122705    -0.050655    -0.0345046  -0.126438    0.122858     0.0897429
 -0.0881006   -0.19071     -0.00136006  -0.0022113    0.065396     0.146946     -0.0467647    0.0448187   -0.0433998   -0.139476    -0.0946107    0.0143955   -0.0272525    0.0334181    -0.171199    -0.036953     0.0749966    -0.114928     0.0761845    -0.198843     0.126389    -0.0533292   -0.0279423   0.0991019  -0.0076524   -0.0229276
  0.216462    -0.116532    -0.0155105   -0.112664    -0.00136023  -0.0814814     0.0453511    0.0260744   -0.0738206   -0.155293     0.129704     0.0763515    0.0283701   -0.0180134     0.0193664    0.0691449    0.111986     -0.00114829   0.0130036    -0.0670021    0.0198599    0.0854812    0.0126419   0.198548   -0.00781338   0.0823181
  0.0773994    0.0526302    0.134149     0.0287832    0.0373657   -0.0786359    -0.0171574   -0.00828239   0.0723016    0.00010886   0.0662626   -0.138484    -0.0054926    0.167274     -0.00948012   0.103376    -0.082303     -0.157564     0.0287492    -0.0839215   -0.0289605   -0.0178712   -0.0108041  -0.092507    0.0550133   -0.0625371
  0.233025    -0.0226037   -0.125759    -0.0843859   -0.0420889   -0.0607852    -0.0463279   -0.0724912    0.128479    -0.137491     0.0836372    0.263619    -0.228233    -0.0723416     0.0849216    0.0705964    0.0582235     0.110979     0.124865      0.212873    -0.00147422   0.158042     0.1367     -0.0747326  -0.0548329    0.0968851kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4168533844419395
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416987
[ Info: iteration 2, average log likelihood -1.416896
[ Info: iteration 3, average log likelihood -1.416675
[ Info: iteration 4, average log likelihood -1.413417
[ Info: iteration 5, average log likelihood -1.395888
[ Info: iteration 6, average log likelihood -1.383013
[ Info: iteration 7, average log likelihood -1.381512
[ Info: iteration 8, average log likelihood -1.381141
[ Info: iteration 9, average log likelihood -1.380926
[ Info: iteration 10, average log likelihood -1.380778
[ Info: iteration 11, average log likelihood -1.380665
[ Info: iteration 12, average log likelihood -1.380574
[ Info: iteration 13, average log likelihood -1.380499
[ Info: iteration 14, average log likelihood -1.380433
[ Info: iteration 15, average log likelihood -1.380372
[ Info: iteration 16, average log likelihood -1.380302
[ Info: iteration 17, average log likelihood -1.380201
[ Info: iteration 18, average log likelihood -1.380024
[ Info: iteration 19, average log likelihood -1.379757
[ Info: iteration 20, average log likelihood -1.379525
[ Info: iteration 21, average log likelihood -1.379397
[ Info: iteration 22, average log likelihood -1.379331
[ Info: iteration 23, average log likelihood -1.379292
[ Info: iteration 24, average log likelihood -1.379266
[ Info: iteration 25, average log likelihood -1.379247
[ Info: iteration 26, average log likelihood -1.379233
[ Info: iteration 27, average log likelihood -1.379222
[ Info: iteration 28, average log likelihood -1.379213
[ Info: iteration 29, average log likelihood -1.379205
[ Info: iteration 30, average log likelihood -1.379199
[ Info: iteration 31, average log likelihood -1.379194
[ Info: iteration 32, average log likelihood -1.379190
[ Info: iteration 33, average log likelihood -1.379186
[ Info: iteration 34, average log likelihood -1.379183
[ Info: iteration 35, average log likelihood -1.379181
[ Info: iteration 36, average log likelihood -1.379178
[ Info: iteration 37, average log likelihood -1.379176
[ Info: iteration 38, average log likelihood -1.379175
[ Info: iteration 39, average log likelihood -1.379173
[ Info: iteration 40, average log likelihood -1.379172
[ Info: iteration 41, average log likelihood -1.379171
[ Info: iteration 42, average log likelihood -1.379170
[ Info: iteration 43, average log likelihood -1.379169
[ Info: iteration 44, average log likelihood -1.379168
[ Info: iteration 45, average log likelihood -1.379167
[ Info: iteration 46, average log likelihood -1.379167
[ Info: iteration 47, average log likelihood -1.379166
[ Info: iteration 48, average log likelihood -1.379165
[ Info: iteration 49, average log likelihood -1.379165
[ Info: iteration 50, average log likelihood -1.379164
┌ Info: EM with 100000 data points 50 iterations avll -1.379164
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4169865480193868
│     -1.4168955482257
│      ⋮
└     -1.3791641790228981
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.379352
[ Info: iteration 2, average log likelihood -1.379190
[ Info: iteration 3, average log likelihood -1.378639
[ Info: iteration 4, average log likelihood -1.372628
[ Info: iteration 5, average log likelihood -1.353835
[ Info: iteration 6, average log likelihood -1.339486
[ Info: iteration 7, average log likelihood -1.334597
[ Info: iteration 8, average log likelihood -1.332776
[ Info: iteration 9, average log likelihood -1.331775
[ Info: iteration 10, average log likelihood -1.331121
[ Info: iteration 11, average log likelihood -1.330654
[ Info: iteration 12, average log likelihood -1.330288
[ Info: iteration 13, average log likelihood -1.329986
[ Info: iteration 14, average log likelihood -1.329732
[ Info: iteration 15, average log likelihood -1.329520
[ Info: iteration 16, average log likelihood -1.329342
[ Info: iteration 17, average log likelihood -1.329187
[ Info: iteration 18, average log likelihood -1.329053
[ Info: iteration 19, average log likelihood -1.328941
[ Info: iteration 20, average log likelihood -1.328854
[ Info: iteration 21, average log likelihood -1.328789
[ Info: iteration 22, average log likelihood -1.328740
[ Info: iteration 23, average log likelihood -1.328703
[ Info: iteration 24, average log likelihood -1.328673
[ Info: iteration 25, average log likelihood -1.328647
[ Info: iteration 26, average log likelihood -1.328621
[ Info: iteration 27, average log likelihood -1.328596
[ Info: iteration 28, average log likelihood -1.328570
[ Info: iteration 29, average log likelihood -1.328544
[ Info: iteration 30, average log likelihood -1.328517
[ Info: iteration 31, average log likelihood -1.328491
[ Info: iteration 32, average log likelihood -1.328465
[ Info: iteration 33, average log likelihood -1.328439
[ Info: iteration 34, average log likelihood -1.328414
[ Info: iteration 35, average log likelihood -1.328392
[ Info: iteration 36, average log likelihood -1.328373
[ Info: iteration 37, average log likelihood -1.328357
[ Info: iteration 38, average log likelihood -1.328343
[ Info: iteration 39, average log likelihood -1.328333
[ Info: iteration 40, average log likelihood -1.328325
[ Info: iteration 41, average log likelihood -1.328319
[ Info: iteration 42, average log likelihood -1.328314
[ Info: iteration 43, average log likelihood -1.328311
[ Info: iteration 44, average log likelihood -1.328309
[ Info: iteration 45, average log likelihood -1.328307
[ Info: iteration 46, average log likelihood -1.328306
[ Info: iteration 47, average log likelihood -1.328305
[ Info: iteration 48, average log likelihood -1.328305
[ Info: iteration 49, average log likelihood -1.328304
[ Info: iteration 50, average log likelihood -1.328304
┌ Info: EM with 100000 data points 50 iterations avll -1.328304
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3793520568396869
│     -1.379190188197198
│      ⋮
└     -1.3283040008158387
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.328517
[ Info: iteration 2, average log likelihood -1.328347
[ Info: iteration 3, average log likelihood -1.328017
[ Info: iteration 4, average log likelihood -1.324083
[ Info: iteration 5, average log likelihood -1.307321
[ Info: iteration 6, average log likelihood -1.286626
[ Info: iteration 7, average log likelihood -1.277126
[ Info: iteration 8, average log likelihood -1.273504
[ Info: iteration 9, average log likelihood -1.271591
[ Info: iteration 10, average log likelihood -1.270316
[ Info: iteration 11, average log likelihood -1.269408
[ Info: iteration 12, average log likelihood -1.268688
[ Info: iteration 13, average log likelihood -1.267998
[ Info: iteration 14, average log likelihood -1.267347
[ Info: iteration 15, average log likelihood -1.266774
[ Info: iteration 16, average log likelihood -1.266271
[ Info: iteration 17, average log likelihood -1.265761
[ Info: iteration 18, average log likelihood -1.265140
[ Info: iteration 19, average log likelihood -1.264413
[ Info: iteration 20, average log likelihood -1.263677
[ Info: iteration 21, average log likelihood -1.263152
[ Info: iteration 22, average log likelihood -1.262881
[ Info: iteration 23, average log likelihood -1.262741
[ Info: iteration 24, average log likelihood -1.262631
[ Info: iteration 25, average log likelihood -1.262504
[ Info: iteration 26, average log likelihood -1.262350
[ Info: iteration 27, average log likelihood -1.262173
[ Info: iteration 28, average log likelihood -1.261982
[ Info: iteration 29, average log likelihood -1.261811
[ Info: iteration 30, average log likelihood -1.261685
[ Info: iteration 31, average log likelihood -1.261593
[ Info: iteration 32, average log likelihood -1.261521
[ Info: iteration 33, average log likelihood -1.261458
[ Info: iteration 34, average log likelihood -1.261397
[ Info: iteration 35, average log likelihood -1.261337
[ Info: iteration 36, average log likelihood -1.261280
[ Info: iteration 37, average log likelihood -1.261225
[ Info: iteration 38, average log likelihood -1.261174
[ Info: iteration 39, average log likelihood -1.261126
[ Info: iteration 40, average log likelihood -1.261082
[ Info: iteration 41, average log likelihood -1.261044
[ Info: iteration 42, average log likelihood -1.261010
[ Info: iteration 43, average log likelihood -1.260980
[ Info: iteration 44, average log likelihood -1.260954
[ Info: iteration 45, average log likelihood -1.260930
[ Info: iteration 46, average log likelihood -1.260907
[ Info: iteration 47, average log likelihood -1.260884
[ Info: iteration 48, average log likelihood -1.260862
[ Info: iteration 49, average log likelihood -1.260839
[ Info: iteration 50, average log likelihood -1.260816
┌ Info: EM with 100000 data points 50 iterations avll -1.260816
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3285172331735973
│     -1.32834724178318
│      ⋮
└     -1.260816319050795
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.261087
[ Info: iteration 2, average log likelihood -1.260710
[ Info: iteration 3, average log likelihood -1.258739
[ Info: iteration 4, average log likelihood -1.242180
[ Info: iteration 5, average log likelihood -1.212667
[ Info: iteration 6, average log likelihood -1.188351
[ Info: iteration 7, average log likelihood -1.170690
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.161525
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.161967
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.174478
[ Info: iteration 11, average log likelihood -1.172640
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.162193
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.163336
[ Info: iteration 14, average log likelihood -1.176523
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.163251
[ Info: iteration 16, average log likelihood -1.164940
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.156870
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.174212
[ Info: iteration 19, average log likelihood -1.168820
[ Info: iteration 20, average log likelihood -1.160270
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.154455
[ Info: iteration 22, average log likelihood -1.179230
[ Info: iteration 23, average log likelihood -1.162595
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.153888
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.166727
[ Info: iteration 26, average log likelihood -1.176875
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.162975
[ Info: iteration 28, average log likelihood -1.164679
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.156617
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.174254
[ Info: iteration 31, average log likelihood -1.168838
[ Info: iteration 32, average log likelihood -1.160346
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.154753
[ Info: iteration 34, average log likelihood -1.180202
[ Info: iteration 35, average log likelihood -1.164615
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.158626
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.160799
[ Info: iteration 38, average log likelihood -1.175944
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.162896
[ Info: iteration 40, average log likelihood -1.164678
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.156621
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.174251
[ Info: iteration 43, average log likelihood -1.168850
[ Info: iteration 44, average log likelihood -1.160360
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.154760
[ Info: iteration 46, average log likelihood -1.180177
[ Info: iteration 47, average log likelihood -1.164628
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.158618
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.160742
[ Info: iteration 50, average log likelihood -1.175789
┌ Info: EM with 100000 data points 50 iterations avll -1.175789
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2610872414497203
│     -1.2607100047714903
│      ⋮
└     -1.1757886236199036
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.163053
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.158044
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     13
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.150858
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.139219
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     14
│     20
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.090303
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.088998
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.066990
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.094855
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     14
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.063561
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.079747
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.059928
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.083547
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.055806
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.078188
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.067509
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.070831
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     11
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.044107
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.087966
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.052558
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.065197
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.051634
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.074966
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.047393
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     11
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.068873
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.072070
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.066299
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│      9
│     11
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.041177
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.084572
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.063569
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.060237
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.056583
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.068047
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.062516
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.076733
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.047422
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      8
│     11
│     19
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.061135
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.077808
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.067889
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     11
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.041064
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.076968
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.069289
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.061816
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.056396
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.067867
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.062560
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.076725
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.047411
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      8
│     11
│     19
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.061149
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.077802
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.067897
┌ Info: EM with 100000 data points 50 iterations avll -1.067897
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1630531638102828
│     -1.1580442347124655
│      ⋮
└     -1.0678965028574152
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4168533844419395
│     -1.4169865480193868
│     -1.4168955482257
│     -1.4166753665706502
│      ⋮
│     -1.0611488285050061
│     -1.077801632834003
└     -1.0678965028574152
32×26 Array{Float64,2}:
  0.0922153   -0.123553     -0.00402489  -0.143672     0.0190301    0.0774666  -0.0423372   -0.0302812   0.0763479   -0.00211067   0.0139906    0.00411494   0.132457     -0.0442656    -0.0530233   0.00748324   0.179587     0.0256343    -0.134364    -0.144432    -0.00808018    0.020375    -0.0244536   0.00170027  -0.0401511    0.079408
 -0.12424      0.0616185     0.0788997   -0.00946612  -0.0463481    0.0227101   0.035595    -0.0672658  -0.118585     0.0361986   -0.0350581    0.0401805    0.124456      0.0057499     0.01837    -0.0135636    0.178814    -0.000389819  -0.0550389    0.0428564    0.00202135    0.0138444   -0.0648923  -0.050529     0.00482159   0.0999043
 -0.0675344    0.0502665    -0.11204     -0.105325    -1.02533     -0.149926    0.088617    -0.0306373  -0.0745052   -0.128609    -0.0573751   -8.99535e-5  -0.0870156    -0.0774415     0.0658263   0.0997774   -0.26731      0.0174713    -0.190645    -0.0723826    0.092507     -0.140384     0.0739542  -0.0542345    0.0238882    0.0599502
 -0.016638     0.131754     -0.0930047   -0.140581     0.820794    -0.150888    0.165756    -0.0246299  -0.193413    -0.11198     -0.090923    -0.0053038   -0.0515691    -0.0622344     0.0559963   0.142864     0.0114152   -0.0128951    -0.0186838    0.137201     0.124436     -0.0479313    0.0506256  -0.133817     0.0799915    0.0533945
 -0.184943     0.0642147    -0.113509     0.0270849   -0.02899      0.0492737   0.0551085    0.120225   -0.175181    -0.126245     0.0754273   -0.0176207    0.120123      0.0639074    -0.0956537  -0.00176454  -0.0560484   -0.0213391    -0.131117     0.0131618   -0.0993881    -0.00417932   0.0241246  -0.0759697    0.00644139   0.0286991
  0.0489499   -0.0529463    -0.046377    -0.0972498    0.0974313   -0.0524695   0.00714211   0.0194474  -0.0808494   -0.151682     0.035558    -0.0455376   -0.0581392     0.0426082     0.0139097   0.0418302    0.0937561    0.0330505     0.0460389    0.0788833   -0.0429416     0.104145    -0.0189565   0.104885    -0.0873881    0.0834674
  0.00236898   0.0362522     0.0445088    0.0135404   -0.173517     0.107943    0.00148246   0.0348264  -0.0750107   -0.0264802   -0.0458608    0.106314    -0.0531463    -0.0511603    -0.0777231  -0.22716     -0.0570072   -0.104337      0.0572211    0.0976795    0.0146693     0.148866    -0.103513   -0.0612615   -0.016263     0.0908501
  0.174649    -0.0106799     0.021548     0.134347    -0.0316888   -0.0564105   0.0511824   -0.22308     0.173689    -0.208068    -0.0863188    0.104803     0.181352     -0.0339111     0.0576357  -0.126536     0.101857    -0.0391789    -0.0596573   -0.181834    -0.00803721   -0.114677     0.0662399   0.141       -0.0598625   -0.0293415
 -0.0940875   -0.214198     -0.00514249  -0.0223877    0.0629371    0.150416   -0.0473647    0.0483811  -0.0579315   -0.137638    -0.116437     0.00554205  -0.0225054     0.08747      -0.205652   -0.00332124   0.0730421   -0.124628      0.0757936   -0.178866     0.132901     -0.0572937   -0.0307908   0.107542     0.00856583  -0.0172302
 -0.0393377   -0.0270466     0.0451615    0.0625975   -0.0262083    0.0108772  -0.00491262   0.0802333  -0.0429307   -0.0525279   -0.019996    -0.0773168    0.0342179    -0.00275665    0.0485005   0.142673    -0.0270463   -0.0504735    -0.0663568    0.124567    -0.0832183    -0.0855123   -0.0191947   0.0207838    0.0517406    0.051293
 -0.170164    -0.154225     -0.0796468    4.84518e-5  -0.118188    -0.270552   -0.0585041    0.247125   -0.00219558   0.00674841  -0.0710823   -0.0864414    0.137245      0.116094      0.0884278   0.00607828   0.0900325   -0.00649961    0.11963      0.0817304    0.129303     -0.00457168   0.0247082   0.00471524   0.0257139   -0.0263491
 -0.0528262   -0.0760363     0.141564    -0.0538419   -0.0209591    0.240318   -0.0278877    0.0216991  -0.108039    -0.0491899    0.00627889  -0.0799673    0.0394235    -0.0408339     0.0409855  -0.0355393    0.0860575   -0.187951      0.0846791    0.0388228   -0.0433745     0.0514491   -0.132973    0.0256172    0.0394554    0.00996387
  0.0625704    0.0965747    -0.164502    -0.0564544    0.00225153   0.031152    0.0522788    0.0711684   0.0222534    0.00807507  -0.0637093    0.0803321   -0.0898093    -0.0613744     0.0281367   0.102855     0.161509     0.0358954    -0.0647998    0.0440729   -0.169918      0.0264803   -0.037639    0.059502    -0.0140797   -0.0177273
 -0.0103527    0.147861      0.058072    -0.169292    -0.045846    -0.0910992  -0.00491297  -0.204338    0.144576    -0.0143903   -0.131273    -0.0517876    0.00670035    0.0453836     0.0228175   0.198892    -0.00635296  -0.00969951    0.163563    -0.14239     -0.120915     -0.179818    -0.0409762  -0.0859532    0.0374609    0.148704
  0.193171     0.0916385    -0.103745     0.172149     0.12514     -0.226632   -0.201061    -0.034697   -0.0406356    0.187146     0.0943968    0.107832    -0.000828365  -0.0883907    -0.324351    0.0188018    0.0291335    0.149525      0.14747      0.0451208   -0.218153      0.0255042   -0.114951   -0.0935333    0.0475635    0.0897242
  0.0871031    0.152186     -0.0661854    0.0481888    0.098209    -0.0466431  -0.0444274    0.0143976  -0.0213699    0.184272     0.0787955    0.158502    -0.010848      0.218677      0.282249    0.0370858   -0.00225636   0.0478723    -0.129364     0.190571     0.0549871     0.324605    -0.289169   -0.0712969    0.00814282   0.122957
  0.0904548    0.093297      0.163894    -0.026548     0.0673685   -0.0476067  -0.0148344   -0.227158   -0.00899432  -0.0642701    0.176131    -0.128083    -0.00117767    0.131187      0.0273755   0.11301     -0.0975298   -0.165705      0.0508686   -0.0730581    0.0141976     0.0119792   -0.0418681  -0.103737     0.0445746   -0.0717566
  0.12252     -0.0427218     0.00300549   0.125545    -0.0153361   -0.20129    -0.0293159    0.523896    0.24409      0.094264    -0.215789    -0.181167    -0.011094      0.27082      -0.208796    0.114825    -0.0659103   -0.142009     -0.0466282   -0.103474    -0.063524     -0.024087     0.145258   -0.0600611    0.0505024   -0.0337898
 -0.0163587   -0.0440406     0.150141     0.0188936   -0.396796    -0.236825   -0.120533     0.180448   -0.114347     0.063352     0.0100768   -0.140695    -0.0187816     0.220132     -0.0917112  -0.0665254   -0.164768     0.212595      0.0234298    0.0512271    0.0251455    -0.00290794  -0.0447442  -0.0670673    0.109986    -0.0898589
 -0.0285666   -0.0111013    -0.0111872   -0.0298997    0.817042     0.635826   -0.1498       0.198063   -0.110608     0.125514     0.00535059   0.0480285    0.0617087     0.139085     -0.0251917  -0.0284614    0.153283     0.260674      0.0232397   -0.210217     0.0274082     0.279705     0.263287    0.0437514    0.221776    -0.156157
 -0.0776625    0.242543     -0.0172085    0.108323     0.019978     0.0206349   0.0798252   -0.131237   -0.0194916    0.033125     0.00754514   0.100732    -0.0360098     0.15353      -0.0139724  -0.0703621    0.0397561    0.125384     -0.0530612    0.04119      0.125638      0.153434     0.0910109  -0.204402     0.0158337   -9.56746e-5
  0.158683     0.265515     -0.0373298   -0.0786685   -0.0466651   -0.0553842  -0.112266     0.0104842   0.00300851   0.108287    -0.0963214   -0.082966    -0.112029      0.0174426    -0.0435624   0.0796854    0.0537088    0.0237308    -0.194528     0.055453    -0.170179     -0.0246432   -0.303013   -0.0245887   -0.0294784    0.163189
 -0.0791748   -0.0675574    -0.0513699    0.0352892    0.0974703    0.0162727  -0.0791786   -0.0101059   0.0595815    0.0169948    0.0742086    0.0412795   -0.0625894     0.0390766    -0.0190588  -0.00255529   0.00593451   0.0922733     0.031024     0.0185363    0.000561154   0.101925    -0.101094   -0.0309822    0.0128451   -0.0847226
  0.00906423  -0.0201244     0.0412666    0.00519418   0.0084895    0.07309    -0.0488229   -0.0219279  -0.0364399    0.117098     0.0827349   -0.0463238   -0.0203245    -0.0690492     0.111814    0.0348666   -0.121194     0.0248066     0.00370251  -0.0776042    0.0421258    -0.0163395   -0.121939    0.073557     0.0698025   -0.020046
 -0.0495665   -0.939022      0.268545     0.091642    -0.0865524    0.112212   -0.121585     0.0260313  -0.0332639   -0.142063    -0.00998611   0.187121     0.0284564     0.119848      0.142998    0.017321    -0.0747725   -0.0045136    -0.0637334    0.214814     0.159203     -0.00531443  -0.0631871   0.0711469   -0.0481709   -0.307674
 -0.0477287    0.825241      0.107653    -0.0781734   -0.0891114    0.308678    0.304725     0.0260093   0.0584493    0.0453054   -0.00873999  -0.192271     0.151502      0.116296     -0.217265   -0.0310441   -0.0719933    0.0396797    -0.0480622   -0.252172     0.273245     -0.00484409  -0.0810425   0.0421585   -0.0487453   -0.0216142
 -0.0609632   -0.116359      0.201296     0.143909     0.293767    -0.0976897  -0.118996    -0.106035   -0.0944993    0.0637471   -0.121887    -0.284247    -0.26831       0.103548      0.0657713   0.132224     0.00132219   0.0694424     0.0556419   -0.141972    -0.019119      0.142322     0.0595349  -0.033936    -0.0608533   -0.0777409
 -0.120721     0.00253265   -0.157369     0.0196474   -0.116128     0.0412111   0.0465726    0.0457972   0.0377376   -0.0568595   -0.0462128   -0.160576     0.00967521   -0.000758735  -0.157233   -0.135276    -0.129427     0.114313     -0.0896535    0.00114589  -0.00696301   -0.042777    -0.115295    0.102754    -0.113393     0.136425
 -0.130968    -0.000782292   0.0150677   -0.0669715   -0.12371      0.0411184  -0.0370593    0.0681216  -0.167454     0.05314      0.0666271   -0.0839448    0.0761107    -0.0312444    -0.596865   -0.0209204    0.091334     0.0701778    -0.201215     0.0308232   -0.264419      0.22248     -0.227283   -0.265131    -0.10436      0.00557809
 -0.110908    -0.183967      0.0342705   -0.07534     -0.192923     0.0630654  -0.0241037    0.0611333   0.235497     0.0410043    0.0564582   -0.0590027    0.0602395    -0.0249534     0.671532   -0.0273812    0.116815     0.0794878     0.116956     0.0900344    0.164299      0.222346    -0.239087    0.302713    -0.221696     0.0229726
  0.0818012    0.0488235    -0.215641    -0.129864     0.0706242    0.0575446   0.00447921  -0.107016    0.0903243   -0.128597    -0.25327     -0.126399     0.0310363     0.169644      0.100174    0.116737    -0.039771    -0.0212526     0.16962      0.13157      0.033273     -0.0811241    0.064388    0.143013    -0.104978    -0.0530597
  0.238866    -0.0265109    -0.12206     -0.0704147   -0.0205674   -0.076209   -0.0419791   -0.0774636   0.116375    -0.137825     0.0920252    0.297393    -0.235715     -0.0725045     0.0884501   0.069718     0.0522109    0.0518984     0.133088     0.179622    -0.00612291    0.136636     0.133544   -0.0829785   -0.0575157    0.0978291[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     11
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.041063
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      8
│      9
│     11
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.031807
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     11
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.040960
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      8
│      9
│     11
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.031744
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     11
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.040959
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      8
│      9
│     11
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.031746
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     11
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.040958
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      8
│      9
│     11
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.031748
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     11
│     14
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.040958
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      8
│      9
│     11
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.031749
┌ Info: EM with 100000 data points 10 iterations avll -1.031749
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.913701e+05
      1       6.900649e+05      -2.013052e+05 |       32
      2       6.522813e+05      -3.778366e+04 |       32
      3       6.373867e+05      -1.489455e+04 |       32
      4       6.291223e+05      -8.264419e+03 |       32
      5       6.234151e+05      -5.707226e+03 |       32
      6       6.205539e+05      -2.861216e+03 |       32
      7       6.191088e+05      -1.445040e+03 |       32
      8       6.181768e+05      -9.320276e+02 |       32
      9       6.174322e+05      -7.446240e+02 |       32
     10       6.164148e+05      -1.017406e+03 |       32
     11       6.144033e+05      -2.011478e+03 |       32
     12       6.114881e+05      -2.915236e+03 |       32
     13       6.095929e+05      -1.895175e+03 |       32
     14       6.087959e+05      -7.969900e+02 |       32
     15       6.083294e+05      -4.664722e+02 |       32
     16       6.080112e+05      -3.182044e+02 |       32
     17       6.077167e+05      -2.945006e+02 |       32
     18       6.074308e+05      -2.859255e+02 |       32
     19       6.071704e+05      -2.603388e+02 |       32
     20       6.069337e+05      -2.367801e+02 |       32
     21       6.066917e+05      -2.419569e+02 |       32
     22       6.064824e+05      -2.093593e+02 |       32
     23       6.063105e+05      -1.718188e+02 |       32
     24       6.062099e+05      -1.006747e+02 |       32
     25       6.061515e+05      -5.831747e+01 |       32
     26       6.061112e+05      -4.030942e+01 |       32
     27       6.060864e+05      -2.484719e+01 |       32
     28       6.060758e+05      -1.054336e+01 |       29
     29       6.060690e+05      -6.823998e+00 |       27
     30       6.060654e+05      -3.637508e+00 |       26
     31       6.060631e+05      -2.319863e+00 |       26
     32       6.060610e+05      -2.016565e+00 |       20
     33       6.060596e+05      -1.446058e+00 |       14
     34       6.060590e+05      -5.979238e-01 |        9
     35       6.060587e+05      -2.639056e-01 |        6
     36       6.060586e+05      -1.352140e-01 |        5
     37       6.060585e+05      -1.066954e-01 |        2
     38       6.060585e+05      -1.649304e-02 |        0
     39       6.060585e+05       0.000000e+00 |        0
K-means converged with 39 iterations (objv = 606058.4783584845)
┌ Info: K-means with 32000 data points using 39 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.318016
[ Info: iteration 2, average log likelihood -1.283584
[ Info: iteration 3, average log likelihood -1.247795
[ Info: iteration 4, average log likelihood -1.212399
[ Info: iteration 5, average log likelihood -1.172247
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.127847
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     17
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.090102
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.105692
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.060421
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│     18
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.055301
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.117927
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.064185
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     10
│     16
│     18
│     20
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.028246
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.100240
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│     11
│     14
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.058876
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.079412
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.073713
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     16
│     22
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.040991
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      7
│      8
│     14
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.045619
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.126086
[ Info: iteration 21, average log likelihood -1.095266
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      8
│     10
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.009166
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.098441
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.098440
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.050557
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     10
│     16
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.040091
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.066634
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     11
│     14
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.059901
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.083597
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     16
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.038021
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     20
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.060589
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.082592
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     14
│     16
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.042210
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      8
│     18
│     20
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.045156
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      7
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.113331
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.077928
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.055528
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     11
│     14
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.051670
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.078657
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     10
│     18
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.065898
[ Info: iteration 41, average log likelihood -1.103106
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     11
│     14
│     20
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.018139
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     18
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.072575
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.111893
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.050811
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      8
│     11
│     16
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.021369
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│     10
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.083660
[ Info: iteration 48, average log likelihood -1.108600
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     14
│     16
│     18
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.016203
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     10
│     11
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.081259
┌ Info: EM with 100000 data points 50 iterations avll -1.081259
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.204982     0.0695884    -0.114804      0.0306232   -0.0374689    0.0547804    0.0631998     0.119433     -0.18808     -0.134728      0.0721605   -0.0197949    0.125519     0.0662306    -0.100913   -0.0223185    -0.0624729   -0.0233587    -0.126798     0.0166534    -0.107447     -0.00508844   0.0285818    -0.0891081    0.008727      0.0276381
  0.134503     0.117117     -0.0768976     0.103427     0.111647    -0.133353    -0.119123     -0.00778946   -0.0280721    0.179061      0.0814249    0.125927    -0.00398439   0.0659241    -0.0200448   0.0287804     0.0169394    0.0926644     0.00960538   0.0910299    -0.0890135     0.166239    -0.1941       -0.0818788    0.0266106     0.112945
 -0.0777391    0.247261     -0.017242      0.10681      0.0179214    0.022526     0.0796919    -0.132046     -0.0195566    0.0349916     0.00951721   0.101369    -0.0373832    0.154789     -0.0117096  -0.0709894     0.0411108    0.125159     -0.0527894    0.04145       0.127301      0.154556     0.0897546    -0.205852     0.016205      0.000321614
  0.23642     -0.023532     -0.125644     -0.0782034   -0.0259319   -0.0722996   -0.0361715    -0.0718541     0.119963    -0.13469       0.0980003    0.282088    -0.23512     -0.0725784     0.0857828   0.0606726     0.0502135    0.0429187     0.12281      0.176654     -0.0161298     0.138618     0.122167     -0.0795282   -0.0560747     0.0981417
 -0.025272    -0.0252858    -0.0129172    -0.167109     0.043023    -0.112878    -0.0731057    -0.0568811     0.0328828   -0.169148      0.127339    -0.0656487   -0.154335     0.0420405    -0.0630076  -0.0268095     0.0498134    0.0289277     0.223498     0.266773     -0.0316445     0.0640651   -0.0885035    -0.00616093  -0.167226      0.157026
 -0.00765221   0.0479276     0.131858      0.0447368   -0.065878     0.032821    -0.115774     -0.133535     -0.0168685    0.171506      0.0696857    0.0293228    0.0454816   -0.162672      0.180273   -0.171741     -0.189569    -0.0167945     0.0272785   -0.00171211    0.00659353   -0.0320486   -0.106059      0.0692393    0.0847445    -0.0485592
 -0.0610921   -0.0190156    -0.0741308    -0.00252717   0.19958      0.0234291    0.00200887    0.0985993    -0.139071    -0.124785     -0.111571    -0.137417    -0.00767679   0.0942801     0.0678468   0.0794278     0.109525     0.0538807    -0.0736577    0.043708     -0.097396      0.163063    -0.000753705   0.101613    -0.0764172     0.0158487
 -0.0989956    0.0669103    -0.121253      0.00372315   0.151963    -0.00635754   0.00292962   -0.0204537     0.0746766    0.000368959   0.150576     0.14052     -0.0724572   -0.0895067     0.0102705  -0.100862      0.0082996   -0.0155045     0.0833266   -0.000268607  -0.0841583    -0.0308275   -0.151889      0.0544576    0.0793639    -0.0675866
 -0.0398754   -0.0841808     0.127749     -0.0495405   -0.022255     0.199368    -0.0220564     0.0316366    -0.0805418   -0.0436881    -0.0278586   -0.0758911    0.0565288   -0.0295922     0.0363928  -0.0101812     0.0834897   -0.178593      0.119923     0.0442681    -0.0388783     0.0512825   -0.139356      0.0125786    0.0448538     0.0261015
 -0.0173029   -0.0304032     0.115674     -0.00111574   0.232134     0.181773    -0.137189      0.200865     -0.137043     0.0895807     0.009238    -0.0677954   -0.0194103    0.188995     -0.0678426  -0.0557578    -0.0454395    0.236415      0.0244259   -0.0793097     0.0250881     0.158807     0.110446     -0.0247294    0.174799     -0.120377
 -0.0949201   -0.215959     -0.00588827   -0.0275433    0.0591515    0.148397    -0.0471567     0.0532326    -0.0589441   -0.13795      -0.114494     0.00637481  -0.0219845    0.0843032    -0.211649    0.000234007   0.0749042   -0.127856      0.0764571   -0.184969      0.13472      -0.0589968   -0.0308036     0.104344     0.00175672   -0.0173866
 -0.124991     0.0630208     0.0792487    -0.0063079   -0.0449336    0.0247069    0.0314414    -0.0638966    -0.125044     0.0377732    -0.0455747    0.0395489    0.125289     0.00579233    0.0176164  -0.0120191     0.18087      0.000824361  -0.0515815    0.046639      0.00440399    0.0142257   -0.0668032    -0.0560495    0.00608652    0.0977156
  0.0961348    0.0523817     0.109309      0.0143362    0.0388304   -0.0983689   -0.017645      0.000688397   0.0659048   -0.0231735     0.0411443   -0.143595     0.00353149   0.17345      -0.0392723   0.11363      -0.0761531   -0.14513       0.0217603   -0.0744719     0.000556963  -0.00483255   0.0253279    -0.0926086    0.042733     -0.0706479
 -0.102306    -0.133301      0.0928201     0.0788145   -0.0718413   -0.0413597   -0.0336399     0.0552171    -0.154421    -0.0411056     0.0295362   -0.116473     0.0619269    0.0859011     0.0573594   0.0938085     0.0240918   -0.0754691    -0.0915893    0.17913      -0.111559     -0.0314118   -0.0392942    -0.190915     0.130172      0.087267
  0.0925042   -0.028626      0.0135892    -0.0447651   -0.0998134    0.015906     0.0333391     0.0348845    -0.095782    -0.0751117     0.0338424    0.0990826   -0.0151791   -0.0355932    -0.0320604  -0.0930679     0.0243647   -0.0591457     0.0287194    0.026428      0.0228517     0.110188    -0.0529008     0.0553186   -0.00986746    0.0907135
 -0.0645505   -0.0909847    -0.00297233   -0.0583525   -0.0977971    0.0688023   -0.00445151    0.0754491     0.010306     0.0497657     0.0800654   -0.100176     0.0170637   -0.00663896    0.0376658   0.0438551     0.0412156    0.0794218    -0.033673    -0.0183067    -0.00663024    0.141803    -0.189624      0.0479037   -0.0880955     0.00983169
  0.0542055    0.0998576    -0.156407     -0.0739572    0.00142924   0.0235224    0.0516225     0.0605223     0.0229884    0.00524815   -0.0705673    0.0757247   -0.0840207   -0.0593373     0.023888    0.106623      0.158568     0.0318667    -0.0487652    0.0287763    -0.181258      0.0191955   -0.0386278     0.0543073   -0.0126241    -0.00491349
  0.0798476   -0.170089      0.045209     -0.101932     0.145988     0.167889    -0.0467798    -0.000833318  -0.0436054    0.054663     -0.0717372   -0.0088773    0.152626    -0.0274134    -0.137316    0.0754465     0.332907     0.0511785    -0.0728042   -0.211955     -0.0843327     0.0375255   -0.0282694    -0.0426614   -0.0551216     0.0824367
 -0.0468395   -0.16864      -0.000587895   0.0748486    0.0598745    0.0350149   -0.156328      0.0217283     0.0527865    0.02809      -0.00552572   0.00299837  -0.0824877    0.149105     -0.0448664   0.0664721     0.00800462   0.224171     -0.0374978    0.0728295     0.0895499     0.220903    -0.0440471    -0.110648    -0.0672512    -0.103555
 -0.125081    -0.000684513  -0.157564      0.011932    -0.107147     0.0347638    0.0350416     0.0466823     0.0373904   -0.0527003    -0.0484612   -0.16629      0.0122513   -0.000859166  -0.152965   -0.142934     -0.124559     0.112453     -0.0922825    0.00693989   -0.00286406   -0.0403872   -0.112255      0.099537    -0.109337      0.121959
 -0.0416718    0.0889123    -0.101888     -0.122792    -0.069214    -0.150296     0.128633     -0.0270959    -0.137942    -0.119579     -0.0745167   -0.00276559  -0.0679069   -0.0688197     0.0607517   0.123778     -0.123034     0.0015391    -0.100868     0.03652       0.110133     -0.0884165    0.064364     -0.0947757    0.0553634     0.0556614
  0.174852    -0.0104606     0.0214671     0.137374    -0.0312548   -0.0558504    0.049895     -0.227557      0.181359    -0.208713     -0.0904695    0.105287     0.182118    -0.0347125     0.0561309  -0.13145       0.0998476   -0.0418062    -0.0624612   -0.183857     -0.00664637   -0.116433     0.066401      0.137179    -0.063789     -0.0327026
  0.154335     0.250755     -0.0328434    -0.0688128   -0.0473489   -0.0558614   -0.108969      0.0106823     0.00335197   0.112064     -0.0986259   -0.081661    -0.105971     0.0246087    -0.0413804   0.0838445     0.0493886    0.0184181    -0.196509     0.057608     -0.175693     -0.02672     -0.297284     -0.0371423   -0.027449      0.160774
 -0.0351495   -0.0361653     0.018446      0.0145641   -0.29541     -0.112918    -0.121112      0.155112     -0.0573209    0.067428      0.00712935  -0.0749883    0.063541     0.172414     -0.0681174  -0.0477643    -0.0635011    0.203069      0.0238636    0.0130158     0.0322302    -0.00465299  -0.0196579    -0.0123404    0.0964725    -0.12608
  0.00968615   0.0644489    -0.0184664     0.0502658    0.0259032    0.0287642   -0.000880873   0.118676      0.0408091   -0.0533425    -0.0561582   -0.0270065   -0.00209699  -0.083589      0.0377324   0.186432     -0.0736912   -0.0279175    -0.0639509    0.0702969    -0.0315298    -0.160288    -0.00392545    0.185701    -0.0018154     0.00129466
 -0.0482876   -0.0359338     0.186182      0.00266373  -0.089003     0.214321     0.0975878     0.0256961     0.0104948   -0.0443167    -0.00897668  -0.00704022   0.0919635    0.117807     -0.0406297  -0.00843847   -0.0732984    0.0159318    -0.055719    -0.0234349     0.218144     -0.00485488  -0.0736621     0.0573904   -0.048159     -0.164261
  0.117465    -0.0950555    -0.0435049    -0.171324    -0.0794889   -0.0239131   -0.026624     -0.0531806     0.201614    -0.0498801     0.109598     0.0106086    0.142074    -0.0626556     0.0380954  -0.0581615     0.0237586   -0.00178319   -0.20129     -0.14005       0.0795633     0.00857842  -0.0313199     0.0488072    0.000233079   0.0732182
 -0.0294866   -0.10765      -0.0250833    -0.00608901   0.102057     0.0725535    0.0138187     0.0788003    -0.0932976    0.0329576     0.124986    -0.14135     -0.0587063    0.0255672     0.0855959   0.257463     -0.0553241    0.0272587    -0.0155707   -0.0364197     0.0724646    -0.00402965  -0.134206      0.136952     0.0815239     0.0251446
 -0.0628525   -0.109424      0.177072      0.139806     0.250251    -0.0983039   -0.105806     -0.0857603    -0.0883186    0.0622117    -0.117704    -0.271711    -0.245849     0.09933       0.0651658   0.135895      0.00294238   0.0672699     0.0549969   -0.143144     -0.0115366     0.142622     0.0511695    -0.0328786   -0.0578598    -0.0731457
  0.0827555    0.0507964    -0.219142     -0.126206     0.0704235    0.058435     0.0129969    -0.105309      0.0872365   -0.125412     -0.24748     -0.131206     0.0426229    0.175137      0.112288    0.123442     -0.0398098   -0.0231381     0.167685     0.130116      0.0374196    -0.0950357    0.0584112     0.141975    -0.101056     -0.0556956
 -0.168146    -0.176736     -0.091801      0.0176147   -0.227027    -0.250412    -0.0487681     0.235543      0.00749982   0.0179117    -0.124163    -0.0923221    0.132442     0.143928      0.119965    0.00961239    0.0805105   -0.0172035     0.157056     0.0827463     0.125151     -0.0168273    0.0924184     0.0246007    0.040653     -0.0866137
 -0.0758747    0.140301      0.0398873    -0.201124    -0.0595272   -0.0983861   -0.0098493    -0.215044      0.160104    -0.00661223   -0.135086    -0.0567517    0.0190398    0.0581678     0.0312994   0.225428      0.0101172   -0.00634585    0.174029    -0.166263     -0.123833     -0.205869    -0.0388413    -0.0903186    0.0366945     0.186847[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.064511
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     18
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.997789
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      7
│     10
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.003533
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     18
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.020151
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│     16
│     20
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.015188
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      7
│      8
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.966971
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│     10
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.058355
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     18
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.997496
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      7
│     11
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.999557
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.011210
┌ Info: EM with 100000 data points 10 iterations avll -1.011210
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0486537    0.0750677   -0.133611   -0.218217     -0.0330216    0.109231   -0.120824     -0.0284428    0.167725     0.00244666   0.0380531   -0.0568903     0.0921412    -0.104619     0.0745221    -0.136249     -0.0236172   -0.00704232   0.0417373    0.0817048   -0.0588268     0.0454234    0.00527698  -0.016015    -0.0814692   -0.185533
 -0.0202418    0.0706569   -0.158538    0.0482413     0.0169669    0.0477265   0.0273821     0.0815795   -0.140236    -0.16192      0.111227     0.121847     -0.0585352     0.0465665   -0.00409218    0.0416177     0.0267692    0.0945956   -0.0496352    0.0736105   -0.183867     -0.0949846    0.0766747   -0.0463585    0.197548    -0.0845302
 -0.0943927    0.277899     0.0400361   0.00547965    0.21877      0.106049   -0.0165672    -0.0143317   -0.0207938   -0.0778402   -0.190072    -0.0465317    -0.145452     -0.0857199   -0.224671     -0.116391      0.0317295   -0.0426699    0.111715     0.126299    -0.00595303    0.136172    -0.0377667    0.165188    -0.0233257    0.111947
 -0.00681916   0.0616296   -0.076426    0.0157071     0.122445    -0.0374161   0.0987969     0.089502     0.0874192   -0.057557     0.0286791   -0.0348253     0.0620308     0.0165893   -0.0500203    -0.0344003    -0.0144991    0.118335     0.122343     0.120904     0.0293963    -0.176306     0.0752407    0.00295266   0.0209124    0.000192116
  0.0672772    0.0591922    0.027004   -0.194034     -0.0507136    0.141526   -0.0585826     0.0246083    0.142323     0.00965128  -0.0850864    0.0323594    -0.229632      0.115152     0.00381796   -0.0126279    -0.0129784   -0.0432901   -0.0643764    0.0497089   -0.0200448    -0.10086      0.0137802   -0.0118023   -0.0219906    0.0220612
 -0.152939     0.138634    -0.109245   -0.0281553     0.0530657   -0.0915956  -0.0311524     0.12854      0.00332169   0.122892     0.123157     0.115084      0.0160892     0.0800444   -0.0198912     0.141631      0.0996938    0.0493437    0.0964233    0.0933238   -0.114432     -0.0561765    0.0306122   -0.00915542  -0.133949     0.0251494
 -0.0881499    0.106575    -0.0579116  -0.009247      0.0418221    0.181658   -0.0483636     0.110781     0.124354     0.0533211    0.0528601    0.335869      0.0831785    -0.0273202    0.207737     -0.00219706   -0.0993915    0.105815     0.0436474    3.39829e-5  -0.0254725    -0.0793543    0.223482    -0.0400686   -0.0249249    0.123678
 -0.0186946    0.00965213   0.10205    -0.00776224    0.00732228  -0.134975    0.00961933    0.123623    -0.112087     0.0487735   -0.162598     0.158557      0.00836647   -0.20225     -0.069175     -0.0965426     0.0984305   -0.122048     0.019708    -0.168192    -0.0972353    -0.026965    -0.158569     0.147981     0.0128792    0.00717749
  0.0189319   -0.140862     0.0205211  -0.138802     -0.0255622   -0.131926   -0.0204907    -0.0306367    0.090701     0.0301206    0.0182281    0.051238      0.0812012     0.050268     0.049502      0.0920727     0.0919291   -0.0836525   -0.0824167    0.111882     0.010617      0.0243346    0.0545701    0.0603229   -0.0665084   -0.232476
 -0.215905    -0.237029     0.245634   -0.0212824    -0.0607815   -0.230336   -0.0568268    -0.0109008   -0.0292389   -0.0398869   -0.155115    -0.11627       0.00541565   -0.0656395    0.0996296    -0.0105323    -0.00281792  -0.0224825   -0.0483581    0.108912    -0.136586     -0.0911779   -0.0309831    0.0998347   -0.0873574    0.136578
  0.0970461   -0.0255402    0.0818667  -0.00588325    0.0607059    0.0843055   0.132937     -0.067062     0.0786602    0.167879    -0.0973318   -0.0631471     0.0538388     0.0803117   -0.0272317     0.0654431     0.0606416   -0.0514706   -0.114983     0.0501055   -0.078022     -0.0137814    0.0122602    0.170693     0.0181414    0.0691769
 -0.184765    -0.0104736    0.0559186  -0.0657306    -0.0332488   -0.0745509   0.000503252   0.00262848  -0.0412158   -0.275181    -0.037987    -0.119757      0.0270981    -0.0979913    0.240225      0.10538      -0.0995084   -0.0542835   -0.039133    -0.134556    -0.0596149    -0.0375601    0.0580724   -0.237687     0.207252    -0.0992379
 -0.117028    -0.0912334    0.0153102   0.138904      0.114235    -0.10493    -0.0485983     0.136068    -0.0842204    0.088179    -0.077939     0.164574     -0.00354841   -0.00873925  -0.0778485     0.0811173     0.0349535    0.029712    -0.0870989   -0.114577    -0.0776996    -0.0338891    0.0603086    0.0579059   -0.0190594    0.0168707
 -0.0110903   -0.104559     0.01256    -0.0913898    -0.155912    -0.0815829   0.00897039   -0.117807     0.0288865   -0.0195813    0.0373578    0.0752275     0.0389809    -0.11648     -0.102178     -0.0339846     0.0720322   -0.119403     0.0716287    0.0645321    0.0767892     0.040452     0.0130588   -0.0495449   -0.16784      0.0750791
  0.138784    -0.0630278    0.0375111  -0.169615      0.0603672   -0.121237    0.141077     -0.194597     0.00871315   0.0271784    0.0120591   -0.07338       0.0779109     0.0306249    0.0404559    -0.0790416    -0.0415745   -0.0217545   -0.0968289   -0.0810852    0.0594489     0.126138    -0.0305773    0.175913    -0.140128    -0.056684
 -0.0330422   -0.0241118    0.0107867   0.174825     -0.0719564    0.0859921  -0.0205796    -0.0641667    0.0190105    0.0108422   -0.0371861    0.0840574     0.0376216     0.0875469   -0.0407176     0.195058      0.0244938    0.0902122    0.00118891  -0.00608012   0.0270789    -0.00569278  -0.00254012   0.212445    -0.140261     0.113182
 -0.100264    -0.00639989  -0.0211847   0.000773682   0.00529824  -0.0220281  -0.0540847    -0.0131769   -0.0237197    0.0320053    0.134093     0.0320128    -0.0561612     0.0606434    0.0424271    -0.0117021     0.0298629   -0.0239655   -0.0555015    0.0445176   -0.254245      0.0524582   -0.13348      0.0568687   -0.0287432    0.0638207
  0.0607145   -0.0298679    0.0401553   0.137983      0.0192008    0.03281     0.079639     -0.0379906   -0.0819814    0.0244567    0.116631     0.1385       -0.07818      -0.0639872    0.265955     -0.133552      0.00335634   0.0819489    0.0220897    0.146575     0.117127     -0.0988591   -0.194145     0.0533484    0.139576     0.0479335
  0.0288962   -0.0742044    0.116444   -0.162776      0.192437     0.0145465   0.0372562     0.0677486    0.0160583    0.149568    -0.0161381   -0.0435987     0.0708363    -0.0475072    0.054507      0.0386288    -0.0272269   -0.21012      0.079374     0.0221118   -0.00205787    0.0841476    0.121356    -0.170139    -0.0404026   -0.063933
  0.0411022    0.0179158   -0.0848209   0.00411746    0.0203354    0.0683532   0.0172852     0.0474375    0.248585     0.0390734   -0.0262283   -0.142879      0.0639351    -0.0494172   -0.0864677    -0.0321175     0.137486    -0.0704745   -0.0824984    0.122774     0.0119429    -0.0823821   -0.106475     0.0293086    0.0872702    0.15428
 -0.0180927    0.0713499    0.0795324  -0.0238397     0.0438054    0.155261   -0.216134     -0.0404839   -0.0388913   -0.0108473   -0.0411597   -0.127525      0.0713264    -0.00204878  -0.0798557    -0.0143594     0.113288    -0.149464     0.0672511   -0.00682807  -0.0171052     0.110497    -0.0876725   -0.159397    -0.101417    -0.00314002
 -0.176381    -0.0219169   -0.0643545  -0.132173     -0.0112877   -0.108427    0.0648243    -0.0186527   -2.18412e-5   0.0524472   -0.167311    -0.200398     -0.0131488     0.0262208    0.075224     -0.00112546   -0.125664     0.0304287    0.0577262    0.158489     0.228931     -0.0669737   -0.0347002   -0.0704601    0.0946224    0.243
 -0.0475879   -0.0707076    0.310583    0.11975       0.0172973    0.0685982  -0.0257213    -0.0117685    0.0142565   -0.123627     0.0180864   -0.142272     -0.000176062  -0.0526563    0.164143     -0.122823      0.157647    -0.0389266   -0.0124382    0.095261    -0.0621003     0.0336161   -0.0719735    0.0931169   -0.0670695   -0.00662601
  0.156611     0.00231773  -0.0284981  -0.0367086    -0.0456023    0.0055857  -0.114944      0.0358825    0.0531481   -0.0217374   -0.0653364   -0.0355443    -0.0749804    -0.0332635    0.0124101     0.0254299    -0.0796951   -0.104047     0.00148674  -0.0656336   -0.0837748    -0.0697432   -0.0175477    0.0189398   -0.0117198   -0.246696
 -0.166091    -0.125889     0.0858551   0.0628314    -0.138327     0.0078214   0.0432065     0.101872     0.158238     0.111115     0.00280581  -0.124037      0.147898     -0.0153679   -0.102673      0.0521471    -0.00421409   0.115258    -0.0603258   -0.0776019    0.0774064    -0.0111187   -0.198882    -0.151975    -0.0151413   -0.104786
 -0.127597    -0.060178     0.19549    -0.339509     -0.105982    -0.0868426   0.0304944    -0.0378607    0.216025    -0.00758133   0.0901267    0.010572     -0.1479       -0.0828177    0.0616012    -0.0913042    -0.0675994   -0.0583463    0.0156148    0.083259    -0.11942       0.0581697    0.0479564    0.0468245    0.00554907  -0.0418055
 -0.0114077    0.100318     0.0298468   0.0791486    -0.0442456    0.275005   -0.0235339    -0.223267    -0.148882     0.148937    -0.0126395    0.12841       0.259527      0.127333     0.147673      0.035547      0.0870674   -0.220962     0.0280721    0.0822566    0.0675546    -0.0426964   -0.00403269  -0.0684796   -0.101991    -0.12789
  0.106556     0.0872344   -0.0234087  -0.273559      0.204153    -0.115518   -0.147595      0.116017    -0.0828013   -0.0125957   -0.0171762   -0.0172844     0.132692      0.0220975    0.0264913    -0.11777       0.13474     -0.065976     0.0806104   -0.112436     0.0690668     0.17196      0.0451982    0.0453409    0.0857954   -0.0578161
 -0.163416     0.0192262   -0.0962943  -0.220704      0.0287315    0.134422    0.0469211    -0.109766     0.00938359  -0.046395     0.0553054    0.0487263     0.000382126  -0.00318745  -0.0554501     0.000363092   0.0273921   -0.032084    -0.0275983   -0.145802     0.000231374   0.127965    -0.18121      0.0592429   -0.0182876    0.182234
  0.00826414  -0.0529537    0.0324839   0.0587115    -0.00767754  -0.0313766  -0.0119219     0.147927    -0.112976     0.170979    -0.0153347   -0.000236438   0.113242     -0.143008     0.0686786    -0.145443     -0.100264     0.0890787    0.0492879    0.0253528   -0.16106       0.0675491   -0.284392    -0.109238     0.129757    -0.0912254
 -0.0514083    0.143058     0.0469425  -0.0050643    -0.0734592    0.0504966   0.0513763     0.1047      -0.0660697    0.0207574   -0.00691477   0.0980888    -0.0016883    -0.103548     0.000668329  -0.0761316     0.00791547  -0.0194422   -0.0888852    0.139258    -0.178411     -0.201259     0.0401322    0.212301     0.0156592   -0.036477
 -0.0758951    0.0996935    0.110656   -0.0544819     0.0858426    0.0035262   0.0277997    -0.0559121    0.0893712   -0.0709199   -0.0932022   -0.0569397    -0.246514      0.11471      0.0487234    -0.151649      0.0603391    0.0301571    0.204357     0.0671834    0.162933     -0.0881824    0.0816556   -0.0677122    0.0602239    0.0581431kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.425759267997494
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425778
[ Info: iteration 2, average log likelihood -1.425721
[ Info: iteration 3, average log likelihood -1.425681
[ Info: iteration 4, average log likelihood -1.425637
[ Info: iteration 5, average log likelihood -1.425585
[ Info: iteration 6, average log likelihood -1.425514
[ Info: iteration 7, average log likelihood -1.425396
[ Info: iteration 8, average log likelihood -1.425153
[ Info: iteration 9, average log likelihood -1.424620
[ Info: iteration 10, average log likelihood -1.423622
[ Info: iteration 11, average log likelihood -1.422312
[ Info: iteration 12, average log likelihood -1.421252
[ Info: iteration 13, average log likelihood -1.420711
[ Info: iteration 14, average log likelihood -1.420503
[ Info: iteration 15, average log likelihood -1.420431
[ Info: iteration 16, average log likelihood -1.420405
[ Info: iteration 17, average log likelihood -1.420396
[ Info: iteration 18, average log likelihood -1.420393
[ Info: iteration 19, average log likelihood -1.420391
[ Info: iteration 20, average log likelihood -1.420391
[ Info: iteration 21, average log likelihood -1.420391
[ Info: iteration 22, average log likelihood -1.420391
[ Info: iteration 23, average log likelihood -1.420390
[ Info: iteration 24, average log likelihood -1.420390
[ Info: iteration 25, average log likelihood -1.420390
[ Info: iteration 26, average log likelihood -1.420390
[ Info: iteration 27, average log likelihood -1.420390
[ Info: iteration 28, average log likelihood -1.420390
[ Info: iteration 29, average log likelihood -1.420390
[ Info: iteration 30, average log likelihood -1.420390
[ Info: iteration 31, average log likelihood -1.420390
[ Info: iteration 32, average log likelihood -1.420390
[ Info: iteration 33, average log likelihood -1.420390
[ Info: iteration 34, average log likelihood -1.420390
[ Info: iteration 35, average log likelihood -1.420390
[ Info: iteration 36, average log likelihood -1.420390
[ Info: iteration 37, average log likelihood -1.420390
[ Info: iteration 38, average log likelihood -1.420390
[ Info: iteration 39, average log likelihood -1.420390
[ Info: iteration 40, average log likelihood -1.420390
[ Info: iteration 41, average log likelihood -1.420390
[ Info: iteration 42, average log likelihood -1.420390
[ Info: iteration 43, average log likelihood -1.420390
[ Info: iteration 44, average log likelihood -1.420390
[ Info: iteration 45, average log likelihood -1.420390
[ Info: iteration 46, average log likelihood -1.420390
[ Info: iteration 47, average log likelihood -1.420390
[ Info: iteration 48, average log likelihood -1.420390
[ Info: iteration 49, average log likelihood -1.420390
[ Info: iteration 50, average log likelihood -1.420390
┌ Info: EM with 100000 data points 50 iterations avll -1.420390
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4257782541286041
│     -1.4257207239058065
│      ⋮
└     -1.4203897846863147
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420405
[ Info: iteration 2, average log likelihood -1.420356
[ Info: iteration 3, average log likelihood -1.420319
[ Info: iteration 4, average log likelihood -1.420278
[ Info: iteration 5, average log likelihood -1.420230
[ Info: iteration 6, average log likelihood -1.420178
[ Info: iteration 7, average log likelihood -1.420122
[ Info: iteration 8, average log likelihood -1.420065
[ Info: iteration 9, average log likelihood -1.420010
[ Info: iteration 10, average log likelihood -1.419958
[ Info: iteration 11, average log likelihood -1.419910
[ Info: iteration 12, average log likelihood -1.419864
[ Info: iteration 13, average log likelihood -1.419822
[ Info: iteration 14, average log likelihood -1.419785
[ Info: iteration 15, average log likelihood -1.419752
[ Info: iteration 16, average log likelihood -1.419723
[ Info: iteration 17, average log likelihood -1.419699
[ Info: iteration 18, average log likelihood -1.419678
[ Info: iteration 19, average log likelihood -1.419660
[ Info: iteration 20, average log likelihood -1.419644
[ Info: iteration 21, average log likelihood -1.419630
[ Info: iteration 22, average log likelihood -1.419618
[ Info: iteration 23, average log likelihood -1.419606
[ Info: iteration 24, average log likelihood -1.419596
[ Info: iteration 25, average log likelihood -1.419586
[ Info: iteration 26, average log likelihood -1.419578
[ Info: iteration 27, average log likelihood -1.419571
[ Info: iteration 28, average log likelihood -1.419564
[ Info: iteration 29, average log likelihood -1.419558
[ Info: iteration 30, average log likelihood -1.419553
[ Info: iteration 31, average log likelihood -1.419548
[ Info: iteration 32, average log likelihood -1.419544
[ Info: iteration 33, average log likelihood -1.419541
[ Info: iteration 34, average log likelihood -1.419538
[ Info: iteration 35, average log likelihood -1.419535
[ Info: iteration 36, average log likelihood -1.419532
[ Info: iteration 37, average log likelihood -1.419529
[ Info: iteration 38, average log likelihood -1.419527
[ Info: iteration 39, average log likelihood -1.419525
[ Info: iteration 40, average log likelihood -1.419523
[ Info: iteration 41, average log likelihood -1.419520
[ Info: iteration 42, average log likelihood -1.419518
[ Info: iteration 43, average log likelihood -1.419516
[ Info: iteration 44, average log likelihood -1.419514
[ Info: iteration 45, average log likelihood -1.419512
[ Info: iteration 46, average log likelihood -1.419510
[ Info: iteration 47, average log likelihood -1.419508
[ Info: iteration 48, average log likelihood -1.419506
[ Info: iteration 49, average log likelihood -1.419504
[ Info: iteration 50, average log likelihood -1.419502
┌ Info: EM with 100000 data points 50 iterations avll -1.419502
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4204049515306456
│     -1.4203556552869068
│      ⋮
└     -1.4195020391295405
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419509
[ Info: iteration 2, average log likelihood -1.419467
[ Info: iteration 3, average log likelihood -1.419431
[ Info: iteration 4, average log likelihood -1.419389
[ Info: iteration 5, average log likelihood -1.419338
[ Info: iteration 6, average log likelihood -1.419276
[ Info: iteration 7, average log likelihood -1.419203
[ Info: iteration 8, average log likelihood -1.419123
[ Info: iteration 9, average log likelihood -1.419040
[ Info: iteration 10, average log likelihood -1.418959
[ Info: iteration 11, average log likelihood -1.418885
[ Info: iteration 12, average log likelihood -1.418819
[ Info: iteration 13, average log likelihood -1.418761
[ Info: iteration 14, average log likelihood -1.418711
[ Info: iteration 15, average log likelihood -1.418666
[ Info: iteration 16, average log likelihood -1.418627
[ Info: iteration 17, average log likelihood -1.418592
[ Info: iteration 18, average log likelihood -1.418561
[ Info: iteration 19, average log likelihood -1.418534
[ Info: iteration 20, average log likelihood -1.418509
[ Info: iteration 21, average log likelihood -1.418487
[ Info: iteration 22, average log likelihood -1.418466
[ Info: iteration 23, average log likelihood -1.418446
[ Info: iteration 24, average log likelihood -1.418427
[ Info: iteration 25, average log likelihood -1.418409
[ Info: iteration 26, average log likelihood -1.418391
[ Info: iteration 27, average log likelihood -1.418374
[ Info: iteration 28, average log likelihood -1.418357
[ Info: iteration 29, average log likelihood -1.418340
[ Info: iteration 30, average log likelihood -1.418324
[ Info: iteration 31, average log likelihood -1.418308
[ Info: iteration 32, average log likelihood -1.418293
[ Info: iteration 33, average log likelihood -1.418278
[ Info: iteration 34, average log likelihood -1.418264
[ Info: iteration 35, average log likelihood -1.418250
[ Info: iteration 36, average log likelihood -1.418236
[ Info: iteration 37, average log likelihood -1.418224
[ Info: iteration 38, average log likelihood -1.418211
[ Info: iteration 39, average log likelihood -1.418200
[ Info: iteration 40, average log likelihood -1.418188
[ Info: iteration 41, average log likelihood -1.418177
[ Info: iteration 42, average log likelihood -1.418166
[ Info: iteration 43, average log likelihood -1.418156
[ Info: iteration 44, average log likelihood -1.418145
[ Info: iteration 45, average log likelihood -1.418135
[ Info: iteration 46, average log likelihood -1.418125
[ Info: iteration 47, average log likelihood -1.418115
[ Info: iteration 48, average log likelihood -1.418105
[ Info: iteration 49, average log likelihood -1.418095
[ Info: iteration 50, average log likelihood -1.418085
┌ Info: EM with 100000 data points 50 iterations avll -1.418085
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4195093458184178
│     -1.4194673606677597
│      ⋮
└     -1.4180854213710306
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418086
[ Info: iteration 2, average log likelihood -1.418026
[ Info: iteration 3, average log likelihood -1.417972
[ Info: iteration 4, average log likelihood -1.417912
[ Info: iteration 5, average log likelihood -1.417840
[ Info: iteration 6, average log likelihood -1.417756
[ Info: iteration 7, average log likelihood -1.417658
[ Info: iteration 8, average log likelihood -1.417549
[ Info: iteration 9, average log likelihood -1.417434
[ Info: iteration 10, average log likelihood -1.417317
[ Info: iteration 11, average log likelihood -1.417205
[ Info: iteration 12, average log likelihood -1.417100
[ Info: iteration 13, average log likelihood -1.417005
[ Info: iteration 14, average log likelihood -1.416921
[ Info: iteration 15, average log likelihood -1.416848
[ Info: iteration 16, average log likelihood -1.416786
[ Info: iteration 17, average log likelihood -1.416732
[ Info: iteration 18, average log likelihood -1.416686
[ Info: iteration 19, average log likelihood -1.416645
[ Info: iteration 20, average log likelihood -1.416609
[ Info: iteration 21, average log likelihood -1.416578
[ Info: iteration 22, average log likelihood -1.416549
[ Info: iteration 23, average log likelihood -1.416523
[ Info: iteration 24, average log likelihood -1.416500
[ Info: iteration 25, average log likelihood -1.416478
[ Info: iteration 26, average log likelihood -1.416458
[ Info: iteration 27, average log likelihood -1.416440
[ Info: iteration 28, average log likelihood -1.416423
[ Info: iteration 29, average log likelihood -1.416406
[ Info: iteration 30, average log likelihood -1.416391
[ Info: iteration 31, average log likelihood -1.416377
[ Info: iteration 32, average log likelihood -1.416363
[ Info: iteration 33, average log likelihood -1.416350
[ Info: iteration 34, average log likelihood -1.416338
[ Info: iteration 35, average log likelihood -1.416326
[ Info: iteration 36, average log likelihood -1.416315
[ Info: iteration 37, average log likelihood -1.416304
[ Info: iteration 38, average log likelihood -1.416293
[ Info: iteration 39, average log likelihood -1.416283
[ Info: iteration 40, average log likelihood -1.416273
[ Info: iteration 41, average log likelihood -1.416264
[ Info: iteration 42, average log likelihood -1.416255
[ Info: iteration 43, average log likelihood -1.416246
[ Info: iteration 44, average log likelihood -1.416237
[ Info: iteration 45, average log likelihood -1.416229
[ Info: iteration 46, average log likelihood -1.416221
[ Info: iteration 47, average log likelihood -1.416213
[ Info: iteration 48, average log likelihood -1.416206
[ Info: iteration 49, average log likelihood -1.416198
[ Info: iteration 50, average log likelihood -1.416191
┌ Info: EM with 100000 data points 50 iterations avll -1.416191
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4180859141769702
│     -1.418025982360378
│      ⋮
└     -1.4161911179634392
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416193
[ Info: iteration 2, average log likelihood -1.416127
[ Info: iteration 3, average log likelihood -1.416064
[ Info: iteration 4, average log likelihood -1.415989
[ Info: iteration 5, average log likelihood -1.415893
[ Info: iteration 6, average log likelihood -1.415772
[ Info: iteration 7, average log likelihood -1.415626
[ Info: iteration 8, average log likelihood -1.415460
[ Info: iteration 9, average log likelihood -1.415284
[ Info: iteration 10, average log likelihood -1.415111
[ Info: iteration 11, average log likelihood -1.414949
[ Info: iteration 12, average log likelihood -1.414804
[ Info: iteration 13, average log likelihood -1.414676
[ Info: iteration 14, average log likelihood -1.414565
[ Info: iteration 15, average log likelihood -1.414468
[ Info: iteration 16, average log likelihood -1.414382
[ Info: iteration 17, average log likelihood -1.414307
[ Info: iteration 18, average log likelihood -1.414240
[ Info: iteration 19, average log likelihood -1.414180
[ Info: iteration 20, average log likelihood -1.414125
[ Info: iteration 21, average log likelihood -1.414076
[ Info: iteration 22, average log likelihood -1.414031
[ Info: iteration 23, average log likelihood -1.413989
[ Info: iteration 24, average log likelihood -1.413951
[ Info: iteration 25, average log likelihood -1.413916
[ Info: iteration 26, average log likelihood -1.413884
[ Info: iteration 27, average log likelihood -1.413854
[ Info: iteration 28, average log likelihood -1.413826
[ Info: iteration 29, average log likelihood -1.413800
[ Info: iteration 30, average log likelihood -1.413776
[ Info: iteration 31, average log likelihood -1.413753
[ Info: iteration 32, average log likelihood -1.413731
[ Info: iteration 33, average log likelihood -1.413710
[ Info: iteration 34, average log likelihood -1.413689
[ Info: iteration 35, average log likelihood -1.413670
[ Info: iteration 36, average log likelihood -1.413651
[ Info: iteration 37, average log likelihood -1.413633
[ Info: iteration 38, average log likelihood -1.413616
[ Info: iteration 39, average log likelihood -1.413599
[ Info: iteration 40, average log likelihood -1.413582
[ Info: iteration 41, average log likelihood -1.413565
[ Info: iteration 42, average log likelihood -1.413549
[ Info: iteration 43, average log likelihood -1.413534
[ Info: iteration 44, average log likelihood -1.413518
[ Info: iteration 45, average log likelihood -1.413503
[ Info: iteration 46, average log likelihood -1.413488
[ Info: iteration 47, average log likelihood -1.413473
[ Info: iteration 48, average log likelihood -1.413459
[ Info: iteration 49, average log likelihood -1.413445
[ Info: iteration 50, average log likelihood -1.413431
┌ Info: EM with 100000 data points 50 iterations avll -1.413431
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4161930734906252
│     -1.4161273509014278
│      ⋮
└     -1.413431046153521
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.425759267997494
│     -1.4257782541286041
│     -1.4257207239058065
│     -1.4256810190851523
│      ⋮
│     -1.4134590258440103
│     -1.413444899755448
└     -1.413431046153521
32×26 Array{Float64,2}:
 -0.111975     0.249432    0.0950325   0.386462   -0.205032     0.243765   -0.171633    -0.427133     -0.491306   -0.16331     -0.173829    0.445884     0.546558   -0.599529     0.0411441     0.251006    0.135343    -0.747584   -0.754548   -1.10059    -0.163442    -0.539502   -0.309802    0.131301     0.0797549   0.36709
 -0.00896187   0.180978   -0.0426504   0.508546   -0.101717    -0.777223   -0.00433922   0.362407     -0.232122   -0.264851    -0.215867    0.466781     0.431418    0.16275     -0.101328     -0.407928   -0.324432    -1.18438    -0.642515   -0.340153    0.288731     0.0959159  -0.433235   -0.330381    -0.0227856  -0.297442
  0.575449     0.246308   -0.316861   -0.074908   -0.500771    -0.417783    0.493072     0.0576333    -0.0961515   0.206758    -0.488638    0.44263     -0.0800734   0.0616553    0.413226      0.211585   -0.170489    -0.622119    0.203349    0.314697   -0.131618     0.12649     0.240093    0.121565     0.283172   -0.416957
  0.496334    -0.117711    0.743691   -0.24111     0.253749    -0.0453519   0.020454     0.389956      0.129689   -0.00629638   0.0735002   0.465647    -0.0275897  -0.491851     0.1935        0.610464    0.166728    -0.587793    0.0611078   0.0135597   0.0784489   -0.0715407   0.293201    1.01945      0.130269    0.23031
 -0.528345    -0.382281    0.509258   -0.399607    0.0432573   -0.583563   -0.529918     0.504421     -0.193984    0.562645    -0.0965278  -0.325025     0.299513    0.0288367    0.302571     -0.39412    -0.0936655    0.406159    0.479528    0.011549    0.115696    -0.0050682  -0.11746     0.620598     0.284303    0.251097
 -0.0665606   -0.139048   -0.647674   -0.111209    0.18752      0.305535    0.0349338    0.528126     -0.223335    0.379547     0.360331   -0.11039     -0.098674    0.136457    -0.230041     -0.141919   -0.187778    -0.358999    0.640092   -0.550544   -0.253937     0.250506   -0.292835    0.626866    -0.353857    0.536162
 -0.084406     0.052898   -0.0442129  -0.431538    0.564058    -0.467919   -0.205836     1.24124      -0.434779    0.00779728  -0.222532    0.125006    -0.26855     0.0185104   -0.221938      0.474212   -0.281936     0.0269734  -0.183975    0.467049    0.0501857    0.172118    0.0077556   0.279723    -0.202959   -0.220895
 -0.532487    -0.461729    0.138913   -0.0497516   0.625504    -0.240458    1.1551       0.328666      0.171759    0.0280658    0.213723    0.273479    -0.446523    0.0447504   -0.400337     -0.0378089   0.00024044   0.352462   -0.356711    0.613303   -0.0417314    0.284335    0.337319    0.715577    -0.53271    -0.522146
  0.0128336    0.423125   -0.251394    0.200381   -0.431168     0.100105   -0.306259    -0.587946      0.109478    0.624194    -0.211989   -0.211758    -0.0202665   0.38681      0.621389     -0.270969   -0.182824     0.399006    0.160883   -0.4479     -0.309109    -0.278949   -0.129609   -0.535414     0.372097   -0.29094
 -0.72345     -0.155194   -0.0137327   0.628162    0.640121     0.43296     0.130762    -0.571147      0.325612    0.0329807    0.393468   -0.147757    -0.0840391   0.00271427  -0.389488     -0.501944   -0.0411318    0.825474    0.468557   -0.860758    0.676501    -0.418128   -0.215593   -0.936002    -0.527601    0.572342
 -0.28706     -0.226201   -0.112086   -0.0129303   0.14199     -0.490416    0.279195     0.151606      0.0654336   0.0833028   -0.217741    0.380202     0.0485852  -0.129834    -0.177176      0.0534196   0.0639543   -0.182711   -0.401598    0.16098     0.102014    -0.0661956   0.0266234  -0.0639706   -0.0725643   0.0218969
  0.289671     0.137183    0.200708   -0.246811   -0.0473531    0.414072   -0.27671      0.000615525   0.103467   -0.15768      0.204993   -0.377872    -0.0976472   0.0659649    0.037015      0.145496    0.0801853    0.242887    0.299593    0.247073   -0.213488     0.129617   -0.0126151   0.20924     -0.0185308  -0.0989554
  0.0814367   -0.327954   -0.135144    0.239338    0.205595    -0.247031    0.239609     0.517883     -0.743228   -0.23299      0.839696   -0.278055     0.453365   -0.704394     0.663319     -0.562304    0.0524271    0.0153671   1.06622     0.540655   -0.00677649   0.429556   -0.438035    0.291894    -0.29453    -0.397228
  0.476801     0.131491    0.802428   -0.144867    0.518358     0.364589    0.114605    -0.259758     -0.400776   -0.824747     0.398441   -0.213968     0.223608    0.0457826   -0.101637     -0.203835   -0.370309    -0.7729      0.273544    0.197962    0.399996     0.700022    0.225755    0.0240801    0.0496862   0.104347
 -0.285595    -0.299632   -0.0714267  -0.0184165   0.263023     0.547682   -0.00817886  -0.312567     -0.653278   -0.45018      0.040809    0.426659    -0.461908    0.0141032   -0.286475     -0.597028    0.0227864   -0.0340186   0.128968    0.365189   -0.58556      0.477834   -0.295084   -0.405602     0.482062    0.0660583
 -0.146043    -0.311606    0.679379   -0.333489    0.622064     0.11734     0.0706884   -0.275294     -0.701337    0.462102     0.339009    0.560056     0.124133   -0.0728017   -0.511979     -0.356412   -0.210585     0.415365   -0.508727   -0.325038   -0.507035     0.0930596   0.0381762  -0.00274128  -0.0606852   0.256036
  0.190077    -0.602747    0.0641374   0.187684   -0.00719138  -0.912064    0.153822    -0.379718      0.486861    0.0137953    0.212517   -0.3123       0.0836172  -0.160664    -0.273384     -0.171795    0.180626     0.162295   -0.0445838  -0.282829    0.0944519   -0.231666   -0.031639   -0.279908    -0.369005   -0.457872
 -0.131485     0.233028    0.240381   -0.181567    0.167906     0.256524    0.0245743   -0.34933       0.809905    0.00927857  -0.238038    0.244973     0.0619363   0.610907    -0.390357      0.217224   -0.0529251   -0.066013   -0.682466   -0.533598    0.524023     0.295798    0.0314221  -0.215335    -0.151661    0.19632
 -0.422288     0.215879   -0.219941   -0.186763   -0.587025     0.559448    0.0507065    0.378292      0.0699122  -0.555795     0.0468812   0.00422084   0.304534    0.0897102    0.127526     -0.468035    0.0344613   -0.144894   -0.331176    0.0929288  -0.636919    -0.303848    0.0153362   0.0401789   -0.546637   -0.127745
  0.0082598    0.180535    0.475026    0.301609   -0.375033     0.432367   -0.392464    -0.293791     -0.0552286  -0.141991    -0.229218   -0.584888     0.726212   -0.219047     0.167414     -0.247593    0.00555442  -0.220937   -0.0560638  -0.209992    0.130136    -0.517871    0.168766   -0.0759217   -0.0363067  -0.118471
 -0.705495     0.0874808  -0.340104    0.424566   -0.0179441    0.0157435   0.40101     -0.145386      0.270608   -0.199256    -0.599733   -0.508648     0.170646    0.439109    -0.447722     -0.381505   -0.0909565    0.661495   -0.272557    0.377098    0.361168    -0.0299562  -0.449863   -0.935617     0.245906    0.0750343
 -0.502369     0.12672    -0.345745    0.0711151  -0.302954    -0.731024    0.0965838    0.173794      0.241777    0.501456    -0.406563    0.166747    -0.48116     0.535063     0.48682      -0.395713   -0.473556     0.812444    0.165504    0.237063    0.203545     0.188229   -0.309981   -0.367551     0.390813    0.0136649
 -0.0232625   -0.0500856  -0.0827009  -0.0358277  -0.118271     0.14933    -0.841383    -0.0510489     0.171362   -0.13116      0.175143    0.137262    -0.302861    0.277009    -0.0832456     0.220449    0.670545     0.224597   -0.0176035   0.441494    0.0819596    0.152402   -0.224587   -0.766341     0.282642    0.201013
 -0.368649    -0.0190654  -0.486697   -0.016512    0.0872149    0.213463    0.639229    -0.578681     -0.0585912  -0.0956131    0.120035    0.517861    -0.0998954  -0.0430796   -0.0948375     0.395528    0.589365    -0.2467      0.0347052   0.250317    0.361326    -0.170136    0.0465089  -0.479032    -0.0960416   0.354445
  0.0129917   -0.0231967   0.0329364  -0.103446    0.187142     0.0292973  -0.0478044    0.0202294     0.0470205   0.00769009   0.128497   -0.214482    -0.0216962   0.0252717   -0.351951      0.100626    0.0680225    0.176779    0.270058    0.227268   -0.0263709    0.0232992  -0.150673    0.166907    -0.0788309   0.247385
  0.0666607    0.193938    0.13205     0.0865545   0.14075     -0.0158126  -0.0570195    0.0182208    -0.0954319  -0.0943183    0.078779    0.177639     0.0121628  -0.0778688    0.502533     -0.0105808  -0.0352754   -0.107505    0.277763    0.0231216   0.163062     0.157423   -0.0953917   0.0431832    0.196591   -0.0323896
 -0.304189    -0.178619    0.0505635  -0.079808   -0.221515    -0.0638033   0.0586422    0.0467653    -0.0268995   0.278966    -0.350236    0.198837     0.0292723  -0.0499027   -0.0273075    -0.0948443   0.202421    -0.188913   -0.362274   -0.0865317  -0.19288     -0.322573    0.0346778   0.0319935    0.110283    0.187642
  0.160041     0.0162149  -0.183345   -0.108981   -0.00130055   0.0519895   0.0518369    0.024423     -0.07678    -0.0795968    0.0967929   0.0474267    0.0951368   0.013538    -0.000285135  -0.18989    -0.279239    -0.1647     -0.326818   -0.209813   -0.385763     0.194246    0.125337   -0.0907247   -0.281621   -0.394591
 -0.0357314    0.0363293  -0.143822    0.127357   -0.403899    -0.241205   -0.0682768    0.277088      0.866035   -0.714017    -0.28973    -0.927949    -0.230139   -0.0987538    0.11694       0.455725    0.377635    -0.24652     0.299894    0.362483    0.346228    -0.320586   -0.0977705   0.150517    -0.10226     0.0235841
  0.00423994   0.163105   -0.651373   -0.113806   -0.318487    -0.36954    -0.124497     0.190186      0.631628    0.949289    -0.114086   -0.162072     0.0664382  -0.209354     0.162451      0.469074    0.119961     0.557319   -0.0704672  -0.252143    0.218501    -0.180946    0.0199012   0.302956    -0.547249   -0.0836692
 -0.0953642   -0.45795     0.414449   -0.489185    0.0337372    0.564961   -0.0711525   -0.196043      0.0875484  -0.0401232   -0.0278663  -0.531963    -0.248342   -0.213525     0.207269      0.114981    0.10786      0.675639    0.414164    0.50051    -0.187307    -0.284941    0.440785    0.144084     0.119515   -0.0251558
  0.510182     0.801026    0.399403   -0.0403307   0.274997     0.330328    0.0748683   -0.465263      0.134633    0.128698     0.0276099  -0.12049     -0.273618   -0.187081     0.396941      0.0831689  -0.145636     0.149306    0.208456    0.0544536  -0.330993    -0.0294881   0.136585    0.374049     0.526006   -0.325135[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413417
[ Info: iteration 2, average log likelihood -1.413404
[ Info: iteration 3, average log likelihood -1.413391
[ Info: iteration 4, average log likelihood -1.413378
[ Info: iteration 5, average log likelihood -1.413366
[ Info: iteration 6, average log likelihood -1.413354
[ Info: iteration 7, average log likelihood -1.413342
[ Info: iteration 8, average log likelihood -1.413331
[ Info: iteration 9, average log likelihood -1.413319
[ Info: iteration 10, average log likelihood -1.413308
┌ Info: EM with 100000 data points 10 iterations avll -1.413308
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.791108e+05
      1       7.088756e+05      -2.702352e+05 |       32
      2       6.967643e+05      -1.211128e+04 |       32
      3       6.917777e+05      -4.986631e+03 |       32
      4       6.890452e+05      -2.732475e+03 |       32
      5       6.872335e+05      -1.811685e+03 |       32
      6       6.859412e+05      -1.292305e+03 |       32
      7       6.849834e+05      -9.578690e+02 |       32
      8       6.842260e+05      -7.573791e+02 |       32
      9       6.836499e+05      -5.760440e+02 |       32
     10       6.831961e+05      -4.538678e+02 |       32
     11       6.828142e+05      -3.818562e+02 |       32
     12       6.824970e+05      -3.171790e+02 |       32
     13       6.822392e+05      -2.578121e+02 |       32
     14       6.820046e+05      -2.346108e+02 |       32
     15       6.817787e+05      -2.259395e+02 |       32
     16       6.815848e+05      -1.938429e+02 |       32
     17       6.814177e+05      -1.671421e+02 |       32
     18       6.812882e+05      -1.295145e+02 |       32
     19       6.811795e+05      -1.087226e+02 |       32
     20       6.810859e+05      -9.358780e+01 |       32
     21       6.809756e+05      -1.103135e+02 |       32
     22       6.808678e+05      -1.077081e+02 |       32
     23       6.807638e+05      -1.040935e+02 |       32
     24       6.806637e+05      -1.000287e+02 |       32
     25       6.805598e+05      -1.038966e+02 |       32
     26       6.804537e+05      -1.060953e+02 |       32
     27       6.803494e+05      -1.043335e+02 |       32
     28       6.802450e+05      -1.044243e+02 |       32
     29       6.801436e+05      -1.013967e+02 |       32
     30       6.800518e+05      -9.176063e+01 |       32
     31       6.799638e+05      -8.803153e+01 |       32
     32       6.798852e+05      -7.857883e+01 |       32
     33       6.798066e+05      -7.855983e+01 |       32
     34       6.797275e+05      -7.918955e+01 |       32
     35       6.796491e+05      -7.832303e+01 |       32
     36       6.795683e+05      -8.081282e+01 |       32
     37       6.794919e+05      -7.643750e+01 |       32
     38       6.794257e+05      -6.622168e+01 |       32
     39       6.793582e+05      -6.742495e+01 |       32
     40       6.792974e+05      -6.079032e+01 |       32
     41       6.792418e+05      -5.566585e+01 |       32
     42       6.791930e+05      -4.879340e+01 |       32
     43       6.791455e+05      -4.751527e+01 |       32
     44       6.791008e+05      -4.470415e+01 |       32
     45       6.790562e+05      -4.458889e+01 |       32
     46       6.790104e+05      -4.579015e+01 |       32
     47       6.789649e+05      -4.547072e+01 |       32
     48       6.789204e+05      -4.454943e+01 |       32
     49       6.788782e+05      -4.214888e+01 |       32
     50       6.788382e+05      -4.001116e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 678838.2094719191)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425391
[ Info: iteration 2, average log likelihood -1.420367
[ Info: iteration 3, average log likelihood -1.419057
[ Info: iteration 4, average log likelihood -1.418147
[ Info: iteration 5, average log likelihood -1.417190
[ Info: iteration 6, average log likelihood -1.416213
[ Info: iteration 7, average log likelihood -1.415431
[ Info: iteration 8, average log likelihood -1.414944
[ Info: iteration 9, average log likelihood -1.414666
[ Info: iteration 10, average log likelihood -1.414496
[ Info: iteration 11, average log likelihood -1.414376
[ Info: iteration 12, average log likelihood -1.414283
[ Info: iteration 13, average log likelihood -1.414207
[ Info: iteration 14, average log likelihood -1.414141
[ Info: iteration 15, average log likelihood -1.414083
[ Info: iteration 16, average log likelihood -1.414031
[ Info: iteration 17, average log likelihood -1.413984
[ Info: iteration 18, average log likelihood -1.413941
[ Info: iteration 19, average log likelihood -1.413901
[ Info: iteration 20, average log likelihood -1.413863
[ Info: iteration 21, average log likelihood -1.413827
[ Info: iteration 22, average log likelihood -1.413793
[ Info: iteration 23, average log likelihood -1.413761
[ Info: iteration 24, average log likelihood -1.413730
[ Info: iteration 25, average log likelihood -1.413700
[ Info: iteration 26, average log likelihood -1.413671
[ Info: iteration 27, average log likelihood -1.413643
[ Info: iteration 28, average log likelihood -1.413615
[ Info: iteration 29, average log likelihood -1.413589
[ Info: iteration 30, average log likelihood -1.413562
[ Info: iteration 31, average log likelihood -1.413537
[ Info: iteration 32, average log likelihood -1.413511
[ Info: iteration 33, average log likelihood -1.413486
[ Info: iteration 34, average log likelihood -1.413460
[ Info: iteration 35, average log likelihood -1.413435
[ Info: iteration 36, average log likelihood -1.413411
[ Info: iteration 37, average log likelihood -1.413386
[ Info: iteration 38, average log likelihood -1.413362
[ Info: iteration 39, average log likelihood -1.413338
[ Info: iteration 40, average log likelihood -1.413315
[ Info: iteration 41, average log likelihood -1.413292
[ Info: iteration 42, average log likelihood -1.413270
[ Info: iteration 43, average log likelihood -1.413249
[ Info: iteration 44, average log likelihood -1.413228
[ Info: iteration 45, average log likelihood -1.413209
[ Info: iteration 46, average log likelihood -1.413189
[ Info: iteration 47, average log likelihood -1.413171
[ Info: iteration 48, average log likelihood -1.413153
[ Info: iteration 49, average log likelihood -1.413136
[ Info: iteration 50, average log likelihood -1.413119
┌ Info: EM with 100000 data points 50 iterations avll -1.413119
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0574819    0.0866734  -0.43782     -0.233191    -0.499711    -0.0830462   -0.156894    0.0767312   0.810194   -0.0105941  -0.463842    -0.273006     -0.347756     0.112912     0.107388    0.318856    0.245692   -0.142356     0.451667    0.276436     0.47689      0.172768    -0.0594354  -0.0943319   -0.112216    0.167733
 -0.288488    -0.377272   -0.160331    -0.0505101    0.375076     0.645696    -0.392045    0.023715   -0.370469   -0.388137    0.217853    -0.0864695    -0.271971     0.163885    -0.611788   -1.18905    -0.195685    0.144287     0.0147344  -0.0236469   -0.675303     0.489445    -0.101472   -0.300433     0.165324    0.0237999
  0.408694     0.0650062   0.787549    -0.183925     0.509525     0.427289     0.148718   -0.255171   -0.0864922  -0.679925    0.336796     0.0269333     0.148879     0.0285193   -0.247538   -0.0743364  -0.178204   -0.766707     0.082252    0.0748161    0.499725     0.745524     0.276824    0.153869     0.0403548   0.166915
 -0.458206    -0.122737    0.154852    -0.126465    -0.129383     0.109657    -0.478972    0.0455733  -0.0219252  -0.199511    0.047788     0.329584     -0.185265     0.578312    -0.19634     0.0260095   0.471892    0.0389833   -0.332077    0.271239     0.0957231    0.0523375   -0.41802    -0.826872     0.0282914   0.480409
  0.276532     0.16704     0.384011     0.0174147    0.130202    -0.142495    -0.157985   -0.60416     0.293949   -0.28413     0.0905046    0.073369      0.439529    -0.405167     0.290507   -0.102327    0.618751    0.490131    -0.644999    0.380075     0.00941165  -0.224327     0.653849   -0.568402     0.253204   -0.832916
 -0.107946    -0.38186    -0.0456526    0.0150958    0.163356    -0.106854    -0.10331     1.09416    -0.546214   -0.179437    0.28684      0.148164      0.38468     -0.423091    -0.289912    0.222823   -0.309846   -0.376527    -0.150333   -0.0395851   -0.078768     0.00761765  -0.0426013   0.6781      -0.64298     0.263596
 -0.0562229    0.0238882  -0.215745     0.03913     -0.265056     0.0993832    0.450862   -0.366357   -0.138035   -0.273391   -0.176208     0.760587      0.0919852   -0.294314     0.138418    0.0815866   0.303796   -0.66321     -0.587487   -0.408266    -0.58967     -0.428915    -0.0143767   0.061027     0.0157946   0.206337
 -0.231528    -0.0646133  -0.0191807    0.0124618    0.0151623    0.0409089   -0.0374393  -0.123233    0.144979    0.0445281  -0.00148667  -0.0731854    -0.0366115    0.0496226   -0.127367   -0.0783905   0.0304127   0.177169     0.0653522  -0.00441096  -0.00298076  -0.0956078   -0.104963   -0.101824    -0.0228089   0.0719423
 -0.184316     0.0903072  -0.154769     0.231493     0.287905    -0.719218     0.572212    0.232977   -0.580943    0.326496   -0.162976     0.804045      0.471538     0.0659207    0.733173   -0.624809   -0.33823    -0.459219     0.539378   -0.100705     0.588106     0.0304936    0.0428151  -0.325504     0.25987     0.16389
  0.479786     0.407543    0.232393     0.366924     0.110678    -0.0767096    0.0877162  -0.0961083  -0.0805997  -0.299905    0.234288     0.038713      0.0123669   -0.457446     0.621309   -0.0800758  -0.310987   -0.355434     0.443135    0.0506219   -0.0159264    0.10549      0.0303641   0.403052     0.361274   -0.333107
  0.200526    -0.111333   -0.0297741    0.168967    -0.143632     0.499371    -0.080225   -0.348919    0.394811   -0.0717336   0.181082    -0.911609     -0.261248    -0.236873    -0.784396    0.299935    0.173993    0.682633    -0.180355    0.443352    -0.579156    -0.341642     0.211435    0.384007    -0.152034   -0.470776
 -0.0869808    0.240679   -0.0399162    0.443898    -0.165934    -0.622017    -0.209979    0.406184   -0.128511   -0.352723   -0.309813     0.365836      0.342023     0.0332837   -0.138992   -0.322024   -0.277065   -1.0429      -1.01801    -0.416252     0.272845     0.117715    -0.373884   -0.402991    -0.134248   -0.571381
 -0.0232089    0.40279    -0.481974    -0.312457     0.0520354    0.283372    -0.683383    0.915013    0.256365    0.431705    1.06866     -0.549564     -0.26871      0.320357     0.348011    0.160868    0.298551   -0.151739    -0.191501   -0.642417    -0.523863    -0.533995     0.0548462   0.735013    -0.218043   -0.148599
 -0.120997    -0.0769683  -0.0799243   -0.00269789  -0.113633    -0.041625     0.0528741   0.013688    0.0064766   0.0449506  -0.0925098    0.0523428     0.0505114   -0.0493816    0.131552   -0.143552   -0.0116326  -0.0730604   -0.14344    -0.0761528   -0.144499    -0.0660434    0.0389559  -0.0514158   -0.0703525  -0.104225
 -0.587065    -0.484403    0.397002    -0.372111    -0.0646484   -0.640378    -0.548361    0.510023   -0.241995    0.512154   -0.133093    -0.297224      0.235976     0.0767213    0.32685    -0.389783   -0.162753    0.592616     0.397752    0.191483     0.021702    -0.032031    -0.0968337   0.427381     0.352293    0.180287
  0.0817494    0.431984   -0.198007     0.0671151   -0.49441      0.427607     0.128201   -0.357271    0.0630277   0.112404    0.175782    -0.218071      0.625281     0.180843     0.336228   -0.100663   -0.186096   -0.0679588    0.142473   -0.415077     0.206234    -0.24843     -0.32941    -0.227666    -0.929324   -0.255953
 -0.341224     0.0497036  -0.606606    -0.209235    -0.0984101   -0.628723     0.0534879   0.208589    0.452407    0.999927   -0.295981     0.454127     -0.177826     0.00419735   0.0760446   0.234662    0.0360974   0.481403    -0.450692   -0.306693     0.105023    -0.0576427   -0.179245    0.146615    -0.488122   -0.0203593
 -0.0424426   -0.064146    0.424701     0.343422    -0.170759     0.0527096   -0.104971   -0.41829    -0.129869    0.452046   -0.531499     0.1916        0.429279    -0.385626    -0.374285   -0.128593    0.109888   -0.639373    -0.442919   -0.666418    -0.120404    -0.247784    -0.0580337   0.222664     0.312576    0.323897
 -0.0968233   -0.146671    0.138781     0.0972665   -0.418415    -0.54639     -0.0536886   0.431587    0.745778   -0.304732   -0.157254    -0.804704      0.202551    -0.268563     0.218313    0.39596     0.457342   -0.186234     0.0121012  -0.0297786    0.267718    -0.744721     0.194979    0.203998    -0.326824    0.0123069
 -0.00964346  -0.218834    0.913574    -0.497851     0.607513     0.106138     0.147692   -0.451042   -0.616489    0.667268    0.33783      0.64979      -0.00271315  -0.183635    -0.478833   -0.082453   -0.189384    0.496358    -0.419825   -0.30433     -0.373446     0.0369407    0.0654561  -0.0303653   -0.100781    0.398628
 -0.753668     0.155115   -0.337573     0.51001      0.129373    -0.0190678    0.318196   -0.0185193   0.381433   -0.175228   -0.393075    -0.446781      0.132662     0.359053    -0.542718   -0.307987   -0.0242541   0.507168    -0.224374    0.0637276    0.476605    -0.117231    -0.411532   -0.599934     0.127947    0.237489
  0.538068    -0.374462   -0.00917955  -0.0483455    0.0178214   -0.727155     0.242886   -0.167372    0.0824019   0.0346919   0.15853     -0.148753     -0.128253     0.229093    -0.662558    0.243984   -0.453077   -0.149075     0.199711    0.271708     0.171278     0.350442    -0.365082   -0.285069    -0.226052   -0.186963
 -0.00863118   0.249709    0.0197568    0.06229     -0.275992     0.123473     0.0183142  -0.728198    0.337639    0.412093   -0.617942    -0.000928079  -0.40613      0.712144     0.476211   -0.407253   -0.280499    0.385829    -0.133333   -0.189034    -0.159525    -0.316863     0.158828   -0.519731     0.770558   -0.362121
 -0.633088    -0.568112    0.185545    -0.153023     0.526478    -0.334769     1.2923      0.381171    0.0830609  -0.010274    0.0725087    0.44771      -0.446507     0.0207542   -0.466375   -0.0715739  -0.0191561   0.226933    -0.425232    0.618972    -0.0401899    0.270356     0.383792    0.576131    -0.606935   -0.454401
 -0.186414    -0.132435    0.722962    -0.458273    -0.194419     1.0008      -0.104051   -0.208938   -0.184654   -0.547602   -0.172888    -0.606564      0.241805    -0.275373     0.370626   -0.080657    0.0369462  -0.00400962   0.34741     0.256559    -0.105752    -0.454896     0.412254   -0.0504494    0.0667635   0.273779
 -0.387199    -0.203424   -0.410776     0.00631185   0.298503     0.301166     0.184454   -0.455524   -0.198085   -0.202006    0.362623     0.464127     -0.365565    -0.205887    -0.0380893   0.376411    0.788579    0.0676754    0.247883    0.28238      0.181812     0.0149022   -0.0801559  -0.356077     0.14143     0.221397
  0.453778     0.594436   -0.00762063   0.280248    -0.38499      0.389692    -1.27384    -0.269923   -0.130477    0.432481   -0.0741359   -0.423913      0.406022    -0.0311681    0.470804    0.408561    0.075342    0.180122     0.47411    -0.374422     0.0643817    0.126483    -0.356975   -0.460615     0.394036    0.428851
  0.238035     0.122705    0.122605    -0.306221     0.547918     0.0336154    0.197263   -0.0681225   0.319965    0.485377    0.1906      -0.462493     -0.29035     -0.371992     0.30921     0.166631   -0.116911    0.568403     0.851121   -0.0964133   -0.00781283   0.199576     0.211629    0.665226     0.0431637  -0.000675644
  0.0927832    0.0989954   0.178234    -0.162626     0.320594     0.0823124   -0.111176    0.0857849  -0.0311563   0.0227465   0.0922619   -0.0829784    -0.0508943   -0.0162092   -0.110275    0.184383    0.0823374   0.0953667    0.254379    0.161351     0.0488399    0.0562227   -0.0850915   0.287058     0.0228885   0.226873
  0.268843     0.52015    -0.043071    -0.384547     0.00668442   0.332946     0.184057    0.319828   -0.295662   -0.18098     0.0915884    0.295665      0.214787     0.489295     0.0246131  -0.127176   -0.560616   -0.39396     -0.334642    0.111336    -0.646112     0.285678     0.143225    0.132554    -0.0926665  -0.265417
 -0.0826743   -0.35207    -0.331424     0.0368875   -0.102568     0.00554761   0.0681356   0.543476   -0.432596   -0.148159    0.667303    -0.268649     -0.10155     -0.073408     0.756161   -0.529631    0.167894    0.470446     1.02213     0.561149    -0.274745     0.367604    -0.429434   -0.00168798  -0.310783   -0.580194
  0.373992     0.244453    0.233756    -0.500734     0.0852892   -0.220162    -0.0949413   0.586138   -0.0801919   0.0715558  -0.579533     0.291116     -0.427431     0.0423991    0.229563    0.618283    0.270057   -0.278417     0.0450904   0.842956    -0.10153      0.238255     0.176439    0.584572     0.585413   -0.169009[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413103
[ Info: iteration 2, average log likelihood -1.413087
[ Info: iteration 3, average log likelihood -1.413072
[ Info: iteration 4, average log likelihood -1.413057
[ Info: iteration 5, average log likelihood -1.413043
[ Info: iteration 6, average log likelihood -1.413030
[ Info: iteration 7, average log likelihood -1.413017
[ Info: iteration 8, average log likelihood -1.413004
[ Info: iteration 9, average log likelihood -1.412993
[ Info: iteration 10, average log likelihood -1.412982
┌ Info: EM with 100000 data points 10 iterations avll -1.412982
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
