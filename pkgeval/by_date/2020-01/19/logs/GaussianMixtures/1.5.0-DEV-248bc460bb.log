Julia Version 1.5.0-DEV.107
Commit 248bc460bb (2020-01-19 02:41 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed DataAPI ──────────── v1.1.0
 Installed GaussianMixtures ─── v0.3.0
 Installed Compat ───────────── v2.2.0
 Installed NearestNeighbors ─── v0.4.4
 Installed Parameters ───────── v0.12.0
 Installed BinDeps ──────────── v1.0.0
 Installed HDF5 ─────────────── v0.12.5
 Installed SpecialFunctions ─── v0.9.0
 Installed OrderedCollections ─ v1.1.0
 Installed Missings ─────────── v0.4.3
 Installed Arpack ───────────── v0.4.0
 Installed StatsFuns ────────── v0.9.3
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed BinaryProvider ───── v0.5.8
 Installed CMakeWrapper ─────── v0.2.3
 Installed LegacyStrings ────── v0.4.1
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed URIParser ────────── v0.4.0
 Installed JLD ──────────────── v0.9.1
 Installed Rmath ────────────── v0.6.0
 Installed DataStructures ───── v0.17.9
 Installed StatsBase ────────── v0.32.0
 Installed Blosc ────────────── v0.5.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed Distributions ────── v0.22.3
 Installed Distances ────────── v0.8.2
 Installed CMake ────────────── v1.1.2
 Installed StaticArrays ─────── v0.12.1
 Installed SortingAlgorithms ── v0.3.1
 Installed FillArrays ───────── v0.8.4
 Installed QuadGK ───────────── v2.3.1
 Installed FileIO ───────────── v1.2.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed PDMats ───────────── v0.9.10
 Installed Clustering ───────── v0.13.3
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_dBlW9x/Project.toml`
 [no changes]
  Updating `/tmp/jl_dBlW9x/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_FHGoBT/Project.toml`
 [no changes]
  Updating `/tmp/jl_FHGoBT/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_TzUE5c/Project.toml`
 [no changes]
  Updating `/tmp/jl_TzUE5c/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_DZc3VQ/Project.toml`
 [no changes]
  Updating `/tmp/jl_DZc3VQ/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_FGDthO/Project.toml`
 [no changes]
  Updating `/tmp/jl_FGDthO/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_FGDthO/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.803305642923262e7, [60808.64997194275, 39191.35002805725], [31541.12943494645 4449.301412708156 -15106.803156428832; -31651.268639757058 -4432.578205153324 15353.16064337828], [[57320.20326668507 -3268.248042542371 115.45205662093922; -3268.248042542371 62831.83958343626 3243.117825837049; 115.45205662093922 3243.1178258370487 62598.73487895853], [42851.77028609797 2666.7784874401414 -12.053826907419037; 2666.7784874401414 37651.15014585974 -2887.749417561841; -12.053826907418994 -2887.749417561841 36939.518062894625]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.078919e+03
      1       9.069478e+02      -1.719716e+02 |        5
      2       8.625402e+02      -4.440766e+01 |        0
      3       8.625402e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 862.5401617423931)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.077474
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.884413
[ Info: iteration 2, lowerbound -3.788347
[ Info: iteration 3, lowerbound -3.680366
[ Info: iteration 4, lowerbound -3.530886
[ Info: iteration 5, lowerbound -3.343393
[ Info: iteration 6, lowerbound -3.139698
[ Info: iteration 7, lowerbound -2.953660
[ Info: dropping number of Gaussions to 7
[ Info: iteration 8, lowerbound -2.800196
[ Info: iteration 9, lowerbound -2.699615
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.625975
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.543284
[ Info: iteration 12, lowerbound -2.472124
[ Info: iteration 13, lowerbound -2.414746
[ Info: iteration 14, lowerbound -2.370658
[ Info: iteration 15, lowerbound -2.338029
[ Info: iteration 16, lowerbound -2.316167
[ Info: iteration 17, lowerbound -2.307486
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302972
[ Info: iteration 19, lowerbound -2.299262
[ Info: iteration 20, lowerbound -2.299257
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: 46 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Jan 19 22:41:19 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Jan 19 22:41:26 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Sun Jan 19 22:41:29 2020: EM with 272 data points 0 iterations avll -2.077474
5.8 data points per parameter
, Sun Jan 19 22:41:30 2020: GMM converted to Variational GMM
, Sun Jan 19 22:41:39 2020: iteration 1, lowerbound -3.884413
, Sun Jan 19 22:41:39 2020: iteration 2, lowerbound -3.788347
, Sun Jan 19 22:41:39 2020: iteration 3, lowerbound -3.680366
, Sun Jan 19 22:41:39 2020: iteration 4, lowerbound -3.530886
, Sun Jan 19 22:41:39 2020: iteration 5, lowerbound -3.343393
, Sun Jan 19 22:41:39 2020: iteration 6, lowerbound -3.139698
, Sun Jan 19 22:41:39 2020: iteration 7, lowerbound -2.953660
, Sun Jan 19 22:41:39 2020: dropping number of Gaussions to 7
, Sun Jan 19 22:41:39 2020: iteration 8, lowerbound -2.800196
, Sun Jan 19 22:41:39 2020: iteration 9, lowerbound -2.699615
, Sun Jan 19 22:41:39 2020: dropping number of Gaussions to 4
, Sun Jan 19 22:41:39 2020: iteration 10, lowerbound -2.625975
, Sun Jan 19 22:41:39 2020: dropping number of Gaussions to 3
, Sun Jan 19 22:41:39 2020: iteration 11, lowerbound -2.543284
, Sun Jan 19 22:41:39 2020: iteration 12, lowerbound -2.472124
, Sun Jan 19 22:41:39 2020: iteration 13, lowerbound -2.414746
, Sun Jan 19 22:41:39 2020: iteration 14, lowerbound -2.370658
, Sun Jan 19 22:41:39 2020: iteration 15, lowerbound -2.338029
, Sun Jan 19 22:41:39 2020: iteration 16, lowerbound -2.316167
, Sun Jan 19 22:41:39 2020: iteration 17, lowerbound -2.307486
, Sun Jan 19 22:41:39 2020: dropping number of Gaussions to 2
, Sun Jan 19 22:41:39 2020: iteration 18, lowerbound -2.302972
, Sun Jan 19 22:41:39 2020: iteration 19, lowerbound -2.299262
, Sun Jan 19 22:41:39 2020: iteration 20, lowerbound -2.299257
, Sun Jan 19 22:41:39 2020: iteration 21, lowerbound -2.299255
, Sun Jan 19 22:41:39 2020: iteration 22, lowerbound -2.299254
, Sun Jan 19 22:41:39 2020: iteration 23, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 24, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 25, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 26, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 27, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 28, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 29, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 30, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 31, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 32, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 33, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 34, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 35, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 36, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 37, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 38, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 39, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 40, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 41, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 42, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 43, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 44, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: iteration 45, lowerbound -2.299253
, Sun Jan 19 22:41:39 2020: 46 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398241, 178.04509222601752]
β = [95.95490777398241, 178.04509222601752]
m = [2.00022925777534 53.85198717246115; 4.250300733269881 79.28686694436142]
ν = [97.95490777398241, 180.04509222601752]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948933 -0.008953123827346789; 0.0 0.012748664777409753], [0.18404155547483908 -0.00764404904232747; 0.0 0.008581705166333128]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000006
avll from stats: -1.0171906934558472
avll from llpg:  -1.0171906934558153
avll direct:     -1.0171906934558153
sum posterior: 99999.99999999999
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0125063077048855
avll from llpg:  -1.0125063077048855
avll direct:     -1.0125063077048855
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.00717184  -0.0762384   -0.0570965    0.0377571  -0.012081    -0.0253773   -0.16053     -0.031632     0.0741964     0.00715895  -0.130111    -0.150643    -0.00650338  -0.11846      -0.181451     -0.17115      0.00125207  -0.0454154   -0.0492894   -0.0507099    0.0462057    0.182524     0.0929909   -0.109785    0.0522734    0.0280619
  0.108231    -0.0173129   -0.0281413   -0.0844384   0.118581    -0.0181249    0.0727312   -0.175312    -0.0678219     0.160093     0.126415     0.104376    -0.0406037   -0.131367      0.0459427    -0.00411546   0.101931     0.0608646    0.0771422   -0.0606939    0.180062     0.0775662    0.0848933    0.134303   -0.0527561   -0.112384
  0.112788     0.214399    -0.0967909   -0.0168452   0.0349985   -0.189358    -0.0487295    0.0912465    0.27208       0.121312     0.0609805   -0.161968     0.191109    -0.00472538   -0.120513      0.138057    -0.0848698    0.00475934   0.0627345    0.0359688    0.014712     0.270426    -0.0446019    0.0442373   0.176656     0.0729113
 -0.0585604    0.054763    -0.184955     0.0936348  -0.242425     0.10209     -0.0334894    0.0411646   -0.00972951    0.0375456    0.0479137   -0.0604593    0.0914429    0.0740773     0.0947164     0.0815748   -0.0986106   -0.110796    -0.107645    -0.0339345   -0.0300623   -0.0400245   -0.0567312   -0.0985622   0.105726     0.177524
  0.216982    -0.0297492   -0.108365     0.144476   -0.124639    -0.0918337    0.121086     0.0119074   -0.150636      0.153632     0.0385542   -0.108334     0.276428    -0.127622      0.0623856    -0.0873292   -0.0422395    0.024915     0.0168133    0.0123173    0.0516805   -0.115739     0.0083175   -0.0300486   0.112017     0.0703819
 -0.0776436    0.180033     0.0194592    0.0244153  -0.016363    -0.257972    -0.129617     0.12693      0.0110407     0.155348     0.158938    -0.043327     0.0284139    0.207116      0.0380751     0.05375      0.0808086    0.0252297    0.0644722    0.0303202   -0.104885    -0.172061     0.0116096   -0.0771605  -0.00807729   0.044909
 -0.0196808   -0.0446223   -0.0850078   -0.0080642   0.0114073   -0.0528652    0.054303     0.0577699    0.130549      0.114356    -0.0789995   -0.0514816   -0.135741     0.121111      0.041005     -0.0743731   -0.279185     0.0252919   -0.0444085   -0.0653571    0.135821     0.0991872   -0.0228461    0.0981524  -0.170325     0.130133
 -0.0724058   -0.116246     0.0721966    0.0596915   0.0474599    0.0052064   -0.0440585   -0.00579377   0.194072     -0.066537     0.067709    -0.154833     0.00735683   0.144181      0.118889      0.0982296    0.104912     0.0971507    0.0188799    0.0127092    0.0131549   -0.14438      0.0295446   -0.169301    0.0259652   -0.0326038
 -0.0927799   -0.0291027   -0.10559     -0.0543862  -0.0211393    0.192598    -0.075589     0.0704997   -0.0697005    -0.0231584   -0.0352634    0.228143     0.0506898   -0.0997242    -0.108528     -0.0345302   -0.0585645   -0.061341    -0.0554347   -0.100472    -0.12308     -0.0073796    0.0522927    0.0404479  -0.0267316   -0.00198174
  0.1191      -0.0582584   -0.108306     0.193277    0.0506046    0.010118    -0.0146555   -0.105756    -0.144882      0.0517637    0.0401713   -0.204759     0.0561748    0.0284545    -0.178888     -0.0104985   -0.125171    -0.0930866   -0.0340453   -0.0465099   -0.0769408    0.0781254   -0.00578623   0.0975476   0.00101584  -0.0349063
  0.016172    -0.137881     0.00234263  -0.0536336   0.00475583   0.0424497   -0.0977453   -0.177048    -0.0561285    -0.0754298    0.153122     0.00387571  -0.216263     0.0538431    -0.0942631     0.0194015   -0.0181464    0.0236135   -0.0589816    0.136001    -0.226405     0.0172016   -0.0512619    0.021097    0.164135     0.304604
  0.0793185    0.133531     0.00870548  -0.0191079   0.184673     0.131763     0.120158    -0.020337     0.0837678    -0.063668    -0.0398097   -0.0408147    0.0187409    0.0823516     0.15304      -0.20983      0.0462105   -0.0921112    0.0492017   -0.0388484   -0.0747138   -0.00800222   0.0784426   -0.0627313  -0.0830077   -0.133293
  0.0177935   -0.118896    -0.0565895    0.0320507  -0.00361365   0.0159089   -0.00152841  -0.113743    -0.140144      0.183344    -0.266677     0.0522996   -0.0493729    0.0500827     0.156886      0.0828579    0.00545853  -0.0401674    0.106886     0.0695864    0.181476    -0.176833     0.0862528   -0.10062    -0.072257     0.00442242
 -0.107531    -0.0975135    0.0771371   -0.0642169   0.220263     0.0291123    0.0556331    0.0893609    0.0288255    -0.106801     0.12284     -0.101019     0.108201    -0.0518443    -0.0408746     0.0324591   -0.192455     0.101939    -0.0812206   -0.0625394   -0.118925    -0.0502211   -0.15218      0.132886    0.0418676   -0.0133904
  0.0244446   -0.0970523   -0.0374806    0.0665825  -0.0615861    0.0272676    0.137497    -0.0310779   -0.0060773     0.12859      0.0486017    0.11831     -0.0549074    0.112729     -0.0897513    -0.0958932   -0.00716013  -0.0154003   -0.0367874    0.168953     0.0375363    0.117811     0.13026      0.0299789  -0.021638     0.0667547
  0.237694    -0.0757492   -0.0284733   -0.0248219  -0.120659    -0.022688     0.00328473   0.0328822    0.0180948    -0.0669319   -0.0266344   -0.127999    -0.0609955    0.22615       0.103487      0.159351     0.0397932    0.00926357  -0.0706964   -0.0882419   -0.105965     0.124905    -0.0331729   -0.0144808   0.108709     0.0387696
  0.117873    -0.0219315    0.00995743  -0.0161096  -0.0182197    0.112845    -0.141496     0.0576937   -0.103151     -0.0362707   -0.034142    -0.0532227    0.0171536   -0.0535029    -0.0542652     0.0241526    0.017672     0.0877126    0.156579    -0.0364393   -0.0165249    0.0180316    0.0713666    0.0573794  -0.0203038   -0.00464191
 -0.037336     0.126288    -0.0369173    0.0205454   0.00369745   0.170368     0.112708     0.159638    -0.064646      0.0892903    0.0654515    0.0587025   -0.0329701    0.219677     -0.000229888  -0.0211895   -0.133038    -0.0522608    0.0123189   -0.135998     0.0600173   -0.0317662    0.0595537   -0.072235   -0.004573     0.0307318
 -0.0562698    0.0192509   -0.0117018   -0.127462    0.123496     0.101612     0.0850925    0.0680693   -0.0193695     0.135414    -0.0714243   -0.0716142   -0.0868402   -0.0491181    -0.0134005     0.00361228  -0.103983    -0.0792585   -0.125722    -0.0367936   -0.0591574    0.0185152   -0.0472225    0.0683921  -0.126155    -0.0748288
 -0.0225871    0.00289787  -0.104971     0.27532    -0.0917474   -0.0236605    0.0190548   -0.10976      0.0390259     0.130444     0.0223884    0.19046      0.0483542   -0.00817807    0.0366042    -0.0448768    0.163113     0.0143596    0.0513913   -0.11121     -0.192246     0.034637     0.0562787    0.0115537   0.0693683   -0.02788
 -0.113496    -0.143945    -0.206704     0.149441    0.0210179   -0.102292     0.044854    -0.0960471    0.0124233     0.127324    -0.00714776  -0.0436262    0.166955    -0.191258     -0.100004      0.219178     0.0614997   -0.0656791    0.216852     0.0518369    0.0997301   -0.00135726   0.143812     0.0274141  -0.124235     0.011635
  0.0340584    0.0119218   -0.0110233    0.101789    0.106856    -0.0202696    0.134661     0.00440124   0.0562322    -0.105353     0.00604523  -0.0864736   -0.0692148    0.0966246    -0.0782973     0.0153907   -0.00183504   0.0543874    0.0481847   -0.0128228   -0.0686651   -0.11976      0.112928     0.122       0.0542085    0.150682
  0.0794996   -0.0312936    0.120523     0.0224765   0.0199308    0.0480928   -0.11991      0.0380991    0.117485      0.210283    -0.0968213   -0.0946002   -0.0040029    0.0313726     0.0564051     0.0477981    0.0163843   -0.0417979   -0.0902761    0.0349593    0.0511008   -0.0173871    0.289079     0.0688887   0.0675329    0.219228
  0.0352169    0.112492    -0.00628663   0.0596483  -0.0144352    0.106529    -0.0682171   -0.0528684   -0.1234       -0.0359019    0.0137907   -0.0844116   -0.0655622    0.227504     -0.164261     -0.123219     0.0862255   -0.0555103   -0.143054     0.134958    -0.00306742  -0.00717628  -0.230242    -0.0776621  -0.149345    -0.0550666
  0.100152    -0.154773     0.051339     0.119203    0.120209     0.020697     0.140367     0.191325     0.0771181     0.063733     0.115047     0.0888639   -0.107211    -0.11869       0.0697485     0.0446634   -0.0379624    0.0537294    0.0343755   -0.00697946  -0.132298     0.00932539  -0.0636387    0.227841   -0.144207    -0.123988
 -0.0141448   -0.0981459   -0.0951817    0.0569731  -0.0701868   -0.0105874   -0.00135372  -0.0508774   -0.0358466     0.0959106    0.0866162    0.00872624  -0.139198    -0.127712     -0.0941042     0.112368     0.0436686   -0.0418899    0.00939048  -0.24839      0.0610462   -0.0395463   -0.159389    -0.104873    0.0897719    0.0129635
  0.123012    -0.148201    -0.253617    -0.09053    -0.083977    -0.0934219    0.0107416    0.0699192    0.12709       0.00596558  -0.199734    -0.00120639  -0.119035    -0.18341      -0.24162      -0.165883    -0.186067    -0.120629    -0.0740234    0.0604617    0.001055     0.042037    -0.115481     0.107056   -0.0312206   -0.0135197
  0.0487628    0.0117469    0.0385872   -0.0810955   0.0317424    0.0703013    0.073516     0.0502233    0.0791218     0.10003     -0.0880623    0.0592395    0.166298     0.0398174     0.0648099     0.0771395   -0.176949    -0.154755     0.093027    -0.169456    -0.0149696   -0.0225288    0.160856     0.134686   -0.0108469    0.0393409
 -0.125888     0.139682     0.0381319   -0.015213   -0.0219227    0.113042     0.197157    -0.0176204   -0.0121464    -0.0449989   -0.11417     -0.0448793   -0.110781     0.0957588     0.0916176     0.00161653   0.26005     -0.101644    -0.0838963    0.0314422    0.197307    -0.0239149   -0.109271    -0.0637297   0.113289    -0.075772
  0.111133     0.107209    -0.150381    -0.164203   -0.0135242    0.00563459  -0.0423809   -0.0782193   -0.000784601   0.00175218  -0.0555107   -0.0773333   -0.0465428    0.000647588  -0.133593     -0.140615    -0.022788     0.0611412   -0.116033     0.040429    -0.0629388    0.0354315   -0.0501543    0.0776412  -0.146897    -0.0153077
  0.0846669   -0.195       -0.0199253   -0.200768   -0.0963771    0.0415659    0.0767431   -0.0751609   -0.0712471     0.0313212   -0.0397133    0.09013      0.222488    -0.175191      0.119518     -0.048179     0.0659557   -0.00960599  -0.139648    -0.0254636    0.0132502    0.154342    -0.0299848   -0.100748   -0.0617046    0.137008
 -0.00417225  -0.0709373    0.132711     0.115862    0.00425031   0.109644    -0.14201      0.0933747   -0.0329346    -0.0971247    0.025117    -0.227165     0.0380733    0.0793418     0.0364061     0.0361459   -0.140847     0.156398    -0.0606856    0.173487     0.0528715    0.00306206  -0.0696845    0.171683    0.0574348   -0.0140829kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3903869424661264
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.390439
[ Info: iteration 2, average log likelihood -1.390376
[ Info: iteration 3, average log likelihood -1.389683
[ Info: iteration 4, average log likelihood -1.382753
[ Info: iteration 5, average log likelihood -1.367930
[ Info: iteration 6, average log likelihood -1.361039
[ Info: iteration 7, average log likelihood -1.358916
[ Info: iteration 8, average log likelihood -1.357745
[ Info: iteration 9, average log likelihood -1.356983
[ Info: iteration 10, average log likelihood -1.356486
[ Info: iteration 11, average log likelihood -1.356173
[ Info: iteration 12, average log likelihood -1.355966
[ Info: iteration 13, average log likelihood -1.355815
[ Info: iteration 14, average log likelihood -1.355692
[ Info: iteration 15, average log likelihood -1.355586
[ Info: iteration 16, average log likelihood -1.355488
[ Info: iteration 17, average log likelihood -1.355386
[ Info: iteration 18, average log likelihood -1.355263
[ Info: iteration 19, average log likelihood -1.355110
[ Info: iteration 20, average log likelihood -1.354934
[ Info: iteration 21, average log likelihood -1.354759
[ Info: iteration 22, average log likelihood -1.354600
[ Info: iteration 23, average log likelihood -1.354449
[ Info: iteration 24, average log likelihood -1.354283
[ Info: iteration 25, average log likelihood -1.354036
[ Info: iteration 26, average log likelihood -1.353568
[ Info: iteration 27, average log likelihood -1.352958
[ Info: iteration 28, average log likelihood -1.352585
[ Info: iteration 29, average log likelihood -1.352416
[ Info: iteration 30, average log likelihood -1.352337
[ Info: iteration 31, average log likelihood -1.352294
[ Info: iteration 32, average log likelihood -1.352270
[ Info: iteration 33, average log likelihood -1.352255
[ Info: iteration 34, average log likelihood -1.352245
[ Info: iteration 35, average log likelihood -1.352238
[ Info: iteration 36, average log likelihood -1.352233
[ Info: iteration 37, average log likelihood -1.352229
[ Info: iteration 38, average log likelihood -1.352226
[ Info: iteration 39, average log likelihood -1.352223
[ Info: iteration 40, average log likelihood -1.352220
[ Info: iteration 41, average log likelihood -1.352218
[ Info: iteration 42, average log likelihood -1.352215
[ Info: iteration 43, average log likelihood -1.352212
[ Info: iteration 44, average log likelihood -1.352209
[ Info: iteration 45, average log likelihood -1.352206
[ Info: iteration 46, average log likelihood -1.352203
[ Info: iteration 47, average log likelihood -1.352199
[ Info: iteration 48, average log likelihood -1.352196
[ Info: iteration 49, average log likelihood -1.352193
[ Info: iteration 50, average log likelihood -1.352190
┌ Info: EM with 100000 data points 50 iterations avll -1.352190
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3904393413549616
│     -1.390376435372069
│      ⋮
└     -1.3521898797950886
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.352293
[ Info: iteration 2, average log likelihood -1.352168
[ Info: iteration 3, average log likelihood -1.351314
[ Info: iteration 4, average log likelihood -1.344114
[ Info: iteration 5, average log likelihood -1.326522
[ Info: iteration 6, average log likelihood -1.314839
[ Info: iteration 7, average log likelihood -1.310272
[ Info: iteration 8, average log likelihood -1.307599
[ Info: iteration 9, average log likelihood -1.305594
[ Info: iteration 10, average log likelihood -1.304045
[ Info: iteration 11, average log likelihood -1.302819
[ Info: iteration 12, average log likelihood -1.301867
[ Info: iteration 13, average log likelihood -1.301155
[ Info: iteration 14, average log likelihood -1.300619
[ Info: iteration 15, average log likelihood -1.300197
[ Info: iteration 16, average log likelihood -1.299821
[ Info: iteration 17, average log likelihood -1.299441
[ Info: iteration 18, average log likelihood -1.299004
[ Info: iteration 19, average log likelihood -1.298560
[ Info: iteration 20, average log likelihood -1.298201
[ Info: iteration 21, average log likelihood -1.297886
[ Info: iteration 22, average log likelihood -1.297527
[ Info: iteration 23, average log likelihood -1.297149
[ Info: iteration 24, average log likelihood -1.296790
[ Info: iteration 25, average log likelihood -1.296506
[ Info: iteration 26, average log likelihood -1.296309
[ Info: iteration 27, average log likelihood -1.296175
[ Info: iteration 28, average log likelihood -1.296074
[ Info: iteration 29, average log likelihood -1.295991
[ Info: iteration 30, average log likelihood -1.295918
[ Info: iteration 31, average log likelihood -1.295854
[ Info: iteration 32, average log likelihood -1.295795
[ Info: iteration 33, average log likelihood -1.295741
[ Info: iteration 34, average log likelihood -1.295692
[ Info: iteration 35, average log likelihood -1.295646
[ Info: iteration 36, average log likelihood -1.295603
[ Info: iteration 37, average log likelihood -1.295561
[ Info: iteration 38, average log likelihood -1.295521
[ Info: iteration 39, average log likelihood -1.295484
[ Info: iteration 40, average log likelihood -1.295449
[ Info: iteration 41, average log likelihood -1.295417
[ Info: iteration 42, average log likelihood -1.295388
[ Info: iteration 43, average log likelihood -1.295358
[ Info: iteration 44, average log likelihood -1.295328
[ Info: iteration 45, average log likelihood -1.295297
[ Info: iteration 46, average log likelihood -1.295264
[ Info: iteration 47, average log likelihood -1.295231
[ Info: iteration 48, average log likelihood -1.295198
[ Info: iteration 49, average log likelihood -1.295167
[ Info: iteration 50, average log likelihood -1.295137
┌ Info: EM with 100000 data points 50 iterations avll -1.295137
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3522929161138788
│     -1.352167714382554
│      ⋮
└     -1.29513721286303
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.295261
[ Info: iteration 2, average log likelihood -1.295010
[ Info: iteration 3, average log likelihood -1.293197
[ Info: iteration 4, average log likelihood -1.279959
[ Info: iteration 5, average log likelihood -1.259747
[ Info: iteration 6, average log likelihood -1.249623
[ Info: iteration 7, average log likelihood -1.244878
[ Info: iteration 8, average log likelihood -1.241776
[ Info: iteration 9, average log likelihood -1.239423
[ Info: iteration 10, average log likelihood -1.237502
[ Info: iteration 11, average log likelihood -1.236096
[ Info: iteration 12, average log likelihood -1.235209
[ Info: iteration 13, average log likelihood -1.234438
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.233408
[ Info: iteration 15, average log likelihood -1.244864
[ Info: iteration 16, average log likelihood -1.238412
[ Info: iteration 17, average log likelihood -1.236711
[ Info: iteration 18, average log likelihood -1.236175
[ Info: iteration 19, average log likelihood -1.235880
[ Info: iteration 20, average log likelihood -1.235685
[ Info: iteration 21, average log likelihood -1.235548
[ Info: iteration 22, average log likelihood -1.235442
[ Info: iteration 23, average log likelihood -1.235344
[ Info: iteration 24, average log likelihood -1.235243
[ Info: iteration 25, average log likelihood -1.235132
[ Info: iteration 26, average log likelihood -1.235010
[ Info: iteration 27, average log likelihood -1.234881
[ Info: iteration 28, average log likelihood -1.234750
[ Info: iteration 29, average log likelihood -1.234621
[ Info: iteration 30, average log likelihood -1.234497
[ Info: iteration 31, average log likelihood -1.234379
[ Info: iteration 32, average log likelihood -1.234270
[ Info: iteration 33, average log likelihood -1.234167
[ Info: iteration 34, average log likelihood -1.234070
[ Info: iteration 35, average log likelihood -1.233978
[ Info: iteration 36, average log likelihood -1.233891
[ Info: iteration 37, average log likelihood -1.233812
[ Info: iteration 38, average log likelihood -1.233744
[ Info: iteration 39, average log likelihood -1.233687
[ Info: iteration 40, average log likelihood -1.233639
[ Info: iteration 41, average log likelihood -1.233599
[ Info: iteration 42, average log likelihood -1.233562
[ Info: iteration 43, average log likelihood -1.233528
[ Info: iteration 44, average log likelihood -1.233497
[ Info: iteration 45, average log likelihood -1.233466
[ Info: iteration 46, average log likelihood -1.233434
[ Info: iteration 47, average log likelihood -1.233399
[ Info: iteration 48, average log likelihood -1.233360
[ Info: iteration 49, average log likelihood -1.233316
[ Info: iteration 50, average log likelihood -1.233269
┌ Info: EM with 100000 data points 50 iterations avll -1.233269
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2952605056761435
│     -1.2950098604443125
│      ⋮
└     -1.233268504969249
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.233457
[ Info: iteration 2, average log likelihood -1.233100
[ Info: iteration 3, average log likelihood -1.231293
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.211451
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.175468
[ Info: iteration 6, average log likelihood -1.154932
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.132603
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.133077
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.127881
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.130670
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.126562
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.129238
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.125271
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.128467
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.124949
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.128350
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.124905
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.128328
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.124893
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.128320
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.124888
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.128316
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.124885
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.128314
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.124883
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.128312
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.124881
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.128310
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.124879
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.128307
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.124876
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.128304
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.124873
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.128300
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.124867
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.128293
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.124857
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.128278
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.124836
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.128249
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.124794
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.128192
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.124715
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.128081
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.124555
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.127849
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.124229
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.127420
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.123735
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.126972
┌ Info: EM with 100000 data points 50 iterations avll -1.126972
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2334568357126252
│     -1.2330995376625309
│      ⋮
└     -1.126971940200263
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.123802
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.123224
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.119935
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     17
│     18
│     19
│     20
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.088762
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     10
│     11
│     12
│     13
│      ⋮
│     20
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.042002
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      9
│     17
│     18
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.035421
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      8
│     10
│     11
│      ⋮
│     20
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.016797
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     17
│     18
│     19
│     20
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.041977
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      7
│      9
│     10
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.999801
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     17
│     18
│     19
│     20
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.054231
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      3
│      9
│     10
│      ⋮
│     22
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.013883
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│     26
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.047025
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      7
│      8
│      9
│     10
│      ⋮
│     19
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.006612
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│     17
│     18
│     19
│      ⋮
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.042567
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.022463
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     17
│     18
│     19
│     20
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.050509
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│      ⋮
│     20
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.013588
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     17
│     18
│     19
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.028863
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      3
│      9
│     10
│      ⋮
│     22
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.012135
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     17
│     18
│     19
│     20
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.056565
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.016378
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     17
│     18
│     19
│     20
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.031287
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      2
│      3
│      7
│      9
│      ⋮
│     22
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.002844
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.056923
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     19
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.019043
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.056071
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.007637
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     17
│     18
│     19
│     20
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.041881
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     23
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.007851
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│     26
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.056110
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     20
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.019560
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│      ⋮
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.045176
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.019737
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│     23
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.041711
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     22
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.003760
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│     26
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.066767
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│      ⋮
│     19
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.021184
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│      ⋮
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.037478
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.011255
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     17
│     18
│     19
│     20
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.052633
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     20
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.021470
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│     26
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.052636
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     20
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.013119
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      8
│     17
│     18
│      ⋮
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.040386
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      9
│     10
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.020636
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     17
│     18
│     19
│     20
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.039397
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      9
│     10
│      ⋮
│     22
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.013804
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      8
│     17
│     18
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.048961
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     20
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.025027
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.046418
┌ Info: EM with 100000 data points 50 iterations avll -1.046418
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.123801528488228
│     -1.123224264767865
│      ⋮
└     -1.046418468997436
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3903869424661264
│     -1.3904393413549616
│     -1.390376435372069
│     -1.389683456954806
│      ⋮
│     -1.0489607405795598
│     -1.0250274478352914
└     -1.046418468997436
32×26 Array{Float64,2}:
  0.0608636    0.0355872    0.0376706    -0.0418922    -0.00690507   0.0729962     0.113418    0.032548     0.0745429    0.09642     -0.0816063     0.0462897    0.159215     0.0463284    0.0537879   0.0664338   -0.172724     -0.13756       0.0792158   -0.164616    -0.0375331   -0.0346062    0.14584      0.139198    -0.0124205    0.039925
  0.0186431   -0.041058    -0.109965     -0.00438226    0.0149568   -0.0223445    -0.140996   -0.0520837    0.0546827   -0.00317753  -0.131143     -0.0943472   -0.020924    -0.0906847   -0.162361   -0.191752     0.0294126    -0.0303501    -0.065314    -0.0249362    0.0205414    0.148199     0.0554151   -0.0929364    0.0191999   -0.00537376
  0.0230092    0.00974422  -0.00752426    0.0978687     0.0709876   -0.0188613     0.130364    0.01267      0.0359841   -0.0888003   -0.00176383   -0.10353     -0.064658     0.0911587   -0.0816885  -0.0051304   -0.0229006     0.0444592     0.0489936    0.00139628  -0.0411893   -0.115632     0.109212     0.124072     0.0142033    0.13855
 -0.109985    -0.108554    -0.217462      0.144384      0.0508203   -0.106415      0.0462639  -0.094673     0.00497019   0.122435    -0.000349218  -0.0536423    0.156643    -0.164498    -0.0899049   0.216489     0.0369991    -0.0635541     0.218939     0.0499119    0.0766155   -0.0119157    0.143617     0.0305106   -0.124841     0.00587109
 -0.0909194   -0.0283199   -0.109568     -0.0506388     0.0200054    0.182586     -0.089818    0.108346    -0.072778    -0.0244618   -0.0962705     0.223881     0.0102284   -0.0978932   -0.120729   -0.019679    -0.0701282    -0.0681322    -0.0782736   -0.0943206   -1.04211      0.00726159  -0.00872181   0.103155    -0.0251343    0.0561047
 -0.0920602   -0.036245    -0.0939891    -0.0656993    -0.0561027    0.21571      -0.0139363  -0.00650781  -0.0687568   -0.0196729   -0.00672725    0.225687     0.0901896   -0.0573735   -0.106545   -0.10345     -0.0490362    -0.0655519    -0.0769447   -0.100378     0.652251    -0.0191884    0.104186    -0.00895536  -0.0277398   -0.0282298
 -0.012385    -0.0721619   -0.109664      0.0255985    -0.0639371    0.000917179  -0.0072815  -0.0436183   -0.0336868    0.0929581    0.0824297     0.00696702  -0.148212    -0.105447    -0.108238    0.114282    -0.0073078    -0.0456434    -0.0156004   -0.20291      0.0623407   -0.0254192   -0.168426    -0.100245     0.0659954    0.0163723
 -0.062171    -0.08536      0.0666929     0.0386854     0.0675141    0.0217492    -0.0367809  -0.0248143    0.179636    -0.0620113    0.0324968    -0.149368    -0.0244719    0.132105     0.0820599   0.0837221    0.0175326     0.0975856    -0.00546781   0.0271023    0.0036575   -0.129288     0.0469581   -0.117277    -0.0423498   -0.0306019
  0.105166    -0.100164    -0.116916      0.178984      0.0324693    0.00921334   -0.0370117  -0.0580173   -0.117578     0.0341144    0.0244152    -0.24114      0.0631244    0.013746    -0.177155    6.43918e-5  -0.130315     -0.0973618    -0.0265321   -0.0513815    0.0149778    0.0896288   -0.0267478    0.0987696    0.0140575    0.00240979
  0.0438674    0.156149    -0.00736728    0.090073     -0.0218511    0.112775     -0.0613965  -0.049019    -0.0969245   -0.0350804    0.00649541   -0.0936454   -0.09098      0.254959    -0.173916   -0.161444     0.0929968    -0.0453264    -0.155405     0.139317    -0.00812199  -0.0109949   -0.211918    -0.0856403   -0.173643    -0.0626951
 -0.0283597   -0.00240242  -0.110274      0.273942     -0.0889752   -0.0146956     0.010696   -0.11061      0.0551222    0.134251     0.0200498     0.154169     0.051122    -0.00472169   0.0167563  -0.0526475    0.15186       0.0179906     0.0416111   -0.0778779   -0.182182     0.0201527    0.04246      0.0124774    0.0692825   -0.0383894
  0.0289707   -0.119253    -0.0125567     0.0630231    -0.0569659    0.0394835     0.135269   -0.0423268   -0.0400655    0.125118     0.0444697     0.127459    -0.0485812    0.113972    -0.119048   -0.0923238   -0.000287834  -0.0289355    -0.0905353    0.242605     0.0368015    0.137842     0.109856     0.0307816   -0.0368564    0.154336
  0.241408    -0.0785022   -0.0289315    -0.0525804    -0.103693    -0.0130686    -0.0429448   0.0501499    0.0390665   -0.0991714   -0.0232896    -0.127936    -0.0562218    0.20892      0.124867    0.164081     0.0518422     0.012459     -0.0812159   -0.0316487   -0.10553      0.131556    -0.0337819   -0.00935299   0.107196     0.0386282
  0.106295     0.215098    -0.0952952    -0.0130781     0.0206875   -0.208396     -0.0336104   0.0910871    0.314924     0.116984     0.064809     -0.169606     0.186015    -0.0201417   -0.160935    0.134047    -0.0909439     0.00279732    0.0861908    0.0584764    0.0115926    0.273367    -0.0453274    0.0608139    0.17987      0.0757833
  0.00813552  -0.0978907    0.0332416     0.087485      0.00150602   0.0815182    -0.0746199  -0.0103586   -0.0743579    0.0391992   -0.117595     -0.0815856   -0.0102432    0.0408755    0.130523    0.0604902   -0.0531145     0.0663845     0.0402041    0.119361     0.116611    -0.093937    -0.00479508   0.0269432   -0.00431937  -0.00552363
  0.0850499    0.137824     0.00676242   -0.0575563     0.185877     0.11861       0.126055   -0.0657       0.0831549   -0.0903563   -0.0352746    -0.0327914    0.0233259    0.0831601    0.143966   -0.209731     0.0391138    -0.0824999     0.0479448   -0.0536068   -0.0732427    0.00659502   0.0774415   -0.0406103   -0.0979247   -0.117812
 -0.0333876   -0.523816    -0.000600047  -0.216056     -0.161017     0.0430425     0.0797159  -0.0746304   -0.0682032    0.0167645   -0.105721      0.22386      0.219961    -0.132722     0.120332   -0.0515092    0.0668941    -0.0275238     0.123967    -0.03192      0.0112118    2.30145     -0.0040663   -0.148193    -0.0280457    0.131978
  0.203912    -0.00865956   0.0031494    -0.205113     -0.0527279    0.0419145     0.10643    -0.0743392   -0.0678951    0.0196465    0.0397047     0.0218671    0.221603    -0.224242     0.123321   -0.0470246    0.0653746     0.00211886   -0.440936    -0.0246761    0.0135168   -1.59664     -0.0555187   -0.105252    -0.0696247    0.144008
  0.205247    -0.0112268   -0.12178       0.181693     -0.130995    -0.368247     -0.0931517   0.0133225   -0.230365     0.146936     0.056733     -0.100545     0.135489    -0.121412     0.0510901  -0.281537    -0.0441107    -0.288601      0.0206651   -0.123718    -0.0404463   -0.0937786   -0.0802319   -0.087751    -0.0425445    0.0977628
  0.213552    -0.0220081   -0.0954295     0.135398     -0.0918406    0.172122      0.25533     0.0125973   -0.0734445    0.143364     0.0327848    -0.102999     0.425828    -0.12821      0.0621282   0.154768    -0.0425666     0.52114       0.016765     0.174258     0.158022    -0.127313     0.125603    -0.085825     0.350747     0.0326032
  0.0348687   -0.0646197    0.0462372    -0.015236      0.0176826    0.0515744    -0.0879828  -0.0622969    0.0301094    0.0767943    0.0262374    -0.0169508   -0.10856      0.0313837   -0.0347767   0.0378685    0.0131383    -0.000205751  -0.075089     0.0779485   -0.093561    -0.00263537   0.112874     0.0540595    0.107337     0.233645
  0.0189718   -0.0452415   -0.0777901     0.00531697    0.0037856   -0.0483486     0.0894753   0.0587878    0.143657     0.0996528   -0.074883     -0.0512356   -0.154101     0.0954696    0.0369526  -0.0776317   -0.278457      0.0230946    -0.0184243   -0.0506471    0.122778     0.0970772   -0.0755985    0.0777108   -0.158616     0.0988877
 -0.0597407   -0.0660073    0.0298665    -0.0634296     0.221699     0.0445305     0.0492527   0.089559     0.0258598   -0.0710498    0.129212     -0.102535     0.0983353   -0.0368119    0.011307    0.00956084  -0.176574      0.130875     -0.090608    -0.0646557   -0.0878581   -0.0290769   -0.127553     0.162214     0.011715    -0.012706
 -0.084012     0.174756    -0.0195985     0.0107826    -0.0424479   -0.0576179    -0.0228915   0.131573    -0.0541745    0.135097     0.0857192    -0.00473608  -0.00427418   0.271098     0.0227959   0.0146272   -0.00728222   -0.0266087     0.0374428   -0.0375326   -0.00523695  -0.111992     0.045001    -0.024074    -0.0330361    0.0418266
  0.0929407   -0.152034    -0.260288     -0.0856453    -0.069889    -0.092561      0.011931    0.0674984    0.11933      0.00749293  -0.198832      0.00909377  -0.115584    -0.184356    -0.240781   -0.16809     -0.198428     -0.100556     -0.103863     0.0610216    0.0069585    0.045143    -0.161004     0.0801717   -0.0787862   -0.018262
  0.112999    -0.170739     0.0323753     0.165633      0.113114     0.0115182     0.159769    0.190958     0.127786     0.0420427    0.123983      0.0371965   -0.107558    -0.124353     0.0693776   0.0482102   -0.0257783     0.0270736     0.0729968   -0.0174758   -0.129713     0.00803369   0.0023735    0.229528    -0.145336    -0.140933
  0.140381    -0.035358    -0.0136115    -0.0134563    -0.0444521    0.116967     -0.139517    0.0552597   -0.0969297   -0.0670261   -0.0413221    -0.0414256    0.0164705   -0.0533576   -0.0541476   0.0214786   -0.000933233   0.0633841     0.151037    -0.0359065   -0.0192099    0.017469     0.0586606    0.0497153   -0.0184709   -0.00185989
 -0.135416     0.153203     0.0340214    -0.000933931  -0.0373823    0.105001      0.196756   -0.0103622   -0.0279669   -0.0356071   -0.0986434    -0.0465705   -0.111821     0.100932     0.097415    0.00237054   0.268345     -0.179989     -0.0753551    0.031468     0.197317    -0.0231979   -0.117105    -0.0518802    0.118274    -0.0743059
 -0.0219069    0.0248553   -0.195384      0.143641     -0.405565    -0.114875     -0.0795524   0.0756174   -0.0343363    0.150064    -0.04962      -0.0617806    0.0980373    0.111491     0.0490289   0.0998879   -0.170089     -0.0973269    -0.0424332   -0.0263365    0.00755224  -0.687631    -0.1081      -0.188541     0.122353     0.186951
 -0.0268275    0.0679955   -0.18091       0.0859116     0.047007     0.320669     -0.0137696   0.00892817   0.0243148    0.0097579    0.103693     -0.0562494    0.0720638    0.049494     0.130497    0.0635889   -0.0537352    -0.112718     -0.121883    -0.0426056   -0.0172513    0.699541     0.0122458   -0.0248956   -0.037206     0.169259
 -0.060365    -0.0037166   -0.00879243   -0.131243      0.120272     0.0954738     0.120561    0.0646738   -0.0191077    0.135468    -0.0668673    -0.0553206   -0.0971161   -0.0395348   -0.0137086   0.00326579  -0.12359      -0.076044     -0.163949    -0.0371348   -0.0680241    0.0582556   -0.042985     0.0687593   -0.154241    -0.0578611
  0.145815    -0.0342568   -0.0316654    -0.074403      0.115833    -0.0225493     0.0739492  -0.152       -0.0675656    0.134565     0.126447      0.0727244   -0.0258853   -0.133615     0.0460801  -0.00318412   0.14569       0.0632731     0.0934056   -0.0620127    0.18598      0.0751994    0.0924586    0.137937    -0.0370912   -0.105824[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      3
│      9
│     10
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.999356
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      3
│      7
│      8
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.985809
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      3
│      9
│     10
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.995047
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      3
│      7
│      8
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.981731
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      3
│      8
│      9
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.997525
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      3
│      7
│      8
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.985295
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      3
│      8
│      9
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.993794
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      3
│      7
│      8
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.987249
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      3
│      8
│      9
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.995333
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      3
│      7
│      8
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.983828
┌ Info: EM with 100000 data points 10 iterations avll -0.983828
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.330191e+05
      1       6.477043e+05      -1.853148e+05 |       32
      2       6.210876e+05      -2.661674e+04 |       32
      3       6.068160e+05      -1.427161e+04 |       32
      4       5.978417e+05      -8.974290e+03 |       32
      5       5.917676e+05      -6.074129e+03 |       32
      6       5.878724e+05      -3.895124e+03 |       32
      7       5.853377e+05      -2.534778e+03 |       32
      8       5.832491e+05      -2.088546e+03 |       32
      9       5.809243e+05      -2.324828e+03 |       32
     10       5.786145e+05      -2.309790e+03 |       32
     11       5.768407e+05      -1.773815e+03 |       32
     12       5.758581e+05      -9.825575e+02 |       32
     13       5.753456e+05      -5.124975e+02 |       32
     14       5.749844e+05      -3.611818e+02 |       32
     15       5.747185e+05      -2.659939e+02 |       32
     16       5.745535e+05      -1.649709e+02 |       32
     17       5.744648e+05      -8.867936e+01 |       32
     18       5.744052e+05      -5.956236e+01 |       32
     19       5.743674e+05      -3.781361e+01 |       32
     20       5.743455e+05      -2.197107e+01 |       32
     21       5.743242e+05      -2.123826e+01 |       31
     22       5.743030e+05      -2.124358e+01 |       32
     23       5.742855e+05      -1.744140e+01 |       32
     24       5.742729e+05      -1.261367e+01 |       31
     25       5.742623e+05      -1.066044e+01 |       31
     26       5.742512e+05      -1.109913e+01 |       30
     27       5.742373e+05      -1.381703e+01 |       31
     28       5.742261e+05      -1.122589e+01 |       28
     29       5.742173e+05      -8.843415e+00 |       28
     30       5.742066e+05      -1.069314e+01 |       31
     31       5.741950e+05      -1.153551e+01 |       30
     32       5.741851e+05      -9.964679e+00 |       29
     33       5.741744e+05      -1.069668e+01 |       30
     34       5.741634e+05      -1.099018e+01 |       30
     35       5.741548e+05      -8.573668e+00 |       28
     36       5.741487e+05      -6.099048e+00 |       26
     37       5.741440e+05      -4.724034e+00 |       26
     38       5.741366e+05      -7.365389e+00 |       27
     39       5.741254e+05      -1.126752e+01 |       29
     40       5.741120e+05      -1.335339e+01 |       31
     41       5.740983e+05      -1.369393e+01 |       30
     42       5.740842e+05      -1.407924e+01 |       31
     43       5.740709e+05      -1.335714e+01 |       29
     44       5.740579e+05      -1.299850e+01 |       29
     45       5.740475e+05      -1.039280e+01 |       27
     46       5.740379e+05      -9.540510e+00 |       28
     47       5.740301e+05      -7.835047e+00 |       27
     48       5.740248e+05      -5.336471e+00 |       26
     49       5.740190e+05      -5.731869e+00 |       26
     50       5.740155e+05      -3.530785e+00 |       26
K-means terminated without convergence after 50 iterations (objv = 574015.5141772432)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.288031
[ Info: iteration 2, average log likelihood -1.253753
[ Info: iteration 3, average log likelihood -1.220856
[ Info: iteration 4, average log likelihood -1.183443
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.138745
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.099387
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     16
│     18
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.044216
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      8
│     10
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.042478
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     11
│     17
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.036755
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.072728
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.038305
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      8
│     14
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.011067
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     10
│     11
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.047035
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     21
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.066713
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.049413
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      8
│     11
│     14
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.011997
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     20
│     21
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.055618
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.072805
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.033540
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│      8
│     11
│     14
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.008706
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.058915
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     19
│     21
│     22
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.016512
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.055742
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      8
│     11
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.023100
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     20
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.032840
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.035008
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     16
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.024753
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      8
│     11
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.039384
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.063331
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.009114
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     10
│     16
│     17
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.022248
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      8
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.062739
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.045415
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│     10
│     19
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.007783
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     16
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.038342
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     14
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.063358
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.065642
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      8
│     10
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.027750
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     16
│     19
│     21
│     23
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.016571
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     14
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.056069
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│     17
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.030696
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.052905
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     11
│     16
│     19
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.020920
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     14
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.036699
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.040851
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     17
│     22
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.020086
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     14
│     16
│     19
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.024016
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      8
│     10
│     20
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.040046
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.068301
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.023445
┌ Info: EM with 100000 data points 50 iterations avll -1.023445
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.144593      0.151423   -0.0933561     0.0121287    0.0301488   -0.26654     -0.02234      0.0801426    0.346535      0.11244      0.052774     -0.159394      0.202343    -0.0053592   -0.127206     0.113424     -0.0904676    0.0206195    0.0854464    0.0338957    0.0143603    0.236496    -0.0359979    0.0565764     0.218711      0.061214
  0.0461707     0.0220581   0.0535553    -0.0227703   -0.0275179    0.0672148    0.121437     0.041744     0.0808259     0.100081    -0.0764326     0.0563994     0.165937     0.0381926    0.0701577    0.0760442    -0.167827    -0.149534     0.087953    -0.170083    -0.0320184   -0.0293914    0.155883     0.125702     -0.000182214   0.0458177
 -0.109751     -0.108138   -0.216226      0.143871     0.0501521   -0.106541     0.0465174   -0.0947903    0.00515075    0.121769     0.000105497  -0.0533181     0.155185    -0.165686    -0.0888109    0.216164      0.0418655   -0.0624036    0.220573     0.0497337    0.0754073   -0.0125117    0.143651     0.0317094    -0.124993      0.00759679
  0.101121     -0.028552   -0.0508756     0.00340845   0.0843439   -0.0185856    0.0511097   -0.141       -0.0443024     0.13589      0.10261       0.0709771    -0.0127267   -0.124162     0.0452085   -0.00868191    0.140669     0.0446722    0.0805758   -0.067478     0.0939926    0.0388057    0.0803672    0.110891     -0.015005     -0.0898022
 -0.0867413     0.140276   -0.0434874     0.012102    -0.00826134   0.169853     0.107697     0.154477    -0.0945227     0.0893121    0.0593499     0.0559633    -0.0246205    0.233691     0.040595     0.00514714   -0.126822    -0.0513038    0.00674058  -0.141438     0.0848296   -0.027777     0.0544912   -0.011163     -0.000232552   0.0351769
 -0.135288      0.153187    0.0345463    -0.0010706   -0.0350528    0.107184     0.193883    -0.0083691   -0.0285131    -0.0348664   -0.0985901    -0.046295     -0.110998     0.0991689    0.0962703    0.0023042     0.267797    -0.181418    -0.0724125    0.0310029    0.19707     -0.0229581   -0.115713    -0.0522974     0.116489     -0.0737917
  0.103866     -0.0906749  -0.10773       0.168865     0.0337609    0.0112095   -0.0411629   -0.0531918   -0.0988279     0.0358139    0.0232804    -0.233307      0.0576956    0.0283489   -0.179354     0.00645767   -0.126126    -0.0941337   -0.0260057   -0.0604912    0.0160912    0.0955068   -0.00768794   0.0982714     0.00863774    0.00242862
  0.0245278    -0.0468619  -0.0898585    -0.0313297    0.00148128  -0.0457       0.164832     0.0393554    0.13567       0.172349    -0.0743205    -0.0534323    -0.210877     0.111905     0.0459527   -0.109518     -0.260562     0.0133171   -0.0175549   -0.0671711    0.118071     0.0914888   -0.122975     0.101153     -0.225651      0.081286
 -0.0255596     0.0464072  -0.187475      0.121906    -0.195319     0.0957066   -0.0478825    0.0462923    0.000559612   0.0837066    0.0236898    -0.0600717     0.0886358    0.0811813    0.0886739    0.0833119    -0.112485    -0.105877    -0.0778258   -0.0351865   -0.00244369  -0.0155605   -0.0471853   -0.111261      0.0544516     0.177009
 -0.029106     -0.0926161  -0.0974097     0.0426578    0.00381716  -0.0253766   -0.170616    -0.0191727    0.0870539    -0.00990345  -0.149806     -0.121957     -0.0229822   -0.118077    -0.144574    -0.183097     -0.00994528  -0.0435516   -0.0435618   -0.0475915    0.0511227    0.160895     0.0624734   -0.0933095     0.0192513     0.00741254
  0.0436854     0.116153   -0.0147281     0.101115    -0.0169588    0.108341    -0.0636311   -0.0454407   -0.0944773    -0.0263264    0.0116153    -0.0918469    -0.0795068    0.243685    -0.160815    -0.167744      0.0852573   -0.050594    -0.156045     0.133764    -0.0174318   -0.00503926  -0.22769     -0.0829846    -0.184654     -0.0595703
  0.0920439    -0.15125    -0.260131     -0.0844446   -0.0730263   -0.0922476    0.0130453    0.067702     0.121114      0.00654436  -0.198991      0.00974712   -0.116129    -0.18495     -0.240038    -0.168844     -0.19979     -0.101343    -0.103883     0.0610005    0.00600671   0.0446195   -0.159382     0.0800361    -0.0788674    -0.0181599
  0.088139     -0.0178586   0.110599      0.0245574    0.0299372    0.0657701   -0.12239      0.0409831    0.113637      0.198905    -0.0935581    -0.000312009  -0.0323108   -0.0175913    0.0477907    0.0666433     0.0349814   -0.043826    -0.0588355    0.0486601    0.0413815   -0.0216807    0.282453     0.0662391     0.0728048     0.190147
  0.0233529     0.0120287  -0.00460811    0.107438     0.0746576   -0.018589     0.134343     0.0210409    0.0384181    -0.0963627    0.00223614   -0.1065       -0.0687879    0.100721    -0.0784669   -0.000948305  -0.01663      0.0425828    0.0552052    0.00271985  -0.0399171   -0.116692     0.104548     0.121849      0.024415      0.139418
 -0.0846026     0.158214    0.0120399     0.0204857   -0.0173478   -0.25613     -0.123328     0.135344     0.011818      0.149658     0.157878     -0.0732336     0.0271501    0.249153     0.0357119    0.063177      0.0598748    0.0266657    0.063881     0.0396443   -0.103906    -0.175398     0.0104857   -0.0136484    -0.015045      0.0513021
 -0.0838601    -0.0933896   0.0425138    -0.0702811    0.231197     0.0376817    0.0541341    0.0873233    0.0311647    -0.0924931    0.134209     -0.122695      0.113064    -0.0578683   -0.00890498   0.0214034    -0.193731     0.151736    -0.0963153   -0.0576585   -0.104656    -0.029493    -0.148721     0.159594      0.025952     -0.017689
 -0.0152298    -0.0856694  -0.110385      0.020749    -0.0636009    0.00169467   0.00077435  -0.0425611   -0.033288      0.098068     0.0846787     0.00743682   -0.148159    -0.111544    -0.102158     0.107572     -0.0161633   -0.0478068   -0.00974212  -0.206054     0.0588616   -0.0284498   -0.16351     -0.102685      0.0770193     0.0197433
  0.128545     -0.101831    0.0141865     0.0769188    0.0303627    0.0646496    0.00666166   0.124222     0.0118807    -0.0130553    0.0388026     0.00363283   -0.0441168   -0.0880136    0.00640286   0.0369063    -0.0133349    0.0446877    0.114198    -0.0271767   -0.072536     0.0121839    0.0327472    0.140839     -0.080006     -0.0727224
  0.0217329    -0.126758    0.0280818     0.0215905   -0.044445     0.0509741    0.143444    -0.00453401  -0.123801      0.126574     0.0560642     0.0772327    -0.0786298    0.104082    -0.136882    -0.0847396    -0.00501985  -0.0390543   -0.13241      0.207992     0.0489668    0.102863     0.0487058    0.0384304    -0.107711      0.239589
 -0.0159305    -0.106395   -0.0042711    -0.0213232   -0.00410209   0.0332234   -0.0689804   -0.133515    -0.00307615   -0.0448002    0.124527     -0.0132668    -0.193946     0.103274    -0.0740595    0.0181433    -0.0587372    0.0232811   -0.0749328    0.0918724   -0.176968     0.034516    -0.044374     0.0442337     0.147302      0.297208
 -0.0629389     0.0852722  -0.00297868   -0.0981877    0.118218     0.102515     0.152102     0.142713    -0.0183275     0.140051    -0.098902     -0.0625128    -0.190752    -0.036469    -0.00865898   0.00149656   -0.212479    -0.0656256   -0.185343    -0.0391106   -0.0650164    0.0342613   -0.0406418    0.0968313    -0.220905     -0.133546
  0.212428     -0.0205515  -0.106022      0.151286    -0.115385    -0.108565     0.0721453    0.0108541   -0.153716      0.14643      0.0451241    -0.10342       0.281243    -0.127639     0.0569007   -0.0667404    -0.043286     0.0973408    0.0147364    0.0223508    0.0551582   -0.106867     0.0225783   -0.0898728     0.152632      0.0679769
  0.000698225  -0.0662894  -0.0649202     0.171154    -0.073072     0.0132591    0.103457    -0.0831404    0.0325751     0.131054     0.0305469     0.165793      0.00507618   0.0803972   -0.0672294   -0.0713282     0.0653935   -0.00620973  -0.027286     0.0879917   -0.0658999    0.12444      0.0949894    0.0162647     0.0288699     0.0402869
  0.0884623     0.141499    0.00297924   -0.0560405    0.184489     0.108117     0.126352    -0.0621547    0.0851188    -0.0864101   -0.033584     -0.0350785     0.0274125    0.0822951    0.133947    -0.201905      0.0359865   -0.0811637    0.0505147   -0.0522363   -0.0721677    0.0126014    0.0754982   -0.0389823    -0.0924302    -0.113185
  0.0160761    -0.061797   -0.0679392     0.0414084    0.00328794   0.00562172  -0.00161845  -0.0833316   -0.0941733     0.157399    -0.213426      0.0335931    -0.0230678    0.0178936    0.117891     0.0897112    -0.00282975  -0.0267822    0.115474     0.0873557    0.167628    -0.127338     0.0217046   -0.0925662    -0.062408      0.0282344
  0.101193      0.109057   -0.170038     -0.14883      0.0709086    0.00443889  -0.0347305   -0.0887178   -0.0135973     0.0153481   -0.0565177    -0.0711202    -0.0315575   -0.00128072  -0.137069    -0.135508     -0.0310138    0.0615849   -0.113017     0.0407496   -0.0618362    0.0426059   -0.0284691    0.0903706    -0.130639     -0.000501266
 -0.0914998    -0.0323653  -0.101705     -0.0584837   -0.0192574    0.198955    -0.0512901    0.0487316   -0.0707542    -0.0220738   -0.0511739     0.224883      0.0510083   -0.0769375   -0.114164    -0.061407     -0.0593638   -0.0659418   -0.0777557   -0.0973299   -0.17407     -0.00582047   0.0492817    0.0462974    -0.0265116     0.0125637
  0.0621986     0.176758   -0.071227      0.0609301   -0.00153957   0.0734726   -0.0220478    0.0261012    0.246387      0.0537633    0.0399173    -0.162724      0.0968336    0.0658886   -0.11763      0.100739     -0.00568877   0.00799386   0.01216      0.211738     0.0246542    0.142551    -0.106695    -0.00383367    0.181008      0.0357418
  0.228361     -0.0567458  -0.0318506    -0.0501242   -0.109664    -0.0263867   -0.0468984    0.053791     0.064738     -0.0817764   -0.0173829    -0.130301     -0.0511825    0.189621     0.107748     0.158895      0.0392117    0.011382    -0.0661845   -0.0373024   -0.094781     0.139477    -0.0343136    0.000540368   0.110964      0.041368
  0.0423602    -0.205193    0.000564941  -0.197197    -0.0325683    0.051396     0.0975235   -0.0597      -0.0554703     0.0527984   -0.0489766     0.0725148     0.168966    -0.144174     0.0791549   -0.0322942     0.0382999   -0.0234201   -0.168       -0.0352452   -0.00580331   0.155429    -0.0341178   -0.0716798    -0.0605816     0.110108
 -0.0725938    -0.109858    0.111603      0.0712928    0.0512937    0.0282554   -0.0350456   -0.0141985    0.190963     -0.072169     0.0547933    -0.154818     -0.022041     0.151568     0.111967     0.108674      0.035188     0.0969697    0.0144647    0.017964     0.0169237   -0.155551     0.0679652   -0.164984     -0.0193777    -0.0281529
  0.02154      -0.0797948   0.130113      0.120887     0.00488524   0.0949527   -0.147005     0.0928385   -0.0115843    -0.0874537    0.0256945    -0.228526      0.0398312    0.0550663    0.0935153    0.0409832    -0.112999     0.162669    -0.0417702    0.159333     0.0387487    0.00390507  -0.0326782    0.165661      0.0583401    -0.0292092[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     14
│     16
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.984931
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.925013
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     11
│     14
│     16
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.973035
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.924729
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     14
│     16
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.974331
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.914891
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     14
│     16
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.982717
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.917460
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     11
│     14
│     16
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.973157
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.924490
┌ Info: EM with 100000 data points 10 iterations avll -0.924490
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.157016    -0.0919353   -0.080503     0.127238     0.113988    -0.00510186   0.091884    -0.0168069    0.115215    -0.112844     0.0594761    -0.049772    -0.127676      0.0799852  -0.0191267   -0.0633885    0.225357     0.117635     0.0512956   -0.0490063   -0.121564   -0.0972115    0.042859    -0.0821793    0.0436284   0.139577
 -0.0209073   -0.0364656   -0.108992     0.100016    -0.0479082    0.139767     0.0890674   -0.0965467    0.10665     -0.0962596    0.201798      0.228245     0.0495344     0.15159    -0.056651     0.0927955   -0.139892    -0.0987209    0.0434483   -0.0873196    0.0246656  -0.0417704    0.00444623  -0.113321    -0.118267   -0.00712236
 -0.147207     0.0644037   -0.0290712    0.0446276   -0.0477323   -0.0108795   -0.04669     -0.0641595    0.0137786   -0.0390433   -0.00751014    0.015498    -0.0279881    -0.118235    0.0294865    0.111146    -0.0895157   -0.209256    -0.011293    -0.0109977    0.10675    -0.056534    -0.133646     0.0180149   -0.0136092   0.121247
  0.025713     0.0380824   -0.106937    -0.0873785    0.117066    -0.192649    -0.0767801    0.0677415    0.00194219   0.0556974   -0.000277992   0.0535139    0.0035885    -0.136422   -0.0621976   -0.077269     0.182262    -0.0924112    0.106615     0.103545    -0.0345982  -0.0168541   -0.174969     0.117617     0.0835532  -0.1674
  0.0200509   -0.185222     0.115696    -0.092954    -0.0720463   -0.0321008    0.0298014    0.0565448    0.168941    -0.0566333   -0.0801035     0.0112522    0.00608554   -0.0214275   0.102356     0.0462861    0.029537     0.0541545    0.0261114    0.0809858   -0.0608174   0.0515685    0.117201    -0.109094    -0.0322316   0.0167178
  0.0278575   -0.098741    -0.0520602   -0.0309148    0.0905785    0.0847325    0.172909     0.0195413    0.0979942    0.0240074    0.118273     -0.185721     0.0630603     0.111549   -0.110481    -0.117913    -0.0789167    0.114393    -0.217515    -0.13168     -0.0406295  -0.101651    -0.112772    -0.0678701    0.0609315   0.0148055
  0.0228059    0.0689669    0.0512591    0.00109514  -0.00922552   0.0495556    0.155118    -0.0828982   -0.0236924    0.0324868   -0.144581      0.064985     0.00632616   -0.0372222  -0.0156527    0.0617818   -0.263534    -0.104178     0.180227    -0.0185642    0.0829838  -0.0542802   -0.0493391    0.0229008   -0.152599    0.0463015
 -0.127462     0.1967       0.00928083  -0.111262    -0.00926112  -0.0471267    0.066362    -0.0327135   -0.00293484   0.016065    -0.161201     -0.062936    -0.0637386    -0.165604    0.101178     0.0255091   -0.0448837   -0.129557    -0.0878214   -0.0544852   -0.0868761  -0.123863    -0.0402112   -0.00833446   0.0561531  -0.130973
  0.0863817   -0.075743     0.113209     0.014116    -0.0654273    0.040764     0.193737     0.010698     0.0480012    0.0261165   -0.0782138     0.108787    -0.00019205   -0.145544    0.00523048  -0.0746908   -0.0161301    0.0205535    0.139345     0.140068     0.115292    0.0107837   -0.175073    -0.156449    -0.015839   -0.136416
 -0.00977271   0.135022     0.0684933   -0.061614     0.1729      -0.0659346    0.0314358   -0.155407     0.0407172    0.00966139  -0.112298     -0.054164     0.0557137    -0.15022    -0.0381463    0.00404394  -0.00795582   0.0542448   -0.0178867    0.0275169    0.186947   -0.151525    -0.0779505   -0.0385696    0.0367315  -0.0424266
  0.00125696   0.234354     0.0030443   -0.0281359    0.0862816   -0.0648564   -0.160015     0.085047    -0.00566164  -0.0203345   -0.0797181    -0.139336    -0.0344286    -0.122728   -0.21158      0.225626     0.00122094  -0.010581    -0.11283     -0.0956902    0.152842    0.0291993    0.063156     0.103759    -0.0449629   0.15263
 -0.141648    -0.0549926    0.101544     0.287586    -0.00864469   0.0215357    0.275647    -0.0346822   -0.141733    -0.154735     0.0741414    -0.158121    -0.132617     -0.0545906   0.012822     0.0914344    0.0551324   -0.0598563    0.0534028   -0.0787588    0.106009   -0.0436154    0.119843    -0.0115683    0.0799048  -0.117708
 -0.173234     0.0835337    0.064234    -0.055568     0.00456558   0.08248      0.119972    -0.064171     0.100691     0.052013    -0.0223847     0.0745587    0.0284215    -0.0612922   0.0604212    0.0192482    0.0989447   -0.0370855   -0.142685    -0.0336801    0.193539   -0.0800843   -0.0785644   -0.106291    -0.213978   -0.119911
 -0.0614196   -0.0379122    0.0399075   -0.00552176  -0.0699495   -0.0420312   -0.0638825    0.0492494    0.183262     0.045799     0.11539      -0.00401268  -0.080229     -0.0103448  -0.175753     0.195639     0.00512575  -0.0619855   -0.0515405    0.287821    -0.0610736   0.148537     0.0326951   -0.076955     0.112668    0.0133581
  0.0612165    0.0849214    0.0123895   -0.0507288   -0.136525    -0.0895855   -0.04521      0.0446675   -0.041036     0.0290476    0.0966182     0.0917303   -0.0209527    -0.0489128  -0.0928808   -0.0302645    0.0247394   -0.0687843   -0.00310634   0.100516    -0.0514722   0.025078    -0.0705014   -0.0375465   -0.0149934   0.0671195
 -0.0240823    0.0124498    0.0438625   -0.00409095  -0.0466345    0.0315889   -0.103129    -0.0029567   -0.0545946   -0.0208107   -0.0181186    -0.163983    -0.0731913    -0.0165976   0.258136    -0.0368467   -0.0462683    0.0492818   -0.066168    -0.0425689    0.0942893   0.0293337    0.108894     0.0209544   -0.097765    0.0919517
  0.0565181    0.0731179   -0.0338405    0.00396072  -0.127204     0.0125378   -0.00708149   0.0227357    0.0245803    0.0493725    0.0348353     0.0508473    0.102967      0.05866     0.164061     0.0369603   -0.0311039    0.0371373    0.0245794    0.0728513   -0.10816     0.0911115   -0.153976     0.11954      0.0389585  -0.0535712
 -0.0582803   -0.108938    -0.061241    -0.0644041    0.0594555    0.0592253    0.0758518    0.00311542   0.0423931   -0.0986232    0.00183968    0.0261807   -0.0889992     0.116683   -0.0104882    0.0048231   -0.0926917   -0.0151838    0.0555475    0.0980511   -0.0795285   0.0544678   -0.110756    -0.119838    -0.0869662  -0.078008
 -0.162385    -0.0620163   -0.140732    -0.0262663    0.0526491   -0.221828     0.0448662    0.0458612    0.031365     0.0800959    0.0198827    -0.0134862    0.0476791     0.0183507  -0.11541     -0.00531498  -0.0762831   -0.104252    -0.24012     -0.347626     0.122327    0.0129299   -0.0673167   -0.0197756    0.0669009   0.215029
 -0.143723    -0.00553924  -0.0317092    0.116828     0.0727972   -0.178473     0.0844721    0.215997     0.281094    -0.0818254   -0.0301554    -0.0455386    0.0343953     0.0286813  -0.158181     0.0967363    0.203826    -0.143802    -0.0428442   -0.0167076    0.0203396  -0.073611    -0.00616318  -0.0938056   -0.0208356  -0.0417286
 -0.0767724    0.00087378   0.345903    -0.0794384   -0.0120091   -0.0252311    0.0296069    0.0933707   -0.00634233  -0.0947969    0.269482     -0.0942645   -0.000321622  -0.0843658  -0.020445     0.0397178   -0.0428649   -0.13318      0.0931277   -0.166271    -0.0372665  -0.0909792   -0.143721     0.0468839    0.015674   -0.033657
  0.142292     0.0603069    0.207505     0.111138    -0.0680461    0.0336817   -0.0158536    0.00943604   0.0901832   -0.0258052    0.0466018     0.00266902  -0.00131532    0.0572044   0.0878272   -0.0604498   -0.0941375    0.143569     0.0130182    0.0296774    0.153562    0.108936     0.0736725    0.0769453   -0.0754497  -0.0701925
  0.0671462   -0.15939      0.0261174   -0.123003    -0.153835    -0.0690003   -0.0703652    0.0291493   -0.059015     0.0299986    0.108654      0.127519     0.0751167     0.0233793   0.0324893    0.0453618    0.0210921   -0.0141322   -0.10908     -0.0431414   -0.0968513   0.108217     0.0388627   -0.107537    -0.0492239  -0.0539909
  0.123681     0.00622036   0.0460047    0.0694507   -0.0418377    0.0668563    0.0352172    0.0478994   -0.0796294    0.20379      0.145877      0.126676    -0.0855616     0.10871    -0.286        0.0517567   -0.0309361    0.00884477   0.032638     0.0504959    0.128801   -0.0735376    0.125071    -0.177459    -0.157268    0.00864354
 -0.143803    -0.0305812   -0.023915     0.0135331   -0.0183425   -0.00692535  -0.134056     0.033568     0.0764153    0.0122365   -0.119832     -0.0706774    0.000220746   0.0303554  -0.0238016   -0.284375     0.0135735   -0.0304998    0.123229     0.17027     -0.0824976   0.0148085    0.107437     0.0229244   -0.233781    0.191843
 -0.0610919   -0.00488324   0.158554     0.0462226    0.162871    -0.0152351   -0.0301688    0.022368    -0.117129    -0.0330915    0.020344      0.0964799    0.0522019    -0.163062    0.133937    -0.105451    -0.078004    -0.0784061   -0.0750662    0.0174146   -0.0854799  -0.0383719   -0.0621446    0.0477664   -0.0433994   0.00268124
  0.086048     0.284802     0.0284198    0.0472705    0.00439741   0.0137362   -0.0757521   -0.0355739   -0.13738     -0.166441    -0.194714      0.0140774    0.0914883    -0.0489733  -0.0137991   -0.152351     0.00255015  -0.0739002   -0.0121015   -0.0701131    0.098932   -0.0631069    0.00462539  -0.0325403    0.0814736   0.0131695
 -0.067918    -0.0955256    0.0342527    0.0374154    0.124945     0.148798    -0.102095    -0.138608     0.088628    -0.0259985    0.305493     -0.0154764   -0.0439436     0.0580696  -0.146185    -0.138482     0.00408318   0.00732901  -0.0687091    0.115145     0.0271239   0.0468641    0.036451     0.00843376   0.0195109  -0.113432
 -0.0664595    0.130325    -0.124651    -0.0259277    0.138224     0.0926456   -0.121422     0.176298     0.0148938    0.0770572   -0.11877      -0.0668166    0.0828508    -0.0664273   0.0484628   -0.111115    -0.135305     0.191446    -0.047787     0.112014    -0.128756    0.204526    -0.0636404    0.0124154    0.0618589  -0.0367869
  0.0108459   -0.0299215   -0.0627089    0.0487003   -0.14068     -0.0472973   -0.0520595    0.0291151   -0.0296656    0.108846    -0.0416329     0.0277128    0.184722     -0.0124054  -0.00422399   0.0440138    0.120923    -0.0863655   -0.050304     0.00325275  -0.114017   -0.22677     -0.126205     0.0276602   -0.140452   -0.0329621
 -0.0271227   -0.218608    -0.0165998    0.045118     0.00569321  -0.0252191   -0.193986     0.0278654   -0.100244     0.0895602    0.119067     -0.165184     0.0412957    -0.0937269   0.0628408    0.00109924   0.0891627    0.0997973    0.0351696    0.277157    -0.0532892  -0.00162452   0.0194477    0.00988252   0.121021   -0.128717
  0.0172392   -0.0757789   -0.0014413   -0.0135328    0.0624576   -0.0767322    0.0670568    0.0494816    0.00805271  -0.155577     0.0718308    -0.0787704   -0.018048     -0.0322404   0.0470515   -0.0212913   -0.00170887   0.0264099   -0.0268713    0.0370606   -0.082781   -0.108257    -0.0976924   -0.0170397    0.085856    0.134407kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4164877156308886
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416506
[ Info: iteration 2, average log likelihood -1.416444
[ Info: iteration 3, average log likelihood -1.416402
[ Info: iteration 4, average log likelihood -1.416358
[ Info: iteration 5, average log likelihood -1.416310
[ Info: iteration 6, average log likelihood -1.416257
[ Info: iteration 7, average log likelihood -1.416196
[ Info: iteration 8, average log likelihood -1.416123
[ Info: iteration 9, average log likelihood -1.416018
[ Info: iteration 10, average log likelihood -1.415828
[ Info: iteration 11, average log likelihood -1.415439
[ Info: iteration 12, average log likelihood -1.414678
[ Info: iteration 13, average log likelihood -1.413500
[ Info: iteration 14, average log likelihood -1.412267
[ Info: iteration 15, average log likelihood -1.411452
[ Info: iteration 16, average log likelihood -1.411077
[ Info: iteration 17, average log likelihood -1.410933
[ Info: iteration 18, average log likelihood -1.410880
[ Info: iteration 19, average log likelihood -1.410859
[ Info: iteration 20, average log likelihood -1.410851
[ Info: iteration 21, average log likelihood -1.410847
[ Info: iteration 22, average log likelihood -1.410845
[ Info: iteration 23, average log likelihood -1.410844
[ Info: iteration 24, average log likelihood -1.410843
[ Info: iteration 25, average log likelihood -1.410842
[ Info: iteration 26, average log likelihood -1.410842
[ Info: iteration 27, average log likelihood -1.410841
[ Info: iteration 28, average log likelihood -1.410841
[ Info: iteration 29, average log likelihood -1.410840
[ Info: iteration 30, average log likelihood -1.410840
[ Info: iteration 31, average log likelihood -1.410840
[ Info: iteration 32, average log likelihood -1.410839
[ Info: iteration 33, average log likelihood -1.410839
[ Info: iteration 34, average log likelihood -1.410839
[ Info: iteration 35, average log likelihood -1.410839
[ Info: iteration 36, average log likelihood -1.410838
[ Info: iteration 37, average log likelihood -1.410838
[ Info: iteration 38, average log likelihood -1.410838
[ Info: iteration 39, average log likelihood -1.410838
[ Info: iteration 40, average log likelihood -1.410838
[ Info: iteration 41, average log likelihood -1.410838
[ Info: iteration 42, average log likelihood -1.410838
[ Info: iteration 43, average log likelihood -1.410837
[ Info: iteration 44, average log likelihood -1.410837
[ Info: iteration 45, average log likelihood -1.410837
[ Info: iteration 46, average log likelihood -1.410837
[ Info: iteration 47, average log likelihood -1.410837
[ Info: iteration 48, average log likelihood -1.410837
[ Info: iteration 49, average log likelihood -1.410837
[ Info: iteration 50, average log likelihood -1.410837
┌ Info: EM with 100000 data points 50 iterations avll -1.410837
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4165064552262103
│     -1.4164435433373717
│      ⋮
└     -1.4108370921874789
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410856
[ Info: iteration 2, average log likelihood -1.410791
[ Info: iteration 3, average log likelihood -1.410747
[ Info: iteration 4, average log likelihood -1.410702
[ Info: iteration 5, average log likelihood -1.410652
[ Info: iteration 6, average log likelihood -1.410597
[ Info: iteration 7, average log likelihood -1.410541
[ Info: iteration 8, average log likelihood -1.410485
[ Info: iteration 9, average log likelihood -1.410435
[ Info: iteration 10, average log likelihood -1.410391
[ Info: iteration 11, average log likelihood -1.410355
[ Info: iteration 12, average log likelihood -1.410325
[ Info: iteration 13, average log likelihood -1.410300
[ Info: iteration 14, average log likelihood -1.410277
[ Info: iteration 15, average log likelihood -1.410255
[ Info: iteration 16, average log likelihood -1.410233
[ Info: iteration 17, average log likelihood -1.410210
[ Info: iteration 18, average log likelihood -1.410186
[ Info: iteration 19, average log likelihood -1.410159
[ Info: iteration 20, average log likelihood -1.410130
[ Info: iteration 21, average log likelihood -1.410098
[ Info: iteration 22, average log likelihood -1.410063
[ Info: iteration 23, average log likelihood -1.410025
[ Info: iteration 24, average log likelihood -1.409986
[ Info: iteration 25, average log likelihood -1.409945
[ Info: iteration 26, average log likelihood -1.409904
[ Info: iteration 27, average log likelihood -1.409865
[ Info: iteration 28, average log likelihood -1.409827
[ Info: iteration 29, average log likelihood -1.409793
[ Info: iteration 30, average log likelihood -1.409763
[ Info: iteration 31, average log likelihood -1.409737
[ Info: iteration 32, average log likelihood -1.409714
[ Info: iteration 33, average log likelihood -1.409696
[ Info: iteration 34, average log likelihood -1.409681
[ Info: iteration 35, average log likelihood -1.409668
[ Info: iteration 36, average log likelihood -1.409657
[ Info: iteration 37, average log likelihood -1.409649
[ Info: iteration 38, average log likelihood -1.409641
[ Info: iteration 39, average log likelihood -1.409635
[ Info: iteration 40, average log likelihood -1.409630
[ Info: iteration 41, average log likelihood -1.409626
[ Info: iteration 42, average log likelihood -1.409622
[ Info: iteration 43, average log likelihood -1.409618
[ Info: iteration 44, average log likelihood -1.409615
[ Info: iteration 45, average log likelihood -1.409613
[ Info: iteration 46, average log likelihood -1.409610
[ Info: iteration 47, average log likelihood -1.409608
[ Info: iteration 48, average log likelihood -1.409606
[ Info: iteration 49, average log likelihood -1.409605
[ Info: iteration 50, average log likelihood -1.409603
┌ Info: EM with 100000 data points 50 iterations avll -1.409603
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4108556734571795
│     -1.410790901756207
│      ⋮
└     -1.4096030201231946
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409613
[ Info: iteration 2, average log likelihood -1.409568
[ Info: iteration 3, average log likelihood -1.409532
[ Info: iteration 4, average log likelihood -1.409492
[ Info: iteration 5, average log likelihood -1.409446
[ Info: iteration 6, average log likelihood -1.409390
[ Info: iteration 7, average log likelihood -1.409323
[ Info: iteration 8, average log likelihood -1.409247
[ Info: iteration 9, average log likelihood -1.409164
[ Info: iteration 10, average log likelihood -1.409081
[ Info: iteration 11, average log likelihood -1.409001
[ Info: iteration 12, average log likelihood -1.408929
[ Info: iteration 13, average log likelihood -1.408867
[ Info: iteration 14, average log likelihood -1.408813
[ Info: iteration 15, average log likelihood -1.408767
[ Info: iteration 16, average log likelihood -1.408727
[ Info: iteration 17, average log likelihood -1.408692
[ Info: iteration 18, average log likelihood -1.408661
[ Info: iteration 19, average log likelihood -1.408632
[ Info: iteration 20, average log likelihood -1.408606
[ Info: iteration 21, average log likelihood -1.408581
[ Info: iteration 22, average log likelihood -1.408558
[ Info: iteration 23, average log likelihood -1.408536
[ Info: iteration 24, average log likelihood -1.408516
[ Info: iteration 25, average log likelihood -1.408497
[ Info: iteration 26, average log likelihood -1.408478
[ Info: iteration 27, average log likelihood -1.408461
[ Info: iteration 28, average log likelihood -1.408445
[ Info: iteration 29, average log likelihood -1.408430
[ Info: iteration 30, average log likelihood -1.408415
[ Info: iteration 31, average log likelihood -1.408402
[ Info: iteration 32, average log likelihood -1.408389
[ Info: iteration 33, average log likelihood -1.408377
[ Info: iteration 34, average log likelihood -1.408365
[ Info: iteration 35, average log likelihood -1.408354
[ Info: iteration 36, average log likelihood -1.408344
[ Info: iteration 37, average log likelihood -1.408334
[ Info: iteration 38, average log likelihood -1.408324
[ Info: iteration 39, average log likelihood -1.408315
[ Info: iteration 40, average log likelihood -1.408305
[ Info: iteration 41, average log likelihood -1.408297
[ Info: iteration 42, average log likelihood -1.408288
[ Info: iteration 43, average log likelihood -1.408280
[ Info: iteration 44, average log likelihood -1.408272
[ Info: iteration 45, average log likelihood -1.408264
[ Info: iteration 46, average log likelihood -1.408256
[ Info: iteration 47, average log likelihood -1.408248
[ Info: iteration 48, average log likelihood -1.408240
[ Info: iteration 49, average log likelihood -1.408232
[ Info: iteration 50, average log likelihood -1.408225
┌ Info: EM with 100000 data points 50 iterations avll -1.408225
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4096131493968846
│     -1.4095678745897486
│      ⋮
└     -1.4082248899402126
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408226
[ Info: iteration 2, average log likelihood -1.408167
[ Info: iteration 3, average log likelihood -1.408114
[ Info: iteration 4, average log likelihood -1.408052
[ Info: iteration 5, average log likelihood -1.407976
[ Info: iteration 6, average log likelihood -1.407883
[ Info: iteration 7, average log likelihood -1.407770
[ Info: iteration 8, average log likelihood -1.407640
[ Info: iteration 9, average log likelihood -1.407501
[ Info: iteration 10, average log likelihood -1.407362
[ Info: iteration 11, average log likelihood -1.407230
[ Info: iteration 12, average log likelihood -1.407111
[ Info: iteration 13, average log likelihood -1.407006
[ Info: iteration 14, average log likelihood -1.406915
[ Info: iteration 15, average log likelihood -1.406836
[ Info: iteration 16, average log likelihood -1.406767
[ Info: iteration 17, average log likelihood -1.406707
[ Info: iteration 18, average log likelihood -1.406654
[ Info: iteration 19, average log likelihood -1.406607
[ Info: iteration 20, average log likelihood -1.406565
[ Info: iteration 21, average log likelihood -1.406526
[ Info: iteration 22, average log likelihood -1.406490
[ Info: iteration 23, average log likelihood -1.406457
[ Info: iteration 24, average log likelihood -1.406426
[ Info: iteration 25, average log likelihood -1.406397
[ Info: iteration 26, average log likelihood -1.406370
[ Info: iteration 27, average log likelihood -1.406344
[ Info: iteration 28, average log likelihood -1.406320
[ Info: iteration 29, average log likelihood -1.406297
[ Info: iteration 30, average log likelihood -1.406275
[ Info: iteration 31, average log likelihood -1.406255
[ Info: iteration 32, average log likelihood -1.406235
[ Info: iteration 33, average log likelihood -1.406216
[ Info: iteration 34, average log likelihood -1.406199
[ Info: iteration 35, average log likelihood -1.406182
[ Info: iteration 36, average log likelihood -1.406165
[ Info: iteration 37, average log likelihood -1.406150
[ Info: iteration 38, average log likelihood -1.406135
[ Info: iteration 39, average log likelihood -1.406120
[ Info: iteration 40, average log likelihood -1.406106
[ Info: iteration 41, average log likelihood -1.406093
[ Info: iteration 42, average log likelihood -1.406080
[ Info: iteration 43, average log likelihood -1.406067
[ Info: iteration 44, average log likelihood -1.406054
[ Info: iteration 45, average log likelihood -1.406042
[ Info: iteration 46, average log likelihood -1.406031
[ Info: iteration 47, average log likelihood -1.406019
[ Info: iteration 48, average log likelihood -1.406008
[ Info: iteration 49, average log likelihood -1.405997
[ Info: iteration 50, average log likelihood -1.405987
┌ Info: EM with 100000 data points 50 iterations avll -1.405987
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4082260174819503
│     -1.408167467129482
│      ⋮
└     -1.4059865929373538
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405986
[ Info: iteration 2, average log likelihood -1.405917
[ Info: iteration 3, average log likelihood -1.405853
[ Info: iteration 4, average log likelihood -1.405779
[ Info: iteration 5, average log likelihood -1.405689
[ Info: iteration 6, average log likelihood -1.405579
[ Info: iteration 7, average log likelihood -1.405448
[ Info: iteration 8, average log likelihood -1.405300
[ Info: iteration 9, average log likelihood -1.405141
[ Info: iteration 10, average log likelihood -1.404978
[ Info: iteration 11, average log likelihood -1.404818
[ Info: iteration 12, average log likelihood -1.404669
[ Info: iteration 13, average log likelihood -1.404533
[ Info: iteration 14, average log likelihood -1.404411
[ Info: iteration 15, average log likelihood -1.404303
[ Info: iteration 16, average log likelihood -1.404209
[ Info: iteration 17, average log likelihood -1.404125
[ Info: iteration 18, average log likelihood -1.404052
[ Info: iteration 19, average log likelihood -1.403986
[ Info: iteration 20, average log likelihood -1.403927
[ Info: iteration 21, average log likelihood -1.403873
[ Info: iteration 22, average log likelihood -1.403824
[ Info: iteration 23, average log likelihood -1.403779
[ Info: iteration 24, average log likelihood -1.403736
[ Info: iteration 25, average log likelihood -1.403697
[ Info: iteration 26, average log likelihood -1.403661
[ Info: iteration 27, average log likelihood -1.403626
[ Info: iteration 28, average log likelihood -1.403593
[ Info: iteration 29, average log likelihood -1.403563
[ Info: iteration 30, average log likelihood -1.403534
[ Info: iteration 31, average log likelihood -1.403506
[ Info: iteration 32, average log likelihood -1.403480
[ Info: iteration 33, average log likelihood -1.403456
[ Info: iteration 34, average log likelihood -1.403432
[ Info: iteration 35, average log likelihood -1.403410
[ Info: iteration 36, average log likelihood -1.403389
[ Info: iteration 37, average log likelihood -1.403370
[ Info: iteration 38, average log likelihood -1.403351
[ Info: iteration 39, average log likelihood -1.403333
[ Info: iteration 40, average log likelihood -1.403316
[ Info: iteration 41, average log likelihood -1.403300
[ Info: iteration 42, average log likelihood -1.403285
[ Info: iteration 43, average log likelihood -1.403271
[ Info: iteration 44, average log likelihood -1.403257
[ Info: iteration 45, average log likelihood -1.403244
[ Info: iteration 46, average log likelihood -1.403232
[ Info: iteration 47, average log likelihood -1.403220
[ Info: iteration 48, average log likelihood -1.403209
[ Info: iteration 49, average log likelihood -1.403198
[ Info: iteration 50, average log likelihood -1.403188
┌ Info: EM with 100000 data points 50 iterations avll -1.403188
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4059861746956324
│     -1.4059170816605964
│      ⋮
└     -1.4031880696301262
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4164877156308886
│     -1.4165064552262103
│     -1.4164435433373717
│     -1.416401593097847
│      ⋮
│     -1.4032090123181422
│     -1.4031983063720375
└     -1.4031880696301262
32×26 Array{Float64,2}:
  0.0580927  -0.319713     0.0233918   0.309529    -0.8553     -0.501842     0.294362     0.630019     0.522156    0.415317    0.131725    -0.303887     0.150962     0.203111    -0.412449    0.345086    0.113894    -0.430064    0.0541116    0.227636      0.300793    0.378699     0.461761    -0.138374    -0.613348     0.198406
 -0.360743   -0.518115    -0.694763    0.330665    -0.0244605  -0.077781    -0.147874     0.695016    -0.0591404  -0.560351    0.179251    -0.169286    -0.0927954    0.167615    -0.129917   -0.210814    0.0594787    0.0549727   0.487224    -0.195028      0.0376906   0.195717     0.208981     0.743619    -0.599942     0.0149133
  0.217013   -0.707751    -0.145619   -0.276882    -0.0470976   0.108009     0.465425     0.0715702    0.0675492   0.206909   -0.223012    -0.223244    -0.736263     0.113969    -0.712702   -0.1042     -0.197564    -0.286683   -0.221418     0.431926     -0.582764    0.274377     0.403984     0.170413    -0.336147    -0.164746
 -0.17437    -0.645954     0.378414   -0.159685     0.558059   -0.0544827    0.0799051   -0.242024    -0.731823    0.180716   -0.0744426   -0.0837855   -0.340767     0.690155    -0.123623    0.158137    0.107323    -0.0746568   0.290032    -0.0173416     0.808425    0.00215235   0.0916172    0.252088    -0.238811     0.509564
  0.0491967   0.161948    -0.259097    0.135977    -0.0403617   0.204293    -0.253692    -0.311286    -0.077264   -0.381093   -0.540711    -0.0471118    0.229737    -0.083312    -0.0250631  -0.0345025  -0.460886    -0.380501   -0.415076    -0.154358      0.457631   -1.0834       0.824571     0.0444019   -0.196626     0.71352
 -0.102044    0.050401    -0.411234    0.3517       0.473084    0.180793     0.342458     0.182151     0.0330782   0.229247   -0.290844    -0.106144     0.290703    -0.214855    -0.914087    0.0752286   0.24426      0.78392    -0.240918    -0.215854      0.252675   -0.0397508    0.553893    -0.0867667   -0.401485     0.189632
  0.0870141   0.144566    -0.191503    0.303876     0.634308    0.732779    -0.421407    -0.238144    -0.433465   -0.187534    0.11166      0.482039    -0.86575     -0.446649    -0.342514   -0.0894266  -0.520257     0.321431   -0.113553     0.126501     -0.22746    -0.352974    -0.0854728    0.0863827   -0.00912468  -0.28463
 -0.0448126   0.496721     0.727207   -0.337832     0.503975   -0.30043     -0.490148     0.167826    -0.0955924  -0.17573    -0.515753     0.256139    -0.782646    -0.44171     -0.195765   -0.0633177  -0.0235358    0.581353    0.336827     0.270222     -0.0872866  -0.104107     0.343932     0.325064    -0.199844     0.151685
 -0.104254    0.417423     0.536151    0.00693244   0.252592    0.0880712    0.0943804   -0.224104     0.174526   -0.0237828   0.103273     0.0731475    0.617119    -0.0817648    0.401351    0.0688365   0.0828851    0.300599    0.115897     0.159404      0.127812   -0.0897527   -0.421776    -0.822878     0.528911     0.0442598
 -0.0922433  -0.101102     0.0522665   0.622811     0.11406     0.365394    -0.122347     0.00460071  -0.245063   -0.09568     0.332714    -0.156482     0.0294183    0.037573     0.371869    0.08402    -0.30635      0.179541    0.413735     0.00896582    0.0336364   0.405952     0.161865     0.464105    -0.232438    -0.234325
  0.354101    0.38266     -0.0182849  -0.271542    -0.386506   -0.93206     -0.575286     0.0619293    0.165241    0.109146    0.219088    -0.0225183    0.0100817    0.0850771    0.135377    0.249464   -0.370675    -0.820011    0.0610208   -0.228727      0.0410331  -0.714032     0.135112    -0.622261    -0.335984    -0.547657
  0.148332   -0.276702    -0.0943987  -0.615978    -0.148672   -0.644102     0.318034    -0.0635284    0.170951    0.0274477  -0.220405     0.234708     0.156864     0.560131     0.161807   -0.233466    0.361653    -0.391195   -0.116664    -0.318416     -0.13917    -0.131033    -0.0789179   -0.0667877   -0.104612     0.29087
 -0.187058    0.278467    -0.466949   -0.274974    -0.523954    0.109404    -0.119483     0.395193    -0.0518198  -0.156598    0.17819     -0.143728    -0.0438612   -0.988111    -0.385246    0.0293609   0.469415    -0.330696   -0.0571277    0.329381     -0.309682   -0.167121    -0.688791    -0.0304051    0.27683     -0.287793
 -0.616416   -0.00508474   0.528332    0.0288689   -0.158882    0.206647    -0.0386624   -0.209365    -0.105128    0.354694   -0.517187    -0.101415    -0.251818    -1.12139     -0.318627   -0.0502839   0.233886    -0.321881   -0.411251    -0.106064      0.615182   -0.302572    -0.532131     0.438117    -0.395807    -0.133061
  0.127657   -0.292372     0.221937    0.0603445    0.104809   -0.375744     0.390126     0.52008      0.588542   -0.26864     0.171262     0.107381    -0.804492     0.29791      0.167664   -0.609043   -0.14391     -0.0290229  -0.00399691   0.35104      -0.0293429   0.734481    -0.774285    -0.100434     0.746163    -0.0124195
  0.249988    0.113653     0.492643   -0.593823     0.243375   -0.432747     0.170993    -0.268171     0.455504    0.370624   -0.337747     0.232346    -0.526389    -0.299721    -0.235403   -0.0261609  -0.0120006   -0.134769   -0.643024    -0.107838     -0.170914   -0.234276    -0.528957    -0.464815     0.569238    -0.013449
 -0.0407771   0.378466    -0.34326    -0.0793585    0.29845    -0.019464     0.0391852    0.243528    -0.329183   -0.448299    0.102919     0.0737118   -0.00599277   0.533645     0.367746   -0.202979   -0.0550413    0.726345    0.265948     0.498705     -0.321526    0.506174     0.063024     0.0851627    0.519575     0.319464
  1.10106     0.0937699   -0.508733    0.183871     0.0446668  -0.122733     0.332842    -0.0495633   -0.158938   -0.531006    0.448858     0.117075     0.29413      0.668571     0.274307    0.263542   -0.00361512   0.0776006   0.518775    -0.0398085    -0.475789    0.088217     0.269433    -0.265683     0.172273    -0.0844639
  0.286841   -0.159379     0.388872    0.217244     0.269186    0.0579083   -0.129482    -0.229397     0.316244    0.0317365   0.267468    -0.00679265  -0.0449985    0.580274     0.324694   -0.0953969  -1.02943      0.305379    0.00956576   0.0554649     0.220404    0.101557     0.412618    -0.0278747   -0.115296     0.196471
 -0.0363899   0.357391     0.605363    0.376279     0.800876    0.0324236    0.149421    -0.163352    -0.0438038  -0.0154858  -0.00975735  -0.228801     0.0299223   -0.0884935    0.0114319  -0.080094    0.286634     0.305929    0.222467    -0.315732      0.501322    0.0191686   -0.123217    -0.0370929    0.0248397    0.185993
 -0.463917   -0.0847711   -0.110788   -0.0449796   -0.217666    0.154943     0.461726    -0.0432485    0.0369108  -0.252729    0.323112     0.243854     0.022223    -0.388315     0.204835   -0.331399    0.0631378    0.456651    0.0182954    0.222565     -0.135118    0.0672807   -0.0996162    0.366177     0.207405    -0.436533
 -0.18715     0.1892       0.201655   -0.116939    -0.124911    0.960901    -0.00438864  -0.774754    -0.197557    0.0183211  -0.316378    -0.153159     0.645271    -0.269463     0.501785    0.139988    0.0297024    0.185785    0.463506    -0.433736     -0.0484236  -0.109264     0.0493213    0.364752    -0.110046    -0.123579
 -0.246768   -0.269359     0.144028   -0.198437    -0.102663    0.404721    -0.351119     0.395473    -0.112574    0.65158     0.561708    -0.658829     0.261287     0.430772    -0.298086   -0.472375    0.329226     0.136865    0.149181     0.719256     -0.155634    0.406435    -0.13807      0.067514    -0.159798    -0.501046
 -0.0678446   0.119863     0.207442    0.426475     0.0458574   0.202464    -0.107074     0.297818     0.0271352   0.280379    0.741237    -0.0274754   -0.170795    -0.290426     0.0647278   0.811902    0.0215339    0.317852    0.173688     0.651206      0.177805    0.611341    -0.217359     0.363299     0.096469    -0.375056
 -0.190834    0.604356    -0.16225     0.163079    -0.295318   -0.0833208   -0.0711198   -0.0190804    0.348542   -0.468316   -0.0974549   -0.0581926    0.190941    -0.7764       0.127101   -0.0173017  -0.299883    -0.348109   -0.228054    -0.100355     -0.351219   -0.590785    -0.0867799   -0.311297     0.441947     0.0100039
 -0.436861    0.160407    -0.350656   -0.0200094   -0.0285794   0.185941    -0.186985     0.233663     0.580601    0.148366   -0.397822    -0.227726     0.4328      -0.208845     0.345113   -0.436174   -0.574744    -0.211544   -1.33526     -0.395882     -0.492573    0.0556743    0.0389      -0.432359     0.0234283    0.177888
  0.277607   -0.253643     0.148233    0.0813279   -0.356462    0.117605     0.415881    -0.340216     0.370032    0.122377    0.611129     0.0188026    0.437464    -0.00483351  -0.0293211   0.109497   -0.0183228   -0.905767   -0.224758    -1.09407       0.673092   -0.167067    -0.445842    -0.319345    -0.225431    -0.538828
 -0.405427   -0.491701    -0.505872    0.258395    -0.603562    0.00182978   0.0984031   -0.222359    -0.0505443  -0.10264     0.441467    -0.219911     0.473989     0.228403     0.34495     0.0708922  -0.185127    -0.623184   -0.281465    -0.0389336     0.0699056   0.0630372   -0.401195    -0.00880606   0.11247      0.261407
 -0.01497    -0.080143     0.162713   -0.121004     0.0309747  -0.208398    -0.342326     0.104052    -0.25987     0.0634423  -0.00950939   0.165278    -0.216735    -0.00362815  -0.0430466   0.0578065  -0.0452558   -0.128434   -0.00548476   0.0556143     0.0977906  -0.208994     0.0415543   -0.0679271   -0.229596    -0.0458189
  0.0348533  -0.0278584   -0.0803358   0.0790636   -0.0209474   0.0870923    0.211419     0.0319643    0.225945   -0.0334136   0.00779401  -0.135836     0.125926     0.0149938   -0.138772   -0.0328108  -0.00830072   0.0289959  -0.0339066    0.000295766  -0.037136    0.118739    -0.00520634  -0.0326076   -0.025627     0.0589175
  0.0335102   0.160846     0.143776   -0.355038    -0.40785    -0.22033     -0.0738072    0.0331841   -0.211803    0.217268   -0.171245     0.366553     0.13981     -0.11366      0.0637414   0.296924    0.793609    -0.0773283   0.101375    -0.083013     -0.475485    0.0449973   -0.207273    -0.287179    -0.140622    -0.62853
  0.299332    0.153656    -0.407114   -0.316507     0.112933   -0.360096     0.116126     0.0493354    0.153954    0.0385837  -0.602375    -0.109444     0.188904     0.159257    -0.266921   -0.136936    0.597301    -0.516393   -0.102121    -0.315923     -0.161061   -0.306693    -0.15323     -0.351182     0.134745     0.682935[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403178
[ Info: iteration 2, average log likelihood -1.403169
[ Info: iteration 3, average log likelihood -1.403160
[ Info: iteration 4, average log likelihood -1.403151
[ Info: iteration 5, average log likelihood -1.403143
[ Info: iteration 6, average log likelihood -1.403135
[ Info: iteration 7, average log likelihood -1.403127
[ Info: iteration 8, average log likelihood -1.403119
[ Info: iteration 9, average log likelihood -1.403112
[ Info: iteration 10, average log likelihood -1.403105
┌ Info: EM with 100000 data points 10 iterations avll -1.403105
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.896981e+05
      1       6.920152e+05      -2.976829e+05 |       32
      2       6.819856e+05      -1.002953e+04 |       32
      3       6.779760e+05      -4.009671e+03 |       32
      4       6.756123e+05      -2.363611e+03 |       32
      5       6.740329e+05      -1.579412e+03 |       32
      6       6.727734e+05      -1.259532e+03 |       32
      7       6.717393e+05      -1.034108e+03 |       32
      8       6.708283e+05      -9.110291e+02 |       32
      9       6.700453e+05      -7.830064e+02 |       32
     10       6.693958e+05      -6.494414e+02 |       32
     11       6.688895e+05      -5.062840e+02 |       32
     12       6.684648e+05      -4.247386e+02 |       32
     13       6.680871e+05      -3.777032e+02 |       32
     14       6.677584e+05      -3.287086e+02 |       32
     15       6.674625e+05      -2.959085e+02 |       32
     16       6.671814e+05      -2.810263e+02 |       32
     17       6.669308e+05      -2.506007e+02 |       32
     18       6.667175e+05      -2.133385e+02 |       32
     19       6.665350e+05      -1.825418e+02 |       32
     20       6.663677e+05      -1.672971e+02 |       32
     21       6.662195e+05      -1.481440e+02 |       32
     22       6.660843e+05      -1.352745e+02 |       32
     23       6.659597e+05      -1.245308e+02 |       32
     24       6.658333e+05      -1.263912e+02 |       32
     25       6.657123e+05      -1.209937e+02 |       32
     26       6.655944e+05      -1.179607e+02 |       32
     27       6.654939e+05      -1.004550e+02 |       32
     28       6.654014e+05      -9.254715e+01 |       32
     29       6.653225e+05      -7.889402e+01 |       32
     30       6.652480e+05      -7.444638e+01 |       32
     31       6.651850e+05      -6.304541e+01 |       32
     32       6.651206e+05      -6.436384e+01 |       32
     33       6.650598e+05      -6.077378e+01 |       32
     34       6.650092e+05      -5.064235e+01 |       32
     35       6.649584e+05      -5.082051e+01 |       32
     36       6.649155e+05      -4.285375e+01 |       32
     37       6.648765e+05      -3.907827e+01 |       32
     38       6.648450e+05      -3.147009e+01 |       32
     39       6.648118e+05      -3.319762e+01 |       32
     40       6.647838e+05      -2.800140e+01 |       32
     41       6.647580e+05      -2.582490e+01 |       32
     42       6.647325e+05      -2.548060e+01 |       32
     43       6.647058e+05      -2.664705e+01 |       32
     44       6.646825e+05      -2.332212e+01 |       32
     45       6.646585e+05      -2.404964e+01 |       32
     46       6.646333e+05      -2.514246e+01 |       32
     47       6.646108e+05      -2.255497e+01 |       32
     48       6.645928e+05      -1.795983e+01 |       32
     49       6.645746e+05      -1.822170e+01 |       32
     50       6.645573e+05      -1.730053e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 664557.2816750936)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415161
[ Info: iteration 2, average log likelihood -1.410251
[ Info: iteration 3, average log likelihood -1.408991
[ Info: iteration 4, average log likelihood -1.408077
[ Info: iteration 5, average log likelihood -1.407056
[ Info: iteration 6, average log likelihood -1.406001
[ Info: iteration 7, average log likelihood -1.405187
[ Info: iteration 8, average log likelihood -1.404709
[ Info: iteration 9, average log likelihood -1.404453
[ Info: iteration 10, average log likelihood -1.404302
[ Info: iteration 11, average log likelihood -1.404199
[ Info: iteration 12, average log likelihood -1.404119
[ Info: iteration 13, average log likelihood -1.404053
[ Info: iteration 14, average log likelihood -1.403996
[ Info: iteration 15, average log likelihood -1.403945
[ Info: iteration 16, average log likelihood -1.403899
[ Info: iteration 17, average log likelihood -1.403856
[ Info: iteration 18, average log likelihood -1.403816
[ Info: iteration 19, average log likelihood -1.403778
[ Info: iteration 20, average log likelihood -1.403742
[ Info: iteration 21, average log likelihood -1.403707
[ Info: iteration 22, average log likelihood -1.403674
[ Info: iteration 23, average log likelihood -1.403641
[ Info: iteration 24, average log likelihood -1.403609
[ Info: iteration 25, average log likelihood -1.403578
[ Info: iteration 26, average log likelihood -1.403547
[ Info: iteration 27, average log likelihood -1.403517
[ Info: iteration 28, average log likelihood -1.403487
[ Info: iteration 29, average log likelihood -1.403459
[ Info: iteration 30, average log likelihood -1.403430
[ Info: iteration 31, average log likelihood -1.403403
[ Info: iteration 32, average log likelihood -1.403377
[ Info: iteration 33, average log likelihood -1.403351
[ Info: iteration 34, average log likelihood -1.403326
[ Info: iteration 35, average log likelihood -1.403303
[ Info: iteration 36, average log likelihood -1.403280
[ Info: iteration 37, average log likelihood -1.403259
[ Info: iteration 38, average log likelihood -1.403238
[ Info: iteration 39, average log likelihood -1.403219
[ Info: iteration 40, average log likelihood -1.403201
[ Info: iteration 41, average log likelihood -1.403183
[ Info: iteration 42, average log likelihood -1.403167
[ Info: iteration 43, average log likelihood -1.403151
[ Info: iteration 44, average log likelihood -1.403136
[ Info: iteration 45, average log likelihood -1.403122
[ Info: iteration 46, average log likelihood -1.403108
[ Info: iteration 47, average log likelihood -1.403095
[ Info: iteration 48, average log likelihood -1.403082
[ Info: iteration 49, average log likelihood -1.403070
[ Info: iteration 50, average log likelihood -1.403058
┌ Info: EM with 100000 data points 50 iterations avll -1.403058
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.10005      0.0926727  -0.405365    -0.0749023  -0.0970566    0.00744542   0.653041     -0.279598    0.010512    -0.451185     0.275518    0.302572     0.301106    0.180923    0.251811   -0.188237    0.00862168   0.307535    0.0814575   0.144543   -0.316007    0.200404      0.0453475    0.11408     0.454923   -0.115212
  0.121333    -0.243235    0.274797     0.116835    0.0610018   -0.313925     0.466758      0.352635    0.738928    -0.0745029    0.126016    0.0923675   -0.595393    0.332818    0.374861   -0.481751   -0.207017    -0.133376   -0.075819    0.293781   -0.0807915   0.766409     -0.799669    -0.303827    0.899337    0.0543332
 -0.00854805   0.272256    1.138       -0.492495    0.00519047   0.369146     0.156217     -0.729234    0.0819166    0.175398    -0.227397    0.0372776    0.535809   -0.263321    0.285591    0.150035    0.340553     0.372299    0.0978594   0.254748    0.302798   -0.265982     -0.549803    -0.6973      0.368866   -0.22528
  0.0693538    0.0820204  -0.0531545   -0.0381148   0.889615     0.465892    -0.482228     -0.539608   -0.624391     0.00995294   0.254231    0.627584    -0.722055   -0.381293   -0.247461   -0.0692041  -0.462962     0.475026   -0.058116    0.182861   -0.138384   -0.386282     -0.00339797   0.0817345   0.254831   -0.192998
  0.140938     0.311632   -0.396543    -0.0595357   0.0409519   -0.272522     0.0372184    -0.34939     0.135903    -0.244602    -0.457888    0.214133     0.634755    0.130453    0.218821    0.0719338  -0.0411337   -0.428992   -0.206723   -0.48627     0.0578966  -0.740926      0.254602    -0.458885    0.011958    0.673823
 -0.187474     0.0589939   0.12572      0.33229     0.0928541    0.307866    -0.0841816     0.295272   -0.0730827    0.266609     0.860638   -0.134783    -0.014011   -0.115196    0.0437658   0.568854    0.0854792    0.393688    0.255872    0.727563    0.156832    0.70381      -0.20199      0.380704    0.179341   -0.334777
 -0.0654833   -0.0739698   0.223232    -0.0305347   0.179659    -0.0126374    0.0872954     0.0871527  -0.00459153   0.0979811    0.0408877   0.00358197  -0.173065   -0.0343515  -0.117905   -0.0482714   0.0550486    0.227743    0.0329891   0.0909896   0.0319865   0.231988      0.0117501    0.106284   -0.0559889  -0.0715753
  0.294544    -0.173419    0.24075      0.281369   -0.249693     0.597373     0.0132413     0.435133   -0.0700783   -0.635553     0.166745    0.410145    -0.744776   -0.032872   -0.301136   -0.0557106  -0.498469     0.392294    0.122787    0.291747    0.280454   -0.121834      0.137951     0.29881    -0.894537   -0.458791
 -0.207117    -0.0669907   0.200246    -0.244293    0.115867    -0.0993234    0.0370442     0.0707528   0.0353463    0.0702702   -0.0879282   0.0201014   -0.297651   -0.186419   -0.282845   -0.0674267   0.121348     0.135474   -0.0102141   0.193917    0.0334468   0.0996463    -0.148568     0.146673    0.0258388  -0.112044
 -0.347773     0.0266693   0.0379815    0.535846    0.0150777    0.939631    -0.0342307    -0.519714   -0.302076     0.122162    -0.125236   -0.401737     0.729003   -0.301207    0.317456    0.0908182  -0.027297     0.168045    0.459351   -0.531003   -0.0141334  -0.000904833   0.321352     0.482547   -0.479134   -0.267804
 -0.0364785   -0.163905    0.222833     0.272071    0.0352717    0.224976    -0.068894      0.054087    0.0775844    0.101254     0.386251   -0.211767     0.0862363   0.181861    0.175419   -0.0797124  -0.296398     0.21595     0.0423774   0.135441    0.108396    0.256659     -0.0151484    0.0110878  -0.0727336  -0.0864984
  0.181114     0.229412    0.255932     0.0245006  -0.569361    -1.08536      0.000943822  -0.380684    0.746362     0.478701     0.470103   -0.248792    -0.0608485   0.255885   -0.174605    0.197716   -0.720216    -0.529021   -0.0480285  -0.480247    0.360827   -0.482365      0.281956    -0.357143   -0.0537152  -0.595809
 -0.616839     0.0797286   0.324489     0.134273    0.0709972    0.400126    -0.255462     -0.0176535   0.0194267    0.00683985  -0.768878   -0.0498669   -0.352368   -0.801059   -0.234588   -0.463519   -0.354913    -0.33443    -0.762623    0.136649    0.688673   -0.60436       0.0911126    0.213857   -0.259102    0.41959
 -0.303545     0.0658141  -0.0996575   -0.509323    0.333852     0.0726704   -0.446549      0.79984    -0.607782    -0.206467    -0.0115554  -0.152169    -0.0680916   0.36716     0.0960325  -0.699571    0.486539     0.624442    0.106767    0.532426   -0.233855    0.308749     -0.03884      0.265729   -0.0354944   0.144441
  0.519313     0.114029    0.00177444   0.166574    0.426636    -0.112659    -0.0370281     0.0126344  -0.0568019   -0.444378     0.47492     0.0633833    0.206759    0.957044    0.537324    0.130291   -0.596025     0.367376    0.640605    0.0525149   0.045854    0.156071      0.402647    -0.207169    0.119153    0.194484
  0.363663     0.560077   -0.157964    -0.112777    0.232213     0.14387      0.388882      0.342055    0.53049     -0.157836    -0.2423     -0.297408     0.109993   -0.496261   -0.924483   -0.20679     0.0212961    0.0318931  -0.389726    0.179937   -0.0398291  -0.17236      -0.113361    -0.702657    0.461079    0.245202
  0.0809389    0.443458    0.237131     0.0769769   0.528174    -0.372257     0.135777      0.038648    0.0829229    0.577287    -0.264511    0.215457     0.04157    -0.0259843   0.0788502   0.338176    0.618615     0.452619    0.258796   -0.566819   -0.542768    0.453918     -0.302004    -0.203528   -0.107307   -0.393198
 -0.543328    -0.807998   -0.131419    -0.230391   -0.161969     0.136986     0.0415459    -0.701411   -0.416799    -0.512568    -0.0616497  -0.299717    -0.173864    0.366179    0.654777    0.0375446  -0.183916    -0.387557    0.0986316  -0.049003    0.0876887  -0.0688931    -0.174749     0.801672    0.428698    0.666036
 -0.0441241   -0.441676   -0.272331     0.0803957  -1.17135     -0.366768     0.469087      0.507985    0.105065     0.194316     0.235487   -0.174968     0.527898    0.597344   -0.0441836   0.269325    0.340167    -0.561509    0.031748    0.0985745   0.109776    0.245437      0.226232    -0.0814362  -0.478177   -0.0439993
 -0.036559     0.697464    0.41288      0.278277    0.347637    -0.0723781   -0.300875     -0.211774    0.188924    -0.528155    -0.397242    0.0432259   -0.406994   -0.537387    0.369256   -0.185829   -0.232984     0.271695    0.457481   -0.0445482  -0.172638   -0.308907      0.19218      0.122231    0.0237489   0.427752
 -0.308287     0.0327902  -0.335677     0.0648307  -0.220003     0.14021     -0.10142       0.038697    0.400716     0.12161     -0.110337   -0.373242     0.465479    0.0119835   0.299104   -0.358581   -0.466754    -0.408032   -0.893137   -0.314589   -0.311321   -0.0849755    -0.117082    -0.38475     0.245814    0.240153
  0.110772     0.0612782  -0.175642    -0.0079436  -0.162519    -0.118656    -0.073652      0.0560728  -0.0659307   -0.0591      -0.051505    0.0640364    0.182658   -0.022955   -0.0227611   0.100094    0.0928156   -0.257253   -0.0138985  -0.110324   -0.079541   -0.269053      0.0397774   -0.218617   -0.0874032   0.0504107
  0.190507    -0.0334757   0.646602     0.0157905   0.248094    -0.187799    -0.85628      -0.0321399  -0.299222     0.461376    -0.388837   -0.0239652   -0.325024    0.234463    0.0585745   0.516245   -0.173076    -0.263679    0.0401721   0.0519986   0.325125   -0.0730432     0.485939    -0.0573698  -0.590462    0.0855171
 -0.240371    -0.0588653   0.103674     0.0144356  -0.0493591    0.087815     0.228527     -0.727866    0.295623    -0.0815037    0.160343    0.358157     0.17578    -0.424403    0.206937    0.28397    -0.0323412   -0.395744   -0.382813   -0.898597    0.659546   -0.180812     -0.383767     0.0884069  -0.313375   -0.0741876
 -0.183877    -0.197703   -0.829243     0.732956    0.233308    -0.0819643    0.166534      0.467093    0.48161     -0.360381    -0.0567178  -0.165807    -0.236911   -0.193369   -0.348336   -0.0176776  -0.176052     0.384447   -0.0961665   0.0949893  -0.175208    0.176291      0.677329     0.576635   -0.351229    0.126343
  0.0958635   -0.180681   -0.197714     0.139061   -0.397396     0.156519    -0.134742      0.202099   -0.204692    -0.14424      0.91154    -0.19159      0.449515   -0.181117    0.319846   -0.147485    0.0358035   -0.93519     0.260522   -0.166471    0.408584   -0.130688     -0.728076    -0.294682   -0.140333   -0.424027
  0.156221     0.139866    0.170774    -0.810866   -0.0586195   -1.01426     -0.356785      0.32295     0.0624935    0.0213239   -0.293792    0.293583    -0.453559   -0.0365038  -0.132456   -0.375775    0.227018    -0.40825    -0.488777   -0.169995   -0.171198   -0.55648      -0.498571    -0.490954    0.0569257  -0.0418853
  0.0724966   -0.377865    0.124649     0.101855    0.681144    -0.039025     0.610543     -0.15267    -0.142364     0.169288    -0.182987   -0.176547     0.0109058   0.460213   -0.617437   -0.120155    0.211337     0.26371     0.113185   -0.260902    0.693217   -0.0442641     0.266136     0.0596407  -0.265915    0.55572
  0.462974    -0.426905   -0.0250979   -0.31287    -0.286867     0.135558     0.428603      0.0559105  -0.085106     0.0057285   -0.31516    -0.317264    -0.344274    0.158132   -0.199939   -0.0352605   0.467301    -0.740409    0.257871    0.349694   -1.07305    -0.0494774     0.145134    -0.186887    0.0832416  -0.393518
 -0.410012     0.0395799  -0.0810168   -0.185917   -0.2765      -0.125555    -0.0980984     0.177007   -0.338866     0.305441    -0.246434   -0.134581    -0.0816265  -0.990789   -0.86453     0.371035    0.804649    -0.0179281   0.0697269   0.160796    0.226345   -0.33183      -0.418576     0.354262   -0.18786    -0.22192
  0.0865077   -0.857383   -0.385092    -0.223732   -0.244093    -0.102157    -0.0478496     0.427384    0.0723665    0.570755    -0.0846714  -0.18288     -0.624374    0.0976486  -0.728397   -0.0799401  -0.286437    -0.485585   -0.424635    0.204237   -0.22141     0.570125      0.22565      0.258117   -0.564969    0.27609
 -0.33235      0.534211   -0.211915    -0.0144119  -0.805222     0.108318    -0.226861     -0.0106086   0.261021    -0.129696     0.0705882   0.193894     0.171003   -0.85717     0.331695    0.14101     0.0828225   -0.140331   -0.261717    0.125229   -0.755669   -0.184312     -0.377852    -0.151833    0.283479   -0.723687[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403047
[ Info: iteration 2, average log likelihood -1.403036
[ Info: iteration 3, average log likelihood -1.403025
[ Info: iteration 4, average log likelihood -1.403014
[ Info: iteration 5, average log likelihood -1.403004
[ Info: iteration 6, average log likelihood -1.402993
[ Info: iteration 7, average log likelihood -1.402983
[ Info: iteration 8, average log likelihood -1.402973
[ Info: iteration 9, average log likelihood -1.402964
[ Info: iteration 10, average log likelihood -1.402955
┌ Info: EM with 100000 data points 10 iterations avll -1.402955
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
