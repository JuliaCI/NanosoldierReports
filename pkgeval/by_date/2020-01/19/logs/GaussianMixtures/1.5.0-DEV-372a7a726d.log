Julia Version 1.5.0-DEV.104
Commit 372a7a726d (2020-01-18 18:35 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed PDMats ───────────── v0.9.10
 Installed CMakeWrapper ─────── v0.2.3
 Installed Rmath ────────────── v0.6.0
 Installed NearestNeighbors ─── v0.4.4
 Installed StatsFuns ────────── v0.9.3
 Installed DataStructures ───── v0.17.9
 Installed StatsBase ────────── v0.32.0
 Installed Distances ────────── v0.8.2
 Installed DataAPI ──────────── v1.1.0
 Installed CMake ────────────── v1.1.2
 Installed Parameters ───────── v0.12.0
 Installed LegacyStrings ────── v0.4.1
 Installed JLD ──────────────── v0.9.1
 Installed FillArrays ───────── v0.8.4
 Installed FileIO ───────────── v1.2.1
 Installed Clustering ───────── v0.13.3
 Installed Compat ───────────── v2.2.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Arpack ───────────── v0.4.0
 Installed BinDeps ──────────── v1.0.0
 Installed Blosc ────────────── v0.5.1
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed SortingAlgorithms ── v0.3.1
 Installed Missings ─────────── v0.4.3
 Installed ScikitLearnBase ──── v0.5.0
 Installed QuadGK ───────────── v2.3.1
 Installed Distributions ────── v0.22.3
 Installed BinaryProvider ───── v0.5.8
 Installed SpecialFunctions ─── v0.9.0
 Installed HDF5 ─────────────── v0.12.5
 Installed URIParser ────────── v0.4.0
 Installed StaticArrays ─────── v0.12.1
 Installed OrderedCollections ─ v1.1.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_eSYVOo/Project.toml`
 [no changes]
  Updating `/tmp/jl_eSYVOo/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_7g0x0H/Project.toml`
 [no changes]
  Updating `/tmp/jl_7g0x0H/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_m4VuMu/Project.toml`
 [no changes]
  Updating `/tmp/jl_m4VuMu/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_D6OfZY/Project.toml`
 [no changes]
  Updating `/tmp/jl_D6OfZY/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_svkSiU/Project.toml`
 [no changes]
  Updating `/tmp/jl_svkSiU/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_svkSiU/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.0855277020121445e6, [1709.7712417478588, 98290.22875825215], [1247.460977999518 2265.363047251391 -3316.149016805401; -532.8912028265321 -2669.4155684787006 3433.6268360630224], [[2624.797926981932 1373.319014407942 -2026.3601478749733; 1373.319014407942 4283.707513367442 -3737.051445379874; -2026.3601478749733 -3737.051445379874 7196.991110089521], [97663.89905146955 -1552.3344431654668 2409.3258552850357; -1552.3344431654668 95294.08958470124 3673.2545609892713; 2409.3258552850357 3673.2545609892713 92914.0227264316]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.779132e+03
      1       9.115834e+02      -8.675488e+02 |        8
      2       8.696142e+02      -4.196923e+01 |        0
      3       8.696142e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 869.6141836443662)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.082014
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.813522
[ Info: iteration 2, lowerbound -3.668619
[ Info: iteration 3, lowerbound -3.502677
[ Info: iteration 4, lowerbound -3.307059
[ Info: iteration 5, lowerbound -3.108346
[ Info: iteration 6, lowerbound -2.933371
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.786472
[ Info: iteration 8, lowerbound -2.671516
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.590404
[ Info: iteration 10, lowerbound -2.526564
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.474599
[ Info: iteration 12, lowerbound -2.428517
[ Info: iteration 13, lowerbound -2.391597
[ Info: iteration 14, lowerbound -2.359219
[ Info: iteration 15, lowerbound -2.331776
[ Info: iteration 16, lowerbound -2.313030
[ Info: iteration 17, lowerbound -2.307489
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302925
[ Info: iteration 19, lowerbound -2.299260
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Jan 19 21:58:15 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Jan 19 21:58:23 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Sun Jan 19 21:58:26 2020: EM with 272 data points 0 iterations avll -2.082014
5.8 data points per parameter
, Sun Jan 19 21:58:27 2020: GMM converted to Variational GMM
, Sun Jan 19 21:58:35 2020: iteration 1, lowerbound -3.813522
, Sun Jan 19 21:58:35 2020: iteration 2, lowerbound -3.668619
, Sun Jan 19 21:58:35 2020: iteration 3, lowerbound -3.502677
, Sun Jan 19 21:58:35 2020: iteration 4, lowerbound -3.307059
, Sun Jan 19 21:58:35 2020: iteration 5, lowerbound -3.108346
, Sun Jan 19 21:58:35 2020: iteration 6, lowerbound -2.933371
, Sun Jan 19 21:58:36 2020: dropping number of Gaussions to 6
, Sun Jan 19 21:58:36 2020: iteration 7, lowerbound -2.786472
, Sun Jan 19 21:58:36 2020: iteration 8, lowerbound -2.671516
, Sun Jan 19 21:58:36 2020: dropping number of Gaussions to 4
, Sun Jan 19 21:58:36 2020: iteration 9, lowerbound -2.590404
, Sun Jan 19 21:58:36 2020: iteration 10, lowerbound -2.526564
, Sun Jan 19 21:58:36 2020: dropping number of Gaussions to 3
, Sun Jan 19 21:58:36 2020: iteration 11, lowerbound -2.474599
, Sun Jan 19 21:58:36 2020: iteration 12, lowerbound -2.428517
, Sun Jan 19 21:58:36 2020: iteration 13, lowerbound -2.391597
, Sun Jan 19 21:58:36 2020: iteration 14, lowerbound -2.359219
, Sun Jan 19 21:58:36 2020: iteration 15, lowerbound -2.331776
, Sun Jan 19 21:58:36 2020: iteration 16, lowerbound -2.313030
, Sun Jan 19 21:58:36 2020: iteration 17, lowerbound -2.307489
, Sun Jan 19 21:58:36 2020: dropping number of Gaussions to 2
, Sun Jan 19 21:58:36 2020: iteration 18, lowerbound -2.302925
, Sun Jan 19 21:58:36 2020: iteration 19, lowerbound -2.299260
, Sun Jan 19 21:58:36 2020: iteration 20, lowerbound -2.299256
, Sun Jan 19 21:58:36 2020: iteration 21, lowerbound -2.299254
, Sun Jan 19 21:58:36 2020: iteration 22, lowerbound -2.299254
, Sun Jan 19 21:58:36 2020: iteration 23, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 24, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 25, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 26, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 27, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 28, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 29, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 30, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 31, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 32, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 33, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 34, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 35, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 36, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 37, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 38, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 39, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 40, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 41, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 42, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 43, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 44, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 45, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 46, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 47, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 48, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 49, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: iteration 50, lowerbound -2.299253
, Sun Jan 19 21:58:36 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601382, 95.95490777398618]
β = [178.04509222601382, 95.95490777398618]
m = [4.25030073326991 79.28686694436185; 2.000229257775371 53.8519871724613]
ν = [180.04509222601382, 97.95490777398618]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554748454 -0.007644049042327357; 0.0 0.00858170516633346], [0.37587636119484036 -0.008953123827345958; 0.0 0.01274866477740938]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000013
avll from stats: -1.010890549635354
avll from llpg:  -1.0108905496353544
avll direct:     -1.0108905496353544
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9915142303131662
avll from llpg:  -0.9915142303131664
avll direct:     -0.9915142303131664
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0308464   -0.0945011    0.0345763  -0.149702     0.119871    -0.175093    -0.115858     0.0204339     0.00657077  -0.137584    0.0813237   -0.0520337    0.0527617   0.0866465    -0.0721447   -0.0476583   -0.156938     0.0317768   -0.0490501   -0.122241     -0.0779177   -0.138149    0.0683889   -0.047747    -0.118637     0.0867004
 -0.0634201   -0.164864    -0.0282992   0.089575     0.15883      0.26487      0.0773916   -0.046428      0.00588059  -0.0189426  -0.0452818    0.0250099    0.0105875   0.0148277     0.00247527   0.129649    -0.0355953   -0.104176     0.0593122    0.0620939     0.218455    -0.0906303   0.00221747   0.0839305   -0.0964316    4.02937e-5
  0.0907047   -0.129405    -0.188965   -0.0177385   -0.0732598    0.0328867   -0.106966    -0.105064      0.119803     0.0750257   0.0452891   -0.164228     0.147028    0.0704746    -0.0626365    0.161697     0.0334548   -0.0736757    0.0293712   -0.217263      0.0623784    0.0845528  -0.0452022   -0.0522808   -0.0855228    0.0418503
  0.0792459   -0.0954647   -0.0954653  -0.117215    -0.0893819    0.0400091    0.0521615    0.0758132     0.0903544   -0.0882195   0.0588813   -0.100434    -0.11187     0.106236      0.155897     0.0602806   -0.187164    -0.0619869    0.00263729   0.309068     -0.00789514  -0.0274893   0.0183279    0.146908     0.0944394    0.0739281
  0.0459144   -0.0367292    0.0968358   0.0707277   -0.048992    -0.0879978   -0.0110716    0.0925477     0.0138549    0.0210985   0.170439    -0.139065    -0.0523651   0.0403835     0.0559238    0.0361136   -0.0260176   -0.0365804   -0.0285337   -0.0652995     0.00460188  -0.108628   -0.0466146   -0.038921     0.103827    -0.275655
  0.0817024    0.0518139   -0.0758499   0.120869     0.0410919    0.0389795    0.0228219    0.0317789    -0.0564055    0.0189276   0.0813322    0.0642472    0.0735826  -0.202766     -0.10631      0.0447069    0.121997     0.0260811   -0.0168579    0.000581742  -0.110689     0.0318852   0.0275317    0.020714     0.113175     0.0523234
 -0.104979    -0.0109655   -0.112645    0.0108374   -0.132678    -0.139419     0.195828     0.0667511     0.0966242    0.0386698   0.0651329    0.220964    -0.0989607   0.0810768     0.217542    -0.0362171    0.0276269   -0.133063     0.0944245   -0.0480083    -0.165274    -0.0850932  -0.0328665    0.17015      0.0683748   -0.0339487
  0.00327291  -0.0775639    0.172496    0.00473028  -0.00651754   0.0798868   -0.116686    -0.0139395     0.136831    -0.167537    0.0155738    0.128406    -0.117359   -0.0152372    -0.0524036    0.0120075   -0.239751    -0.16541     -0.179033    -0.106727      0.0697182   -0.0894114  -0.0426513   -0.00983252  -0.0016469   -0.0572142
  0.0886247   -0.100499     0.0885412   0.132246    -0.0123874    0.0112164   -0.0138435    0.267166      0.0284486   -0.0201606   0.171517     0.00610588  -0.0584876  -0.0967129     0.105044    -0.00678874  -0.00662478  -0.262625     0.102151    -0.0626735    -0.100726     0.0237513   0.0563573    0.0675383    0.0598535    0.0153899
  0.00517281  -0.0264004    0.0289839  -0.0522882   -0.027421     0.0602261    0.0291812   -0.0521301     0.0937912   -0.0380395   0.144031     0.0807712   -0.0392438  -0.0198667    -0.00617782   0.0827719   -0.0420611    0.0118593    0.0743326    0.0407254    -0.111437    -0.0136595   0.0395392   -0.0202757   -0.0106656    0.00343283
  0.119894     0.0136349    0.0312063  -0.124307     0.114522    -0.0892417   -0.111199     0.0200647    -0.0553361   -0.147401   -0.165507     0.00570946  -0.05373    -0.075219      0.0476807   -0.11336      0.00174209   0.00199092  -0.0482911    0.0460804    -0.0192656    0.0444021  -0.0283257    0.0872197   -0.0512827   -0.0256337
 -0.140414    -0.00718005  -0.0166886   0.00326643   0.0543549   -0.0636783   -0.00536993   0.146613     -0.111618     0.0613566  -0.0941026    0.00346344  -0.0782181  -0.0512585     0.0214578   -0.0720514    0.140143    -0.035661     0.0677442    0.0692648    -0.114841     0.111668    0.0233765   -0.00023898   0.139067    -0.088916
  0.020127    -0.20849      0.047744   -0.143925    -0.0125992   -0.0136954    0.164245     0.174158      0.126392    -0.0737645  -0.00897477   0.124019     0.0333508  -0.000438129   0.0890742   -0.0476734   -0.0471195    0.0232622   -0.110411    -0.125372     -0.0455271    0.0392467  -0.0925769    0.0188155   -0.00660313   0.0909757
  0.0118073    0.203685     0.109947   -0.0440671    0.0400194   -0.145394    -0.0495214    0.00387556   -0.162399     0.0462746   0.0794892   -0.0383739    0.343167   -0.0834463    -0.0795459    0.107729    -0.0624634    0.0898825   -0.188057    -0.0899556     0.180454     0.0553349   0.0563024    0.0273166    0.110542     0.250226
  0.00447074  -0.108845     0.0186532  -0.0851947   -0.0259448   -0.0392996   -0.120173     0.107448     -0.00213598  -0.0444463  -0.0161189   -0.043533     0.107314   -0.134877     -0.0836158   -0.120891     0.0438866   -0.212545    -0.0350669    0.128502     -0.0689452    0.0502807   0.0710429    0.100896    -0.0538156   -0.0812379
 -0.0489723   -0.0117905   -0.0419076   0.00325613   0.132475     0.111124    -0.198684    -0.112762     -0.0414756   -0.130604    0.100487     0.0692677   -0.0371092  -0.0039853    -0.0527376   -0.15414     -0.0528557    0.139359     0.0659577   -0.142577     -0.0681611    0.0214039  -0.0561113   -0.043324     0.146817     0.0644799
 -0.0476875   -0.0542006    0.185724   -0.0668971    0.0182663   -0.00732509   0.118719     0.0238373     0.0313407   -0.141017    0.184978     0.0349816    0.0877609   0.0675511    -0.0184364   -0.0862286   -0.132444    -0.0273827   -0.188535    -0.12247       0.226608     0.0827415  -0.0593516    0.0429702    0.102608    -0.0583233
  0.20239     -0.197806    -0.0486986  -0.0667397   -0.297067    -0.173085    -0.0934717   -0.0842407    -0.0967758   -0.17114    -0.0204459    0.117805    -0.0382463   0.0178261     0.101321    -0.00903767   0.147204    -0.163041    -0.00802792   0.143563      0.101812    -0.0423798   0.204501     0.0303401   -0.0127623    0.145194
 -0.012563    -0.0495344    0.0173627  -0.0855555   -0.101002    -0.0333915    0.00595748   0.000120511   0.0940335   -0.0675932  -0.0265611    0.0169489   -0.0339236   0.0435802     0.0317759    0.0172039   -0.0166205    0.018561     0.134019    -0.00202713    0.136471    -0.07405     0.00491491  -0.160819    -0.0484354    0.120644
  0.0188551    0.0571705   -0.102779    0.0402248    0.0227303    0.0328535   -0.15988     -0.0780716     0.153128    -0.0888559   0.0488102   -0.0543305    0.0258595   0.0625377    -0.00130447  -0.106339     0.150193    -0.0811283   -0.0418665    0.103847     -0.0424399   -0.27446     0.0150417   -0.0631      -0.08376     -0.0807528
 -0.14406     -0.062973    -0.0518301   0.191142    -0.0388048    0.231272     0.0704528   -0.138102     -0.00177745  -0.0626035   0.0346806   -0.15878      0.0318877   0.20006       0.0748635   -0.0431183   -0.0131412    0.0471213   -0.103536    -0.095902      0.0159866    0.0596947   0.057115     0.0145823    0.0141802   -0.151568
  0.0775923    0.155784    -0.0949347  -0.0616962    0.0282669   -0.0786288    0.0917475   -0.0107323     0.0285261    0.0406744  -0.161121    -0.0316657    0.0735602   0.137286      0.0733888    0.021527    -0.0133106    0.214748     0.179575    -0.0506915    -0.13335      0.0876572  -0.0706153   -0.0485503   -0.0116805    0.0163298
 -0.0287103    0.0911906   -0.016376   -0.0965701    0.0736885   -0.00227951  -0.0711299   -0.176393     -0.176896     0.0631446  -0.251901     0.00652156   0.0908264   0.0282444    -0.0317622   -0.0785125   -0.0527377   -0.0805139   -0.0131558   -0.175929      0.0293554    0.0409392   0.0241989    0.115633     0.0965325   -0.131168
  0.281273     0.119483     0.017904    0.117323     0.012832     0.00433179   0.142964     0.0594526    -0.118379     0.012762    0.0303322   -0.0079444    0.341998   -0.00211091    0.0566541   -0.0111261   -0.214546    -0.166634    -0.158584    -0.132093      0.118777    -0.0389731  -0.122634     0.0115124    0.101506    -0.00661944
 -0.0384883   -0.0676593   -0.0210814   0.0133253    0.196884     0.0899836    0.0164008   -0.0699605     0.00943784   0.177746    0.0976047    0.0607656    0.0257774   0.0522093     0.0315438   -0.172189    -0.0135122    0.0909842   -0.100133    -0.0179836    -0.0708504    0.11847     0.0341119    0.0437618   -0.0550752   -0.00242306
  0.0690093    0.0508005   -0.0018986  -0.0603131    0.138082     0.0419836   -0.046037    -0.0168234     0.122028     0.0643561   0.0521826    0.0565784   -0.0772095   0.0552342    -0.102519    -0.0495912   -6.93543e-5   0.111489    -0.139878     0.0621614    -0.0677736    0.144814    0.0991068    0.0967221   -0.105491     0.0152958
  0.0766238    0.0212439   -0.0552968  -0.0470896   -0.165984     0.0817842    0.109155    -0.0752939     0.123827    -0.166482    0.183841    -0.0296081    0.0531521  -0.124236      0.12579      0.0490827    0.207749     0.00850669   0.00166464  -0.148149      0.132664     0.0135138  -0.0659331    0.0040259   -0.0660531    0.0853773
 -0.145185    -0.0452138    0.176252    0.182437     0.0318821   -0.0965292    0.00268103  -0.104896     -0.060288    -0.0659181   0.0843924   -0.0474351   -0.0165048  -0.0349049     0.0601915    0.0574718    0.103939    -0.0353545   -0.0161953    0.081488     -0.0703964    0.0866152   0.00189112   0.134099    -0.0638598    0.0326381
  0.0774701    0.190544     0.0951104   0.0138526   -0.00568587  -0.0696436   -0.00256198   0.241921      0.175925    -0.0191434   0.166218    -0.177305     0.067927   -0.0518215     0.0827081   -0.0450907    0.0670428   -0.0105511   -0.0720091    0.0204517    -0.051472    -0.108975   -0.114675     0.00218961   0.0996348    0.0397001
  0.162618     0.0268738    0.274392   -0.0893607    0.134504     0.0127877   -0.12614     -0.215896      0.131936     0.0873082  -0.205657    -0.0309126   -0.286521   -0.0489325     0.0249878   -0.216152    -0.129422    -0.0363012   -0.0884258    0.173076      0.150131     0.113217   -0.265558    -0.0368615   -0.146676    -0.0886269
  0.0228462    0.0484452   -0.162031    0.0467244   -0.010469     0.123482     0.193164    -0.0511711     0.0591921   -0.106904   -0.0267148    0.0599258   -0.0935723  -0.123801     -0.195102     0.0197421   -0.0349342    0.0964793   -0.0504198   -0.157682      0.0471701   -0.121007   -0.153457     0.00204979   0.279821     0.0428619
  0.116928    -0.0704468   -0.0156956   0.154833     0.134642    -0.18843     -0.0628384    0.0679138     0.130436    -0.0708178   0.0753636    0.111229    -0.0304883   0.0352808    -0.12556      0.0037567    0.0714748    0.0722361    0.106975    -0.0556201    -0.172835     0.228114   -0.0342945   -0.15789      0.0100865   -0.0163534kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4221523301101848
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422216
[ Info: iteration 2, average log likelihood -1.422129
[ Info: iteration 3, average log likelihood -1.420898
[ Info: iteration 4, average log likelihood -1.408160
[ Info: iteration 5, average log likelihood -1.388570
[ Info: iteration 6, average log likelihood -1.383884
[ Info: iteration 7, average log likelihood -1.382620
[ Info: iteration 8, average log likelihood -1.381857
[ Info: iteration 9, average log likelihood -1.381309
[ Info: iteration 10, average log likelihood -1.380887
[ Info: iteration 11, average log likelihood -1.380553
[ Info: iteration 12, average log likelihood -1.380291
[ Info: iteration 13, average log likelihood -1.380089
[ Info: iteration 14, average log likelihood -1.379931
[ Info: iteration 15, average log likelihood -1.379803
[ Info: iteration 16, average log likelihood -1.379699
[ Info: iteration 17, average log likelihood -1.379614
[ Info: iteration 18, average log likelihood -1.379544
[ Info: iteration 19, average log likelihood -1.379487
[ Info: iteration 20, average log likelihood -1.379441
[ Info: iteration 21, average log likelihood -1.379404
[ Info: iteration 22, average log likelihood -1.379373
[ Info: iteration 23, average log likelihood -1.379347
[ Info: iteration 24, average log likelihood -1.379327
[ Info: iteration 25, average log likelihood -1.379311
[ Info: iteration 26, average log likelihood -1.379299
[ Info: iteration 27, average log likelihood -1.379289
[ Info: iteration 28, average log likelihood -1.379281
[ Info: iteration 29, average log likelihood -1.379275
[ Info: iteration 30, average log likelihood -1.379270
[ Info: iteration 31, average log likelihood -1.379267
[ Info: iteration 32, average log likelihood -1.379264
[ Info: iteration 33, average log likelihood -1.379262
[ Info: iteration 34, average log likelihood -1.379260
[ Info: iteration 35, average log likelihood -1.379259
[ Info: iteration 36, average log likelihood -1.379258
[ Info: iteration 37, average log likelihood -1.379257
[ Info: iteration 38, average log likelihood -1.379257
[ Info: iteration 39, average log likelihood -1.379256
[ Info: iteration 40, average log likelihood -1.379256
[ Info: iteration 41, average log likelihood -1.379256
[ Info: iteration 42, average log likelihood -1.379256
[ Info: iteration 43, average log likelihood -1.379256
[ Info: iteration 44, average log likelihood -1.379255
[ Info: iteration 45, average log likelihood -1.379255
[ Info: iteration 46, average log likelihood -1.379255
[ Info: iteration 47, average log likelihood -1.379255
[ Info: iteration 48, average log likelihood -1.379255
[ Info: iteration 49, average log likelihood -1.379255
[ Info: iteration 50, average log likelihood -1.379255
┌ Info: EM with 100000 data points 50 iterations avll -1.379255
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4222157404148759
│     -1.4221293601586096
│      ⋮
└     -1.3792552862666787
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.379410
[ Info: iteration 2, average log likelihood -1.379215
[ Info: iteration 3, average log likelihood -1.377758
[ Info: iteration 4, average log likelihood -1.365592
[ Info: iteration 5, average log likelihood -1.346204
[ Info: iteration 6, average log likelihood -1.340468
[ Info: iteration 7, average log likelihood -1.338732
[ Info: iteration 8, average log likelihood -1.337665
[ Info: iteration 9, average log likelihood -1.336904
[ Info: iteration 10, average log likelihood -1.336371
[ Info: iteration 11, average log likelihood -1.336001
[ Info: iteration 12, average log likelihood -1.335736
[ Info: iteration 13, average log likelihood -1.335544
[ Info: iteration 14, average log likelihood -1.335406
[ Info: iteration 15, average log likelihood -1.335304
[ Info: iteration 16, average log likelihood -1.335227
[ Info: iteration 17, average log likelihood -1.335165
[ Info: iteration 18, average log likelihood -1.335114
[ Info: iteration 19, average log likelihood -1.335072
[ Info: iteration 20, average log likelihood -1.335037
[ Info: iteration 21, average log likelihood -1.335007
[ Info: iteration 22, average log likelihood -1.334983
[ Info: iteration 23, average log likelihood -1.334963
[ Info: iteration 24, average log likelihood -1.334946
[ Info: iteration 25, average log likelihood -1.334932
[ Info: iteration 26, average log likelihood -1.334920
[ Info: iteration 27, average log likelihood -1.334910
[ Info: iteration 28, average log likelihood -1.334901
[ Info: iteration 29, average log likelihood -1.334893
[ Info: iteration 30, average log likelihood -1.334886
[ Info: iteration 31, average log likelihood -1.334881
[ Info: iteration 32, average log likelihood -1.334876
[ Info: iteration 33, average log likelihood -1.334871
[ Info: iteration 34, average log likelihood -1.334868
[ Info: iteration 35, average log likelihood -1.334864
[ Info: iteration 36, average log likelihood -1.334861
[ Info: iteration 37, average log likelihood -1.334859
[ Info: iteration 38, average log likelihood -1.334856
[ Info: iteration 39, average log likelihood -1.334854
[ Info: iteration 40, average log likelihood -1.334853
[ Info: iteration 41, average log likelihood -1.334851
[ Info: iteration 42, average log likelihood -1.334850
[ Info: iteration 43, average log likelihood -1.334848
[ Info: iteration 44, average log likelihood -1.334847
[ Info: iteration 45, average log likelihood -1.334846
[ Info: iteration 46, average log likelihood -1.334845
[ Info: iteration 47, average log likelihood -1.334844
[ Info: iteration 48, average log likelihood -1.334844
[ Info: iteration 49, average log likelihood -1.334843
[ Info: iteration 50, average log likelihood -1.334842
┌ Info: EM with 100000 data points 50 iterations avll -1.334842
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3794096093060837
│     -1.3792150696416585
│      ⋮
└     -1.334842294767479
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.335030
[ Info: iteration 2, average log likelihood -1.334785
[ Info: iteration 3, average log likelihood -1.333370
[ Info: iteration 4, average log likelihood -1.323747
[ Info: iteration 5, average log likelihood -1.304274
[ Info: iteration 6, average log likelihood -1.290610
[ Info: iteration 7, average log likelihood -1.285544
[ Info: iteration 8, average log likelihood -1.282813
[ Info: iteration 9, average log likelihood -1.280704
[ Info: iteration 10, average log likelihood -1.279054
[ Info: iteration 11, average log likelihood -1.277725
[ Info: iteration 12, average log likelihood -1.276544
[ Info: iteration 13, average log likelihood -1.275400
[ Info: iteration 14, average log likelihood -1.274199
[ Info: iteration 15, average log likelihood -1.272806
[ Info: iteration 16, average log likelihood -1.270998
[ Info: iteration 17, average log likelihood -1.268357
[ Info: iteration 18, average log likelihood -1.265280
[ Info: iteration 19, average log likelihood -1.264370
[ Info: iteration 20, average log likelihood -1.263973
[ Info: iteration 21, average log likelihood -1.263629
[ Info: iteration 22, average log likelihood -1.263348
[ Info: iteration 23, average log likelihood -1.263143
[ Info: iteration 24, average log likelihood -1.263004
[ Info: iteration 25, average log likelihood -1.262914
[ Info: iteration 26, average log likelihood -1.262855
[ Info: iteration 27, average log likelihood -1.262816
[ Info: iteration 28, average log likelihood -1.262789
[ Info: iteration 29, average log likelihood -1.262770
[ Info: iteration 30, average log likelihood -1.262755
[ Info: iteration 31, average log likelihood -1.262743
[ Info: iteration 32, average log likelihood -1.262732
[ Info: iteration 33, average log likelihood -1.262722
[ Info: iteration 34, average log likelihood -1.262713
[ Info: iteration 35, average log likelihood -1.262705
[ Info: iteration 36, average log likelihood -1.262697
[ Info: iteration 37, average log likelihood -1.262689
[ Info: iteration 38, average log likelihood -1.262681
[ Info: iteration 39, average log likelihood -1.262673
[ Info: iteration 40, average log likelihood -1.262666
[ Info: iteration 41, average log likelihood -1.262659
[ Info: iteration 42, average log likelihood -1.262652
[ Info: iteration 43, average log likelihood -1.262646
[ Info: iteration 44, average log likelihood -1.262640
[ Info: iteration 45, average log likelihood -1.262634
[ Info: iteration 46, average log likelihood -1.262629
[ Info: iteration 47, average log likelihood -1.262624
[ Info: iteration 48, average log likelihood -1.262620
[ Info: iteration 49, average log likelihood -1.262616
[ Info: iteration 50, average log likelihood -1.262612
┌ Info: EM with 100000 data points 50 iterations avll -1.262612
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3350295613865275
│     -1.334785381892855
│      ⋮
└     -1.2626123769345516
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.262838
[ Info: iteration 2, average log likelihood -1.262546
[ Info: iteration 3, average log likelihood -1.260832
[ Info: iteration 4, average log likelihood -1.247998
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.223315
[ Info: iteration 6, average log likelihood -1.212704
[ Info: iteration 7, average log likelihood -1.198643
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.190810
[ Info: iteration 9, average log likelihood -1.196401
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.188268
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.193943
[ Info: iteration 12, average log likelihood -1.197158
[ Info: iteration 13, average log likelihood -1.188995
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.182823
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.190076
[ Info: iteration 16, average log likelihood -1.194637
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.184184
[ Info: iteration 18, average log likelihood -1.190367
[ Info: iteration 19, average log likelihood -1.182036
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.175757
[ Info: iteration 21, average log likelihood -1.207510
[ Info: iteration 22, average log likelihood -1.189882
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.181658
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.188367
[ Info: iteration 25, average log likelihood -1.191408
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.181232
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.188197
[ Info: iteration 28, average log likelihood -1.192051
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.180730
[ Info: iteration 30, average log likelihood -1.199081
[ Info: iteration 31, average log likelihood -1.186390
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.179543
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.186899
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.190006
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.191945
[ Info: iteration 36, average log likelihood -1.193612
[ Info: iteration 37, average log likelihood -1.184085
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.177140
[ Info: iteration 39, average log likelihood -1.197048
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.185018
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.189651
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.191898
[ Info: iteration 43, average log likelihood -1.193709
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.182724
[ Info: iteration 45, average log likelihood -1.189492
[ Info: iteration 46, average log likelihood -1.181313
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.175152
[ Info: iteration 48, average log likelihood -1.207032
[ Info: iteration 49, average log likelihood -1.190162
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.182617
┌ Info: EM with 100000 data points 50 iterations avll -1.182617
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2628380352156283
│     -1.2625455360142457
│      ⋮
└     -1.1826174367620443
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.189222
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.180859
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.174591
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     19
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.164455
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.132142
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.112154
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.120431
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.084189
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.109090
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     19
│     20
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.099060
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.093116
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.080657
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.087655
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.066306
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.093055
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.072521
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.081212
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     12
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.074226
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.100135
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.061219
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.084767
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.081535
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.088931
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     12
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.064852
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.092061
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.070508
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.092758
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.072152
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.080844
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     12
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.074207
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.100098
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.061121
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.084644
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.081529
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.088917
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     12
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.064816
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.092015
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.070502
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.092750
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.072136
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.080825
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     12
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.074200
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.100091
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.061111
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.084633
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.081522
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.088910
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     12
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.064808
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.092006
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.070495
┌ Info: EM with 100000 data points 50 iterations avll -1.070495
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1892219256623744
│     -1.1808593096953932
│      ⋮
└     -1.070494532305619
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4221523301101848
│     -1.4222157404148759
│     -1.4221293601586096
│     -1.4208980580349828
│      ⋮
│     -1.0648075576038225
│     -1.0920064601055373
└     -1.070494532305619
32×26 Array{Float64,2}:
  0.0114732   -0.0669798    0.0875478   0.0696312   -0.0534841    -0.0959103   -0.024958     0.113875     0.0164503   0.0143803    0.174718   -0.169108    -0.0712276    0.0499181    0.0563204     0.0559052   -0.0242132   -0.0257743   -0.0409903   -0.107728     -0.011069    -0.109217    -0.0468691  -0.0611189    0.0992373   -0.242674
 -0.0469075   -0.0871245    0.0862168  -0.0712333    0.0643814    -0.0646441   -0.115251     0.00896062   0.0702071  -0.157838     0.0483502   0.0474764   -0.0286995    0.0409691   -0.058593     -0.0328324   -0.2059      -0.068683    -0.125124    -0.104909     -0.011314    -0.122353     0.0132409  -0.00986614  -0.0585002    0.0124755
 -0.114054     0.00861235  -0.160416    0.0558445    0.11926       0.111531    -0.136532    -0.146894     0.0109859  -0.0914989   -0.0142667   0.00453761  -0.108401    -0.244384    -0.312376      0.0387016   -0.0930378    0.10193     -0.0359896   -0.147034      0.0501988   -0.148786    -0.154175    0.065473     0.245282     0.0690192
  0.236436     0.044733    -0.174906    0.0405833   -0.0952967     0.14504      0.55412      0.00177463   0.13756    -0.143423    -0.0188882   0.130448    -0.0734102   -0.0857532   -0.0861358     0.00276648  -0.00664919   0.0925815   -0.09588     -0.221112      0.0336278   -0.0967403   -0.144446   -0.0797944    0.284979     0.0239425
 -0.116488    -0.0108828   -0.112996    0.021667    -0.104819     -0.143567     0.191978     0.0414831    0.102176    0.0345666    0.0638354   0.24071     -0.0969627    0.0668621    0.22811      -0.038604     0.0241488   -0.124723     0.0939903   -0.054145     -0.167519    -0.0785035   -0.0279532   0.151135     0.0630592   -0.0367027
 -0.141941    -0.0641145   -0.0420598   0.190997    -0.0245514     0.233577     0.114805    -0.122808     0.0263216  -0.0833776    0.034744   -0.163481     0.0611744    0.186233     0.0845525    -0.0526959    0.00951257   0.0555055   -0.103237    -0.123384     -0.00709999   0.0554832    0.0651128   0.026003     0.0182295   -0.15426
  0.107244     0.0303998    0.0401307  -0.127172     0.0450092    -0.0830518   -0.0860556    0.0259399   -0.0615168  -0.147923    -0.169874    0.017867    -0.0616682   -0.053903     0.054925     -0.113759    -0.00397338   0.00657111  -0.0486482    0.0333379    -0.0183063    0.0498519   -0.0264934   0.0691747   -0.0572511   -0.0248515
 -0.139094    -0.0223781   -0.0254182   0.00316143   0.0674478    -0.0517985   -0.00328145   0.144427    -0.112059    0.021033    -0.100096    0.0146463   -0.0535675   -0.053877     0.0305475    -0.0636476    0.141348    -0.0374001    0.0685701    0.0648507    -0.124769     0.112233     0.0231453   0.0460926    0.123794    -0.0886011
  0.00573196   0.0221901   -0.109718    0.0595962    0.0742883     0.594441    -0.17537     -0.490433     0.070153   -0.216998     0.0460088  -0.0489865    0.0254906    0.0524973   -0.000908894  -0.10819      0.153247    -0.0954537   -0.0417754    0.153394     -0.0549057   -0.369853     0.0377291  -0.155916    -0.0972955    0.0501904
  0.0425034    0.0805203   -0.103734    0.0226279   -0.0266082    -0.248019    -0.153497     0.212559     0.196975   -0.0178094    0.0527716  -0.0483786    0.0257155    0.0840237   -0.0162779    -0.101954     0.143371    -0.0718079   -0.0418281    0.0736633    -0.045752    -0.232633    -0.0150679   0.031001    -0.0818297   -0.0961477
  0.0679675    0.190275     0.0945648   0.0140885   -0.00420718   -0.0563972   -0.00107041   0.242706     0.173716   -0.0132374    0.166731   -0.176694     0.0596274   -0.0547308    0.0810691    -0.0576842    0.00474771   0.0150656   -0.0748642    0.0244421     0.0097399   -0.0237126   -0.083616    0.00742135   0.0972824    0.0406517
 -0.0504194   -0.0118571   -0.0448043   0.0168562    0.139601      0.112692    -0.196364    -0.114273    -0.0284045  -0.141779     0.101274    0.0421541   -0.0363519   -0.013289    -0.0389201    -0.152662    -0.063634     0.155484     0.0686025   -0.135116     -0.0784964   -0.00914669  -0.0530145  -0.0450937    0.146863     0.0662196
  0.0575481   -0.114358     0.0147964   0.0448585    0.0706736    -0.104122     0.0271418    0.115849     0.113484   -0.0937044    0.0276198   0.106514    -0.00106615   0.0283566   -0.0441944    -0.028776     0.0250322    0.0498151    0.0351681   -0.0892551    -0.112814     0.155967    -0.0581146  -0.064247    -0.0112573    0.0300439
  0.105472     0.0645522    0.103598   -0.0762655    0.123858      0.0209056   -0.110712    -0.126118     0.124349    0.0719939   -0.0487039   0.018057    -0.166793     0.019464    -0.0229105    -0.124748    -0.0636462    0.0149611   -0.0935244    0.101003      0.0418629    0.139149    -0.0727724   0.050066    -0.102429    -0.0448462
 -0.0474058    0.0696073    0.0183378  -0.080568     0.0627447     0.0153163   -0.0392122   -0.156646    -0.182731    0.0649285   -0.215247    0.0140148    0.09648      0.0264237    0.0815063    -0.0632266   -0.047569    -0.102756    -0.0135473   -0.149076     -0.0058211    0.00896699   0.0241704   0.108302     0.0782293   -0.101634
 -0.0278492   -0.10334     -0.0051105   0.0187726    0.0701066     0.17864      0.0584384   -0.0704187    0.0644431  -0.00103068   0.0478418   0.0566945   -0.015467    -0.00277696  -0.031967      0.122472    -0.04998     -0.0328183    0.106658     0.0615335     0.0601287   -0.0465018    0.0249426   0.0484301   -0.0578591    0.00132259
 -0.0210339   -0.0351016    0.0297592   0.0783473   -0.00448931   -0.0274799    0.0230247   -0.0180115   -0.0099092  -0.0340481    0.0480467   0.00728598   0.0114433   -0.0769211   -0.0088734     0.0390714    0.0715654    0.00476727   0.0265348    0.0226894    -0.0162292    0.0224537    0.0139306  -0.00988586   0.00397526   0.0699325
  0.202202    -0.211221    -0.0365509  -0.079747    -0.300229     -0.158741    -0.0943807   -0.0568577   -0.100567   -0.167861    -0.0140341   0.12812     -0.0286736    0.011423     0.110897     -0.0166167    0.145835    -0.173081    -0.0222405    0.12238       0.0986514   -0.0437178    0.208657    0.0315174   -0.0165308    0.180659
 -0.248231     0.0232291   -0.042388   -0.685371    -0.180358      0.0283788    0.206711    -0.131402     0.104466   -0.163456     0.190098   -0.024343     0.0579861   -0.16867     -0.0855254     0.0193279    0.215859     0.0229503   -0.0588404   -0.14216       0.0597661    0.0167423   -0.130307    0.0297352    0.0338007    0.0902254
  0.4333       0.0212171   -0.0509258   0.603976    -0.19416       0.234669    -0.0419438   -0.0836717    0.128025   -0.164836     0.165825   -0.0412358    0.0342428    0.103726     0.423741      0.0872763    0.157878     0.0157657    0.127421    -0.159673      0.206291     0.00582648  -0.0337906   0.00427506  -0.206276     0.160152
 -0.0235777   -0.054615     0.186012   -0.0709277   -0.000929135  -0.00959282   0.12779      0.0226457    0.0431976  -0.140875     0.158667    0.0289917    0.0548608    0.0876367   -0.0202145    -0.0794668   -0.153524    -0.0232948   -0.177584    -0.143082      0.212303     0.0843051   -0.0328469   0.034806     0.100302    -0.0575897
 -0.0115041    0.186845     0.109915   -0.0292167    0.0383983    -0.13748     -0.0506888    0.00272717  -0.170645    0.0460324    0.0796741  -0.0565508    0.356329    -0.0868923   -0.108493      0.107801    -0.0646642    0.0925785   -0.193804    -0.063714      0.193896     0.0525701    0.055527    0.0294428    0.101993     0.248841
  0.0771566   -0.103072    -0.100516   -0.114457    -0.0976968     0.04207      0.0695172    0.0782398    0.0865438  -0.080419     0.0757491  -0.0924913   -0.110055     0.0960309    0.122377      0.0514862   -0.163508    -0.0588761    0.00349278   0.293935     -0.00563633  -0.0374006    0.0132153   0.138165     0.0473943    0.0744709
  0.132381     0.00129671   0.0132176  -0.00659481  -0.00670418   -0.0186321    0.00839096   0.093739    -0.0756452  -0.00753586   0.0160048   0.00176601   0.212399    -0.087876    -0.0148244    -0.0689743   -0.094513    -0.198825    -0.0590376   -0.000472869   0.0151228    0.00603507  -0.0247951   0.0541496    0.0254756   -0.0413603
  0.0917725   -0.114476    -0.166631   -0.0124545   -0.100979      0.0647331   -0.0577385   -0.291235     0.12414     0.0670732   -0.154805    0.0260182    0.145522     0.0498084   -0.16749       0.280629    -1.63234     -0.149876     0.00640488  -0.213764      0.0602993    0.0688534   -0.0395549  -0.0627428   -0.115495    -0.120676
  0.0947806   -0.15204     -0.220527    0.0262671   -0.0467453    -0.0194876   -0.0650821   -0.135083     0.119088    0.0844541   -0.253815   -0.288638     0.151365     0.0570978   -0.269361     -0.179495     0.47162      0.200733     0.0527677   -0.218655      0.078324     0.0893299   -0.0412534  -0.0366921   -0.0526317   -0.106478
  0.0835413   -0.1264      -0.231673   -0.0915714   -0.0839853     0.110827    -0.0691372    0.108002     0.102466    0.0797501    0.144155   -0.283153     0.150164     0.178623     0.377407     -0.913845     1.04762     -0.0615356   -0.329049    -0.21083       0.0515096    0.0791554   -0.0408081  -0.0621554   -0.108484     0.253359
  0.0898848   -0.11792     -0.157572    0.0311987   -0.0634423    -0.0627157   -0.220791    -0.057602     0.121747    0.0742673    0.412778   -0.194534     0.146987     0.148336    -0.124106      1.37243      0.432097    -0.250683    -0.00553153  -0.213053      0.0659309    0.103811    -0.0558059  -0.0346642   -0.0779655    0.123779
  0.0685282    0.160785    -0.0619161  -0.606828     0.00903935   -0.0405589    0.0409561   -0.294241     0.0234721   0.0565627   -0.176682   -0.0773672    0.0804102    0.131119     0.0702694    -0.00265684   0.0670776    0.171247     0.15388     -0.0562432    -0.116524     0.0823089   -0.0718568   0.00956106  -0.00854634  -0.0157245
  0.080322     0.15508     -0.0557788   0.536487     0.0393799    -0.0805898    0.127312     0.282636     0.0474906   0.0220907   -0.133075    0.0341143    0.106631     0.142437     0.0758553     0.0752234   -0.0961223    0.250556     0.157754    -0.0581977    -0.148434     0.0913327   -0.080542   -0.103349    -0.0103344    0.0198162
  0.0750002   -0.100889     0.0797955   0.130612     0.00258254    0.0147125   -0.0198511    0.31936      0.0283463  -0.0219316    0.17179     0.00547421  -0.0675628   -0.0987896    0.0964155    -0.0327069   -0.0102564   -0.290897     0.0881322   -0.0853919    -0.124604     0.0235683    0.0430629   0.0704225    0.0582326   -0.00224743
 -0.0502345   -0.0665431   -0.0240072   0.0189905    0.195424      0.0861423    0.0325207   -0.116183     0.0185684   0.173304     0.108651    0.0770812    0.00703275   0.0349721    0.0300458    -0.17805     -0.0189658    0.116353    -0.0827668   -0.0167589    -0.0554054    0.121948     0.0456049   0.0661544   -0.0572143    0.00949857[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.092743
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│      ⋮
│     20
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.062455
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.084733
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│      ⋮
│     20
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.066641
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.088015
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│      ⋮
│     20
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.058660
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.092601
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│      ⋮
│     20
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.062146
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.084471
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│      ⋮
│     20
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.066639
┌ Info: EM with 100000 data points 10 iterations avll -1.066639
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.112966e+05
      1       6.943863e+05      -2.169103e+05 |       32
      2       6.668475e+05      -2.753872e+04 |       32
      3       6.484266e+05      -1.842095e+04 |       32
      4       6.337213e+05      -1.470534e+04 |       32
      5       6.268659e+05      -6.855358e+03 |       32
      6       6.242515e+05      -2.614366e+03 |       32
      7       6.230181e+05      -1.233457e+03 |       32
      8       6.222633e+05      -7.548209e+02 |       32
      9       6.216063e+05      -6.569086e+02 |       32
     10       6.207178e+05      -8.885043e+02 |       32
     11       6.195045e+05      -1.213384e+03 |       32
     12       6.183719e+05      -1.132580e+03 |       32
     13       6.174978e+05      -8.740638e+02 |       32
     14       6.169031e+05      -5.946797e+02 |       32
     15       6.165302e+05      -3.729377e+02 |       32
     16       6.163192e+05      -2.109607e+02 |       32
     17       6.161853e+05      -1.339502e+02 |       32
     18       6.160555e+05      -1.297913e+02 |       32
     19       6.158909e+05      -1.645959e+02 |       31
     20       6.156617e+05      -2.292362e+02 |       32
     21       6.152373e+05      -4.243194e+02 |       32
     22       6.145175e+05      -7.198690e+02 |       32
     23       6.138206e+05      -6.969084e+02 |       32
     24       6.133354e+05      -4.851145e+02 |       32
     25       6.129254e+05      -4.100593e+02 |       32
     26       6.126302e+05      -2.952032e+02 |       32
     27       6.124537e+05      -1.765213e+02 |       32
     28       6.123652e+05      -8.843147e+01 |       32
     29       6.123099e+05      -5.534627e+01 |       32
     30       6.122649e+05      -4.494012e+01 |       31
     31       6.122259e+05      -3.907623e+01 |       31
     32       6.121866e+05      -3.927866e+01 |       32
     33       6.121493e+05      -3.724504e+01 |       29
     34       6.121061e+05      -4.321686e+01 |       32
     35       6.120548e+05      -5.128872e+01 |       32
     36       6.119878e+05      -6.704739e+01 |       30
     37       6.118890e+05      -9.879305e+01 |       32
     38       6.117710e+05      -1.180270e+02 |       31
     39       6.116151e+05      -1.559214e+02 |       32
     40       6.114362e+05      -1.788400e+02 |       32
     41       6.112657e+05      -1.705300e+02 |       32
     42       6.111505e+05      -1.151406e+02 |       32
     43       6.110693e+05      -8.123584e+01 |       32
     44       6.110189e+05      -5.038323e+01 |       31
     45       6.109885e+05      -3.043203e+01 |       31
     46       6.109725e+05      -1.598542e+01 |       29
     47       6.109650e+05      -7.477791e+00 |       25
     48       6.109602e+05      -4.823233e+00 |       19
     49       6.109579e+05      -2.262297e+00 |       21
     50       6.109562e+05      -1.790399e+00 |       27
K-means terminated without convergence after 50 iterations (objv = 610956.1510042672)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.331722
[ Info: iteration 2, average log likelihood -1.300395
[ Info: iteration 3, average log likelihood -1.267920
[ Info: iteration 4, average log likelihood -1.230105
[ Info: iteration 5, average log likelihood -1.183856
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.133358
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.126329
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.107197
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.072982
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.072730
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     23
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.061980
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.075580
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      5
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.057830
[ Info: iteration 14, average log likelihood -1.084760
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     22
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.040345
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      5
│     10
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.064749
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.088119
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.052176
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│     10
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.029643
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.085545
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.067376
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     10
│     13
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.055932
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.074825
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.047341
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     10
│     12
│     18
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.031759
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.096595
[ Info: iteration 27, average log likelihood -1.070509
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     18
│     22
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.023950
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     10
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.076238
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.098480
[ Info: iteration 31, average log likelihood -1.064551
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     19
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.020067
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.080184
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.060519
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     10
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.059193
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.058826
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.067880
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     12
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.060180
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.060119
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.064903
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.053564
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     18
│     19
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.030795
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.082258
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.049789
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     18
│     19
│     22
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.022346
[ Info: iteration 46, average log likelihood -1.096436
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     12
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.047514
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.047280
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.060672
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.047151
┌ Info: EM with 100000 data points 50 iterations avll -1.047151
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0847813    0.00954273  -0.11552      0.11943      0.029943      0.0415771    0.0382624     0.0170421   -0.0685059    0.0286992    0.0800119    0.0603882    0.0724917   -0.203522     -0.100393    0.0497074    0.106698      0.0355006    -0.0170392  -0.000145654  -0.103338     0.0380744    0.0284305    -0.00472043   0.111855     0.0666707
  0.0700129    0.189801     0.0950757    0.0133684   -0.00857267   -0.0676484    0.000435603   0.233759     0.1679      -0.0109194    0.163096    -0.175039     0.0791759   -0.0572939     0.0790212  -0.0506224    0.00347143    0.0155052    -0.0774463   0.0231265     0.0195019   -0.0260108   -0.0774308     0.00772664   0.0981238    0.047131
 -0.00433679  -0.0916679    0.0192342   -0.150007     0.119965     -0.191704    -0.105217      0.0239526    0.00704367  -0.145663     0.0809899   -0.0426584    0.0533593    0.0757446    -0.0711839  -0.0659856   -0.175495      0.0211373    -0.0637253  -0.113208     -0.082117    -0.144908     0.0673958    -0.0315161   -0.122862     0.0850408
  0.093148    -0.0393263   -0.0181156    0.164756     0.137356     -0.194915    -0.0628783     0.0664208    0.105355    -0.115204     0.057237     0.0983      -0.0332024    0.0525927    -0.144663   -0.0157992    0.0678316     0.0682417     0.150893   -0.0513461    -0.166696     0.264411    -0.0397259    -0.132502     0.00162711  -0.0195947
  0.0748681   -0.101269     0.0797773    0.130508     0.00215247    0.0124319   -0.0187268     0.324506     0.0275509   -0.0224689    0.173133     0.00512621  -0.0661701   -0.100182      0.0969377  -0.0331839   -0.00957603   -0.294747      0.0872092  -0.0846161    -0.127274     0.0232318    0.0439156     0.0696978    0.0574445   -0.000398795
  0.0743992    0.158117    -0.0590076   -0.0411429    0.0243135    -0.0600516    0.0832576    -0.00850606   0.0342374    0.0394567   -0.155508    -0.0221665    0.0929926    0.136964      0.0730404   0.0367933   -0.013695      0.212182      0.156263   -0.0573009    -0.13253      0.0868121   -0.0767233    -0.0464311   -0.00917994   0.00222204
  0.0635544    0.0315519   -0.16983      0.0487375    0.0130446     0.12664      0.228667     -0.072361     0.0758      -0.12488     -0.0148064    0.0674683   -0.0915632   -0.160775     -0.199216    0.0209845   -0.0507429     0.0975813    -0.0666389  -0.183104      0.0424432   -0.123548    -0.148705     -0.0103143    0.269548     0.0468989
 -0.0616868   -0.158282    -0.0318845    0.0894918    0.169752      0.269426     0.078243     -0.0613351    0.00659673  -0.0082789   -0.0492445    0.0241396    0.00892656   0.0159928    -0.0350434   0.145279    -0.0626722    -0.0973048     0.0818507   0.0609535     0.252398    -0.0800002   -0.000176002   0.143939    -0.0605524    0.000596791
  0.158833     0.0348075    0.24293     -0.0895702    0.133279      0.00522409  -0.202333     -0.217476     0.135323     0.075961    -0.19749     -0.030473    -0.288732    -0.0404197     0.0209852  -0.199518    -0.131709     -0.0367619    -0.0997964   0.194084      0.164968     0.127798    -0.264188     -0.0229782   -0.151298    -0.0901037
  0.0226782   -0.19802      0.0551935   -0.134906    -0.012388     -0.0125992    0.164169      0.187308     0.127334    -0.0519714   -0.0153323    0.118282     0.0316951   -0.000656569   0.08376    -0.0447352   -0.0439772     0.0232051    -0.109394   -0.132783     -0.0492473    0.0090665   -0.0806528     0.025451    -0.0146809    0.0902471
 -0.0502308   -0.0667402   -0.0236142    0.0199372    0.195608      0.0862578    0.033003     -0.114936     0.0174632    0.176525     0.108304     0.0788701    0.00630144   0.034071      0.0303684  -0.179283    -0.01879       0.116272     -0.0855457  -0.0171834    -0.0567679    0.123052     0.0465121     0.0688974   -0.056509     0.0108582
 -0.0110576   -0.0504357    0.0320912   -0.0826609   -0.0822161    -0.0331701    0.0028467     0.0133436    0.0885274   -0.0663312   -0.0437354   -0.0237732   -0.0435749    0.0359294     0.033242    0.00289754  -0.00098613    0.01777       0.124637    0.00741135    0.140812    -0.0674161    0.00818966   -0.158005    -0.0356764    0.121671
 -0.00564474  -0.0777447    0.0635629   -0.0870226   -0.00966025   -0.0382551   -0.0534056    -0.00659271  -0.0258424    0.00985848  -0.00805853   0.0645034    0.00862477   0.00613527    0.0240403   0.00592322  -0.0234377     0.0433594    -0.0691408  -0.0573484     0.15128     -0.0828886    0.0413291    -0.0364627   -0.0129813    0.0963919
  0.090709    -0.129406    -0.193513    -0.00390368  -0.0713844     0.015297    -0.102673     -0.108948     0.117855     0.0767131    0.0110065   -0.186279     0.148574     0.100734     -0.0859291   0.181626     0.045204     -0.0482494    -0.0451389  -0.21456       0.065672     0.0858861   -0.0443122    -0.0472973   -0.0850977    0.0149593
 -0.117605    -0.00643442  -0.106985     0.0247398   -0.102041     -0.148871     0.190926      0.04175      0.0913063    0.0350788    0.0646089    0.235489    -0.0751393    0.0629525     0.227576   -0.0335743    0.0223509    -0.119754      0.0856601  -0.055372     -0.168024    -0.075861    -0.0259523     0.151789     0.0627773   -0.0313069
  0.0116822   -0.0666843    0.0877885    0.0694032   -0.0525682    -0.098183    -0.0250382     0.113264     0.0149913    0.0158572    0.174682    -0.170052    -0.0674002    0.0492906     0.0564028   0.0563201   -0.0240235    -0.0261803    -0.041217   -0.106666     -0.00987403  -0.108889    -0.046717     -0.0597465    0.0965223   -0.240992
  0.070338    -0.106333    -0.095635    -0.0982979   -0.0959289     0.0408421    0.0583689     0.0692163    0.0826003   -0.0766398    0.0833124   -0.103153    -0.107996     0.093293      0.119898    0.0631633   -0.16649      -0.0537325     0.0063571   0.303739      0.00548826  -0.0288159    0.0230852     0.127564     0.058239     0.083915
 -0.140109    -0.0101184   -0.0226927    0.00309838   0.0655981    -0.0522795   -0.00742482    0.141488    -0.112733     0.0223427   -0.0958213    0.0107932   -0.0426404   -0.055326      0.0247399  -0.0598671    0.139798     -0.0372978     0.0635069   0.0649979    -0.120816     0.112023     0.023413      0.0497835    0.126999    -0.0822203
  0.0748054    0.0220892   -0.0458447   -0.0963416   -0.187352      0.120687     0.0930418    -0.111332     0.114917    -0.164122     0.179526    -0.0297188    0.0497405   -0.0438777     0.153006    0.0523843    0.193786      0.0216077     0.0216511  -0.150959      0.126914     0.012779    -0.0863961     0.0204338   -0.0792322    0.123173
 -0.143393    -0.0631201   -0.0396972    0.190661    -0.0233226     0.234843     0.114322     -0.122085     0.0232747   -0.0831388    0.0353975   -0.165302     0.066127     0.184828      0.0831474  -0.0517611    0.00844238    0.0578104    -0.102756   -0.123715     -0.00274721   0.0564674    0.0674107     0.0250262    0.017837    -0.152863
 -0.0881194   -0.0766926    0.15161      0.00323856  -0.0032961     0.0471144   -0.13018      -0.00686334   0.137856    -0.169348     0.013252     0.129409    -0.112556    -0.00614712   -0.0452057   0.00309226  -0.231669     -0.161597     -0.190376   -0.101504      0.0589928   -0.103199    -0.0422938     0.0127312    0.00751244  -0.0593496
  0.0285375    0.0573281   -0.105773     0.0372687    0.0141988     0.0754596   -0.162268     -0.0613241    0.146987    -0.0969652    0.050164    -0.0477386    0.025697     0.073223     -0.0122901  -0.1044       0.147576     -0.0802712    -0.0416017   0.105559     -0.0497011   -0.285227     0.00622676   -0.0422941   -0.0880432   -0.0393873
 -0.0503651    0.0900919   -0.00918367  -0.101012     0.0623592     0.0304338   -0.0606046    -0.15531     -0.236576     0.085665    -0.310087     0.00873098   0.0956963    0.0209981     0.0752398  -0.0687661   -0.0710457    -0.101967     -0.0139469  -0.169994      0.0135722    0.039293     0.0283924     0.124189     0.0882384   -0.0983361
  0.103049     0.0317307    0.038268    -0.120127     0.0591739    -0.0817917   -0.0911294     0.0313036   -0.0639562   -0.149268    -0.169404     0.0159469   -0.0555087   -0.053982      0.0564277  -0.11044      0.000701593   0.00832      -0.0516965   0.0417759    -0.0184111    0.0519168   -0.0223744     0.0776631   -0.0483612   -0.0256453
 -0.0226725   -0.0543176    0.18757     -0.0717725   -0.000480802  -0.00934914   0.127719      0.0227091    0.0434746   -0.140691     0.158038     0.0293455    0.0557526    0.087303     -0.0210069  -0.0781611   -0.152619     -0.0241601    -0.176474   -0.143551      0.212456     0.0838674   -0.032932      0.0348232    0.100984    -0.0577707
  0.0040038   -0.0153416    0.0145993   -0.0358679   -0.0244654     0.110879     0.0153187    -0.0962432    0.06843      0.00512017   0.135048     0.0844184    0.00218607  -0.0203425    -0.0221572   0.0763776   -0.0375576     0.000865279   0.0828981   0.0312011    -0.118038     0.00594872   0.047973     -0.0170551   -0.0175346    0.00246876
 -0.00895031   0.250022     0.129925    -0.0292699    0.0394769    -0.156268    -0.0669428    -0.012501    -0.192243     0.0500587    0.0715005   -0.0408937    0.401965    -0.0691559    -0.147095    0.076329    -0.0671218     0.0794167    -0.193539   -0.131057      0.240067     0.0702491    0.0510254     0.0552289    0.105861     0.197643
  0.0795858    0.103993    -0.00749119  -0.067322     0.119352      0.0210537   -0.0343782    -0.0456939    0.108998     0.0655031    0.0779888    0.0472017   -0.0465794    0.0671148    -0.0644808  -0.0602467   -0.0131765     0.0678313    -0.0977052   0.0209166    -0.0689111    0.142378     0.081415      0.0969166   -0.0604198    0.00974428
 -0.140313    -0.0246281    0.16667      0.16577      0.0272278    -0.118578     0.00401485   -0.0906299   -0.0763719   -0.0471323    0.0950174   -0.0353398    0.0381401   -0.0618995     0.0245436   0.0586119    0.103376     -0.0193643    -0.0385064   0.0587959    -0.0537658    0.0916666    0.0102883     0.108645    -0.0506151    0.0441906
 -0.0513839   -0.00431274  -0.0358962    0.0146556    0.138799      0.103788    -0.191833     -0.105523    -0.035878    -0.132053     0.101674     0.0403707   -0.0204026   -0.0168142    -0.034289   -0.141666    -0.0635225     0.151147      0.0617309  -0.134681     -0.0635689   -0.00631356  -0.0478584    -0.0416358    0.145772     0.0723376
  0.202833    -0.213694    -0.0351618   -0.0841445   -0.302884     -0.158407    -0.0958823    -0.0604058   -0.100042    -0.167937    -0.00930965   0.131444    -0.0286323    0.0107585     0.111072   -0.0131166    0.147904     -0.175733     -0.0228361   0.124561      0.0980783   -0.0433493    0.211328      0.0345113   -0.0153083    0.181314
  0.136153     0.00680963   0.0123019   -0.00015195  -0.0061503    -0.0178198    0.00960474    0.091069    -0.0806776   -0.00893908   0.0192906   -0.00206565   0.221827    -0.0892372    -0.0148919  -0.0657224   -0.0962105    -0.192686     -0.061587   -0.00204054    0.0201824    0.00496674  -0.0245222     0.0535087    0.028534    -0.0370238[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.049599
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     18
│     19
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.015674
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│     12
│     18
│     19
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.002928
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     18
│     19
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.034654
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     13
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.028363
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│     12
│     18
│      ⋮
│     23
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.989941
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.048665
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     18
│     19
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.016722
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│     12
│     18
│     19
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.002753
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     18
│     19
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.034688
┌ Info: EM with 100000 data points 10 iterations avll -1.034688
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0244806   -0.0429552    -0.0464438  -0.00139654  -0.0628451   -0.0311487   -0.115401     0.100522      0.00258684   0.0644323  -0.0969493   -0.0657348    0.0715373    0.126159   -0.0653988    0.0616941   -0.0363539   -0.0332564   -0.111168    -0.0961623     0.13494      0.0162769   -0.0766165    0.167962     0.0570756   -0.0494597
  0.0336682   -0.0804457    -0.113697    0.200799    -0.166346     0.109327    -0.0985593    0.0520902    -0.18052      0.0122588   0.210965    -0.0785885   -0.216135    -0.208193   -0.005168    -0.0608592   -0.0344516   -0.283237     0.11317     -0.0908726     0.0299095   -0.237172     0.0821414    0.0850344    0.00690697  -0.0569325
 -0.0683149   -0.0559459     0.105118    0.0600006    0.0739095   -0.120074    -0.0883851    0.0286265    -0.122223     0.0309905   0.0262682   -0.0684185   -0.0288526   -0.0345233   0.126595     0.0667547   -0.0220939   -0.0583592    0.0478271   -0.0349264    -0.00249417  -0.0354355   -0.0358619   -0.100862    -0.0449222    0.102615
 -0.0349872   -0.0134662     0.0484967  -0.159755    -0.0386392   -0.0440942   -0.119858     0.0804401     0.0068052    0.0320499   0.0715552    0.0431205   -0.0209544    0.0518986  -0.162893    -0.0351933    0.00498237  -0.0908862   -0.138786     0.024603      0.0221405   -0.0582952   -0.114275     0.166589    -0.0990127   -0.0218842
 -0.186873    -0.0663298     0.0343795  -0.0104528   -0.0304429    0.142058     0.0211133   -0.119484      0.0655164    0.153714   -0.013072     0.0259453   -0.0089559    0.240101   -0.00535108   0.0272253    0.0501382    0.11433     -0.105509    -0.0611589     0.0702407    0.0198706    0.115425    -0.152757     0.239177    -0.05111
  0.166091    -0.119384     -0.0506633  -0.00688622   0.22735     -0.0161631    0.0824663    0.0954532     0.00924813  -0.115793   -0.0361803   -0.0701915    0.015866    -0.112551    0.0217244   -0.0886489   -0.163546    -0.0365053   -0.0557898    0.160641     -0.0548606   -0.132883     0.0968388   -0.0564431   -0.183491     0.165892
 -0.0613182   -0.0218049    -0.0123237   0.0133622   -0.0486353   -0.00165755   0.0746466   -0.0718216     0.0272214   -0.206543   -0.00150791   0.0976355    0.0314295   -0.046447   -0.249462    -0.0175111    0.0373184    0.0128566   -0.154906    -0.118673      0.0706174   -0.101387     0.0937199    0.0114407    0.089557     0.0520176
 -0.0644201   -0.0262487    -0.109388    0.0663731    0.0450057   -0.0565584    0.0334543    0.0698019    -0.149144    -0.0105296  -0.0256021    0.0557388    0.11313      0.0723472   0.0585643    0.084151     0.2029      -0.119978    -0.0256609    0.0588101     0.0542639   -0.0872859    0.0683301    0.0197732    0.180815    -0.115598
  0.0208239    0.0725075    -0.0506157  -0.0606195   -0.164358    -0.221615    -0.0381157    0.0107194     0.156869     0.122647   -0.121209    -0.0630993    0.0647671    0.0518922  -0.102241     0.0367558   -0.035366     0.11552      0.00785373  -0.0627713    -0.0960582   -0.190383     0.0985008    0.168184    -0.106601     0.100376
  0.0118462   -0.0272276     0.0501381  -0.0453892    0.162926    -0.214321     0.0140889   -0.168276     -0.183561    -0.0797181  -0.0643088    0.0437716   -0.0697167   -0.0115233  -0.0552975   -0.00856515  -0.00117271  -0.210572    -0.0256382   -0.0959661     0.282372    -0.0537444   -0.11708      0.0616737    0.0740272   -0.0263427
  0.0256351   -0.0311179     0.0589962  -0.0657034    0.0435677   -0.224766     0.00323501  -0.0217694    -0.0175168   -0.0848879  -0.040221    -0.187308     0.118558     0.127808    0.0515986    0.0783001   -0.0364727    0.0210084    0.0134136   -0.000100469   0.114607     0.0276631   -0.0187812    0.0769184   -0.129543     0.0418865
  0.0763503    0.0439075    -0.0784039   0.0670216   -0.0782069    0.036212    -0.150968     0.104939     -0.176729     0.115668   -0.145345     0.0738817    0.110631     0.0894055   0.0623244   -0.129097     0.0225501   -0.087129     0.0759199    0.00724445   -0.0099842   -0.00297318  -0.0539973   -0.0806391    0.0670442    0.0170058
  0.0681547   -0.203724      0.0663697   0.00965446   0.0322436   -0.16594      0.0596988   -0.149101      0.00239847  -0.141117   -0.00403006  -0.17242      0.0815077    0.0021365  -0.0178098    0.0194444    0.157922     0.0784867    0.200791     0.0159159    -0.0289451    0.204851     0.00846891  -0.146889    -0.135271     0.0650008
  0.0363461   -0.0521987     0.0572247   0.0557556    0.0522432   -0.123907     0.0482649    0.248102      0.0363482    0.130315   -0.0677731   -0.0482683    0.0633906    0.108351   -0.202907     0.0825003   -0.0934657    0.182806     0.00258309   0.0706952     0.114153    -0.0755729    0.129909     0.0472143   -0.101368    -0.0405817
  0.11023      0.0704527    -0.0204732  -0.0410635    0.0989824    0.0230884   -0.0576226    0.000454337  -0.0488178   -0.0430225  -0.0865648   -0.0962581   -0.0886709   -0.0062358  -0.0646567    0.00385131   0.0863596    0.0204906    0.0371745   -0.00543985   -0.051619     0.111558    -0.0586807    0.0563182    0.107386     0.0369887
 -0.102861    -0.0555262    -0.06154     0.194232    -0.0859088    0.0275782    0.233165    -0.0119454     0.149642    -0.0194544   0.0810933   -0.081607    -0.0749213    0.075828    0.0209027    0.0750157    0.00178959   0.174562    -0.0275449   -0.0126963     0.0592537   -0.0314872    0.210232    -0.00569722   0.0615409    0.0273776
  0.0115162    0.172183     -0.0112739  -0.0563513   -0.0722652    0.116031     0.19285      0.0235842    -0.0907255   -0.129602    0.057582     0.0252921    0.0181834    0.0373083   0.0726921   -0.075352     0.133343    -0.195265    -0.10824      0.108016     -0.0165197    0.0213621    0.147237    -0.0347184    0.0842868   -0.0155338
  0.14672     -0.261783     -0.131979   -0.0192167   -0.0362776    0.149122     0.0571683   -0.0257341     0.0627029   -0.0158291   0.0817695   -0.109614     0.0450515   -0.0213259  -0.00138317   0.0830448    0.00345348  -0.0438974    0.0819996   -0.000859657   0.0327505    0.0747877    0.112283     0.0176495    0.030254     0.0330715
  0.179009    -0.0606524    -0.0311379   0.223894     0.0606464    0.093781     0.0635598   -0.0662224    -0.00248746   0.023159    0.190106     0.0219488   -0.156475    -0.0129365   0.0644313    0.00039507  -0.0347757    0.0911986   -0.107802     0.0418617    -0.200066     0.153144     0.0185644   -0.0223749    0.018618    -0.0882175
  0.116257    -0.110716     -0.178711   -0.00452464  -0.0322343    0.0512015    0.0178712   -0.0974732    -0.0185894    0.0385543  -0.0812974    0.00352758  -0.0766536    0.0437825   0.0651996    0.0794591    0.116335     0.110631    -0.0856143   -0.0621091    -0.0354529    0.0974027    0.108843    -0.0948974    0.0233679    0.00965887
 -0.125798     0.00322864    0.0768767   0.058252     0.0461313   -0.170429     0.16266     -0.0804244    -0.0069869    0.0412953   0.00277374  -0.0887511   -0.300155     0.107986    0.0626654   -0.00513254  -0.041149    -0.0808901    0.145641    -0.0421372    -0.0814309   -0.0721996   -0.0143341    0.123169    -0.0150157    0.0299603
 -0.0356175   -0.0474936    -0.197149   -0.0717516    0.0815516    0.0969305    0.279527    -0.154305     -0.183826     0.304206    0.0571263   -0.154299     0.00799627  -0.133332   -0.0543361    0.0636165    0.030959    -0.121999    -0.0799782   -0.0883315    -0.118047    -0.0326764    0.135674    -0.111058     0.0184334    0.0287138
  0.0540608   -0.0498524     0.0424964  -0.154011    -0.0255628   -0.0763395   -0.0170853    0.0286927    -0.0902824    0.0764443  -0.0582991   -0.00358981  -0.0522504    0.0916956  -0.0567658    0.117655    -0.040183    -0.103359     0.029285    -0.161115     -0.112574     0.193525     0.085765    -0.020016     0.139205    -0.0257719
  0.0277663    0.108067     -0.123454   -0.015883    -0.0476305    0.0579061   -0.15157     -0.0696854     0.0153146    0.0149682  -0.0413672   -0.0327216   -0.194647     0.0652612   0.0980326    0.212065     0.101396     0.0714496   -0.11116      0.0391347     0.0218451   -0.0230695    0.00783577  -0.12593      0.193947     0.0553778
  0.201025    -0.000218331   0.109731    0.0111303   -0.0434828   -0.137397     0.103014    -0.0552657     0.0518062   -0.0263147  -0.0582879   -0.0915654   -0.068113    -0.0164134  -0.0245442    0.0231506   -0.180002     0.00125863  -0.216053    -0.0569276     0.111663    -0.248018     0.0677952    0.0282272   -0.15237     -0.0297933
  0.00628721   0.0881308    -0.0966985   0.015769    -0.0629474   -0.115715    -0.0535383    0.049139     -0.0541566    0.218447   -0.00160567  -0.0147767   -0.205111     0.120632    0.144291     0.099835    -0.0697254   -0.137865    -0.0776895    0.0528024    -0.0277004   -0.0990998    0.0816404   -0.0557294   -0.113833    -0.0403358
 -0.146907    -0.000506291   0.053491    0.0193852   -0.00376511   0.033597     0.0516145   -0.0566915     0.041517     0.131338    0.0885998   -0.0438394    0.0934396   -0.0177191   0.0012377    0.123993     0.0450626    0.0144701    0.0231941    0.0610268     0.0747774   -0.0484849    0.065671    -0.193682    -0.157002     0.0257356
  0.136921    -0.128137      0.145091    0.171327     0.231911     0.0248997   -0.166348    -0.0855727    -0.168014    -0.0886379   0.0415173    0.0866571    0.0158782   -0.0433589   0.00698201  -0.175253    -0.0892311   -0.0354079   -0.0439469   -0.0855732     0.0992725   -0.00659153  -0.10844     -0.147477    -0.121871     0.0272642
  0.186357     0.11867      -0.119517   -0.0557054   -0.0187125   -0.0224014    0.105942    -0.119031      0.134369     0.0885519  -0.0663451    0.0618871   -0.036004     0.0378836   0.0583768    0.0132933    0.117998     0.16399      0.0327749   -0.0367159    -0.220419     0.0877853    0.130681     0.0100301    0.00997675  -0.078142
 -0.0222246   -0.166029      0.05537     0.144442    -0.0248838   -0.0796528    0.0150259    0.0405999    -0.0869739    0.0834927   0.0718858   -0.0282216    0.0486369   -0.028756    0.0655337    0.0066615    0.0596651   -0.00107458  -0.0686974   -0.00856804   -0.0363808   -0.0302302    0.00293684  -0.0935251   -0.0244412   -0.122843
  0.0399999    0.0190855     0.157776    0.086387    -0.0989462   -0.12118     -0.00645692   0.0269874     0.00229968   0.0793527  -0.0378784   -0.0610464   -0.0937804   -0.0523782  -0.0127435   -0.0601279   -0.091079     0.0244606   -0.193593    -0.123019     -0.137653     0.0641805   -0.107313    -0.00911021  -0.0832717   -0.149025
  0.0252594    0.0288274    -0.149762    0.0724729    0.0906613   -0.16573      0.0278716   -0.0611382     0.0292945   -0.0812464   0.130858    -0.183969    -0.049756    -0.0833916   0.0237792    0.152293    -0.0512467    0.0668769    0.156963    -0.0173733    -0.0741659   -0.0204815    0.118469    -0.0301399    0.0848616   -0.0580127kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.42797559560665
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427995
[ Info: iteration 2, average log likelihood -1.427907
[ Info: iteration 3, average log likelihood -1.427832
[ Info: iteration 4, average log likelihood -1.427737
[ Info: iteration 5, average log likelihood -1.427614
[ Info: iteration 6, average log likelihood -1.427455
[ Info: iteration 7, average log likelihood -1.427243
[ Info: iteration 8, average log likelihood -1.426940
[ Info: iteration 9, average log likelihood -1.426476
[ Info: iteration 10, average log likelihood -1.425778
[ Info: iteration 11, average log likelihood -1.424879
[ Info: iteration 12, average log likelihood -1.423983
[ Info: iteration 13, average log likelihood -1.423328
[ Info: iteration 14, average log likelihood -1.422963
[ Info: iteration 15, average log likelihood -1.422792
[ Info: iteration 16, average log likelihood -1.422717
[ Info: iteration 17, average log likelihood -1.422685
[ Info: iteration 18, average log likelihood -1.422671
[ Info: iteration 19, average log likelihood -1.422665
[ Info: iteration 20, average log likelihood -1.422662
[ Info: iteration 21, average log likelihood -1.422660
[ Info: iteration 22, average log likelihood -1.422660
[ Info: iteration 23, average log likelihood -1.422659
[ Info: iteration 24, average log likelihood -1.422659
[ Info: iteration 25, average log likelihood -1.422659
[ Info: iteration 26, average log likelihood -1.422658
[ Info: iteration 27, average log likelihood -1.422658
[ Info: iteration 28, average log likelihood -1.422658
[ Info: iteration 29, average log likelihood -1.422658
[ Info: iteration 30, average log likelihood -1.422658
[ Info: iteration 31, average log likelihood -1.422658
[ Info: iteration 32, average log likelihood -1.422657
[ Info: iteration 33, average log likelihood -1.422657
[ Info: iteration 34, average log likelihood -1.422657
[ Info: iteration 35, average log likelihood -1.422657
[ Info: iteration 36, average log likelihood -1.422657
[ Info: iteration 37, average log likelihood -1.422657
[ Info: iteration 38, average log likelihood -1.422657
[ Info: iteration 39, average log likelihood -1.422657
[ Info: iteration 40, average log likelihood -1.422657
[ Info: iteration 41, average log likelihood -1.422657
[ Info: iteration 42, average log likelihood -1.422657
[ Info: iteration 43, average log likelihood -1.422657
[ Info: iteration 44, average log likelihood -1.422657
[ Info: iteration 45, average log likelihood -1.422657
[ Info: iteration 46, average log likelihood -1.422657
[ Info: iteration 47, average log likelihood -1.422657
[ Info: iteration 48, average log likelihood -1.422657
[ Info: iteration 49, average log likelihood -1.422657
[ Info: iteration 50, average log likelihood -1.422657
┌ Info: EM with 100000 data points 50 iterations avll -1.422657
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4279946628961901
│     -1.4279070847537805
│      ⋮
└     -1.422656567991824
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422675
[ Info: iteration 2, average log likelihood -1.422585
[ Info: iteration 3, average log likelihood -1.422505
[ Info: iteration 4, average log likelihood -1.422407
[ Info: iteration 5, average log likelihood -1.422287
[ Info: iteration 6, average log likelihood -1.422156
[ Info: iteration 7, average log likelihood -1.422032
[ Info: iteration 8, average log likelihood -1.421933
[ Info: iteration 9, average log likelihood -1.421861
[ Info: iteration 10, average log likelihood -1.421813
[ Info: iteration 11, average log likelihood -1.421778
[ Info: iteration 12, average log likelihood -1.421750
[ Info: iteration 13, average log likelihood -1.421724
[ Info: iteration 14, average log likelihood -1.421700
[ Info: iteration 15, average log likelihood -1.421676
[ Info: iteration 16, average log likelihood -1.421651
[ Info: iteration 17, average log likelihood -1.421626
[ Info: iteration 18, average log likelihood -1.421600
[ Info: iteration 19, average log likelihood -1.421576
[ Info: iteration 20, average log likelihood -1.421552
[ Info: iteration 21, average log likelihood -1.421530
[ Info: iteration 22, average log likelihood -1.421510
[ Info: iteration 23, average log likelihood -1.421493
[ Info: iteration 24, average log likelihood -1.421478
[ Info: iteration 25, average log likelihood -1.421465
[ Info: iteration 26, average log likelihood -1.421455
[ Info: iteration 27, average log likelihood -1.421446
[ Info: iteration 28, average log likelihood -1.421439
[ Info: iteration 29, average log likelihood -1.421433
[ Info: iteration 30, average log likelihood -1.421427
[ Info: iteration 31, average log likelihood -1.421423
[ Info: iteration 32, average log likelihood -1.421419
[ Info: iteration 33, average log likelihood -1.421416
[ Info: iteration 34, average log likelihood -1.421413
[ Info: iteration 35, average log likelihood -1.421410
[ Info: iteration 36, average log likelihood -1.421407
[ Info: iteration 37, average log likelihood -1.421405
[ Info: iteration 38, average log likelihood -1.421403
[ Info: iteration 39, average log likelihood -1.421400
[ Info: iteration 40, average log likelihood -1.421398
[ Info: iteration 41, average log likelihood -1.421396
[ Info: iteration 42, average log likelihood -1.421395
[ Info: iteration 43, average log likelihood -1.421393
[ Info: iteration 44, average log likelihood -1.421391
[ Info: iteration 45, average log likelihood -1.421389
[ Info: iteration 46, average log likelihood -1.421388
[ Info: iteration 47, average log likelihood -1.421386
[ Info: iteration 48, average log likelihood -1.421384
[ Info: iteration 49, average log likelihood -1.421383
[ Info: iteration 50, average log likelihood -1.421381
┌ Info: EM with 100000 data points 50 iterations avll -1.421381
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.422675366694946
│     -1.4225845275993938
│      ⋮
└     -1.4213810543778882
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421392
[ Info: iteration 2, average log likelihood -1.421330
[ Info: iteration 3, average log likelihood -1.421273
[ Info: iteration 4, average log likelihood -1.421203
[ Info: iteration 5, average log likelihood -1.421115
[ Info: iteration 6, average log likelihood -1.421009
[ Info: iteration 7, average log likelihood -1.420888
[ Info: iteration 8, average log likelihood -1.420765
[ Info: iteration 9, average log likelihood -1.420651
[ Info: iteration 10, average log likelihood -1.420556
[ Info: iteration 11, average log likelihood -1.420482
[ Info: iteration 12, average log likelihood -1.420427
[ Info: iteration 13, average log likelihood -1.420387
[ Info: iteration 14, average log likelihood -1.420357
[ Info: iteration 15, average log likelihood -1.420333
[ Info: iteration 16, average log likelihood -1.420314
[ Info: iteration 17, average log likelihood -1.420296
[ Info: iteration 18, average log likelihood -1.420280
[ Info: iteration 19, average log likelihood -1.420265
[ Info: iteration 20, average log likelihood -1.420251
[ Info: iteration 21, average log likelihood -1.420237
[ Info: iteration 22, average log likelihood -1.420223
[ Info: iteration 23, average log likelihood -1.420209
[ Info: iteration 24, average log likelihood -1.420195
[ Info: iteration 25, average log likelihood -1.420182
[ Info: iteration 26, average log likelihood -1.420170
[ Info: iteration 27, average log likelihood -1.420158
[ Info: iteration 28, average log likelihood -1.420147
[ Info: iteration 29, average log likelihood -1.420136
[ Info: iteration 30, average log likelihood -1.420126
[ Info: iteration 31, average log likelihood -1.420117
[ Info: iteration 32, average log likelihood -1.420109
[ Info: iteration 33, average log likelihood -1.420101
[ Info: iteration 34, average log likelihood -1.420093
[ Info: iteration 35, average log likelihood -1.420087
[ Info: iteration 36, average log likelihood -1.420081
[ Info: iteration 37, average log likelihood -1.420075
[ Info: iteration 38, average log likelihood -1.420069
[ Info: iteration 39, average log likelihood -1.420064
[ Info: iteration 40, average log likelihood -1.420060
[ Info: iteration 41, average log likelihood -1.420055
[ Info: iteration 42, average log likelihood -1.420051
[ Info: iteration 43, average log likelihood -1.420047
[ Info: iteration 44, average log likelihood -1.420043
[ Info: iteration 45, average log likelihood -1.420040
[ Info: iteration 46, average log likelihood -1.420036
[ Info: iteration 47, average log likelihood -1.420033
[ Info: iteration 48, average log likelihood -1.420030
[ Info: iteration 49, average log likelihood -1.420027
[ Info: iteration 50, average log likelihood -1.420024
┌ Info: EM with 100000 data points 50 iterations avll -1.420024
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.42139212307593
│     -1.421330067165635
│      ⋮
└     -1.420023570692723
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420029
[ Info: iteration 2, average log likelihood -1.419976
[ Info: iteration 3, average log likelihood -1.419927
[ Info: iteration 4, average log likelihood -1.419873
[ Info: iteration 5, average log likelihood -1.419806
[ Info: iteration 6, average log likelihood -1.419725
[ Info: iteration 7, average log likelihood -1.419628
[ Info: iteration 8, average log likelihood -1.419518
[ Info: iteration 9, average log likelihood -1.419401
[ Info: iteration 10, average log likelihood -1.419284
[ Info: iteration 11, average log likelihood -1.419171
[ Info: iteration 12, average log likelihood -1.419068
[ Info: iteration 13, average log likelihood -1.418976
[ Info: iteration 14, average log likelihood -1.418895
[ Info: iteration 15, average log likelihood -1.418825
[ Info: iteration 16, average log likelihood -1.418764
[ Info: iteration 17, average log likelihood -1.418710
[ Info: iteration 18, average log likelihood -1.418664
[ Info: iteration 19, average log likelihood -1.418622
[ Info: iteration 20, average log likelihood -1.418585
[ Info: iteration 21, average log likelihood -1.418551
[ Info: iteration 22, average log likelihood -1.418521
[ Info: iteration 23, average log likelihood -1.418493
[ Info: iteration 24, average log likelihood -1.418467
[ Info: iteration 25, average log likelihood -1.418442
[ Info: iteration 26, average log likelihood -1.418419
[ Info: iteration 27, average log likelihood -1.418397
[ Info: iteration 28, average log likelihood -1.418377
[ Info: iteration 29, average log likelihood -1.418357
[ Info: iteration 30, average log likelihood -1.418339
[ Info: iteration 31, average log likelihood -1.418321
[ Info: iteration 32, average log likelihood -1.418305
[ Info: iteration 33, average log likelihood -1.418289
[ Info: iteration 34, average log likelihood -1.418274
[ Info: iteration 35, average log likelihood -1.418260
[ Info: iteration 36, average log likelihood -1.418247
[ Info: iteration 37, average log likelihood -1.418234
[ Info: iteration 38, average log likelihood -1.418222
[ Info: iteration 39, average log likelihood -1.418211
[ Info: iteration 40, average log likelihood -1.418200
[ Info: iteration 41, average log likelihood -1.418190
[ Info: iteration 42, average log likelihood -1.418180
[ Info: iteration 43, average log likelihood -1.418170
[ Info: iteration 44, average log likelihood -1.418161
[ Info: iteration 45, average log likelihood -1.418152
[ Info: iteration 46, average log likelihood -1.418144
[ Info: iteration 47, average log likelihood -1.418136
[ Info: iteration 48, average log likelihood -1.418128
[ Info: iteration 49, average log likelihood -1.418121
[ Info: iteration 50, average log likelihood -1.418114
┌ Info: EM with 100000 data points 50 iterations avll -1.418114
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4200288960210516
│     -1.4199755092921396
│      ⋮
└     -1.4181136099308236
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418115
[ Info: iteration 2, average log likelihood -1.418048
[ Info: iteration 3, average log likelihood -1.417986
[ Info: iteration 4, average log likelihood -1.417914
[ Info: iteration 5, average log likelihood -1.417826
[ Info: iteration 6, average log likelihood -1.417719
[ Info: iteration 7, average log likelihood -1.417593
[ Info: iteration 8, average log likelihood -1.417452
[ Info: iteration 9, average log likelihood -1.417302
[ Info: iteration 10, average log likelihood -1.417152
[ Info: iteration 11, average log likelihood -1.417007
[ Info: iteration 12, average log likelihood -1.416872
[ Info: iteration 13, average log likelihood -1.416749
[ Info: iteration 14, average log likelihood -1.416638
[ Info: iteration 15, average log likelihood -1.416539
[ Info: iteration 16, average log likelihood -1.416453
[ Info: iteration 17, average log likelihood -1.416377
[ Info: iteration 18, average log likelihood -1.416310
[ Info: iteration 19, average log likelihood -1.416252
[ Info: iteration 20, average log likelihood -1.416200
[ Info: iteration 21, average log likelihood -1.416155
[ Info: iteration 22, average log likelihood -1.416114
[ Info: iteration 23, average log likelihood -1.416076
[ Info: iteration 24, average log likelihood -1.416042
[ Info: iteration 25, average log likelihood -1.416011
[ Info: iteration 26, average log likelihood -1.415981
[ Info: iteration 27, average log likelihood -1.415954
[ Info: iteration 28, average log likelihood -1.415927
[ Info: iteration 29, average log likelihood -1.415902
[ Info: iteration 30, average log likelihood -1.415878
[ Info: iteration 31, average log likelihood -1.415855
[ Info: iteration 32, average log likelihood -1.415832
[ Info: iteration 33, average log likelihood -1.415810
[ Info: iteration 34, average log likelihood -1.415788
[ Info: iteration 35, average log likelihood -1.415767
[ Info: iteration 36, average log likelihood -1.415746
[ Info: iteration 37, average log likelihood -1.415725
[ Info: iteration 38, average log likelihood -1.415705
[ Info: iteration 39, average log likelihood -1.415684
[ Info: iteration 40, average log likelihood -1.415664
[ Info: iteration 41, average log likelihood -1.415644
[ Info: iteration 42, average log likelihood -1.415625
[ Info: iteration 43, average log likelihood -1.415606
[ Info: iteration 44, average log likelihood -1.415587
[ Info: iteration 45, average log likelihood -1.415569
[ Info: iteration 46, average log likelihood -1.415552
[ Info: iteration 47, average log likelihood -1.415535
[ Info: iteration 48, average log likelihood -1.415519
[ Info: iteration 49, average log likelihood -1.415504
[ Info: iteration 50, average log likelihood -1.415489
┌ Info: EM with 100000 data points 50 iterations avll -1.415489
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.418115374984043
│     -1.4180484943388338
│      ⋮
└     -1.4154887864369752
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.42797559560665
│     -1.4279946628961901
│     -1.4279070847537805
│     -1.4278316914918356
│      ⋮
│     -1.4155190585973152
│     -1.4155035899833297
└     -1.4154887864369752
32×26 Array{Float64,2}:
 -0.29178     0.209807   -0.16187      -0.376697    0.183629   -0.0765963   0.272823     0.13212     0.255939    0.147275     0.084429   -0.402476   -0.754775   -0.413276    -0.37233      -0.17027     -0.16031    -0.688127     0.278392    -0.406286     0.21266     -0.315994     0.322952     0.244921     0.00690828   0.433478
 -0.0447311  -0.0889871   0.147318     -0.023772    0.156818   -0.0408067   0.70882      0.337599   -0.37837     0.0168352   -0.271973    0.0936627  -0.373768    0.338434     0.540575     -0.00204526  -0.254727   -0.771377     0.466515    -0.334623    -0.246217     0.507043     0.310634    -0.0105395    0.340679     0.075676
 -0.0524915  -0.13538    -0.15788      -0.291937    0.402597   -0.654937    0.898691    -0.0963596  -0.363256   -0.0865842   -0.331976   -0.0536577  -0.558689    0.456884     0.0754554    -0.427132     0.275824    0.611775     0.491825     0.186531    -0.222365    -0.0741857   -0.0391106   -0.357015     0.114085    -0.412486
  0.376395   -0.37338     0.117867     -0.370925    0.255088   -0.361762   -0.12269     -0.463097   -0.773147    0.285541     0.800596    0.102829    0.0645333   0.0710002    0.433766     -0.0638761    0.138382    0.249097    -0.34048      0.136446    -0.660032    -0.0885535    0.01453     -0.488804     0.112831    -0.129399
 -0.617555    0.160709   -0.200715      0.553012   -0.155033    0.185392   -0.275788    -0.042152   -0.408988   -0.189178     0.0992712  -0.121369    0.252353    0.50984     -0.597616      0.175047    -0.095883    0.123055     0.202868    -0.167669     0.413481    -0.335768    -0.117426     0.453735     0.010864    -0.394057
  0.765058    0.454971   -0.0741066    -0.0630293   0.245887    0.228038   -0.0216225    0.0892807  -0.294577   -0.052057    -0.016347    0.262646   -0.217247    0.310418    -0.306839     -0.0637667   -0.219298    0.273791     0.277563    -0.49305      0.680198    -0.58685     -0.209522    -0.105263    -0.517278    -0.198307
 -0.0377231   0.0110372   0.00991722   -0.247405    0.146626    0.0125904   0.06314     -0.11746     0.0412294  -0.312274    -0.346006   -0.0942521  -0.158944   -0.020691    -0.153766     -0.144145    -0.0996129   0.0945594    0.466785     0.0441948    0.0971313   -0.320431     0.189        0.09895      0.0928271   -0.210057
 -0.175393    0.404663    0.126534      0.257337    0.312627   -0.202288    0.00129197  -0.260288   -0.101498    0.842488    -0.0456924  -0.127217    0.23594     0.0875281   -0.028709      0.208618     0.176959    0.271516     0.409973    -0.280623     0.212014    -0.321515     0.385562     0.0382213    0.204333    -0.187085
  0.15747    -0.202754   -0.212051      0.20232    -0.225897   -0.598276   -0.12159      0.0298497   0.214546   -0.100443     0.0411165  -0.275327   -0.0835929   0.248864    -0.0183425    -0.0878848    0.0917011   0.308778    -0.878305     0.194455     0.0591397   -0.369325    -0.263898     0.172144    -0.237992    -0.103215
  0.0538694  -0.738461    0.189566     -0.174413   -0.0951548  -0.245092    0.205727     0.279648    0.565377   -0.312335     0.0662996  -0.357738   -0.228571   -0.565004     0.369295     -0.0365994    0.176864   -0.0937248   -0.192088     0.244567    -0.312771    -0.351227     0.453246     0.126856    -0.588756    -0.199628
 -0.192452    0.124643   -0.0265436     0.151668   -0.0322281  -0.0772285   0.166758     0.231947    0.0944521   0.0261882    0.21712    -0.112038   -0.0791472   0.0215989    0.0593607    -0.220565    -0.0783207  -0.0970437   -0.13445     -0.0493921   -0.00124227   0.171437     0.0440921   -0.0103398    0.109931     0.17114
  0.123775   -0.250967    0.00518614    0.129814   -0.0224886   0.0813017  -0.24465     -0.213441   -0.172058    0.00710309   0.19121    -0.0346817   0.083007    0.222962     0.223039      0.411612    -0.0321727   0.0482147   -0.209727    -0.0111101   -0.241465    -0.0114721    0.0040907   -0.0178458   -0.0750737    0.0300094
  0.162107   -0.0194257   0.18208       0.312986   -0.131067    0.352488   -0.993741     0.138302    0.194735    0.281892     0.387471   -0.0141446   0.57696    -0.585555     0.0227471     0.636782    -0.178313   -0.765989    -0.549368    -0.213834     0.155986    -0.0517727    0.0298551    0.128009    -0.241341     0.236583
  0.254298   -0.264405   -0.132618      0.0926914  -0.0631227   0.148762   -0.577603    -0.37207     0.559488   -0.0658279    0.0340692  -0.0297932   0.402364   -0.150467    -0.000755585   0.0852162    0.519842    0.899748    -0.906998     0.263389     0.00897327   0.0366567    0.0824818   -0.0628027   -0.110415     0.607113
  0.295027   -0.451873    0.254364     -0.332199   -0.0869683   0.170426   -0.187618     0.0602479   0.195969    0.064943    -0.357555    0.45562     0.305733   -0.473866    -0.238774      0.199999     0.128127   -0.35363      0.102446     0.182475     0.172504     0.352477    -0.549803     0.0938376   -0.265047    -0.0321697
  0.704843    0.481577   -0.0888935    -0.0485627   0.227227    0.153184    0.221321     0.013222   -0.0233026   0.506852    -0.06446     0.352135   -0.0302195  -0.648816    -0.0313344    -0.0569217    0.4544      0.204433     0.00124331  -0.0943896    0.0889002    0.0754472   -0.0381064   -0.498655     0.0329631    0.17807
 -0.422578   -0.170263   -0.14674       0.543089   -0.600959   -0.195315   -0.123072    -0.0857189   0.55477    -0.221126     0.431386   -0.372964   -0.344317    0.49831      0.432714     -0.133177    -0.35817    -0.391481    -0.867807     0.472222    -0.462928     0.360289    -0.164513     0.401031     0.254881     0.403416
 -0.0434667  -0.426848    0.451539      0.257425    0.890481    0.318856    0.204005     0.121691    0.522837   -0.263464     0.771416   -0.137462   -0.118759    0.31248     -0.118914     -0.196582    -0.0174859  -0.553864    -0.250808    -0.149795    -0.509529     0.0199174    0.020363     0.47341      0.370404    -0.100018
 -0.234162    0.417198   -0.125569      0.244027   -0.12567    -0.543061    0.0929705    0.313041   -0.561975    0.663801     0.844301   -0.467373   -0.345627    0.198316     0.173124     -0.168664    -0.271981   -0.298572    -0.206083    -0.386781     0.193482    -0.116339    -0.356944    -0.507376    -0.292338     0.141787
 -0.669624    0.212099    0.000334874   0.538803    0.2331     -0.964008    0.160973     0.530399    0.0575836   0.250751     0.0727709  -0.369537   -0.279562    0.17333      0.259146     -0.70932     -0.569053    0.224855     0.357373    -0.0818571    0.404372    -0.508774     0.610316    -0.0211328   -0.0514911   -0.156641
 -0.440938    0.402305   -0.359808      0.384603   -0.628085    0.290998    0.0950796   -0.130416   -0.155931   -0.160563    -0.378746    0.251579   -0.0360065   0.0383676   -0.0385784    -0.220385    -0.213077    0.252445     0.101615    -0.239826    -0.0189217    0.760534     0.528536     0.313601     0.753455     0.196764
 -0.583503   -0.262607    0.201274      0.273343   -0.559232    0.208405    0.182008     0.166604    0.286906   -0.434196    -0.786987   -0.0259764   0.182024    0.00603193  -0.00857192    0.300711    -0.159618   -0.525321    -0.0618516    0.00368462   0.421302     0.660484    -0.240651     0.0413929    0.313326     0.240722
 -0.537182   -1.03011    -0.411618      0.396334   -0.362087    0.322572    0.191776     0.0186062  -0.345559    0.460941     0.373296    0.25958     0.578228   -0.15495      0.318641      0.264438     0.282076   -0.10827     -0.535739    -0.238316    -0.212965     0.49012      0.0396422   -0.13807     -0.151028    -0.571842
 -0.273221    0.367268   -0.180689     -0.151854   -0.330123   -0.0970479   0.286063     0.223992    0.0199666  -0.022769     0.734521   -0.169195    0.133475    0.181905    -0.526567      0.160714     0.396524    0.0696808    0.0362529    0.0744234   -0.454083     0.844466    -0.179841     0.399482    -0.267303    -0.134753
  0.109029   -0.0191368  -0.151901     -0.1666     -0.0944112  -0.288455   -0.375069    -0.0552307   0.238437   -0.0842714   -0.172412    0.0487911   0.10438    -0.470622    -0.563615     -0.0419983    0.129863    0.54352      0.201044     0.401952     0.281839    -0.560235    -0.0496124    0.247288    -0.492573    -0.765667
  0.395248   -0.0479864   0.156649     -0.675365    0.28368    -0.0468786   0.421894     0.0310114   0.353745    0.173115    -0.390889    0.0493286  -0.477313   -0.859111    -0.0684123    -0.443393     0.159095   -0.135896     0.407501    -0.00648182   0.110293    -0.0686362    0.322923    -0.499605    -0.0601189    0.534609
  0.128271    0.156782    0.0988426     0.106622   -0.132159    0.199254   -0.0655539   -0.0882462  -0.200514    0.0330826   -0.0124892   0.0909061   0.164418    0.335278    -0.0307026     0.324721     0.160122    0.0501156   -0.169982    -0.0786286    0.0199857    0.144905    -0.150243     0.00822424   0.10764     -0.0975271
  0.206045   -0.379629    0.422817     -0.431926    0.364093    0.542328   -0.0593356    0.478161   -0.732681   -0.129252    -0.112547    0.192305    0.574834   -0.443392    -0.194961      0.487938     0.193871    0.0782368    0.896001    -0.319443     0.238418    -0.185159     0.314157    -0.426148    -0.627958    -0.299932
  0.130077   -0.488364    0.0381647     0.029155    0.211018   -0.235259   -0.66273     -0.524258   -0.354777   -0.191411    -0.745751   -0.0590713  -0.143228    0.234075     0.434282      0.0850766   -0.945267    0.00489297  -0.091521     0.0472532    0.149692    -0.485235    -0.0180021   -0.473163     0.304381     0.22648
  0.473798    0.381772   -0.000605507  -0.137276   -0.197734    0.11416    -0.078777     0.44537    -0.0992052  -0.269066    -0.646373    0.250231   -0.282331    0.124875     0.342664      0.0966892    0.13486    -0.193804    -0.0992989    0.681704    -0.346969    -0.00309014   0.294763    -1.17815      0.112566     0.333939
  0.759987    0.458797   -0.131339     -0.16626     0.47101     0.0738596   0.592676    -0.778984    0.0232666  -0.221292    -0.222731   -0.326551   -0.581679    0.668954     0.110596      0.130254    -0.046944    0.0990018    0.0951251   -0.181749    -0.0441089   -0.211366    -0.00953164   0.322992     0.667368     0.4871
  0.626944   -0.162449   -0.443033     -0.377024   -0.0487201   0.437265    0.104338    -0.783646    0.096338   -0.244605    -0.915139    0.0462905   0.428163    0.183769    -0.482235      0.361212     0.539588    0.0180378    0.286366    -0.0198412   -0.170713     0.0768115   -0.221597     0.497979     0.535852    -0.172146[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415475
[ Info: iteration 2, average log likelihood -1.415461
[ Info: iteration 3, average log likelihood -1.415448
[ Info: iteration 4, average log likelihood -1.415436
[ Info: iteration 5, average log likelihood -1.415424
[ Info: iteration 6, average log likelihood -1.415413
[ Info: iteration 7, average log likelihood -1.415402
[ Info: iteration 8, average log likelihood -1.415392
[ Info: iteration 9, average log likelihood -1.415382
[ Info: iteration 10, average log likelihood -1.415372
┌ Info: EM with 100000 data points 10 iterations avll -1.415372
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.321905e+05
      1       7.095726e+05      -2.226179e+05 |       32
      2       6.958962e+05      -1.367630e+04 |       32
      3       6.903999e+05      -5.496367e+03 |       32
      4       6.876713e+05      -2.728598e+03 |       32
      5       6.859612e+05      -1.710102e+03 |       32
      6       6.847778e+05      -1.183419e+03 |       32
      7       6.838709e+05      -9.069022e+02 |       32
      8       6.831337e+05      -7.371133e+02 |       32
      9       6.825074e+05      -6.263861e+02 |       32
     10       6.820074e+05      -4.999999e+02 |       32
     11       6.816195e+05      -3.878813e+02 |       32
     12       6.813018e+05      -3.176532e+02 |       32
     13       6.810633e+05      -2.385699e+02 |       32
     14       6.808684e+05      -1.948353e+02 |       32
     15       6.806857e+05      -1.827259e+02 |       32
     16       6.805270e+05      -1.587233e+02 |       32
     17       6.803677e+05      -1.592960e+02 |       32
     18       6.802132e+05      -1.544676e+02 |       32
     19       6.800701e+05      -1.430644e+02 |       32
     20       6.799441e+05      -1.260085e+02 |       32
     21       6.798258e+05      -1.183726e+02 |       32
     22       6.797278e+05      -9.797724e+01 |       32
     23       6.796258e+05      -1.019859e+02 |       32
     24       6.795383e+05      -8.749887e+01 |       32
     25       6.794520e+05      -8.633552e+01 |       32
     26       6.793744e+05      -7.753114e+01 |       32
     27       6.792914e+05      -8.301571e+01 |       32
     28       6.792084e+05      -8.297701e+01 |       32
     29       6.791325e+05      -7.598730e+01 |       32
     30       6.790641e+05      -6.838600e+01 |       32
     31       6.789987e+05      -6.533236e+01 |       32
     32       6.789299e+05      -6.883068e+01 |       32
     33       6.788699e+05      -5.998159e+01 |       32
     34       6.788106e+05      -5.934828e+01 |       32
     35       6.787487e+05      -6.188923e+01 |       32
     36       6.786864e+05      -6.228322e+01 |       32
     37       6.786227e+05      -6.365650e+01 |       32
     38       6.785657e+05      -5.706880e+01 |       32
     39       6.785058e+05      -5.989927e+01 |       32
     40       6.784465e+05      -5.927207e+01 |       32
     41       6.783953e+05      -5.122495e+01 |       32
     42       6.783472e+05      -4.804737e+01 |       32
     43       6.783035e+05      -4.376528e+01 |       32
     44       6.782601e+05      -4.333051e+01 |       32
     45       6.782154e+05      -4.472121e+01 |       32
     46       6.781725e+05      -4.288433e+01 |       32
     47       6.781299e+05      -4.258829e+01 |       32
     48       6.780908e+05      -3.916515e+01 |       32
     49       6.780485e+05      -4.231988e+01 |       32
     50       6.780016e+05      -4.686812e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 678001.591234706)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427243
[ Info: iteration 2, average log likelihood -1.422167
[ Info: iteration 3, average log likelihood -1.420808
[ Info: iteration 4, average log likelihood -1.419794
[ Info: iteration 5, average log likelihood -1.418730
[ Info: iteration 6, average log likelihood -1.417741
[ Info: iteration 7, average log likelihood -1.417043
[ Info: iteration 8, average log likelihood -1.416640
[ Info: iteration 9, average log likelihood -1.416411
[ Info: iteration 10, average log likelihood -1.416265
[ Info: iteration 11, average log likelihood -1.416160
[ Info: iteration 12, average log likelihood -1.416076
[ Info: iteration 13, average log likelihood -1.416007
[ Info: iteration 14, average log likelihood -1.415946
[ Info: iteration 15, average log likelihood -1.415893
[ Info: iteration 16, average log likelihood -1.415845
[ Info: iteration 17, average log likelihood -1.415801
[ Info: iteration 18, average log likelihood -1.415760
[ Info: iteration 19, average log likelihood -1.415722
[ Info: iteration 20, average log likelihood -1.415686
[ Info: iteration 21, average log likelihood -1.415652
[ Info: iteration 22, average log likelihood -1.415619
[ Info: iteration 23, average log likelihood -1.415588
[ Info: iteration 24, average log likelihood -1.415558
[ Info: iteration 25, average log likelihood -1.415529
[ Info: iteration 26, average log likelihood -1.415502
[ Info: iteration 27, average log likelihood -1.415476
[ Info: iteration 28, average log likelihood -1.415450
[ Info: iteration 29, average log likelihood -1.415426
[ Info: iteration 30, average log likelihood -1.415403
[ Info: iteration 31, average log likelihood -1.415381
[ Info: iteration 32, average log likelihood -1.415360
[ Info: iteration 33, average log likelihood -1.415339
[ Info: iteration 34, average log likelihood -1.415319
[ Info: iteration 35, average log likelihood -1.415300
[ Info: iteration 36, average log likelihood -1.415281
[ Info: iteration 37, average log likelihood -1.415263
[ Info: iteration 38, average log likelihood -1.415245
[ Info: iteration 39, average log likelihood -1.415228
[ Info: iteration 40, average log likelihood -1.415212
[ Info: iteration 41, average log likelihood -1.415196
[ Info: iteration 42, average log likelihood -1.415180
[ Info: iteration 43, average log likelihood -1.415165
[ Info: iteration 44, average log likelihood -1.415150
[ Info: iteration 45, average log likelihood -1.415136
[ Info: iteration 46, average log likelihood -1.415122
[ Info: iteration 47, average log likelihood -1.415109
[ Info: iteration 48, average log likelihood -1.415096
[ Info: iteration 49, average log likelihood -1.415083
[ Info: iteration 50, average log likelihood -1.415071
┌ Info: EM with 100000 data points 50 iterations avll -1.415071
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.748718   -0.202259   -0.544661    0.231055   -0.431652      0.321049    0.160722    0.162365   -0.546958    -0.142973   -0.463017     0.533684     -0.518319    -0.54159     0.375128     0.370788     0.499403     0.370301    -0.219496    -0.500981    0.17378     -0.606272    0.691631    -0.0581538    -0.316784   -0.237318
 -0.0256755  -0.138718    0.0315101   0.177462   -0.105558      0.435002   -0.151778   -0.500981    0.660932    -0.35143     0.139956    -0.120857     -0.163148     0.351703   -0.0635658    0.330709    -0.458567    -0.569365    -0.239043     0.32129    -0.759172     0.451179    0.148397     0.769244      0.212749    0.288659
  0.33932    -0.18514     0.0618911  -0.211337    0.0871544     0.111291   -0.044367   -0.166774    0.00436519  -0.20913    -0.425104     0.143237      0.170921    -0.119127   -0.106434     0.170117     0.00551746   0.0965571    0.219952     0.0821476   0.0670405   -0.0823689  -0.131286    -0.000985599  -0.0901883  -0.165872
  0.250516   -0.435218    0.259018   -0.16066     0.162867     -0.0697428   0.227008    0.285161   -0.0861897   -0.640944   -0.173188     0.304772     -0.439953     0.199116    0.666912    -0.204816    -0.819565    -0.496803    -0.0304003    0.249336   -0.402356     0.155402    0.238622    -0.567913      0.0194688   0.440974
 -0.244765   -0.955405    0.315921   -0.215224    0.163431      0.488598   -0.0256308   0.649662   -0.517057    -0.272472    0.380907    -0.189428      0.639118    -0.553533    0.0392189    0.377526     0.512682    -0.0223586    0.523889    -0.30371     0.187759    -0.0241185   0.100461    -0.193833     -0.995037   -0.485008
  0.626736    0.095678   -0.689599   -0.286225    0.148516      0.159459    0.285495   -0.726724    0.509863    -0.192237   -0.867641    -0.323839      0.0152895    0.101819   -0.505688    -0.0743072    0.605467     0.188441     0.244713    -0.122969    0.301157    -0.280975   -0.067069     0.503157      0.262113    0.0924879
  0.379308   -0.544814    0.188747   -0.0605239   0.196215     -0.0180773  -1.00515    -0.458153   -0.199551     0.0645957  -0.3926      -0.317936      0.148357    -0.230752    0.163393     0.342434    -0.8614      -0.393464    -0.283652    -0.0837105   0.437148    -0.57842    -0.175921    -0.088232     -0.142683    0.429833
 -0.151312    0.382889    0.0720117   0.303447    0.101918     -0.318885   -0.0914947  -0.387313   -0.145164     0.828345    0.190059    -0.35422       0.304589     0.173264    0.00805084   0.274021     0.359835     0.340654     0.0765377   -0.164804    0.105735    -0.274271    0.159886     0.142341      0.0821115  -0.116052
  0.682269    0.252808    0.203714   -0.498084    0.546027      0.0900621  -0.384434   -0.586961   -0.0421624    0.133478   -0.366148     0.465982      0.115136    -0.243399   -0.453527     0.00420558   0.182642     0.770116     0.38693      0.371705    0.306931    -0.498061    0.238113    -0.405216     -0.0810971  -0.100676
 -0.150048    0.135416   -0.145671    0.151914   -0.119606     -0.159914    0.162206    0.164152   -0.0491645   -0.568868    0.817735    -0.375669     -0.0356626    0.819433   -0.446304    -0.0266395    0.184804     0.194757    -0.327844    -0.0311468  -0.325124     0.0709492  -0.304271     0.651842     -0.203257   -0.515727
  0.0675955   0.240127   -0.472258    0.511361   -0.274631     -0.433519   -0.416379   -0.429414    0.143369    -0.20674     0.00897383  -0.235945     -0.301847     0.706807    0.400723    -0.135283    -0.337002     0.451581    -0.970121     0.383075    0.113164    -0.314846   -0.136172    -0.0679035     0.395208    0.2603
 -0.674001    0.345564   -0.0514916   0.0527979  -0.216315     -0.130239    0.200991    0.104068   -0.0349945   -0.348518   -0.473582    -0.324241     -0.327092     0.156743   -0.27276     -0.475393    -0.346078     0.0476288    0.641477    -0.21368     0.411239    -0.167542    0.34724      0.32765       0.339387   -0.214843
  0.371835    0.251427    0.267969   -0.720854   -0.206552      0.285419    0.139041    0.101286    0.0733913    0.0709152  -0.597139     0.258366     -0.2008      -0.302957   -0.070449     0.279523     0.498894    -0.530079     0.351616     0.395976   -0.312619     0.45158     0.0279785   -0.556501      0.253079    0.132235
 -0.400512   -0.240769   -0.26204    -0.0416593  -0.248955      0.249088   -0.0507103  -0.134161    0.258413     0.200424    0.00676479   0.16368       0.214495    -0.522163   -0.713101     0.198504     0.3116       0.0284041    0.130748    -0.0619486   0.294889     0.43531    -0.239987     0.905225     -0.122476   -0.340915
  0.0377961  -0.393926    0.148226    0.0624713   1.1251       -0.0645525   0.890205    0.0597346   0.195668     0.528225   -0.529893    -0.0462509    -0.645584    -0.0667075   0.332339    -0.184434    -0.05642     -0.312054     1.14954     -0.278759   -0.135076    -0.320678    0.736754     0.0796551     0.0853643   0.269697
 -0.0432195  -0.409261    0.0722755  -0.1294      0.556791      0.160373    0.379707   -0.308951   -0.0941952   -0.0127296   0.397974    -0.500055      0.00721929   0.247071    0.421052    -0.0929167    0.169528    -0.656589    -0.545109    -1.01189     0.0723613    0.179457   -0.0346057    0.16243       0.80341     0.269956
  0.674046    0.230335    0.471085    0.189735    0.660107      0.269279    0.329553    0.763436    0.521436     0.346725    0.0536938   -0.00950198    0.139216    -0.286618   -0.227087    -0.276059     0.334666    -0.151373     0.106077    -0.272747    0.270879    -0.505254   -0.246621     0.352011     -0.33817    -0.190302
  0.128213    0.0839891   0.138056   -0.0904975  -0.0555778     0.134899    0.0258156  -0.0672585  -0.0455779   -0.110205   -0.151668    -0.000713038   0.107299     0.0465712  -0.110518     0.13241      0.126396     0.0807616    0.0835424    0.0332907  -0.00164955   0.0881036   0.0131509   -0.0247874     0.0308096  -0.0127368
  0.573527   -0.673319   -0.0484602  -0.0837699   0.230153     -0.109045   -0.313715   -0.334393   -0.229859     0.524175    0.545114     0.309233      0.270775    -0.186915    0.294006     0.184005     0.332114     0.0978611   -0.741888     0.134897   -0.577751     0.0512097  -0.190904    -0.430539     -0.0880835   0.000219969
  0.397424    0.838932   -0.381728    0.238493   -0.0562391    -0.0367892   0.492224    0.136892   -0.167902     0.287171    0.172439     0.289017     -0.373065     0.294954    0.0556611   -0.276283     0.151782     0.164972    -0.044301    -0.20145    -0.25147      0.683698   -0.0868642   -0.289009      0.558139    0.375054
 -1.11219    -0.53705     0.274103    0.491622   -0.427442     -0.251148    0.0821724   0.372697    0.568415    -0.23983     0.0345091   -0.541733      0.226189     0.129166    0.274438    -0.214155    -0.286454    -0.534143    -0.284533     0.371299   -0.0547763    0.426438   -0.152909     0.239016      0.206329    0.179341
  0.256617   -0.0900168  -0.0340709  -0.571772    0.36608      -0.607831    0.497854   -0.268205   -0.539217    -0.0362133  -0.0512698   -0.172863     -0.454868     0.236429    0.238118    -0.438661     0.138795     0.425546     0.281437     0.102296   -0.222043    -0.326125    0.00098888  -0.407804      0.0523296  -0.374592
 -0.673211   -0.277966   -0.249863    0.29056    -0.49808       0.0911771   0.170585   -0.227282   -0.910375     0.0583214   0.139312     0.192372      0.233393     0.359101    0.234703     0.421459    -0.227261     0.00267663   0.00423339  -0.0997095  -0.594146     0.568237    0.188417    -0.190829      0.550486   -0.4067
 -0.131572    0.170956    0.0631458   0.582036   -0.290833     -0.373252   -0.555749    0.867738   -0.0550376   -0.155425   -0.339998     0.425943      0.26625     -0.0570815  -0.229067    -0.0251582   -0.302913     0.280831     0.453289     0.433581    0.294199    -0.440521    0.283122    -0.246452     -0.373713   -0.61158
  0.0816009  -0.719728    0.0256601  -0.146308   -0.242686     -0.344971    0.0488463   0.164248    0.79774     -0.351555    0.0180568   -0.313781     -0.278443    -0.463419    0.197983    -0.197083     0.297791     0.0932773   -0.577985     0.444827   -0.289801    -0.193927    0.22591      0.122866     -0.371785    0.0523148
 -0.254396    0.512507   -0.127833   -0.315856    0.157925     -0.275552    0.330427    0.351062    0.0672298    0.215713    0.338725    -0.469381     -0.742037    -0.334584   -0.386368    -0.194798    -0.256879    -0.552282    -0.0676634   -0.233725    0.274201    -0.248647    0.320981    -0.00305791    0.0160811   0.552747
 -0.0716273   0.225864    0.027252    0.379918   -0.53045       0.375739   -0.577286    0.481792    0.134103     0.23817     0.582523     0.150289      0.749796    -0.336005   -0.0610958    0.604321     0.339143    -0.159689    -0.705535     0.0933172  -0.0257168    0.38167    -0.103303    -0.157177     -0.473515    0.371752
  0.102119   -0.143078   -0.121085    0.189498    0.01372      -0.201453   -0.111466   -0.0159316  -0.0781428   -0.108991    0.271742    -0.183042     -0.0610943    0.289073    0.01416      0.0501405   -0.0669384    0.281541    -0.41406     -0.0854278   0.118665    -0.263076   -0.106042     0.0611991    -0.376094    0.0382564
  0.307854    0.534323   -0.0898552  -0.312771    0.339259      0.366096   -0.0613821  -0.140507   -0.735123     0.174985    0.149751     0.224021     -0.126911     0.396139   -0.361602     0.262868    -0.592426    -0.101443     0.650098    -0.783993    0.585932    -0.462508   -0.0905858   -0.345066     -0.219788   -0.24346
 -0.15093     0.0193858   0.0411688   0.0267304  -0.000204524   0.0134106   0.0708402   0.0660154   0.0227857    0.0961912   0.179754    -0.0728502    -0.06762     -0.0117747   0.12375     -0.0152668   -0.0263863   -0.18332      0.0536086   -0.0238267  -0.203169     0.109807    0.152842    -0.0304653     0.151887    0.0331467
 -0.451492    0.209882   -0.152658    0.297094   -0.0265509    -0.830116    0.142893    0.400707   -0.171392     0.793433    0.567237    -0.417121     -0.470267    -0.0911874   0.241237    -0.417213    -0.39066     -0.208159    -0.0414485   -0.273582    0.19658     -0.232795    0.0866066   -0.290224     -0.499418    0.0553425
 -0.228325   -0.0168578  -0.0513094   0.702747   -0.147962      0.370254    0.0631217  -0.0595206  -0.0414867   -0.173556   -0.548149     0.345447      0.180591     0.0721382   0.0264793    0.217974    -0.0230087   -0.145026    -0.181148    -0.348143    0.568304     0.434659   -0.0824837   -0.0616644     0.589864    0.406912[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415060
[ Info: iteration 2, average log likelihood -1.415049
[ Info: iteration 3, average log likelihood -1.415038
[ Info: iteration 4, average log likelihood -1.415027
[ Info: iteration 5, average log likelihood -1.415018
[ Info: iteration 6, average log likelihood -1.415008
[ Info: iteration 7, average log likelihood -1.414999
[ Info: iteration 8, average log likelihood -1.414990
[ Info: iteration 9, average log likelihood -1.414982
[ Info: iteration 10, average log likelihood -1.414974
┌ Info: EM with 100000 data points 10 iterations avll -1.414974
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
