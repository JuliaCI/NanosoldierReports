Julia Version 1.5.0-DEV.199
Commit cc47f87314 (2020-01-29 16:52 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenBLAS_jll ─────── v0.3.7+5
 Installed CMake ────────────── v1.1.2
 Installed BinDeps ──────────── v1.0.0
 Installed HDF5 ─────────────── v0.12.5
 Installed Parameters ───────── v0.12.0
 Installed StaticArrays ─────── v0.12.1
 Installed StatsBase ────────── v0.32.0
 Installed OrderedCollections ─ v1.1.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed LegacyStrings ────── v0.4.1
 Installed QuadGK ───────────── v2.3.1
 Installed Blosc ────────────── v0.5.1
 Installed PDMats ───────────── v0.9.11
 Installed JLD ──────────────── v0.9.2
 Installed BinaryProvider ───── v0.5.8
 Installed DataAPI ──────────── v1.1.0
 Installed Distances ────────── v0.8.2
 Installed URIParser ────────── v0.4.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed SortingAlgorithms ── v0.3.1
 Installed Missings ─────────── v0.4.3
 Installed NearestNeighbors ─── v0.4.4
 Installed Clustering ───────── v0.13.3
 Installed CMakeWrapper ─────── v0.2.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Rmath ────────────── v0.6.0
 Installed StatsFuns ────────── v0.9.3
 Installed SpecialFunctions ─── v0.9.0
 Installed Distributions ────── v0.22.3
 Installed Compat ───────────── v2.2.0
 Installed FileIO ───────────── v1.2.1
 Installed FillArrays ───────── v0.8.4
 Installed Arpack ───────────── v0.4.0
 Installed DataStructures ───── v0.17.9
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_lvQR9U/Project.toml`
 [no changes]
  Updating `/tmp/jl_lvQR9U/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_5VqbNP/Project.toml`
 [no changes]
  Updating `/tmp/jl_5VqbNP/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_jbIYDL/Project.toml`
 [no changes]
  Updating `/tmp/jl_jbIYDL/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_PMXuA2/Project.toml`
 [no changes]
  Updating `/tmp/jl_PMXuA2/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_xlXb4E/Project.toml`
 [no changes]
  Updating `/tmp/jl_xlXb4E/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_xlXb4E/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.2
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.5132508131128878e6, [82317.49149193369, 17682.50850806631], [10093.367549249391 -6565.790714847768 11601.86588726536; -10844.228770255784 6277.232727065394 -11506.702624606552], [[84976.77634704518 -5065.0282073018925 -2102.655644234067; -5065.0282073018925 79025.02976817919 4873.020862447194; -2102.655644234067 4873.020862447194 78766.57808978026], [14158.386248313074 5214.300490085534 2281.9359317221333; 5214.300490085534 21402.95406775433 -4844.770084434445; 2281.9359317221333 -4844.770084434446 21040.7338767245]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.507283e+03
      1       1.022628e+03      -4.846553e+02 |        7
      2       9.401638e+02      -8.246389e+01 |        4
      3       9.318636e+02      -8.300146e+00 |        4
      4       9.048241e+02      -2.703948e+01 |        0
      5       9.048241e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 904.8241478255059)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.073336
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.705866
[ Info: iteration 2, lowerbound -3.544040
[ Info: iteration 3, lowerbound -3.385441
[ Info: iteration 4, lowerbound -3.221875
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.061126
[ Info: iteration 6, lowerbound -2.924566
[ Info: iteration 7, lowerbound -2.843651
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.807172
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.783250
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.767461
[ Info: iteration 11, lowerbound -2.750686
[ Info: iteration 12, lowerbound -2.729999
[ Info: iteration 13, lowerbound -2.698398
[ Info: iteration 14, lowerbound -2.652858
[ Info: iteration 15, lowerbound -2.593171
[ Info: iteration 16, lowerbound -2.524943
[ Info: iteration 17, lowerbound -2.458926
[ Info: iteration 18, lowerbound -2.404162
[ Info: iteration 19, lowerbound -2.362592
[ Info: iteration 20, lowerbound -2.332182
[ Info: iteration 21, lowerbound -2.312996
[ Info: iteration 22, lowerbound -2.307471
[ Info: dropping number of Gaussions to 2
[ Info: iteration 23, lowerbound -2.302927
[ Info: iteration 24, lowerbound -2.299261
[ Info: iteration 25, lowerbound -2.299256
[ Info: iteration 26, lowerbound -2.299255
[ Info: iteration 27, lowerbound -2.299254
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan 30 09:47:24 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan 30 09:47:32 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Thu Jan 30 09:47:34 2020: EM with 272 data points 0 iterations avll -2.073336
5.8 data points per parameter
, Thu Jan 30 09:47:36 2020: GMM converted to Variational GMM
, Thu Jan 30 09:47:45 2020: iteration 1, lowerbound -3.705866
, Thu Jan 30 09:47:45 2020: iteration 2, lowerbound -3.544040
, Thu Jan 30 09:47:45 2020: iteration 3, lowerbound -3.385441
, Thu Jan 30 09:47:45 2020: iteration 4, lowerbound -3.221875
, Thu Jan 30 09:47:45 2020: dropping number of Gaussions to 7
, Thu Jan 30 09:47:45 2020: iteration 5, lowerbound -3.061126
, Thu Jan 30 09:47:45 2020: iteration 6, lowerbound -2.924566
, Thu Jan 30 09:47:45 2020: iteration 7, lowerbound -2.843651
, Thu Jan 30 09:47:45 2020: dropping number of Gaussions to 5
, Thu Jan 30 09:47:45 2020: iteration 8, lowerbound -2.807172
, Thu Jan 30 09:47:45 2020: dropping number of Gaussions to 4
, Thu Jan 30 09:47:45 2020: iteration 9, lowerbound -2.783250
, Thu Jan 30 09:47:45 2020: dropping number of Gaussions to 3
, Thu Jan 30 09:47:45 2020: iteration 10, lowerbound -2.767461
, Thu Jan 30 09:47:45 2020: iteration 11, lowerbound -2.750686
, Thu Jan 30 09:47:45 2020: iteration 12, lowerbound -2.729999
, Thu Jan 30 09:47:45 2020: iteration 13, lowerbound -2.698398
, Thu Jan 30 09:47:45 2020: iteration 14, lowerbound -2.652858
, Thu Jan 30 09:47:45 2020: iteration 15, lowerbound -2.593171
, Thu Jan 30 09:47:45 2020: iteration 16, lowerbound -2.524943
, Thu Jan 30 09:47:45 2020: iteration 17, lowerbound -2.458926
, Thu Jan 30 09:47:45 2020: iteration 18, lowerbound -2.404162
, Thu Jan 30 09:47:45 2020: iteration 19, lowerbound -2.362592
, Thu Jan 30 09:47:45 2020: iteration 20, lowerbound -2.332182
, Thu Jan 30 09:47:45 2020: iteration 21, lowerbound -2.312996
, Thu Jan 30 09:47:45 2020: iteration 22, lowerbound -2.307471
, Thu Jan 30 09:47:45 2020: dropping number of Gaussions to 2
, Thu Jan 30 09:47:45 2020: iteration 23, lowerbound -2.302927
, Thu Jan 30 09:47:45 2020: iteration 24, lowerbound -2.299261
, Thu Jan 30 09:47:45 2020: iteration 25, lowerbound -2.299256
, Thu Jan 30 09:47:45 2020: iteration 26, lowerbound -2.299255
, Thu Jan 30 09:47:45 2020: iteration 27, lowerbound -2.299254
, Thu Jan 30 09:47:45 2020: iteration 28, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 29, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 30, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 31, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 32, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 33, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 34, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 35, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 36, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 37, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 38, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 39, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 40, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 41, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 42, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 43, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 44, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 45, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 46, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 47, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 48, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 49, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: iteration 50, lowerbound -2.299253
, Thu Jan 30 09:47:45 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777397939, 178.04509222602056]
β = [95.95490777397939, 178.04509222602056]
m = [2.0002292577753127 53.851987172461; 4.250300733269857 79.28686694436105]
ν = [97.95490777397939, 180.04509222602056]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611949316 -0.008953123827347339; 0.0 0.012748664777409742], [0.18404155547483506 -0.007644049042327818; 0.0 0.008581705166332497]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9947073973149051
avll from llpg:  -0.9947073973149041
avll direct:     -0.9947073973149041
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0261570262865696
avll from llpg:  -1.0261570262865694
avll direct:     -1.0261570262865694
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.022672    -0.0429085   -0.0641471  -0.167076    -0.1989       0.152932    -0.0540374   -0.12588     0.124697     0.0456027     0.0356437    0.121321    -0.0708325    0.0172006    0.0671179    0.13274       0.080953   -0.14604     -0.0186929   -0.175529    0.0656277    -0.0519843    0.117572    -0.000462893  -0.0949272   -0.000827922
  0.0391962   -0.0705833   -0.0444619  -0.110911     0.0892222   -0.129347     0.0419741   -0.0869869   0.136071     0.0302299    -0.109847     0.259302    -0.0143477    0.00721813   0.0240565   -0.140146      0.0542769  -0.0877897   -0.0627834    0.0631981  -0.0888687     0.0654458    0.181553     0.0713605    -0.0660167    0.0429771
  0.213577    -0.147142    -0.0785127  -0.0124567    0.0321592    0.0353801    0.0548668    0.163774    0.117698    -0.224107     -0.0533346   -0.0365506   -0.122256     0.196644    -0.0526477   -0.00943031    0.0275851  -0.137524    -0.0982373   -0.0193381   0.158883      0.0321681    0.0496291    0.066408     -0.152843    -0.144273
  0.075261    -0.115999    -0.0193962   0.160909     0.079657    -0.0612107   -0.110043    -0.102449    0.0194434    0.0897214    -0.0199379   -0.118978     0.0896156    0.0467002    0.0232438    0.0855464    -0.142405    0.00987956  -0.00779833   0.0937679   0.117463     -0.0857087    0.147676    -0.123372     -0.0526459    0.0500149
 -0.0103575   -0.146132     0.0789708  -0.0977449   -0.149473    -0.0159195    0.0541585   -0.003079    0.12615     -0.0248657    -0.104371    -0.0399127   -0.00299566   0.0282884    0.0123999   -0.000112684   0.0976672  -0.0165077    0.016589    -0.140157   -0.0346154    -0.0804179   -0.0887239   -0.140691     -0.105442    -0.0263073
 -0.11161      0.17895      0.073003    0.0199503   -0.0663176    0.11152     -0.0311706   -0.0574107  -0.0628905    0.184081      0.00548445  -0.140415     0.046292     0.0380105   -0.0450406    0.00875242    0.0993109   0.0859823   -0.231219     0.0591158  -0.180187     -0.184233    -0.0953706    0.174521      0.101539     0.0664684
 -0.0145944    0.0109933    0.0312549   0.132267    -0.0104486    0.218455     0.0336124   -0.0700833   0.0391981    0.13968       0.0514606    0.0775383    0.0610799    0.0181699    0.111859     0.0489952     0.052976    0.0388364    0.199042     0.104775    0.0152637    -0.101281    -0.0994087    0.00369577   -0.198465    -0.102821
 -0.00911579   0.185027    -0.133446    0.104478     0.0397769   -0.0508099   -0.00997657  -0.0559173   0.129005    -0.123386     -0.051301    -0.0256118   -0.0101908   -0.0320731    0.0420139   -0.203505      0.0131979   0.0818879   -0.00610971   0.134443    0.0305284     0.0323061    0.0364271    0.088205     -0.15106     -0.146486
  0.110328    -0.0223281   -0.0107662   0.346314    -0.03634     -0.00156289   0.0619398    0.133311    0.307708     0.0106076     0.125736     0.12378      0.144558    -0.0440628    0.043299     0.0225506    -0.036703   -0.0295499    0.102888    -0.0705797   0.0293712     0.101664    -0.0755993   -0.0433404     0.0761498    0.0545095
 -0.00298173   0.0710675   -0.0338536   0.0913862   -0.00660649   0.103338    -0.0741118    0.175122   -0.115086    -0.00904735    0.188482     0.0949003   -0.0754013    0.026071     0.163887     0.148093     -0.0198441  -0.0599077   -0.0250772    0.114009    0.0109389    -0.0719007    0.00348612   0.137823      0.00415067   0.0409319
  0.17608     -0.137363     0.0862289   0.105388    -0.0618694   -0.0939995    0.0548401    0.0796969   0.024993     0.0520195    -0.179548    -0.0145519   -0.0181769    0.118583     0.0873907   -0.0309689     0.155596   -0.159302    -0.101772    -0.134999   -0.0587411     0.00619257  -0.0482015   -0.0218307    -0.0800748   -0.0774988
  0.00065416   0.0796033    0.0301916   0.0365784   -0.181619    -0.116655     0.0413441    0.0933543   0.0619222    0.20976       0.0139816    0.013222    -0.0160535    0.0297771    0.0531202    0.0327795     0.0100501  -0.141705    -0.177044    -0.0865314  -0.114669      0.140203     0.00616338  -0.111498     -0.00342128  -0.0365602
 -0.0291146   -0.0738728    0.0614891  -0.0409311    0.099451     0.0505806    0.207489     0.0353617  -0.0643954    0.0411451     0.0436804   -0.117597    -0.045878    -0.154758    -0.0714202    0.0378508    -0.0279845   0.227002    -0.0381964   -0.0992575  -0.104145     -0.0150291   -0.124423    -0.0404252     0.234276    -0.0116686
  0.0272152    0.0934303    0.0191422  -0.00323096   0.164364     0.0343966    0.0674779    0.163195    0.0427291   -0.13137      -0.0939158   -0.0763021    0.0587766    0.0791164   -0.0851194   -0.0167633    -0.16528    -0.076031     0.011997     0.222171    0.0322261    -0.00231574  -0.0328766    0.0618885    -0.145046     0.0137942
  0.0133654   -0.101037    -0.104757   -0.0509284   -0.00388004  -0.0401172    0.258901    -0.0635589   0.0631544    0.0222214    -0.0212198    0.166014    -0.0601721   -0.0996049    0.00639834  -0.0645729     0.0454868  -0.136823     0.0325481   -0.0162189  -0.0457542     0.0601346   -0.0657467    0.070732     -0.0235848   -0.193522
  0.126579     0.0269581   -0.0595558   0.0160166    0.0465847    0.130223     0.00670997  -0.0933493   0.154441     0.0426445     0.151583    -0.0465812   -0.0632113    0.124329     0.105921    -0.014224      0.107037    0.00140041   0.200566    -0.0999079  -0.0679124     0.198042    -0.0555091   -0.0708624     0.0524129   -0.0489825
  0.0938978    0.0052537   -0.044138   -0.0718118   -0.105614     0.010396    -0.0489603    0.0790709  -0.0978986    0.145598     -0.0888009   -0.00692227  -0.0726019    0.131167    -0.0271965    0.0736118    -0.0237055   0.199709    -0.0157316   -0.0468021  -0.017398     -0.141033     0.0808233    0.00370111    0.00368344   0.0398758
  0.051512    -0.0282579   -0.0198754  -0.0807337   -0.0454353    0.175355    -0.0700515   -0.0767423   0.0617696   -0.00201346   -0.13588     -0.00826155   0.0109964   -0.047304    -0.0438098    0.10515       0.141909   -0.0909372    0.244757    -0.0340636  -0.0323167    -0.00404917   0.0153979    0.0207959     0.0710747    0.0592751
 -0.0133083   -0.0806043   -0.105198    0.051734     0.0444603    0.123636    -0.0961368    0.10492     0.125158     0.249011      0.152733    -0.0765764   -0.102385     0.0291896   -0.16634      0.0654067     0.0382381  -0.0667756    0.119358     0.0684877   0.0757753     0.0187218   -0.0647048   -0.0436436     0.0183015    0.0999937
  0.114748    -0.204701    -0.0874318   0.309945     0.0151349   -0.131743    -0.00487552   0.0978604  -0.0356056   -0.0171499    -0.104383     0.100876    -0.230152     0.0362478    0.154467     0.265997      0.0322519   0.156161    -0.06646     -0.0290631   0.199081      0.0536337    0.0714527    0.0872366     0.0530935   -0.037147
  0.149441     0.223511    -0.0272453  -0.0665886   -0.110842    -0.101878     0.143124    -0.223493   -0.121832    -0.000274272  -0.0125958    0.165472    -0.177726     0.214081    -0.145209    -0.107923     -0.155284    0.118966     0.0415812    0.0249013   0.0721394    -0.0300832    0.147179    -0.0871893    -0.115065    -0.0343243
  0.0946948    0.0993997   -0.0550857  -0.0849524    0.0430416   -0.0473753    0.0205672   -0.0154007  -0.0502671   -0.189575     -0.0514345    0.057063     0.00639676  -0.0559548    0.0977798    0.0121254     0.152348    0.130115     0.0367974    0.205542   -0.0100501     0.00696829  -0.0442549   -0.188758     -0.0976667   -0.0605144
 -0.022626     0.0947661    0.0318769   0.0426754   -0.0936591   -0.00434444   0.0735645    0.0122232   0.00169659  -0.0396958    -0.0252492   -0.068877    -0.0164861    0.216905     0.0263147   -0.0406734     0.0198952   0.223129     0.0325333    0.0254424   0.142376      0.0862759    0.0656015    0.0919181    -0.0172427   -0.05109
  0.106518    -0.0546097   -0.0573502   0.202662    -0.0121291    0.202146     0.221974    -0.0338689   0.120065    -0.041767      0.0167033    0.0346382    0.0810628   -0.042905     0.0227004    0.0409945    -0.0983451  -0.110046    -0.130668     0.0951452   0.130937      0.0102032   -0.010858     0.322975     -0.0121731   -0.104073
 -0.204462    -0.0313722    0.10955    -0.0185787    0.0161448   -0.0496151   -0.0320084   -0.0503416  -0.0817318   -0.0192893    -0.090733     0.0241634    0.102106     0.194646    -0.0200883    0.0756356    -0.242702    0.0121534    0.0334023    0.0113638   0.0585742     0.0416819    0.0176286    0.00391784    0.0215714    0.0790842
  0.0590351   -0.091412     0.0424633  -0.0999099    0.272806     0.064409     0.110385    -0.102018    0.0448724    0.0235278     0.157204     0.207223     0.176973    -0.0779956   -0.0035144   -0.0124585     0.205803   -0.0381718    0.101252     0.305525   -0.116753     -0.17312      0.0623731   -0.00130539    0.0732157    0.162254
 -0.0800159    0.00109534   0.0752558   0.18089     -0.060407     0.0360626    0.0348149   -0.0792875   0.00308673  -0.029164      0.122954    -0.0609428    0.0587459    0.0369746   -0.0420722    0.0881868    -0.05314     0.0516607    0.165451    -0.0189224   0.0760649    -0.109017     0.0699558    0.00677169    0.0683312    0.187981
 -0.168281    -0.112733    -0.0659522   0.0168914    0.132096    -0.122871    -0.0489347   -0.153802    0.0429065   -0.0203486    -0.204089     0.00549998   0.0608311    0.141381     0.00798931  -0.0611466     0.0520875  -0.0548134   -0.157164     0.173349    0.100165     -0.107134     0.26624     -0.135446     -0.0450754    0.00287926
 -0.0715487    0.140703     0.111071    0.155205     0.247536    -0.0374481    0.0682586   -0.236333    0.172388     0.0805343     0.0828577   -0.035221     0.0945099    0.0678592    0.0218765   -0.122119      0.0198891   0.0241719    0.0732269    0.0614449  -0.00151347   -0.215642    -0.18328     -0.110865     -0.0394612   -0.05244
  0.12044     -0.096952    -0.13274    -0.150898     0.11938     -0.05153      0.11662      0.0453924  -0.00110199  -0.00811068   -0.146817     0.0666514   -0.156372     0.0390432    0.0764749   -0.1019        0.187387   -0.0092075   -0.0476184    0.104172    0.115743     -0.0027628    0.214729    -0.114262     -0.00404099   0.0533284
  0.032605    -0.00481978   0.0693944  -0.157522    -0.0572638    0.123787    -0.0423848   -0.0444303  -0.186296    -0.00427887    0.0660973   -0.177848    -0.0906677    0.0283449    0.123237    -0.119579      0.0272744  -0.0247164    0.00639985   0.0654347   0.000980086   0.0829554    0.00557191   0.0203308    -0.00368244   0.0531609
  0.00773354  -0.0150527   -0.143003   -0.0719433    0.188993    -0.00587748  -0.0610112    0.115079    0.105746     0.134088     -0.0310137    0.109561     0.00161715  -0.30168      0.109704    -0.0204748    -0.0840923  -0.0285343    0.125213    -0.133923    0.0515864    -0.178729    -0.145648     0.0984152     0.0353251   -0.156303kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.422002954103331
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422097
[ Info: iteration 2, average log likelihood -1.422015
[ Info: iteration 3, average log likelihood -1.421556
[ Info: iteration 4, average log likelihood -1.416181
[ Info: iteration 5, average log likelihood -1.399640
[ Info: iteration 6, average log likelihood -1.391488
[ Info: iteration 7, average log likelihood -1.389639
[ Info: iteration 8, average log likelihood -1.388505
[ Info: iteration 9, average log likelihood -1.387738
[ Info: iteration 10, average log likelihood -1.387209
[ Info: iteration 11, average log likelihood -1.386777
[ Info: iteration 12, average log likelihood -1.386360
[ Info: iteration 13, average log likelihood -1.385851
[ Info: iteration 14, average log likelihood -1.385136
[ Info: iteration 15, average log likelihood -1.384289
[ Info: iteration 16, average log likelihood -1.383472
[ Info: iteration 17, average log likelihood -1.382835
[ Info: iteration 18, average log likelihood -1.382350
[ Info: iteration 19, average log likelihood -1.382024
[ Info: iteration 20, average log likelihood -1.381827
[ Info: iteration 21, average log likelihood -1.381713
[ Info: iteration 22, average log likelihood -1.381637
[ Info: iteration 23, average log likelihood -1.381582
[ Info: iteration 24, average log likelihood -1.381541
[ Info: iteration 25, average log likelihood -1.381514
[ Info: iteration 26, average log likelihood -1.381499
[ Info: iteration 27, average log likelihood -1.381491
[ Info: iteration 28, average log likelihood -1.381487
[ Info: iteration 29, average log likelihood -1.381484
[ Info: iteration 30, average log likelihood -1.381483
[ Info: iteration 31, average log likelihood -1.381482
[ Info: iteration 32, average log likelihood -1.381482
[ Info: iteration 33, average log likelihood -1.381482
[ Info: iteration 34, average log likelihood -1.381481
[ Info: iteration 35, average log likelihood -1.381481
[ Info: iteration 36, average log likelihood -1.381481
[ Info: iteration 37, average log likelihood -1.381481
[ Info: iteration 38, average log likelihood -1.381481
[ Info: iteration 39, average log likelihood -1.381481
[ Info: iteration 40, average log likelihood -1.381481
[ Info: iteration 41, average log likelihood -1.381481
[ Info: iteration 42, average log likelihood -1.381481
[ Info: iteration 43, average log likelihood -1.381481
[ Info: iteration 44, average log likelihood -1.381481
[ Info: iteration 45, average log likelihood -1.381481
[ Info: iteration 46, average log likelihood -1.381481
[ Info: iteration 47, average log likelihood -1.381481
[ Info: iteration 48, average log likelihood -1.381481
[ Info: iteration 49, average log likelihood -1.381481
[ Info: iteration 50, average log likelihood -1.381481
┌ Info: EM with 100000 data points 50 iterations avll -1.381481
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4220968604294215
│     -1.4220150006932506
│      ⋮
└     -1.3814805911877988
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.381629
[ Info: iteration 2, average log likelihood -1.381481
[ Info: iteration 3, average log likelihood -1.380796
[ Info: iteration 4, average log likelihood -1.374729
[ Info: iteration 5, average log likelihood -1.360070
[ Info: iteration 6, average log likelihood -1.349996
[ Info: iteration 7, average log likelihood -1.346187
[ Info: iteration 8, average log likelihood -1.344416
[ Info: iteration 9, average log likelihood -1.343286
[ Info: iteration 10, average log likelihood -1.342447
[ Info: iteration 11, average log likelihood -1.341746
[ Info: iteration 12, average log likelihood -1.341191
[ Info: iteration 13, average log likelihood -1.340774
[ Info: iteration 14, average log likelihood -1.340459
[ Info: iteration 15, average log likelihood -1.340221
[ Info: iteration 16, average log likelihood -1.340040
[ Info: iteration 17, average log likelihood -1.339900
[ Info: iteration 18, average log likelihood -1.339794
[ Info: iteration 19, average log likelihood -1.339715
[ Info: iteration 20, average log likelihood -1.339656
[ Info: iteration 21, average log likelihood -1.339613
[ Info: iteration 22, average log likelihood -1.339581
[ Info: iteration 23, average log likelihood -1.339557
[ Info: iteration 24, average log likelihood -1.339539
[ Info: iteration 25, average log likelihood -1.339524
[ Info: iteration 26, average log likelihood -1.339512
[ Info: iteration 27, average log likelihood -1.339501
[ Info: iteration 28, average log likelihood -1.339492
[ Info: iteration 29, average log likelihood -1.339484
[ Info: iteration 30, average log likelihood -1.339477
[ Info: iteration 31, average log likelihood -1.339471
[ Info: iteration 32, average log likelihood -1.339465
[ Info: iteration 33, average log likelihood -1.339459
[ Info: iteration 34, average log likelihood -1.339454
[ Info: iteration 35, average log likelihood -1.339449
[ Info: iteration 36, average log likelihood -1.339445
[ Info: iteration 37, average log likelihood -1.339441
[ Info: iteration 38, average log likelihood -1.339437
[ Info: iteration 39, average log likelihood -1.339433
[ Info: iteration 40, average log likelihood -1.339430
[ Info: iteration 41, average log likelihood -1.339427
[ Info: iteration 42, average log likelihood -1.339424
[ Info: iteration 43, average log likelihood -1.339421
[ Info: iteration 44, average log likelihood -1.339418
[ Info: iteration 45, average log likelihood -1.339415
[ Info: iteration 46, average log likelihood -1.339412
[ Info: iteration 47, average log likelihood -1.339410
[ Info: iteration 48, average log likelihood -1.339407
[ Info: iteration 49, average log likelihood -1.339405
[ Info: iteration 50, average log likelihood -1.339403
┌ Info: EM with 100000 data points 50 iterations avll -1.339403
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.381629233793453
│     -1.3814809520607982
│      ⋮
└     -1.3394028772780224
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.339615
[ Info: iteration 2, average log likelihood -1.339376
[ Info: iteration 3, average log likelihood -1.338177
[ Info: iteration 4, average log likelihood -1.329285
[ Info: iteration 5, average log likelihood -1.311039
[ Info: iteration 6, average log likelihood -1.296684
[ Info: iteration 7, average log likelihood -1.290286
[ Info: iteration 8, average log likelihood -1.287289
[ Info: iteration 9, average log likelihood -1.285739
[ Info: iteration 10, average log likelihood -1.284656
[ Info: iteration 11, average log likelihood -1.283654
[ Info: iteration 12, average log likelihood -1.282666
[ Info: iteration 13, average log likelihood -1.281756
[ Info: iteration 14, average log likelihood -1.281060
[ Info: iteration 15, average log likelihood -1.280643
[ Info: iteration 16, average log likelihood -1.280427
[ Info: iteration 17, average log likelihood -1.280321
[ Info: iteration 18, average log likelihood -1.280269
[ Info: iteration 19, average log likelihood -1.280243
[ Info: iteration 20, average log likelihood -1.280228
[ Info: iteration 21, average log likelihood -1.280220
[ Info: iteration 22, average log likelihood -1.280215
[ Info: iteration 23, average log likelihood -1.280212
[ Info: iteration 24, average log likelihood -1.280210
[ Info: iteration 25, average log likelihood -1.280208
[ Info: iteration 26, average log likelihood -1.280207
[ Info: iteration 27, average log likelihood -1.280206
[ Info: iteration 28, average log likelihood -1.280205
[ Info: iteration 29, average log likelihood -1.280204
[ Info: iteration 30, average log likelihood -1.280204
[ Info: iteration 31, average log likelihood -1.280203
[ Info: iteration 32, average log likelihood -1.280203
[ Info: iteration 33, average log likelihood -1.280203
[ Info: iteration 34, average log likelihood -1.280202
[ Info: iteration 35, average log likelihood -1.280202
[ Info: iteration 36, average log likelihood -1.280202
[ Info: iteration 37, average log likelihood -1.280202
[ Info: iteration 38, average log likelihood -1.280202
[ Info: iteration 39, average log likelihood -1.280201
[ Info: iteration 40, average log likelihood -1.280201
[ Info: iteration 41, average log likelihood -1.280201
[ Info: iteration 42, average log likelihood -1.280201
[ Info: iteration 43, average log likelihood -1.280201
[ Info: iteration 44, average log likelihood -1.280201
[ Info: iteration 45, average log likelihood -1.280201
[ Info: iteration 46, average log likelihood -1.280201
[ Info: iteration 47, average log likelihood -1.280201
[ Info: iteration 48, average log likelihood -1.280201
[ Info: iteration 49, average log likelihood -1.280201
[ Info: iteration 50, average log likelihood -1.280201
┌ Info: EM with 100000 data points 50 iterations avll -1.280201
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3396152530948993
│     -1.3393760324676882
│      ⋮
└     -1.2802005732711033
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.280478
[ Info: iteration 2, average log likelihood -1.280186
[ Info: iteration 3, average log likelihood -1.279597
[ Info: iteration 4, average log likelihood -1.273218
[ Info: iteration 5, average log likelihood -1.244676
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.217438
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.216558
[ Info: iteration 8, average log likelihood -1.224164
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.206130
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.209818
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.217175
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.209327
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.210640
[ Info: iteration 14, average log likelihood -1.217496
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.200839
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.205109
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.203420
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.201883
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.213087
[ Info: iteration 20, average log likelihood -1.207986
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.192517
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.221055
[ Info: iteration 23, average log likelihood -1.208219
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.187176
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.190651
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.199425
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.205454
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.206967
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.205216
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.203148
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.205437
[ Info: iteration 32, average log likelihood -1.200363
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.182079
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.204994
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.194220
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.207679
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.207868
[ Info: iteration 38, average log likelihood -1.215472
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.198190
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.201808
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.205130
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.195905
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.196465
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.192861
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.192305
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.204608
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.216045
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.206278
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.206481
[ Info: iteration 50, average log likelihood -1.210545
┌ Info: EM with 100000 data points 50 iterations avll -1.210545
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.280478004567881
│     -1.2801857588622592
│      ⋮
└     -1.2105446303317537
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.188912
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.180757
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.176997
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.160370
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.135145
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     11
│     12
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.113278
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.102647
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.107149
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│     12
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.101692
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     19
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.108844
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.105239
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     11
│     12
│     13
│     14
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.106811
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.103777
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.109048
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│     12
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.102526
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.108042
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.103737
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     11
│     12
│     13
│     14
│     15
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.106725
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.103973
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.108122
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│     12
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.101237
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     19
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.108438
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.104312
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     11
│     12
│     13
│     14
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.105913
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.102919
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.108856
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│     12
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.102176
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.107745
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.103285
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     11
│     12
│     13
│     14
│     15
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.106709
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.104008
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.108165
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│     12
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.101094
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     19
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.108460
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.104385
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     11
│     12
│     13
│     14
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.105965
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.102877
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.108864
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│     12
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.102203
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.107765
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.103268
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     11
│     12
│     13
│     14
│     15
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.106706
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.104014
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.108166
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│     12
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.101084
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     19
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.108455
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.104382
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     11
│     12
│     13
│     14
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.105961
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     15
│     16
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.102869
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.108858
┌ Info: EM with 100000 data points 50 iterations avll -1.108858
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1889122542508093
│     -1.1807571024823103
│      ⋮
└     -1.108857633222672
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.422002954103331
│     -1.4220968604294215
│     -1.4220150006932506
│     -1.4215559748875086
│      ⋮
│     -1.1059608307031712
│     -1.1028691801129449
└     -1.108857633222672
32×26 Array{Float64,2}:
 -0.203286    -0.0275099    0.101565     -0.020847      0.0529287    -0.0608929    -0.0348966   -0.0616748  -0.0651798    -0.0154415    -0.119083     0.0168511    0.106846     0.172979    -0.0144124     0.0484813   -0.215151    -0.00221503   0.0236106    0.0127563    0.0503013    0.0408607    0.00962069   0.00513222    0.0123527    0.0956579
 -0.0210416   -0.091702    -0.098652      0.0655783     0.00383738    0.114061     -0.150305     0.0819281   0.0968241     0.22644       0.145248    -0.0771091   -0.097677     0.0453      -0.154858      0.0491724    0.0073708   -0.0439405    0.0886449    0.0455137    0.080127     0.018541    -0.0758814   -0.0447415     0.00647722   0.0845466
  0.0996378   -0.00951902  -0.0460249    -0.070415     -0.0695917     0.00650919   -0.0488606    0.10049    -0.1036        0.141068     -0.0856615   -0.0186484   -0.0739165    0.128861    -0.0222602     0.0948123   -0.0661452    0.202807    -0.0238288   -0.0388385   -0.0256973   -0.146202     0.0945493    0.0308299     0.00877244   0.0355997
  0.0408426    0.0584702    0.0174835    -0.00193295    0.159552      0.0409938     0.0951152    0.164535    0.0933024    -0.143106     -0.0950151   -0.0796082    0.0581792    0.0768806   -0.0863174    -0.0268906   -0.171569    -0.0738176    0.0023186    0.191878     0.0020702   -0.00314803  -0.0603102    0.0438987    -0.146538    -6.08428e-5
  0.00746677   0.0189818    0.0935958     0.152263      0.245002     -0.0858919     0.0790473   -0.0821964   0.192368     -0.245856     -0.128584    -0.0465147    0.164113     0.0740784    0.0105178    -0.116508    -0.92488      0.0148018    0.0598177    0.0700237    0.281838    -0.197432    -0.302112     0.0642443    -0.0380126   -0.0530524
 -0.153459     0.204623     0.138405      0.157324      0.249316     -0.115183      0.0796356   -0.336724    0.158685      0.24103       0.209053    -0.0369612    0.0668376    0.0744987    0.0315365    -0.120451     0.522168     0.0154798    0.057041     0.0697287   -0.156087    -0.221853    -0.122186    -0.198881     -0.0375383   -0.0504013
  0.185098    -0.0969554   -0.124784     -0.380414      0.121842      0.124514      0.149873    -0.0220674   0.000111244  -0.0336946    -0.163395     0.0745926   -0.0917339    0.102095     0.0542117    -0.0435858   -0.121048     0.00136636  -0.0138215    0.0181139    0.066623     0.0364997    0.158914    -0.0957365    -0.0244533    0.0580939
  0.0395527   -0.0887144   -0.162842      0.0743157     0.0991351    -0.183541      0.0561726    0.0635639  -0.00707178    0.057763     -0.14689      0.0598653   -0.224945    -0.00590778   0.0851975    -0.0778657    0.450796    -0.0235172   -0.0705056    0.156397     0.184786    -0.00238722   0.266095    -0.111293     -0.0140847    0.0441345
  0.0942508   -0.018916     0.0121907    -0.104765     -0.822863      0.129049      0.119789    -0.0020481   0.00241514   -0.00185856   -0.137808     0.0553724   -0.11597     -0.0426111   -0.00227008    0.107443     0.172909    -0.1049       0.24583     -0.0314258   -0.0082498    0.0352945    0.0177055    0.0276197     0.10989      0.00848516
 -0.0197422   -0.0311939   -0.0776348    -0.0719554     0.760133      0.186283     -0.185841    -0.11231     0.0788504    -0.00970729   -0.16537     -0.0434537    0.107541    -0.0467729   -0.105203      0.111498     0.116737    -0.0600638    0.220388    -0.0294927   -0.0347998   -0.0707818    0.0314887    0.0188503     0.00620618   0.149073
  0.0532258   -0.091286    -0.0134046     0.17152       0.0640218    -0.00371429   -0.187514    -0.0581531   0.0186981     0.0887244    -0.0296617   -0.115757     0.0737086    0.0634954    0.0236787     0.066472    -0.141463     0.00986432   0.0111752    0.565988     0.119457    -0.0866775    0.150712    -0.125663     -0.0528329    0.0488127
  0.0120876   -0.0936979   -0.0302304     0.175036      0.0516991    -0.125338     -0.0647269   -0.108606    0.0025331     0.0799444    -0.0230323   -0.178133     0.124146     0.0526644    0.0702892     0.101715    -0.14476      0.00868382  -0.0126581   -0.708594     0.116675    -0.12241      0.144058    -0.111006     -0.0474961    0.048112
  0.319647     0.0057666    0.0605884    -0.183394     -0.0880248     0.183607     -0.0422862   -0.0444938  -0.189353     -0.202766     -0.0339892   -0.779608     0.0514009    0.0368347    0.0746681     0.0789449   -0.0877058   -0.0604532    0.00154188   0.0654366    0.00369517   0.106704     0.0491792    0.0206238     0.0256034   -0.0212584
 -0.208123     0.00293869   0.0717151    -0.140601     -0.0386957     0.0621794    -0.0415206   -0.0450129  -0.200311      0.125896      0.197061     0.111967    -0.179131     0.0251244    0.12042      -0.223476     0.0532224   -0.0393024    0.00542926   0.0649715   -0.010479     0.0712833   -0.00289125   0.021161     -0.0176846    0.0991361
  0.162056    -0.113189     0.000375887  -0.135244      0.178964      0.148476      0.0848259   -0.0954082   0.0889665     0.0322268    -0.339027     0.326237     0.17694     -0.0756184   -0.0165352    -0.0113375    0.00458305  -0.234033     0.137718     0.349683    -0.118341    -0.227463     0.0618917   -0.000615604   0.0512756    0.161941
 -0.0338011   -0.0942401    0.0493573    -0.0574944     0.377041     -0.0388947     0.163301    -0.111921   -0.00627685   -0.00368023    0.658324     0.0956706    0.173631    -0.0840142    0.14209      -0.010985     0.356443     0.0290637    0.109115     0.220519    -0.110595    -0.144167     0.0619424    0.000769025   0.0918829    0.163025
 -0.0655411   -0.0784587    0.0043405    -0.012694      0.000958249   0.0396943     0.0147051   -0.0771921   0.0713885     0.0511819    -0.0731263    0.0220943    0.0458996    0.0612726    0.059048     -0.0048934    0.0545166   -0.0247716    0.0151356    0.0352206    0.0419345   -0.0948472    0.0270616   -0.0855597    -0.1072      -0.0595465
 -0.00553634   0.0301092   -0.0417066     0.0393032     0.0218072     0.0371088    -0.0230858    0.0950181  -0.00293881    0.0322159     0.0512486    0.0483437   -0.0355757   -0.0176566    0.0977659     0.0306744   -0.0150063    0.0403431    0.0609074    0.0322584    0.0657765   -0.0237228   -0.0218227    0.092007     -0.00764986  -0.0509651
 -0.107646     0.181947     0.0872308    -0.000277909  -0.0647748     0.086021     -0.0214076   -0.020701   -0.0599639     0.183202     -0.00155517  -0.14707      0.0492105    0.0579453   -0.042323      0.0153661    0.099282     0.0925369   -0.29334      0.0627038   -0.176629    -0.127234    -0.0957466    0.179312      0.0869076    0.0688283
  0.0236315   -0.0489415    0.0301745     0.150017      0.0468275     0.0413353     0.153042     0.0824806   0.106647      0.0243395     0.0770635   -0.0258589    0.0358494   -0.120965    -0.0159146     0.0367341   -0.0319063    0.105508     0.0284132   -0.0559164   -0.0527455    0.00370787  -0.105309    -0.0267533     0.146523     0.0154085
  0.0851566   -0.126214    -0.0454063     0.162199      0.00396015   -0.0131903     0.0242247    0.0576168   0.0429062    -0.0972652    -0.00888879   0.0118312   -0.0674027    0.0909555   -0.00521924    0.0999467   -0.0161532    0.0177313   -0.00340256  -0.00414251   0.145692    -0.0123178    0.0565442    0.0547703    -0.0224169    0.0049523
  0.168584    -0.136335     0.0811835     0.130105     -0.056452     -0.0907234     0.0450997    0.0696427   0.00163174    0.0448705    -0.12246     -0.0120269   -0.032911     0.154951     0.0888406    -0.0103391    0.149283    -0.106095    -0.0861965   -0.0979084   -0.0209387    0.0180056   -0.0268213    0.000582003  -0.0499329   -0.0688457
  0.0252158   -0.107168    -0.132587     -0.0234786    -0.00173045   -0.0730378     0.250667    -0.0632082   0.0534009     0.0193735    -0.0438546    0.149168    -0.0636889   -0.0714314    0.0256082    -0.0313092    0.0279587   -0.102758     0.0291837   -0.0192642   -0.00602847   0.0272884   -0.067093     0.0662412    -0.00734288  -0.194654
  0.140666     0.0249937   -0.0462401    -0.00320998    0.0468413     0.137385      0.014483    -0.0761003   0.155868      0.0430702     0.147922    -0.0169024   -0.0861607    0.107439     0.0887619    -0.0144956    0.101933     0.00207426   0.197371    -0.105135    -0.0609579    0.223173    -0.0555658   -0.0704784     0.0634138   -0.073433
  0.0999011    0.224791    -1.04644      -0.0566703    -0.111275     -0.102645      0.146422    -0.231791   -0.0880012    -0.000743741  -0.0681961    0.173696    -0.214424     0.21238     -0.139076     -0.0369712   -0.183596     0.124854     0.101532     0.0287942    0.109949     0.0656535    0.138244    -0.124859     -0.147194    -0.0633596
  0.246496     0.222664     0.871563     -0.0704759    -0.138873     -0.10241       0.097165    -0.214535   -0.153032      0.000423443   0.00456254   0.150137    -0.166058     0.212031    -0.15469      -0.125536    -0.171553     0.211268    -0.0127546    0.0243986    0.0547864   -0.0375729    0.134268    -0.0989456    -0.123744    -0.0312908
  0.131324     0.088871     0.0469817    -0.0901354     0.0424135    -0.000769646   0.0863721   -0.0139063  -0.0308209    -0.183313     -0.112471     0.00951642   0.121473    -0.0338078    0.162046      0.0105827    0.182502     0.252763    -0.494769     0.20269     -0.0111361    0.0626039   -0.0713471   -0.161618     -0.117592    -0.134912
  0.0775061    0.0985892   -0.219977     -0.0719317     0.0421398    -0.0689498    -0.0118603   -0.014227   -0.0806273    -0.156359     -0.0286323    0.16887     -0.169317    -0.0676956   -0.000301512  -0.00609696   0.122425    -0.0968013    0.715556     0.205081    -0.0117101   -0.109973    -0.0283095   -0.210516     -0.10836      0.052203
  0.0346973   -0.0664271   -0.0495822    -0.0962575     0.0841358    -0.126988      0.0433824   -0.0852234   0.135153      0.0379652    -0.104761     0.259025    -0.0190849    0.0245314    0.0363058    -0.120873     0.0524501   -0.0826262   -0.0504112    0.0693104   -0.0755797    0.0764899    0.184703     0.0732078    -0.138898     0.0547168
  0.00615104   0.162743    -0.132301      0.114124      0.0290081    -0.0519395    -0.00651933  -0.0379239   0.122138     -0.112282     -0.0163947   -0.0167138   -0.00995744  -0.029449     0.0563966    -0.199621     0.0138067    0.0916852    0.00713666   0.144735     0.0619788    0.0231083    0.0426636    0.0824436    -0.184666    -0.137313
  0.0285024   -0.0412802   -0.0791565    -0.158363     -0.207488      0.138197     -0.0896899   -0.123803    0.120482      0.0315831     0.0272574    0.100928    -0.0641545    0.0171891    0.0482042     0.130792     0.0777905   -0.118353    -0.0207416   -0.154719     0.0694967   -0.0562049    0.0963344   -0.00958356   -0.096973     0.0170361
  0.0292921    0.0159391   -0.00272973    0.137159     -0.133872      0.00139285    0.100532     0.032918    0.105442      0.0934376     0.00645718   0.0123349    0.0176554    0.00825398   0.0345626     0.0261135   -0.0262648   -0.130391    -0.155691    -0.0162677    0.0115142    0.105366    -0.00683989   0.0711399    -0.00235638  -0.0624778[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│     12
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.102198
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.091572
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│     12
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.094376
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.087644
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│     12
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.102114
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.091214
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│     12
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.094335
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.087616
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│     12
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.102111
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│     11
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.091207
┌ Info: EM with 100000 data points 10 iterations avll -1.091207
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.220343e+05
      1       6.981309e+05      -2.239033e+05 |       32
      2       6.689570e+05      -2.917395e+04 |       32
      3       6.504893e+05      -1.846770e+04 |       32
      4       6.382591e+05      -1.223022e+04 |       32
      5       6.308074e+05      -7.451616e+03 |       32
      6       6.260914e+05      -4.716032e+03 |       32
      7       6.234418e+05      -2.649604e+03 |       32
      8       6.221612e+05      -1.280646e+03 |       32
      9       6.216014e+05      -5.597165e+02 |       32
     10       6.212176e+05      -3.838037e+02 |       32
     11       6.208390e+05      -3.786034e+02 |       32
     12       6.204033e+05      -4.357736e+02 |       32
     13       6.199610e+05      -4.422413e+02 |       32
     14       6.194111e+05      -5.499666e+02 |       32
     15       6.188094e+05      -6.016304e+02 |       32
     16       6.183485e+05      -4.609310e+02 |       32
     17       6.181395e+05      -2.090169e+02 |       32
     18       6.180303e+05      -1.091924e+02 |       32
     19       6.179680e+05      -6.226058e+01 |       32
     20       6.179415e+05      -2.656426e+01 |       31
     21       6.179232e+05      -1.824162e+01 |       31
     22       6.179075e+05      -1.573424e+01 |       28
     23       6.178938e+05      -1.368467e+01 |       30
     24       6.178811e+05      -1.266922e+01 |       31
     25       6.178643e+05      -1.682839e+01 |       30
     26       6.178438e+05      -2.048269e+01 |       30
     27       6.178193e+05      -2.447501e+01 |       31
     28       6.177847e+05      -3.463889e+01 |       32
     29       6.177455e+05      -3.920722e+01 |       32
     30       6.176975e+05      -4.803877e+01 |       32
     31       6.176519e+05      -4.552332e+01 |       32
     32       6.176097e+05      -4.221652e+01 |       32
     33       6.175651e+05      -4.458237e+01 |       32
     34       6.175197e+05      -4.547512e+01 |       32
     35       6.174721e+05      -4.761101e+01 |       32
     36       6.174338e+05      -3.824477e+01 |       30
     37       6.173954e+05      -3.842843e+01 |       32
     38       6.173428e+05      -5.256338e+01 |       32
     39       6.172952e+05      -4.763777e+01 |       32
     40       6.172566e+05      -3.862094e+01 |       31
     41       6.172261e+05      -3.049139e+01 |       31
     42       6.172025e+05      -2.359171e+01 |       32
     43       6.171815e+05      -2.101005e+01 |       31
     44       6.171633e+05      -1.820646e+01 |       31
     45       6.171492e+05      -1.404116e+01 |       31
     46       6.171396e+05      -9.659083e+00 |       29
     47       6.171337e+05      -5.906093e+00 |       23
     48       6.171294e+05      -4.273052e+00 |       23
     49       6.171265e+05      -2.906199e+00 |       21
     50       6.171247e+05      -1.777703e+00 |       17
K-means terminated without convergence after 50 iterations (objv = 617124.6948022697)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.327902
[ Info: iteration 2, average log likelihood -1.299205
[ Info: iteration 3, average log likelihood -1.272606
[ Info: iteration 4, average log likelihood -1.237391
[ Info: iteration 5, average log likelihood -1.187361
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.122026
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     10
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.093468
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.141139
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.123925
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     12
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.070652
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     10
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.087206
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.127318
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     22
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.092194
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.078388
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│     10
│     12
│     15
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.065121
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.142799
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.085907
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     16
│     22
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.061582
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     10
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.093452
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      9
│     12
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.108311
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.116309
[ Info: iteration 22, average log likelihood -1.107737
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     10
│     15
│     21
│     22
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.051181
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      9
│     12
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.110390
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.131381
[ Info: iteration 26, average log likelihood -1.105747
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     10
│     15
│     16
│     21
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.044627
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.117704
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     17
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.080070
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     12
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.091094
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.076113
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.103663
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      5
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.080589
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     12
│     16
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.056436
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      9
│     15
│     17
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.088671
[ Info: iteration 36, average log likelihood -1.132655
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     16
│     22
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.058619
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     10
│     12
│     17
│     21
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.055694
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      9
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.127095
[ Info: iteration 40, average log likelihood -1.132343
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.063331
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│     10
│     15
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.038123
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     12
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.125355
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.132049
[ Info: iteration 45, average log likelihood -1.107209
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      7
│      9
│     10
│     15
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.033243
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     17
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.126945
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.124040
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.075605
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      7
│      9
│     15
│     16
│     17
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.060162
┌ Info: EM with 100000 data points 50 iterations avll -1.060162
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.141488     0.0266096   -0.046632    -0.00556659   0.0469179    0.1378        0.0129943   -0.0761674   0.155798     0.0433054     0.14774     -0.0189787   -0.0840679    0.103137    0.0876406   -0.0148492    0.102542     0.00200863   0.197126     -0.105568    -0.0622291     0.22544     -0.0557663   -0.0707281     0.0635674   -0.0720582
 -0.10441      0.17031      0.087715    -0.00239214  -0.0527297    0.0840604    -0.0178052   -0.0194588  -0.0588129    0.179877     -0.0017394   -0.141135     0.0476037    0.0409316  -0.0426222    0.0161115    0.096505     0.0945382   -0.278519      0.0506583   -0.171684     -0.137593    -0.0964657    0.171007      0.0965159    0.0647693
  0.211279    -0.149587    -0.0763298   -0.0399345    0.0359014    0.0369594     0.0529639    0.161896    0.109452    -0.212377     -0.0566409   -0.0105002   -0.104789     0.193871   -0.0354401   -0.0268317    0.0340185   -0.147533    -0.0984724     0.00690673   0.155164      0.024816     0.0510422    0.0411518    -0.150804    -0.115411
  0.0235345   -0.0445816   -0.0956982   -0.167882    -0.197615     0.128514     -0.0906622   -0.120848    0.124048     0.0346686     0.0258405    0.112162    -0.0459231    0.0162      0.0324478    0.0987335    0.0785256   -0.138999    -0.0244581    -0.162345     0.0560494    -0.057993     0.113204    -0.00330152   -0.12121      0.0213048
  0.0394196   -0.0951888   -0.0202853    0.175493     0.062224    -0.0461825    -0.153961    -0.0776601   0.0101767    0.0863507    -0.0295835   -0.141705     0.0921113    0.0609699   0.0386775    0.0811425   -0.143538     0.00785183   0.00237418    0.13115      0.118964     -0.0962734    0.150923    -0.121404     -0.0522865    0.0495706
 -0.185396    -0.11465     -0.0674368   -0.0435403    0.129002    -0.137375     -0.0469255   -0.1586      0.0521474   -0.00754228   -0.196848    -0.0128015    0.0625252    0.140591    0.0112334   -0.0502735    0.051292    -0.053927    -0.186535      0.180943     0.0972067    -0.168921     0.263843    -0.159123     -0.040534     0.00313449
 -0.022846     0.00218603   0.0678562   -0.159802    -0.0565474    0.102631     -0.0413794   -0.0445415  -0.195333     0.0116804     0.115919    -0.200308    -0.0987165    0.0273645   0.107765    -0.11801      0.00497788  -0.0455986    0.00343096    0.0643246   -0.00723908    0.0847168    0.0145749    0.0210338    -0.00244624   0.0537202
  0.106192    -0.0907333   -0.151194    -0.136486     0.11232     -0.0381013     0.093399     0.0228921  -0.00403716   0.0137612    -0.148371     0.0669742   -0.157823     0.049723    0.0668228   -0.0635301    0.163834    -0.0155978   -0.0418969     0.0921377    0.110836      0.0210033    0.201621    -0.0956213    -0.0150982    0.0521896
  0.00460817   0.0458013   -0.00769707   0.12132      0.00220875   0.105704     -0.0716586    0.17273    -0.105817     0.00657296    0.186581     0.103111    -0.0672793    0.0209096   0.162635     0.151265     0.00494946  -0.058954    -0.0106364     0.143117     0.00499956   -0.0206979    0.00301217   0.150681      0.0109709    0.0358399
  0.00373546   0.0804293    0.037899     0.103808    -0.120506    -0.15354       0.0192346    0.104094    0.0674771    0.242341     -0.00428455  -0.0275563   -0.0101141    0.0925542   0.0472988    0.0232628    0.00420467  -0.16575     -0.173742     -0.0872475   -0.0911413     0.11966     -0.0351545   -0.117058      0.181575    -0.105808
 -0.0196825    0.0364542   -0.0101111    0.0418477   -0.0561369    0.000154949   0.0651866    0.0158622   0.02828     -0.0157473    -0.0291086   -0.0514987   -0.0253849    0.152746    0.0321089   -0.0260411    0.00446052   0.239941     0.0381342     0.0280679    0.130216      0.0752416    0.0412094    0.0664379    -0.0414405   -0.072294
 -0.0407895   -0.0797444    0.0756774   -0.0951846    0.115077     0.137095      0.178158     0.0362483  -0.03681      0.0225213    -0.00127863  -0.121552    -0.081279    -0.137394   -0.0605947    0.0271643   -0.00376576   0.403851    -0.0485182    -0.0373886   -0.106443     -0.136148    -0.124521    -0.0177451     0.349669    -0.0209727
  0.00978793   0.160959    -0.132024     0.106872     0.0275992   -0.0546012    -0.00455247  -0.0374779   0.125412    -0.103087     -0.0208704   -0.018882    -0.00999402  -0.021746    0.0613475   -0.199548     0.0146202    0.0805269    0.000948175   0.1371       0.0583179     0.0315596    0.047682     0.0830737    -0.19402     -0.136953
 -0.0232255   -0.0842121   -0.0981606    0.118264    -0.00603812   0.108389     -0.160653     0.0721784   0.102422     0.232157      0.162852    -0.0815918   -0.0922719    0.0491247  -0.146833     0.0519894   -0.00574838  -0.0531075    0.0719839     0.0316646    0.0711754     0.0318496   -0.0789889   -0.0494387     0.00902015   0.0910571
  0.102489    -0.00767402  -0.0457846   -0.0713224   -0.0691754    0.0123833    -0.0477644    0.0995611  -0.101721     0.141764     -0.0887107   -0.0114739   -0.0743967    0.130473   -0.0174388    0.108763    -0.0562664    0.202944    -0.0200499    -0.0342809   -0.0199536    -0.145947     0.0920209    0.0355514     0.00780121   0.0326733
  0.177184    -0.137337     0.0782446    0.108147    -0.0619225   -0.0936401     0.0549154    0.0704522   0.00496634   0.0549002    -0.140711    -0.0300542    0.00498309   0.175832    0.089792    -0.0299635    0.154918    -0.144737    -0.0929794    -0.114913    -0.0494703     0.0118109   -0.0461059   -0.0097863    -0.0687572   -0.0671137
 -0.100514     0.15188      0.127192     0.153122     0.250653    -0.103807      0.0772842   -0.257461    0.171589     0.0789426     0.106922    -0.0389621    0.0992396    0.0774407   0.0244081   -0.125246     0.0259738    0.0168673    0.0646138     0.0650935   -0.0153846    -0.21717     -0.201546    -0.121916     -0.0390511   -0.0516343
  0.0420646    0.0586876    0.0169272   -0.00254877   0.156707     0.0400165     0.0910374    0.164411    0.0918253   -0.138494     -0.0940643   -0.0784224    0.0568499    0.0762875  -0.0860964   -0.0275005   -0.171637    -0.0707397    0.00183472    0.190442    -0.000567563  -0.00406045  -0.0583969    0.0410318    -0.142828    -0.000285268
 -0.203451    -0.0252926    0.0998506   -0.0223999    0.0560865   -0.0625412    -0.0348993   -0.0615166  -0.0666597   -0.0147441    -0.123012     0.0157361    0.109841     0.174912   -0.0148258    0.0479946   -0.21862     -0.00335508   0.0226195     0.0128141    0.0501873     0.0407822    0.00993869   0.00466425    0.0115431    0.0964769
  0.174566     0.223056    -0.118075    -0.0666462   -0.12538     -0.103774      0.120657    -0.224886   -0.119367    -3.18028e-5   -0.0346148    0.160766    -0.190139     0.213075   -0.147523    -0.0818699   -0.174296     0.167507     0.0475568     0.0263653    0.0838979     0.0204169    0.141675    -0.113517     -0.133707    -0.0469576
  0.00904876  -0.0506391   -0.040488    -0.163525     0.0482221   -0.113803      0.04726     -0.0468795   0.131006     0.0573265    -0.0993242    0.263337    -0.0255203   -0.0386474   0.0419492   -0.113424     0.0276191   -0.128864    -0.0740157     0.0611219   -0.0877409     0.0768401    0.163456     0.0620355    -0.228495     0.0491463
  0.104564     0.0864977   -0.0766574   -0.0826107    0.0551191   -0.0428815     0.0430807   -0.0144893  -0.0501839   -0.169014     -0.0779044    0.084972    -0.0214342   -0.0589042   0.0913204    0.00163037   0.149943     0.08778      0.0419691     0.202302    -0.0116025    -0.0112649   -0.0552694   -0.184095     -0.114636    -0.0421772
  0.088436    -0.0296257   -0.0186166    0.338601    -0.0012052    0.0204608     0.0934335    0.134929    0.27475      0.013312      0.125047     0.063841     0.13456     -0.129772    0.0373493    0.0335533   -0.0397227   -0.0256301    0.0971884    -0.0534024    0.015949      0.0557089   -0.0844948   -0.0403179     0.0906379    0.0527581
 -0.00453349  -0.107658     0.0806766   -0.100768    -0.0760575    0.00148444    0.103323     0.0167656   0.0685553   -0.000802889  -0.0572345   -0.0428284   -0.0116048   -0.0189286  -0.00810183   0.00737072   0.0554137    0.0236585    0.00938534   -0.153817    -0.0475806    -0.00654892  -0.11243     -0.100641     -0.0310764   -0.0405152
 -0.0213426    0.00890461   0.0331484    0.124159    -0.0111001    0.217593      0.0366723   -0.0720407   0.0431887    0.181932      0.0768953    0.100731     0.0562595    0.0150582   0.137844     0.0225732    0.0313015    0.0380013    0.20706       0.0837117    0.0113741    -0.095146    -0.100007     0.00265588   -0.20148     -0.123487
  0.117526    -0.188624    -0.15198      0.307016     0.0192874   -0.13176      -0.00874389   0.0930723  -0.0274756   -0.01596      -0.112639     0.122651    -0.225493     0.0361104   0.143475     0.255321     0.0384803    0.155053    -0.0655397    -0.0353391    0.184198      0.0533899    0.0465175    0.0821677     0.0597131   -0.0487447
  0.0651764   -0.102934     0.0266088   -0.0947108    0.275719     0.0567331     0.123008    -0.10364     0.0410655    0.0160884     0.156785     0.211745     0.174057    -0.0805364   0.0603594   -0.0114388    0.178186    -0.105616     0.123025      0.284071    -0.113218     -0.185638     0.0608161    0.000133927   0.0716689    0.160921
  0.0814134   -0.0430461   -0.0562183    0.231321    -0.0474981    0.196778      0.223452    -0.0356365   0.120739    -0.0383532     0.0245177    0.0364931    0.0669779   -0.055736    0.0277578    0.0474796   -0.0727314   -0.109884    -0.12866       0.0955718    0.149283      0.0442238   -0.00456351   0.335993     -0.0521414   -0.10281
  0.00699446  -0.0124606   -0.153129    -0.075473     0.179149    -0.0248498    -0.0974429    0.109477    0.0951878    0.154339     -0.0279867    0.118883    -0.0320459   -0.411798    0.0938354   -0.0495276   -0.0891717   -0.0793075    0.254576     -0.137319     0.0528696    -0.172133    -0.153922     0.0799922     0.070662    -0.156262
  0.0253016   -0.0983263   -0.0999591   -0.0454375   -0.00235133  -0.0702974     0.256922    -0.0646773   0.0563873    0.0209435    -0.0430148    0.156594    -0.0578576   -0.0835709   0.0103128   -0.0508577    0.03135     -0.115609     0.0316341    -0.0165207   -0.0252357     0.0342915   -0.070913     0.0617484    -0.0116462   -0.20185
  0.0412789   -0.0256164   -0.0319968   -0.0903349   -0.0662435    0.157055     -0.0268438   -0.0566343   0.0348406   -0.00676806   -0.153885     0.00947549  -0.00869214  -0.0472097  -0.0471048    0.106967     0.14264     -0.0884262    0.240187     -0.0310797   -0.0221162    -0.00654284   0.0256488    0.0234        0.0659141    0.079909
 -0.0745657   -0.0211182    0.0980989    0.190592    -0.0606731    0.0152078     0.0236976   -0.0925811   0.0242576   -0.0221136     0.133663    -0.0520286    0.0761072    0.0326604  -0.0680478    0.0765714   -0.0576682    0.0509945    0.159406     -0.0159591    0.0720215    -0.108171     0.0560799    0.00210536    0.0729089    0.166911[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.136511
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.062230
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     10
│     12
│     16
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.016535
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      7
│      9
│     15
│     21
│     22
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.050901
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.088558
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     10
│     12
│     16
│      ⋮
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.033832
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.065203
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      9
│     12
│     15
│     21
│     22
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.024540
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     10
│     16
│     17
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.072075
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     12
│     21
│     22
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.069551
┌ Info: EM with 100000 data points 10 iterations avll -1.069551
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.161002     0.0631575    0.122263     0.0225577    -0.114099     0.087694      0.20579     -0.000188663   0.00763001  -0.113956    -0.0216472    0.158662     0.00960669   0.040564     0.146782   -0.0676183     0.00852967  -0.0265247     0.0216887     0.102386     0.00130221   0.117151    -0.0067634   -0.0787836    0.137367    -0.11923
  0.0311816    0.114747    -0.0313877   -0.0430633     0.152529     0.023547      0.0411028   -0.0471734    -0.033422     0.00543654  -0.0117086    0.076248     0.168177     0.0600776    0.134727    0.0765615     0.0078616   -0.112249     -0.0153418     0.00318284  -0.0399442    0.00248898  -0.110456    -0.219618     0.124097     3.93937e-5
  0.11427      0.0758275   -0.0582502    0.000614749  -0.00821725   0.244742      0.017458    -0.0685967     0.0883775   -0.242097     0.128817     0.199023    -0.159161    -0.163835    -0.05907    -0.000170894  -0.0985764    0.206115     -0.110505     -0.131172     0.162623    -0.0851844   -0.10312      0.103617    -0.0698621   -0.039665
  0.178665    -0.0626269   -0.0151791    0.0654788     0.136939     0.00533149    0.0954944   -0.0911099    -0.0381056    0.0353573   -0.0456487   -0.0996862   -0.0490052   -0.0504793   -0.0824202   0.0201183    -0.0399122   -0.0404389    -0.0612378     0.17291      0.171835     0.0281005   -0.0597961    0.0289725   -0.0246484   -0.11385
  0.104699     0.0168572   -0.130978    -0.250177     -0.0238531   -0.0137631    -0.0678763   -0.0476939    -0.0619045   -0.0243732    0.203903    -0.0584659    0.106624    -0.0596856   -0.0567954  -0.0914615    -0.0640697    0.0407158    -0.0621286     0.0899933    0.140099     0.0209701   -0.0415326    0.181908    -0.0409798    0.137376
 -0.0757093   -0.0180128   -0.0919975   -0.0416659    -0.123331    -0.057476      0.112599     0.137024     -0.182735    -0.271171     0.0052224    0.214715     0.0863377   -0.0659107    0.0154285  -0.055752      0.00959358   0.0391942     0.151489      0.191135    -0.0918164   -0.0524291   -0.0156166   -0.0631181   -0.127296     0.174772
  0.0861938   -0.0970747    0.0124806   -0.0785443     0.0650861   -0.144567      0.128687     0.136205      0.115827     0.00559406  -0.0106988    0.0263827    0.0682129    0.081036     0.0864039   0.0169324    -0.0841803    0.094339      0.0460239     0.0268116    0.223923     0.170872    -0.111007     0.0154313   -0.00466856   0.090803
 -0.0385496    0.0245761   -0.1222      -0.164727      0.108555     0.00538385   -0.0950104   -0.00649273   -0.0771466   -0.0159916    0.0412123   -0.0877578    0.030804     0.0713792   -0.0840501  -0.166736      0.0366683    0.0166348    -0.206153      0.0665938   -0.125457     0.162392    -0.0037591    0.00729593   0.0856143   -0.134653
 -0.0587092   -0.142081    -0.0357468    0.0162397     0.0710248    0.24955       0.086923    -0.0246987    -0.104011     0.0429783    0.159712     0.102196    -0.0674453   -0.336803     0.0620496   0.0339775    -0.1111       0.0381996     0.0833755    -0.128015     0.222665     0.0238962    0.144053     0.101194     0.0223878   -0.0300265
 -0.0962837    0.0281141    0.103173    -0.092324      0.10285      0.0357763     0.0954154   -0.00892673    0.0230734    0.138732     0.0753549   -0.00268776   0.0410088   -0.0625875   -0.244381   -0.00612813    0.0569293    0.150348      0.0320319    -0.0491207    0.0406401    0.0368709   -0.0739999   -0.162562     0.11049      0.0709561
 -0.00669357   0.0175993    0.0181613   -0.144412      0.0122544    0.00859626   -0.00758546   0.0401822     0.148784    -0.0159667    0.101182    -0.0369927   -0.0588371    0.100542     0.0302463  -0.0755408    -0.0197637    0.0165437     0.0531107     0.101312    -0.104431     0.0106932   -0.0307399   -0.0419381   -0.0811756    0.0946831
  0.140423    -0.0556185   -0.23181     -0.0288204    -0.0405515   -0.0910443     0.0433502    0.142857     -0.23242     -0.0052463   -0.105465    -0.0208276   -0.00974528   0.0861296   -0.0165356   0.14145       0.0294166    0.0792038    -0.0980938     0.154617    -0.122218    -0.064064     0.066338    -0.029796     0.272951    -0.0362975
 -0.248678     0.0129064    0.00635725   0.15986      -0.0293175   -0.172063     -0.0798552    0.102542     -0.0595223   -0.00648108  -0.00783077   0.008873     0.119495    -0.0659835    0.355282   -0.0021945     0.0316965   -0.000141946   0.123758      0.061813     0.0597917   -0.0326579   -0.117229    -0.0486203   -0.00476561  -0.144978
 -0.0495114    0.0441543    0.0439671    0.0596854    -0.0559733    0.0102648     0.0588249   -0.152571      0.112964    -0.0305044   -0.00444862   0.115229    -0.100155    -0.0139512   -0.0239396  -0.0300929     0.0428968    0.0242929    -0.151915     -0.0866734   -0.0911902   -0.0175039    0.00185818   0.104806    -0.0675055    0.173314
  0.158614    -0.148956     0.015998     0.186894     -0.0716847   -0.0770463    -0.00545781   0.0434811     0.0449907    0.131441    -0.207403    -0.202701    -0.0261572   -0.0320712   -0.0982277   0.0672621     0.124912    -0.0218375    -0.0968983    -0.0947265    0.0112961   -0.0144704    0.0918287   -0.0661397   -0.0718985    0.0141616
  0.12214     -0.0533831    0.106725    -0.00731979   -0.0025718   -0.0389563    -0.13532     -0.0958967     0.108313    -0.206252     0.0470842   -0.140144     0.107677     0.00735768   0.107272   -0.12342      -0.112805    -0.134049      0.0965698     0.0165438    0.15122     -0.0750338   -0.137448    -0.0783551   -0.0274966   -0.150241
  0.149386    -0.181317    -0.0145273   -0.0181946    -0.0217497   -0.0831122     0.163097     0.0215486     0.00878208   0.100455    -0.159371     0.067403     0.130631    -0.0411479    0.0187831   0.0118575    -0.0401493    0.194367      0.118233      0.0289518    0.15567     -0.126102    -0.0811608    0.0867808    0.084973     0.0372184
 -0.0226104    0.0892263   -0.0416203   -0.0338523     0.24332     -0.0779664     0.0743767    0.128883     -0.027943     0.0510151    0.0469509   -0.0749861    0.0445134    0.107434     0.0146906   0.04517      -0.189643    -0.202939     -0.0439552    -0.0656673    0.110484    -0.0326371   -0.0216933   -0.102417    -0.159601    -0.0993164
  0.0306655   -0.250471    -0.0245921   -0.0412772    -0.120102    -0.000519057   0.0835776    0.00621987   -0.0883779    0.115095     0.0138264    0.225525    -0.0686582    0.014066     0.0460986   0.219095      0.138584     0.0201599     0.0872462    -0.0251115   -0.013006    -0.0578047    0.121807     0.0879888   -0.0373867    0.152424
  0.0202921   -0.0552986   -0.0910732    0.15271       0.0550731   -0.0380186    -0.0125843    0.1105       -0.00655112   0.076636    -0.195078     0.119772    -0.0244585    0.130039    -0.0515897   0.142501     -0.0567811    0.0803648    -0.0265861     0.0458616    0.00617165  -0.131379     0.141174    -0.259819     0.125336    -0.061247
 -0.138746     0.0230099    0.0877755    0.168966     -0.0508326    0.131041     -0.137523    -0.11504      -0.091235    -0.0496349   -0.0765479    0.130946     0.0578707    0.0620295   -0.0331632   0.044355      0.0255171    0.112981      0.0706207     0.0630057    0.201906     0.0655802   -0.154864    -0.0283697    0.00663061  -0.046732
 -0.188805    -0.00464985   0.0133744   -0.0781688     0.128827    -0.105638     -0.0336862    0.196         0.122803     0.0453805    0.0830612    0.0997568    0.0977735    0.0501063   -0.0493176  -0.0416134     0.0309686    0.211804      0.0246187     0.0615756   -0.114196    -0.0809825   -0.0959131   -0.0239645    0.184419    -0.00195587
 -0.174213     0.133951     0.118457     0.0494378    -0.0631121   -0.0609997     0.0274338   -0.0804114    -0.0175874   -0.0222805   -4.5405e-5    0.0324307    0.173013     0.0162035   -0.0827893  -0.0381115    -0.0150982    0.216423     -0.000543534   0.0825493    0.133636     0.0220656   -0.131552    -0.097205    -0.0686959    0.0201343
 -0.0200999    0.0621976    0.0442641    0.189355     -0.0180358   -0.0570183     0.0431867    0.13153      -0.0454479    0.173724    -0.141013    -0.0798416    0.124644    -0.0701925    0.070353    0.0364585     0.0522553   -0.00423262   -0.0966936    -0.0630646   -0.188574     0.0755055    0.0223169   -0.0670368    0.167966    -0.0900788
  0.0974403    0.120311     0.078034     0.0558081    -0.0279592   -0.0349384    -0.166191     0.108258     -0.130463    -0.0740872    0.137192    -0.0402744   -0.0879575   -0.0140769   -0.044749    0.112214      0.0662765   -0.0337254    -0.180685     -0.00122959  -0.0678094    0.0518408    0.00381768  -0.0159405    0.0129053    0.088397
  0.0981526    0.0347573   -0.228913    -0.0455939    -0.18149      0.0394862     0.00436904   0.055417     -0.0537039   -0.0400661   -0.0460676    0.192492     0.0332639   -0.0150335   -0.0267111  -0.0546083     0.174926     0.0641735     0.0452889     0.00152558   0.1308       0.119342     0.100748     0.0965833   -0.0191293   -0.0832334
 -0.0280046   -0.0744778   -0.0953388   -0.130937     -0.186559     0.0312367    -0.0834713    0.103383     -0.0557624   -0.0829572    0.0955352    0.0977833   -0.107504     0.0493927   -0.0163241   0.0112947     0.122184     0.106267     -0.043544     -0.0887931   -0.0928849   -0.0383214    0.0285743   -0.0902801    0.0179024   -0.0566921
 -0.0739723    0.0436608   -0.013605    -0.0512124    -0.0480817    0.0833192     0.0329954   -0.253271      0.0898633    0.0189155    0.0151746   -0.0261671    0.0326612    0.0432645   -0.0754504   0.00234515    0.0400735    0.0975469    -0.290003     -0.0591674    0.044483     0.0257525    0.163595     0.021084    -0.0422646    0.0595873
 -0.0156853   -0.00357055   0.184151     0.0519162    -0.0189444   -0.0294201     0.0194843   -0.138571     -0.119262     0.128067    -0.0840081   -0.0636053   -0.131158     0.0888818   -0.160211    0.00752223   -0.086718     0.0967017     0.115174      0.0636769    0.0716444    0.00462159  -0.0491066   -0.0401466   -0.0701601   -0.0891527
  0.0321155    0.103443     0.0809003   -0.314547      0.0358356    0.251329     -0.181759     0.00528183   -0.0914387   -0.238731    -0.0504054    0.0432934   -0.032245    -0.0153131   -0.0442119  -0.0716514     0.228441    -0.0873546    -0.0104322     0.0156874   -0.0281802    0.0358637   -0.0852844    0.115845     0.0792242   -0.106157
 -0.107587    -0.0187002    0.129672     0.189425      0.136704    -0.0422513    -0.0614849    0.0320924    -0.027456    -0.236086     0.0578661   -0.0767808   -0.0602368   -0.0119105    0.0154896   0.106696      0.00289074   0.0283707     0.0371186    -0.0814413   -0.0335947    0.116981     0.0717061    0.0326126   -0.0332832    0.087873
 -0.0709621    0.0409794   -0.00912428   0.00339551    0.109737     0.0493274     0.0518203   -0.0964772     0.0230172    0.0249745    0.0340805   -0.0387893   -0.233972     0.108151    -0.108532   -0.251462     -0.121457     0.0788542     0.0101257    -0.10031     -0.106164    -0.21182     -0.0918284    0.00680925   0.117596    -0.0386147kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.419798029457488
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419817
[ Info: iteration 2, average log likelihood -1.419756
[ Info: iteration 3, average log likelihood -1.419702
[ Info: iteration 4, average log likelihood -1.419626
[ Info: iteration 5, average log likelihood -1.419515
[ Info: iteration 6, average log likelihood -1.419355
[ Info: iteration 7, average log likelihood -1.419126
[ Info: iteration 8, average log likelihood -1.418790
[ Info: iteration 9, average log likelihood -1.418288
[ Info: iteration 10, average log likelihood -1.417567
[ Info: iteration 11, average log likelihood -1.416671
[ Info: iteration 12, average log likelihood -1.415803
[ Info: iteration 13, average log likelihood -1.415166
[ Info: iteration 14, average log likelihood -1.414791
[ Info: iteration 15, average log likelihood -1.414598
[ Info: iteration 16, average log likelihood -1.414504
[ Info: iteration 17, average log likelihood -1.414460
[ Info: iteration 18, average log likelihood -1.414438
[ Info: iteration 19, average log likelihood -1.414428
[ Info: iteration 20, average log likelihood -1.414423
[ Info: iteration 21, average log likelihood -1.414421
[ Info: iteration 22, average log likelihood -1.414420
[ Info: iteration 23, average log likelihood -1.414419
[ Info: iteration 24, average log likelihood -1.414418
[ Info: iteration 25, average log likelihood -1.414418
[ Info: iteration 26, average log likelihood -1.414418
[ Info: iteration 27, average log likelihood -1.414418
[ Info: iteration 28, average log likelihood -1.414417
[ Info: iteration 29, average log likelihood -1.414417
[ Info: iteration 30, average log likelihood -1.414417
[ Info: iteration 31, average log likelihood -1.414417
[ Info: iteration 32, average log likelihood -1.414417
[ Info: iteration 33, average log likelihood -1.414417
[ Info: iteration 34, average log likelihood -1.414417
[ Info: iteration 35, average log likelihood -1.414417
[ Info: iteration 36, average log likelihood -1.414417
[ Info: iteration 37, average log likelihood -1.414417
[ Info: iteration 38, average log likelihood -1.414416
[ Info: iteration 39, average log likelihood -1.414416
[ Info: iteration 40, average log likelihood -1.414416
[ Info: iteration 41, average log likelihood -1.414416
[ Info: iteration 42, average log likelihood -1.414416
[ Info: iteration 43, average log likelihood -1.414416
[ Info: iteration 44, average log likelihood -1.414416
[ Info: iteration 45, average log likelihood -1.414416
[ Info: iteration 46, average log likelihood -1.414416
[ Info: iteration 47, average log likelihood -1.414416
[ Info: iteration 48, average log likelihood -1.414416
[ Info: iteration 49, average log likelihood -1.414416
[ Info: iteration 50, average log likelihood -1.414416
┌ Info: EM with 100000 data points 50 iterations avll -1.414416
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4198167992751467
│     -1.419756263824416
│      ⋮
└     -1.4144160833265307
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414431
[ Info: iteration 2, average log likelihood -1.414373
[ Info: iteration 3, average log likelihood -1.414318
[ Info: iteration 4, average log likelihood -1.414241
[ Info: iteration 5, average log likelihood -1.414133
[ Info: iteration 6, average log likelihood -1.413991
[ Info: iteration 7, average log likelihood -1.413825
[ Info: iteration 8, average log likelihood -1.413655
[ Info: iteration 9, average log likelihood -1.413502
[ Info: iteration 10, average log likelihood -1.413372
[ Info: iteration 11, average log likelihood -1.413267
[ Info: iteration 12, average log likelihood -1.413185
[ Info: iteration 13, average log likelihood -1.413123
[ Info: iteration 14, average log likelihood -1.413079
[ Info: iteration 15, average log likelihood -1.413048
[ Info: iteration 16, average log likelihood -1.413027
[ Info: iteration 17, average log likelihood -1.413012
[ Info: iteration 18, average log likelihood -1.413002
[ Info: iteration 19, average log likelihood -1.412994
[ Info: iteration 20, average log likelihood -1.412989
[ Info: iteration 21, average log likelihood -1.412984
[ Info: iteration 22, average log likelihood -1.412981
[ Info: iteration 23, average log likelihood -1.412978
[ Info: iteration 24, average log likelihood -1.412976
[ Info: iteration 25, average log likelihood -1.412974
[ Info: iteration 26, average log likelihood -1.412972
[ Info: iteration 27, average log likelihood -1.412971
[ Info: iteration 28, average log likelihood -1.412970
[ Info: iteration 29, average log likelihood -1.412968
[ Info: iteration 30, average log likelihood -1.412968
[ Info: iteration 31, average log likelihood -1.412967
[ Info: iteration 32, average log likelihood -1.412966
[ Info: iteration 33, average log likelihood -1.412965
[ Info: iteration 34, average log likelihood -1.412965
[ Info: iteration 35, average log likelihood -1.412964
[ Info: iteration 36, average log likelihood -1.412963
[ Info: iteration 37, average log likelihood -1.412963
[ Info: iteration 38, average log likelihood -1.412962
[ Info: iteration 39, average log likelihood -1.412962
[ Info: iteration 40, average log likelihood -1.412961
[ Info: iteration 41, average log likelihood -1.412961
[ Info: iteration 42, average log likelihood -1.412961
[ Info: iteration 43, average log likelihood -1.412960
[ Info: iteration 44, average log likelihood -1.412960
[ Info: iteration 45, average log likelihood -1.412960
[ Info: iteration 46, average log likelihood -1.412959
[ Info: iteration 47, average log likelihood -1.412959
[ Info: iteration 48, average log likelihood -1.412959
[ Info: iteration 49, average log likelihood -1.412958
[ Info: iteration 50, average log likelihood -1.412958
┌ Info: EM with 100000 data points 50 iterations avll -1.412958
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4144309676221718
│     -1.4143733400342684
│      ⋮
└     -1.4129579216264256
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412972
[ Info: iteration 2, average log likelihood -1.412909
[ Info: iteration 3, average log likelihood -1.412859
[ Info: iteration 4, average log likelihood -1.412804
[ Info: iteration 5, average log likelihood -1.412739
[ Info: iteration 6, average log likelihood -1.412664
[ Info: iteration 7, average log likelihood -1.412578
[ Info: iteration 8, average log likelihood -1.412485
[ Info: iteration 9, average log likelihood -1.412387
[ Info: iteration 10, average log likelihood -1.412288
[ Info: iteration 11, average log likelihood -1.412192
[ Info: iteration 12, average log likelihood -1.412103
[ Info: iteration 13, average log likelihood -1.412021
[ Info: iteration 14, average log likelihood -1.411949
[ Info: iteration 15, average log likelihood -1.411885
[ Info: iteration 16, average log likelihood -1.411828
[ Info: iteration 17, average log likelihood -1.411777
[ Info: iteration 18, average log likelihood -1.411730
[ Info: iteration 19, average log likelihood -1.411687
[ Info: iteration 20, average log likelihood -1.411647
[ Info: iteration 21, average log likelihood -1.411611
[ Info: iteration 22, average log likelihood -1.411577
[ Info: iteration 23, average log likelihood -1.411546
[ Info: iteration 24, average log likelihood -1.411519
[ Info: iteration 25, average log likelihood -1.411493
[ Info: iteration 26, average log likelihood -1.411470
[ Info: iteration 27, average log likelihood -1.411450
[ Info: iteration 28, average log likelihood -1.411432
[ Info: iteration 29, average log likelihood -1.411416
[ Info: iteration 30, average log likelihood -1.411401
[ Info: iteration 31, average log likelihood -1.411388
[ Info: iteration 32, average log likelihood -1.411377
[ Info: iteration 33, average log likelihood -1.411367
[ Info: iteration 34, average log likelihood -1.411358
[ Info: iteration 35, average log likelihood -1.411349
[ Info: iteration 36, average log likelihood -1.411342
[ Info: iteration 37, average log likelihood -1.411335
[ Info: iteration 38, average log likelihood -1.411329
[ Info: iteration 39, average log likelihood -1.411323
[ Info: iteration 40, average log likelihood -1.411318
[ Info: iteration 41, average log likelihood -1.411313
[ Info: iteration 42, average log likelihood -1.411309
[ Info: iteration 43, average log likelihood -1.411304
[ Info: iteration 44, average log likelihood -1.411300
[ Info: iteration 45, average log likelihood -1.411297
[ Info: iteration 46, average log likelihood -1.411293
[ Info: iteration 47, average log likelihood -1.411290
[ Info: iteration 48, average log likelihood -1.411287
[ Info: iteration 49, average log likelihood -1.411284
[ Info: iteration 50, average log likelihood -1.411281
┌ Info: EM with 100000 data points 50 iterations avll -1.411281
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4129718454566038
│     -1.4129089592055812
│      ⋮
└     -1.4112806145347654
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411288
[ Info: iteration 2, average log likelihood -1.411234
[ Info: iteration 3, average log likelihood -1.411186
[ Info: iteration 4, average log likelihood -1.411130
[ Info: iteration 5, average log likelihood -1.411060
[ Info: iteration 6, average log likelihood -1.410975
[ Info: iteration 7, average log likelihood -1.410873
[ Info: iteration 8, average log likelihood -1.410760
[ Info: iteration 9, average log likelihood -1.410640
[ Info: iteration 10, average log likelihood -1.410520
[ Info: iteration 11, average log likelihood -1.410406
[ Info: iteration 12, average log likelihood -1.410301
[ Info: iteration 13, average log likelihood -1.410206
[ Info: iteration 14, average log likelihood -1.410120
[ Info: iteration 15, average log likelihood -1.410045
[ Info: iteration 16, average log likelihood -1.409979
[ Info: iteration 17, average log likelihood -1.409922
[ Info: iteration 18, average log likelihood -1.409872
[ Info: iteration 19, average log likelihood -1.409830
[ Info: iteration 20, average log likelihood -1.409793
[ Info: iteration 21, average log likelihood -1.409761
[ Info: iteration 22, average log likelihood -1.409733
[ Info: iteration 23, average log likelihood -1.409708
[ Info: iteration 24, average log likelihood -1.409686
[ Info: iteration 25, average log likelihood -1.409665
[ Info: iteration 26, average log likelihood -1.409646
[ Info: iteration 27, average log likelihood -1.409628
[ Info: iteration 28, average log likelihood -1.409611
[ Info: iteration 29, average log likelihood -1.409594
[ Info: iteration 30, average log likelihood -1.409578
[ Info: iteration 31, average log likelihood -1.409563
[ Info: iteration 32, average log likelihood -1.409547
[ Info: iteration 33, average log likelihood -1.409532
[ Info: iteration 34, average log likelihood -1.409517
[ Info: iteration 35, average log likelihood -1.409503
[ Info: iteration 36, average log likelihood -1.409488
[ Info: iteration 37, average log likelihood -1.409474
[ Info: iteration 38, average log likelihood -1.409459
[ Info: iteration 39, average log likelihood -1.409445
[ Info: iteration 40, average log likelihood -1.409431
[ Info: iteration 41, average log likelihood -1.409417
[ Info: iteration 42, average log likelihood -1.409403
[ Info: iteration 43, average log likelihood -1.409389
[ Info: iteration 44, average log likelihood -1.409376
[ Info: iteration 45, average log likelihood -1.409363
[ Info: iteration 46, average log likelihood -1.409350
[ Info: iteration 47, average log likelihood -1.409337
[ Info: iteration 48, average log likelihood -1.409325
[ Info: iteration 49, average log likelihood -1.409313
[ Info: iteration 50, average log likelihood -1.409301
┌ Info: EM with 100000 data points 50 iterations avll -1.409301
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4112876718229725
│     -1.4112343043456128
│      ⋮
└     -1.4093007391492443
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409297
[ Info: iteration 2, average log likelihood -1.409228
[ Info: iteration 3, average log likelihood -1.409161
[ Info: iteration 4, average log likelihood -1.409080
[ Info: iteration 5, average log likelihood -1.408978
[ Info: iteration 6, average log likelihood -1.408850
[ Info: iteration 7, average log likelihood -1.408697
[ Info: iteration 8, average log likelihood -1.408524
[ Info: iteration 9, average log likelihood -1.408341
[ Info: iteration 10, average log likelihood -1.408160
[ Info: iteration 11, average log likelihood -1.407989
[ Info: iteration 12, average log likelihood -1.407833
[ Info: iteration 13, average log likelihood -1.407696
[ Info: iteration 14, average log likelihood -1.407577
[ Info: iteration 15, average log likelihood -1.407475
[ Info: iteration 16, average log likelihood -1.407387
[ Info: iteration 17, average log likelihood -1.407312
[ Info: iteration 18, average log likelihood -1.407247
[ Info: iteration 19, average log likelihood -1.407190
[ Info: iteration 20, average log likelihood -1.407140
[ Info: iteration 21, average log likelihood -1.407095
[ Info: iteration 22, average log likelihood -1.407056
[ Info: iteration 23, average log likelihood -1.407020
[ Info: iteration 24, average log likelihood -1.406987
[ Info: iteration 25, average log likelihood -1.406957
[ Info: iteration 26, average log likelihood -1.406929
[ Info: iteration 27, average log likelihood -1.406903
[ Info: iteration 28, average log likelihood -1.406879
[ Info: iteration 29, average log likelihood -1.406856
[ Info: iteration 30, average log likelihood -1.406835
[ Info: iteration 31, average log likelihood -1.406815
[ Info: iteration 32, average log likelihood -1.406795
[ Info: iteration 33, average log likelihood -1.406777
[ Info: iteration 34, average log likelihood -1.406760
[ Info: iteration 35, average log likelihood -1.406744
[ Info: iteration 36, average log likelihood -1.406728
[ Info: iteration 37, average log likelihood -1.406713
[ Info: iteration 38, average log likelihood -1.406699
[ Info: iteration 39, average log likelihood -1.406685
[ Info: iteration 40, average log likelihood -1.406672
[ Info: iteration 41, average log likelihood -1.406660
[ Info: iteration 42, average log likelihood -1.406648
[ Info: iteration 43, average log likelihood -1.406637
[ Info: iteration 44, average log likelihood -1.406626
[ Info: iteration 45, average log likelihood -1.406616
[ Info: iteration 46, average log likelihood -1.406606
[ Info: iteration 47, average log likelihood -1.406596
[ Info: iteration 48, average log likelihood -1.406587
[ Info: iteration 49, average log likelihood -1.406578
[ Info: iteration 50, average log likelihood -1.406569
┌ Info: EM with 100000 data points 50 iterations avll -1.406569
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.409297078978078
│     -1.4092284502005605
│      ⋮
└     -1.4065689460281063
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.419798029457488
│     -1.4198167992751467
│     -1.419756263824416
│     -1.419701896582569
│      ⋮
│     -1.4065866209748914
│     -1.4065776372139736
└     -1.4065689460281063
32×26 Array{Float64,2}:
  0.565543     0.346633     0.281929    0.100092   -0.363521     0.0136714    0.0628185  -0.0152144   0.0617623   -0.416299    -0.165057    -0.117824     -0.57014     0.221102   -0.166828     0.183294      0.0345061    -0.0855028  -0.356067     0.185173    0.0954401    0.233905    0.253355    0.0537917   -0.247962     0.382015
 -0.545392    -0.0793524    0.36974     0.202158    0.501004    -0.178277     0.133231    0.28486    -0.0886241   -0.50602      0.419324    -0.553366     -0.0135749   0.836176   -0.12416      0.0975412     0.214415      0.383932   -0.426015     0.226013   -0.0322155    0.31312     0.189321    0.0137893   -0.530885     0.237001
  0.0597066    0.0691352    0.106173   -0.283309   -0.458841    -0.570095     0.0233229   0.371175   -0.290276     0.0218907    0.00972099   0.0837937     0.487571    0.0586429  -0.126423    -0.00754242   -0.0324892     0.193134    0.249658     0.550494   -0.350639    -0.500196   -0.104983   -0.404529    -0.00924809   0.706274
 -0.0506176    0.290959     0.310842   -0.394242   -0.120293     0.0505959   -0.0314218  -0.0264617  -0.399698    -0.183052     0.172397     0.357458      0.537613   -0.0387174   0.105476     0.419492      0.20226      -0.0282857  -0.00968698  -0.0323094  -0.291529     0.381295    0.123874   -0.439865     0.0846522   -0.20782
 -0.236967    -0.416667    -0.255407    0.42412     0.213995    -0.588346     0.481026    0.0390662   0.043444     0.0557897   -0.152077    -0.0934259    -0.225015    0.245205   -0.0321056   -0.809871      0.0175339     0.13701    -0.234968    -0.0760605   0.394614    -0.992296   -0.0238348  -0.355518     0.560755    -0.0546769
 -0.146208     0.0403452   -0.19938     0.265741    0.0999627   -0.293415     0.320843    0.0650328   0.165463     0.609469    -0.248763    -0.0588032    -0.180056    0.434553   -0.0626514   -0.310606      0.048298     -0.486752   -0.385871     0.0527127   0.128734    -0.334606   -0.241339    0.525969     0.053141     0.282922
 -0.180622    -0.0736856   -0.0332498   0.0907545  -0.0444504   -0.0344392    0.0508762  -0.330479   -0.115485    -0.0846418   -0.0196519   -0.0694365     0.0711346   0.0658209  -0.176524    -0.118734     -0.0169806    -0.148102    0.028205     0.062472    0.118597    -0.0684591  -0.142652   -0.060412    -0.0608233   -0.0486825
 -0.0427279   -0.0421207   -0.0354671  -0.0861363   0.0846571    0.119825    -0.0468525   0.377018    0.0858137    0.107827    -0.0161807    0.100578     -0.0303452  -0.0347371   0.0160174    0.000148176   0.000895784   0.288264    0.0889995   -0.0508271  -0.00287646   0.0505994   0.0513408   0.125811     0.176371    -0.0794868
  0.266622     0.870479     0.169358   -0.574047   -0.460811     0.272074    -0.139655   -0.184068    0.216739    -0.0749633    0.691105     0.254605      0.102963    0.0352213  -0.00914443  -0.708055     -0.0500293     0.488563    0.00598259  -0.767466   -0.252113    -0.39628     0.347432   -0.319709     0.571473    -0.117858
  0.388363     0.772644    -0.179588   -0.53116    -0.261242    -0.00525283  -0.522082    0.0643114   0.487095    -0.418945     0.475127     0.140791     -0.290216    0.300316    0.277533    -0.0531729    -0.684858     -0.171165   -0.038021     0.344273    0.114897    -0.239011    0.670105   -0.539751     0.062972    -0.0288587
 -0.117235    -0.390828    -0.385634   -0.161811   -0.058919     0.0832109   -0.861252    0.188049    0.0830853   -0.376897     0.0323079    0.190855     -0.139586   -0.520249    0.284731    -0.136922     -0.857743      0.058673    0.373332     0.096814   -0.212366    -0.0220204   0.199325   -0.144257     0.569685    -0.836405
  0.406422    -0.041949    -0.198301   -0.126982    0.90915      0.0915872   -0.120811    0.046017   -0.685748    -0.040669    -0.306669     0.236911     -0.0981308  -0.0815103   0.210878    -0.342495     -0.205004     -0.109365   -0.0976955    0.171413    0.582206    -0.0217493   0.200241   -0.365718     0.480443    -0.0740589
  0.487573     0.0490867    0.0807414   0.702437    0.30205     -0.136646    -0.202526    0.160532   -0.0895078    0.429562     0.346503    -0.458307     -0.300779   -0.489557    0.02997      0.443172      0.264927      0.32623     0.381655     0.150618    0.15167      0.127116    0.311719    0.142508     0.0157351   -0.146172
  0.392374    -0.266062    -0.648366    0.187226    0.119822     0.0967592    0.146621   -0.275416   -0.259122     0.353829     0.331984     0.448645     -0.150084   -0.736457    0.0893722    0.419079      0.544977      0.0833897   0.313886    -0.22089    -0.240488    -0.01544    -0.310639   -0.0952194    0.0304129    0.0605029
 -0.665467    -0.00124382   0.0651781  -0.0282802   0.0336682    0.227171     0.103729   -0.157277    0.602833     0.150475     0.263042    -0.203519      0.0764413  -0.158382   -0.0803725    0.227736      0.246164      0.485423   -0.139121    -0.171755   -0.56588      0.173732   -0.485652    0.140898    -0.392888    -0.136928
  0.401924     0.263546     0.187649   -0.117826   -0.170634     0.290339    -0.183348   -0.0312716   0.80313     -0.00942613  -0.226498     0.0559253    -0.246747   -0.212026    0.412032     0.435496     -0.0529693     0.142681   -0.198577    -0.515166   -0.0804102   -0.14792    -0.409507    0.107427    -0.192024    -0.182004
 -0.233135    -0.0431025   -0.15072    -0.614211   -0.243522    -0.256521    -0.477279   -0.362375    0.135637    -0.787738     0.232642     0.34638       0.142639   -0.0152301   0.279521     0.120305     -0.426929      0.0203506  -0.118409    -0.0914763  -0.436879     0.143187    0.179762   -0.141705     0.0349434   -0.0576658
  0.237008     0.577274    -0.142279   -0.410932    0.141168    -0.154873    -0.078483   -0.325198   -0.42423      0.871055     0.0421494    0.166154      0.235144   -0.873517    0.166325     0.0599719     0.212004     -0.146511   -0.239584     0.0721374  -0.477939    -0.205168   -0.153706   -0.220466     0.969107    -0.664253
 -0.0953619   -0.162153    -0.207368   -0.289972    0.0539095    0.173741     0.255117   -0.471746    0.0222301    0.119891    -0.317806     0.438939      0.325557   -0.0961008   0.631157     0.194586     -0.226386     -0.455632   -0.677684    -0.167136    0.670662    -0.106954   -0.167595    0.64419      0.0261585   -0.0211987
 -0.0353941    0.354422     0.0541381  -0.61161     0.100952    -0.300943    -0.0276144   0.523792    0.0960788   -0.0853911   -0.0973033    0.423814      0.156051   -0.395886    0.64114      0.378273      0.13919       0.24145    -0.628176    -0.430358   -0.260054     0.423443    0.53232     0.261291     0.421963     0.214104
  0.140915     0.141487     0.337934    0.106676   -1.13218      0.290089     0.276556    0.0495395   0.610545    -0.230941     0.182775    -0.294023      0.0611647   0.179152   -0.29919      0.203012      0.162359      0.158848   -0.200707    -0.255859   -0.278639    -0.346543    0.035806   -0.198723    -0.741383     0.401897
  0.491477     0.600559     0.305007    0.0185778   0.00367337   0.226759    -0.0848019   0.365477    0.328983     0.228006    -0.21297     -0.105438     -0.144829    0.151153    0.21659      0.518545     -0.00599124   -0.127758   -0.299737     0.0144271   0.213002     0.0415117  -0.0583047  -0.185385    -0.204268     0.359441
  0.186837     0.375929     0.316412   -0.750171    0.0779906    0.624034    -0.104585    0.233908   -0.241003    -0.140472    -0.0579072    0.164623      0.192015    0.220299   -0.319983     0.367411      0.030216      0.253828    0.916418     0.298787   -0.324498     0.757259   -0.783704    0.00758296  -0.350452     0.0643652
  0.00716726   0.258233     0.708462    0.54044     0.271282     0.598329     1.00305     0.057898   -0.11272      0.0639046   -0.526325    -0.149172      0.0396938   0.628938   -0.633837    -0.37358       0.742197      0.324279    0.133983     0.135539    0.452609     0.329258   -0.144892    0.0293235   -0.0557164    0.290676
 -0.00314531  -0.32043     -0.426175    0.305561    0.0241079   -0.0606836   -0.0546457  -1.24138    -0.322304    -0.410441     0.211765     0.000117621  -0.132517   -0.09629    -0.596659    -0.365177     -0.24147      -0.436798    0.266928    -0.133653    0.324195     0.0221669  -0.215979   -0.0434676   -0.114252    -0.351037
 -0.311068    -0.618341     0.0288783   0.246808   -0.192334    -0.0261434   -0.0764666   0.0545312  -0.142835    -0.805895     0.010419     0.301282      0.118472    0.53694     0.0295793   -0.0978636    -0.069705     -0.351778    0.352153     0.120185    0.353214     0.142491   -0.203815   -0.138397    -0.955932     0.181704
  0.157676    -0.336669    -0.182625   -0.0358088   0.162168    -0.220955     0.298518    0.0297202  -1.06214     -0.113924     0.115787     0.210032      0.261702    0.235035   -0.271728    -0.410045     -0.0648954    -0.267224    0.253227     0.450564    0.517108     0.0810382   0.779384   -0.252516     0.430344     0.121841
 -0.0462535    0.138013     0.0309009  -0.0356993   0.0963962   -0.147375    -0.0232372  -0.236304   -0.0164715    0.42469     -0.378626    -0.68134      -0.0557482   0.282281   -0.674384    -0.159012     -0.207791     -0.678351   -0.0809604    0.108482    0.317011     0.34866     0.356281    0.0190356    0.485191    -0.0215952
 -0.58906     -0.911505     0.374283    0.436732    0.427158    -0.0893968    0.62694     0.0760217  -0.917851     0.434557    -0.361645     0.0794082     0.381338   -0.68666    -0.134174    -0.0691864     0.423681      0.344057    0.347834    -0.175397   -0.249165     0.0317452  -0.595836    0.498051     0.154276    -0.458301
 -0.211448    -0.537175    -0.412988    1.07671     0.201051    -0.035887     0.151056    0.0315813   0.0129034    0.184468    -0.0888969   -0.228548     -0.367973    0.0130722  -0.0736236   -0.206319      0.500796      0.0747155   0.257692     0.145327   -0.00275578  -0.330503   -0.850283    0.334347    -0.428487    -0.0038278
 -0.649991    -0.419382     0.048507   -0.0621981  -0.247323     0.539873     0.0272372   0.946512   -0.00105338  -0.0639636   -0.140619     0.297706     -0.0461646  -0.0490902  -0.0673254   -0.460793     -0.0103125     0.881583    0.18495      0.0675144   0.322819     0.0176013   0.088379   -0.05278      0.258931    -0.209589
 -0.0256069   -0.783004    -0.528918    0.247095    1.23345     -0.557535    -0.535297    0.0775292   0.249925    -0.256192    -0.115512    -0.233815     -0.176141    0.434328    0.183697    -0.969773     -0.168223      0.809334   -0.328765    -0.257883    0.380192     0.496605    0.316502    0.911025     0.321872     0.142323[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406561
[ Info: iteration 2, average log likelihood -1.406552
[ Info: iteration 3, average log likelihood -1.406544
[ Info: iteration 4, average log likelihood -1.406537
[ Info: iteration 5, average log likelihood -1.406529
[ Info: iteration 6, average log likelihood -1.406522
[ Info: iteration 7, average log likelihood -1.406514
[ Info: iteration 8, average log likelihood -1.406507
[ Info: iteration 9, average log likelihood -1.406500
[ Info: iteration 10, average log likelihood -1.406494
┌ Info: EM with 100000 data points 10 iterations avll -1.406494
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.805814e+05
      1       7.099966e+05      -1.705848e+05 |       32
      2       6.891933e+05      -2.080330e+04 |       32
      3       6.823777e+05      -6.815625e+03 |       32
      4       6.791876e+05      -3.190037e+03 |       32
      5       6.772122e+05      -1.975434e+03 |       32
      6       6.758209e+05      -1.391257e+03 |       32
      7       6.747380e+05      -1.082900e+03 |       32
      8       6.738730e+05      -8.650689e+02 |       32
      9       6.731621e+05      -7.108265e+02 |       32
     10       6.725590e+05      -6.031680e+02 |       32
     11       6.720532e+05      -5.057311e+02 |       32
     12       6.716408e+05      -4.124152e+02 |       32
     13       6.712960e+05      -3.448176e+02 |       32
     14       6.709862e+05      -3.098534e+02 |       32
     15       6.707300e+05      -2.561147e+02 |       32
     16       6.704998e+05      -2.302480e+02 |       32
     17       6.703017e+05      -1.981143e+02 |       32
     18       6.701367e+05      -1.649354e+02 |       32
     19       6.699711e+05      -1.656819e+02 |       32
     20       6.698149e+05      -1.561266e+02 |       32
     21       6.696800e+05      -1.349654e+02 |       32
     22       6.695551e+05      -1.248558e+02 |       32
     23       6.694410e+05      -1.141561e+02 |       32
     24       6.693305e+05      -1.104843e+02 |       32
     25       6.692239e+05      -1.066130e+02 |       32
     26       6.691238e+05      -1.000259e+02 |       32
     27       6.690388e+05      -8.502148e+01 |       32
     28       6.689622e+05      -7.664834e+01 |       32
     29       6.688844e+05      -7.774030e+01 |       32
     30       6.688093e+05      -7.516772e+01 |       32
     31       6.687384e+05      -7.090993e+01 |       32
     32       6.686760e+05      -6.236876e+01 |       32
     33       6.686124e+05      -6.355899e+01 |       32
     34       6.685540e+05      -5.841618e+01 |       32
     35       6.684906e+05      -6.337158e+01 |       32
     36       6.684281e+05      -6.256166e+01 |       32
     37       6.683667e+05      -6.136791e+01 |       32
     38       6.683098e+05      -5.687791e+01 |       32
     39       6.682513e+05      -5.855240e+01 |       32
     40       6.681867e+05      -6.460088e+01 |       32
     41       6.681200e+05      -6.668732e+01 |       32
     42       6.680593e+05      -6.069023e+01 |       32
     43       6.679941e+05      -6.522586e+01 |       32
     44       6.679223e+05      -7.175449e+01 |       32
     45       6.678562e+05      -6.612344e+01 |       32
     46       6.677972e+05      -5.899403e+01 |       32
     47       6.677443e+05      -5.285266e+01 |       32
     48       6.676868e+05      -5.757438e+01 |       32
     49       6.676322e+05      -5.462150e+01 |       32
     50       6.675786e+05      -5.359823e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 667578.5530790174)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418127
[ Info: iteration 2, average log likelihood -1.413131
[ Info: iteration 3, average log likelihood -1.411763
[ Info: iteration 4, average log likelihood -1.410735
[ Info: iteration 5, average log likelihood -1.409680
[ Info: iteration 6, average log likelihood -1.408740
[ Info: iteration 7, average log likelihood -1.408100
[ Info: iteration 8, average log likelihood -1.407732
[ Info: iteration 9, average log likelihood -1.407517
[ Info: iteration 10, average log likelihood -1.407377
[ Info: iteration 11, average log likelihood -1.407275
[ Info: iteration 12, average log likelihood -1.407194
[ Info: iteration 13, average log likelihood -1.407126
[ Info: iteration 14, average log likelihood -1.407068
[ Info: iteration 15, average log likelihood -1.407016
[ Info: iteration 16, average log likelihood -1.406970
[ Info: iteration 17, average log likelihood -1.406928
[ Info: iteration 18, average log likelihood -1.406889
[ Info: iteration 19, average log likelihood -1.406853
[ Info: iteration 20, average log likelihood -1.406820
[ Info: iteration 21, average log likelihood -1.406789
[ Info: iteration 22, average log likelihood -1.406759
[ Info: iteration 23, average log likelihood -1.406731
[ Info: iteration 24, average log likelihood -1.406705
[ Info: iteration 25, average log likelihood -1.406680
[ Info: iteration 26, average log likelihood -1.406657
[ Info: iteration 27, average log likelihood -1.406635
[ Info: iteration 28, average log likelihood -1.406614
[ Info: iteration 29, average log likelihood -1.406594
[ Info: iteration 30, average log likelihood -1.406576
[ Info: iteration 31, average log likelihood -1.406558
[ Info: iteration 32, average log likelihood -1.406541
[ Info: iteration 33, average log likelihood -1.406525
[ Info: iteration 34, average log likelihood -1.406510
[ Info: iteration 35, average log likelihood -1.406496
[ Info: iteration 36, average log likelihood -1.406482
[ Info: iteration 37, average log likelihood -1.406469
[ Info: iteration 38, average log likelihood -1.406457
[ Info: iteration 39, average log likelihood -1.406445
[ Info: iteration 40, average log likelihood -1.406434
[ Info: iteration 41, average log likelihood -1.406423
[ Info: iteration 42, average log likelihood -1.406413
[ Info: iteration 43, average log likelihood -1.406403
[ Info: iteration 44, average log likelihood -1.406393
[ Info: iteration 45, average log likelihood -1.406384
[ Info: iteration 46, average log likelihood -1.406375
[ Info: iteration 47, average log likelihood -1.406366
[ Info: iteration 48, average log likelihood -1.406358
[ Info: iteration 49, average log likelihood -1.406350
[ Info: iteration 50, average log likelihood -1.406342
┌ Info: EM with 100000 data points 50 iterations avll -1.406342
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.239066    -0.465643    -0.0818325   -0.106659    0.264174    -0.473701      0.181914     0.560508   -0.522331     0.0713048  -0.141153    0.228771      0.35347     0.273594   -0.232923   -0.754803     0.0908744    0.487164     0.359001      0.375834     0.0281403   -0.327956    0.0675996   -0.0928627   0.56298     0.340635
  0.177561     0.0668327    0.142527    -0.0421336  -0.139608     0.05429      -0.00731944   0.0180073   0.139401     0.092667   -0.54867     0.685847     -0.147751   -0.0783759   0.452086    0.19272     -0.116124    -0.259164    -0.216336     -0.209775     0.111385    -0.502719   -0.900483     0.130027   -0.677039    0.0351593
 -0.115686     0.0679635    0.264917     0.0504286  -0.396755     0.30729      -0.566002     0.539183    0.206619    -0.532474   -0.239225   -0.414155      0.139114   -0.308482    0.129136   -0.1806       0.0866009    0.774512     0.714719      0.00152296   0.546592    -0.0346814  -0.33712     -0.740968   -0.578279   -0.262904
 -0.592817    -0.31669     -0.176153     0.223359   -0.0736436    0.130436     -0.0481713   -0.126554    0.564501     0.0853183   0.423285   -0.140172     -0.0189277  -0.195755   -0.0774158   0.0972551    0.414173     0.771129    -0.0532668    -0.0207629   -0.931186    -0.0216255  -0.625103     0.325171   -0.503417    0.0227029
 -0.00383154   0.0548173    0.0884571    0.242626    0.302524     0.107434      0.737014     0.0442237  -0.21404      0.0323381   0.0928443   0.383628      0.163253    0.560854    0.140593    0.518748     1.21087      0.151898    -0.512508     -0.267193    -0.012771     0.35084    -0.0273677   -0.230311   -0.563666    0.479588
  0.0763851    0.111152     0.0555598   -0.0370695  -0.122403    -0.13903       0.104702     0.0144732   0.0510369    0.0556644  -0.0200301  -0.00836807    0.0551259   0.120321   -0.120143   -0.0664433    0.113527     0.0369691   -0.090123      0.0307467   -0.0183808   -0.186992   -0.0205574   -0.0582908   0.0414011   0.257366
  0.0226656    0.273005     0.558448     0.359935    0.367838     0.551577      0.548929     0.0266861  -0.0750357    0.179273   -0.575475   -0.349888     -0.0743718   0.891555   -0.754929   -0.525379     0.424107     0.207152     0.286303      0.214091     0.454264     0.428268   -0.291677     0.277859    0.0330447   0.237676
 -0.393779    -0.654874     0.0752414    0.350736   -0.17003     -0.0784041     0.136961    -0.0813017  -0.341593    -0.779449    0.162765    0.331942      0.230131    0.399039   -0.11862    -0.195729     0.032059    -0.142278     0.427483      0.162865     0.200685    -0.0020724  -0.342557    -0.279472   -1.01135     0.159209
 -0.295973    -0.095933     0.0138803   -0.190608    0.0303591    0.1763       -0.167971     0.104397   -0.159168    -0.104836    0.115325    0.208139      0.24663    -0.117212    0.14708     0.0954694   -0.0607007    0.152975     0.116539      0.00689077  -0.0662086    0.218914    0.0241206   -0.116229    0.0612242  -0.317738
  0.454347     0.0977212   -0.0490003   -0.0999547   0.228788     0.0492571     0.0501613   -0.256452   -0.654112    -0.297925   -0.120906    0.14586      -0.146438    0.157048   -0.110925   -0.331801    -0.415332    -0.411398    -0.000871263   0.245965     0.704449    -0.0714598   0.458444    -0.456008    0.230614    0.0323225
  0.204085     0.235873     0.192843    -0.746973    0.256084     0.659437     -0.218009     0.154173   -0.419234    -0.0351212  -0.0929831   0.322696      0.405069    0.236854   -0.0218658   0.521471    -0.134282     0.100308     0.807877      0.305256    -0.285731     1.08211    -0.599699     0.0399938  -0.249532    0.0677362
  0.647374    -0.0885108   -0.452439     0.598516    0.0789849   -0.423826     -0.0637467   -0.719141   -0.337241     0.374547    0.414725   -0.0450853     0.10688    -0.615624    0.0137229   0.263034     0.582028    -0.258826     0.482201     -0.162074    -0.126532    -0.111637   -0.142055    -0.20713     0.0137796   0.0817654
  0.292892     0.505221     0.693949    -0.299259   -0.283861    -0.196495      0.090133     0.952141    0.0595214    0.0585046  -0.223312   -0.158974      0.383926   -0.18478     0.36393     0.656726     0.0196294    0.480675    -0.19071       0.161325    -0.540575    -0.0858018   0.0320514   -0.121248   -0.237007    0.581177
 -0.0385911    0.241632     0.452333    -0.226565   -0.221063     0.246113      0.0382748   -0.623442    0.560585    -0.377404    0.172991   -0.334895     -0.139686    0.0216317   0.0828519   0.479836    -0.166067     0.00730254  -0.532432     -0.15101     -0.193713    -0.0326394  -0.323825    -0.149396   -0.601622   -0.0716686
 -0.384427    -0.00646438   0.0623466    0.0787457  -0.00533786  -0.509625      0.0497817    0.0739114  -0.00605439   0.147836    0.0818651  -0.356904      0.150516    0.918462   -0.177572   -0.219958    -0.0411603   -0.51562     -0.342341      0.256008     0.0647061   -0.0169657  -0.0276242    0.257284   -0.103708    0.228319
 -0.173489     0.0415175   -0.200031    -0.502738    0.0800283    0.162644      0.165976    -0.16906     0.0328975    0.227581   -0.223241    0.548369      0.439634   -0.36609     0.612722    0.20476     -0.00421176  -0.119876    -0.491775     -0.332023     0.208774     0.0699065  -0.0714496    0.415158    0.406295   -0.106594
 -0.396378     0.145364    -0.0729341   -0.255189    0.252943    -0.0040886     0.10815     -0.355006    0.171509     0.486283   -0.432228   -0.771075     -0.0404172  -0.4186     -0.871715   -0.361053    -0.055513     0.297563    -0.360164     -0.480311    -0.435332     0.914948    0.365003    -0.0679578   0.260491    0.138756
 -0.0901351    0.485821     0.308338    -0.130122   -0.69404      0.36286       0.525958    -0.105791   -0.0142719    0.0808352   0.367966    0.152538      0.136526   -0.29554    -1.01173     0.451921     0.349237    -0.327611     0.659807     -0.108757    -0.600804    -0.161908   -0.524278    -0.31934    -0.176443   -0.0501002
 -0.0579848   -0.648076    -0.343944     0.096115    1.20974     -0.536289     -0.592772     0.2012      0.406842    -0.552207   -0.0321241  -0.274011     -0.236454    0.256841    0.684749   -0.470703    -0.246683     0.836424    -0.533533     -0.302607     0.320999     0.478664    0.545218     0.785903    0.204411    0.209469
 -0.310904    -0.132292     0.210961    -0.438374   -0.572003     0.772831      0.11133      0.516126    0.472622    -0.62271    -0.18853     0.191584     -0.184088    0.715553   -0.0316495  -0.156206    -0.273591     0.222846    -0.673553     -0.0900618    0.450771     0.143127    0.643672     0.339995   -0.262812    0.244558
  0.381489     0.219803     0.00271786   0.145459   -0.153099     0.438392     -0.0920538    0.159245    0.76151      0.273233   -0.12848     0.117004     -0.423735   -0.362691    0.260779    0.281673    -0.0480104    0.30305      0.0718526    -0.499677    -0.00630172  -0.118398   -0.275305     0.289819    0.0274063  -0.324947
 -0.397294    -0.792187     0.171717     0.703161    0.46411      0.14041       0.585985     0.286811   -0.58262      0.580213   -0.319027   -0.164263      0.0453675  -0.653654   -0.0883832   0.031723     0.573337     0.399668     0.259006     -0.00486745   0.111387     0.0288116  -0.514088     0.488781    0.117503   -0.447137
 -0.431805    -0.617967    -0.624263     0.372176    0.152781     0.000150311  -0.0582398   -0.98409    -0.313009    -0.277065    0.241948    0.0131378    -0.0989413   0.062881   -0.458329   -0.629039    -0.251271    -0.488398     0.203286     -0.0685391    0.416013     0.133761   -0.0761002    0.189709    0.147729   -0.524183
  0.0112226    0.264809     0.141461    -0.0499379   0.0298272    0.191428     -0.100127     0.319524    0.0323183   -0.41235     0.770765    0.0667714    -0.14176    -0.0387631  -0.143523    0.132429     0.156076     0.886408     0.262071     -0.0778778   -0.446447     0.28926     0.457045    -0.559774    0.0325022  -0.132833
  0.867382     0.722408    -0.0193134   -0.102798    0.193937     0.0878025    -0.36852     -0.0133149   0.35372      0.594503    0.0734477  -0.352761     -0.377413   -0.109561    0.0215817   0.64834     -0.124566    -0.453189    -0.317068      0.211748     0.232456     0.372421    0.497985    -0.0715224   0.555379    0.185064
 -0.0407001    0.0989471   -0.0185803   -0.477572    0.155442    -0.204364     -0.0810471   -0.103773   -0.421449     0.214016    0.0301706   0.284296      0.346635   -0.596241    0.231174   -0.00641583  -0.120338     0.0021908   -0.165591      0.0243252   -0.284442     0.0381488   0.144125    -0.147762    0.920761   -0.612885
 -0.13886     -0.27675     -0.272352     0.659664    0.0995835   -0.506043      0.468084    -0.085294    0.291586     0.220325   -0.266391   -0.208033     -0.424446    0.0769652   0.0714427  -0.539639    -0.02979     -0.0985657   -0.556005     -0.149952     0.50765     -1.00603    -0.0592828   -0.01645     0.283141    0.0574536
  0.275927     0.798685    -0.159072    -0.721337   -0.451576     0.150869     -0.50121      0.081926    0.394778    -0.120264    0.289605    0.367077     -0.087227    0.0433015   0.18874    -0.745529    -0.452629     0.208424    -0.0440654    -0.113786    -0.0801127   -0.592863    0.396616    -0.391999    0.581227   -0.194643
  0.0554088    0.101748     0.144814     0.434059   -0.300021     0.00980695    0.102241     0.128791    0.122628    -0.147476    0.0835064  -0.51986      -0.112902    0.441662   -0.326837   -0.0531466    0.0867213   -0.0564269    0.0995592     0.269256     0.22475     -0.0528289   0.152538    -0.125297   -0.331008    0.409361
  0.10782      0.192574    -0.396787    -0.644895   -0.459417    -0.507634     -0.750191    -0.21928     0.221975    -0.707514    0.376536    0.410025      0.085119   -0.0630552   0.470262    0.413857    -0.609042    -0.454078     0.06363       0.0258582   -0.457067    -0.0300427   0.333011    -0.263208   -0.185946    0.111419
  0.407525    -0.179614     0.028502     0.248614   -0.0786304   -0.0140976    -0.220385     0.0250763  -0.122234    -0.409656   -0.362812   -0.273654     -0.459687    0.107276   -0.0427293   0.583115     0.154225    -0.229044    -0.169295      0.177108     0.145409     0.561921    0.00562446   0.472839   -0.37391     0.113509
 -0.0722046   -0.278378    -0.310605     0.320699    0.386929     0.0110768    -0.0636945    0.074421   -0.201621     0.194658   -0.135653    0.000784665  -0.39551    -0.280911   -0.114074   -0.152959    -0.137441    -0.0137537    0.286066      0.143801     0.249949    -0.0715512  -0.124199     0.180048    0.271502   -0.390366[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406334
[ Info: iteration 2, average log likelihood -1.406327
[ Info: iteration 3, average log likelihood -1.406320
[ Info: iteration 4, average log likelihood -1.406313
[ Info: iteration 5, average log likelihood -1.406306
[ Info: iteration 6, average log likelihood -1.406299
[ Info: iteration 7, average log likelihood -1.406293
[ Info: iteration 8, average log likelihood -1.406286
[ Info: iteration 9, average log likelihood -1.406280
[ Info: iteration 10, average log likelihood -1.406274
┌ Info: EM with 100000 data points 10 iterations avll -1.406274
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
