Julia Version 1.5.0-DEV.158
Commit ed177d17d6 (2020-01-27 16:45 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.3.1
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.3
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.22.3
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+5
 Installed OrderedCollections â”€ v1.1.0
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.2
 Installed OpenSpecFun_jll â”€â”€â”€â”€ v0.5.3+1
 Installed SpecialFunctions â”€â”€â”€ v0.9.0
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.2.1
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.9
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.4
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.11
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
   Cloning [f67ccb44-e63f-5c2f-98bd-6dc0ccc4ba2f] HDF5 from https://github.com/JuliaIO/HDF5.jl.git
[?25l    Fetching: [>                                        ]  0.0 %[2K[?25h Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_rBmHUn/Project.toml`
 [no changes]
  Updating `/tmp/jl_rBmHUn/Manifest.toml`
 [no changes]
  Building Blosc â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_goyZ7c/Project.toml`
 [no changes]
  Updating `/tmp/jl_goyZ7c/Manifest.toml`
 [no changes]
  Building Rmath â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_DKTKJ2/Project.toml`
 [no changes]
  Updating `/tmp/jl_DKTKJ2/Manifest.toml`
 [no changes]
  Building HDF5 â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_aEo136/Project.toml`
 [no changes]
  Updating `/tmp/jl_aEo136/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_baBn2C/Project.toml`
 [no changes]
  Updating `/tmp/jl_baBn2C/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_baBn2C/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.2
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -3.3076027447102414e6, [33283.70673283804, 66716.29326716196], [-2023.6885933236995 -3223.9373166399632 27615.417529521383; 1912.3965888257046 2897.3081470710526 -27674.026662909386], [[29453.357877575007 -2355.9920228827414 -5404.292732681766; -2355.992022882741 30856.291391763465 -5271.622711563069; -5404.292732681767 -5271.622711563068 29128.56145987934], [70570.06751620024 2220.9404176979183 5319.557757592237; 2220.9404176979183 68417.7254751188 4926.321627967193; 5319.557757592237 4926.321627967193 71323.65986959335]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.577478e+03
      1       9.386787e+02      -6.387991e+02 |        7
      2       8.901080e+02      -4.857079e+01 |        0
      3       8.901080e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 890.1079548438802)
â”Œ Info: K-means with 272 data points using 3 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.083359
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
â”” @ Core ./broadcast.jl:631
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
â”” @ Core ./broadcast.jl:631
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
â”” @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.881759
[ Info: iteration 2, lowerbound -3.764448
[ Info: iteration 3, lowerbound -3.621698
[ Info: iteration 4, lowerbound -3.426434
[ Info: iteration 5, lowerbound -3.181767
[ Info: iteration 6, lowerbound -2.914582
[ Info: iteration 7, lowerbound -2.677303
[ Info: dropping number of Gaussions to 7
[ Info: iteration 8, lowerbound -2.504743
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -2.391893
[ Info: iteration 10, lowerbound -2.340615
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.322796
[ Info: dropping number of Gaussions to 2
[ Info: iteration 12, lowerbound -2.306616
[ Info: iteration 13, lowerbound -2.299271
[ Info: iteration 14, lowerbound -2.299261
[ Info: iteration 15, lowerbound -2.299257
[ Info: iteration 16, lowerbound -2.299255
[ Info: iteration 17, lowerbound -2.299254
[ Info: iteration 18, lowerbound -2.299253
[ Info: iteration 19, lowerbound -2.299253
[ Info: iteration 20, lowerbound -2.299253
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: 48 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan 30 12:45:56 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan 30 12:46:05 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Thu Jan 30 12:46:08 2020: EM with 272 data points 0 iterations avll -2.083359
5.8 data points per parameter
, Thu Jan 30 12:46:10 2020: GMM converted to Variational GMM
, Thu Jan 30 12:46:18 2020: iteration 1, lowerbound -3.881759
, Thu Jan 30 12:46:18 2020: iteration 2, lowerbound -3.764448
, Thu Jan 30 12:46:18 2020: iteration 3, lowerbound -3.621698
, Thu Jan 30 12:46:18 2020: iteration 4, lowerbound -3.426434
, Thu Jan 30 12:46:18 2020: iteration 5, lowerbound -3.181767
, Thu Jan 30 12:46:18 2020: iteration 6, lowerbound -2.914582
, Thu Jan 30 12:46:18 2020: iteration 7, lowerbound -2.677303
, Thu Jan 30 12:46:19 2020: dropping number of Gaussions to 7
, Thu Jan 30 12:46:19 2020: iteration 8, lowerbound -2.504743
, Thu Jan 30 12:46:19 2020: dropping number of Gaussions to 6
, Thu Jan 30 12:46:19 2020: iteration 9, lowerbound -2.391893
, Thu Jan 30 12:46:19 2020: iteration 10, lowerbound -2.340615
, Thu Jan 30 12:46:19 2020: dropping number of Gaussions to 4
, Thu Jan 30 12:46:19 2020: iteration 11, lowerbound -2.322796
, Thu Jan 30 12:46:19 2020: dropping number of Gaussions to 2
, Thu Jan 30 12:46:19 2020: iteration 12, lowerbound -2.306616
, Thu Jan 30 12:46:19 2020: iteration 13, lowerbound -2.299271
, Thu Jan 30 12:46:19 2020: iteration 14, lowerbound -2.299261
, Thu Jan 30 12:46:19 2020: iteration 15, lowerbound -2.299257
, Thu Jan 30 12:46:19 2020: iteration 16, lowerbound -2.299255
, Thu Jan 30 12:46:19 2020: iteration 17, lowerbound -2.299254
, Thu Jan 30 12:46:19 2020: iteration 18, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 19, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 20, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 21, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 22, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 23, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 24, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 25, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 26, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 27, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 28, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 29, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 30, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 31, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 32, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 33, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 34, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 35, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 36, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 37, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 38, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 39, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 40, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 41, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 42, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 43, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 44, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 45, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 46, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: iteration 47, lowerbound -2.299253
, Thu Jan 30 12:46:19 2020: 48 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509222601382, 95.95490777398615]
Î² = [178.04509222601382, 95.95490777398615]
m = [4.250300733269911 79.28686694436185; 2.0002292577753704 53.8519871724613]
Î½ = [180.04509222601382, 97.95490777398615]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484843 -0.007644049042327528; 0.0 0.008581705166333562], [0.37587636119483764 -0.008953123827345972; 0.0 0.012748664777409383]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9997103928244361
avll from llpg:  -0.999710392824437
avll direct:     -0.999710392824437
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9825221056277414
avll from llpg:  -0.9825221056277412
avll direct:     -0.9825221056277412
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
  0.0781546   0.164056    -0.138996    -0.146038      0.0187531   -0.0397406   -0.0649137   -0.126896    -0.0460586   -0.000995518  -0.0814327   -0.0570366   -0.0264707   -0.11977     -0.0398467   -0.106769     0.0329608  -0.164224     0.175181      0.0132042   -0.00403337   0.0300731   -0.226324   -0.130601     0.0801969    0.00767277
  0.0650899  -0.108821     0.00541757   0.0498393     0.0754118    0.0936508    0.0386454    0.126392    -0.0211679    0.107027      0.0576691    0.137078    -0.0671188   -0.214686    -0.100001     0.0386738   -0.114102    0.166564     0.0423165    -0.120239     0.141044     0.063204    -0.0218782  -0.0156611   -0.0113163    0.0142618
  0.113032    0.0774285   -0.00715516  -0.053552     -0.0707057    0.0271616   -0.138568    -0.0313679   -0.140218     0.0946598     0.322094    -0.0419827   -0.120988    -0.0618196    0.240677    -0.0553909    0.105325   -0.0251325    0.156479      0.0760335    0.052019    -0.157793    -0.0647059  -0.0306137    0.152356     0.0625674
  0.0505789  -0.0761135   -0.130977     0.00805842    0.0485176    0.106296    -0.0468301   -0.206292     0.100586     0.0183839    -0.175989     0.0512575   -0.0221888    0.0802373    0.0224118   -0.117954    -0.0734531   0.0310361    0.0291843    -0.0133124    0.0420787   -0.125536     0.111238    0.0332534   -0.0174879   -0.0562499
  0.0103317  -0.0782225   -0.018567     0.0188834     0.130307     0.148739    -0.00408078  -0.122884    -0.0186353    0.0775826    -0.00843046  -0.126509    -0.0387798    0.0229528    0.0881981    0.149597     0.209438   -0.0170134    0.0253868     0.03096     -0.0318951   -0.0297091   -0.175095    0.00609648   0.135084     0.270349
  0.0331443   0.0620217   -0.0853208   -0.0711341    -0.0160217    0.0509495   -0.049987     0.195924     0.00642959  -0.00596124   -0.107443     0.0454523    0.00847365  -0.0592269    0.0324723    0.0061604    0.103776    0.0011968   -0.0522502     0.077331     0.0116291   -0.0258457    0.128388    0.0356591    0.244349     0.0957178
  0.0380271   0.136847     0.0504196    0.00834382   -0.0310424   -0.0873051    0.069359    -0.162414    -0.215797    -0.14599       0.143639     0.125247     0.0264007   -0.111832     0.120131    -0.00759331  -0.0334972   0.0529013    0.058542      0.0136145    0.0197226    0.00692736   0.0989202  -0.0866046   -0.039258    -0.115953
 -0.035587   -0.0277247   -0.00478258  -0.0335011    -0.0393444   -0.0578111    0.173284     0.015992     0.134881     0.0100413     0.00979504  -0.0277061    0.117744    -0.0348463   -0.0460628   -0.158913    -0.0110293   0.0965626    0.236947     -0.00707665   0.141062    -0.100973     0.0594653   0.00612478   0.0724054   -0.0143413
  0.011027   -0.0843692   -0.0626862    0.153544      0.0152976    0.067876     0.0324613   -0.103049     0.155307    -0.113174      0.0363396   -0.0504028   -0.127131    -0.0721325    0.0886058   -0.127851     0.0641319  -0.0690131    0.0110573    -0.211586    -0.029647    -0.0720837    0.0407336   0.0146571   -0.0933912   -0.106673
  0.0730863  -0.00364516   0.0152322    0.00328912   -0.0316982    0.0602735    0.0344487    0.0308315    0.130617     0.010903      0.0312902   -0.0310977    0.0700786   -0.0654811    0.21161      0.0583019   -0.111771   -0.17916     -0.0348422     0.0291399   -0.00372318   0.130779    -0.118716   -0.100522    -0.0170945   -0.0110689
 -0.059419   -0.0894632   -0.12424      0.140716     -0.0416084   -0.0514757    0.098492     0.0582571    0.195825     0.0257431     0.00350774   0.00814716  -0.0173961    0.174769    -0.0985387    0.0276289    0.0433189  -0.11562     -0.0303282    -0.0647836    0.0306833    0.114957    -0.0267899  -0.0449947    0.0172818    0.117912
  0.165154   -0.0535049    0.0205121    0.0525814    -0.0802606   -0.0793481    0.0050722    0.0844267   -0.101828     0.106418     -0.0403334    0.007653     0.109787     0.125108     0.167499    -0.15108      0.0585155  -0.121245     0.0219791     0.113644    -0.0531593   -0.123111     0.103795   -0.0105118    0.0954302   -0.0535274
  0.0243957   0.0376853    0.0122379    0.193111      0.133155     0.10369     -0.355468     0.0669671   -0.127348    -0.11938      -0.070585     0.0341774    0.141695    -0.00551417   0.169449     0.0840776   -0.0413562  -0.0694982   -0.0425702    -0.106453     0.0832228    0.0833673    0.141145    0.0715056   -0.161757    -0.116681
 -0.0638481   0.0702427    0.024332    -0.135782      0.114461     0.0210274   -0.0321579    0.0369088   -0.121999    -0.0207009    -0.0189694    0.180128     0.19291      0.0478199    0.0512426    0.156466    -0.0867902  -0.0475321    0.0289506     0.109891     0.0745974    0.174053    -0.0506989  -0.0570611   -0.0169927    0.195811
 -0.138866    0.065568    -0.0398708    0.000868645   0.0551419    0.0575424    0.174917     0.0603535    0.00177694  -0.0458794     0.080801     0.10247      0.0363062   -0.132542    -0.165264    -0.0609585    0.0647574   0.17417      0.0120658     0.0191467   -0.187859     0.0923285    0.0016244   0.0756826    0.0719263   -0.0293548
 -0.0140358   0.00271194  -0.0922904   -0.0351779     0.155395    -0.123852     0.016871    -0.11987     -0.113381     0.103955     -0.0709398   -0.138272     0.0716051    0.0105838    0.130112    -0.0354157   -0.0750381   0.0259324    0.0216729    -0.079234    -0.0503751    0.0207934    0.0319292   0.0204642    0.00762776  -0.0343588
  0.0416321   0.0803199    0.107682    -0.125895     -0.0650357   -0.13312     -0.0734454   -0.056918    -0.13426      0.135125      0.127572     0.0570503    0.0767384    0.040758     0.0272187    0.0415377   -0.160351   -0.121119    -0.126715      0.159389    -0.114397    -0.19917     -0.0658231  -0.0684125   -0.13132     -0.00259303
 -0.0901316   0.00511409   0.0122087    0.210816     -0.0388068    0.00528195  -0.110394     0.00878068  -0.0600673   -0.070982      0.0956071    0.0215859    0.0408787   -0.0913509    0.0429249   -0.00330401  -0.047096    0.0119691    0.148082     -0.0822561   -0.0870524   -0.142434    -0.024815   -0.0334591   -0.0354796    0.0438228
  0.0412695   0.0679147    0.101042    -0.063439     -0.099751     0.246335    -0.0443353   -0.019871     0.0515168    0.0657963     0.0649395    0.0115801   -0.024526     0.247529     0.0677207    0.111801     0.187752    0.0637176   -0.126191      0.0635923    0.0492898   -0.00815945  -0.0526912  -0.0938848   -0.049801    -0.0569957
  0.0286166   0.122334     0.0684706    0.0604883    -0.020491     0.0804132    0.0301985    0.170154     0.0207726    0.139878      0.0466643    0.0610592    0.147631     0.0382885    0.136645    -0.0107016   -0.124295    0.00231078   0.000135627  -0.0797309    0.0327033   -0.166078    -0.0469874  -0.0395794    0.0438713   -0.159326
  0.143226    0.0701702   -0.0261902    0.150477     -0.03893     -0.00825342   0.0194164    0.118152     0.149942     0.188977      0.17334      0.0171281    0.0679409   -0.0820749    0.00807252  -0.0709864    0.0841133  -0.0252282    0.108965      0.131845    -0.00867476   0.081989    -0.0816397  -0.293559    -0.173802    -0.00742517
 -0.175437    0.0109331   -0.161009    -0.132443      0.0442839   -0.0983533   -0.0968043   -0.0757456   -0.0531231   -0.128362     -0.136285    -0.00763211  -0.0653787    0.0560278   -0.060315     0.0127189    0.0976495  -0.00609591  -0.0415835    -0.0637401   -0.018318    -0.0297108    0.0724166   0.0370027   -0.22958     -0.0572009
  0.0335539   0.0155511    0.0789269    0.0318113    -0.143757    -0.0615922    0.0747484   -0.0119189   -0.192549     0.0531143     0.0390722   -0.139291    -0.133661    -0.160971    -0.0838438    0.123128    -0.13995    -0.0162922   -0.046153     -0.0260271    0.0974129   -0.180032     0.155186   -0.145589    -0.00506781   0.0229732
 -0.0780716   0.0123426   -0.0235569   -0.030377     -0.0279698    0.129329     0.0899503   -0.00684202  -0.0408174   -0.0296805     0.1345      -0.0422442    0.129831     0.108674    -0.0265963    0.122028    -0.23596    -0.0160648    0.0602557    -0.106777     0.0837145    0.164374    -0.0834973  -0.167086     0.00967627  -0.165992
 -0.176846   -0.192283    -0.0710429    0.128953     -0.0804773   -0.0476884   -0.0521941    0.10397     -0.00104251  -0.047975      0.255971    -0.164053    -0.0149897   -0.0220603   -0.148605     0.0191852   -0.0138699  -0.0589119   -0.106357      0.00679729  -0.26835     -0.0139466   -0.0308759   0.0606811    0.0636458    0.0639606
  0.0854422   0.0355688   -0.012191     0.0924936     0.109647     0.00699067  -0.0223928    0.0162906    0.00957467  -0.0574853     0.139763    -0.109844    -0.0515802    0.159754    -0.144649     0.151558    -0.0223894  -0.0688176    0.102035     -0.0605179   -0.17899     -0.129938    -0.14156     0.0185236    0.120097     0.0176265
  0.10754     0.0222686    0.152778    -0.0826003     0.026586    -0.0355705    0.0677188   -0.0473894    0.0829316    0.0722872    -0.0578361   -0.0249723   -0.121135     0.0337403   -0.0796284    0.151689    -0.0102123  -0.0160269   -0.104604      0.0125482    0.172838     0.25102      0.151724    0.130158    -0.0345859   -0.0489352
 -0.105119   -0.00844796   0.174782     0.21649       0.038014    -0.119345     0.075526    -0.214441    -0.0073651   -0.175508      0.120186    -0.00909333   0.0652198   -0.0345171   -0.110112     0.0217012    0.0229389  -0.0812375    0.0294922    -0.0406859    0.100669     0.0435127   -0.0721881   0.0255163   -0.034015     0.0376433
  0.0926233   0.0650941   -0.0787481   -0.165301     -0.0650751   -0.0123669    0.0543229    0.0872049   -0.052031    -0.0355415     0.103179     0.09953     -0.0301634   -0.0199346    0.0868806   -0.0471335   -0.110297    0.120578    -0.0606839     0.00804016  -0.142578     0.0249326   -0.0394195  -0.0583857   -0.0844863    0.0706401
 -0.100942    0.120489     0.0918837   -0.0159504     0.0443956    0.295602    -0.075635     0.0461959    0.0320421    0.334377     -0.087059    -0.163006     0.0881581   -0.00622819  -0.120177     0.100133     0.0800664  -0.174256     0.0646304    -0.0770875    0.0110895    0.164872    -0.107348   -0.200076    -0.134067    -0.103953
 -0.0620483  -0.0581316    0.0192061   -0.0411278    -0.00255757   0.18893     -0.0287802   -0.0257216   -0.0496949   -0.0212606    -0.224124     0.0341789   -0.0220878   -0.212815     0.120088     0.188689     0.0484178   0.12423      0.102457      0.0291417    0.0701478    0.110364     0.160436    0.143503     0.207749     0.0158247
 -0.0212637   0.146991    -0.0791218    0.00307828   -0.062307    -0.0149701    0.0144621    0.116103    -0.224612    -0.0261115    -0.0117594    0.00146685  -0.043795    -0.0336673    0.130962    -0.0627168    0.0854739   0.050248     0.072669     -0.0475275    0.0559188   -0.181536     0.0745042  -0.0321599   -0.0304992    0.240741kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4021014092184312
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.402181
[ Info: iteration 2, average log likelihood -1.402107
[ Info: iteration 3, average log likelihood -1.401716
[ Info: iteration 4, average log likelihood -1.396415
[ Info: iteration 5, average log likelihood -1.377993
[ Info: iteration 6, average log likelihood -1.368798
[ Info: iteration 7, average log likelihood -1.366927
[ Info: iteration 8, average log likelihood -1.365939
[ Info: iteration 9, average log likelihood -1.365294
[ Info: iteration 10, average log likelihood -1.364848
[ Info: iteration 11, average log likelihood -1.364503
[ Info: iteration 12, average log likelihood -1.364167
[ Info: iteration 13, average log likelihood -1.363743
[ Info: iteration 14, average log likelihood -1.363252
[ Info: iteration 15, average log likelihood -1.362946
[ Info: iteration 16, average log likelihood -1.362813
[ Info: iteration 17, average log likelihood -1.362750
[ Info: iteration 18, average log likelihood -1.362715
[ Info: iteration 19, average log likelihood -1.362693
[ Info: iteration 20, average log likelihood -1.362678
[ Info: iteration 21, average log likelihood -1.362668
[ Info: iteration 22, average log likelihood -1.362660
[ Info: iteration 23, average log likelihood -1.362654
[ Info: iteration 24, average log likelihood -1.362650
[ Info: iteration 25, average log likelihood -1.362648
[ Info: iteration 26, average log likelihood -1.362646
[ Info: iteration 27, average log likelihood -1.362644
[ Info: iteration 28, average log likelihood -1.362644
[ Info: iteration 29, average log likelihood -1.362643
[ Info: iteration 30, average log likelihood -1.362643
[ Info: iteration 31, average log likelihood -1.362642
[ Info: iteration 32, average log likelihood -1.362642
[ Info: iteration 33, average log likelihood -1.362642
[ Info: iteration 34, average log likelihood -1.362642
[ Info: iteration 35, average log likelihood -1.362642
[ Info: iteration 36, average log likelihood -1.362642
[ Info: iteration 37, average log likelihood -1.362642
[ Info: iteration 38, average log likelihood -1.362642
[ Info: iteration 39, average log likelihood -1.362642
[ Info: iteration 40, average log likelihood -1.362642
[ Info: iteration 41, average log likelihood -1.362642
[ Info: iteration 42, average log likelihood -1.362642
[ Info: iteration 43, average log likelihood -1.362642
[ Info: iteration 44, average log likelihood -1.362642
[ Info: iteration 45, average log likelihood -1.362642
[ Info: iteration 46, average log likelihood -1.362642
[ Info: iteration 47, average log likelihood -1.362642
[ Info: iteration 48, average log likelihood -1.362642
[ Info: iteration 49, average log likelihood -1.362642
[ Info: iteration 50, average log likelihood -1.362642
â”Œ Info: EM with 100000 data points 50 iterations avll -1.362642
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4021813536382466
â”‚     -1.4021073663408692
â”‚      â‹®
â””     -1.3626419450394662
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.362751
[ Info: iteration 2, average log likelihood -1.362656
[ Info: iteration 3, average log likelihood -1.362447
[ Info: iteration 4, average log likelihood -1.360180
[ Info: iteration 5, average log likelihood -1.348991
[ Info: iteration 6, average log likelihood -1.336114
[ Info: iteration 7, average log likelihood -1.331444
[ Info: iteration 8, average log likelihood -1.329932
[ Info: iteration 9, average log likelihood -1.329135
[ Info: iteration 10, average log likelihood -1.328639
[ Info: iteration 11, average log likelihood -1.328297
[ Info: iteration 12, average log likelihood -1.328013
[ Info: iteration 13, average log likelihood -1.327737
[ Info: iteration 14, average log likelihood -1.327437
[ Info: iteration 15, average log likelihood -1.327091
[ Info: iteration 16, average log likelihood -1.326693
[ Info: iteration 17, average log likelihood -1.326251
[ Info: iteration 18, average log likelihood -1.325787
[ Info: iteration 19, average log likelihood -1.325360
[ Info: iteration 20, average log likelihood -1.325010
[ Info: iteration 21, average log likelihood -1.324747
[ Info: iteration 22, average log likelihood -1.324565
[ Info: iteration 23, average log likelihood -1.324437
[ Info: iteration 24, average log likelihood -1.324344
[ Info: iteration 25, average log likelihood -1.324272
[ Info: iteration 26, average log likelihood -1.324211
[ Info: iteration 27, average log likelihood -1.324153
[ Info: iteration 28, average log likelihood -1.324096
[ Info: iteration 29, average log likelihood -1.324039
[ Info: iteration 30, average log likelihood -1.323984
[ Info: iteration 31, average log likelihood -1.323931
[ Info: iteration 32, average log likelihood -1.323879
[ Info: iteration 33, average log likelihood -1.323825
[ Info: iteration 34, average log likelihood -1.323770
[ Info: iteration 35, average log likelihood -1.323712
[ Info: iteration 36, average log likelihood -1.323651
[ Info: iteration 37, average log likelihood -1.323586
[ Info: iteration 38, average log likelihood -1.323517
[ Info: iteration 39, average log likelihood -1.323441
[ Info: iteration 40, average log likelihood -1.323356
[ Info: iteration 41, average log likelihood -1.323258
[ Info: iteration 42, average log likelihood -1.323144
[ Info: iteration 43, average log likelihood -1.323013
[ Info: iteration 44, average log likelihood -1.322863
[ Info: iteration 45, average log likelihood -1.322696
[ Info: iteration 46, average log likelihood -1.322519
[ Info: iteration 47, average log likelihood -1.322338
[ Info: iteration 48, average log likelihood -1.322159
[ Info: iteration 49, average log likelihood -1.321991
[ Info: iteration 50, average log likelihood -1.321840
â”Œ Info: EM with 100000 data points 50 iterations avll -1.321840
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3627507686284053
â”‚     -1.3626559126901434
â”‚      â‹®
â””     -1.3218401565868179
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.321904
[ Info: iteration 2, average log likelihood -1.321631
[ Info: iteration 3, average log likelihood -1.321042
[ Info: iteration 4, average log likelihood -1.315746
[ Info: iteration 5, average log likelihood -1.298640
[ Info: iteration 6, average log likelihood -1.282757
[ Info: iteration 7, average log likelihood -1.276181
[ Info: iteration 8, average log likelihood -1.273214
[ Info: iteration 9, average log likelihood -1.271124
[ Info: iteration 10, average log likelihood -1.269297
[ Info: iteration 11, average log likelihood -1.267710
[ Info: iteration 12, average log likelihood -1.266513
[ Info: iteration 13, average log likelihood -1.265696
[ Info: iteration 14, average log likelihood -1.265147
[ Info: iteration 15, average log likelihood -1.264741
[ Info: iteration 16, average log likelihood -1.264409
[ Info: iteration 17, average log likelihood -1.264137
[ Info: iteration 18, average log likelihood -1.263931
[ Info: iteration 19, average log likelihood -1.263791
[ Info: iteration 20, average log likelihood -1.263700
[ Info: iteration 21, average log likelihood -1.263641
[ Info: iteration 22, average log likelihood -1.263601
[ Info: iteration 23, average log likelihood -1.263574
[ Info: iteration 24, average log likelihood -1.263554
[ Info: iteration 25, average log likelihood -1.263541
[ Info: iteration 26, average log likelihood -1.263531
[ Info: iteration 27, average log likelihood -1.263523
[ Info: iteration 28, average log likelihood -1.263518
[ Info: iteration 29, average log likelihood -1.263514
[ Info: iteration 30, average log likelihood -1.263511
[ Info: iteration 31, average log likelihood -1.263509
[ Info: iteration 32, average log likelihood -1.263507
[ Info: iteration 33, average log likelihood -1.263505
[ Info: iteration 34, average log likelihood -1.263504
[ Info: iteration 35, average log likelihood -1.263504
[ Info: iteration 36, average log likelihood -1.263503
[ Info: iteration 37, average log likelihood -1.263502
[ Info: iteration 38, average log likelihood -1.263502
[ Info: iteration 39, average log likelihood -1.263502
[ Info: iteration 40, average log likelihood -1.263501
[ Info: iteration 41, average log likelihood -1.263501
[ Info: iteration 42, average log likelihood -1.263501
[ Info: iteration 43, average log likelihood -1.263501
[ Info: iteration 44, average log likelihood -1.263501
[ Info: iteration 45, average log likelihood -1.263501
[ Info: iteration 46, average log likelihood -1.263501
[ Info: iteration 47, average log likelihood -1.263501
[ Info: iteration 48, average log likelihood -1.263501
[ Info: iteration 49, average log likelihood -1.263501
[ Info: iteration 50, average log likelihood -1.263501
â”Œ Info: EM with 100000 data points 50 iterations avll -1.263501
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3219044863658218
â”‚     -1.321631278850436
â”‚      â‹®
â””     -1.263500575430568
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.263729
[ Info: iteration 2, average log likelihood -1.263424
[ Info: iteration 3, average log likelihood -1.261511
[ Info: iteration 4, average log likelihood -1.246590
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.215578
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.203778
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.193991
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚     12
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.182864
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.199571
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.194584
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.182737
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.188596
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.192791
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.186104
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.191626
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.183842
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚     12
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.178285
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.197192
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.186878
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.182921
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.188967
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚     12
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.179765
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.188248
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.192006
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.184457
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.179899
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.184784
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.189648
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.182557
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.189159
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.181097
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚     12
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.175360
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.194693
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.184511
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.180147
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.186132
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚     12
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.177267
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.185776
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.189367
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.182136
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.176929
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.181549
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.188087
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.180789
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.186734
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.179169
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚     12
â”‚     13
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.173207
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.192754
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      3
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.183288
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     14
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.178506
â”Œ Info: EM with 100000 data points 50 iterations avll -1.178506
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2637290006111734
â”‚     -1.263424143754751
â”‚      â‹®
â””     -1.1785064202291486
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.196018
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.167859
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     21
â”‚     25
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.157418
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     12
â”‚     21
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.166810
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.131289
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚     13
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.127522
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     12
â”‚     21
â”‚     23
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.141744
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     24
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.129836
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚      8
â”‚     13
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.116476
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     24
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.141203
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     25
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.122215
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚     13
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.126142
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.133232
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.129797
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚      8
â”‚     13
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.123557
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.135312
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.114912
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚     13
â”‚     21
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.139991
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     25
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.121535
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.115856
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚      8
â”‚     13
â”‚      â‹®
â”‚     24
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.122595
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.123800
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.106347
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚     13
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.122342
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.111084
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.117880
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚      8
â”‚     13
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.113470
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.123320
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.109045
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚     13
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.122665
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.110825
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.117881
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚      8
â”‚     13
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.113209
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.123297
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.108908
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚     13
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.122635
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.110775
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.117840
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚      8
â”‚     13
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.113279
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.122936
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.105700
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚     13
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.122555
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.110716
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.117807
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚      8
â”‚     13
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.113157
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.123218
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.108048
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚     13
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.119875
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.113993
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      5
â”‚      6
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     26
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.117774
â”Œ Info: EM with 100000 data points 50 iterations avll -1.117774
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.1960183357173464
â”‚     -1.167859344020103
â”‚      â‹®
â””     -1.1177739269988793
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4021014092184312
â”‚     -1.4021813536382466
â”‚     -1.4021073663408692
â”‚     -1.401715971335527
â”‚      â‹®
â”‚     -1.1198750084588964
â”‚     -1.1139928531021344
â””     -1.1177739269988793
32Ã—26 Array{Float64,2}:
  0.124828     0.0406215  -0.0690093  -0.191593    -0.0705246   -0.00923533    0.0560645     0.0869333   -0.0812306   -0.027423     0.0925986    0.101902    -0.0220892   -0.0323233     0.089757    -0.0513587   -0.103147      0.0721812  -0.0238422     0.0165458   -0.120891      0.0403299   -0.0407441  -0.0460202   -0.0844765    0.076034
  0.0223615    0.0892507   0.11955    -0.0884314   -0.0642      -0.131055     -0.0688543    -0.0558948   -0.0949632    0.177038     0.13276      0.0661038    0.0781501    0.0343893     0.00827883   0.103552    -0.161686     -0.135421   -0.118641      0.149725    -0.0887433    -0.165018    -0.0667285  -0.0650173   -0.183064    -0.00590723
 -0.0846472   -0.0853841  -0.164064    0.156072    -0.0501252   -0.0519572     0.0992631     0.0519928    0.250441     0.053285     0.034637     0.00022175  -0.00567008   0.167133     -0.123139     0.0232438    0.0211657    -0.0982182  -0.0231009    -0.0760479    0.0405833     0.117297    -0.0374429  -0.043705     0.0211504    0.138749
 -0.0518635    0.0136439   0.0298687  -0.092019     0.038174    -0.0159897     0.0737583     0.021742     0.00719678  -0.00612671  -0.00520539   0.0703905    0.151209     0.0127887     0.00311332  -0.01324     -0.0530854     0.0257717   0.134163      0.0592985    0.108073      0.0329108    0.0131529  -0.01987      0.0418734    0.0933971
  0.0226723    0.0809732  -0.157133    0.0853152    0.144267     0.227958     -0.348433      0.0636463   -0.142784    -0.115597    -0.0748531    0.0303321    0.143513    -0.000412631   0.220633     0.0235441    0.054493     -0.0611828   0.205512     -0.110117     0.0675633     0.0667732    0.325988    0.0714695   -0.192838    -0.122298
  0.0287071   -0.0714635   0.270288    0.445418     0.101616    -0.018734     -0.380361      0.0164888   -0.100227    -0.112964    -0.0835501    0.0469707    0.142281    -0.0108266     0.0852228    0.219079    -0.207119     -0.0486527  -0.476869     -0.108644     0.115365      0.114899    -0.195468    0.0711616    0.0781377   -0.114824
  0.00835713   0.163986    0.0500937   0.020227    -0.0261693   -0.0914603     0.0611404    -0.172331    -0.205415    -1.66308      0.160711     0.124718     0.0194407   -0.124829      0.129364    -0.0294065   -0.0379434     0.0993549   0.0416509     0.0710231    0.021616     -0.0471375    0.0815149  -0.0816648   -0.0349735   -0.126396
  0.0607424    0.057081    0.0602915   0.00279736  -0.0261091   -0.067095      0.0616564    -0.170066    -0.205729     1.55623      0.131817     0.122493     0.0278415   -0.0925056     0.122017     0.00464741  -0.0397323     0.0332166   0.0470466    -0.00684833   0.00972623    0.0162212    0.0722563  -0.0859551   -0.0321883   -0.10399
  0.113765     0.0120488   0.145855   -0.0766963    0.027344    -0.0505969     0.0704495    -0.0359474    0.0113421    0.0815879   -0.0489775   -0.030125    -0.0933619    0.0655881    -0.0752241    0.149355    -0.0204669    -0.0239261  -0.099505      0.0155744    0.167129      0.199118     0.151528    0.125466    -0.0394997   -0.0105618
  0.0940828   -0.01075     0.033339   -0.00566514  -0.0339882    0.0518868     0.0306346     0.0303408    0.138824    -0.00840898   0.0145076   -0.0277178    0.0236856   -0.0765804     0.199457     0.0614554   -0.110713     -0.149034   -0.035633      0.00560199  -0.00418458    0.175693    -0.125746   -0.0618146   -0.00728747  -0.0152335
  0.0843962    0.0356929  -0.0146057   0.0925299    0.107722     0.0118715    -0.023111      0.019115     0.0184768   -0.0584655    0.128669    -0.0772277   -0.0454893    0.151321     -0.148919     0.160912    -0.0460664    -0.0621036   0.11859      -0.0428554   -0.183124     -0.129996    -0.203418    0.0344455    0.119828     0.0139869
 -0.104578    -0.0119838   0.178751    0.26038      0.0371848   -0.106194      0.0753286    -0.218326    -0.0288143   -0.157003     0.115604     0.00167243   0.0889071   -0.0331824    -0.0965514   -0.0211226    0.0460481    -0.0815151   0.0100367    -0.0464431    0.089759      0.0336775   -0.0664337   0.00442851  -0.0111748    0.0393067
  0.0827955   -0.101867   -0.0321667   0.0307878    0.0754956    0.129436      0.0427688     0.135384    -0.0184417    0.103189     0.0528761    0.149434    -0.0314926   -0.21291      -0.0995833    0.0469118   -0.122832      0.165492    0.0541678    -0.135054     0.164865      0.0623825   -0.031771   -0.0162107   -0.012751    -0.0120861
 -0.0090181    0.0343456  -0.0845526  -0.0355683    0.150523    -0.0828341     0.0129276    -0.110937    -0.110752     0.103532    -0.0717081   -0.103896     0.0707317    0.0130622     0.130136    -0.0634281   -0.0661784     0.0231973   0.0198232    -0.0811746   -0.0576772     0.0222793    0.0560171   0.0195294    0.00568454  -0.0383005
 -0.171113    -0.0615898  -0.0426154  -0.0709476   -0.0820858   -0.15247      -0.000155991   0.0818809   -0.102581    -0.00238199  -0.085068     0.0852248   -0.0122694    0.105384      0.220225    -0.125424    -0.0118173    -0.142753    0.0314455     0.0960671   -0.0481114    -0.135381    -0.0722836  -0.0300104    0.133193    -0.0417662
  0.543376    -0.0360525   0.0662889   0.118259    -0.0750994   -0.040831      0.00838114    0.0828263   -0.107407     0.265054    -0.00719208  -0.107302     0.162027     0.127607      0.131651    -0.177985     0.134326     -0.0895606   0.0264473     0.113678    -0.000746913  -0.133395     0.262464    0.00419634   0.0592927   -0.0770439
 -0.115966    -0.0204782  -0.0537007   0.030018     0.0278088    0.0388553     0.0250351    -0.0254341   -0.0328704   -0.0386349    0.0333202    0.00195251   0.0208164   -0.0174974    -0.0165889    0.0444967    0.0214374     0.0230894   0.0567213    -0.0313928   -0.0404307    -0.00314637  -0.044863   -0.0213948   -0.0168076    0.0257652
  0.0222016   -0.0558536  -0.020122    0.0180651   -0.0546787    0.009802      0.0134384    -0.113835    -0.0718318    0.0226451   -0.0456695   -0.0518879   -0.0611752   -0.0304866    -0.034952     0.0127161   -0.086373      0.0068386  -0.0133609    -0.0190696    0.0687213    -0.136938     0.132276   -0.0565239    0.00942633  -0.000894806
  0.0119789    0.0747353  -0.027099   -0.0482942   -0.0710592    0.0939124    -0.0104186     0.0972177   -0.0481507    0.00782086  -0.0462664    0.028539    -0.01827      0.043676      0.075344     0.0189685    0.127739      0.0292597  -0.0321637     0.0370325    0.0519412    -0.0531613    0.0528432  -0.0188389    0.0637553    0.0936653
 -0.063003    -0.0723447   0.0346803  -0.0325341    0.00751678   0.178572     -0.0220087    -0.0452063   -0.0501399   -0.0233511   -0.212625     0.0246886   -0.0142134   -0.22322       0.125814     0.133902     0.0388499     0.0971826   0.118573      0.0448577    0.065594      0.112764     0.156227    0.139223     0.213632     0.0164096
  0.0187457    0.198571    0.0612358   0.0670058   -0.0431692    0.0795378     0.0256862     0.169358    -0.0080336    0.138465     0.0469822    0.0594684    0.141937     0.0434546     0.149506    -0.00904267  -0.0855048     0.0161622  -0.000519909  -0.0785755    0.008822     -0.106721    -0.0541791  -0.059791     0.0741817   -0.143463
  0.147056     0.0960874  -0.0282055   0.170482    -0.0230602    0.000113985   0.0201864     0.11683      0.145197     0.189245     0.176976     0.0709098    0.0670288   -0.118291      0.00039432  -0.0662626    0.116462     -0.0203906   0.0852248     0.130182     0.00961578    0.0628352   -0.0512516  -0.300214    -0.170626     0.00879678
 -0.254006     0.107684    0.326477   -0.0894436   -0.105242     0.448045      0.116041      0.0786448   -0.146219     0.233892    -0.0870272   -0.434404     0.0487478   -1.04577      -0.0311735   -0.222426     0.0785046    -0.202778    0.0553164    -0.174525    -0.0139501     0.181827    -0.172145   -0.0765122   -0.133055    -0.103489
 -0.0936626    0.121385   -0.0709919  -0.0016427    0.0831468    0.295906     -0.11986       0.0465327    0.0491007    0.351501    -0.0869436   -0.207716     0.0877511    0.285325     -0.158184     0.165868     0.0804098    -0.167478    0.0646737    -0.0618211    0.0500616     0.160525    -0.0731093  -0.213071    -0.133039    -0.104996
 -0.018154    -0.127123   -0.0542458   0.157512    -0.0812452    0.15748       0.0377578    -0.147268     0.15569     -0.112895     0.0386416   -0.0896673   -0.125901    -0.0889486     0.0710316   -0.118825     1.60018      -0.0631015   0.0119881    -0.337192    -0.103447     -0.0734564    0.0411075   0.0107475   -0.11105     -0.102234
 -0.0263297   -0.076626   -0.0684065   0.131458     0.133691    -0.049678      0.030235     -0.0627852    0.153936    -0.11299      0.0395013    0.00879249  -0.126157    -0.0693531     0.0966475   -0.137505    -1.41815      -0.0787321   0.0333198    -0.211907     0.016949     -0.0715675    0.0377444   0.118142    -0.0869223   -0.106663
 -0.1956      -0.189237   -0.0433123   0.108195    -0.0856576   -0.0476709    -0.105763      0.123374    -0.00793611  -0.0569227    0.367107    -0.161416    -0.0234147   -0.0575433    -0.143905     0.0894906   -0.0037537    -0.0474147   0.0575219    -0.0588896   -0.263242     -0.472867    -0.031671    0.0662078    0.046487     0.0666903
 -0.152736    -0.195978   -0.0833753   0.142285    -0.0800338   -0.0583654    -0.0484105     0.100687    -0.00383119  -0.0452979    0.312544    -0.158948    -0.0177016    0.0257273    -0.118257    -0.06618     -0.000201041  -0.0553472  -0.121906      0.0632909   -0.263787      0.379205    -0.0313425   0.0658059    0.0794905    0.0558492
  0.0769447    0.163827   -0.137864   -0.166881     0.0824265   -0.0287636    -0.0463933    -0.0904705   -0.0470912   -0.0120385   -0.0965392   -0.0911632   -0.0976568   -0.177322     -0.0401041   -0.116892     0.0334163    -0.159139    0.190723      0.0192131   -0.0036802     0.0396984   -0.225857   -0.129018     0.0882556    0.0253969
  0.0774261    0.164096   -0.137522   -0.0282442   -0.223794    -0.0852964    -0.0969356     0.109442    -0.0169377    0.127184     0.0446649    0.00883873   1.01392      0.165177      0.267134     0.3401       0.0130522    -0.202386    0.254557     -0.0857261   -0.0198691     0.137329    -0.225341   -0.140156     0.0192254   -0.206544
  0.245351     0.149514    0.178868   -0.0552539   -0.0602073    0.044473     -0.0812766    -0.0641557   -0.139115     0.126541     0.297171    -0.0387096   -0.125312    -0.0531272     0.192437    -0.0383994   -0.893161      0.0441071   0.150484      0.0310178    0.0272992    -0.137003    -0.0639971  -0.0112063    0.144932     0.062386
 -0.0252593    0.0256428  -0.179905   -0.0515143   -0.0607929   -0.0062273    -0.219393      0.00273848  -0.138963     0.0350759    0.304959    -0.0192232   -0.121097    -0.063362      0.240518    -0.0503543    1.0731       -0.0653773   0.264304      0.0827515    0.019578     -0.16618     -0.0635751  -0.0743815    0.137269     0.0604932[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚      8
â”‚     13
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.113252
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    19-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚      7
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.085747
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.098953
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    18-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚      7
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.096757
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚      8
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.101949
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    21-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚      7
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.082284
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚      8
â”‚     13
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.113203
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    19-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚      7
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.085591
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.098930
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    18-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      6
â”‚      7
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.096731
â”Œ Info: EM with 100000 data points 10 iterations avll -1.096731
â”” 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.464874e+05
      1       6.689004e+05      -1.775870e+05 |       32
      2       6.380535e+05      -3.084687e+04 |       32
      3       6.233057e+05      -1.474784e+04 |       32
      4       6.174165e+05      -5.889146e+03 |       32
      5       6.141597e+05      -3.256866e+03 |       32
      6       6.108680e+05      -3.291712e+03 |       32
      7       6.073767e+05      -3.491260e+03 |       32
      8       6.047987e+05      -2.577981e+03 |       32
      9       6.032208e+05      -1.577959e+03 |       32
     10       6.015666e+05      -1.654159e+03 |       32
     11       6.000546e+05      -1.512019e+03 |       32
     12       5.990580e+05      -9.965460e+02 |       32
     13       5.984704e+05      -5.876717e+02 |       32
     14       5.980135e+05      -4.568646e+02 |       32
     15       5.976399e+05      -3.736353e+02 |       32
     16       5.973870e+05      -2.528751e+02 |       32
     17       5.972051e+05      -1.819325e+02 |       32
     18       5.969991e+05      -2.059999e+02 |       32
     19       5.966187e+05      -3.803312e+02 |       32
     20       5.960123e+05      -6.064383e+02 |       32
     21       5.951172e+05      -8.950651e+02 |       32
     22       5.944557e+05      -6.615514e+02 |       32
     23       5.941221e+05      -3.335401e+02 |       32
     24       5.939504e+05      -1.717306e+02 |       32
     25       5.938802e+05      -7.025824e+01 |       31
     26       5.938486e+05      -3.157858e+01 |       32
     27       5.938329e+05      -1.564425e+01 |       32
     28       5.938259e+05      -7.059382e+00 |       29
     29       5.938206e+05      -5.310616e+00 |       26
     30       5.938170e+05      -3.516897e+00 |       25
     31       5.938142e+05      -2.827862e+00 |       21
     32       5.938129e+05      -1.358775e+00 |       17
     33       5.938120e+05      -8.775652e-01 |       20
     34       5.938112e+05      -8.279750e-01 |       18
     35       5.938104e+05      -7.464700e-01 |       15
     36       5.938098e+05      -5.997559e-01 |       13
     37       5.938092e+05      -5.705878e-01 |       10
     38       5.938085e+05      -7.523029e-01 |       15
     39       5.938074e+05      -1.043267e+00 |       12
     40       5.938069e+05      -5.336837e-01 |        8
     41       5.938067e+05      -1.957985e-01 |        4
     42       5.938065e+05      -1.623691e-01 |        3
     43       5.938065e+05      -5.853200e-02 |        2
     44       5.938065e+05      -3.650883e-02 |        0
     45       5.938065e+05       0.000000e+00 |        0
K-means converged with 45 iterations (objv = 593806.4521986907)
â”Œ Info: K-means with 32000 data points using 45 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.323248
[ Info: iteration 2, average log likelihood -1.294675
[ Info: iteration 3, average log likelihood -1.261593
[ Info: iteration 4, average log likelihood -1.222438
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.177849
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     12
â”‚     15
â”‚     20
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.141423
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     14
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.159037
[ Info: iteration 8, average log likelihood -1.151616
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      9
â”‚     20
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.086488
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     10
â”‚     12
â”‚     14
â”‚     15
â”‚     25
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.085493
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     16
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.133024
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.133012
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     20
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.093365
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚     10
â”‚     12
â”‚     14
â”‚     15
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.080409
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      9
â”‚     16
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.130034
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.131280
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     20
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.093030
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     12
â”‚     14
â”‚     15
â”‚     25
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.072380
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     16
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.137801
[ Info: iteration 20, average log likelihood -1.127354
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     12
â”‚     20
â”‚     23
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.075137
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      9
â”‚     10
â”‚     14
â”‚     15
â”‚     25
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.091350
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.152032
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     16
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.104628
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     12
â”‚     15
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.092915
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     14
â”‚     23
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.088044
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.127684
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     16
â”‚     17
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.086649
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     12
â”‚     15
â”‚     23
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.086863
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     14
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.133389
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.125869
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     16
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.078094
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚     12
â”‚     15
â”‚     17
â”‚     23
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.097524
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     14
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.117659
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.111077
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     16
â”‚     20
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.093890
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     12
â”‚     14
â”‚     15
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.111791
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.131177
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      9
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.104581
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚     12
â”‚     14
â”‚     16
â”‚     17
â”‚     20
â”‚     23
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.064866
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      2
â”‚     10
â”‚     15
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.129032
[ Info: iteration 42, average log likelihood -1.139075
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      9
â”‚     20
â”‚     25
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.073093
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚     10
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     17
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.068894
[ Info: iteration 45, average log likelihood -1.165646
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.115496
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     12
â”‚     20
â”‚     25
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.065989
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚     14
â”‚     15
â”‚     16
â”‚     17
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.105163
[ Info: iteration 49, average log likelihood -1.152935
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     20
â”‚     23
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.094187
â”Œ Info: EM with 100000 data points 50 iterations avll -1.094187
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0417852  -0.0331675    0.096616     0.0323134   -0.14393    -0.0601049   0.0798869   -0.0213442   -0.193362     0.0638131    0.0677975   -0.122155    -0.127245    -0.138833   -0.108106     0.121882    -0.146213     -0.0130397   -0.0523012   -0.00922384   0.0968904  -0.175683     0.172435    -0.144602     0.0423861   0.0155475
 -0.0551288   0.0339212    0.0909966    0.153158     0.0394342  -0.076322    0.052763    -0.219584    -0.0289474   -0.1381       0.0898489   -0.00845524   0.0642806   -0.0293255  -0.0816032   -0.0220641    0.0368613    -0.0919909    0.0357316   -0.0426654    0.0427156   0.0381319   -0.108973    -0.031896     0.0208842   0.0353432
  0.139966   -0.0295101    0.0274987    0.0144641   -0.0570293  -0.0268533   0.0159682    0.0584121    0.0119881    0.0697567   -0.0180967   -0.0200541    0.0458833    0.0221266   0.188139    -0.0484639   -0.0209529    -0.138352    -0.00325985   0.0604722   -0.0189391   0.013483    -0.011143    -0.0385742    0.0457451  -0.0321211
 -0.011273    0.0839376   -0.0970211    0.00382967  -0.0618698  -0.0196576   0.0822841    0.121089    -0.265436    -0.0241486   -0.367583     0.0386941   -0.0435409   -0.0366659   0.130114    -0.0106039    0.119826      0.049074     0.0595221   -0.0202996    0.0139714  -0.217439     0.0941518   -0.00806178  -0.0350129   0.295749
 -0.179837    0.0693469   -0.0552142    0.00885385   0.0450075   0.0748314   0.199991     0.0630368    0.0115241   -0.0279432    0.0690643    0.104153     0.0284013   -0.156667   -0.109043    -0.0609916    0.0657015     0.116415    -0.005456     0.0512914   -0.177499    0.0851068   -0.00776184   0.0853311    0.0446039  -0.0275197
  0.106622    0.0136165    0.149733    -0.0794077    0.0273177  -0.0516469   0.0705435   -0.0263975    0.0152208    0.0876469   -0.0445879   -0.0303538   -0.0987685    0.0674734  -0.0751517    0.147618    -0.019109     -0.0277843   -0.0991415    0.013406     0.172007    0.200905     0.143625     0.128721    -0.0476585  -0.0113082
 -0.135339    0.32327     -0.00833186   0.118995    -0.0413035   0.0302652  -0.0828741    0.103891    -0.107037    -0.036107     0.812833    -0.0787651    0.0940807   -0.0310691   0.255103    -0.17301      0.0523101     0.0456874    0.142444    -0.0629629    0.108526   -0.116269     0.0145726    0.00396022  -0.0168718   0.107891
  0.0375847   0.0628574    0.104854    -0.0801628   -0.0925295   0.236527   -0.0352625   -0.015893     0.0488728    0.0712685    0.0599645    0.0213789   -0.0443043    0.236653    0.0608395    0.112358     0.228848      0.0921509   -0.108723     0.0584071    0.0719616   0.0160425   -0.0507886   -0.091446    -0.039283   -0.0637771
 -0.114229    0.121016     0.00180325  -0.00934472   0.0453216   0.310637   -0.0841501    0.0556296    0.0293053    0.32831     -0.0818145   -0.230342     0.0821608    0.0518982  -0.1353       0.0967163    0.0812757    -0.166749     0.0651512   -0.0722499    0.0351281   0.160187    -0.0848984   -0.190204    -0.132945   -0.105481
 -0.165027   -0.186048    -0.0649853    0.12257     -0.0822878  -0.0638701  -0.0682012    0.110836    -0.00298561  -0.0502178    0.315122    -0.163656    -0.01583     -0.0175057  -0.147667    -0.0141435   -0.0100322    -0.0531145   -0.0217604    0.00764963  -0.264194   -7.45757e-5  -0.0345196    0.0570712    0.0707151   0.0641675
 -0.06478     0.0656994    0.0674255   -0.130778     0.11419     0.0213013  -0.028947     0.0419795   -0.145669    -0.0264392   -0.010506     0.185006     0.196238     0.0472351   0.0606505    0.145611    -0.111062     -0.0418801    0.0311038    0.107353     0.0605303   0.173581    -0.036959    -0.0528032    0.0113636   0.194346
 -0.0222262  -0.0990473   -0.0634941    0.145749     0.0266035   0.0529644   0.0337787   -0.104599     0.154151    -0.110962     0.0395123   -0.0419246   -0.122555    -0.0791328   0.0813838   -0.129056     0.091051     -0.0714215    0.0211621   -0.267389    -0.0425686  -0.0725946    0.0398563    0.0643732   -0.0976038  -0.103243
  0.0116813  -0.0689546   -0.0198796    0.0158956    0.130758    0.0925752   0.00690606  -0.132513    -0.0167289    0.0731307   -0.0126675   -0.145148    -0.0387926    0.0144113   0.0473823    0.150364     0.214471     -0.0308812    0.0113424    0.0215751   -0.0337241  -0.0918786   -0.218624     0.00655727   0.131755    0.278161
  0.0994023   0.132957    -0.113924    -0.118343     0.0833573  -0.0259915  -0.070332    -0.112423    -0.0392872    0.0322023   -0.162743    -0.123932    -0.0451063   -0.199106   -0.0339011   -0.0915238    0.0262822    -0.170443     0.286072     0.0341946   -0.0399746   0.0113402   -0.232604    -0.120528     0.0924566   0.0139443
 -0.0378062  -0.0319716   -0.0175845   -0.0420898   -0.0278901  -0.0434644   0.166262     0.0156062    0.160787     0.0212637    0.00286068  -0.0213028    0.11315     -0.0340698  -0.0563157   -0.148263    -0.0314293     0.0825515    0.214766     0.0155717    0.155947   -0.095754     0.0507894    0.00719099   0.0789062  -0.00782512
  0.0284256   0.223438     0.0765079    0.0664257   -0.0550209   0.0814757   0.027245     0.160208     0.00985433   0.13646      0.0326705    0.0628427    0.142203     0.0352726   0.245202    -0.0769604   -0.0957927     0.0218279   -0.0101113   -0.0759686    0.0388712  -0.136101    -0.064712    -0.0581069    0.145489   -0.181866
  0.0877375   0.0524416   -0.0317409    0.0684965    0.130702    0.0126035  -0.0226618    0.118047     0.0402255   -0.066684     0.17176     -0.0849749   -0.0419388    0.206693   -0.146456     0.182301    -0.0497124    -0.0732551    0.0858274   -0.0567487   -0.162121   -0.127781    -0.21495      0.032077     0.122474    0.015215
 -0.086017   -0.0795535   -0.0180966   -0.016275    -0.0228782   0.130993    0.0887051   -0.00437888  -0.0269625   -0.0138771    0.135451    -0.0515177    0.126684     0.109008   -0.0209411    0.122888    -0.233175     -0.00814035   0.0556876   -0.0992022    0.106098    0.159774    -0.0896204   -0.191933     0.0318462  -0.177711
 -0.0882699  -0.0792912   -0.16466      0.155438    -0.0514935  -0.0528191   0.0975996    0.0523483    0.262583     0.0576273    0.0450642    0.00154885  -0.0063509    0.168795   -0.127364     0.0223055    0.0201276    -0.0978825   -0.0235259   -0.0775591    0.0450275   0.114508    -0.034498    -0.0447077    0.021641    0.136462
  0.103582    0.0793754   -0.0113334   -0.0524133   -0.0701003   0.0129956  -0.151175    -0.0254764   -0.14068      0.0853606    0.308883    -0.0288961   -0.124969    -0.0675696   0.231178    -0.0542378    0.0960209    -0.0153009    0.191774     0.0622444    0.0250474  -0.155854    -0.0650141   -0.0384488    0.146965    0.0620571
  0.0467512  -0.0386836   -0.0485071    0.0103415    0.113696    0.0181019   0.0299612    0.0158868   -0.0672993    0.103669    -0.00293452   0.00928428   0.023475    -0.102161    0.0120606    0.00226496  -0.0960397     0.0892115    0.0443731   -0.106072     0.0429235   0.0348338   -0.00186649   0.00848559   0.0037549  -0.0246616
  0.0373142  -0.100928    -0.15188      0.0143469    0.0441284   0.11708    -0.0381033   -0.203903     0.100129     0.00348241  -0.18133      0.0294111    0.00363065   0.079037    0.037873    -0.124914    -0.0764252     0.0318444    0.0425943   -0.0101792    0.0354604  -0.124979     0.122482     0.0270577   -0.0193972  -0.0524218
  0.0254224   0.0281567    0.00113108   0.210772     0.123178    0.130092   -0.350949     0.044096    -0.131022    -0.114272    -0.0693864    0.0382838    0.142745    -0.0051679   0.161358     0.090101    -0.0433422    -0.0553265   -0.0401067   -0.107639     0.0867852   0.0768907    0.131247     0.0702911   -0.100829   -0.119468
  0.0305426   0.0447157   -0.0975592   -0.098389    -0.0680229   0.0327469  -0.0277009    0.190884    -0.0222572   -0.0142843   -0.137421     0.0662435   -0.00906141  -0.0671595   0.00410663   0.00986851   0.110624     -0.0317742   -0.0454654    0.0748738    0.0319808   0.00211193   0.129643     0.0310969    0.243955    0.147599
  0.160775    0.101643    -0.0290933    0.167569    -0.0261557  -0.0292752   0.0243604    0.11882      0.148295     0.187046     0.18822      0.0858541    0.0687535   -0.147495    0.00142889  -0.0710482    0.12135      -0.0236133    0.0797346    0.116677     0.0153058   0.0798746   -0.0573018   -0.301246    -0.190283    0.0141523
  0.0327807   0.110356     0.120857    -0.0732667   -0.0582332  -0.10212    -0.0842753   -0.0190371   -0.126226     0.191055     0.121763     0.0671996    0.0873866    0.108018    0.0128803    0.138004    -0.174778     -0.147609    -0.14625      0.121102    -0.108584   -0.202635    -0.0679517   -0.0630357   -0.181659   -0.0231412
 -0.0629431  -0.0685578    0.0314607   -0.0344168    0.010572    0.18372    -0.0248625   -0.0443638   -0.0518183   -0.0235606   -0.223089     0.0302451   -0.0138198   -0.237878    0.138207     0.148066     0.0430826     0.0967008    0.127829     0.0438569    0.0712922   0.114509     0.162086     0.148247     0.226392    0.0188693
  0.0224042   0.0939059    0.0964371    0.0359311   -0.0624674  -0.0543689   0.0214731    0.0349797   -0.107952     0.027957     0.163788     0.0835433    0.0901934   -0.111887    0.151752     0.00377887   0.000650869   0.0881197    0.0725058    0.072217     0.0876518  -0.184472    -0.0230346   -0.0623141   -0.0390068  -0.0582384
  0.115705    0.0393936   -0.0631494   -0.181804    -0.0704261  -0.0139297   0.0562552    0.079219    -0.0747709   -0.0219778    0.0950019    0.0989462   -0.016581    -0.0328933   0.0905025   -0.0354118   -0.105913      0.0636175   -0.0223989    0.0237067   -0.118326    0.0339543   -0.0413653   -0.0471934   -0.0896472   0.0748501
 -0.0703609   0.00863906  -0.00121257   0.212498    -0.0584124  -0.0131513  -0.103298     0.00567641  -0.0614767   -0.0736614    0.0851836    0.0323636    0.0400037   -0.0864314   0.0539652   -0.00687496  -0.0465626     0.0102682    0.21799     -0.0459719   -0.0803875  -0.108433    -0.00290389  -0.0247895   -0.0379161   0.037985
 -0.188797   -0.00819069  -0.162042    -0.117864     0.050843   -0.0917464  -0.0951876   -0.0768105   -0.0618417   -0.136919    -0.129809     0.0161581   -0.0616335    0.0619132  -0.0473064    0.0202118    0.0928373    -0.00503902  -0.0506297   -0.0925858   -0.0187489  -0.0214866    0.0758131    0.0161079   -0.220471   -0.0285664
  0.0357408   0.124647     0.0600962    0.0203183   -0.03034    -0.0870126   0.0672984   -0.170047    -0.210732    -0.15717      0.152594     0.126561     0.0223235   -0.113584    0.123668    -0.0244604   -0.0433618     0.0660804    0.0503592    0.0392785    0.0210621  -0.00148667   0.0915288   -0.0870903   -0.0388592  -0.120479[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     12
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.086218
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      2
â”‚      9
â”‚     10
â”‚     12
â”‚      â‹®
â”‚     17
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.025159
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     12
â”‚     14
â”‚      â‹®
â”‚     23
â”‚     25
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.038898
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      9
â”‚     10
â”‚     12
â”‚     15
â”‚     17
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.060319
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     12
â”‚     14
â”‚     16
â”‚     20
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.043990
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      2
â”‚      9
â”‚     10
â”‚     12
â”‚      â‹®
â”‚     26
â”‚     28
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.037590
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     12
â”‚     14
â”‚     16
â”‚     20
â”‚     23
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.051560
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      9
â”‚     10
â”‚     12
â”‚     15
â”‚     17
â”‚     25
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.054982
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      9
â”‚     10
â”‚     12
â”‚     14
â”‚     16
â”‚     25
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.038926
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      2
â”‚      9
â”‚     10
â”‚     12
â”‚      â‹®
â”‚     25
â”‚     26
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.023190
â”Œ Info: EM with 100000 data points 10 iterations avll -1.023190
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.06791      0.0169719   -0.0328905    0.0945446   -0.196469     -0.0574202    0.110658    -0.134827     -0.0422643    0.161613      0.0784076    0.0723779    -0.124356     0.108931     -0.00151139    0.139063    -0.0256861  -0.0921781    -0.0899246   -0.0359999    0.0429523   -0.0249201    0.070326     0.0958389   -0.119372     0.116606
  0.013926    -0.0302257   -0.00553718   0.0688263   -0.0296117     0.0528835   -0.0522698   -0.0860242     0.0309493   -0.00767036    0.13072     -0.090039     -0.138278    -0.0540622     0.193966     -0.0301984   -0.113232    0.0423237     0.0544725   -0.0123594    0.0410182    0.0705458   -0.0472834   -0.065159     0.276848    -0.0112929
  0.0417863    0.0214838   -0.128278    -0.00583351   0.0824811     0.151711     0.00142984  -0.0330439    -0.00315474  -0.101837      0.0823044   -0.00812381   -0.111655     0.0901615    -0.0152702    -0.0546122    0.0633802  -0.130128      0.0107185   -0.10755      0.00784183  -0.0240124   -0.00632475   0.00475564  -0.143341    -0.0226022
 -0.11018     -0.0868774   -0.0295164    0.0203768    0.00457884   -0.0283152   -0.200353    -0.171388     -0.0230334    0.10238      -0.0176472    0.0426999     0.0720155    0.0337488     0.0753521    -0.0514851   -0.131255   -0.215956      0.0141969    0.0613512   -0.126434    -0.00300694  -0.0179316   -0.0477699   -0.0313613    0.0523351
  0.0136668   -0.114609    -0.013319    -0.100752    -0.0312877    -0.143167     0.00670214   0.132075     -0.0686707   -0.092046      0.0963981   -0.0740049     0.250167    -0.0427684     0.112277      0.148195     0.0125185  -0.0587151    -0.0127213    0.0281232   -0.0843027   -0.154914     0.0693561    0.143464     0.122354     0.0389647
 -0.0185481   -0.0648821   -0.155553    -0.12814      0.00380097    0.130965    -0.0447771    0.135565     -0.0957515    0.0041945     0.185125     0.00539712    0.0841643    0.0146281    -0.0623201     0.0491959    0.108683   -0.160709      0.0100004    0.0603606   -0.0877829   -0.0888578    0.163479    -0.0526404   -0.130194     0.0194853
  0.0612121   -0.11231      0.145814    -0.0292144    0.0104798     0.00759172  -0.0942385    0.159523      0.158958    -0.0815403    -0.131995     0.182791      0.0231188   -0.0921472     0.00282656    0.0727978   -0.0109675  -0.0830085    -0.178244    -0.00270882   0.0303063   -0.132327    -0.112177    -0.0500753   -0.0662088    0.0641221
 -0.0801367    0.196043    -0.0248876   -0.00647232   0.109101     -0.0431561    0.0822212   -0.0599734    -0.0165496   -0.0432157    -0.172363    -0.0339343     0.210562     0.244888     -0.0531399     0.0503701    0.231699    0.140064     -0.0581907   -0.0354768   -0.0405273   -0.0846218   -0.0359091   -0.0410023    0.062641    -0.0571932
 -0.154689    -0.0842526   -0.108576    -0.0339272    0.0623509     0.0714731    0.0301205   -0.106759     -0.0301115   -0.0750122    -0.00629521   0.136522      0.087733     0.0341932    -0.0946095    -0.00428583   0.104543   -0.126006      0.148004     0.0488535   -0.0397634   -0.020013     0.0524065    0.0170794    0.0350413   -0.027254
  0.055498    -0.141611    -0.101734    -0.0674437   -0.107847      0.109634    -0.0732507   -0.1089        0.086741     0.0143416    -0.0631484    0.092827      0.0727893    0.000125313  -0.0649951     0.142116    -0.0883901   0.108117     -0.0682546   -0.0186985    0.0745907   -0.049574    -0.0475069   -0.133005     0.303112    -0.0245589
  0.00393505   0.00237888   0.128068     0.0847589    0.0134149     0.0885783   -0.0296851    0.0194314    -0.044213    -0.0755068     0.102868     0.0108907     0.136867     0.027459      0.15318      -0.00188794   0.0226763   0.0522022     0.0629922   -0.109798     0.0474208    0.209616    -0.156557    -0.173401     0.0424358    0.00860458
  0.0391794   -0.109413    -0.0788655   -0.053175     0.0678913     0.0726447    0.0165378    0.00351776   -0.195312     0.167168     -0.012894     0.037921     -0.0406288   -0.122808      0.149288     -0.0486301    0.0560422   0.0397286    -0.0371949   -0.107311     0.116618    -0.0680736    0.0691589    0.0108739   -0.00781119  -0.0457469
  0.00188891   0.0496699   -0.00851062   0.115138    -0.129116      0.125246    -0.00760544  -0.128657      0.119285    -0.117771      0.0363932   -0.101393      0.134112    -0.0247438    -0.126363      0.0502436   -0.0933086   0.142578      0.0734843   -0.12721     -0.2852       0.0699504    0.14129      0.00674138   0.0263103   -0.0191293
 -0.0140157    0.172035    -0.0561059   -0.0439073   -0.0107517     0.0254093   -0.0628482    0.0743248    -0.0581032    0.0286928     0.0927497    0.112878     -0.0745162   -0.154412      0.00294392    0.10413      0.0411905   0.00412643    0.108137     0.118828    -0.105059     0.157308     0.0199925   -0.168732    -0.0482641    0.09296
 -0.125858     0.109513     0.0613661    0.00480467  -0.173862     -0.178231    -0.0422016   -0.0844846     0.0617662   -0.199567     -0.0340759    0.0953746    -0.13067      0.0142847     0.0253542     0.0269935    0.104175   -0.102852     -0.0885361   -0.126655     0.0995278    0.132185    -0.0569258    0.0278771    0.149079     0.0418803
 -0.158891     0.0464467   -0.0841601    0.153763     0.0907422     0.172139     0.0134968    0.017783      0.0989052    0.00954036   -0.0215152   -0.0410998     0.00354458   0.0305639    -0.0749309     0.0731935   -0.164813    0.123282      0.15904      0.0304523   -0.115498    -0.0430702    0.150304     0.159816    -0.0821686   -0.0608401
  0.188775     0.135805    -0.161014     0.145269     0.149186      0.0328933    0.0314212    0.114042      0.270692    -0.110159     -0.142541     0.0818826    -0.0453449    0.123806      0.0253722     0.0162055   -0.1474     -0.119926      0.0520982    0.0899692    0.0305927    0.0697702    0.0626831    0.0452613   -0.0798804    0.272952
  0.00318232  -0.0141526   -0.00826213   0.0255932    0.0455217     0.150494    -0.0170626    0.0475919     0.129013     0.106293     -0.0985754    0.0542        0.141504     0.0326543    -0.058883      0.0492201   -0.0747456   0.0824531    -0.00771683  -0.125054    -0.118343    -0.0538772    0.151763    -0.0759225   -0.0337838    0.0331809
 -0.0589696   -0.110784     0.0415761    0.0657701    0.0609416    -0.0622652    0.099351     0.210734     -0.0414552    0.0239271     0.0132246    0.0996694    -0.0499615   -0.109962      0.0420453     0.0974614    0.113544    0.0505383     0.128515     0.00588333  -0.0759048   -0.218978    -0.0742097   -0.0770317    0.0281466    0.0494747
 -0.0344585    0.0909637    0.111663    -0.140949    -0.154557      0.12846     -0.0976945   -0.000462631   0.0677777   -0.0457301     0.0213337    0.136801     -4.33968e-5   0.0691029    -0.00632495    0.039681    -0.056253    0.0156031    -0.0541429   -0.0114569    0.0246436    0.0380519   -0.130833    -0.0154072    0.0136262   -0.16749
 -0.109115     0.0440153   -0.160577    -0.0313876   -0.072702     -0.0797       0.0781668    0.0261581     0.0484853   -0.116409     -0.0439359   -0.0654072    -0.00129189  -0.0151037     0.0825679     0.0143484   -0.0832317  -0.00569615   -0.0241227   -0.154472    -0.118403     0.0835568   -0.00622078  -0.146235    -0.00908318  -0.097199
 -0.0850778   -0.0502359    0.11374     -0.0713894   -0.0231163    -0.0681582    0.0262227    0.00740144    0.10534     -0.000957776   0.0696022    0.21602       0.0809351    0.055784     -0.0598537     0.0514916   -0.0107403   0.000178783   0.15683      0.0470256    0.194364    -0.0206966   -0.0459139    0.112803    -0.0199105   -0.0390484
 -0.195457     0.0861618    0.00454984   0.219414    -0.0156019    -0.140302    -0.0501336    0.0028701    -0.0994446   -0.0108478     0.0368105   -0.124811      0.0851889   -0.107574      0.0297453     0.0635623    0.0403452   0.111732     -0.0646666    0.0407559   -0.0339872    0.00790713  -0.00627579  -0.0369346   -0.0881219   -0.0365659
 -0.00522276  -0.161392    -0.0176205   -0.031779     0.137897     -0.0903391    0.290771     0.115273      0.00463986  -0.0802112    -0.120949    -0.00657443    0.0038603    0.231974     -0.0339002    -0.0529464   -0.0945067   0.0519319    -0.100612     0.0269748   -0.0159842    0.00571679  -0.0173196   -0.0612243    0.0370327   -0.151516
  0.0569278    0.114501     0.0584783    0.0768664    0.0303702    -0.0435365   -0.161552    -0.0232281     0.165841    -0.144952     -0.085739    -0.11192      -0.0249275   -0.116871     -0.107588      0.115141    -0.0533652  -0.022979     -0.0239693    0.113457    -0.0471095    0.0368895   -0.106582    -0.0191432   -0.021256    -0.0687686
 -0.0933284   -0.0748001    0.148029     0.0391553    0.0345894     0.0414286   -0.0902128    0.0807371     0.111957     0.0657966    -0.1342      -0.0119627    -0.0987198   -0.11181       0.00700747    0.0958234    0.0649198   0.0744762     0.0808088    0.132501     0.0735483   -0.0548275    0.222348     0.147471    -0.0227515    0.150978
 -0.0401396    0.129743    -0.0512281    0.0421001   -0.000647877   0.128416    -0.0325876   -0.173144      0.134743     0.0139677     0.116238    -0.0566546     0.0444025    0.0603529     0.00419846   -0.223219    -0.0816468  -0.00332492    0.0570616   -0.0571994   -0.125775     0.0605602    0.0151949    0.107195     0.0857041    0.017678
 -0.0752642    0.0584456    0.0742992    0.0139603   -0.0229957     0.083264     0.0521334   -0.0973057     0.0744007   -0.22517       0.13378      0.00320388    0.00331267   0.174504     -0.000828819  -0.168975     0.12824    -0.0479785    -0.201495    -0.237726     0.116097     0.085363     0.0242792    0.112409     0.0482406    0.0448933
 -0.00092361  -0.0683847   -0.158224    -0.146231     0.113164      0.129809     0.0450471    0.0391718    -0.17378     -0.11273      -0.100573     0.000124928  -0.0343478   -0.113871      0.0886106     0.0180167    0.0126323   0.0880736     0.0637813    0.00256836  -0.00789165   0.199473     0.111936    -0.0169503    0.132305     0.126181
 -0.0508489    0.0266769    0.131814    -0.0109977    0.059672     -0.0266339    0.024246    -0.00093638    0.133523     0.0102356     0.0746233   -0.0393456     0.107949     0.0658165     0.153874      0.144421     0.124761    0.0307747    -0.0305101   -0.264952    -0.235592     0.0944726    0.128467    -0.125889    -0.00183441   0.0230752
  0.30105     -0.0362088   -0.00204513  -0.0339476   -0.0558904     0.0887145    0.0151127   -0.0764752    -0.0907729   -0.13186       0.0491856   -0.073123      0.0070408    0.098856      0.0597274    -0.0155944    0.0868396  -0.00134789    0.100532     0.0559605    0.11181     -0.0951197    0.0295903   -0.0441258    0.176772    -0.0607545
 -0.10503     -0.0610382   -0.0275173   -0.133935     0.0827961    -0.0537771   -0.0293436   -0.0282437    -0.0708498    0.122432     -0.147386    -0.114284     -0.00109739  -0.0515287     0.165574     -0.0129206    0.114621    0.0732145    -0.0807905   -0.0785349    0.0311939   -0.103087    -0.00710504   0.150333     0.0810866   -0.102607kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4353265654613512
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.435347
[ Info: iteration 2, average log likelihood -1.435281
[ Info: iteration 3, average log likelihood -1.435229
[ Info: iteration 4, average log likelihood -1.435164
[ Info: iteration 5, average log likelihood -1.435086
[ Info: iteration 6, average log likelihood -1.434992
[ Info: iteration 7, average log likelihood -1.434884
[ Info: iteration 8, average log likelihood -1.434752
[ Info: iteration 9, average log likelihood -1.434566
[ Info: iteration 10, average log likelihood -1.434256
[ Info: iteration 11, average log likelihood -1.433719
[ Info: iteration 12, average log likelihood -1.432886
[ Info: iteration 13, average log likelihood -1.431875
[ Info: iteration 14, average log likelihood -1.431004
[ Info: iteration 15, average log likelihood -1.430474
[ Info: iteration 16, average log likelihood -1.430224
[ Info: iteration 17, average log likelihood -1.430120
[ Info: iteration 18, average log likelihood -1.430077
[ Info: iteration 19, average log likelihood -1.430060
[ Info: iteration 20, average log likelihood -1.430052
[ Info: iteration 21, average log likelihood -1.430049
[ Info: iteration 22, average log likelihood -1.430048
[ Info: iteration 23, average log likelihood -1.430047
[ Info: iteration 24, average log likelihood -1.430047
[ Info: iteration 25, average log likelihood -1.430046
[ Info: iteration 26, average log likelihood -1.430046
[ Info: iteration 27, average log likelihood -1.430046
[ Info: iteration 28, average log likelihood -1.430046
[ Info: iteration 29, average log likelihood -1.430045
[ Info: iteration 30, average log likelihood -1.430045
[ Info: iteration 31, average log likelihood -1.430045
[ Info: iteration 32, average log likelihood -1.430045
[ Info: iteration 33, average log likelihood -1.430045
[ Info: iteration 34, average log likelihood -1.430045
[ Info: iteration 35, average log likelihood -1.430045
[ Info: iteration 36, average log likelihood -1.430045
[ Info: iteration 37, average log likelihood -1.430045
[ Info: iteration 38, average log likelihood -1.430045
[ Info: iteration 39, average log likelihood -1.430045
[ Info: iteration 40, average log likelihood -1.430045
[ Info: iteration 41, average log likelihood -1.430045
[ Info: iteration 42, average log likelihood -1.430045
[ Info: iteration 43, average log likelihood -1.430044
[ Info: iteration 44, average log likelihood -1.430044
[ Info: iteration 45, average log likelihood -1.430044
[ Info: iteration 46, average log likelihood -1.430044
[ Info: iteration 47, average log likelihood -1.430044
[ Info: iteration 48, average log likelihood -1.430044
[ Info: iteration 49, average log likelihood -1.430044
[ Info: iteration 50, average log likelihood -1.430044
â”Œ Info: EM with 100000 data points 50 iterations avll -1.430044
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4353466698901078
â”‚     -1.4352813589869984
â”‚      â‹®
â””     -1.4300443334967992
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.430064
[ Info: iteration 2, average log likelihood -1.429997
[ Info: iteration 3, average log likelihood -1.429943
[ Info: iteration 4, average log likelihood -1.429877
[ Info: iteration 5, average log likelihood -1.429798
[ Info: iteration 6, average log likelihood -1.429710
[ Info: iteration 7, average log likelihood -1.429619
[ Info: iteration 8, average log likelihood -1.429536
[ Info: iteration 9, average log likelihood -1.429466
[ Info: iteration 10, average log likelihood -1.429410
[ Info: iteration 11, average log likelihood -1.429367
[ Info: iteration 12, average log likelihood -1.429331
[ Info: iteration 13, average log likelihood -1.429301
[ Info: iteration 14, average log likelihood -1.429273
[ Info: iteration 15, average log likelihood -1.429246
[ Info: iteration 16, average log likelihood -1.429218
[ Info: iteration 17, average log likelihood -1.429190
[ Info: iteration 18, average log likelihood -1.429160
[ Info: iteration 19, average log likelihood -1.429129
[ Info: iteration 20, average log likelihood -1.429098
[ Info: iteration 21, average log likelihood -1.429067
[ Info: iteration 22, average log likelihood -1.429038
[ Info: iteration 23, average log likelihood -1.429011
[ Info: iteration 24, average log likelihood -1.428987
[ Info: iteration 25, average log likelihood -1.428966
[ Info: iteration 26, average log likelihood -1.428949
[ Info: iteration 27, average log likelihood -1.428935
[ Info: iteration 28, average log likelihood -1.428923
[ Info: iteration 29, average log likelihood -1.428914
[ Info: iteration 30, average log likelihood -1.428907
[ Info: iteration 31, average log likelihood -1.428902
[ Info: iteration 32, average log likelihood -1.428897
[ Info: iteration 33, average log likelihood -1.428894
[ Info: iteration 34, average log likelihood -1.428891
[ Info: iteration 35, average log likelihood -1.428889
[ Info: iteration 36, average log likelihood -1.428887
[ Info: iteration 37, average log likelihood -1.428885
[ Info: iteration 38, average log likelihood -1.428884
[ Info: iteration 39, average log likelihood -1.428883
[ Info: iteration 40, average log likelihood -1.428882
[ Info: iteration 41, average log likelihood -1.428881
[ Info: iteration 42, average log likelihood -1.428880
[ Info: iteration 43, average log likelihood -1.428880
[ Info: iteration 44, average log likelihood -1.428879
[ Info: iteration 45, average log likelihood -1.428878
[ Info: iteration 46, average log likelihood -1.428878
[ Info: iteration 47, average log likelihood -1.428878
[ Info: iteration 48, average log likelihood -1.428877
[ Info: iteration 49, average log likelihood -1.428877
[ Info: iteration 50, average log likelihood -1.428877
â”Œ Info: EM with 100000 data points 50 iterations avll -1.428877
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4300642209279004
â”‚     -1.4299972448560403
â”‚      â‹®
â””     -1.428876726529114
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428890
[ Info: iteration 2, average log likelihood -1.428839
[ Info: iteration 3, average log likelihood -1.428796
[ Info: iteration 4, average log likelihood -1.428744
[ Info: iteration 5, average log likelihood -1.428680
[ Info: iteration 6, average log likelihood -1.428603
[ Info: iteration 7, average log likelihood -1.428517
[ Info: iteration 8, average log likelihood -1.428425
[ Info: iteration 9, average log likelihood -1.428337
[ Info: iteration 10, average log likelihood -1.428257
[ Info: iteration 11, average log likelihood -1.428189
[ Info: iteration 12, average log likelihood -1.428132
[ Info: iteration 13, average log likelihood -1.428086
[ Info: iteration 14, average log likelihood -1.428048
[ Info: iteration 15, average log likelihood -1.428016
[ Info: iteration 16, average log likelihood -1.427989
[ Info: iteration 17, average log likelihood -1.427964
[ Info: iteration 18, average log likelihood -1.427941
[ Info: iteration 19, average log likelihood -1.427919
[ Info: iteration 20, average log likelihood -1.427898
[ Info: iteration 21, average log likelihood -1.427878
[ Info: iteration 22, average log likelihood -1.427857
[ Info: iteration 23, average log likelihood -1.427837
[ Info: iteration 24, average log likelihood -1.427817
[ Info: iteration 25, average log likelihood -1.427798
[ Info: iteration 26, average log likelihood -1.427780
[ Info: iteration 27, average log likelihood -1.427763
[ Info: iteration 28, average log likelihood -1.427746
[ Info: iteration 29, average log likelihood -1.427731
[ Info: iteration 30, average log likelihood -1.427717
[ Info: iteration 31, average log likelihood -1.427704
[ Info: iteration 32, average log likelihood -1.427692
[ Info: iteration 33, average log likelihood -1.427682
[ Info: iteration 34, average log likelihood -1.427672
[ Info: iteration 35, average log likelihood -1.427664
[ Info: iteration 36, average log likelihood -1.427656
[ Info: iteration 37, average log likelihood -1.427648
[ Info: iteration 38, average log likelihood -1.427642
[ Info: iteration 39, average log likelihood -1.427636
[ Info: iteration 40, average log likelihood -1.427631
[ Info: iteration 41, average log likelihood -1.427626
[ Info: iteration 42, average log likelihood -1.427621
[ Info: iteration 43, average log likelihood -1.427617
[ Info: iteration 44, average log likelihood -1.427613
[ Info: iteration 45, average log likelihood -1.427609
[ Info: iteration 46, average log likelihood -1.427605
[ Info: iteration 47, average log likelihood -1.427602
[ Info: iteration 48, average log likelihood -1.427599
[ Info: iteration 49, average log likelihood -1.427596
[ Info: iteration 50, average log likelihood -1.427593
â”Œ Info: EM with 100000 data points 50 iterations avll -1.427593
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4288898279187796
â”‚     -1.4288390596748806
â”‚      â‹®
â””     -1.4275926535065733
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427600
[ Info: iteration 2, average log likelihood -1.427552
[ Info: iteration 3, average log likelihood -1.427510
[ Info: iteration 4, average log likelihood -1.427462
[ Info: iteration 5, average log likelihood -1.427402
[ Info: iteration 6, average log likelihood -1.427330
[ Info: iteration 7, average log likelihood -1.427244
[ Info: iteration 8, average log likelihood -1.427146
[ Info: iteration 9, average log likelihood -1.427040
[ Info: iteration 10, average log likelihood -1.426931
[ Info: iteration 11, average log likelihood -1.426823
[ Info: iteration 12, average log likelihood -1.426721
[ Info: iteration 13, average log likelihood -1.426626
[ Info: iteration 14, average log likelihood -1.426540
[ Info: iteration 15, average log likelihood -1.426463
[ Info: iteration 16, average log likelihood -1.426395
[ Info: iteration 17, average log likelihood -1.426334
[ Info: iteration 18, average log likelihood -1.426280
[ Info: iteration 19, average log likelihood -1.426233
[ Info: iteration 20, average log likelihood -1.426191
[ Info: iteration 21, average log likelihood -1.426154
[ Info: iteration 22, average log likelihood -1.426120
[ Info: iteration 23, average log likelihood -1.426090
[ Info: iteration 24, average log likelihood -1.426062
[ Info: iteration 25, average log likelihood -1.426037
[ Info: iteration 26, average log likelihood -1.426014
[ Info: iteration 27, average log likelihood -1.425992
[ Info: iteration 28, average log likelihood -1.425971
[ Info: iteration 29, average log likelihood -1.425951
[ Info: iteration 30, average log likelihood -1.425932
[ Info: iteration 31, average log likelihood -1.425913
[ Info: iteration 32, average log likelihood -1.425895
[ Info: iteration 33, average log likelihood -1.425878
[ Info: iteration 34, average log likelihood -1.425861
[ Info: iteration 35, average log likelihood -1.425844
[ Info: iteration 36, average log likelihood -1.425828
[ Info: iteration 37, average log likelihood -1.425812
[ Info: iteration 38, average log likelihood -1.425797
[ Info: iteration 39, average log likelihood -1.425782
[ Info: iteration 40, average log likelihood -1.425767
[ Info: iteration 41, average log likelihood -1.425753
[ Info: iteration 42, average log likelihood -1.425739
[ Info: iteration 43, average log likelihood -1.425725
[ Info: iteration 44, average log likelihood -1.425712
[ Info: iteration 45, average log likelihood -1.425699
[ Info: iteration 46, average log likelihood -1.425687
[ Info: iteration 47, average log likelihood -1.425675
[ Info: iteration 48, average log likelihood -1.425663
[ Info: iteration 49, average log likelihood -1.425651
[ Info: iteration 50, average log likelihood -1.425640
â”Œ Info: EM with 100000 data points 50 iterations avll -1.425640
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4275998725938281
â”‚     -1.427552172796051
â”‚      â‹®
â””     -1.4256395597662777
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425637
[ Info: iteration 2, average log likelihood -1.425578
[ Info: iteration 3, average log likelihood -1.425523
[ Info: iteration 4, average log likelihood -1.425461
[ Info: iteration 5, average log likelihood -1.425387
[ Info: iteration 6, average log likelihood -1.425297
[ Info: iteration 7, average log likelihood -1.425189
[ Info: iteration 8, average log likelihood -1.425066
[ Info: iteration 9, average log likelihood -1.424930
[ Info: iteration 10, average log likelihood -1.424787
[ Info: iteration 11, average log likelihood -1.424645
[ Info: iteration 12, average log likelihood -1.424507
[ Info: iteration 13, average log likelihood -1.424379
[ Info: iteration 14, average log likelihood -1.424262
[ Info: iteration 15, average log likelihood -1.424158
[ Info: iteration 16, average log likelihood -1.424065
[ Info: iteration 17, average log likelihood -1.423983
[ Info: iteration 18, average log likelihood -1.423911
[ Info: iteration 19, average log likelihood -1.423847
[ Info: iteration 20, average log likelihood -1.423790
[ Info: iteration 21, average log likelihood -1.423738
[ Info: iteration 22, average log likelihood -1.423692
[ Info: iteration 23, average log likelihood -1.423649
[ Info: iteration 24, average log likelihood -1.423609
[ Info: iteration 25, average log likelihood -1.423573
[ Info: iteration 26, average log likelihood -1.423539
[ Info: iteration 27, average log likelihood -1.423507
[ Info: iteration 28, average log likelihood -1.423477
[ Info: iteration 29, average log likelihood -1.423449
[ Info: iteration 30, average log likelihood -1.423423
[ Info: iteration 31, average log likelihood -1.423398
[ Info: iteration 32, average log likelihood -1.423374
[ Info: iteration 33, average log likelihood -1.423352
[ Info: iteration 34, average log likelihood -1.423331
[ Info: iteration 35, average log likelihood -1.423310
[ Info: iteration 36, average log likelihood -1.423291
[ Info: iteration 37, average log likelihood -1.423272
[ Info: iteration 38, average log likelihood -1.423254
[ Info: iteration 39, average log likelihood -1.423237
[ Info: iteration 40, average log likelihood -1.423220
[ Info: iteration 41, average log likelihood -1.423204
[ Info: iteration 42, average log likelihood -1.423189
[ Info: iteration 43, average log likelihood -1.423174
[ Info: iteration 44, average log likelihood -1.423159
[ Info: iteration 45, average log likelihood -1.423145
[ Info: iteration 46, average log likelihood -1.423132
[ Info: iteration 47, average log likelihood -1.423119
[ Info: iteration 48, average log likelihood -1.423106
[ Info: iteration 49, average log likelihood -1.423093
[ Info: iteration 50, average log likelihood -1.423081
â”Œ Info: EM with 100000 data points 50 iterations avll -1.423081
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4256371937885333
â”‚     -1.4255779144270357
â”‚      â‹®
â””     -1.4230810807247725
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4353265654613512
â”‚     -1.4353466698901078
â”‚     -1.4352813589869984
â”‚     -1.4352285075628044
â”‚      â‹®
â”‚     -1.4231057616212262
â”‚     -1.4230932752997247
â””     -1.4230810807247725
32Ã—26 Array{Float64,2}:
 -0.510798   -0.093454   -0.0527974    0.0123186   -0.126999    0.00120694   0.00636649   0.292282    -0.0266923   0.112496   -0.0343823  -0.062509     0.0171735    0.0764283  -0.196305    -0.00172148  -0.0542463   -0.0981656  -0.10589    -0.0603068    0.1125      0.0821946    0.225579   -0.275949    0.0347672  -0.244204
  0.158279    0.0679353   0.0927048    0.0185724   -0.0629951  -0.0500248   -0.0160821   -0.2028      -0.186409   -0.0018232  -0.0238509   0.0140681   -0.0575262   -0.117265    0.0367003    0.0790766   -0.0591983   -0.0286327  -0.241065   -0.0720532   -0.104638   -0.0542382   -0.0364852   0.0136948   0.0448764   0.0768951
 -0.81472     0.156852    0.00652748  -0.430782    -0.301521    0.101514    -0.337568     0.135578    -0.197739   -0.637144   -0.181738   -0.0798937    0.360265    -0.206727    0.067289    -0.0956547    0.41019      0.283013   -0.0406782  -0.365801     0.193071    0.0107919   -0.116096   -0.0557914   0.0592675   0.184981
 -0.103995   -0.254613    0.0865293   -0.489851     0.380585    0.191328    -0.00101012   0.118169     0.213087   -0.386167   -0.288778    0.0201377    0.06773     -0.308088    0.333967    -0.398627     0.413801    -0.0364889   0.251122    0.185882    -0.0645622  -0.312423     0.0678482   0.158307    0.0289172   0.275055
  0.17294    -0.816528   -0.0650541    0.164395    -0.554492   -0.712659    -0.192893     0.361708     0.330755   -0.137183   -0.125023   -0.298704    -0.111122     0.148417   -0.441936     0.32091      0.176322    -0.064941    0.118184    0.316129     0.40077     0.371893    -0.480262    0.564928    0.014216   -0.130224
  0.066207   -0.46061    -0.12851     -0.32276     -0.0340496   0.302383     0.0154103    0.230667     0.0666717   0.0537551   0.293048   -0.558328    -0.298724     0.15911    -0.40155     -0.561008    -0.340249    -0.27278    -0.141126   -0.0676922   -0.402293    0.351094    -0.455259    0.24246    -0.212679    0.348595
 -0.0927929   0.308897   -0.267537     0.0503447    0.0187674  -0.258505    -0.198731     0.00842339   0.165971   -0.595616   -0.106357   -0.0245464   -0.15946     -0.430857   -0.251082    -0.899261     0.0713645   -0.926973   -0.208078   -0.122611     0.115587   -0.0922896   -0.172702    0.463437    0.0862191   0.0555721
  0.492909    0.195774   -0.026665     0.377846     0.0461024   0.155149     0.360276     0.227924     0.423551   -0.557497    0.0130966   0.0190506   -0.0973165    0.142915   -0.134852    -0.0451627   -0.0535939   -0.26476    -0.1245      0.124634     0.113507    0.52637      0.304124    0.360863    0.234358    0.48558
  0.132473    0.226186    0.0745168    0.0726407    0.734971    0.678006     0.00132635  -0.0245069   -0.135122   -0.423122   -0.0832548   0.435382     0.834433     0.179404   -0.412916    -0.238639    -0.194795     0.344843    0.633262    0.0575594    0.157648    0.186866    -0.657364    0.353997    0.293195    0.314077
 -0.217212    0.200977   -0.488155     0.76399      0.490014    0.367765     0.0255952    0.0269683    0.0269245   0.131536    0.0252563   0.359399     0.202787     0.106282   -0.408793     0.139042    -0.246387    -0.0572576   0.24746    -0.0558505   -0.298003    0.544881     0.238202    0.52049     0.247003   -0.470383
  0.232646    0.183484   -0.642296    -0.0567901   -0.248078    0.318684    -0.334996    -0.453282     0.0148425   0.292116    0.138919    0.265936    -0.607024     0.0405109   0.00795638   0.432215     0.503236     0.0651765   0.66888    -0.179687     0.28653    -0.133771    -0.242323    0.0687593  -0.155625   -0.364223
  0.127343    0.120473   -0.118805     0.156586     0.240127    0.0370602   -0.0524325   -0.29586      0.387997    0.199167    0.126784    0.250347     0.216695     0.264624    0.270323     0.105919     0.0868911    0.169185    0.632412    0.138931    -0.0329822  -0.00741221  -0.0652264   0.161891    0.0708007  -0.0677851
  0.446462    0.110153    0.332345     0.546118     0.219618   -0.338645     0.570393    -0.58875      0.03145    -0.0653158   0.129919    0.500531     0.2084      -0.149667    0.274772     0.569899     0.0345161   -0.0398567  -0.371835   -0.167764    -0.108219   -0.342736     0.285359    0.188656   -0.0374061   0.0987838
  0.204025    0.329621    0.258411     0.149803    -0.158216   -0.428307     0.332537     0.0322254   -0.062816   -0.516898    0.134554    0.282635    -0.130438     0.519302    0.196006     0.315023     0.15484      0.580593   -0.228872   -0.174531     0.383907   -0.179141    -0.142599   -0.197034   -0.624833    0.467453
  0.498253   -0.417836    0.810268     0.00593023   0.205784   -0.126716     0.0637676   -0.426671    -0.0181699   0.255454   -0.265728   -0.483497     0.0406924    0.543747    0.229002     0.652821    -0.245797     0.46938     0.499524    0.779386     0.0503974   0.311303    -0.402139    0.0140681   0.111553    0.276019
  0.161489    0.43264     0.156208     0.157171     0.161726    0.0591944   -0.161182    -0.0903605   -0.0397405   0.0598732   0.484441   -0.42293      0.432085    -0.397399    0.466891     0.191061    -0.316362     0.0451556  -0.11862     0.920057    -0.61594     0.276637     0.38172    -0.317569    0.63381     0.263839
 -0.407962    0.123592    0.104181    -0.00328773  -0.885946   -0.822305     0.0436258    0.306371    -0.159569    0.140408    0.369492   -0.63597     -0.511811    -0.0172244   0.629468     0.010816     0.264158    -0.427552   -0.0865786   0.0224753   -0.262968   -0.289415     0.15875    -0.529226   -0.492887   -0.346023
 -0.328415   -0.228754    0.0791302   -0.0655798   -0.575747   -0.451122    -0.0905955    0.237       -0.0374201   0.169382   -0.071714   -0.270291     0.355666     0.128442   -0.0339582   -0.0628451    0.248586     0.258616    0.597421   -0.140843     0.30228    -0.084268    -0.58571    -0.542189   -0.022123   -0.423772
  0.358027   -0.662836   -0.00691689  -0.495613    -0.212277    0.471172     0.0442387    0.00528032   0.526359    0.155611    0.279528   -0.243331     0.442064     0.777913    0.74957      0.2878      -0.687285     0.0215581  -0.0217773  -0.342875    -0.178302   -0.151693     0.482307   -0.218444   -0.0596748   0.112131
 -0.345817    0.377631    0.0189672   -0.409638    -0.16272     0.3797      -0.166087     0.238323     0.126289    0.292425    0.155384   -0.539847    -0.181634     0.627527    0.0180516    0.0240226   -0.619679     0.343063    0.199734    0.0327976    0.0290144  -0.55229      0.195406   -0.726005    0.224363   -0.418017
 -0.213001   -0.24684    -0.183147    -0.560459    -0.338034   -0.163959     0.472577     0.204834    -0.680182    0.0254788   0.0992766   0.162636     0.00474666  -0.399067    0.271732     0.777867     0.745494    -0.0173909  -0.114704   -0.221227     0.434271   -1.09839      0.622797    0.395801    0.494805    0.170374
  0.0311569  -0.631813   -0.441699     0.0377846   -0.391555   -0.203459    -0.242504     0.500959    -0.166094    0.0875156   0.223742    0.685193    -0.272707    -0.488333   -0.0908035    0.0887858    0.108186    -0.362836   -0.620434   -0.724733     0.154658    0.362342     0.287814    0.355018   -0.0457747  -0.242854
 -0.250544    0.312422    0.16934      0.158977     0.11165     0.0993363   -0.760888    -0.552044    -0.481202    0.46148    -0.439356    0.390661     0.183483    -0.291954    0.0465088    0.464268    -0.146294     0.560463   -0.276609   -0.125299    -0.212443   -0.102355     0.0517169  -0.379474    0.123172   -0.502016
  0.0294085  -0.111511    0.0806841    0.437377    -0.252326    0.0174002    0.586241    -0.0747133   -0.425934    0.553682    0.396453    0.273423     0.00431039   0.448353   -0.440174     0.410383    -0.444131     0.0262417  -0.103639   -0.0332028   -0.3491     -0.287311     0.0367899  -0.255578   -0.158466   -0.977579
 -0.538006   -0.0510796   0.564847     0.127173     0.107566    0.183223     0.266415     0.145417    -0.256192   -0.223685   -0.224724   -0.450596     0.584614    -0.348076   -0.193019    -0.517151    -0.508543    -0.158047   -0.799152   -0.00180334  -0.248688   -0.0926013    0.455624   -0.777701   -0.1402      0.306162
 -0.268139    0.34682    -0.543148    -0.0857189    0.242513    0.739634     0.45223      0.473372    -0.405214   -0.0377895   0.411372    0.853195     0.228034    -0.851887    0.429773    -0.391269     0.0857935   -0.161685   -0.462527   -0.569992    -0.309709   -0.184515     0.221931   -0.682356    0.151052    0.0309106
  0.0861703  -0.115601   -0.274784    -0.309978     0.341412   -0.0892768    0.0792875   -0.346964     0.694902    0.0187631  -0.274949    0.00391909  -1.13076     -0.154606   -0.196587     0.207973     0.00199952  -0.322195   -0.835944    0.186879     0.130387   -0.125127     0.656218   -0.0158157  -0.158573    0.39252
  0.382243    0.083625    0.0902401    0.381807     0.63365    -0.137799     0.412673    -0.292627    -0.12196    -0.028955   -0.501051    0.37861      0.308428    -0.40455    -0.175845    -0.248129     0.386518    -0.0421003  -0.356005    0.386558    -0.252716    0.670882    -0.121465    0.229525    0.248935    0.389261
  0.306729   -0.0818319   0.106311     0.173374    -0.650688   -0.532734    -0.426445    -0.524616     0.0109793   0.150521    0.0313117  -0.10178     -0.0694982   -0.164555    0.0439599    0.367531     0.00655994  -0.0284231  -0.286982   -0.0312798    0.0222474  -0.0489946   -0.0209608   0.347741    0.221039    0.0790865
 -0.345101   -0.167771   -0.181224     0.0171599   -0.0180984   0.244339    -0.0183219    0.621292     0.269894   -0.496646    0.0227692  -0.170137     0.0380797    0.373192   -0.154789    -0.263218    -0.211513     0.0640295   0.0977249  -0.0620903    0.263041    0.183729     0.0859294  -0.173699   -0.0780116  -0.000593725
 -0.0445759   0.433023    0.0812846   -0.427983     0.832169    0.245317    -0.0581052   -0.291797     0.157511    0.185214   -0.161727   -0.105024    -0.0303265    0.312013    0.520727     0.0396009    0.278193    -0.0258334   0.960541    0.275835    -0.600025   -0.467969    -0.0276997   0.153648   -0.213995    0.132228
  0.56718     0.0977237  -0.134797    -0.359175     0.232864    0.285404    -0.225758     0.222629     0.993831   -0.211194    0.0924519  -0.134512    -0.319623     0.0382386   0.564939    -0.167121     0.702719    -0.031399    1.03042    -0.644632     0.483784    0.566848    -0.347441    0.585825    0.184342    0.57881[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423069
[ Info: iteration 2, average log likelihood -1.423057
[ Info: iteration 3, average log likelihood -1.423046
[ Info: iteration 4, average log likelihood -1.423035
[ Info: iteration 5, average log likelihood -1.423024
[ Info: iteration 6, average log likelihood -1.423013
[ Info: iteration 7, average log likelihood -1.423002
[ Info: iteration 8, average log likelihood -1.422991
[ Info: iteration 9, average log likelihood -1.422981
[ Info: iteration 10, average log likelihood -1.422970
â”Œ Info: EM with 100000 data points 10 iterations avll -1.422970
â”” 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.323675e+05
      1       7.268203e+05      -2.055472e+05 |       32
      2       7.089613e+05      -1.785906e+04 |       32
      3       7.019680e+05      -6.993276e+03 |       32
      4       6.986879e+05      -3.280145e+03 |       32
      5       6.967237e+05      -1.964208e+03 |       32
      6       6.953839e+05      -1.339766e+03 |       32
      7       6.943827e+05      -1.001194e+03 |       32
      8       6.935854e+05      -7.973098e+02 |       32
      9       6.929412e+05      -6.442004e+02 |       32
     10       6.924341e+05      -5.070346e+02 |       32
     11       6.920229e+05      -4.112929e+02 |       32
     12       6.916905e+05      -3.323668e+02 |       32
     13       6.914010e+05      -2.895351e+02 |       32
     14       6.911206e+05      -2.803134e+02 |       32
     15       6.908809e+05      -2.397552e+02 |       32
     16       6.906807e+05      -2.001400e+02 |       32
     17       6.905129e+05      -1.678763e+02 |       32
     18       6.903544e+05      -1.584689e+02 |       32
     19       6.901740e+05      -1.803972e+02 |       32
     20       6.899972e+05      -1.767748e+02 |       32
     21       6.898561e+05      -1.411632e+02 |       32
     22       6.897452e+05      -1.108624e+02 |       32
     23       6.896403e+05      -1.048981e+02 |       32
     24       6.895540e+05      -8.630798e+01 |       32
     25       6.894744e+05      -7.964085e+01 |       32
     26       6.893925e+05      -8.188933e+01 |       32
     27       6.893157e+05      -7.674595e+01 |       32
     28       6.892449e+05      -7.081938e+01 |       32
     29       6.891737e+05      -7.118409e+01 |       32
     30       6.891126e+05      -6.106479e+01 |       32
     31       6.890636e+05      -4.908781e+01 |       32
     32       6.890167e+05      -4.691195e+01 |       32
     33       6.889673e+05      -4.938080e+01 |       32
     34       6.889246e+05      -4.266015e+01 |       32
     35       6.888786e+05      -4.600091e+01 |       32
     36       6.888276e+05      -5.103219e+01 |       32
     37       6.887795e+05      -4.809347e+01 |       32
     38       6.887338e+05      -4.565423e+01 |       32
     39       6.886942e+05      -3.962951e+01 |       32
     40       6.886570e+05      -3.722228e+01 |       32
     41       6.886254e+05      -3.160196e+01 |       32
     42       6.885966e+05      -2.876395e+01 |       32
     43       6.885707e+05      -2.589511e+01 |       32
     44       6.885509e+05      -1.980624e+01 |       32
     45       6.885304e+05      -2.046391e+01 |       32
     46       6.885064e+05      -2.408935e+01 |       32
     47       6.884833e+05      -2.306985e+01 |       32
     48       6.884580e+05      -2.531002e+01 |       32
     49       6.884266e+05      -3.140214e+01 |       32
     50       6.883969e+05      -2.962742e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 688396.9466682076)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.435001
[ Info: iteration 2, average log likelihood -1.429757
[ Info: iteration 3, average log likelihood -1.428334
[ Info: iteration 4, average log likelihood -1.427256
[ Info: iteration 5, average log likelihood -1.426136
[ Info: iteration 6, average log likelihood -1.425155
[ Info: iteration 7, average log likelihood -1.424522
[ Info: iteration 8, average log likelihood -1.424182
[ Info: iteration 9, average log likelihood -1.423992
[ Info: iteration 10, average log likelihood -1.423867
[ Info: iteration 11, average log likelihood -1.423772
[ Info: iteration 12, average log likelihood -1.423693
[ Info: iteration 13, average log likelihood -1.423625
[ Info: iteration 14, average log likelihood -1.423564
[ Info: iteration 15, average log likelihood -1.423510
[ Info: iteration 16, average log likelihood -1.423460
[ Info: iteration 17, average log likelihood -1.423415
[ Info: iteration 18, average log likelihood -1.423373
[ Info: iteration 19, average log likelihood -1.423335
[ Info: iteration 20, average log likelihood -1.423299
[ Info: iteration 21, average log likelihood -1.423266
[ Info: iteration 22, average log likelihood -1.423236
[ Info: iteration 23, average log likelihood -1.423208
[ Info: iteration 24, average log likelihood -1.423182
[ Info: iteration 25, average log likelihood -1.423157
[ Info: iteration 26, average log likelihood -1.423134
[ Info: iteration 27, average log likelihood -1.423113
[ Info: iteration 28, average log likelihood -1.423093
[ Info: iteration 29, average log likelihood -1.423074
[ Info: iteration 30, average log likelihood -1.423056
[ Info: iteration 31, average log likelihood -1.423039
[ Info: iteration 32, average log likelihood -1.423023
[ Info: iteration 33, average log likelihood -1.423008
[ Info: iteration 34, average log likelihood -1.422993
[ Info: iteration 35, average log likelihood -1.422979
[ Info: iteration 36, average log likelihood -1.422966
[ Info: iteration 37, average log likelihood -1.422953
[ Info: iteration 38, average log likelihood -1.422941
[ Info: iteration 39, average log likelihood -1.422929
[ Info: iteration 40, average log likelihood -1.422917
[ Info: iteration 41, average log likelihood -1.422906
[ Info: iteration 42, average log likelihood -1.422896
[ Info: iteration 43, average log likelihood -1.422885
[ Info: iteration 44, average log likelihood -1.422875
[ Info: iteration 45, average log likelihood -1.422866
[ Info: iteration 46, average log likelihood -1.422856
[ Info: iteration 47, average log likelihood -1.422847
[ Info: iteration 48, average log likelihood -1.422838
[ Info: iteration 49, average log likelihood -1.422829
[ Info: iteration 50, average log likelihood -1.422821
â”Œ Info: EM with 100000 data points 50 iterations avll -1.422821
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.466908    0.266891    -0.14744     -0.135225     0.121572    0.134657    -0.500768     -0.351141     0.286872   -0.0532763  -0.611601    -0.135036    -0.0277885   -0.335431    0.171738     0.100865     0.108515     0.267007     0.358677    0.302243     0.151321    -0.0102826    0.286882    -0.186425     1.08361    -0.49597
 -0.497345    0.0962851   -0.506062    -0.851151     1.03939     0.83919     -0.294524     -0.0459589    0.118048    0.324824   -0.297742    -0.332298    -0.456712     0.199084    0.429508    -0.16326      0.554845    -0.574644     0.341038   -0.26279     -1.02283     -0.00768824   0.196779     0.175974    -0.64999     0.260776
 -0.0323044   0.0461621    0.104317     0.209172     0.0304475  -0.046836    -0.000980351  -0.24128     -0.147261    0.178394   -0.0817673    0.138983     0.164424     0.0761992   0.00775691   0.241037     0.0257564    0.194827     0.0460826   0.00797325  -0.0932693   -0.0836824    0.00245818  -0.126219    -0.0516496  -0.182289
 -0.182543   -0.258565    -0.31811     -0.462571    -0.41268    -0.180245     0.213473      0.14673     -0.614572    0.142448    0.222056     0.298824     0.0150897   -0.488407    0.478383     0.725616     0.705611     0.0464799   -0.173969   -0.340906     0.340902    -0.682725     0.528337     0.308686     0.450212    0.134501
  0.0671971   0.00998823  -0.654579     0.00829861  -0.163333    0.110768    -0.219517     -0.210893     0.184899    0.212037    0.244164     0.230755    -0.32058      0.172217    0.0353202    0.0855163    0.251085    -0.0260291    0.436707   -0.148577     0.240032    -0.0485764   -0.104555     0.0710351   -0.100089   -0.287985
 -0.162855   -0.373074     0.180529     0.559646    -0.561065    0.167844     0.0263182     0.102339    -0.152252   -0.220121    0.0528659   -0.00755997   0.439842    -0.171777   -0.489899     0.277385    -0.35097      0.0778845   -0.791984   -0.439963     0.543523     0.423985     0.274362    -0.805731     0.198657   -0.418724
  0.0330347  -0.6485      -0.139701    -0.0582842   -0.897319   -0.975947    -0.788266      0.428184     0.172547    0.812096   -0.411034    -0.174266    -0.343621    -0.452509   -0.0674765   -0.138086    -0.324716    -0.497319    -0.769628   -0.262367    -0.370609    -0.0102486   -0.199939     0.0973967    0.464323   -0.239808
  0.447472   -0.694355     0.940639    -0.0601395    0.0302144  -0.248402     0.00215622   -0.48534      0.0133488   0.399772   -0.257775    -0.579425    -0.00778251   0.505932    0.244879     0.820206    -0.224247     0.240703     0.410492    0.758709     0.184377     0.328723    -0.422769     0.0456227    0.0858284   0.172174
  0.76643     0.0764204   -0.163716    -0.18053      0.0581635   0.209442     0.107392      0.0241996    0.0176216   0.546997    0.416254     0.45194     -0.261692    -0.283373    0.316753    -0.00424197  -0.0679367    0.23541      0.708928    0.22684     -0.940205     0.151664    -0.948457     0.0986619    0.11343    -0.295022
 -0.0795291   0.205506    -0.696409     0.102852     0.131994    0.710616     0.222964      0.228462    -0.0466895  -0.0344346   0.614501     0.431451    -0.244118    -0.59538    -0.22002     -0.365838    -0.127342    -0.669504    -0.674732   -0.659059    -0.292295     0.159878     0.442548     0.0138046    0.181817   -0.0746178
  0.707448    0.00463253  -0.282777    -0.151331     0.146808    0.215767    -0.219956      0.109042     0.99171    -0.191627    0.165645    -0.150621    -0.38065      0.0864524   0.317304    -0.0476642    0.545764    -0.0449998    0.867171   -0.472591     0.424027     0.681631    -0.445257     0.709796     0.249001    0.482562
 -0.40132    -0.148445    -0.0900517   -0.265567    -0.109377    0.227131     0.0610396     0.951341     0.343572   -0.760283    0.0100912   -0.349569     0.10181      0.389811    0.0148701   -0.494146    -0.126217     0.00544432   0.238288    0.0545641    0.445898     0.0289707    0.0729409   -0.069944    -0.0526667   0.316719
 -0.452309    0.299462     0.113004    -0.316433    -0.366569    0.270259    -0.132948     -0.0182758   -0.331998    0.729192    0.272354    -0.136434    -0.0417955    0.595989   -0.191643     0.281953    -0.57749      0.401059     0.0315129   0.0567542   -0.140103    -0.481569     0.105828    -0.757793     0.197324   -0.759282
  0.209706   -0.297425    -0.25581      0.120254    -0.0572623  -0.0994715   -0.101442      0.00709624  -0.068865   -0.0538191  -0.531584     0.476021    -0.927915     0.167071   -0.820343    -0.00330852  -0.0144536   -0.190398     0.0713754  -0.666399     0.380333    -0.100532    -0.121099     0.3526      -0.768166   -0.594257
  0.36526     0.105229    -0.00312126  -0.200551     0.044415   -0.35625      0.210784     -0.313998     0.656658   -0.230635   -0.131131     0.0519637   -0.979126     0.124161    0.035598     0.336815     0.0547396    0.164275    -0.751847    0.303282     0.0266131   -0.0428791    0.358523    -0.0972046   -0.277872    0.773175
  0.163311   -0.344104    -0.00142899   0.257977    -0.666451   -0.656728     0.045675      0.127341    -0.105197   -0.250784    0.317013    -0.181949     0.278938     0.487745   -0.334607     0.5844       0.168593     0.551071     0.233116    0.220302     0.237245     0.0970824   -0.492848     0.266939    -0.193774   -0.0110723
 -0.333287    0.0575828    0.710562    -0.283418     0.0593623   0.110535     0.340853      0.0764542   -0.383972   -0.0458267   0.0742944   -0.19131      0.143114    -0.214596    0.170416    -0.329393    -0.266654    -0.133721    -0.657508    0.118443    -0.122713    -0.816253     0.441872    -0.644233    -0.479938    0.241088
  0.179817   -0.248414    -0.181084     0.0877471    0.34023    -0.262895     0.00677188   -0.0473469    0.0830658  -0.379636   -0.427807     0.411903     0.100008    -0.964752   -0.204942    -0.477949     0.520509    -0.533515    -0.177446    0.409744     0.0423851    0.306114    -0.239734     0.612919     0.198376    0.268058
  0.0909813   0.341608     0.232917    -0.122049     0.712594    0.128552     0.173343     -0.331064     0.308092   -0.0653218   0.039997     0.0294272    0.303692     0.280077    0.337505     0.126124     0.187623     0.253353     0.902845    0.451555    -0.0670894   -0.510397    -0.175662     0.160546    -0.101879    0.391376
 -0.349764   -0.381839    -0.14354     -0.53596     -0.197394    0.0851726   -0.148915      0.228242     0.0318017   0.038864    0.0441327   -0.674535    -0.175861     0.0551732  -0.316079    -0.665194    -0.111568    -0.260427    -0.0465546  -0.0910346   -0.230395     0.114794    -0.279342     0.00512569  -0.0141042   0.125218
 -0.592939    0.049953    -0.0496145   -0.415007    -0.207539    0.144606    -0.259031      0.166557    -0.289244   -0.467663   -0.166563     0.239092     0.285654    -0.414367    0.0464631   -0.116896     0.54769      0.240761    -0.208788   -0.524835     0.144738    -0.0683952   -0.162926    -0.198427    -0.202495    0.184866
 -0.491695    0.191592    -0.0231054    0.138048    -0.839186   -0.782425     0.0791089     0.211819    -0.121202    0.109211    0.38837     -0.459327    -0.404423     0.0624274   0.571208     0.0678439    0.364286    -0.362898     0.235589    0.0217703   -0.090041    -0.254997     0.0204085   -0.546475    -0.501864   -0.538367
 -0.17883     0.0513593    0.200563    -0.114141    -0.0190648  -0.0776944   -0.066954      0.00897482  -0.0180844  -0.0719888  -0.0851047   -0.013592     0.0995993   -0.11559     0.210264     0.0417281    0.0474033    0.0848628    0.0406532   0.0180298    0.00644734  -0.212793     0.0719232   -0.140574     0.0445383   0.0299191
  0.0584905  -0.195661    -0.0514022    0.289406    -0.0986837  -0.12017      0.394543      0.238005     0.0711847  -0.107272    0.0137683    0.0975948   -0.072793     0.152684   -0.229807     0.0582215    0.00801903  -0.312058    -0.288782   -0.0982389    0.121966     0.262553     0.10825      0.171738    -0.0653678   0.0417317
  0.470848    0.173218     0.162845     0.0373816    0.191527    0.309132    -0.1191       -0.125701     0.172052   -0.271567   -0.00129854  -0.18091     -0.101412     0.0282072   0.0828222   -0.131411    -0.235987     0.0338753    0.0538625   0.450435    -0.173099     0.403319     0.0308842    0.193249     0.40626     0.369722
 -0.25376     0.0885899   -0.266501     0.48322      0.555661    0.569224     0.0991805     0.162529    -0.0598828   0.0443454  -0.185001     0.507545     0.609909     0.33809    -0.350135    -0.114927    -0.122925     0.191219     0.56112    -0.0432075    0.0477255    0.467818    -0.179632     0.334222     0.211077   -0.282801
  0.409082   -0.412177     0.03369     -0.346623    -0.176002    0.359236     0.0707156     0.0192252    0.532413    0.239961    0.361583    -0.160358     0.356285     0.64193     0.751391     0.32711     -0.664599     0.00238147   0.0388482  -0.392353    -0.142396    -0.160564     0.476711    -0.245385    -0.0892181   0.0428935
  0.0626011   0.153912     0.307005     0.192395     0.622582    0.10065      0.295846     -0.268547    -0.041799   -0.122972   -0.370141    -0.192196     0.740432    -0.0554011   0.25527     -0.680934    -0.221242     0.0387961   -0.42802     0.461113    -0.617471     0.647238     0.0354362   -0.526503     0.352382    0.49144
  0.315354    0.385791     0.193239     0.34052      0.18328    -0.452184     0.252063     -0.438806     0.199661   -0.810673   -0.0105264    0.167603    -0.00323159  -0.0997469   0.0238504   -0.0244068    0.159969    -0.732053    -0.525039   -0.375308     0.366805    -0.247525     0.360972     0.679451    -0.0601508   0.518522
  0.138222    0.851018     0.853538     0.294312    -0.178419   -0.0167362   -0.477107     -0.189995    -0.712712   -0.840375    0.120565    -0.247593     0.625792    -0.102716    0.144653    -0.353284    -0.429114     0.0226769    0.155159   -0.615297     0.122448    -0.00830166  -0.969627     0.315013     0.457683   -0.0758459
  0.303028    0.230537     0.153065     0.465705     0.279747   -0.00676171   0.0449032    -0.65008     -0.254621    0.371661   -0.0838214    0.492135     0.174634    -0.141467    0.0908203    0.716969    -0.0264233    0.333822    -0.20694    -0.239495    -0.236357    -0.0492768    0.173634     0.00688497  -0.0110648  -0.197417
 -0.210584    0.217004    -0.1923       0.710802     0.376276   -0.0949067   -0.0398759     0.257808    -0.173991    0.118653    0.399251    -0.127184     0.220489    -0.199929   -0.378132     0.115475    -0.59425     -0.0059031   -0.372471    0.52075     -0.93482      0.191576     0.519031    -0.0212268    0.0497376  -0.196043[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422813
[ Info: iteration 2, average log likelihood -1.422805
[ Info: iteration 3, average log likelihood -1.422797
[ Info: iteration 4, average log likelihood -1.422790
[ Info: iteration 5, average log likelihood -1.422783
[ Info: iteration 6, average log likelihood -1.422776
[ Info: iteration 7, average log likelihood -1.422769
[ Info: iteration 8, average log likelihood -1.422763
[ Info: iteration 9, average log likelihood -1.422757
[ Info: iteration 10, average log likelihood -1.422750
â”Œ Info: EM with 100000 data points 10 iterations avll -1.422750
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
