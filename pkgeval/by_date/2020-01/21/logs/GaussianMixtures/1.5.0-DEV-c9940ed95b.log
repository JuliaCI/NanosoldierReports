Julia Version 1.5.0-DEV.133
Commit c9940ed95b (2020-01-21 18:51 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed PDMats ───────────── v0.9.10
 Installed GaussianMixtures ─── v0.3.0
 Installed CMake ────────────── v1.1.2
 Installed Distances ────────── v0.8.2
 Installed Arpack ───────────── v0.4.0
 Installed FileIO ───────────── v1.2.1
 Installed BinDeps ──────────── v1.0.0
 Installed BinaryProvider ───── v0.5.8
 Installed ScikitLearnBase ──── v0.5.0
 Installed SortingAlgorithms ── v0.3.1
 Installed NearestNeighbors ─── v0.4.4
 Installed StaticArrays ─────── v0.12.1
 Installed LegacyStrings ────── v0.4.1
 Installed StatsBase ────────── v0.32.0
 Installed OrderedCollections ─ v1.1.0
 Installed Clustering ───────── v0.13.3
 Installed QuadGK ───────────── v2.3.1
 Installed Blosc ────────────── v0.5.1
 Installed Parameters ───────── v0.12.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed DataStructures ───── v0.17.9
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed DataAPI ──────────── v1.1.0
 Installed JLD ──────────────── v0.9.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Compat ───────────── v2.2.0
 Installed FillArrays ───────── v0.8.4
 Installed SpecialFunctions ─── v0.9.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed StatsFuns ────────── v0.9.3
 Installed Rmath ────────────── v0.6.0
 Installed URIParser ────────── v0.4.0
 Installed Missings ─────────── v0.4.3
 Installed HDF5 ─────────────── v0.12.5
 Installed Distributions ────── v0.22.3
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_e7xI14/Project.toml`
 [no changes]
  Updating `/tmp/jl_e7xI14/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_zR3rGO/Project.toml`
 [no changes]
  Updating `/tmp/jl_zR3rGO/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_kCrSdz/Project.toml`
 [no changes]
  Updating `/tmp/jl_kCrSdz/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_1vrp3F/Project.toml`
 [no changes]
  Updating `/tmp/jl_1vrp3F/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_wPPA47/Project.toml`
 [no changes]
  Updating `/tmp/jl_wPPA47/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_wPPA47/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.837397179643643e6, [71053.7631484551, 28946.23685154491], [-23020.30135667039 2343.281345862901 23806.648423604005; 23206.81424602072 -1975.027926249471 -24038.7058922537], [[62281.52569709844 -248.27550702914863 8606.241339219872; -248.2755070291486 63921.67759654038 847.4841538058986; 8606.241339219872 847.4841538058984 60997.99475816259], [37785.91855811832 219.22329256547485 -8790.392319959896; 219.22329256547494 35684.06107936516 -722.1428555909954; -8790.392319959896 -722.1428555909954 38832.621930268375]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.227046e+03
      1       1.040806e+03      -1.862401e+02 |        6
      2       9.897712e+02      -5.103473e+01 |        4
      3       9.576760e+02      -3.209524e+01 |        4
      4       9.142115e+02      -4.346452e+01 |        0
      5       9.142115e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 914.211484589091)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.075204
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.748902
[ Info: iteration 2, lowerbound -3.600227
[ Info: iteration 3, lowerbound -3.456875
[ Info: iteration 4, lowerbound -3.304306
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.145974
[ Info: iteration 6, lowerbound -2.999578
[ Info: iteration 7, lowerbound -2.894042
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.827633
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.795033
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.777132
[ Info: iteration 11, lowerbound -2.759701
[ Info: iteration 12, lowerbound -2.745715
[ Info: iteration 13, lowerbound -2.726619
[ Info: iteration 14, lowerbound -2.701415
[ Info: iteration 15, lowerbound -2.669613
[ Info: iteration 16, lowerbound -2.631567
[ Info: iteration 17, lowerbound -2.588680
[ Info: iteration 18, lowerbound -2.543333
[ Info: iteration 19, lowerbound -2.498406
[ Info: iteration 20, lowerbound -2.456352
[ Info: iteration 21, lowerbound -2.418310
[ Info: iteration 22, lowerbound -2.384020
[ Info: iteration 23, lowerbound -2.353048
[ Info: iteration 24, lowerbound -2.327043
[ Info: iteration 25, lowerbound -2.310726
[ Info: iteration 26, lowerbound -2.308026
[ Info: dropping number of Gaussions to 2
[ Info: iteration 27, lowerbound -2.302916
[ Info: iteration 28, lowerbound -2.299259
[ Info: iteration 29, lowerbound -2.299256
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299254
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Jan 22 03:39:06 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Jan 22 03:39:14 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Wed Jan 22 03:39:17 2020: EM with 272 data points 0 iterations avll -2.075204
5.8 data points per parameter
, Wed Jan 22 03:39:19 2020: GMM converted to Variational GMM
, Wed Jan 22 03:39:26 2020: iteration 1, lowerbound -3.748902
, Wed Jan 22 03:39:26 2020: iteration 2, lowerbound -3.600227
, Wed Jan 22 03:39:26 2020: iteration 3, lowerbound -3.456875
, Wed Jan 22 03:39:26 2020: iteration 4, lowerbound -3.304306
, Wed Jan 22 03:39:27 2020: dropping number of Gaussions to 7
, Wed Jan 22 03:39:27 2020: iteration 5, lowerbound -3.145974
, Wed Jan 22 03:39:27 2020: iteration 6, lowerbound -2.999578
, Wed Jan 22 03:39:27 2020: iteration 7, lowerbound -2.894042
, Wed Jan 22 03:39:27 2020: dropping number of Gaussions to 6
, Wed Jan 22 03:39:27 2020: iteration 8, lowerbound -2.827633
, Wed Jan 22 03:39:27 2020: dropping number of Gaussions to 5
, Wed Jan 22 03:39:27 2020: iteration 9, lowerbound -2.795033
, Wed Jan 22 03:39:27 2020: dropping number of Gaussions to 3
, Wed Jan 22 03:39:27 2020: iteration 10, lowerbound -2.777132
, Wed Jan 22 03:39:27 2020: iteration 11, lowerbound -2.759701
, Wed Jan 22 03:39:27 2020: iteration 12, lowerbound -2.745715
, Wed Jan 22 03:39:27 2020: iteration 13, lowerbound -2.726619
, Wed Jan 22 03:39:27 2020: iteration 14, lowerbound -2.701415
, Wed Jan 22 03:39:27 2020: iteration 15, lowerbound -2.669613
, Wed Jan 22 03:39:27 2020: iteration 16, lowerbound -2.631567
, Wed Jan 22 03:39:27 2020: iteration 17, lowerbound -2.588680
, Wed Jan 22 03:39:27 2020: iteration 18, lowerbound -2.543333
, Wed Jan 22 03:39:27 2020: iteration 19, lowerbound -2.498406
, Wed Jan 22 03:39:27 2020: iteration 20, lowerbound -2.456352
, Wed Jan 22 03:39:27 2020: iteration 21, lowerbound -2.418310
, Wed Jan 22 03:39:27 2020: iteration 22, lowerbound -2.384020
, Wed Jan 22 03:39:27 2020: iteration 23, lowerbound -2.353048
, Wed Jan 22 03:39:27 2020: iteration 24, lowerbound -2.327043
, Wed Jan 22 03:39:27 2020: iteration 25, lowerbound -2.310726
, Wed Jan 22 03:39:27 2020: iteration 26, lowerbound -2.308026
, Wed Jan 22 03:39:27 2020: dropping number of Gaussions to 2
, Wed Jan 22 03:39:27 2020: iteration 27, lowerbound -2.302916
, Wed Jan 22 03:39:27 2020: iteration 28, lowerbound -2.299259
, Wed Jan 22 03:39:27 2020: iteration 29, lowerbound -2.299256
, Wed Jan 22 03:39:27 2020: iteration 30, lowerbound -2.299254
, Wed Jan 22 03:39:27 2020: iteration 31, lowerbound -2.299254
, Wed Jan 22 03:39:27 2020: iteration 32, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 33, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 34, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 35, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 36, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 37, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 38, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 39, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 40, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 41, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 42, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 43, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 44, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 45, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 46, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 47, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 48, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 49, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: iteration 50, lowerbound -2.299253
, Wed Jan 22 03:39:27 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222614618, 95.95490777385375]
β = [178.04509222614618, 95.95490777385375]
m = [4.250300733268838 79.28686694434606; 2.0002292577742598 53.85198717245553]
ν = [180.04509222614618, 97.95490777385375]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547470297 -0.007644049042341712; 0.0 0.008581705166313723], [0.37587636119668855 -0.008953123827367782; 0.0 0.012748664777415132]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9897928289400088
avll from llpg:  -0.9897928289400088
avll direct:     -0.9897928289400088
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9966563833500273
avll from llpg:  -0.9966563833500272
avll direct:     -0.9966563833500272
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.015068      0.154735     0.0902915   0.0612045   -0.187125     0.0322749   -0.0571013     0.10278       0.0929692   -0.025826     0.132271    0.113713     0.0394604   -0.115347    -0.00594781  -0.0425944   -0.0815693    0.114039    -0.0100048    0.0809871   -0.106204     0.230939     0.028923     0.0226585   0.241598     0.051541
  0.0724143     0.0122041    0.0177241  -0.0746917   -0.0348541    0.0351436    0.0792493     0.066694      0.137224    -0.00666374   0.106057   -0.118123     0.0756436   -0.0631382    0.124281    -0.0199021   -0.151123     0.0255749   -0.0386154    0.0463324   -0.0124529   -0.0785951    0.00768149   0.245074    0.123563     0.0667982
 -0.0939514     0.00671512  -0.0681159  -0.0149297   -0.117573    -0.0596233   -0.0300113    -0.107855      0.0701591    0.0710255   -0.0479781   0.00822156  -0.103422     0.0756791   -0.133004    -0.158371     0.117648     0.00903133  -0.081609    -0.0061065   -0.0832123   -0.0266059    0.0166237   -0.120921   -0.203798     0.0826192
 -0.104271      0.0480908    0.0939582   0.155038     0.0136373   -0.00753108  -0.0597117    -0.0292422    -0.0815879   -0.0806827    0.0654942   0.0860312   -0.00668347   0.0086561    0.00636627   0.1019      -0.086941    -0.169055    -0.0667077   -0.0474394    0.0750585   -0.0796313   -0.0673347   -0.104699   -0.0252076    0.141694
  0.029917      0.186072    -0.0698164   0.0751982    0.0901009    0.160567    -0.0479578     0.220889     -0.265198     0.157941     0.0343535  -0.102179    -0.0547332    0.0921454   -0.147678     0.0865341   -0.0351881    0.134943    -0.0156192   -0.0345283   -0.0527042    0.103662     0.0629759    0.0163334  -0.080861    -0.0796584
 -0.00383612   -0.0782895   -0.181173   -0.111653     0.167866    -0.0552206   -0.0594136    -0.044581     -0.105761     0.0772785   -0.0754741   0.019831     0.0489963   -0.0612036    0.0386782   -0.0294694   -0.0914416    0.0695158    0.017548     0.0321085   -0.110914     0.00298113  -0.0227882    0.0627367   0.169825    -0.110452
 -0.115821      0.0699187   -0.136417   -0.127029     0.0445947   -0.137828    -0.226605     -0.0932297    -0.00842929  -0.087935     0.284297    0.0388403    0.0882947   -0.00893425   0.120347    -0.0258224   -0.110992    -0.0944857   -0.104943     0.0899354   -0.0338472   -0.0773057   -0.197033     0.0342193  -0.185244    -0.261024
 -0.0334067     0.0670616    0.125361   -0.037246    -0.151967    -0.0148496   -0.0579254     0.093698     -0.0264074    0.0670148   -0.103318    0.0476894   -0.104678    -0.191817     0.0991912    0.0988703    0.0205967   -0.11592      0.00681125  -0.0694466   -0.0865896   -0.0327849   -0.0893202   -0.123553   -0.11735      0.0278328
  0.0623367     0.0706285   -0.043734   -0.0615221    0.0465597   -0.138349     0.0909899    -0.235141      0.139926     0.00331987  -0.0552589   0.147101     0.00761462   0.00822853   0.0206574   -0.0401706    0.0394007    0.131472     0.164735    -0.0848178    0.0850883    0.0425938    0.0390603    0.0739631  -0.0370046   -0.158169
  0.060686      0.0403905    0.0220992   0.0631346    0.207993     0.0159651   -0.0174017    -0.00428776   -0.0264678   -0.0795852   -0.0305726   0.00951374  -0.175575     0.00949491  -0.191519     0.204276    -0.00171543   0.139253    -0.263765    -0.0914248   -0.145936    -0.268647    -0.0100176    0.206588    0.0976094    0.10446
 -0.0735162    -0.068661    -0.131521    0.139228     0.0896383   -0.0924489    0.0808326    -0.00795676   -0.0193912    0.031302    -0.202515    0.0502009    0.111324    -0.0944751    0.18996      0.0461638    0.0951823    0.00931943  -0.149571    -0.0162685    0.0533946    0.0558973   -0.0835969   -0.0114244  -0.0296342   -0.0591613
  0.0182489    -0.0623052   -0.139925   -0.23165     -0.134773    -0.0191841    0.00720256    0.0311815    -0.00652551   0.255652    -0.0103719  -0.11579      0.0318945   -0.122555     0.153142     0.0334566   -0.00065361   0.0403519   -0.0481167    0.0330418   -0.150882    -0.146675    -0.0662702   -0.203669   -0.0401361    0.118039
 -0.00135769    0.106615     0.121823   -0.00985955   0.0832518    0.0384169   -0.0109323     0.108287      0.135562     0.111299     0.171569    0.0798912   -0.130796    -0.140733     0.0927752   -0.00761049  -0.0183252   -0.029785     0.00667488  -0.0184499   -0.0152675    0.108297     0.0745074   -0.0527214  -0.0642946   -0.0973929
 -0.0757468    -0.0335245   -0.045058    0.0165936    0.0525935    0.0776579    0.146946     -0.000739513  -0.00583263  -0.18918     -0.107893    0.0932291   -0.0967215   -0.0793758   -0.0451967   -0.0799774    0.112931    -0.0125749    0.0753572    0.0634147   -0.0911896   -0.0990856    0.174256     0.0300233   0.00113532  -0.0341367
 -0.085214      0.12291      0.0943713   0.208025     0.0421353   -0.197271     0.0713655     0.0478504     7.41549e-5   0.0196994   -0.0285038   0.0803438    0.100755    -0.0545779    0.03885      0.102569    -0.0830173    0.0449987   -0.0406583   -0.109951    -0.00595846   0.120454     0.0690996   -0.118953    0.00553652  -0.0975352
 -0.0133117     0.077618     0.0535164   0.0716917    0.0796028   -0.0079391   -0.0725103    -0.219574     -0.103454     0.16195     -0.067679   -0.0519173   -0.0427817    0.0939958    0.122971    -0.0644366   -0.174524    -0.0401025    0.0432258   -0.131179    -0.035003     0.203075    -0.161085     0.0105227  -0.0166046   -0.070216
  0.0399227     0.256551    -0.0612539  -0.21736     -0.0210068   -0.106888     0.0900388     0.26888      -0.0106181   -0.0219413    0.023242    0.172677    -0.0349711   -0.0631302   -0.18504     -0.0122311   -0.0729336   -0.0371947   -0.0769726    0.0772078    0.0926674   -0.0544782    0.134178     0.231852    0.0264777    0.0350022
  0.0248698     0.0867607   -0.0387757   0.0300421   -0.114422    -0.0734144   -0.00924137    0.0604123    -0.049367     0.0600905    0.0974422  -0.130724    -0.011046     0.0898058    0.0584104    0.119438     0.01054      0.105368    -0.14777      0.064246     0.242505    -0.15521      0.0247289    0.077006    0.102561    -0.0789132
  0.0941112     0.0832548    0.207022   -0.0840171   -0.0593102    0.0626842   -0.104916      0.182767     -0.0234622    0.0398365   -0.189106   -0.0475984   -0.0210527    0.0635383   -0.0153481    0.0240852   -0.0996588   -0.0803937   -0.017149     0.0435988    0.0730573    0.0673205   -0.0817416   -0.204995   -0.13707     -0.0179399
  0.0707574    -0.0882221   -0.0335269   0.0150971   -0.0421181   -0.0428577   -0.0330695    -0.17161       0.0440571    0.223104     0.09019     0.0779643    0.0435179    0.0813336    0.0866036   -0.200707    -0.114216    -0.0106491   -0.0964635    0.226879     0.159559    -0.0208489   -0.0564048   -0.0734975   0.0618443   -0.207838
 -0.172986      0.123638     0.0486529   0.0964658    0.00314903  -0.0711469    0.030396     -0.0851841     0.0803679   -0.0307565   -0.0670974  -0.0385197   -0.27564     -0.0649757    0.0339399   -0.063445    -0.131161     0.0381253   -0.188604     0.0628927    0.0244354    0.0581538    0.142155     0.0636644   0.0170057    0.00374068
 -0.0226751     0.0384193   -0.116672   -0.111295    -0.0613321    0.0737105   -0.0498878    -0.103485     -0.053309    -0.0271009    0.112644   -0.0886804   -0.200908     0.114855    -0.112847     0.134523     0.187064     0.0854484    0.0261569    0.0783782    0.0507544   -0.0442871   -0.088297     0.0653483   0.00405525  -0.124678
 -0.0428393    -0.087963    -0.192667   -0.134986    -0.149335    -0.0160182   -0.000835976   0.0846328    -0.0809204   -0.102089     0.126684   -0.0862185    0.263546    -0.0639266   -0.0386727   -0.0985713   -0.0382701   -0.0742785    0.0611259   -0.129511    -0.0249934    0.0410017   -0.0536093   -0.139182   -0.211401     0.00281521
 -0.022778     -0.18229     -0.0329101   0.0449509    0.0499942   -0.0699735   -0.0243127     0.110295     -0.154656     0.28624      0.0672221   0.0054497   -0.120811     0.0546849    0.146986     0.0759492   -0.0292238    0.0402507    0.0889792   -0.102146    -0.00391694  -0.0304247   -0.185134    -0.033692    0.118577     0.0219204
 -0.0991585    -0.144065     0.142576   -0.034623    -0.0204925    0.0645865    0.0551147    -0.0964069     0.177737     0.0541834   -0.0698208   0.00120255   0.1195      -0.0304603   -0.15294     -0.00307948  -0.0471797    0.0703865   -0.00315406  -0.12136     -0.00444518  -0.0691082    0.0550759    0.106064    0.0134402    0.0563034
  0.0849047    -0.125404    -0.0316518   0.0222972    0.0867663    0.0947849   -0.0170353     0.0996026     0.0522249   -0.00865333   0.095766   -0.127123     0.0606405    0.229599     0.106107    -0.0751918    0.0608621    0.148513    -0.0140803    0.0904032   -0.0244171   -0.124988     0.0649619   -0.0305368  -0.154191    -0.029765
 -0.0127005     0.0105299   -0.0620674   0.0136539    0.110659     0.109159    -0.0874711    -0.196353      0.0223092    0.0110867   -0.079014    0.108067    -0.0360929   -0.0886231   -0.0342487    0.207242     0.166122     0.104911     0.0355754    0.0528553   -0.0755218    0.0496501   -0.0789384   -0.0342841  -0.178374    -0.0788588
 -0.000780172   0.142061    -0.0877361  -0.0690197    0.0178149   -0.0927828   -0.1231        0.096628      3.79245e-5  -0.0512502   -0.0259661  -0.168679    -0.0429156   -0.095825     0.0427536   -0.0778013   -0.0830428    0.0899351    0.128045    -0.0447662   -0.0240973   -0.0508205    0.0574879    0.0632525   0.0691264    0.0552066
 -3.86789e-5   -0.0270986    0.031167   -0.0517921   -0.0126456   -0.0517343   -0.0109029     0.12414       0.00531305  -0.00876925   0.0955776  -0.0694189   -0.0866091    0.16447      0.0633545   -0.0835529   -0.00321182  -0.00319183   0.173026     0.00992399   0.058149     0.156483     0.114624    -0.0570409  -0.00453296   0.0493566
  0.0071994    -0.414074    -0.10417     0.0173363   -0.131439     0.0185058   -0.0989062    -0.0118209     0.230621     0.0543857    0.0684891  -0.064515    -0.0735542    0.136115     0.0288571    0.0423615   -0.0784001   -0.00422682  -0.0561288   -0.0935751   -0.011783     0.1295      -0.0215296    0.0413195   0.0416468   -0.121599
 -0.19791       0.0142936   -0.0633389  -0.108754    -0.0182163   -0.0296403    0.0713906     0.0446015    -0.151805     0.159589     0.0115915   0.115061     0.105523     0.0851207   -0.0889834    0.0537576    0.0356257   -0.00265376  -0.11782      0.0631768    0.0495684    0.0215001    0.014266     0.0493549   0.179982     0.0595132
  0.0811647    -0.0492409    0.026974    0.044965    -0.0858838    0.141319    -0.0695        0.112273     -0.0522092   -0.0847618    0.158719   -0.156406    -0.155495    -0.0629689   -0.327556     0.0180985   -0.123956    -0.182541    -0.170177    -0.031249    -0.0051795   -0.00218886  -0.0868094    0.130626    0.108478    -0.00757187kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4256712023298224
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425757
[ Info: iteration 2, average log likelihood -1.425684
[ Info: iteration 3, average log likelihood -1.425446
[ Info: iteration 4, average log likelihood -1.422053
[ Info: iteration 5, average log likelihood -1.405425
[ Info: iteration 6, average log likelihood -1.393016
[ Info: iteration 7, average log likelihood -1.390795
[ Info: iteration 8, average log likelihood -1.389974
[ Info: iteration 9, average log likelihood -1.389420
[ Info: iteration 10, average log likelihood -1.389019
[ Info: iteration 11, average log likelihood -1.388728
[ Info: iteration 12, average log likelihood -1.388507
[ Info: iteration 13, average log likelihood -1.388334
[ Info: iteration 14, average log likelihood -1.388189
[ Info: iteration 15, average log likelihood -1.388061
[ Info: iteration 16, average log likelihood -1.387940
[ Info: iteration 17, average log likelihood -1.387825
[ Info: iteration 18, average log likelihood -1.387712
[ Info: iteration 19, average log likelihood -1.387602
[ Info: iteration 20, average log likelihood -1.387495
[ Info: iteration 21, average log likelihood -1.387387
[ Info: iteration 22, average log likelihood -1.387268
[ Info: iteration 23, average log likelihood -1.387122
[ Info: iteration 24, average log likelihood -1.386929
[ Info: iteration 25, average log likelihood -1.386691
[ Info: iteration 26, average log likelihood -1.386478
[ Info: iteration 27, average log likelihood -1.386332
[ Info: iteration 28, average log likelihood -1.386238
[ Info: iteration 29, average log likelihood -1.386177
[ Info: iteration 30, average log likelihood -1.386134
[ Info: iteration 31, average log likelihood -1.386103
[ Info: iteration 32, average log likelihood -1.386082
[ Info: iteration 33, average log likelihood -1.386066
[ Info: iteration 34, average log likelihood -1.386055
[ Info: iteration 35, average log likelihood -1.386047
[ Info: iteration 36, average log likelihood -1.386041
[ Info: iteration 37, average log likelihood -1.386037
[ Info: iteration 38, average log likelihood -1.386033
[ Info: iteration 39, average log likelihood -1.386031
[ Info: iteration 40, average log likelihood -1.386029
[ Info: iteration 41, average log likelihood -1.386028
[ Info: iteration 42, average log likelihood -1.386027
[ Info: iteration 43, average log likelihood -1.386026
[ Info: iteration 44, average log likelihood -1.386025
[ Info: iteration 45, average log likelihood -1.386025
[ Info: iteration 46, average log likelihood -1.386024
[ Info: iteration 47, average log likelihood -1.386024
[ Info: iteration 48, average log likelihood -1.386024
[ Info: iteration 49, average log likelihood -1.386023
[ Info: iteration 50, average log likelihood -1.386023
┌ Info: EM with 100000 data points 50 iterations avll -1.386023
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4257565421570162
│     -1.4256837556575668
│      ⋮
└     -1.386023295308192
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.386110
[ Info: iteration 2, average log likelihood -1.386029
[ Info: iteration 3, average log likelihood -1.385776
[ Info: iteration 4, average log likelihood -1.383413
[ Info: iteration 5, average log likelihood -1.373618
[ Info: iteration 6, average log likelihood -1.361447
[ Info: iteration 7, average log likelihood -1.354739
[ Info: iteration 8, average log likelihood -1.351394
[ Info: iteration 9, average log likelihood -1.349399
[ Info: iteration 10, average log likelihood -1.348097
[ Info: iteration 11, average log likelihood -1.347151
[ Info: iteration 12, average log likelihood -1.346361
[ Info: iteration 13, average log likelihood -1.345683
[ Info: iteration 14, average log likelihood -1.345140
[ Info: iteration 15, average log likelihood -1.344696
[ Info: iteration 16, average log likelihood -1.344345
[ Info: iteration 17, average log likelihood -1.344071
[ Info: iteration 18, average log likelihood -1.343856
[ Info: iteration 19, average log likelihood -1.343684
[ Info: iteration 20, average log likelihood -1.343545
[ Info: iteration 21, average log likelihood -1.343429
[ Info: iteration 22, average log likelihood -1.343325
[ Info: iteration 23, average log likelihood -1.343227
[ Info: iteration 24, average log likelihood -1.343133
[ Info: iteration 25, average log likelihood -1.343042
[ Info: iteration 26, average log likelihood -1.342949
[ Info: iteration 27, average log likelihood -1.342852
[ Info: iteration 28, average log likelihood -1.342755
[ Info: iteration 29, average log likelihood -1.342658
[ Info: iteration 30, average log likelihood -1.342564
[ Info: iteration 31, average log likelihood -1.342474
[ Info: iteration 32, average log likelihood -1.342394
[ Info: iteration 33, average log likelihood -1.342323
[ Info: iteration 34, average log likelihood -1.342262
[ Info: iteration 35, average log likelihood -1.342212
[ Info: iteration 36, average log likelihood -1.342172
[ Info: iteration 37, average log likelihood -1.342142
[ Info: iteration 38, average log likelihood -1.342118
[ Info: iteration 39, average log likelihood -1.342099
[ Info: iteration 40, average log likelihood -1.342083
[ Info: iteration 41, average log likelihood -1.342070
[ Info: iteration 42, average log likelihood -1.342059
[ Info: iteration 43, average log likelihood -1.342048
[ Info: iteration 44, average log likelihood -1.342039
[ Info: iteration 45, average log likelihood -1.342031
[ Info: iteration 46, average log likelihood -1.342023
[ Info: iteration 47, average log likelihood -1.342015
[ Info: iteration 48, average log likelihood -1.342007
[ Info: iteration 49, average log likelihood -1.342000
[ Info: iteration 50, average log likelihood -1.341992
┌ Info: EM with 100000 data points 50 iterations avll -1.341992
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3861104447796175
│     -1.3860292672380548
│      ⋮
└     -1.3419916249406887
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.342114
[ Info: iteration 2, average log likelihood -1.341976
[ Info: iteration 3, average log likelihood -1.341573
[ Info: iteration 4, average log likelihood -1.337955
[ Info: iteration 5, average log likelihood -1.322991
[ Info: iteration 6, average log likelihood -1.307303
[ Info: iteration 7, average log likelihood -1.301546
[ Info: iteration 8, average log likelihood -1.298700
[ Info: iteration 9, average log likelihood -1.296461
[ Info: iteration 10, average log likelihood -1.294532
[ Info: iteration 11, average log likelihood -1.293013
[ Info: iteration 12, average log likelihood -1.291864
[ Info: iteration 13, average log likelihood -1.291009
[ Info: iteration 14, average log likelihood -1.290338
[ Info: iteration 15, average log likelihood -1.289726
[ Info: iteration 16, average log likelihood -1.289078
[ Info: iteration 17, average log likelihood -1.288504
[ Info: iteration 18, average log likelihood -1.288117
[ Info: iteration 19, average log likelihood -1.287879
[ Info: iteration 20, average log likelihood -1.287711
[ Info: iteration 21, average log likelihood -1.287563
[ Info: iteration 22, average log likelihood -1.287409
[ Info: iteration 23, average log likelihood -1.287239
[ Info: iteration 24, average log likelihood -1.287043
[ Info: iteration 25, average log likelihood -1.286808
[ Info: iteration 26, average log likelihood -1.286534
[ Info: iteration 27, average log likelihood -1.286239
[ Info: iteration 28, average log likelihood -1.285948
[ Info: iteration 29, average log likelihood -1.285666
[ Info: iteration 30, average log likelihood -1.285346
[ Info: iteration 31, average log likelihood -1.284907
[ Info: iteration 32, average log likelihood -1.284272
[ Info: iteration 33, average log likelihood -1.283555
[ Info: iteration 34, average log likelihood -1.283100
[ Info: iteration 35, average log likelihood -1.282931
[ Info: iteration 36, average log likelihood -1.282869
[ Info: iteration 37, average log likelihood -1.282842
[ Info: iteration 38, average log likelihood -1.282829
[ Info: iteration 39, average log likelihood -1.282821
[ Info: iteration 40, average log likelihood -1.282817
[ Info: iteration 41, average log likelihood -1.282813
[ Info: iteration 42, average log likelihood -1.282810
[ Info: iteration 43, average log likelihood -1.282807
[ Info: iteration 44, average log likelihood -1.282805
[ Info: iteration 45, average log likelihood -1.282802
[ Info: iteration 46, average log likelihood -1.282799
[ Info: iteration 47, average log likelihood -1.282796
[ Info: iteration 48, average log likelihood -1.282793
[ Info: iteration 49, average log likelihood -1.282788
[ Info: iteration 50, average log likelihood -1.282783
┌ Info: EM with 100000 data points 50 iterations avll -1.282783
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3421142624515516
│     -1.341976080365475
│      ⋮
└     -1.2827834254560804
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.282967
[ Info: iteration 2, average log likelihood -1.282720
[ Info: iteration 3, average log likelihood -1.281282
[ Info: iteration 4, average log likelihood -1.266447
[ Info: iteration 5, average log likelihood -1.229456
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.205751
[ Info: iteration 7, average log likelihood -1.199871
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.185949
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      4
│      5
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.198332
[ Info: iteration 10, average log likelihood -1.226986
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.201430
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.199332
[ Info: iteration 13, average log likelihood -1.213195
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.197023
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      5
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.189403
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.212935
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.211284
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.204556
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.197774
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.191938
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.197995
[ Info: iteration 22, average log likelihood -1.224504
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.205168
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.197116
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.192493
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.201750
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.197507
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.204278
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.195650
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.205142
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.197180
[ Info: iteration 32, average log likelihood -1.195360
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.180982
[ Info: iteration 34, average log likelihood -1.222136
[ Info: iteration 35, average log likelihood -1.209103
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.191747
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.202218
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.199833
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.199261
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.193660
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.194120
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.207418
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.206885
[ Info: iteration 44, average log likelihood -1.197396
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.182570
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.198001
[ Info: iteration 47, average log likelihood -1.218939
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.201143
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.202527
[ Info: iteration 50, average log likelihood -1.201340
┌ Info: EM with 100000 data points 50 iterations avll -1.201340
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.282967294882482
│     -1.2827197713287983
│      ⋮
└     -1.201340320566078
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     11
│     12
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.187513
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     11
│     12
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.181229
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.175623
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     12
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.165455
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│     11
│     12
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.128935
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.089320
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     12
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.103079
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      8
│     11
│      ⋮
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.084621
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.093113
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.090601
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│     11
│      ⋮
│     22
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.102800
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.083804
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.092831
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.091193
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.104040
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.086795
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.085472
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.069338
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.105150
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.091879
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.087126
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.077367
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.085224
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.096474
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.092335
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.082127
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.090623
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.076485
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.097294
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.084040
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.098262
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.082154
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.077049
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.088926
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.099831
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.089605
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.083069
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.071881
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.102143
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.091548
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.090452
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.074289
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.088027
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.093959
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.094925
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.079107
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.093301
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.077175
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.097250
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.084036
┌ Info: EM with 100000 data points 50 iterations avll -1.084036
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1875126843660297
│     -1.1812285486752028
│      ⋮
└     -1.0840359552849421
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4256712023298224
│     -1.4257565421570162
│     -1.4256837556575668
│     -1.4254464951424775
│      ⋮
│     -1.0771750620559726
│     -1.0972499902818749
└     -1.0840359552849421
32×26 Array{Float64,2}:
  0.104956     0.0373473   -0.0702187   0.0530824  -0.167063    -0.00181324   -1.25766     -0.00533938   0.0673889    0.0908537   -0.0286242    0.733939    -0.0945719    0.0753432   -0.105087    -0.171337     0.19277      0.230072    -0.0942073   -0.177925    -0.119552     -0.0269656    0.248002    -0.120111    -0.306328     0.00329713
 -0.133422    -0.0209339   -0.0673683  -0.0849297  -0.0967549   -0.0978523     0.555194    -0.147489     0.0744432    0.0609309   -0.0347358   -0.254685    -0.102649     0.067116    -0.133416    -0.158795     0.0113596   -0.104852    -0.0581677    0.045927    -0.0840208    -0.0267333   -0.0888177   -0.126371    -0.144884     0.0798781
 -0.193382    -0.0233382   -0.0568071   0.144556    0.130464     0.0893906     0.163995    -0.0149448   -0.00545137  -0.18756     -0.108385    -0.0298444   -0.0965969   -0.0838381   -0.329253    -0.0737756    0.123922     0.0176103   -0.0535362    0.0651578   -0.179789     -0.190215     0.242296     0.0284963   -0.0650188   -0.0814844
  0.0185995   -0.0115542   -0.0215919  -0.054136   -0.016252     0.0928929     0.13933     -0.00781067  -0.00610709  -0.168658    -0.11037      0.239038    -0.0963265   -0.0807314    0.245405    -0.0812861    0.101768    -0.0447426    0.167591     0.0629708    0.0211811    -0.0384192    0.0725428    0.0321529    0.179237     0.0262644
 -0.0768479   -0.104412    -0.137044    0.144066    0.0937237   -0.0926657     0.0765347   -0.00710549  -0.0581026    0.0331114   -0.207516     0.0548879    0.107459    -0.0857346    0.185994     0.0546906    0.0964103   -0.00457069  -0.14754     -0.0162397    0.0462642     0.0595839   -0.0755224    0.00556183  -0.0585033   -0.0740368
 -0.090196     0.165464     0.0982911   0.224547    0.0454198   -0.211734      0.0705431    0.0498033    0.0381459    0.0221247   -0.0302071    0.0937397    0.122589    -0.0254471    0.0406543    0.100986    -0.108359     0.0761303   -0.0315128   -0.106167     0.0199034     0.123929     0.0769846   -0.110976    -0.00851529  -0.00634969
 -0.235066     0.00515756  -0.0863926  -0.110892   -0.0156295   -0.0273788     0.0859108    0.0393803   -0.155452     0.168378     0.0112821    0.123988     0.154846     0.0929147   -0.0861316    0.0551848    0.0703157    0.0186582   -0.130809     0.0490794    0.025573      0.0176152    0.0411734    0.0473275    0.19427      0.0737868
  0.0607629   -0.114194    -0.0372121   0.0326584   0.0819612    0.0931244     0.0401968    0.104095     0.0523608   -0.00604327   0.0951754   -0.11663     -0.0129862    0.219896     0.106856    -0.0770769    0.0805656    0.178301    -0.0230091    0.0850245   -0.0244881    -0.123373     0.0921813   -0.00497904  -0.148421    -0.0138835
 -0.0317461    0.0694967    0.115515   -0.0545726  -0.161345    -0.0176054    -0.0578008    0.0933717   -0.0657932    0.0643997   -0.135089     0.061972    -0.11538     -0.165654     0.122739     0.14012      0.0071457   -0.114366     0.0363608   -0.0751914   -0.0866017    -0.0539265   -0.090931    -0.123023    -0.10593      0.0121653
 -0.033909     0.0600533    0.0493798   0.221245   -0.0528365   -0.00490651   -0.0567029   -0.0237258    0.516524     0.131516     0.225357     0.0255691   -0.0606136   -0.355713     0.0487731   -0.234311     0.0222896   -0.0627651   -0.0517583   -0.308223    -0.0799594    -0.0743894   -0.0851482   -0.123501    -0.0845355    0.101049
 -0.0132598    0.0497891    0.0563769  -0.0409176  -0.326846    -0.000521128  -0.0957049   -0.218722    -0.224899     0.0479935   -0.12671      0.0356711   -0.0799038    0.0679261    0.122267    -0.0735808   -0.277656    -0.0353934    0.139224    -0.103546    -0.208999      0.19728     -0.199365    -0.26103      0.0127052   -0.0580227
 -0.0155619    0.106199     0.140164    0.201961    0.430456    -0.00696897   -0.051526    -0.220769    -0.0374563    0.251502     0.0251434   -0.212255     0.00245312   0.14014      0.129552    -0.062708    -0.0653858   -0.0521887   -0.0441043   -0.148496     0.0403141     0.219564    -0.129814     0.277249    -0.0412382   -0.0302592
 -0.117049     0.0719084   -0.0911314  -0.167657    0.117039    -0.144599     -0.25638     -0.0702882   -0.0227923   -0.405152     0.273615    -0.498544     0.0402623    0.00211521   0.0837562   -0.0263258    0.00494281  -0.0885951   -0.161839    -0.0424037   -0.0725314    -0.0710192   -0.197481    -0.0203615   -0.178756    -0.216327
 -0.116832     0.0289191   -0.251136   -0.0959665   0.00479051  -0.127219     -0.207185    -0.113271    -0.0124452    0.178775     0.349129     0.390942     0.126194    -0.0122188    0.135955    -0.024845    -0.312211    -0.0941803   -0.0496852    0.1989       0.083875     -0.0758989   -0.208143     0.0747414   -0.191564    -0.299471
  0.0867648    0.0768542    0.203792   -0.0836808  -0.0521287    0.0656521    -0.113233     0.181931    -0.00686057   0.0259572   -0.202805    -0.0225103   -0.0424923    0.0778463   -0.00987229   0.0295932   -0.0957608   -0.0775681   -0.0170547    0.0214979    0.0852349     0.0996965   -0.0796718   -0.193584    -0.138588    -0.0139324
 -0.0340864    0.0439177   -0.0715207  -0.125212   -0.0513688    0.0471404    -0.041842    -0.0953376   -0.0104566   -0.0503404    0.101867    -0.0675353   -0.16524      0.100861    -0.115002     0.140195     0.166159     0.0699934    0.0283646    0.130778     0.105704     -0.0332884   -0.0825994    0.0568803    0.0104012   -0.0988411
  0.00292523   0.0558684   -0.0165323  -0.0488804   0.0119427   -0.0782827    -0.0658156    0.115398    -0.014503    -0.0526264    0.0275697   -0.117659    -0.0779462    0.0277504    0.0710204   -0.0891135   -0.0488067    0.0292285    0.159805    -0.0281274    0.0142239     0.0606096    0.0886693   -0.0196021    0.00942644   0.105804
  0.0336533   -0.0278069   -0.0037588   0.0477332  -0.00455764   0.125742     -0.0780692   -0.0477347    0.0279946   -0.041242     0.0452325   -0.0186518   -0.083018    -0.0723658   -0.175037     0.0991583    0.0327843   -0.0465036   -0.0550992    0.00676458  -0.0237871     0.0163908   -0.0967424    0.0584678   -0.0385538   -0.0552659
  0.0238235    0.0912064   -0.141865   -0.206245   -0.100375    -0.0471218     0.0456477    0.16726     -0.0510071   -0.0343972    0.0823641    0.0357755    0.165311    -0.0777368   -0.127407    -0.0553674   -0.0503323   -0.0597046    0.0139287   -0.050117     0.0337865    -0.0131866   -0.0125206    0.0381816   -0.134228     0.0175044
 -0.151271     0.13503      0.0310441   0.128969   -0.00398732  -0.0627105     0.0277053   -0.0392706    0.0835202   -0.0355622   -0.0534653   -0.0266207   -0.235442    -0.0601069    0.0208866   -0.0653432   -0.129236     0.016985    -0.159399     0.0170987    0.0160769     0.0538621    0.130104     0.0444663   -0.003232     0.00795945
  0.00283943   0.154714     0.12216     0.0647984  -0.187122     0.0384124    -0.209175     0.404093     0.237812     0.00814985   0.0537856    0.113725     0.0404289   -0.292718    -0.00256214  -0.0164815   -0.129095     0.0982683   -0.00379569  -0.440202    -0.115818      0.153788     0.00253685  -0.431233     0.269703     0.152814
  0.0378148    0.154776     0.0626437   0.0614537  -0.187025     0.00434656    0.122803    -0.102339     0.0124196   -0.0674682    0.109641     0.113693     0.033511     0.00325705   0.0140431   -0.0363305   -0.0884731    0.102896     0.0285137    0.493752    -0.0735635     0.300146     0.128253     0.430773     0.242607    -0.0262502
  0.0430815    0.0796824   -0.049792    0.0379047  -0.110207    -0.138685     -0.0137415    0.0587552   -0.043396     0.0631436    0.0359599   -0.131663    -0.0148582    0.0862192    0.0585601    0.118428     0.0232218    0.114552    -0.159979     0.0658987    0.241094     -0.16433      0.0204711    0.0832095    0.0976267   -0.105279
 -0.0102316   -0.0807048   -0.176543   -0.112102    0.159192    -0.0672264    -0.0537549   -0.0532064   -0.0716923    0.0563238   -0.0651748    0.00305954   0.0261301   -0.0571075    0.029439    -0.0287439   -0.10951      0.0425274   -0.0180043    0.0575813   -0.104546     -0.00869324  -0.00977626   0.0721044    0.166667    -0.10651
 -0.0435687    0.129577     0.0409389   0.0626717   0.0718578    0.0762606    -0.0380388    0.113416    -0.0756986    0.0826614    0.0881875    0.0100096   -0.0718432   -0.0113264   -0.0167622    0.0589704   -0.0591449   -0.00979082  -0.0236129   -0.0413136   -0.0098331     0.0460069    0.0370105   -0.0387559   -0.07149     -0.0223711
  0.0762553    0.0608141    0.0222043   0.0745306   0.202175     0.0187164     0.00207391   0.0102962   -0.0284133   -0.0291325   -0.0314273    0.00918662  -0.181544     0.00849551  -0.18586      0.224042    -0.104838     0.138876    -0.262218    -0.0979159   -0.146143     -0.268505    -0.0103778    0.206469     0.0944303    0.10925
  0.0227759   -0.157742    -0.058586   -0.0306731  -0.0495392   -0.0694522     0.00308118  -0.122955     0.173446     0.0230291    0.0121453    0.0419826   -0.0296767    0.0855078   -0.00914061   0.00355882  -0.0142207    0.0487675    0.054253    -0.0912209    0.0240335     0.0732186    0.0137155    0.0405016    0.0297975   -0.120589
  0.0253666   -0.0297904   -0.133956   -0.230272   -0.151943    -0.026205     -0.0106266    0.0290577   -0.0264996    0.25587     -0.00331525  -0.110959     0.0547682   -0.132987     0.193364    -0.0581147    0.0103098    0.0442365   -0.0482741    0.0331214   -0.1004       -0.139736    -0.0662468   -0.179157     0.00741644   0.12468
 -0.10018     -0.134581     0.139767   -0.0300762   0.0242965    0.0830421     0.0635298   -0.0563692    0.166186     0.0542965   -0.0636395   -0.00423814   0.111897    -0.0498705   -0.148659    -0.00325989  -0.0577437    0.0614247   -0.012807    -0.167284    -0.0180562    -0.0788957    0.0592833    0.0997495    0.0285363    0.0546491
  0.0697658   -0.0637839   -0.0261145   0.0153959  -0.0399167   -0.0385834    -0.0405046   -0.171015     0.0550721    0.214009     0.0746136    0.076466     0.0629336    0.0640561    0.0889009   -0.200814    -0.117239    -0.00585671  -0.0980317    0.22714      0.161478     -0.0463365   -0.0419228   -0.0595618    0.0594172   -0.207984
  0.0733755    0.00417123   0.0141588  -0.0790752  -0.0428136    0.0727102     0.0683609    0.0644377    0.144769    -0.00250469   0.117305    -0.0859742    0.0645938   -0.0607631    0.122176    -0.0143727   -0.143812     0.0362769   -0.0838743    0.0424771   -0.000609758  -0.0844148   -0.00121666   0.212026     0.104147     0.0668797
 -0.0144669   -0.18056     -0.0318514   0.0478947   0.0545367   -0.054065      0.0155121    0.178483    -0.142159     0.280783     0.0679851    0.00857067  -0.122057     0.0516587    0.148728     0.0992759   -0.0325195    0.0412435    0.0836541   -0.106731     0.00943631   -0.092095    -0.184516    -0.0328769    0.0986285    0.0210907[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.095026
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.067144
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.077016
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.063557
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.086910
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.061933
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.069775
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.049517
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.077350
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.057341
┌ Info: EM with 100000 data points 10 iterations avll -1.057341
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.015013e+05
      1       7.082973e+05      -1.932040e+05 |       32
      2       6.806273e+05      -2.766997e+04 |       32
      3       6.669918e+05      -1.363554e+04 |       32
      4       6.578757e+05      -9.116131e+03 |       32
      5       6.513341e+05      -6.541579e+03 |       32
      6       6.471170e+05      -4.217113e+03 |       32
      7       6.446737e+05      -2.443313e+03 |       32
      8       6.431872e+05      -1.486483e+03 |       32
      9       6.420252e+05      -1.162001e+03 |       32
     10       6.411028e+05      -9.224169e+02 |       32
     11       6.401633e+05      -9.394745e+02 |       32
     12       6.390074e+05      -1.155936e+03 |       32
     13       6.375929e+05      -1.414513e+03 |       32
     14       6.364648e+05      -1.128073e+03 |       32
     15       6.356719e+05      -7.928970e+02 |       32
     16       6.350324e+05      -6.394969e+02 |       32
     17       6.345731e+05      -4.593167e+02 |       32
     18       6.341478e+05      -4.253063e+02 |       32
     19       6.337259e+05      -4.219082e+02 |       32
     20       6.333460e+05      -3.798354e+02 |       32
     21       6.330608e+05      -2.852213e+02 |       32
     22       6.328880e+05      -1.727631e+02 |       32
     23       6.327927e+05      -9.533270e+01 |       32
     24       6.327334e+05      -5.925175e+01 |       32
     25       6.326988e+05      -3.468642e+01 |       31
     26       6.326733e+05      -2.550554e+01 |       32
     27       6.326558e+05      -1.748055e+01 |       31
     28       6.326417e+05      -1.407282e+01 |       32
     29       6.326264e+05      -1.532499e+01 |       30
     30       6.326137e+05      -1.268399e+01 |       28
     31       6.326072e+05      -6.500380e+00 |       27
     32       6.326028e+05      -4.438093e+00 |       28
     33       6.325994e+05      -3.393013e+00 |       25
     34       6.325951e+05      -4.233599e+00 |       23
     35       6.325921e+05      -3.018047e+00 |       26
     36       6.325886e+05      -3.507642e+00 |       29
     37       6.325854e+05      -3.241656e+00 |       25
     38       6.325826e+05      -2.720665e+00 |       23
     39       6.325807e+05      -1.907110e+00 |       18
     40       6.325796e+05      -1.145861e+00 |       20
     41       6.325785e+05      -1.062721e+00 |       14
     42       6.325780e+05      -5.696266e-01 |        8
     43       6.325776e+05      -3.562320e-01 |        7
     44       6.325774e+05      -2.355500e-01 |        7
     45       6.325772e+05      -1.468532e-01 |        6
     46       6.325770e+05      -1.813809e-01 |        6
     47       6.325769e+05      -1.675916e-01 |        4
     48       6.325768e+05      -5.277071e-02 |        2
     49       6.325767e+05      -6.993030e-02 |        7
     50       6.325765e+05      -2.669244e-01 |        7
K-means terminated without convergence after 50 iterations (objv = 632576.4780444959)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.345078
[ Info: iteration 2, average log likelihood -1.311241
[ Info: iteration 3, average log likelihood -1.279791
[ Info: iteration 4, average log likelihood -1.245616
[ Info: iteration 5, average log likelihood -1.209102
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.159606
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      5
│      7
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.102412
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     16
│     23
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.103745
[ Info: iteration 9, average log likelihood -1.151665
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.087746
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│     19
│     20
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.045312
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     10
│     15
│     16
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.097670
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.145282
[ Info: iteration 14, average log likelihood -1.113317
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      5
│     15
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.049919
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     16
│     19
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.088275
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      9
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.117420
[ Info: iteration 18, average log likelihood -1.122733
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      5
│     16
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.061147
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.087852
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     19
│     22
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.091481
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.118560
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      5
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.067206
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.064490
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     22
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.102126
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.116768
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      5
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.062187
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     15
│     22
│     23
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.051328
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.137460
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.114612
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      5
│     16
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.054803
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     22
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.072770
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.122356
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.092088
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     16
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.067297
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.063437
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.103942
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.097389
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     16
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.065763
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     10
│     15
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.058908
[ Info: iteration 41, average log likelihood -1.137518
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.074211
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     16
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.060461
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     10
│     15
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.080688
[ Info: iteration 45, average log likelihood -1.134909
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.069520
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     22
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.017222
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.165216
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.137481
[ Info: iteration 50, average log likelihood -1.096859
┌ Info: EM with 100000 data points 50 iterations avll -1.096859
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0120319   -0.0809659   -0.180665   -0.11462     0.161701    -0.0721763   -0.0530995   -0.0517192   -0.0785831     0.0575674   -0.0698818    0.000716315   0.0295764   -0.0536851    0.0307561   -0.0277839   -0.107744     0.0450326    -0.0164246    0.0642014  -0.105335     -0.00457224  -0.0180158    0.0707423    0.16817     -0.111922
  0.0868275    0.0770352    0.201426   -0.08391    -0.0527       0.0656761   -0.111027     0.181908    -0.00614549    0.0263306   -0.203139    -0.0200276    -0.0439397    0.0777914   -0.0105105    0.0304067   -0.0968735   -0.0767517    -0.0164253    0.0210588   0.085705      0.100085    -0.0799082   -0.192237    -0.138575    -0.0119885
 -0.0263626    0.177896    -0.0685737   0.0812418   0.0872344    0.171949    -0.0397427    0.217732    -0.245093      0.160042     0.0310201   -0.111415     -0.0582352    0.0873649   -0.151523     0.084401    -0.0584945    0.141295     -0.01996     -0.0297219  -0.0499394     0.108532     0.0651911    0.0489149   -0.0997281   -0.081912
  0.0102166    0.14007     -0.082526   -0.0355239   0.0158022   -0.0699332   -0.119179     0.0832632    1.54383e-5   -0.079689    -0.0316675   -0.176543     -0.0702222   -0.0908168    0.0748509   -0.0858592   -0.0957933    0.071994      0.146371    -0.0343598  -0.0245734    -0.0499366    0.0573294    0.0429296    0.0296358    0.10347
 -0.0992374   -0.123224     0.138061   -0.0330206   0.00996555   0.073965     0.0560022   -0.0613342    0.159774      0.0565365   -0.0682237   -0.00377286    0.120139    -0.0565592   -0.145643    -0.00398458  -0.0556455    0.0604127    -0.00514327  -0.165741   -0.0150507    -0.0830722    0.0542927    0.0958955    0.0198458    0.0565439
  0.0799263   -0.0502418    0.0462209   0.053965   -0.116276     0.149085    -0.065338     0.114957    -0.0126003    -0.0954667    0.154792    -0.154323     -0.155335    -0.0550725   -0.333798     0.0224874   -0.143658    -0.196257     -0.162344    -0.0168735  -0.00390889    0.00432726  -0.099299     0.146666     0.104736    -0.00750612
 -0.0580425   -0.00105538  -0.0677434  -0.0349553  -0.127545    -0.0696887   -0.0648308   -0.101725     0.0736466     0.0734636   -0.0384444    0.0902828    -0.100085     0.0711877   -0.132965    -0.163103     0.0746816   -0.00674597   -0.0754094   -0.0328593  -0.100433     -0.0263243    0.0286513   -0.124056    -0.203476     0.0553661
  0.0792672   -0.00680861   0.0095347  -0.0572499  -0.037346     0.0514418    0.0534095    0.0122737    0.125937      0.0341805    0.10428     -0.0488329     0.0821807   -0.0354289    0.124046    -0.0573369   -0.142497     0.034175     -0.0966101    0.0830987   0.0293823    -0.0827503   -0.00975708   0.168651     0.101422     0.0060305
  0.0622882   -0.049131    -0.0381674   0.0121063  -0.0473765   -0.0401361   -0.0382778   -0.141521     0.0209671     0.225226     0.0447714    0.0571808     0.0251641    0.0620106    0.081764    -0.166719    -0.102704    -0.0090197    -0.0969034    0.206858    0.169696     -0.0358464   -0.0281762   -0.0702792    0.0608051   -0.190475
  0.0146115   -0.103839    -0.271411   -0.167945   -0.139749    -0.0159872    0.00152286   0.0338653   -0.0745275    -0.106442     0.126368    -0.0786685     0.356938    -0.067469    -0.021632    -0.102419    -0.0475887   -0.0724593     0.0926133   -0.143632   -0.00938929    0.0425148   -0.115402    -0.139512    -0.243348     0.00183761
  0.0507088    0.0599081   -0.059099   -0.101796    0.00320715  -0.129698     0.0834243   -0.215823     0.15283       0.0251686   -0.0570691    0.144492      0.0166593    0.0212133   -0.0464699   -0.0182994    0.0583177    0.126185      0.169147    -0.0724188   0.0588718     0.0420153    0.0305724    0.0388239   -0.00836104  -0.143132
 -0.0376283    0.0425438   -0.0840483  -0.138062   -0.0583531    0.0531435   -0.049209    -0.117161    -0.0152305    -0.0403031    0.108811    -0.0826387    -0.174679     0.115207    -0.12294      0.148888     0.187784     0.0839852     0.0245812    0.117473    0.123558     -0.0390127   -0.0916261    0.0607691    0.00978218  -0.113117
 -0.00336522  -0.0148884    0.0331982  -0.0752654   0.00904326  -0.0918602   -0.0162871    0.13298     -0.0248406    -0.0276313    0.0681225   -0.0696496    -0.0872848    0.152719     0.0644946   -0.0739366    0.00135533   0.000311273   0.16933     -0.0180544   0.0337706     0.156888     0.115296    -0.0943446   -0.00452261   0.120509
 -4.32508e-5  -0.413778    -0.0969001   0.0167685  -0.123507     0.0267525   -0.06579     -0.014433     0.247943      0.0573947    0.0704167   -0.0728253    -0.0747913    0.133519     0.0362768    0.0228995   -0.0755892   -0.00341488   -0.0577193   -0.0969996  -0.0232056     0.127704    -0.0056688    0.0411217    0.0652092   -0.116918
 -0.0170671    0.0757381    0.102446    0.0748386   0.0183209   -0.00739233  -0.0711425   -0.183556    -0.11284       0.133071    -0.0640425   -0.0625738    -0.0470893    0.0751786    0.128695    -0.0518539   -0.147951    -0.0472886     0.0424707   -0.1266     -0.0861753     0.170281    -0.151693    -0.0264881   -0.0201529   -0.0317986
 -0.0259756    0.0060414   -0.0508075   0.0380197   0.101601     0.121616    -0.0824664   -0.193179     0.0787816     0.0043376   -0.0599438    0.102642     -0.0102808   -0.10022     -0.0307435    0.15445      0.190409     0.103361      0.0345714    0.0436977  -0.0594313     0.0262534   -0.0968117   -0.0212159   -0.172545    -0.0986348
 -0.116869     0.0506083   -0.166982   -0.137253    0.0622208   -0.13559     -0.231775    -0.0924724   -0.0139863    -0.116129     0.314878    -0.0637263     0.0855811   -0.00499066   0.110498    -0.0254395   -0.150199    -0.0907906    -0.107391     0.0744626   0.000449058  -0.0714886   -0.203535     0.0299123   -0.184929    -0.25758
  0.0122911    0.274248    -0.0391924  -0.187185   -0.0291281   -0.0930662    0.0910264    0.26891     -0.00742654    0.00774221   0.00781324   0.153049     -0.0550558   -0.0634641   -0.203789    -0.0143527   -0.0720485   -0.0377006    -0.0781957    0.0535295   0.0895459    -0.0519729    0.112274     0.222563     0.00148176   0.0337768
 -0.0390898    0.06314      0.129494   -0.0840428  -0.175818    -0.0178246   -0.0502702    0.114627    -0.0230661     0.0633373   -0.0936478    0.0411824    -0.132565    -0.234724     0.109695     0.121239     0.0277779   -0.135578      0.038814    -0.0880025  -0.0773048    -0.0862424   -0.0860244   -0.121871    -0.123106     0.0147063
  0.0242353    0.1539       0.0912188   0.0622239  -0.186217     0.0230646   -0.04156      0.157458     0.129821     -0.028281     0.0829885    0.111388      0.0415472   -0.146083     0.00642564  -0.0263678   -0.108954     0.101552      0.0101202    0.0266506  -0.0977111     0.234467     0.0610769   -0.00565805   0.258106     0.0629211
 -0.0143867   -0.180776    -0.0320368   0.0477771   0.0519046   -0.0537726    0.0161872    0.176969    -0.143165      0.281218     0.0673443    0.00878244   -0.122873     0.0525317    0.14783      0.0981654   -0.0323577    0.0412932     0.0844049   -0.105258    0.0108679    -0.0934789   -0.18401     -0.0323433    0.0984711    0.0202176
 -0.0951946   -0.00372186  -0.0317038   0.0549238   0.0525914    0.0848528    0.144401    -0.00395059  -0.000453236  -0.185599    -0.106527     0.102954     -0.0942595   -0.0787896   -0.0345912   -0.0737607    0.103162    -0.00985394    0.0467867    0.0586022  -0.0829104    -0.121631     0.174241     0.0336412    0.0631782   -0.0235326
 -0.16652      0.154657     0.072943    0.23983    -0.00269836  -0.0811496    0.0272082   -0.0836514    0.0871576    -0.0193003   -0.0718509   -0.032163     -0.376246    -0.0681327    0.0317107   -0.0713424   -0.145381     0.0347646    -0.205594     0.0224238   0.0209737     0.0780252    0.208758     0.0417248    0.00774015   0.0150838
  0.0757727    0.0608693    0.0226991   0.0740084   0.202092     0.0187518    0.00421694   0.0106844   -0.0286051    -0.0288942   -0.031415     0.00867266   -0.181873     0.00774512  -0.186212     0.223029    -0.104979     0.139239     -0.262369    -0.097572   -0.146174     -0.26856     -0.0104785    0.206481     0.0947921    0.109413
  0.0226507   -0.0269512   -0.139517   -0.231698   -0.154514    -0.0251111   -0.0102319    0.0283069   -0.046075      0.245256     0.00478089  -0.136837      0.0647341   -0.1399       0.222521    -0.0768089    0.0123957    0.0379019    -0.0459868    0.0325423  -0.102502     -0.161031    -0.0648695   -0.194035     0.0146388    0.134063
  0.0433648   -0.0395976   -0.0235151  -0.0515077  -0.0248096    0.061217    -0.0655865    0.0880952    0.021351      0.0163129    0.134623    -0.152933     -0.087076     0.120156     0.0889409   -0.035289     0.0436835    0.102217     -0.0447661    0.028883    0.0387038    -0.0774253    0.101233    -0.0839457   -0.0069168   -0.0161477
 -0.1043       0.0526178    0.0898357   0.124777    0.0306282   -0.0267145   -0.0658967   -0.0400967   -0.10209      -0.0589265    0.0659699    0.0622319    -0.00723522   0.0212939    0.0140984    0.099786    -0.0918469   -0.169322     -0.0679687   -0.0193951   0.0657945    -0.0791359   -0.0606836   -0.100065    -0.0211218    0.123539
  0.0417217   -0.101305    -0.0290952   0.039126    0.0722297    0.0873973    0.0401377    0.0885898    0.0510661    -0.00352016   0.0867409   -0.110072     -0.0275055    0.196221     0.0994902   -0.0735464    0.0625904    0.174205     -0.0351276    0.0947502  -0.0154362    -0.115364     0.0783324    0.00597031  -0.133465    -0.0194781
 -0.00447695   0.115933     0.121791   -0.0218436   0.0829262    0.034348     0.00082508   0.110371     0.135393      0.117939     0.170249     0.0844863    -0.135776    -0.142797     0.0955912   -0.012654    -0.0280225   -0.0278642     0.0143743   -0.0758281  -0.0352094     0.104973     0.0701203   -0.0706195   -0.0826758   -0.0943875
  0.0458101    0.0846643   -0.0511855   0.045      -0.111344    -0.167298    -0.0325728    0.0575868   -0.0466712     0.0552568    0.0486596   -0.129932     -0.0149301    0.0838116    0.0667401    0.11794      0.0171732    0.107262     -0.163786     0.0630238   0.240738     -0.18351      0.0160766    0.0978143    0.0978996   -0.107613
 -0.233261     0.00390469  -0.0857407  -0.110121   -0.0161674   -0.0277587    0.0850764    0.0388809   -0.156061      0.16715      0.0117251    0.121971      0.154618     0.093311    -0.0849124    0.0550182    0.0693673    0.0224686    -0.131149     0.0488498   0.0244003     0.0186998    0.0379461    0.0474811    0.191323     0.072897
 -0.0856984    0.0268085   -0.0215127   0.182398    0.0711966   -0.153196     0.073766     0.0187771   -0.0119249     0.0272485   -0.121632     0.0759673     0.11824     -0.0579757    0.117918     0.0770051   -0.00102181   0.0371935    -0.0913139   -0.0597942   0.0325138     0.0885991   -0.00144582  -0.0551126   -0.0320984   -0.03788[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.010010
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.987242
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.008795
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.987769
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.008219
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.984176
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.999781
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.983123
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.004272
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.983173
┌ Info: EM with 100000 data points 10 iterations avll -0.983173
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.18989      0.00187693  -0.205524     -0.0765061   -0.0626717    0.0392362     0.0579884     0.138162      0.125916     -0.0139078   -0.0694944    -0.0440648   -0.0342221    0.0702532   -0.0897326   -0.141513    -0.0932249  -0.0907853     0.137165     0.087538      0.013289     0.102954     -0.115629    -0.117927     0.178744    0.0788381
  0.120657    -0.0866269   -0.0360516     0.0954838    0.0411841    0.0813256    -0.0840213     0.0520101     0.105062     -0.216563     0.0734202    -0.055729    -0.022156     0.0420531   -0.00947163  -0.16176      0.0561919   0.0102951     0.0295727    0.0761102    -0.0363517    0.0479892     0.0415525    0.0326232    0.0475559  -0.149528
 -0.0487156    0.013332     0.179267     -0.0262068    0.211385     0.134318     -0.0370267     0.145718     -0.0353158     0.0475669    0.0844586    -0.0770881    0.172571     0.163302     0.0790693   -0.0529665   -0.0433414  -0.00480732   -0.249103     0.0943206     0.00554275  -0.0778313    -0.126526     0.0417092    0.0909086  -0.302309
 -0.00667431  -0.0321402    0.0441189    -0.119271    -0.0499159    0.0359817    -0.0305249    -0.000578616   0.0283991     0.11859     -0.0928044    -0.011049    -0.0748946    0.113676    -0.186629    -0.125993     0.0771486  -0.126633      0.020974    -0.167872     -0.0136249    0.0510781    -0.132482     0.0168701   -0.0360917   0.182573
  0.0647745   -0.0688061    0.0788474    -0.111271     0.101229     0.0642206     0.0285579     0.213629     -0.148195      0.0126068    0.247601      0.0127328    0.114235    -0.043119     0.0865401   -0.0726243   -0.031364    0.089021     -0.141799     0.00621428   -0.12123      0.000536289  -0.107091    -0.00788703   0.165412   -0.112896
  0.131024     0.148394     0.0249711    -0.0816375   -0.0597898    0.0756339     0.0304579    -0.0191334     0.0700566     0.141218    -0.0435502     0.203776    -0.0264029    0.0719638   -0.0552648   -0.108203    -0.0353297  -0.00566125   -0.0404537   -0.0105692    -0.069747     0.0784033    -0.00725195   0.114635     0.013806    0.0256101
  0.0279326   -0.018449     0.0715323     0.155925    -0.154916    -0.133693     -0.173098     -0.0737565    -0.0838121    -0.00316393  -0.015438     -0.10643      0.116246    -0.153738     0.00822729   0.0302723   -0.089181    0.0836614    -0.117222    -0.160742      0.0405713   -0.176244     -0.0185179    0.00232274  -0.123838    0.0088424
 -0.0237799   -0.0866815   -0.164133     -0.192711     0.0995264   -0.0130462    -0.000185017   0.0291326    -0.186335     -0.0394028   -0.073809     -0.177092    -0.115852    -0.237408    -0.0248111   -0.094024    -0.208072    0.0145938     0.0970677   -0.134263     -0.0257272    0.0269618     0.126398     0.0416927   -0.0381002  -0.248377
  0.012865    -0.00760693   0.0276968     0.0518118   -0.024677     0.0549129    -0.0656684    -0.126186     -0.187348      0.141548    -0.088844      0.0122608    0.147435     0.0658472    0.0333557    0.0553119   -0.0944508   0.0554813    -0.0103633    0.0452689    -0.107631    -0.0175139    -0.0239029   -0.0185665    0.0653223  -0.0176131
  0.0893931   -0.135082     0.0624904     0.0827064   -0.132505    -0.0905358    -0.0370755     0.0959185    -0.000771065   0.0829265    0.078775     -0.0293531    0.185301    -0.0582491    0.040427     0.0277495   -0.0277142  -0.058256      0.109875     0.0585161     0.0282678   -0.101316      0.248041    -0.0116553    0.104263   -0.00922537
  0.0937934   -0.056706     0.184159      0.0705805    0.112884    -0.0995381    -0.152288      0.0964285     0.0193478     0.0633153    0.027667     -0.129746    -0.0980481    0.0413761    0.0116438   -0.0178988   -0.163471   -0.182097      0.0221264    0.0100402    -0.108143    -0.0494432     0.1426       0.0762294    0.0932655   0.0164594
 -0.159382    -0.164231     0.0808577    -0.0238722   -0.0145981    0.00384297   -0.111386      0.123629     -0.0717436     0.01937      0.0253797     0.0329394   -0.0580273    0.00239448  -0.0043064   -0.168791     0.0822363  -0.000183448   0.0388418    0.0380061    -0.00121022  -0.0166947     0.246599     0.0923965    0.108603   -0.100335
  0.0701729   -0.115397     0.0320509    -0.0900558   -0.119129     0.0148527    -0.0125316     0.0708099     0.0834568    -0.0741944   -0.0242604    -0.0815555   -0.0161651   -0.0393033   -0.0695943   -0.0679575   -0.0388971   0.0779241     0.111396    -0.135569      0.0758365   -0.0193601     0.0515397   -0.0432153   -0.157427    0.116751
 -0.10217      0.10763     -0.0244634     0.11391     -0.0152683    0.22663       0.105734      0.0763736    -0.0294446     0.0654902    0.127814      0.0630207    0.123405    -0.15852      0.00697697  -0.0729505    0.128893    0.112804      0.00888524   0.288452      0.0137663   -0.0216151     0.0301479    0.123821     0.0732499   0.0275596
 -0.0768847   -0.0965516   -0.00590618   -0.035787     0.04798      0.0325126    -0.0716304     0.0288139    -0.137042     -0.125764    -0.000337003  -0.035132    -0.0679802    0.0304963    0.120556    -0.0533443    0.175506   -0.187407     -0.0290321   -0.0209314     0.0040551   -0.112297      0.136252    -0.0323091   -0.123751   -0.115525
 -0.0799486    0.0329453    0.0199916     0.091415     0.0105109    0.134458      0.0139276     0.0301401    -0.0299096     0.0941535   -0.0743425     0.0728794   -0.0364881   -0.136646    -0.122394     0.0200517    0.0526529   0.0549133     0.166196     0.000412423  -0.146635     0.0318999    -0.0343548    0.0379593    0.0250654  -0.0611479
 -0.00281918  -0.028417     0.191984     -0.231305    -0.0449231    0.0108274    -0.311905     -0.0601438     0.0616101    -0.0839725    0.00595009   -0.0309108    0.0517333    0.0976378    0.058197    -0.0442076   -0.154452    0.0365382     0.265925     0.0021513    -0.0754904   -0.0283924    -0.161717    -0.041817    -0.0613731   0.0920057
  0.0391341    0.0416645   -0.104969     -0.0797561   -0.0976024    0.0440894     0.135662     -0.0597149    -0.110547     -0.0585259   -0.0450546    -0.165599     0.0308447   -0.0782038    0.0719509    0.0886579   -0.0317253   0.0778639    -0.0580863   -0.0321954     0.160833     0.02715       0.0293251    0.0130554    0.0661737  -0.0680806
 -0.11668      0.176449    -0.000946865  -0.0351393    0.247199    -0.000684641  -0.0501861    -0.0755022     0.092376      0.046257     0.00106548   -0.220134    -0.027116    -0.126262    -0.153045    -0.0686036    0.0685983  -0.243996      0.00881191   0.0787922     0.123884    -0.0996262     0.0765203   -0.0378618   -0.0259472  -0.0893087
  0.057184    -0.0756662    0.00196008   -0.200258    -0.106358    -0.168207      0.104384     -0.0629626     0.151608     -0.110691     0.00331204    0.0669521   -0.104237     0.0751575   -0.101676    -0.00352531   0.0917075  -0.104189     -0.0885487    0.0268811     0.135725     0.0691213    -0.0755927   -0.0167846   -0.0106967   0.022584
 -0.143386    -0.120302    -0.0663848    -0.146668    -0.06147      0.0428431     0.120049     -0.125762     -0.285987      0.0647599   -0.130822     -0.0684586    0.0596386    0.0693661    0.180261    -0.0629991    0.152702    0.146776     -0.0617724   -0.07427      -0.0324614   -0.176183      0.0271539    0.0185352    0.0312786   0.0390904
 -0.0330122   -0.0702684    0.0376624    -0.0642343    0.0725949   -0.227697      0.168287     -0.0755783     0.00728288   -0.145031    -0.101108      0.210394    -0.095557    -0.0533396    0.125525    -0.0757336    0.15256    -0.129412     -0.129434     0.00558009   -0.213754    -0.171428     -0.129428     0.0860453    0.0755029   0.202907
  0.127132    -0.0783976   -0.0901566    -0.159325     0.0653924   -0.0760069    -0.300559     -0.0881455     0.06917       0.0272337   -0.154301     -0.0433524   -0.0736508   -0.151905    -0.156979     0.0132925   -0.0945128   0.0101296    -0.00852734   0.154311     -0.0590067    0.0646319    -0.157564     0.0527598    0.035872    0.0532245
 -0.00389862   0.0516209    0.103195     -0.0787312    0.0664583    0.0794564    -0.039068      0.0278809    -0.0708928     0.00283388   0.139644      0.119387    -0.00815757   0.0779231    0.0157471    0.223352    -0.0768669   0.055811     -0.1316      -0.0605523     0.0863372   -0.160508     -0.0453506    0.100126     0.0714676   0.00766328
  0.0961372    0.100636    -0.158094      0.103247    -0.0597463    0.15668       0.0807403     0.207623      0.0355514    -0.141871     0.134266      0.11445      0.0905521   -0.124326    -0.141164     0.121441    -0.0409276   0.0590418     0.189972    -0.0101724     0.0671817   -0.0757624     0.201207    -0.0708072   -0.165885   -0.114472
 -0.28127     -0.158445     0.11734      -0.0562638   -0.165209     0.0230177     0.00895881   -0.0670725    -0.0158476    -0.01114      0.151652     -0.0814936   -0.0592909   -0.0592315   -0.0816372    0.151698     0.0345736  -0.0159813     0.0462285    0.0283711     0.066668     0.134768      0.0574042   -0.00722819   0.115142    0.0109206
  0.139994     0.0240284   -0.198035      0.0680032   -0.20341     -0.02871       0.107939      0.190638      0.24712       0.0750394   -0.0538859     0.0192895   -0.0575524    0.0105224    0.0203605    0.0200596    0.0251591   0.00943268    0.0624768    0.014954      0.108222     0.0558007    -0.0439457   -0.0798968   -0.160932    0.00593311
 -0.0840101   -0.062484     0.133049     -0.0955387    0.177029     0.0628192    -0.159468     -0.0852857    -0.10697      -0.0781957    0.0270734     0.10002      0.072984    -0.121204    -0.189743     0.0383423    0.0898996  -0.00214342   -0.0201444    0.184453     -0.109314     0.0894749     0.109201    -0.0441734   -0.026461   -0.201476
 -0.0330034   -0.224301    -0.171845      0.027417     0.0218744   -0.0353337     0.123807      0.00917822    0.0335813    -0.0133095   -0.133472     -0.022002     0.0838613    0.0289421   -0.0118289   -0.00828528  -0.153841   -0.0196923    -0.0467353    0.0258546    -0.0569075    0.0159868     0.0521704   -0.145711    -0.165423    0.108076
 -0.0962238    0.120354     0.278789      0.00311508  -0.0904322   -0.120863     -0.163242      0.0366866    -0.169263     -0.126715     0.00119156   -0.00869635  -0.13668      0.0537       0.0762691    0.0207896   -0.02801    -0.125789     -0.123338    -0.159341      0.0493654    0.00580455   -0.0461979    0.190878    -0.0530758   0.0970789
  0.167999     0.133445     0.0912363     0.106958     0.00556922  -0.180618      0.115217      0.136146      0.0470724    -0.0837679   -0.1099        0.0459979    0.112558    -0.0211848    0.0275467    0.309047    -0.163655    0.00661515   -0.0984242   -0.0749883     0.0405911    0.0427715    -0.0591539   -0.245188     0.0284999   0.155415
  0.174882     0.146253    -0.0352139     0.130792     0.0360252   -0.0878944     0.0692022    -0.0606624     0.0221645     0.0822241   -0.0936815    -0.0497424    0.0671127    0.0597292    0.135579    -0.130196    -0.0940879   0.105099      0.203033    -0.112097     -0.108291    -0.0573487     0.0207322   -0.0163883    0.057491   -0.0767528kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.428802382422764
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428822
[ Info: iteration 2, average log likelihood -1.428766
[ Info: iteration 3, average log likelihood -1.428726
[ Info: iteration 4, average log likelihood -1.428676
[ Info: iteration 5, average log likelihood -1.428611
[ Info: iteration 6, average log likelihood -1.428526
[ Info: iteration 7, average log likelihood -1.428412
[ Info: iteration 8, average log likelihood -1.428246
[ Info: iteration 9, average log likelihood -1.427970
[ Info: iteration 10, average log likelihood -1.427468
[ Info: iteration 11, average log likelihood -1.426611
[ Info: iteration 12, average log likelihood -1.425462
[ Info: iteration 13, average log likelihood -1.424406
[ Info: iteration 14, average log likelihood -1.423753
[ Info: iteration 15, average log likelihood -1.423450
[ Info: iteration 16, average log likelihood -1.423325
[ Info: iteration 17, average log likelihood -1.423275
[ Info: iteration 18, average log likelihood -1.423254
[ Info: iteration 19, average log likelihood -1.423245
[ Info: iteration 20, average log likelihood -1.423241
[ Info: iteration 21, average log likelihood -1.423239
[ Info: iteration 22, average log likelihood -1.423237
[ Info: iteration 23, average log likelihood -1.423237
[ Info: iteration 24, average log likelihood -1.423236
[ Info: iteration 25, average log likelihood -1.423235
[ Info: iteration 26, average log likelihood -1.423235
[ Info: iteration 27, average log likelihood -1.423234
[ Info: iteration 28, average log likelihood -1.423234
[ Info: iteration 29, average log likelihood -1.423234
[ Info: iteration 30, average log likelihood -1.423234
[ Info: iteration 31, average log likelihood -1.423233
[ Info: iteration 32, average log likelihood -1.423233
[ Info: iteration 33, average log likelihood -1.423233
[ Info: iteration 34, average log likelihood -1.423233
[ Info: iteration 35, average log likelihood -1.423232
[ Info: iteration 36, average log likelihood -1.423232
[ Info: iteration 37, average log likelihood -1.423232
[ Info: iteration 38, average log likelihood -1.423232
[ Info: iteration 39, average log likelihood -1.423232
[ Info: iteration 40, average log likelihood -1.423232
[ Info: iteration 41, average log likelihood -1.423232
[ Info: iteration 42, average log likelihood -1.423232
[ Info: iteration 43, average log likelihood -1.423232
[ Info: iteration 44, average log likelihood -1.423232
[ Info: iteration 45, average log likelihood -1.423232
[ Info: iteration 46, average log likelihood -1.423231
[ Info: iteration 47, average log likelihood -1.423231
[ Info: iteration 48, average log likelihood -1.423231
[ Info: iteration 49, average log likelihood -1.423231
[ Info: iteration 50, average log likelihood -1.423231
┌ Info: EM with 100000 data points 50 iterations avll -1.423231
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4288216859693743
│     -1.42876631740844
│      ⋮
└     -1.423231345977288
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423250
[ Info: iteration 2, average log likelihood -1.423193
[ Info: iteration 3, average log likelihood -1.423151
[ Info: iteration 4, average log likelihood -1.423098
[ Info: iteration 5, average log likelihood -1.423031
[ Info: iteration 6, average log likelihood -1.422948
[ Info: iteration 7, average log likelihood -1.422853
[ Info: iteration 8, average log likelihood -1.422755
[ Info: iteration 9, average log likelihood -1.422666
[ Info: iteration 10, average log likelihood -1.422590
[ Info: iteration 11, average log likelihood -1.422530
[ Info: iteration 12, average log likelihood -1.422482
[ Info: iteration 13, average log likelihood -1.422443
[ Info: iteration 14, average log likelihood -1.422409
[ Info: iteration 15, average log likelihood -1.422379
[ Info: iteration 16, average log likelihood -1.422353
[ Info: iteration 17, average log likelihood -1.422328
[ Info: iteration 18, average log likelihood -1.422307
[ Info: iteration 19, average log likelihood -1.422287
[ Info: iteration 20, average log likelihood -1.422270
[ Info: iteration 21, average log likelihood -1.422255
[ Info: iteration 22, average log likelihood -1.422241
[ Info: iteration 23, average log likelihood -1.422230
[ Info: iteration 24, average log likelihood -1.422220
[ Info: iteration 25, average log likelihood -1.422211
[ Info: iteration 26, average log likelihood -1.422204
[ Info: iteration 27, average log likelihood -1.422198
[ Info: iteration 28, average log likelihood -1.422193
[ Info: iteration 29, average log likelihood -1.422189
[ Info: iteration 30, average log likelihood -1.422186
[ Info: iteration 31, average log likelihood -1.422183
[ Info: iteration 32, average log likelihood -1.422180
[ Info: iteration 33, average log likelihood -1.422178
[ Info: iteration 34, average log likelihood -1.422176
[ Info: iteration 35, average log likelihood -1.422174
[ Info: iteration 36, average log likelihood -1.422173
[ Info: iteration 37, average log likelihood -1.422172
[ Info: iteration 38, average log likelihood -1.422171
[ Info: iteration 39, average log likelihood -1.422170
[ Info: iteration 40, average log likelihood -1.422169
[ Info: iteration 41, average log likelihood -1.422168
[ Info: iteration 42, average log likelihood -1.422167
[ Info: iteration 43, average log likelihood -1.422166
[ Info: iteration 44, average log likelihood -1.422165
[ Info: iteration 45, average log likelihood -1.422165
[ Info: iteration 46, average log likelihood -1.422164
[ Info: iteration 47, average log likelihood -1.422163
[ Info: iteration 48, average log likelihood -1.422163
[ Info: iteration 49, average log likelihood -1.422162
[ Info: iteration 50, average log likelihood -1.422162
┌ Info: EM with 100000 data points 50 iterations avll -1.422162
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4232504424851133
│     -1.4231931266975717
│      ⋮
└     -1.4221617236001265
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422175
[ Info: iteration 2, average log likelihood -1.422117
[ Info: iteration 3, average log likelihood -1.422071
[ Info: iteration 4, average log likelihood -1.422020
[ Info: iteration 5, average log likelihood -1.421960
[ Info: iteration 6, average log likelihood -1.421890
[ Info: iteration 7, average log likelihood -1.421812
[ Info: iteration 8, average log likelihood -1.421729
[ Info: iteration 9, average log likelihood -1.421645
[ Info: iteration 10, average log likelihood -1.421564
[ Info: iteration 11, average log likelihood -1.421489
[ Info: iteration 12, average log likelihood -1.421420
[ Info: iteration 13, average log likelihood -1.421356
[ Info: iteration 14, average log likelihood -1.421298
[ Info: iteration 15, average log likelihood -1.421247
[ Info: iteration 16, average log likelihood -1.421200
[ Info: iteration 17, average log likelihood -1.421157
[ Info: iteration 18, average log likelihood -1.421118
[ Info: iteration 19, average log likelihood -1.421081
[ Info: iteration 20, average log likelihood -1.421046
[ Info: iteration 21, average log likelihood -1.421011
[ Info: iteration 22, average log likelihood -1.420978
[ Info: iteration 23, average log likelihood -1.420946
[ Info: iteration 24, average log likelihood -1.420916
[ Info: iteration 25, average log likelihood -1.420889
[ Info: iteration 26, average log likelihood -1.420864
[ Info: iteration 27, average log likelihood -1.420842
[ Info: iteration 28, average log likelihood -1.420823
[ Info: iteration 29, average log likelihood -1.420806
[ Info: iteration 30, average log likelihood -1.420792
[ Info: iteration 31, average log likelihood -1.420779
[ Info: iteration 32, average log likelihood -1.420767
[ Info: iteration 33, average log likelihood -1.420757
[ Info: iteration 34, average log likelihood -1.420747
[ Info: iteration 35, average log likelihood -1.420739
[ Info: iteration 36, average log likelihood -1.420731
[ Info: iteration 37, average log likelihood -1.420724
[ Info: iteration 38, average log likelihood -1.420717
[ Info: iteration 39, average log likelihood -1.420710
[ Info: iteration 40, average log likelihood -1.420705
[ Info: iteration 41, average log likelihood -1.420699
[ Info: iteration 42, average log likelihood -1.420694
[ Info: iteration 43, average log likelihood -1.420689
[ Info: iteration 44, average log likelihood -1.420684
[ Info: iteration 45, average log likelihood -1.420680
[ Info: iteration 46, average log likelihood -1.420676
[ Info: iteration 47, average log likelihood -1.420672
[ Info: iteration 48, average log likelihood -1.420669
[ Info: iteration 49, average log likelihood -1.420665
[ Info: iteration 50, average log likelihood -1.420662
┌ Info: EM with 100000 data points 50 iterations avll -1.420662
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4221749692277181
│     -1.42211734974644
│      ⋮
└     -1.420662037000127
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420669
[ Info: iteration 2, average log likelihood -1.420612
[ Info: iteration 3, average log likelihood -1.420563
[ Info: iteration 4, average log likelihood -1.420508
[ Info: iteration 5, average log likelihood -1.420443
[ Info: iteration 6, average log likelihood -1.420364
[ Info: iteration 7, average log likelihood -1.420273
[ Info: iteration 8, average log likelihood -1.420171
[ Info: iteration 9, average log likelihood -1.420064
[ Info: iteration 10, average log likelihood -1.419957
[ Info: iteration 11, average log likelihood -1.419856
[ Info: iteration 12, average log likelihood -1.419764
[ Info: iteration 13, average log likelihood -1.419680
[ Info: iteration 14, average log likelihood -1.419605
[ Info: iteration 15, average log likelihood -1.419539
[ Info: iteration 16, average log likelihood -1.419479
[ Info: iteration 17, average log likelihood -1.419426
[ Info: iteration 18, average log likelihood -1.419378
[ Info: iteration 19, average log likelihood -1.419334
[ Info: iteration 20, average log likelihood -1.419293
[ Info: iteration 21, average log likelihood -1.419256
[ Info: iteration 22, average log likelihood -1.419221
[ Info: iteration 23, average log likelihood -1.419189
[ Info: iteration 24, average log likelihood -1.419158
[ Info: iteration 25, average log likelihood -1.419130
[ Info: iteration 26, average log likelihood -1.419103
[ Info: iteration 27, average log likelihood -1.419077
[ Info: iteration 28, average log likelihood -1.419052
[ Info: iteration 29, average log likelihood -1.419029
[ Info: iteration 30, average log likelihood -1.419007
[ Info: iteration 31, average log likelihood -1.418985
[ Info: iteration 32, average log likelihood -1.418965
[ Info: iteration 33, average log likelihood -1.418945
[ Info: iteration 34, average log likelihood -1.418926
[ Info: iteration 35, average log likelihood -1.418908
[ Info: iteration 36, average log likelihood -1.418890
[ Info: iteration 37, average log likelihood -1.418874
[ Info: iteration 38, average log likelihood -1.418857
[ Info: iteration 39, average log likelihood -1.418841
[ Info: iteration 40, average log likelihood -1.418826
[ Info: iteration 41, average log likelihood -1.418812
[ Info: iteration 42, average log likelihood -1.418797
[ Info: iteration 43, average log likelihood -1.418784
[ Info: iteration 44, average log likelihood -1.418770
[ Info: iteration 45, average log likelihood -1.418758
[ Info: iteration 46, average log likelihood -1.418745
[ Info: iteration 47, average log likelihood -1.418734
[ Info: iteration 48, average log likelihood -1.418722
[ Info: iteration 49, average log likelihood -1.418711
[ Info: iteration 50, average log likelihood -1.418701
┌ Info: EM with 100000 data points 50 iterations avll -1.418701
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4206687605553845
│     -1.4206118580085474
│      ⋮
└     -1.4187008147268043
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418699
[ Info: iteration 2, average log likelihood -1.418631
[ Info: iteration 3, average log likelihood -1.418566
[ Info: iteration 4, average log likelihood -1.418488
[ Info: iteration 5, average log likelihood -1.418388
[ Info: iteration 6, average log likelihood -1.418263
[ Info: iteration 7, average log likelihood -1.418112
[ Info: iteration 8, average log likelihood -1.417944
[ Info: iteration 9, average log likelihood -1.417768
[ Info: iteration 10, average log likelihood -1.417596
[ Info: iteration 11, average log likelihood -1.417436
[ Info: iteration 12, average log likelihood -1.417290
[ Info: iteration 13, average log likelihood -1.417159
[ Info: iteration 14, average log likelihood -1.417044
[ Info: iteration 15, average log likelihood -1.416942
[ Info: iteration 16, average log likelihood -1.416851
[ Info: iteration 17, average log likelihood -1.416770
[ Info: iteration 18, average log likelihood -1.416697
[ Info: iteration 19, average log likelihood -1.416631
[ Info: iteration 20, average log likelihood -1.416571
[ Info: iteration 21, average log likelihood -1.416517
[ Info: iteration 22, average log likelihood -1.416467
[ Info: iteration 23, average log likelihood -1.416421
[ Info: iteration 24, average log likelihood -1.416378
[ Info: iteration 25, average log likelihood -1.416339
[ Info: iteration 26, average log likelihood -1.416303
[ Info: iteration 27, average log likelihood -1.416270
[ Info: iteration 28, average log likelihood -1.416239
[ Info: iteration 29, average log likelihood -1.416210
[ Info: iteration 30, average log likelihood -1.416182
[ Info: iteration 31, average log likelihood -1.416157
[ Info: iteration 32, average log likelihood -1.416132
[ Info: iteration 33, average log likelihood -1.416110
[ Info: iteration 34, average log likelihood -1.416088
[ Info: iteration 35, average log likelihood -1.416067
[ Info: iteration 36, average log likelihood -1.416047
[ Info: iteration 37, average log likelihood -1.416028
[ Info: iteration 38, average log likelihood -1.416010
[ Info: iteration 39, average log likelihood -1.415992
[ Info: iteration 40, average log likelihood -1.415975
[ Info: iteration 41, average log likelihood -1.415959
[ Info: iteration 42, average log likelihood -1.415943
[ Info: iteration 43, average log likelihood -1.415927
[ Info: iteration 44, average log likelihood -1.415912
[ Info: iteration 45, average log likelihood -1.415897
[ Info: iteration 46, average log likelihood -1.415883
[ Info: iteration 47, average log likelihood -1.415869
[ Info: iteration 48, average log likelihood -1.415856
[ Info: iteration 49, average log likelihood -1.415843
[ Info: iteration 50, average log likelihood -1.415830
┌ Info: EM with 100000 data points 50 iterations avll -1.415830
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.418699309043612
│     -1.4186310630264631
│      ⋮
└     -1.4158297922315162
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.428802382422764
│     -1.4288216859693743
│     -1.42876631740844
│     -1.4287256101196346
│      ⋮
│     -1.4158557285130933
│     -1.4158425867946234
└     -1.4158297922315162
32×26 Array{Float64,2}:
 -0.142896    -0.0666529    0.437909    0.135356   -0.559037    -1.01953     0.0185849   -0.164785    0.151869     0.359307   -0.0538565    0.542518     0.779023   -0.156993    -0.047902   -0.41351    -0.0585862  -0.718305   -0.11629    -0.361814   -0.108199    0.225918    -0.0591253   -0.00647854   0.179987   -0.659176
 -0.299954    -0.101806     0.251788    0.587915   -0.42256      0.146471   -0.0866407   -0.522745   -0.24462      0.114747   -0.215937     0.112434     0.617953   -0.0345857    0.495908    0.3638     -0.349898    0.242593   -0.060443    0.315774    0.322121    0.142246    -0.287352     0.175134    -0.0416627  -0.169017
 -0.139911    -0.596334     0.841774    0.186189   -0.0760012   -0.502475   -0.190006     0.397868    0.543548    -0.425885    0.309246    -0.580344     0.118524    0.439271    -0.457022   -0.316827   -0.270396   -0.400658   -0.246764   -0.167323   -0.0184136   0.469863     0.0542705   -0.525107    -0.829035    0.900704
 -0.267059    -0.853933     0.367677   -0.726233   -0.616793    -0.325772   -0.513402     0.312203   -0.204936    -0.286004   -0.112388    -0.246121     0.127944   -0.119476    -0.263962   -0.172039   -1.10275    -0.0340006   0.0389422  -0.291379    0.0616179  -0.209247    -0.513166     0.477772     0.0626503   0.165542
  0.189121    -0.347768    -0.0771527  -0.437927    0.550953     0.241921   -0.416767    -0.311651   -0.49302     -0.604479    0.267107     0.0194156   -0.733139    0.0565291   -0.262091   -0.0506979   0.220934    0.017512   -0.045717    0.0663412   0.506084    0.295249     0.129707    -0.122841     0.148166   -0.0961812
  0.294906    -0.46349     -0.085218    0.300145    0.0957203    0.0925628   0.0475663   -0.450342    0.0312135    0.481622    0.15539      0.0546381   -0.557767   -0.147052    -0.346883    0.308018    0.185445    0.0800664  -0.0589588   0.569705    0.860793    0.302575    -0.726567    -0.0831633   -0.113077   -0.0683823
 -0.714757     0.0946369   -0.226405   -0.541084   -0.269425     0.0640648  -0.486522    -0.394034    0.374592     0.563801   -0.127885    -0.583167     0.107608   -0.73325      0.0459376  -0.108013    0.361355    0.151382   -0.0143292  -0.318933    0.473762    0.327928    -0.787488    -0.350649     0.338707   -0.137526
  0.721417    -0.436057    -0.308836   -0.317575   -0.27268     -0.390213   -0.0615828   -0.058207   -0.114036     0.313479   -0.0429262   -0.680509     0.387749   -0.21016     -0.374071    0.0166102  -0.20153     1.04447     0.0874476  -0.0292206   0.212142    0.00256355  -0.668844    -0.0131842    0.322105    0.39782
  0.102239     0.511015    -0.252711   -0.223338    0.242923    -0.111351   -0.253451     0.0479151   0.467034    -0.348901    0.172763    -0.63776     -0.0881583   0.141983     0.38725    -0.538954   -0.662652    0.183883   -0.235466    0.139913    0.325714    0.211784     0.789661     0.295573     0.165371    0.0986243
 -0.199502     0.457888    -0.237742   -0.539234   -0.28565      0.513145    0.058814    -0.298092    0.275112    -0.181822   -0.317292    -0.593575    -0.197728   -0.220281     0.38143    -0.445721    0.475309   -0.389735    0.712975    0.525673   -0.261369    0.0851945    0.149369     0.0484489    0.501947   -0.8668
 -0.0307921   -0.0497734   -0.696338   -0.547802    0.234326     1.11641     0.84919      0.874088    0.120103    -0.615534   -0.200966    -0.00722864  -0.323453   -0.332718    -0.0815375   0.753522   -0.192726    0.52073     0.68785     0.533635    0.125327   -0.568643    -0.21267     -0.162661    -0.326817    0.341465
 -0.569895     0.16266     -0.600389   -0.851785   -0.488037     0.320608   -0.51662      0.45298    -0.103338    -0.188347    0.0307307   -0.00531196   0.494021    0.306792    -0.355832    0.486621   -0.446833   -0.179127    0.355193   -0.0144896   0.143463    0.0693009    0.151384    -0.206001     0.208575   -0.522185
 -0.0690762    0.084725     0.121008    0.177888   -0.253302    -0.110714   -0.468671    -0.0218364  -0.443807    -0.172567   -0.0994995    0.269118    -0.0333703  -0.129147    -0.0825223  -0.335739   -0.050696   -0.104199   -0.306236    0.105827    0.07163     0.119173     0.481642    -0.069849    -0.43402     0.0979122
 -0.113985     0.122842     0.0790643   0.0264256   0.385561     0.238907    0.520425     0.381694    0.204671     0.0501039   0.0557702    0.300906    -0.105742    0.142473     0.214073    0.523711    0.171453   -0.317626    0.213468   -0.213043   -0.448016   -0.281912    -0.0719066    0.0194527    0.146439   -0.192351
  0.550252    -0.109544    -0.47076     0.264555    0.212489    -0.0950998   0.365509     0.490944   -0.235103    -0.125866   -0.0270144    0.560087    -0.348523    0.420719    -0.55903     0.422844   -0.0757811  -0.0934604  -0.174254    0.467156    0.0665684  -0.350397     0.505947     0.106063    -0.158668   -0.0129693
  0.40362     -0.473831     0.270887    0.618166    0.563227     0.0131763   0.221354     0.316696   -0.15344      0.389205    0.0398461    0.472497     0.210813    0.0374119   -0.247342    0.419006    0.109062    0.646646   -0.394053   -0.779593   -0.211256   -0.295868    -0.115351     0.0722036   -0.247465    0.464017
  0.19352     -0.313987     0.292527    0.17814    -0.0138862   -0.82072    -0.315382    -0.221042    0.316826     0.136829    0.485303     0.347503    -0.0355483  -1.08117     -0.0575657  -0.74373    -0.0280007  -0.0838486  -0.585177   -0.338702    0.0838326  -0.402002     0.04721     -0.137257     0.159519    0.102583
  0.0572455   -0.0968637    0.544121    0.286307    0.720411     0.0629267   0.482884     0.139129   -0.0474783    0.242772    0.0779086   -0.182099    -0.719921   -0.886776     0.418266   -0.591913   -0.0700775  -0.273198   -0.261271   -0.1848     -0.469918    0.229846     0.103174    -0.207234     0.196379    0.108558
 -0.0218613    0.222356     0.186521    0.188041    0.599526    -0.35432     0.378588     0.321397    0.424079    -0.0129724  -0.259679    -0.148368     0.126064    0.248118    -0.120634   -0.0300856  -0.77439     0.144205    0.678003   -0.328899    0.01587    -0.492277     0.4674       0.13471      0.869197   -0.0813085
  0.524747     0.186703     0.161257    0.731889    0.316546    -0.419786    0.724977    -0.778033    0.593032     0.298444   -0.431128    -0.00763673  -0.524079    0.351746     0.257253   -0.39283     0.742752   -0.159944    0.25793    -0.0831866  -0.127301   -0.223412    -0.388639     0.254176     0.39548     0.472954
  0.11185      0.210976    -0.0500299  -0.185305   -0.47419     -0.110871   -0.277061    -0.268931   -0.587658    -0.320185   -0.106474    -0.0381186    0.16937    -0.218133     0.0525933  -0.294816   -0.473824   -0.0499749  -0.2432      0.680199    0.0366814  -0.114897     0.199333     0.102892     0.248813   -0.38617
 -0.269187     0.253162    -0.0454208  -0.0476499   0.00798807  -0.168963   -0.0136102   -0.0293071   0.354736     0.0979625  -0.0916955   -0.166447     0.0644006   0.00118954   0.224092   -0.344133   -0.173864   -0.264966    0.0828482   0.0551304   0.151349    0.0692339    0.265768    -0.0380408    0.413221   -0.411269
  0.032155    -0.119239    -0.103914    0.227039   -0.212142    -0.200377   -0.300756    -0.45132     0.00720836   0.119782    0.00221915  -0.153068    -0.0481215  -0.121494    -0.0103091  -0.213713    0.121866    0.250455   -0.0507438   0.197678    0.394626    0.351998    -0.143792    -0.258772    -0.199624    0.150155
  0.140298    -0.00268292   0.0706592   0.0342125  -0.0376045    0.0522493  -0.149469     0.0404981  -0.0913356   -0.180319    0.115239     0.0370639   -0.0335645  -0.056796    -0.0711815  -0.258163   -0.0067519   0.161889   -0.123982   -0.0115284  -0.113728   -0.0766647    0.109956     0.28091     -0.275642    0.288837
 -0.00386836  -0.35656      0.165381   -0.0511853   0.307014    -0.0391472  -0.00900829   0.131276    0.0389737    0.214489   -0.155245    -0.0253647   -0.306471   -0.39377     -0.312724    0.395068    0.055977   -0.152244    0.212358   -0.221438    0.0686003  -0.0870145   -0.235064    -0.0769787    0.323634   -0.0345619
  0.0449409    0.0644394   -0.158374   -0.0866959   0.0233144    0.040409    0.374188     0.242549   -0.0426466    0.105517   -0.0399752    0.0551347    0.204865    0.306836    -0.0103168   0.458049    0.142428   -0.0480606   0.0720025  -0.123676   -0.275171   -0.0767579   -0.189657    -0.0172389    0.0368417  -0.183642
 -0.228632     0.16533      0.45553    -0.0517157   0.21712      0.427174    0.00934285   0.415025   -0.195681    -0.162899    0.114319     0.625288    -0.114127    0.173478     0.112323    0.200863    0.375686   -0.654306   -0.164244    0.138888   -0.135952    0.13535      0.00684276  -0.466146    -0.220082   -0.0625077
 -0.277516     0.135424     0.293581   -0.0266283  -0.201778     0.11475     0.0193821    0.308132   -0.10035     -0.430423   -0.0522592    0.119991    -0.21199     0.410383    -0.021175   -0.10585     0.0822869  -0.785946   -0.124667   -0.21531    -0.629612   -0.293955     0.617519     0.545617    -0.333724    0.00555155
 -0.087017     0.154456    -0.358653    0.0462093  -0.15026      0.060594    0.534941     0.634057    0.263083     0.329036    0.131471    -0.148931     0.450753   -0.0747277    0.146707   -0.24814     0.123481    0.613493   -0.200388    0.27669    -0.284551   -0.656679     0.0389204    0.17739     -0.38243    -0.386382
 -0.0860681   -0.0759492   -0.0671313  -0.566359   -0.36334      0.216963    0.465427    -0.0698817   0.113644    -0.108807   -0.0434898   -0.314546     0.887192   -0.272961     0.425802    0.267112   -0.181162    0.665954   -0.0842355  -0.377667   -0.205358    0.226276    -0.278698    -0.4845       0.331299    0.0418088
 -0.289603    -0.28495     -0.13543    -0.316584   -0.401636     0.202384   -0.393897    -0.339206   -0.279599     0.028693    0.245634    -0.221858     0.225504    0.115494    -0.0654783  -0.256994    0.553366    0.368003    0.446674   -0.384823   -0.528854   -0.26728     -0.175721    -0.0479117   -0.516041    0.468828
  0.443741     0.648501    -0.226502   -0.013391    0.0853197    0.341434   -0.405204    -0.136008   -0.254879     0.198373   -0.407418    -0.365237    -0.122231    0.500467    -0.0394665   0.251417    0.323745    0.238211    0.361775    0.111723   -0.317863    0.16326      0.139665     0.52118     -0.137229    0.446654[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415817
[ Info: iteration 2, average log likelihood -1.415805
[ Info: iteration 3, average log likelihood -1.415793
[ Info: iteration 4, average log likelihood -1.415782
[ Info: iteration 5, average log likelihood -1.415771
[ Info: iteration 6, average log likelihood -1.415760
[ Info: iteration 7, average log likelihood -1.415749
[ Info: iteration 8, average log likelihood -1.415738
[ Info: iteration 9, average log likelihood -1.415728
[ Info: iteration 10, average log likelihood -1.415718
┌ Info: EM with 100000 data points 10 iterations avll -1.415718
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.958875e+05
      1       7.202656e+05      -1.756219e+05 |       32
      2       6.988093e+05      -2.145624e+04 |       32
      3       6.931688e+05      -5.640563e+03 |       32
      4       6.905304e+05      -2.638335e+03 |       32
      5       6.888456e+05      -1.684802e+03 |       32
      6       6.875836e+05      -1.262041e+03 |       32
      7       6.865843e+05      -9.992723e+02 |       32
      8       6.857522e+05      -8.321306e+02 |       32
      9       6.850652e+05      -6.870423e+02 |       32
     10       6.844468e+05      -6.183800e+02 |       32
     11       6.838901e+05      -5.566764e+02 |       32
     12       6.833894e+05      -5.006817e+02 |       32
     13       6.829137e+05      -4.757091e+02 |       32
     14       6.824793e+05      -4.343961e+02 |       32
     15       6.821332e+05      -3.461260e+02 |       32
     16       6.818483e+05      -2.849161e+02 |       32
     17       6.815909e+05      -2.573896e+02 |       32
     18       6.813651e+05      -2.257301e+02 |       32
     19       6.811437e+05      -2.214000e+02 |       32
     20       6.809354e+05      -2.083099e+02 |       32
     21       6.807584e+05      -1.770803e+02 |       32
     22       6.805973e+05      -1.610679e+02 |       32
     23       6.804513e+05      -1.459790e+02 |       32
     24       6.803127e+05      -1.386358e+02 |       32
     25       6.801784e+05      -1.342377e+02 |       32
     26       6.800484e+05      -1.300120e+02 |       32
     27       6.799275e+05      -1.208811e+02 |       32
     28       6.798229e+05      -1.046434e+02 |       32
     29       6.797271e+05      -9.575833e+01 |       32
     30       6.796407e+05      -8.640436e+01 |       32
     31       6.795620e+05      -7.878156e+01 |       32
     32       6.794950e+05      -6.693093e+01 |       32
     33       6.794313e+05      -6.369797e+01 |       32
     34       6.793656e+05      -6.577481e+01 |       32
     35       6.793000e+05      -6.550588e+01 |       32
     36       6.792345e+05      -6.549699e+01 |       32
     37       6.791693e+05      -6.523627e+01 |       32
     38       6.790959e+05      -7.336426e+01 |       32
     39       6.790346e+05      -6.133870e+01 |       32
     40       6.789806e+05      -5.402911e+01 |       32
     41       6.789246e+05      -5.598155e+01 |       32
     42       6.788737e+05      -5.089659e+01 |       32
     43       6.788297e+05      -4.397728e+01 |       32
     44       6.787885e+05      -4.118499e+01 |       32
     45       6.787578e+05      -3.073491e+01 |       32
     46       6.787293e+05      -2.847833e+01 |       32
     47       6.787025e+05      -2.682170e+01 |       32
     48       6.786743e+05      -2.825254e+01 |       32
     49       6.786464e+05      -2.783027e+01 |       32
     50       6.786181e+05      -2.833906e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 678618.0831067171)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427729
[ Info: iteration 2, average log likelihood -1.422746
[ Info: iteration 3, average log likelihood -1.421451
[ Info: iteration 4, average log likelihood -1.420508
[ Info: iteration 5, average log likelihood -1.419483
[ Info: iteration 6, average log likelihood -1.418458
[ Info: iteration 7, average log likelihood -1.417682
[ Info: iteration 8, average log likelihood -1.417219
[ Info: iteration 9, average log likelihood -1.416958
[ Info: iteration 10, average log likelihood -1.416793
[ Info: iteration 11, average log likelihood -1.416675
[ Info: iteration 12, average log likelihood -1.416581
[ Info: iteration 13, average log likelihood -1.416502
[ Info: iteration 14, average log likelihood -1.416433
[ Info: iteration 15, average log likelihood -1.416373
[ Info: iteration 16, average log likelihood -1.416318
[ Info: iteration 17, average log likelihood -1.416268
[ Info: iteration 18, average log likelihood -1.416223
[ Info: iteration 19, average log likelihood -1.416180
[ Info: iteration 20, average log likelihood -1.416140
[ Info: iteration 21, average log likelihood -1.416103
[ Info: iteration 22, average log likelihood -1.416068
[ Info: iteration 23, average log likelihood -1.416035
[ Info: iteration 24, average log likelihood -1.416003
[ Info: iteration 25, average log likelihood -1.415973
[ Info: iteration 26, average log likelihood -1.415944
[ Info: iteration 27, average log likelihood -1.415916
[ Info: iteration 28, average log likelihood -1.415890
[ Info: iteration 29, average log likelihood -1.415865
[ Info: iteration 30, average log likelihood -1.415841
[ Info: iteration 31, average log likelihood -1.415818
[ Info: iteration 32, average log likelihood -1.415796
[ Info: iteration 33, average log likelihood -1.415775
[ Info: iteration 34, average log likelihood -1.415755
[ Info: iteration 35, average log likelihood -1.415736
[ Info: iteration 36, average log likelihood -1.415718
[ Info: iteration 37, average log likelihood -1.415701
[ Info: iteration 38, average log likelihood -1.415684
[ Info: iteration 39, average log likelihood -1.415668
[ Info: iteration 40, average log likelihood -1.415653
[ Info: iteration 41, average log likelihood -1.415639
[ Info: iteration 42, average log likelihood -1.415625
[ Info: iteration 43, average log likelihood -1.415612
[ Info: iteration 44, average log likelihood -1.415600
[ Info: iteration 45, average log likelihood -1.415588
[ Info: iteration 46, average log likelihood -1.415576
[ Info: iteration 47, average log likelihood -1.415565
[ Info: iteration 48, average log likelihood -1.415554
[ Info: iteration 49, average log likelihood -1.415544
[ Info: iteration 50, average log likelihood -1.415534
┌ Info: EM with 100000 data points 50 iterations avll -1.415534
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.249674     0.275355    0.0983212   0.149569     0.0893885   0.264095    0.254444      0.45875     0.00764353  -0.0523293    0.0540837   0.409049    0.0614796   0.123622    0.0887106    0.187434     0.270571    -0.324363     -0.022804   -0.0157853   -0.551977    -0.344954    0.26668     -0.048443   -0.221356    -0.19795
 -0.189169    -0.535444    0.223452    0.426233    -0.264414   -0.177033   -1.00617      -0.726636   -0.145817     0.23231     -0.428683   -0.0868399   0.142137   -0.567357    0.603536    -0.175225    -0.505628     0.269407      0.125928   -0.0379529    0.145825     0.249305   -0.308126     0.53328    -0.4053       0.124194
  0.0720743   -0.369471    0.883616   -0.357353     0.0904102   0.117945    0.000761701   0.453405    0.0899544   -0.788645     0.143472   -0.1504     -0.561203    0.426493   -0.0315913   -0.0772172   -0.484488    -0.885224     -0.478547    0.228036     0.153136     0.443109   -0.0933051    0.208863   -0.172837     0.148159
 -0.303398    -0.0254609  -0.0559801   0.188977    -0.300754    0.585601   -0.570875     -0.287711   -0.806324     0.269865    -0.0208051   0.153153    0.147467   -0.164831   -0.340514     0.0838114    0.417982     0.433238      0.268093    0.542731     0.278292    -0.246558   -0.434023    -0.219842   -0.279012     0.198018
  0.114406    -0.486757    0.385024    0.00253418  -0.202056   -0.603512   -0.147504     -0.149176    0.199852    -0.149955     0.551176    0.33181     0.180521   -1.23193    -0.072891    -0.691574    -0.252751     0.000703273  -0.548727   -0.309362     0.00958142  -0.514283   -0.112809    -0.105489    0.160531    -0.064166
  0.104718    -0.190207    0.118371    0.147431     0.115294    0.0512944  -0.119488      0.195364    0.0275747   -0.352671     0.314011    0.187055   -0.504806    0.054931   -0.37513     -0.271983     0.167469     0.0868343    -0.110034    0.173908     0.0196921   -0.0638794   0.0122705    0.173046   -0.713904     0.609602
  0.28157     -0.06055     0.333727    0.294668     0.480221   -0.359995    0.632968     -0.134909    0.73547      0.309724    -0.0821056   0.287985   -0.436787    0.581816   -0.0462503    0.0640368    0.363421    -0.240774      0.661498   -0.584304    -0.209357    -0.471986   -0.448751     0.45754     0.512874     0.522468
  0.696457     0.20869     0.263853    0.264666     0.538195   -0.324988    0.3036       -0.103778   -0.254357    -0.875767     0.185458    0.0718872   0.356543    0.89263     0.627182     0.685542    -1.02781      0.198531      0.443189    0.346152     0.0468837   -0.260463    0.289817     0.394245    0.126615     0.133727
 -0.394162    -0.404474   -0.176902    0.0766399   -0.197131    0.293014    0.0200907    -0.14371    -0.581426    -0.407292    -0.45151     0.16652    -0.591154    0.685225   -0.0765072    0.243354     0.203484    -0.592614      0.208661   -0.141034    -0.326463    -0.380097    0.975587     0.601203   -0.320636    -0.103717
 -0.0933148   -0.0818326   0.403537    0.0182508   -0.704802   -0.953592    0.15026      -0.0591465   0.0593772    0.292603    -0.124788    0.692415    0.797468   -0.141439   -0.0755049   -0.273       -0.115555    -0.841573     -0.129837   -0.290727    -0.205094     0.124771   -0.12281      0.0252094   0.0740063   -0.66664
 -0.313191     0.0940291   0.0253763   0.0188679    0.266416   -0.246683    0.0579813     0.165269    0.409604     0.101427    -0.30133    -0.0547982   0.0717681  -0.0464011   0.0613414    0.00558285  -0.347069    -0.323424      0.408903   -0.0486307    0.277967     0.0194519   0.209229    -0.263199    0.82211     -0.469
  0.267826     0.477797    0.325978    0.465504     0.079055   -0.218615   -0.27982      -0.538151   -0.0939704   -0.114292     0.114154    0.209333   -0.470202   -0.163464    0.0121699   -0.526494     0.13201     -0.553729     -0.561037    0.420771     0.123562     0.0543081   0.433875     0.0290794   0.0739176   -0.0197803
 -0.120809    -0.328562   -0.342975   -0.485445    -0.0857014  -0.167314    0.197255      0.36706     0.299714     0.411562     0.227131   -0.868691    0.464944   -0.392213    0.0609645   -0.191062    -0.396248     0.64537       0.126877   -0.290879    -0.15922     -0.369912   -0.525053     0.276882    0.238251    -0.0131281
  0.295117     0.703911   -0.426035    0.117963     0.614308    0.470675   -0.355997     -0.419107    0.138187     0.716804    -0.475033   -0.368106   -0.490504    0.372279    0.0141121    0.380704     0.597794     0.00955148    0.602512   -0.121769    -0.37676      0.463642   -0.0849762    0.168636   -0.0223142    0.339592
 -0.310452     0.625294   -0.0958554   0.425685    -0.452143   -0.414595   -0.301336     -0.874443    0.275239     0.492481     0.131199   -0.543133    0.608123    0.242131    0.152179    -0.397594     0.0175093    0.415476     -0.0951455  -0.00798558   0.367302     0.305751    0.372657     0.224587    0.30729     -0.205722
 -0.638713    -0.519553    0.810265    0.262821    -0.17962    -0.552243   -0.510777      0.254691    0.528847    -0.241865     0.446432   -0.691107    0.546689    0.302557   -0.361801    -0.543804     0.028858    -0.303504     -0.0612037  -0.509386    -0.238741     0.249019    0.229998    -0.620083   -0.642218     0.762079
  0.160239    -0.510568   -0.113855    0.416134    -0.0491104  -0.358928    0.213858     -0.290868    0.221621     0.446847    -0.0798743  -0.179318   -0.103254   -0.179985   -0.115605     0.260803    -0.0137806    0.116562     -0.187442    0.505628     0.601481     0.320813   -0.596917    -0.372336    0.0152338   -0.087027
  0.315046    -0.286483    0.23901     0.414784     0.314018    0.124961    0.431332      0.255647   -0.00849885   0.473144     0.0156753   0.32757     0.234196    0.0962501  -0.147895     0.422494     0.347086     0.364529     -0.296875   -0.671966    -0.397126    -0.303144   -0.275374    -0.062619   -0.0453218    0.238108
 -0.143241    -0.0750724   0.431873    0.179606     0.768425    0.179259    0.584324      0.307623   -0.0543429    0.364344     0.161376   -0.131577   -0.643522   -1.06751     0.557768    -0.466724     0.00489215  -0.313389      0.0316527  -0.256964    -0.63416      0.222899    0.055081    -0.266091    0.192786    -0.00442849
  0.00285839   0.0244248  -0.0441867  -0.05477     -0.0688546  -0.0345292  -0.00423093   -0.0214885  -0.0106025    0.00600831  -0.0570448  -0.0891155   0.059775   -0.0394671   0.00999938  -0.0374578   -0.0443971    0.0416509     0.0157848   0.00228578  -0.0477739   -0.0276534   0.00340263   0.0749235   0.059234    -0.0606494
  0.0965695   -0.487505    0.0149416  -0.586134     0.237599    0.0437879  -0.422166     -0.30431    -0.396436    -0.21622      0.259884   -0.043602   -0.423417   -0.0697238  -0.367855     0.0185024    0.402188     0.023477      0.156732   -0.331347     0.299366     0.305533   -0.296516    -0.29786     0.108301     0.0465661
 -0.0497911    0.511689   -0.0700713  -0.620548    -0.567591    0.58951     0.200588     -0.658223    0.425928    -0.432999    -0.297744   -0.820875   -0.152237   -0.0195765   0.42493     -0.814542     0.824656    -0.569537      1.26536     0.529548    -0.362627     0.15023    -0.143496     0.251288    0.657302    -0.670457
  0.123606    -0.390978   -0.211646    0.421776     0.308875   -0.613231    0.0761349     0.559295   -0.296416     0.31236     -0.165385    0.639569   -0.0770891  -0.0150982  -0.772117     0.235574    -0.750118     0.487063     -0.69768    -0.334141     0.313195    -0.0380569   0.513044    -0.059886   -0.165712     0.344132
 -0.49762      0.117941   -0.491174   -1.14982     -0.500465    0.103293   -0.803242      0.271278   -0.130035    -0.355011     0.0376808  -0.271048    0.194949    0.0604631  -0.199018    -0.1317      -0.665863    -0.140359      0.113049    0.107576     0.243704     0.165265    0.272762    -0.124854    0.00312819  -0.442979
 -0.329033     0.194734    0.133463   -0.42719     -0.578694    0.537832    0.218334     -0.153077   -0.176185    -0.301554    -0.152706   -0.148943    0.939734    0.0239066   0.614445     0.0980737   -0.108716     0.44712      -0.0384953  -0.0775468   -0.206168     0.204409   -0.10476     -0.271318    0.00929992   0.00681919
  0.506934     0.531317   -0.740408   -0.312765     0.192988    0.44457     0.0725942    -0.475312   -0.386584     0.336079    -0.275591    0.564271   -0.660006   -0.547429    0.334245     0.336792     0.102622     0.0478495     0.400174    0.410693     0.43855     -0.476554   -0.30482      0.663944    0.581962    -0.994868
  0.122598    -0.0811956  -0.465949   -0.636421     0.103472    0.782563    0.666472      0.803424    0.206847    -0.528435    -0.376978   -0.0756247  -0.181866   -0.228501   -0.339375     0.897138    -0.218909     0.360261      0.841073    0.13713      0.0201637   -0.447021   -0.205439    -0.179578   -0.0530996    0.192683
  0.124177    -0.322142    0.0883306  -0.0495264   -0.0726886  -0.11061    -0.186186     -0.325323   -0.0152764    0.217362    -0.122345   -0.25058    -0.0505893  -0.399141   -0.155537    -0.0943244    0.0365884    0.260105     -0.100858   -0.00996314   0.519639     0.323877   -0.417213    -0.256531    0.158822     0.168287
  0.711851     0.084812   -0.617534   -0.12322     -0.701274   -0.280379   -0.0992432     0.0290432  -0.216114    -0.141148     0.0557415  -0.134205    0.285587    0.439054   -0.171258     0.0174067    0.24513      0.439846     -0.135545    0.246625    -0.324957    -0.021738   -0.214236     0.567351   -0.572718     0.248653
  0.170535     0.465455    0.226376   -0.0737072    0.0895955  -0.190267   -0.268967      0.49843     0.0861926   -0.288167    -0.199031   -0.30409     0.175655    0.0767699   0.210235    -0.590234    -0.342678    -0.018926      0.154204   -0.32173     -0.418449    -0.240862    1.04928      0.609235    0.168057     0.289464
 -0.16454      0.203893    0.0602555  -0.00205217   0.0837702   0.26825     0.208397      0.506606   -0.188693    -0.0446575    0.0359734   0.435427    0.073633    0.292487   -0.00503098   0.330288     0.276819    -0.505592     -0.0952603   0.187446    -0.234478    -0.0975423   0.12201     -0.188093   -0.193247    -0.304795
  0.181297     0.280022   -0.690861   -0.182488     0.46078     0.554242    0.216431      0.218254    0.25974     -0.373142     0.273092   -0.520637   -0.663404    0.229016    0.173811    -0.111621    -0.0446878    0.622425     -0.353553    0.538168     0.170261    -0.117599    0.738339    -0.0204663   0.0351578    0.0127033[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415525
[ Info: iteration 2, average log likelihood -1.415516
[ Info: iteration 3, average log likelihood -1.415507
[ Info: iteration 4, average log likelihood -1.415498
[ Info: iteration 5, average log likelihood -1.415490
[ Info: iteration 6, average log likelihood -1.415482
[ Info: iteration 7, average log likelihood -1.415475
[ Info: iteration 8, average log likelihood -1.415467
[ Info: iteration 9, average log likelihood -1.415460
[ Info: iteration 10, average log likelihood -1.415454
┌ Info: EM with 100000 data points 10 iterations avll -1.415454
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
