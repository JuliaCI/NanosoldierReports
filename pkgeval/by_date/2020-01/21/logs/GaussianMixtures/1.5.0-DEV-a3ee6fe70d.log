Julia Version 1.5.0-DEV.122
Commit a3ee6fe70d (2020-01-20 16:27 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed URIParser ────────── v0.4.0
 Installed GaussianMixtures ─── v0.3.0
 Installed LegacyStrings ────── v0.4.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed Parameters ───────── v0.12.0
 Installed StatsFuns ────────── v0.9.3
 Installed Clustering ───────── v0.13.3
 Installed Distributions ────── v0.22.3
 Installed DataAPI ──────────── v1.1.0
 Installed Rmath ────────────── v0.6.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed NearestNeighbors ─── v0.4.4
 Installed HDF5 ─────────────── v0.12.5
 Installed DataStructures ───── v0.17.9
 Installed ScikitLearnBase ──── v0.5.0
 Installed JLD ──────────────── v0.9.1
 Installed BinaryProvider ───── v0.5.8
 Installed Missings ─────────── v0.4.3
 Installed OrderedCollections ─ v1.1.0
 Installed FillArrays ───────── v0.8.4
 Installed PDMats ───────────── v0.9.10
 Installed SortingAlgorithms ── v0.3.1
 Installed Blosc ────────────── v0.5.1
 Installed StaticArrays ─────── v0.12.1
 Installed FileIO ───────────── v1.2.1
 Installed Arpack ───────────── v0.4.0
 Installed Compat ───────────── v2.2.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed BinDeps ──────────── v1.0.0
 Installed CMake ────────────── v1.1.2
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Distances ────────── v0.8.2
 Installed QuadGK ───────────── v2.3.1
 Installed StatsBase ────────── v0.32.0
 Installed SpecialFunctions ─── v0.9.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_na1p6R/Project.toml`
 [no changes]
  Updating `/tmp/jl_na1p6R/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_adLI0Q/Project.toml`
 [no changes]
  Updating `/tmp/jl_adLI0Q/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_1RVtpP/Project.toml`
 [no changes]
  Updating `/tmp/jl_1RVtpP/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_cPjqZ8/Project.toml`
 [no changes]
  Updating `/tmp/jl_cPjqZ8/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_Py8YlM/Project.toml`
 [no changes]
  Updating `/tmp/jl_Py8YlM/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_Py8YlM/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.595278321436265e6, [96668.69157117943, 3331.3084288205864], [1875.0832416757046 -2486.8398205930093 -4355.796718942231; -2170.8039205985137 2393.4873183773066 4514.127768439335], [[94592.00220972883 -133.93434602111947 3074.9366318295442; -133.9343460211195 96766.85395173953 -2971.9121789068236; 3074.9366318295447 -2971.912178906824 93366.42430464459], [5661.200546002456 94.29488284529799 -3286.5462952204375; 94.29488284529798 2789.616632043084 3072.7370923108606; -3286.5462952204375 3072.7370923108606 6465.722780206872]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.758749e+03
      1       8.792962e+02      -8.794526e+02 |        7
      2       8.250546e+02      -5.424158e+01 |        4
      3       8.069522e+02      -1.810241e+01 |        0
      4       8.069522e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 806.9522222911596)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.059132
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.765916
[ Info: iteration 2, lowerbound -3.621727
[ Info: iteration 3, lowerbound -3.476135
[ Info: iteration 4, lowerbound -3.328577
[ Info: iteration 5, lowerbound -3.202054
[ Info: iteration 6, lowerbound -3.119063
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.085951
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -3.070955
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -3.051726
[ Info: iteration 10, lowerbound -3.037049
[ Info: iteration 11, lowerbound -3.021020
[ Info: iteration 12, lowerbound -2.998255
[ Info: iteration 13, lowerbound -2.966697
[ Info: iteration 14, lowerbound -2.924065
[ Info: iteration 15, lowerbound -2.868017
[ Info: iteration 16, lowerbound -2.796730
[ Info: iteration 17, lowerbound -2.710637
[ Info: iteration 18, lowerbound -2.615694
[ Info: iteration 19, lowerbound -2.524813
[ Info: iteration 20, lowerbound -2.450437
[ Info: iteration 21, lowerbound -2.396230
[ Info: iteration 22, lowerbound -2.361306
[ Info: dropping number of Gaussions to 3
[ Info: iteration 23, lowerbound -2.331103
[ Info: iteration 24, lowerbound -2.310908
[ Info: iteration 25, lowerbound -2.307970
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.302917
[ Info: iteration 27, lowerbound -2.299259
[ Info: iteration 28, lowerbound -2.299256
[ Info: iteration 29, lowerbound -2.299254
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Jan 22 02:14:02 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Jan 22 02:14:11 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Wed Jan 22 02:14:13 2020: EM with 272 data points 0 iterations avll -2.059132
5.8 data points per parameter
, Wed Jan 22 02:14:15 2020: GMM converted to Variational GMM
, Wed Jan 22 02:14:23 2020: iteration 1, lowerbound -3.765916
, Wed Jan 22 02:14:23 2020: iteration 2, lowerbound -3.621727
, Wed Jan 22 02:14:23 2020: iteration 3, lowerbound -3.476135
, Wed Jan 22 02:14:23 2020: iteration 4, lowerbound -3.328577
, Wed Jan 22 02:14:23 2020: iteration 5, lowerbound -3.202054
, Wed Jan 22 02:14:23 2020: iteration 6, lowerbound -3.119063
, Wed Jan 22 02:14:24 2020: dropping number of Gaussions to 7
, Wed Jan 22 02:14:24 2020: iteration 7, lowerbound -3.085951
, Wed Jan 22 02:14:24 2020: dropping number of Gaussions to 5
, Wed Jan 22 02:14:24 2020: iteration 8, lowerbound -3.070955
, Wed Jan 22 02:14:24 2020: dropping number of Gaussions to 4
, Wed Jan 22 02:14:24 2020: iteration 9, lowerbound -3.051726
, Wed Jan 22 02:14:24 2020: iteration 10, lowerbound -3.037049
, Wed Jan 22 02:14:24 2020: iteration 11, lowerbound -3.021020
, Wed Jan 22 02:14:24 2020: iteration 12, lowerbound -2.998255
, Wed Jan 22 02:14:24 2020: iteration 13, lowerbound -2.966697
, Wed Jan 22 02:14:24 2020: iteration 14, lowerbound -2.924065
, Wed Jan 22 02:14:24 2020: iteration 15, lowerbound -2.868017
, Wed Jan 22 02:14:24 2020: iteration 16, lowerbound -2.796730
, Wed Jan 22 02:14:24 2020: iteration 17, lowerbound -2.710637
, Wed Jan 22 02:14:24 2020: iteration 18, lowerbound -2.615694
, Wed Jan 22 02:14:24 2020: iteration 19, lowerbound -2.524813
, Wed Jan 22 02:14:24 2020: iteration 20, lowerbound -2.450437
, Wed Jan 22 02:14:24 2020: iteration 21, lowerbound -2.396230
, Wed Jan 22 02:14:24 2020: iteration 22, lowerbound -2.361306
, Wed Jan 22 02:14:24 2020: dropping number of Gaussions to 3
, Wed Jan 22 02:14:24 2020: iteration 23, lowerbound -2.331103
, Wed Jan 22 02:14:24 2020: iteration 24, lowerbound -2.310908
, Wed Jan 22 02:14:24 2020: iteration 25, lowerbound -2.307970
, Wed Jan 22 02:14:24 2020: dropping number of Gaussions to 2
, Wed Jan 22 02:14:24 2020: iteration 26, lowerbound -2.302917
, Wed Jan 22 02:14:24 2020: iteration 27, lowerbound -2.299259
, Wed Jan 22 02:14:24 2020: iteration 28, lowerbound -2.299256
, Wed Jan 22 02:14:24 2020: iteration 29, lowerbound -2.299254
, Wed Jan 22 02:14:24 2020: iteration 30, lowerbound -2.299254
, Wed Jan 22 02:14:24 2020: iteration 31, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 32, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 33, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 34, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 35, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 36, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 37, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 38, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 39, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 40, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 41, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 42, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 43, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 44, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 45, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 46, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 47, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 48, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 49, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: iteration 50, lowerbound -2.299253
, Wed Jan 22 02:14:24 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777392259, 178.04509222607757]
β = [95.95490777392259, 178.04509222607757]
m = [2.000229257774835 53.85198717245849; 4.250300733269392 79.2868669443542]
ν = [97.95490777392259, 180.04509222607757]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119573026 -0.008953123827357124; 0.0 0.012748664777411867], [0.18404155547477818 -0.007644049042334341; 0.0 0.008581705166323813]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000004
avll from stats: -1.0152890533659569
avll from llpg:  -1.0152890533659606
avll direct:     -1.0152890533659606
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9758290337518339
avll from llpg:  -0.9758290337518339
avll direct:     -0.975829033751834
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0639511     0.0581948    0.093083     0.0514408    0.0189332   -0.160081   -0.101256    -0.00106316  -0.126994     0.0572619    -0.0999691    0.0736096    0.026124    -0.0653992   -0.09846      0.00103051  -0.110049      0.13768      0.0460858  -0.0512789     0.0054587    0.309349      0.0822908     0.178553     0.0609213   0.0255152
 -0.064375     -0.00791985  -0.0311439    0.198577    -0.122675    -0.0201808   0.0910888    0.0520809   -0.0570446   -0.11598      -0.219547    -0.0410838   -0.00469529  -0.0416368   -0.0559959   -0.215178     0.0157441    -0.164535     0.105868    0.0260988     0.125936    -0.129804      0.122385      0.0207773    0.1331     -0.0431577
 -0.0453804    -0.163401    -0.139263     0.142479    -0.0772404    0.0901533  -0.0133253   -0.10611     -0.0243184   -0.193496      0.172102    -0.0449609    0.0865052    0.196828    -0.0267566    0.0101214    0.0896522    -0.0837787   -0.154205   -0.194898      0.0238221   -0.00443623   -0.0320959     0.0703807    0.0524976  -0.086357
  0.170867      0.140053     0.104691    -0.0118016    0.051538     0.240201    0.145715    -0.0694807   -0.0984961   -0.0940747    -0.00279647  -0.0396624   -0.0251291   -0.336835     0.287309    -0.0913714   -0.030761     -0.0277931   -0.0566927  -0.00337707    0.0296274   -0.0473159     0.100564      0.0477174    0.0656911   0.115269
 -0.0244261    -0.017882     0.0219458    0.0649746   -0.0610044   -0.231828   -0.0444445   -0.118902    -0.114931    -0.1032        0.0172414    0.0655738    0.00237043   0.104964     0.0857747   -0.0966906    0.0542933     0.0998919   -0.174436    0.127739      0.00418596  -0.203634      0.128488      0.250268     0.0203746  -0.0213256
 -0.073569     -0.083869    -0.00982332   0.0466192   -0.13489      0.0444593  -0.0860587    0.048316     0.0435041    0.0408358    -0.0142676    0.0122638   -0.00196012   0.114376    -0.0616542    0.0649574    0.0951899     0.0493108   -0.0858326  -0.0910618    -0.0390215   -0.116511     -0.0792347     0.0852346    0.195659    0.174859
 -0.0204955    -0.142385     0.0609347   -0.0508894   -0.118967     0.077646   -0.108146     0.0380968   -0.122733    -0.00731065   -0.0470175    0.0926732   -0.0984324   -0.082136    -0.112236     0.0484746   -0.034759     -0.135504     0.0322684  -0.162946     -0.0604478   -0.0129945     0.00241057    0.021547     0.156842   -0.0209444
 -0.0159728     0.0064084   -0.0937416   -0.0173449   -0.105197     0.0269688  -0.160451     0.190157    -0.0753586   -0.187359     -0.0949124   -0.216551     0.0224575    0.109697    -0.0869508    0.0187753   -0.0539991     0.0145938   -0.163123    0.000767478   0.10026     -0.0367122     0.125706      0.0307242   -0.153836   -0.0383099
  0.0252268     0.017142     0.075976     0.0131784    0.0842755    0.183214    0.0104936   -0.0885032   -0.140045     0.000131269   0.0965239    0.141729     0.0983114    0.109254    -0.0562968   -0.00856078   0.193502     -0.0251114    0.0163081  -0.178151     -0.0125842    0.0230393    -0.0569914     0.018654    -0.028859   -0.17921
 -0.0685018     0.0457421   -0.00965309   0.0192861    0.0111531    0.0697724   0.0864403   -0.0774153   -0.0573195   -0.0662912    -0.0624496    0.0910534    0.0723899    0.103485     0.141883     0.0312236    0.0708679    -0.0583984   -0.109851    0.0587198     0.131867    -0.0908616    -0.0566545     0.0419072   -0.141539   -0.209807
  0.0112844    -0.0972824    0.137656     0.168262     0.148117     0.0683634   0.0647432   -0.148937     0.106347    -0.147301     -0.100558    -0.188374     0.0461893   -0.0858788    0.12731      0.169033    -0.0938821    -0.123522    -0.0412392   0.00607295    0.0153824   -0.0192399    -0.153727      0.0226834   -0.128157   -0.0767735
 -0.0348373    -0.0162133   -0.0447254    0.00738665  -0.0875885    0.0834338   0.040642     0.0755696    0.0564475   -0.0200439     0.145272    -0.102819    -0.169406     0.0854064    0.00952065   0.0624987   -0.0281375    -0.0988055    0.0632126   0.00538274   -0.0443406   -0.107871     -0.00418589   -0.057963    -0.033437   -0.0671859
  0.0152424     0.00768566   0.0958713   -0.0143108   -0.0770401    0.237961    0.0230801    0.165186     0.110343     0.107585      0.0591123    0.0428313    0.122037     0.0677046    0.0798491   -0.149171     0.0718215    -0.25594      0.0488129  -0.155413     -0.120063     0.0828472     0.127058     -0.0453424    0.0078959  -0.116515
  0.0432519    -0.148333     0.22241      0.123868    -0.0715417   -0.160935   -0.0797505    0.0364155    0.202268     0.0531358     0.0116106    0.0373093    0.0961505   -0.11916      0.143827     0.0378458   -0.0648932    -0.0736072   -0.122667    0.109705     -0.0638196   -0.0818085    -0.0826068    -0.0423261    0.0419396   0.016842
 -0.1287        0.0412549    0.0833584   -0.121635     0.0635561   -0.107379   -0.0356239   -0.0781564    0.128562     0.104849     -0.052234     0.00498512  -0.0337548   -0.13869     -0.0841127   -0.0268147   -0.0830693    -0.0589496   -0.0106255   0.0545719    -0.00281546  -0.0780926     0.10265       0.0568332    0.0421517  -0.0900349
 -0.17486      -0.069316    -0.0187756   -0.0929783   -0.113237     0.0919728  -0.095831     0.0848339   -0.0282011    0.0761593    -0.166377     0.11932     -0.0356325   -0.0861228    0.0497754   -0.0166445   -0.155499     -0.0413964   -0.112491   -0.146868      0.0507292   -0.0311026    -0.0953591    -0.080068    -0.115126    0.233001
 -0.0167972    -0.0322192    0.0907508    0.0274587   -0.0778046   -0.0961617  -0.075046    -0.0480642   -0.050727     0.0605295    -0.0497133   -0.107349     0.0695348   -0.113195    -0.185585     0.0684038   -0.100487     -0.0332207    0.214986    0.0207558     0.0503032    0.176868     -0.0119427    -0.00755792   0.0330271  -0.158792
 -0.19159      -0.0539049   -0.104038     0.0541451   -0.157962    -0.0539319  -0.138211     0.0407114    0.00957551   0.200724      0.00224937  -0.0938054   -0.121091     0.0904058   -0.101031     0.0514896    0.00448005    0.0518383   -0.164472    0.151822     -0.104362    -0.078177      0.16395       0.0808013    0.0286218   0.172178
 -0.00149729   -0.101601     0.151514    -0.0494341   -0.0191905    0.0612228  -0.0309464   -0.130111    -0.0328988    0.0849489     0.109365     0.0470811   -0.0297657    0.148551    -0.202836     0.0374139    0.0254825     0.0419847    0.0655597   0.0359238     0.211042    -0.0011185    -0.139287      0.0826937    0.103077    0.0862472
  0.124201     -0.040948    -0.00777409   0.0220701   -0.0162272   -0.185197    0.00270233   0.199288     0.159746    -0.0838561    -0.129706    -0.104516    -0.138414    -0.0852961    0.0455556    0.134858    -0.0293879     0.0526396   -0.155674    0.0818085     0.140491    -0.0855296     0.000752936   0.0692091    0.116313    0.0920118
 -0.0318228     0.0185366   -0.122929     0.164613     0.138201     0.0592403  -0.11937     -0.013459     0.0188409    0.0156463    -0.185175    -0.0440418    0.115903    -0.015286    -0.0685764    0.0596771   -0.120591      0.0328022   -0.118345   -0.114264      0.0491437    0.0159885     0.0188717    -0.150409    -0.0174676  -0.134694
  0.0095757    -0.0426056   -0.0326527    0.0448778    0.0221805   -0.0845407  -0.0860748    0.0157051    0.0132419    0.106354      0.133395     0.157061     0.0402739   -0.0250898   -0.0686448   -0.0313333   -0.160478      0.10209      0.111126   -0.0290755    -0.0850328    0.0696073    -0.191782      0.0681515    0.0583875   0.0389979
 -0.0655561     0.152708    -0.023952     0.1538       0.188121    -0.160007    0.227651    -0.175264     0.0228286   -0.114416     -0.0529428    0.0293906   -0.0373962    0.022433    -0.0430008    0.133453    -0.000458658   0.02091     -0.0547193  -0.0662302    -0.149356    -0.0413842    -0.0368921     0.0657096   -0.0727405   0.138015
  0.0625941     0.0499981    0.0653642   -0.0775029   -0.117687    -0.0528364  -0.0357873   -0.029556     0.111109     0.00544703   -0.125084    -0.0823406   -0.0365455    0.131407    -0.055312     0.0564814    0.0707067     0.0312472    0.115825   -0.062002     -0.0904282   -0.05042       0.0807712    -0.00192863  -0.0765825  -0.0834523
 -0.0779375    -0.106645    -0.0143777   -0.25668      0.014639     0.188474   -0.0337861    0.0680312    0.0462697   -0.176378     -0.0782411   -0.0543766    0.0171397   -0.1025       0.0152906   -0.218391     0.110668      0.184842    -0.10751     0.102539     -0.0174801   -0.111726     -0.0668756    -0.228426     0.0574907   0.112121
 -0.0510247    -0.111323    -0.0377069   -0.170044     0.135973    -0.0208301  -0.0357211    0.0204961    0.0450878   -0.0707971     0.0748132   -0.150415    -0.0938746    0.0767769   -0.0818277    0.0586997    0.0490053     0.0471188   -0.0413363  -0.0268054     0.0225361   -0.000915746   0.11367      -0.0928094   -0.174284    0.0485466
 -0.0655741     0.00690084   0.0225089    0.0117585   -0.00344633   0.0545046   0.00998079   0.0975781    0.083119    -0.0918981     0.195973     0.0858455    0.0535039    0.0997927    0.186714     0.0199478   -0.0389453    -0.157399     0.143234    0.00927329    0.0638101   -0.040497      0.00925902   -0.165196    -0.0826741  -0.0931035
  0.000196248  -0.0549047   -0.026018     0.0288144    0.0860325   -0.0196815   0.00129942  -0.0275818    0.194089     0.0176834    -0.187194    -0.0625475    0.0964024    0.0735242    0.0547199    0.211528    -0.132958     -0.0047157   -0.111841    0.0544524     0.0323932   -0.0603281     5.93812e-5   -0.126392    -0.091753   -0.00339667
  0.0468669    -0.144316     0.00213396   0.203443     0.0345512    0.0814283  -0.157708     0.0658049    0.0777504   -0.0402192    -0.0184164   -0.0450707    0.104446    -0.226046     0.0801161   -0.00985237  -0.00419812   -0.0858044   -0.133921   -0.0494992    -0.129384     0.21529       0.132596      0.0114406   -0.201308    0.0720843
  0.129953     -0.146817    -0.240803    -0.0528654    0.0780304    0.0932299  -0.0128674   -0.00149128  -0.192538     0.0203425    -0.0652255   -0.0219881   -0.0991589   -0.0292984    0.0427613   -0.156259    -0.0577873     0.00646702   0.108375   -0.00104256    0.0890136    0.10538       0.039946     -0.0390344    0.0109573   0.191211
 -0.110413     -0.0251802    0.0257493   -0.168546    -0.0613679   -0.0380902  -0.0165776   -0.105149     0.0235854    0.0575339     0.0707271   -0.0330712   -0.0444246   -0.0890575   -0.124357     0.00790965   0.00461187    0.0952943    0.0997188   0.0209364     0.183933     0.129061     -0.0169414    -0.0140163   -0.0796201   0.0210819
  0.0953089    -0.0316551    0.0560181   -0.0319755   -0.0598036    0.0138782  -0.107889    -0.120563     0.0851675   -0.248563     -0.126658     0.0836099    0.00973042   0.00725695  -0.0893711    0.205185     0.174114     -0.136616     0.0351754  -0.077842      0.0794525   -0.0764614    -0.116203     -0.0706645   -0.0930112   0.035425kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.406277530367239
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406360
[ Info: iteration 2, average log likelihood -1.406289
[ Info: iteration 3, average log likelihood -1.405839
[ Info: iteration 4, average log likelihood -1.400662
[ Info: iteration 5, average log likelihood -1.384459
[ Info: iteration 6, average log likelihood -1.376126
[ Info: iteration 7, average log likelihood -1.374725
[ Info: iteration 8, average log likelihood -1.374317
[ Info: iteration 9, average log likelihood -1.374107
[ Info: iteration 10, average log likelihood -1.373962
[ Info: iteration 11, average log likelihood -1.373846
[ Info: iteration 12, average log likelihood -1.373748
[ Info: iteration 13, average log likelihood -1.373669
[ Info: iteration 14, average log likelihood -1.373607
[ Info: iteration 15, average log likelihood -1.373557
[ Info: iteration 16, average log likelihood -1.373517
[ Info: iteration 17, average log likelihood -1.373484
[ Info: iteration 18, average log likelihood -1.373458
[ Info: iteration 19, average log likelihood -1.373437
[ Info: iteration 20, average log likelihood -1.373420
[ Info: iteration 21, average log likelihood -1.373406
[ Info: iteration 22, average log likelihood -1.373394
[ Info: iteration 23, average log likelihood -1.373385
[ Info: iteration 24, average log likelihood -1.373377
[ Info: iteration 25, average log likelihood -1.373371
[ Info: iteration 26, average log likelihood -1.373366
[ Info: iteration 27, average log likelihood -1.373361
[ Info: iteration 28, average log likelihood -1.373357
[ Info: iteration 29, average log likelihood -1.373354
[ Info: iteration 30, average log likelihood -1.373352
[ Info: iteration 31, average log likelihood -1.373349
[ Info: iteration 32, average log likelihood -1.373347
[ Info: iteration 33, average log likelihood -1.373345
[ Info: iteration 34, average log likelihood -1.373344
[ Info: iteration 35, average log likelihood -1.373342
[ Info: iteration 36, average log likelihood -1.373341
[ Info: iteration 37, average log likelihood -1.373339
[ Info: iteration 38, average log likelihood -1.373338
[ Info: iteration 39, average log likelihood -1.373337
[ Info: iteration 40, average log likelihood -1.373336
[ Info: iteration 41, average log likelihood -1.373335
[ Info: iteration 42, average log likelihood -1.373334
[ Info: iteration 43, average log likelihood -1.373333
[ Info: iteration 44, average log likelihood -1.373332
[ Info: iteration 45, average log likelihood -1.373331
[ Info: iteration 46, average log likelihood -1.373329
[ Info: iteration 47, average log likelihood -1.373328
[ Info: iteration 48, average log likelihood -1.373327
[ Info: iteration 49, average log likelihood -1.373326
[ Info: iteration 50, average log likelihood -1.373324
┌ Info: EM with 100000 data points 50 iterations avll -1.373324
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4063600740707094
│     -1.4062885218309016
│      ⋮
└     -1.3733240786104823
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.373441
[ Info: iteration 2, average log likelihood -1.373342
[ Info: iteration 3, average log likelihood -1.373065
[ Info: iteration 4, average log likelihood -1.370557
[ Info: iteration 5, average log likelihood -1.360338
[ Info: iteration 6, average log likelihood -1.348432
[ Info: iteration 7, average log likelihood -1.343876
[ Info: iteration 8, average log likelihood -1.342140
[ Info: iteration 9, average log likelihood -1.340952
[ Info: iteration 10, average log likelihood -1.339899
[ Info: iteration 11, average log likelihood -1.338887
[ Info: iteration 12, average log likelihood -1.338012
[ Info: iteration 13, average log likelihood -1.337330
[ Info: iteration 14, average log likelihood -1.336805
[ Info: iteration 15, average log likelihood -1.336410
[ Info: iteration 16, average log likelihood -1.336097
[ Info: iteration 17, average log likelihood -1.335836
[ Info: iteration 18, average log likelihood -1.335617
[ Info: iteration 19, average log likelihood -1.335423
[ Info: iteration 20, average log likelihood -1.335221
[ Info: iteration 21, average log likelihood -1.334954
[ Info: iteration 22, average log likelihood -1.334574
[ Info: iteration 23, average log likelihood -1.334086
[ Info: iteration 24, average log likelihood -1.333592
[ Info: iteration 25, average log likelihood -1.333146
[ Info: iteration 26, average log likelihood -1.332743
[ Info: iteration 27, average log likelihood -1.332370
[ Info: iteration 28, average log likelihood -1.332015
[ Info: iteration 29, average log likelihood -1.331681
[ Info: iteration 30, average log likelihood -1.331378
[ Info: iteration 31, average log likelihood -1.331122
[ Info: iteration 32, average log likelihood -1.330931
[ Info: iteration 33, average log likelihood -1.330800
[ Info: iteration 34, average log likelihood -1.330712
[ Info: iteration 35, average log likelihood -1.330653
[ Info: iteration 36, average log likelihood -1.330613
[ Info: iteration 37, average log likelihood -1.330585
[ Info: iteration 38, average log likelihood -1.330566
[ Info: iteration 39, average log likelihood -1.330552
[ Info: iteration 40, average log likelihood -1.330541
[ Info: iteration 41, average log likelihood -1.330533
[ Info: iteration 42, average log likelihood -1.330527
[ Info: iteration 43, average log likelihood -1.330521
[ Info: iteration 44, average log likelihood -1.330517
[ Info: iteration 45, average log likelihood -1.330513
[ Info: iteration 46, average log likelihood -1.330509
[ Info: iteration 47, average log likelihood -1.330506
[ Info: iteration 48, average log likelihood -1.330503
[ Info: iteration 49, average log likelihood -1.330500
[ Info: iteration 50, average log likelihood -1.330498
┌ Info: EM with 100000 data points 50 iterations avll -1.330498
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.373441099825118
│     -1.37334189648815
│      ⋮
└     -1.330497809499437
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.330650
[ Info: iteration 2, average log likelihood -1.330502
[ Info: iteration 3, average log likelihood -1.330039
[ Info: iteration 4, average log likelihood -1.326389
[ Info: iteration 5, average log likelihood -1.314177
[ Info: iteration 6, average log likelihood -1.299372
[ Info: iteration 7, average log likelihood -1.290883
[ Info: iteration 8, average log likelihood -1.286791
[ Info: iteration 9, average log likelihood -1.284397
[ Info: iteration 10, average log likelihood -1.282429
[ Info: iteration 11, average log likelihood -1.280621
[ Info: iteration 12, average log likelihood -1.279245
[ Info: iteration 13, average log likelihood -1.278260
[ Info: iteration 14, average log likelihood -1.277588
[ Info: iteration 15, average log likelihood -1.277156
[ Info: iteration 16, average log likelihood -1.276844
[ Info: iteration 17, average log likelihood -1.276560
[ Info: iteration 18, average log likelihood -1.276247
[ Info: iteration 19, average log likelihood -1.275824
[ Info: iteration 20, average log likelihood -1.275193
[ Info: iteration 21, average log likelihood -1.274327
[ Info: iteration 22, average log likelihood -1.273371
[ Info: iteration 23, average log likelihood -1.272558
[ Info: iteration 24, average log likelihood -1.271991
[ Info: iteration 25, average log likelihood -1.271537
[ Info: iteration 26, average log likelihood -1.271171
[ Info: iteration 27, average log likelihood -1.270929
[ Info: iteration 28, average log likelihood -1.270754
[ Info: iteration 29, average log likelihood -1.270617
[ Info: iteration 30, average log likelihood -1.270514
[ Info: iteration 31, average log likelihood -1.270435
[ Info: iteration 32, average log likelihood -1.270373
[ Info: iteration 33, average log likelihood -1.270324
[ Info: iteration 34, average log likelihood -1.270284
[ Info: iteration 35, average log likelihood -1.270252
[ Info: iteration 36, average log likelihood -1.270226
[ Info: iteration 37, average log likelihood -1.270204
[ Info: iteration 38, average log likelihood -1.270187
[ Info: iteration 39, average log likelihood -1.270172
[ Info: iteration 40, average log likelihood -1.270160
[ Info: iteration 41, average log likelihood -1.270151
[ Info: iteration 42, average log likelihood -1.270143
[ Info: iteration 43, average log likelihood -1.270137
[ Info: iteration 44, average log likelihood -1.270132
[ Info: iteration 45, average log likelihood -1.270129
[ Info: iteration 46, average log likelihood -1.270126
[ Info: iteration 47, average log likelihood -1.270124
[ Info: iteration 48, average log likelihood -1.270122
[ Info: iteration 49, average log likelihood -1.270120
[ Info: iteration 50, average log likelihood -1.270119
┌ Info: EM with 100000 data points 50 iterations avll -1.270119
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.330650108770644
│     -1.330501806802308
│      ⋮
└     -1.270119261931774
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.270350
[ Info: iteration 2, average log likelihood -1.270033
[ Info: iteration 3, average log likelihood -1.267517
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.247782
[ Info: iteration 5, average log likelihood -1.221534
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.191845
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.198239
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.186621
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.205893
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.197777
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.193234
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.179741
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     11
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.182101
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.206313
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.191115
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.182675
[ Info: iteration 17, average log likelihood -1.189052
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     10
│     11
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.165875
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.206566
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.194070
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.177453
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      3
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.177589
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.202088
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.193346
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.194190
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.178563
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.188447
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     10
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.179404
[ Info: iteration 29, average log likelihood -1.195848
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      4
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.172801
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.201425
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.191154
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.174905
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.182187
[ Info: iteration 35, average log likelihood -1.200258
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.174406
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.182146
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.182823
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.195055
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.189321
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.183907
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     10
│     11
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.174466
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.207675
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.189157
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.178408
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.181546
[ Info: iteration 47, average log likelihood -1.209492
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.178161
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.183638
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.183683
┌ Info: EM with 100000 data points 50 iterations avll -1.183683
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2703499559797398
│     -1.2700332947738233
│      ⋮
└     -1.1836832906718742
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.190586
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     19
│     20
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.170231
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.172543
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.152649
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      7
│      8
│     20
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.147058
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      5
│      6
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.123822
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     14
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.126940
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.120200
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      7
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.102103
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.117293
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.106104
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.101457
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.081332
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     20
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.118994
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      7
│      8
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.103327
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.105683
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.081166
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.111147
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     22
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.100638
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     19
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.108094
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      4
│      7
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.079340
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.118968
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.097189
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     12
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.102893
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.072928
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.124005
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      7
│      8
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.097738
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.102282
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.088829
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.101846
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.104966
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     19
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.106951
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      7
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.089155
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.103744
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│     24
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.102198
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     19
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.091062
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      7
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.081159
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.094711
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      7
│      8
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.092711
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     19
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.103744
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.077288
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     19
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.120887
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      7
│      8
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.079112
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.083788
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.097023
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.100552
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      7
│      8
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.100714
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.101170
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      4
│      7
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.062008
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.111771
┌ Info: EM with 100000 data points 50 iterations avll -1.111771
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1905856711927352
│     -1.170231427863903
│      ⋮
└     -1.111771079220905
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.406277530367239
│     -1.4063600740707094
│     -1.4062885218309016
│     -1.4058386264840206
│      ⋮
│     -1.1011698593860733
│     -1.062007513671
└     -1.111771079220905
32×26 Array{Float64,2}:
 -0.0695924    -0.111145    -0.0528392    -0.154239     0.140659    -0.0243814  -0.0389409    0.018086     0.0250477   -0.0646628   0.067826   -0.151519    -0.107756     0.0740979   -0.0774782    0.0892328    0.0500658     0.0395989   -0.047227    -0.0383661    0.0245906     0.00734879    0.10791      -0.0854843   -0.159651     0.0504136
 -0.0237872     0.00495191  -0.103449      0.16618      0.110995     0.0711684  -0.11821     -0.0102384    0.0286123   -0.0432646  -0.153865   -0.0376279    0.10377     -0.0367271   -0.0844426    0.0472596   -0.112923      0.0243582   -0.117103    -0.10979      0.0356616     0.0573826     0.0310428    -0.11842     -0.0472823   -0.126782
 -0.0906744    -0.125685    -0.0765465    -0.261784     0.0189548    0.200352   -0.0230922    0.0308725    0.0478432   -0.181658   -0.0906971  -0.0521505    0.00403952  -0.127728     0.00339006  -0.195343     0.114549      0.193156    -0.0830491    0.0859092   -0.0181327    -0.11129      -0.0179683    -0.229012     0.0642381    0.107942
  0.126807     -0.0491433   -0.000929738   0.00847711  -0.00206728  -0.141348   -0.010526     0.212512     0.158551    -0.0616806  -0.166647   -0.0965304   -0.145468    -0.102781     0.0395209    0.113226    -0.0172928     0.0778038   -0.176945     0.0804577    0.150997     -0.0864763    -0.0636635     0.0912698    0.0932995    0.0984447
 -0.198984     -0.03922      0.072477     -0.16713     -0.0652827   -0.0208762  -0.438021    -0.192086     0.198365    -0.32941     0.0697147  -0.0281531    0.0200453   -0.0913427   -0.0703401   -0.0417177    0.0020167     0.228857     0.0730165    0.0196915    0.199385      0.234301     -0.0127009     0.0879959   -0.0812134    0.0209134
 -0.070202     -0.00258107   0.0141952    -0.169367    -0.0651908   -0.0490655   0.213531    -0.0408685   -0.132532     0.304536    0.0700903  -0.0324514   -0.101004    -0.0880642   -0.155218     0.0527804    0.00673994    0.00640454   0.0926975    0.0169258    0.17758       0.0614054     0.000599345  -0.0659037   -0.0806858    0.0210953
  0.0805191     0.0578122    0.106039      0.145007     0.0543765   -0.0499301  -0.0173586    0.0128292   -0.0878796    0.0447824  -0.360667    0.0785101    0.0632378   -0.0750698   -0.126013     0.032378    -0.127223      0.127114     0.0515252    0.0215668   -0.00244416    0.331178      0.0785823     0.176836     0.0527717    0.0912934
  0.0190706     0.0585839    0.0831259    -0.0372922    0.036554    -0.264587   -0.23157     -0.0147778   -0.174556     0.0812311   0.26202     0.0715336   -0.0169146   -0.0651267   -0.0849673   -0.0851164   -0.0837729     0.136115     0.0584394   -0.112624     0.000123592   0.278556      0.0855036     0.17956      0.0900534   -0.0317395
 -0.0211963    -0.0581186    0.0934293     0.0258559   -0.0690316   -0.0941027  -0.0834514   -0.0376361   -0.0494388    0.0543005  -0.0459613  -0.105979     0.0651165   -0.109834    -0.174742     0.0472329   -0.082738     -0.0253887    0.196367     0.0154619    0.0452595     0.171017     -0.0116831     0.00485011   0.0732806   -0.146782
 -0.17589      -0.0895157   -0.0620215    -0.0958596   -0.123684     0.094109   -0.0984328    0.0938485   -0.0609614    0.0797124  -0.166087    0.115703    -0.0377974   -0.082117     0.0600215   -0.0531358   -0.156897     -0.0286285   -0.10437     -0.140986     0.0152246    -0.0328456    -0.100037     -0.100011    -0.131363     0.24365
  0.0196303    -0.0697666    0.141791      0.166299     0.153142     0.0690266   0.0239741   -0.142091     0.103771    -0.138006   -0.112037   -0.194796     0.0448567   -0.145101     0.127461     0.169612    -0.0942217    -0.129116    -0.0491706   -0.0097052    0.0211224    -0.0121223    -0.152551      0.0311846   -0.128577    -0.0889689
  0.0413963    -0.168093     0.220184      0.123737    -0.128041    -0.176448   -0.108209     0.00672929   0.203005     0.0487214   0.0112412   0.0323726    0.0947836   -0.0786199    0.146117     0.0261598   -0.0644536    -0.0843818   -0.11487      0.125599    -0.0605672    -0.0669701    -0.0827712    -0.0330262    0.0469391    0.0204523
 -0.0430401    -0.166235    -0.12673       0.122814    -0.065413     0.0109813  -0.0105406   -0.0832458   -0.00761724  -0.189517    0.162108   -0.0436984    0.0858563    0.181543    -0.00787833  -0.00607471   0.0781343    -0.0712653   -0.0988117   -0.18492      0.0250329    -0.00253607   -0.0319553     0.0900159    0.0514738   -0.0783097
  0.0914462    -0.115316    -0.159706     -0.0134602    0.00955815   0.0103733  -0.0440289    0.00144452  -0.167685     0.0187993  -0.0585331  -0.0155343   -0.0422568   -0.0503686    0.0247462   -0.10875     -0.0154672    -0.00714742   0.00909989  -0.00259335   0.0376763     0.103944      0.0706144     0.0100698   -0.00583398   0.169052
 -0.017572      0.0574968    0.0220712     0.0469828    0.00127829  -0.136669    0.022605    -0.0861455    0.00433567  -0.0578448  -0.0752239  -0.00462664  -0.0291626    0.0771032   -0.0142746    0.0610094    0.0405119     0.033861    -0.0293174    0.0247012   -0.0969504    -0.0958281     0.0601786     0.0865882   -0.0798591    0.00321916
 -0.126744      0.0417419    0.114916     -0.0935545    0.0430376   -0.1071     -0.0249979   -0.0423546    0.127098     0.141557   -0.0884536  -0.00487398  -0.0436106   -0.133946    -0.0912249   -0.0291031   -0.0687764    -0.0556475   -0.0150904    0.0687885    0.000936235  -0.0909543     0.10158       0.0548639    0.0497799   -0.0807483
 -0.01893       0.0399002   -0.0594654    -0.0428357   -0.101926     0.0234135  -0.189837     0.190117    -0.108738    -0.249621   -0.0976989  -0.185521     0.00500989   0.120836    -0.0827388   -0.0724984   -0.0659895     0.0610075   -0.170235    -0.027164     0.204616     -0.0362062     0.165133      0.0112739   -0.156743    -0.674879
 -0.0115495    -0.0250671   -0.130058     -0.00335141  -0.0844855    0.0272473  -0.132948     0.292456    -0.0899692   -0.165778   -0.102513   -0.264982     0.0376062    0.109986    -0.106608     0.0750136   -0.037355      0.00425027  -0.167373     0.0168336   -0.00890741   -0.0400786     0.0827368     0.0696096   -0.128129     0.625597
  0.00103467   -0.0399105   -0.034503      0.0463853    0.0216783   -0.080365   -0.0420805    0.0229729    0.010711     0.0866765   0.120067    0.185099     0.0422889   -0.0146805   -0.0375411   -0.0233318   -0.160227      0.124426     0.0469302   -0.0397982   -0.072987      0.0680799    -0.186388      0.0900435    0.0606414    0.0089856
 -0.0720318    -0.0702674    0.0176445     0.0617385   -0.135555     0.0492485  -0.111042     0.0646666    0.05172      0.0489902  -0.0140943   0.0397146    0.00422045   0.113139    -0.0575881    0.0908415    0.0947099     0.0514423   -0.0886219   -0.094765    -0.0394854    -0.13083      -0.0986579     0.0825388    0.177289     0.201394
  0.0707642    -0.121287     0.0559021     0.113353    -0.0302284    0.0680094  -0.0928802    0.0186621    0.0645153   -0.0309716   0.0379585  -0.0237888    0.0522063   -0.189341    -0.0438431    0.00654736   0.000702559  -0.0558283   -0.0452216   -0.0134684   -0.0942393     0.170491      0.119481      0.0343474   -0.0305169    0.0191806
  0.0204269    -0.0899867    0.131551     -0.0575307   -0.116783     0.0778606  -0.0243931   -0.111756     0.0131402    0.137674    0.0977635   0.0586157   -0.0219718    0.196488    -0.212479     0.0437874    0.0390658     0.0528015    0.041166     0.0354012    0.266832     -0.0233241    -0.199937      0.0887906    0.0923895    0.0853752
  0.0279586     0.0541164    0.05021       0.0214823    0.0457169    0.182212    0.0138473   -0.0451637   -0.147238    -0.01222     0.108517    0.127602     0.101088     0.108191    -0.0258066   -0.00951379   0.217571     -0.0670302    0.0179909   -0.212842    -0.00649443    0.000307725  -0.0614101     0.028542    -0.0263934   -0.196836
 -0.0823944     0.0358719   -0.0118317     0.0200777    0.0489829    0.0770949   0.0796196   -0.0914201   -0.0613999   -0.0683224  -0.0605925   0.0888913    0.0849836    0.103611     0.135962     0.0334931    0.0627019    -0.0570507   -0.121448     0.0683596    0.138429     -0.089275     -0.0546372     0.0394916   -0.14673     -0.203645
  0.0916944    -0.0580514    0.0585978    -0.0239523   -0.061988     0.0254799  -0.102293    -0.113426     0.0947462   -0.247418   -0.0945712   0.0902277    0.0384733    0.00631389  -0.0839861    0.220943     0.171243     -0.106654     0.0345017   -0.0752397    0.0593718    -0.0932255    -0.107621     -0.0716206   -0.0900557    0.0388982
  0.000807598  -0.0552477   -0.0371606     0.0234549    0.0846694   -0.0229694   0.00320893  -0.0118189    0.197258     0.0176041  -0.183042   -0.0685036    0.0966918    0.0838144    0.0488995    0.216991    -0.130154     -0.0063163   -0.116813     0.0666786    0.045701     -0.0488099     0.0107948    -0.125884    -0.0911609    0.00375265
 -0.025437     -0.0663442   -0.0489624     0.0338194   -0.08716      0.0852794   0.299247     0.102568     0.058885    -0.0201429   0.198158   -0.13168     -0.183006     0.0348455    0.135741     0.0220566   -0.0146555    -0.0933959    0.0630658    0.039761    -0.0432124    -0.0979661    -0.0352283    -0.0590312    1.31872     -0.0389607
 -0.0403148    -0.0237801   -0.0266543     0.040861    -0.0870808    0.0916945  -0.364241     0.0472708    0.0609211   -0.0222354   0.113491   -0.123533    -0.170601     0.192466    -0.164607     0.0890446   -0.0758215    -0.0938128    0.0641949   -0.0677264   -0.0726519    -0.0989894     0.0356131    -0.0588958   -1.92213     -0.0882564
  0.0243434    -0.137754     0.0393672    -0.0887119   -0.132883     0.115319   -0.197464    -0.00374805  -0.131185     0.0335246  -0.0439515   0.0951618   -0.253649    -0.0633133   -0.119027     0.0422197   -0.0353665    -0.10948      0.0298418   -0.200363    -0.120932     -0.0210204     0.0031649     0.103425     0.172433     0.00077324
 -0.0893834    -0.140112     0.0492086     0.0170301   -0.0701705    0.0290376  -0.0227637    0.090874    -0.135757    -0.083291   -0.056888    0.111338     0.0898358   -0.050541     0.0438588    0.0592001   -0.0468739    -0.148499    -0.0132332   -0.100742     0.0325887    -0.0433778     0.0030046    -0.162071     0.128596    -0.151997
  0.0328637     0.0802024    0.0117319     0.0902293   -0.0200451    0.122221    0.115578     0.0149848   -0.0809344   -0.100981   -0.10866    -0.0452498   -0.01298     -0.1892       0.180175    -0.152083    -0.00525537   -0.0966045    0.028614     0.0131836    0.0912216    -0.0935871     0.105487      0.0370964    0.119762     0.0491371
 -0.0642989    -0.00594624   0.0130774     0.0259612   -0.069282     0.095107   -0.0159464    0.0950418    0.0648706    0.0602409   0.0849606   0.0145362    0.00195819   0.0693555    0.0552842   -0.0176109    0.0110462    -0.113277     0.0194024   -0.0302437   -0.0539331    -0.0113076     0.0975329    -0.0450274   -0.0153856   -0.0112707[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.115647
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      5
│      6
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.072189
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      7
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.080506
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.074958
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      7
│      8
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.075314
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.065670
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      7
│      8
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.107576
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      3
│      5
│      6
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.063661
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      7
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.079657
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      3
│      5
│      6
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.067669
┌ Info: EM with 100000 data points 10 iterations avll -1.067669
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.427340e+05
      1       6.915090e+05      -1.512249e+05 |       32
      2       6.533154e+05      -3.819366e+04 |       32
      3       6.348272e+05      -1.848814e+04 |       32
      4       6.266917e+05      -8.135552e+03 |       32
      5       6.228060e+05      -3.885667e+03 |       32
      6       6.201414e+05      -2.664613e+03 |       32
      7       6.177684e+05      -2.373016e+03 |       32
      8       6.150848e+05      -2.683584e+03 |       32
      9       6.121613e+05      -2.923462e+03 |       32
     10       6.099814e+05      -2.179930e+03 |       32
     11       6.082942e+05      -1.687245e+03 |       32
     12       6.067648e+05      -1.529324e+03 |       32
     13       6.052865e+05      -1.478379e+03 |       32
     14       6.039163e+05      -1.370165e+03 |       32
     15       6.030783e+05      -8.379506e+02 |       32
     16       6.026367e+05      -4.416872e+02 |       32
     17       6.024153e+05      -2.214039e+02 |       32
     18       6.023003e+05      -1.149515e+02 |       32
     19       6.022284e+05      -7.186446e+01 |       32
     20       6.021858e+05      -4.260593e+01 |       32
     21       6.021404e+05      -4.548316e+01 |       32
     22       6.020850e+05      -5.539937e+01 |       32
     23       6.020094e+05      -7.558206e+01 |       32
     24       6.019066e+05      -1.028092e+02 |       32
     25       6.017444e+05      -1.621207e+02 |       32
     26       6.015220e+05      -2.224298e+02 |       32
     27       6.012549e+05      -2.670859e+02 |       32
     28       6.009806e+05      -2.743132e+02 |       32
     29       6.006887e+05      -2.918763e+02 |       32
     30       6.004394e+05      -2.493243e+02 |       32
     31       6.002375e+05      -2.019479e+02 |       32
     32       6.000679e+05      -1.695209e+02 |       32
     33       5.999383e+05      -1.296447e+02 |       32
     34       5.998573e+05      -8.098658e+01 |       32
     35       5.998031e+05      -5.418484e+01 |       32
     36       5.997710e+05      -3.207943e+01 |       32
     37       5.997511e+05      -1.991480e+01 |       30
     38       5.997389e+05      -1.226180e+01 |       29
     39       5.997309e+05      -7.963744e+00 |       27
     40       5.997229e+05      -8.016044e+00 |       29
     41       5.997172e+05      -5.706603e+00 |       24
     42       5.997119e+05      -5.299395e+00 |       27
     43       5.997077e+05      -4.189727e+00 |       24
     44       5.997041e+05      -3.570648e+00 |       23
     45       5.997008e+05      -3.304091e+00 |       26
     46       5.996969e+05      -3.961796e+00 |       27
     47       5.996926e+05      -4.273509e+00 |       28
     48       5.996880e+05      -4.599440e+00 |       25
     49       5.996841e+05      -3.931479e+00 |       25
     50       5.996818e+05      -2.241082e+00 |       22
K-means terminated without convergence after 50 iterations (objv = 599681.8111206096)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.327487
[ Info: iteration 2, average log likelihood -1.299276
[ Info: iteration 3, average log likelihood -1.272922
[ Info: iteration 4, average log likelihood -1.241401
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.204682
[ Info: iteration 6, average log likelihood -1.171260
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     13
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.109507
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      7
│     15
│     17
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.114973
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.144509
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.139858
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      6
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.119693
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     13
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.108940
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     15
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.112878
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     14
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.115634
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│      7
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.120022
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     12
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.140169
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.130543
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     15
│     19
│     22
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.087373
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│     13
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.129750
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.135679
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     14
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.109303
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     11
│     15
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.114263
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     18
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.104259
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     12
│     13
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.115158
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.130828
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.111590
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│     11
│     18
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.097822
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.138102
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     17
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.129604
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     13
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.123447
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.105507
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│      7
│     11
│     12
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.083751
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     14
│     15
│     17
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.114063
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.146586
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     18
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.109528
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      7
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.119184
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     14
│     15
│     17
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.108754
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.128042
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     11
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.098858
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     12
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.093545
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│     14
│     15
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.105215
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     21
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.121185
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│     11
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.100730
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     12
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.108697
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     14
│     15
│     17
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.101874
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.119160
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.095781
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│     11
│     12
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.087820
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     14
│     15
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.117169
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.117831
┌ Info: EM with 100000 data points 50 iterations avll -1.117831
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0202131    -0.0694781    0.14003      0.166244     0.154621     0.0689819    0.0191098   -0.142071      0.103587    -0.138179    -0.11345     -0.193572      0.0458066    -0.148611    0.127719     0.169059     -0.0943841   -0.12899      -0.0471194  -0.00984352   0.0221516    -0.0131031   -0.152597     0.0300416    -0.128865    -0.0887144
 -0.00547295   -0.0602445   -0.0345346    0.0357476    0.00609373  -0.0705592   -0.0608839    0.0240104    -0.0269758    0.0723465    0.0949041    0.177262      0.000167654  -0.0203039  -0.0562937   -0.0178712    -0.13703      0.08147       0.0658398  -0.0598431   -0.0672045     0.0592371   -0.144841     0.0805237     0.0683268    0.00555834
 -0.000369218  -0.0543458   -0.0396435    0.0218298    0.0826214   -0.024243    -0.00111047  -0.00130205    0.189787     0.0150435   -0.179753    -0.0605255     0.100699      0.0818022   0.048564     0.215251     -0.126693    -0.007261     -0.113023    0.0640845    0.0444173    -0.0507981    0.00891026  -0.130248     -0.0889899    0.00111561
 -0.0344786     0.0191133   -0.126737     0.154197     0.112835     0.0685382   -0.106383    -0.021416      0.0245543   -0.0423187   -0.175387    -0.039342      0.0974987    -0.0183223  -0.10597      0.0562029    -0.119666     0.0324692    -0.115648   -0.111962     0.0471682     0.0407073    0.0208492   -0.133823     -0.0281509   -0.120675
 -0.00716976   -0.136717     0.0141051   -0.065474    -0.115786     0.130186    -0.125926    -0.0276802    -0.156725     0.0189899   -0.0334567    0.0927196    -0.19149      -0.0544867  -0.0815817    0.0361633    -0.0357901   -0.107314      0.0390452  -0.245532    -0.103062     -0.0247188    0.0171027    0.042929      0.157353    -0.0391026
 -0.0889638    -0.0290277   -0.239128     0.0498114   -0.154076    -0.0779414   -0.107027     0.0343227     0.0494222    0.20894      0.0170518   -0.0523175    -0.158244      0.203182   -0.125198     0.0180476    -0.0250148    0.0386187    -0.157722    0.187555    -0.101186     -0.103683     0.142211     0.0900326     0.00409156   0.139633
  0.0448513    -0.145977     0.0076972    0.212173     0.0121099    0.0579788   -0.162075     0.0661011     0.0873243   -0.0315675   -0.0146196   -0.0578235     0.113219     -0.228875    0.079219     0.00676251    0.0229903   -0.111947     -0.132684   -0.0461251   -0.133839      0.210282     0.123801    -4.96406e-5   -0.196135     0.00612027
 -0.118196      0.0421848    0.114081    -0.0988881    0.0446169   -0.107482    -0.0265023   -0.0425377     0.126664     0.132799    -0.0886303    0.000721881  -0.0439674    -0.14235    -0.089184    -0.0344303    -0.0713001   -0.0533193    -0.0116534   0.0657841   -0.00039652   -0.090749     0.10306      0.052969      0.0504513   -0.0821849
  0.032789      0.0391012    0.0553815    0.0213676    0.0405761    0.180399     0.00838281  -0.0488879    -0.146736    -0.00734306   0.109328     0.113922      0.101046      0.107814   -0.0308949   -0.00441789    0.200545    -0.0542606     0.0168057  -0.203835    -0.00266282    0.00258873  -0.0656393    0.0230588    -0.0246417   -0.176319
  0.0163537     0.0287556    0.0869506    0.00683233  -0.0961444    0.22889      0.0697658    0.158964      0.108651     0.120521     0.06296      0.0607136     0.131279      0.076194    0.113614    -0.129481      0.0693831   -0.22925       0.050122   -0.176375    -0.115568      0.0938092    0.11415     -0.0540699     0.0432896   -0.0893291
 -0.102486      0.0606396   -0.00616565   0.0186151   -0.0271508    0.0947568   -0.0732748    0.10895       0.0469692   -0.0363688    0.170591     0.157436      0.130655      0.0955761   0.196746     0.03512      -0.0477809   -0.110868      0.13557     0.00438139   0.0503608    -0.0364173    0.0693097   -0.19408      -0.165912    -0.0263322
  0.036449     -0.103611     0.128624    -0.0481162   -0.0889347    0.0711098   -0.0291296   -0.0834493     0.00914044   0.107109     0.104347     0.0571114    -0.0289993     0.137206   -0.23147      0.0435204     0.0264774    0.0302699     0.0458527   0.0291942    0.216464      0.0130885   -0.142669     0.084891      0.0988392    0.0891658
 -0.0702683    -0.111027    -0.053712    -0.150096     0.139681    -0.0246731   -0.0389186    0.0148976     0.0230532   -0.0649719    0.066989    -0.150233     -0.111889      0.0729951  -0.0764718    0.0862465     0.0486926    0.0411896    -0.0447851  -0.0317306    0.0246837     0.0063934    0.107136    -0.0888667    -0.156438     0.0499591
  0.0936005    -0.147172    -0.223757    -0.0870664    0.137283     0.113046    -0.0177558   -0.0109936    -0.305344     0.0798527   -0.0820367   -0.0129913    -0.101518     -0.051434    0.0206568   -0.144106     -0.0488742   -0.000572729   0.120049   -0.0369502    0.134359      0.160959     0.0582457   -0.0367481     0.00875025   0.176661
  0.097311     -0.0441642   -0.050267     0.00152217   0.0294876   -0.157476    -0.0157901    0.225276      0.144026    -0.0593309   -0.148157    -0.0734559    -0.174093     -0.122494    0.0643105    0.0836193    -0.0145636    0.0113153    -0.177694    0.0844426    0.204151     -0.0649168   -0.0580462    0.20738       0.0986559    0.0978022
 -0.015144      0.00610019  -0.0913804   -0.0218689   -0.0930667    0.0248441   -0.162029     0.234577     -0.100201    -0.200855    -0.0979387   -0.225568      0.0252907     0.11519    -0.0908656   -0.00370831   -0.0537821    0.0307237    -0.169228   -0.00637087   0.0959731    -0.0369242    0.115907     0.0396829    -0.139597    -0.0355399
 -0.103518     -0.12475     -0.133538    -0.285324     0.032082     0.195848    -0.0283378    0.030568      0.0380686   -0.197093    -0.0973955   -0.0586506     0.00409985   -0.126593   -0.00686539  -0.191634      0.094106     0.174169     -0.075821    0.0968115   -0.0170883    -0.10171     -0.0337868   -0.241281      0.0555421    0.104932
  0.049121      0.0569066    0.0939978    0.0538459    0.0449544   -0.155885    -0.12709     -0.000595644  -0.130887     0.0617868   -0.0506486    0.0733559     0.0219468    -0.0701053  -0.104384    -0.0229898    -0.103946     0.132436      0.0547605  -0.0467904    0.000208378   0.302681     0.0809466    0.177273      0.071106     0.0291029
 -0.0610202     0.146305    -0.0309753    0.161553     0.165931    -0.167401     0.227641    -0.181966      0.0118609   -0.0907746   -0.115617     0.0226265    -0.0491636     0.0598381  -0.0505702    0.143952      0.0113085   -0.00108258   -0.0550677  -0.0398251   -0.140909     -0.0422254   -0.0529136    0.061475     -0.0813033    0.138606
  0.129294      0.160437     0.0969056   -0.0119636    0.0629785    0.250553     0.136635    -0.00524949   -0.0943454   -0.08645     -0.0183171   -0.039663     -0.0201155    -0.339145    0.387631    -0.0928192    -0.0242006   -0.0287926    -0.0518361  -0.00464691   0.0450836    -0.0428985    0.106204     0.055011      0.0793958    0.118244
 -0.121823     -0.0217625    0.0379743   -0.166282    -0.067611    -0.0349776   -0.0657601   -0.107852      0.0136103    0.0272578    0.0702795   -0.0303615    -0.0485941    -0.0886837  -0.121328     0.0120952     0.00525735   0.10563       0.084297    0.0185079    0.186809      0.133612    -0.00584714   0.000811536  -0.0793875    0.0213112
  0.12183      -0.0556578   -0.0249735    0.0193903   -0.0272547   -0.135755    -0.0100331    0.213403      0.162912    -0.0609122   -0.155301    -0.0973203    -0.160218     -0.0467331   0.0215112    0.127103     -0.0378462    0.0910354    -0.151516    0.0829135    0.138359     -0.077713    -0.0214423    0.0583914     0.100949     0.0911175
  0.0852936    -0.0499004    0.0498009   -0.0197787   -0.0633758    0.025672    -0.0946155   -0.1195        0.0904454   -0.230982    -0.0833858    0.079283      0.0340451     0.0115416  -0.0853875    0.211569      0.158754    -0.112418      0.0361076  -0.0697382    0.0546258    -0.0931935   -0.107622    -0.0725463    -0.0888218    0.0327863
 -0.0365031    -0.166679    -0.135337     0.122882    -0.064763     0.00938365  -0.0076032   -0.0799798    -0.0165691   -0.179372     0.156811    -0.0444813     0.0854635     0.171583    0.00723302  -0.0151821     0.0761474   -0.0741163    -0.0918498  -0.185193     0.0231014     0.00221249  -0.031242     0.0864799     0.0505876   -0.0727215
 -0.0698986    -0.0104733   -0.0752447    0.18841     -0.114883    -0.00663648   0.0911352    0.0439742    -0.0613944   -0.122463    -0.207677    -0.0496044    -0.00354292   -0.0387814  -0.0448954   -0.220101      0.017473    -0.162867      0.114331    0.0297999    0.143281     -0.156591     0.11124      0.0221699     0.150513    -0.0231169
 -0.0357776    -0.0641463   -0.0426594    0.0271075   -0.0758546    0.0796536    0.0364689    0.0787318     0.0448425   -0.0117397    0.152868    -0.1895       -0.262843      0.0991493   0.0043135    0.0504073    -0.039423    -0.0902941     0.0629675   0.0318156   -0.0566821    -0.11505      0.0012498   -0.0547541     0.0746545   -0.0383399
  0.0641021     0.0500752    0.102615    -0.13369     -0.141912    -0.0421761   -0.0375365   -0.0406455     0.0815554   -0.0228387   -0.125619    -0.0781635    -0.0396902     0.138005   -0.0447211    0.058537      0.0683702    0.0252402     0.117653   -0.0371792   -0.0842863    -0.0939084    0.0731559   -0.00767464   -0.0823539   -0.0757702
  0.0222492    -0.18698      0.331811     0.127185    -0.134704    -0.198026    -0.104988     0.0115859     0.169511     0.0593858    0.0165166    0.0384558     0.110205     -0.162565    0.145076     0.0192551    -0.0557002   -0.0758791    -0.123054    0.142353    -0.0465343    -0.0692021   -0.0728507   -0.0472501     0.0546113    0.0412744
 -0.0707451    -0.0739188    0.00295682   0.0488731   -0.131837     0.0507545   -0.0943967    0.0742924     0.051955     0.0438151   -0.00397796   0.0383581     0.0037031     0.115036   -0.0585901    0.0726434     0.0924301    0.0495152    -0.0842561  -0.0902444   -0.0392412    -0.124758    -0.0738959    0.0747616     0.168856     0.189369
 -0.0835449     0.0357687   -0.0119598    0.020267     0.0494936    0.077412     0.0814658   -0.0921682    -0.0608997   -0.0684113   -0.0597933    0.0895268     0.0872662     0.103577    0.134112     0.0332701     0.0622555   -0.057333     -0.120017    0.0689905    0.13743      -0.0900788   -0.0546399    0.0398452    -0.146647    -0.203507
 -0.0362708     0.0204837    0.016827     0.0585714   -0.0370034   -0.231255    -0.0616186   -0.104424     -0.1683      -0.0959748    0.0026618    0.0614097    -0.000202501   0.100094    0.0942057   -0.0707997     0.0571715    0.111478     -0.145539    0.134488    -0.0121654    -0.187436     0.13733      0.248591      0.0185895   -0.0253846
 -0.0945565    -0.0777514    0.0218744   -0.0300582   -0.0907428   -0.00695929  -0.0915652    0.0241977    -0.0574534    0.0629694   -0.104965    -0.00252651    0.0184073    -0.100142   -0.0675452   -0.000145607  -0.120891    -0.024812      0.0557211  -0.0546723    0.0335711     0.0752976   -0.0541826   -0.0467123    -0.023983     0.0361364[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│     12
│     18
│     21
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.092479
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      7
│     12
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.049472
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.018573
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      7
│     11
│      ⋮
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.062976
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      6
│      7
│     12
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.045185
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      5
│      7
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.038531
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.046332
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      7
│     12
│      ⋮
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.047226
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.029019
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      7
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.061005
┌ Info: EM with 100000 data points 10 iterations avll -1.061005
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0950892  -0.223727    -0.105321    -0.00230166   0.0452904    0.113541     0.168482    -0.148776     0.0221585   -0.21013     0.0349171   -0.0421707   -0.179101    -0.0569305   -0.046903    -0.117508     -0.0492288    0.0377193   -0.108313     0.20212    -0.106545    0.0368904   0.108163     0.012433     0.204045     0.0594909
 -0.0742626  -0.019591    -0.187849     0.0590143    0.0658925    0.029893    -0.0934478   -0.04949      0.156079     0.0578016   0.048123    -0.167773    -0.210309     0.0159626    0.0153709    0.000696647  -0.12761      0.0476496    0.0523812   -0.0699405   0.0930623   0.0587808   0.0860436   -0.126219    -0.106919     0.162039
 -0.0688497   0.124688    -0.0169049    0.0943892    0.0824119    0.0802747    0.0650973   -0.00205833  -0.0091994    0.149715   -0.111628     0.00326141  -0.15324     -0.093061     0.040019    -0.0147605     0.0445301    0.149676    -0.010944    -0.0699173   0.0841861  -0.207825    0.0212892   -0.0171534   -0.0120566   -0.314354
 -0.116091   -0.0781711    0.0883254    0.0283977    0.0346993    0.0883872    0.0244111    0.0346347   -0.0396117   -0.014246    0.0403866   -0.0557167   -0.09983     -0.0875705    0.0821596    0.0497885     0.0122792    0.172806    -0.109106    -0.0240264  -0.15646    -0.0927764   0.0304386   -0.19515     -0.00107866  -0.0826732
  0.0680896  -0.0967212    0.113794     0.0143652   -0.0154677   -0.115555    -0.0887355    0.0248983   -0.00957264   0.119427   -0.0254955   -0.0424144   -0.0585431   -0.174474     0.149946     0.10343       0.0103797    0.0335915   -0.0462472   -0.015964    0.0346271   0.0324847  -0.0214485   -0.0580855   -0.00854229   0.00813273
 -0.129273   -0.154231     0.00830315  -0.0234025    0.066199    -0.0737708   -0.0791634   -0.0810505    0.0217231   -0.116051    0.0896293    0.0198696   -0.0677059   -0.00362484  -0.105309    -0.140589     -0.0748449   -0.0781388   -0.0434032   -0.255736    0.092673   -0.0180907  -0.0785654   -0.0823467   -0.0969896    0.00645579
  0.0284299  -0.0117632    0.106692     0.225668    -0.143203    -0.131717    -0.0667626   -0.058993    -0.00240515   0.0406897  -0.0304621   -0.13126      0.109379     0.0526872    0.0956713   -0.149057      0.0399957   -0.0434605   -0.132643     0.0541757  -0.0159356  -0.0717061  -0.135235    -0.0331544   -0.123954     0.0836543
  0.0135645  -0.0301658    0.0542141    0.202524     0.0419825   -0.0452544    0.119154     0.0304345    0.106196     0.0695087  -0.02274      0.0480127   -0.00922139  -0.0771435   -0.148808    -0.101197      0.147027    -0.00274951   0.0137186   -0.137861   -0.0721023  -0.157373   -0.00378149  -0.0359278   -0.0190774   -0.0179228
 -0.127965    0.14486     -0.0942663   -0.130404    -0.0637889   -0.0949142    0.0782319   -0.0716951   -0.145471     0.150027   -0.10922      0.11161      0.0274338    0.0439166    0.0316384   -0.00353561    0.0910669    0.0818804   -0.137096    -0.0179752   0.141162    0.195022    0.0399091   -0.0878716    0.097035     0.13553
  0.108209   -0.0112585    0.109881    -0.0145204   -0.0254655   -0.010268    -0.143029     0.139659    -0.0870138    0.0144078   0.0304536   -0.0229854   -0.0795598    0.0270426   -0.047317     0.139064      0.136517     0.125303     0.00539017  -0.143734    0.0449356   0.146396   -0.0456464   -0.0611148   -0.0685211   -0.147184
 -0.0130127   0.102904    -0.0464805    0.0585091    0.205208     0.0577207    0.0329101   -0.0377877   -0.076531     0.0552239   0.0710349   -0.104255    -0.0677443    0.0482727   -0.00826243   0.0647259    -0.0966008   -0.0711878    0.197422     0.0821116  -0.0531315  -0.0162703  -0.105343     0.0139868   -0.043677     0.142562
  0.0650954  -0.051785    -0.0171209   -0.169829    -0.0817227    0.0950011    0.0138192    0.0336349    0.136326     0.0462128  -0.148325     0.0359282    0.0268104   -0.0283111   -0.00116402  -0.143139      0.0319806   -0.00329273  -0.0186313   -0.0273133   0.106751    0.0613847   0.0111036   -0.0970831    0.0785895   -0.0962875
  0.317107    0.119544     0.0148224   -0.0804852    0.239753     0.00348284   0.00301968   0.00106594   0.118533     0.129447    0.0701211   -0.0679399    0.0889762   -0.00331182  -0.0998422    0.0538512    -0.00750769  -0.0647754    0.0894425    0.104073    0.148464   -0.163168    0.256565     0.0467459    0.0266045    0.0201906
  0.0575267   0.00969795  -0.0197276   -0.0195387    0.0080859    0.0393526    0.00512854  -0.155497    -0.0677417    0.0759339  -0.0534567   -0.216219     0.0414213   -0.0634205   -0.111879     0.0111446     0.128222    -0.00565241  -0.086931     0.0464965  -0.0207856   0.0730644  -0.00339703   0.06818      0.0953625   -0.207569
 -0.0859753   0.18197     -0.0323017   -0.0637355   -0.0624815    0.0931026    0.186262     0.00367598  -0.140481     0.0300458   0.0335511   -0.0147024    0.0595541   -0.247857     0.10157     -0.0931355     0.0781538    0.170698    -0.0352706   -0.0406881   0.0214432  -0.0388477  -0.162915    -0.0389589    0.103715     0.168103
  0.008536    0.0526695    0.145577    -0.0881322    0.00966938  -0.041198    -0.0583326   -0.0638154   -0.0221886   -0.0527511   0.0678667    0.0456747   -0.0602189   -0.0831965    0.141909     0.0115407     0.0372477   -0.0213072   -0.0482937    0.102543    0.0417032  -0.0645101   0.243077     0.00232399   0.0693153   -0.00192132
  0.0915762  -0.0297662    0.0530618   -0.124525     0.235771    -0.0815624   -0.00441772   0.101538    -0.0634296    0.0908331  -0.0953316   -0.0822486    0.0239271    0.0313513   -0.10039      0.155555      0.225776    -0.109382    -0.0224339   -0.0791682   0.140005   -0.0786236  -0.104304    -0.0109707    0.0655017    0.111795
 -0.0212721   0.127596     0.16849      0.0730194    0.00232324   0.123547     0.0721644   -0.0819007    0.00595499   0.0318488  -0.0779348   -0.0447654    0.0455214   -0.194693    -0.00276257  -0.143135     -0.130689     0.218267     0.176972    -0.0377505   0.143159   -0.0817668   0.00958572   0.00127765   0.0914784    0.113581
  0.137433    0.00908673  -0.0660157    0.0511036   -0.0230961    0.0289457    0.207504    -0.0542836    0.0511281    0.189953   -0.17035     -0.0376091   -0.0634904    0.116909     0.0549348   -0.0382596    -0.15103     -0.190295    -0.113311     0.0597387  -0.0156567   0.0203851   0.0381004   -0.0630128   -0.0996735    0.088174
 -0.0325636  -0.056512    -0.0780325   -0.061518     0.0875093    0.0282851    0.0302723    0.0305348   -0.123013     0.098778    0.113987     0.133673    -0.0781156   -0.0217568    0.0406616   -0.0876221     0.0321593    0.137284     0.0235946   -0.0213231   0.0803651  -0.124072    0.0231784   -0.124475    -0.211165    -0.0299751
 -0.062017   -0.0494645    0.0657355    0.0532455    0.0768728   -0.0376086    0.0472406   -0.0333019   -0.155478    -0.0718596   0.0723575    0.105908    -0.133392    -0.0211875    0.0785753   -0.0552957     0.0410581   -0.0946862   -0.0827634    0.109722    0.148543    0.274903    0.0153519   -0.0436721    0.0693172    0.0805404
  0.0206975   0.0122359    0.0837726    0.00762848  -0.140111     0.0341488   -0.00988693   0.162202     0.199748    -0.118303    0.0082019   -0.110282     0.288336    -0.117135    -0.0342825   -0.189546      0.0417195    0.155062     0.0118548   -0.0383527   0.0409501   0.0811894  -0.00098462  -0.00944955   0.103099     0.0201422
  0.031417   -0.186755    -0.105674    -0.0133869   -0.0972481    0.0412545   -0.0124196    0.168753    -0.100292     0.066167   -0.00705341   0.0998479    0.0170802   -0.120082     0.155589    -0.0177712     0.0976088   -0.00180742  -0.0228614   -0.0442137  -0.14774    -0.0831572   0.148299     0.027786    -0.0195645   -0.194883
  0.0291059   0.0792895   -0.166907     0.184309    -0.0407681   -0.104865     0.0856784    0.00112194  -0.108799    -0.0184709  -0.0340449    0.134444     0.0313301   -0.0730568    0.0384704    0.0530757    -0.0908617   -0.0958846    0.151374     0.210591   -0.0941484   0.108793   -0.00609951   0.0172853    0.0276758   -0.0319871
  0.0970947   0.00277377  -0.152485     0.0338594   -0.00668641   0.0837194    0.174296     0.00794084  -0.0143054    0.120608    0.0192073   -0.1524      -0.0281624   -0.104828    -0.124549    -0.028211     -0.00890741  -0.0188762   -0.146342     0.216884    0.0952343  -0.0112627   0.00780952   0.102612    -0.0908086   -0.0298811
 -0.0879535  -0.0711495    0.00325681   0.0238491    0.120304     0.0957194   -0.115042     0.056878     0.0820371   -0.109322   -0.065456    -0.0257213   -0.055807    -0.0641674   -0.0359793    0.183815     -0.22602      0.0546854    0.11207     -0.0191605   0.0981858  -0.13666    -0.112177     0.118682    -0.117631     0.0903384
 -0.0257981   0.0169018   -0.0606762    0.0455287   -0.0908203    0.0982378   -0.0258089    0.246602     0.0019581    0.0991727  -0.0439405   -0.0231579   -0.0313493   -0.0404241   -0.241353     0.0418894     0.0150035    0.052776    -0.0463382    0.0189242  -0.150863   -0.186195   -0.100107    -0.0848667   -0.0478166    0.0187646
 -0.091858    0.136201    -0.102445    -0.193646     0.129694     0.0880993    0.0554106   -0.0709074    0.0803336    0.0437987  -0.0112617    0.342532     0.0466885    0.054177     0.0545399   -0.0562403     0.0130511   -0.100629     0.0929857   -0.0021296   0.0264417   0.0241516  -0.00448231   0.137239     0.027695    -0.17303
 -0.0838448   0.124198    -0.0448021   -0.0130424   -0.0832974   -0.143776    -0.0944347   -0.089449    -0.0585827    0.011792    0.154438    -0.0320777   -0.0213545    0.148034    -0.029507    -0.00645876   -0.0622963    0.0162115   -0.00441344   0.0694998   0.147781    0.0527282   0.0723406    0.100407     0.105027     0.0781923
  0.0399844  -0.0612403   -0.135385     0.0834408   -0.0347547   -0.0254657    0.0394907   -0.164697    -0.0462944    0.0488609  -0.0610096    0.131883     0.0577962   -0.122804     0.216123    -0.126865      0.0753808   -0.0405136    0.1943       0.0943569  -0.0697645  -0.0807013  -0.133483     0.00524538   0.034323    -0.0761754
 -0.0364647   0.0693185   -0.182367     0.111173    -0.0651498   -0.0432673    0.00208991  -0.0875229    0.0288121   -0.0790499   0.11315      0.146097     0.126671     0.207336     0.103752    -0.0191206     0.0619853    0.153822    -0.066621    -0.0210243  -0.0500367  -0.0780417   0.0444415   -0.0546478   -0.110033     0.259324
 -0.0775207   0.268375    -0.0926976   -0.0573814   -0.067929    -0.0330977    0.0515273    0.169004    -0.0496107   -0.230329    0.072924    -0.0126388   -0.0621052   -0.0349317    0.0200756    0.059259     -0.0580211   -0.218851    -0.00360854  -0.0921295   0.0354717  -0.0520882   0.134304    -0.084822    -0.0758697   -0.0317847kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4250259226818494
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425047
[ Info: iteration 2, average log likelihood -1.424976
[ Info: iteration 3, average log likelihood -1.424932
[ Info: iteration 4, average log likelihood -1.424884
[ Info: iteration 5, average log likelihood -1.424828
[ Info: iteration 6, average log likelihood -1.424761
[ Info: iteration 7, average log likelihood -1.424677
[ Info: iteration 8, average log likelihood -1.424557
[ Info: iteration 9, average log likelihood -1.424347
[ Info: iteration 10, average log likelihood -1.423933
[ Info: iteration 11, average log likelihood -1.423155
[ Info: iteration 12, average log likelihood -1.421986
[ Info: iteration 13, average log likelihood -1.420781
[ Info: iteration 14, average log likelihood -1.419985
[ Info: iteration 15, average log likelihood -1.419620
[ Info: iteration 16, average log likelihood -1.419481
[ Info: iteration 17, average log likelihood -1.419431
[ Info: iteration 18, average log likelihood -1.419412
[ Info: iteration 19, average log likelihood -1.419405
[ Info: iteration 20, average log likelihood -1.419402
[ Info: iteration 21, average log likelihood -1.419400
[ Info: iteration 22, average log likelihood -1.419400
[ Info: iteration 23, average log likelihood -1.419399
[ Info: iteration 24, average log likelihood -1.419399
[ Info: iteration 25, average log likelihood -1.419399
[ Info: iteration 26, average log likelihood -1.419399
[ Info: iteration 27, average log likelihood -1.419398
[ Info: iteration 28, average log likelihood -1.419398
[ Info: iteration 29, average log likelihood -1.419398
[ Info: iteration 30, average log likelihood -1.419398
[ Info: iteration 31, average log likelihood -1.419398
[ Info: iteration 32, average log likelihood -1.419398
[ Info: iteration 33, average log likelihood -1.419398
[ Info: iteration 34, average log likelihood -1.419398
[ Info: iteration 35, average log likelihood -1.419398
[ Info: iteration 36, average log likelihood -1.419397
[ Info: iteration 37, average log likelihood -1.419397
[ Info: iteration 38, average log likelihood -1.419397
[ Info: iteration 39, average log likelihood -1.419397
[ Info: iteration 40, average log likelihood -1.419397
[ Info: iteration 41, average log likelihood -1.419397
[ Info: iteration 42, average log likelihood -1.419397
[ Info: iteration 43, average log likelihood -1.419397
[ Info: iteration 44, average log likelihood -1.419397
[ Info: iteration 45, average log likelihood -1.419397
[ Info: iteration 46, average log likelihood -1.419397
[ Info: iteration 47, average log likelihood -1.419397
[ Info: iteration 48, average log likelihood -1.419397
[ Info: iteration 49, average log likelihood -1.419397
[ Info: iteration 50, average log likelihood -1.419397
┌ Info: EM with 100000 data points 50 iterations avll -1.419397
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4250468860170622
│     -1.4249763773985102
│      ⋮
└     -1.4193970619197596
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419418
[ Info: iteration 2, average log likelihood -1.419344
[ Info: iteration 3, average log likelihood -1.419296
[ Info: iteration 4, average log likelihood -1.419243
[ Info: iteration 5, average log likelihood -1.419184
[ Info: iteration 6, average log likelihood -1.419117
[ Info: iteration 7, average log likelihood -1.419046
[ Info: iteration 8, average log likelihood -1.418976
[ Info: iteration 9, average log likelihood -1.418912
[ Info: iteration 10, average log likelihood -1.418855
[ Info: iteration 11, average log likelihood -1.418804
[ Info: iteration 12, average log likelihood -1.418759
[ Info: iteration 13, average log likelihood -1.418717
[ Info: iteration 14, average log likelihood -1.418675
[ Info: iteration 15, average log likelihood -1.418634
[ Info: iteration 16, average log likelihood -1.418591
[ Info: iteration 17, average log likelihood -1.418546
[ Info: iteration 18, average log likelihood -1.418499
[ Info: iteration 19, average log likelihood -1.418451
[ Info: iteration 20, average log likelihood -1.418404
[ Info: iteration 21, average log likelihood -1.418358
[ Info: iteration 22, average log likelihood -1.418315
[ Info: iteration 23, average log likelihood -1.418276
[ Info: iteration 24, average log likelihood -1.418241
[ Info: iteration 25, average log likelihood -1.418211
[ Info: iteration 26, average log likelihood -1.418186
[ Info: iteration 27, average log likelihood -1.418164
[ Info: iteration 28, average log likelihood -1.418146
[ Info: iteration 29, average log likelihood -1.418130
[ Info: iteration 30, average log likelihood -1.418117
[ Info: iteration 31, average log likelihood -1.418106
[ Info: iteration 32, average log likelihood -1.418097
[ Info: iteration 33, average log likelihood -1.418088
[ Info: iteration 34, average log likelihood -1.418081
[ Info: iteration 35, average log likelihood -1.418075
[ Info: iteration 36, average log likelihood -1.418069
[ Info: iteration 37, average log likelihood -1.418064
[ Info: iteration 38, average log likelihood -1.418059
[ Info: iteration 39, average log likelihood -1.418055
[ Info: iteration 40, average log likelihood -1.418052
[ Info: iteration 41, average log likelihood -1.418048
[ Info: iteration 42, average log likelihood -1.418045
[ Info: iteration 43, average log likelihood -1.418042
[ Info: iteration 44, average log likelihood -1.418040
[ Info: iteration 45, average log likelihood -1.418037
[ Info: iteration 46, average log likelihood -1.418035
[ Info: iteration 47, average log likelihood -1.418033
[ Info: iteration 48, average log likelihood -1.418031
[ Info: iteration 49, average log likelihood -1.418030
[ Info: iteration 50, average log likelihood -1.418028
┌ Info: EM with 100000 data points 50 iterations avll -1.418028
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4194177493636424
│     -1.4193436754863604
│      ⋮
└     -1.4180280727781474
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418046
[ Info: iteration 2, average log likelihood -1.417972
[ Info: iteration 3, average log likelihood -1.417922
[ Info: iteration 4, average log likelihood -1.417867
[ Info: iteration 5, average log likelihood -1.417803
[ Info: iteration 6, average log likelihood -1.417731
[ Info: iteration 7, average log likelihood -1.417653
[ Info: iteration 8, average log likelihood -1.417577
[ Info: iteration 9, average log likelihood -1.417506
[ Info: iteration 10, average log likelihood -1.417444
[ Info: iteration 11, average log likelihood -1.417390
[ Info: iteration 12, average log likelihood -1.417343
[ Info: iteration 13, average log likelihood -1.417301
[ Info: iteration 14, average log likelihood -1.417263
[ Info: iteration 15, average log likelihood -1.417227
[ Info: iteration 16, average log likelihood -1.417194
[ Info: iteration 17, average log likelihood -1.417163
[ Info: iteration 18, average log likelihood -1.417134
[ Info: iteration 19, average log likelihood -1.417106
[ Info: iteration 20, average log likelihood -1.417081
[ Info: iteration 21, average log likelihood -1.417056
[ Info: iteration 22, average log likelihood -1.417033
[ Info: iteration 23, average log likelihood -1.417010
[ Info: iteration 24, average log likelihood -1.416989
[ Info: iteration 25, average log likelihood -1.416968
[ Info: iteration 26, average log likelihood -1.416948
[ Info: iteration 27, average log likelihood -1.416929
[ Info: iteration 28, average log likelihood -1.416910
[ Info: iteration 29, average log likelihood -1.416891
[ Info: iteration 30, average log likelihood -1.416873
[ Info: iteration 31, average log likelihood -1.416855
[ Info: iteration 32, average log likelihood -1.416837
[ Info: iteration 33, average log likelihood -1.416820
[ Info: iteration 34, average log likelihood -1.416803
[ Info: iteration 35, average log likelihood -1.416787
[ Info: iteration 36, average log likelihood -1.416771
[ Info: iteration 37, average log likelihood -1.416756
[ Info: iteration 38, average log likelihood -1.416741
[ Info: iteration 39, average log likelihood -1.416727
[ Info: iteration 40, average log likelihood -1.416714
[ Info: iteration 41, average log likelihood -1.416702
[ Info: iteration 42, average log likelihood -1.416690
[ Info: iteration 43, average log likelihood -1.416679
[ Info: iteration 44, average log likelihood -1.416669
[ Info: iteration 45, average log likelihood -1.416660
[ Info: iteration 46, average log likelihood -1.416651
[ Info: iteration 47, average log likelihood -1.416643
[ Info: iteration 48, average log likelihood -1.416636
[ Info: iteration 49, average log likelihood -1.416629
[ Info: iteration 50, average log likelihood -1.416622
┌ Info: EM with 100000 data points 50 iterations avll -1.416622
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4180461013153063
│     -1.4179723218117462
│      ⋮
└     -1.4166223305406445
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416626
[ Info: iteration 2, average log likelihood -1.416555
[ Info: iteration 3, average log likelihood -1.416491
[ Info: iteration 4, average log likelihood -1.416418
[ Info: iteration 5, average log likelihood -1.416329
[ Info: iteration 6, average log likelihood -1.416224
[ Info: iteration 7, average log likelihood -1.416106
[ Info: iteration 8, average log likelihood -1.415983
[ Info: iteration 9, average log likelihood -1.415863
[ Info: iteration 10, average log likelihood -1.415751
[ Info: iteration 11, average log likelihood -1.415647
[ Info: iteration 12, average log likelihood -1.415552
[ Info: iteration 13, average log likelihood -1.415466
[ Info: iteration 14, average log likelihood -1.415388
[ Info: iteration 15, average log likelihood -1.415318
[ Info: iteration 16, average log likelihood -1.415255
[ Info: iteration 17, average log likelihood -1.415200
[ Info: iteration 18, average log likelihood -1.415151
[ Info: iteration 19, average log likelihood -1.415108
[ Info: iteration 20, average log likelihood -1.415069
[ Info: iteration 21, average log likelihood -1.415033
[ Info: iteration 22, average log likelihood -1.415001
[ Info: iteration 23, average log likelihood -1.414971
[ Info: iteration 24, average log likelihood -1.414944
[ Info: iteration 25, average log likelihood -1.414918
[ Info: iteration 26, average log likelihood -1.414893
[ Info: iteration 27, average log likelihood -1.414870
[ Info: iteration 28, average log likelihood -1.414848
[ Info: iteration 29, average log likelihood -1.414827
[ Info: iteration 30, average log likelihood -1.414807
[ Info: iteration 31, average log likelihood -1.414788
[ Info: iteration 32, average log likelihood -1.414770
[ Info: iteration 33, average log likelihood -1.414752
[ Info: iteration 34, average log likelihood -1.414735
[ Info: iteration 35, average log likelihood -1.414719
[ Info: iteration 36, average log likelihood -1.414703
[ Info: iteration 37, average log likelihood -1.414688
[ Info: iteration 38, average log likelihood -1.414674
[ Info: iteration 39, average log likelihood -1.414660
[ Info: iteration 40, average log likelihood -1.414646
[ Info: iteration 41, average log likelihood -1.414633
[ Info: iteration 42, average log likelihood -1.414620
[ Info: iteration 43, average log likelihood -1.414608
[ Info: iteration 44, average log likelihood -1.414595
[ Info: iteration 45, average log likelihood -1.414583
[ Info: iteration 46, average log likelihood -1.414572
[ Info: iteration 47, average log likelihood -1.414560
[ Info: iteration 48, average log likelihood -1.414549
[ Info: iteration 49, average log likelihood -1.414538
[ Info: iteration 50, average log likelihood -1.414527
┌ Info: EM with 100000 data points 50 iterations avll -1.414527
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.416626167867113
│     -1.4165550216603948
│      ⋮
└     -1.4145268582063912
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414524
[ Info: iteration 2, average log likelihood -1.414459
[ Info: iteration 3, average log likelihood -1.414399
[ Info: iteration 4, average log likelihood -1.414330
[ Info: iteration 5, average log likelihood -1.414244
[ Info: iteration 6, average log likelihood -1.414136
[ Info: iteration 7, average log likelihood -1.414005
[ Info: iteration 8, average log likelihood -1.413853
[ Info: iteration 9, average log likelihood -1.413689
[ Info: iteration 10, average log likelihood -1.413523
[ Info: iteration 11, average log likelihood -1.413364
[ Info: iteration 12, average log likelihood -1.413217
[ Info: iteration 13, average log likelihood -1.413086
[ Info: iteration 14, average log likelihood -1.412968
[ Info: iteration 15, average log likelihood -1.412863
[ Info: iteration 16, average log likelihood -1.412770
[ Info: iteration 17, average log likelihood -1.412686
[ Info: iteration 18, average log likelihood -1.412610
[ Info: iteration 19, average log likelihood -1.412541
[ Info: iteration 20, average log likelihood -1.412478
[ Info: iteration 21, average log likelihood -1.412420
[ Info: iteration 22, average log likelihood -1.412367
[ Info: iteration 23, average log likelihood -1.412317
[ Info: iteration 24, average log likelihood -1.412270
[ Info: iteration 25, average log likelihood -1.412227
[ Info: iteration 26, average log likelihood -1.412185
[ Info: iteration 27, average log likelihood -1.412146
[ Info: iteration 28, average log likelihood -1.412109
[ Info: iteration 29, average log likelihood -1.412074
[ Info: iteration 30, average log likelihood -1.412041
[ Info: iteration 31, average log likelihood -1.412009
[ Info: iteration 32, average log likelihood -1.411979
[ Info: iteration 33, average log likelihood -1.411950
[ Info: iteration 34, average log likelihood -1.411923
[ Info: iteration 35, average log likelihood -1.411896
[ Info: iteration 36, average log likelihood -1.411871
[ Info: iteration 37, average log likelihood -1.411846
[ Info: iteration 38, average log likelihood -1.411823
[ Info: iteration 39, average log likelihood -1.411800
[ Info: iteration 40, average log likelihood -1.411778
[ Info: iteration 41, average log likelihood -1.411757
[ Info: iteration 42, average log likelihood -1.411737
[ Info: iteration 43, average log likelihood -1.411717
[ Info: iteration 44, average log likelihood -1.411698
[ Info: iteration 45, average log likelihood -1.411680
[ Info: iteration 46, average log likelihood -1.411662
[ Info: iteration 47, average log likelihood -1.411644
[ Info: iteration 48, average log likelihood -1.411627
[ Info: iteration 49, average log likelihood -1.411611
[ Info: iteration 50, average log likelihood -1.411594
┌ Info: EM with 100000 data points 50 iterations avll -1.411594
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4145244115207831
│     -1.4144591268654068
│      ⋮
└     -1.4115943114963023
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4250259226818494
│     -1.4250468860170622
│     -1.4249763773985102
│     -1.424931567492079
│      ⋮
│     -1.4116271692220275
│     -1.4116105565874268
└     -1.4115943114963023
32×26 Array{Float64,2}:
 -0.154831    0.0897382    0.0310345     0.119315    0.263603    0.170311    0.208411   -0.800122   -0.223411    -0.132418      0.296934    -0.00732132  -0.14563     -0.0320765     0.309458    0.192902     -0.420556   -0.0465105   -0.567335     0.417846     0.357711    0.0380427   0.607905   -0.0885023    0.538458     0.018059
 -0.0108688  -0.0979629    0.367222      0.0666715   0.0876254  -0.160662    0.180506   -0.630568    0.156176     0.205867      0.47107      0.122012     0.289523     0.456834      0.0517468  -0.423483     -0.467158    0.238996    -0.421197     0.776629    -0.0970418  -0.13167    -0.208776   -0.172376     0.147757     0.418094
  0.305383    0.563603     0.407882      0.196879   -0.160191    0.113318    0.67002     0.35074    -0.441235     0.128122     -0.100065     0.639673     0.544954    -0.135709     -0.230065    0.103247      0.27522     0.123063    -0.0991846    0.159436     0.401178   -0.287761    0.113059   -0.359551     0.0501543    0.0246071
  0.152714    0.459365     0.151008      0.432355    0.0280744   0.447743    0.0362944   0.0954887  -0.666955    -0.0784036    -0.442914     0.325288     0.0569198   -0.204483     -0.0300538  -0.013969     -0.382802   -0.285015     0.218713     0.484965     0.363486   -0.648411   -0.447139    0.878043     0.00594142   0.172105
 -0.321035   -0.0223765    0.316465     -0.0194355  -0.342899    0.175569    0.0643356  -0.250684    0.286559    -0.261663     -0.214237    -0.613499     0.289869     0.0476628    -0.640588    0.50181      -0.10767    -0.313448    -0.256638    -0.0482432    0.333359    0.151795   -0.0369789  -0.109622    -0.28941      0.165484
  0.16398     0.517359    -0.349222     -0.245895    0.177255    0.448897    0.0100784   0.0989175   0.243734    -0.417994      0.0848559   -0.278677    -0.608154    -0.0435112    -0.462983   -0.00581614   -0.072559   -0.0163844    0.0257267    0.0693017    0.242546    0.0760305  -0.636536    0.368929    -0.0431565   -0.0468847
 -0.214549   -0.0220865   -0.219954     -0.0947961   0.262186    0.116036    0.128426    0.19471     0.555255     0.255951     -0.0873867    0.170189    -0.0190907    0.377134     -0.0993488  -0.0995142     0.0877124   0.0672794   -0.0970126   -0.278041     0.328173    0.116638   -0.164133   -0.416676     0.0438067   -0.270019
 -0.014771    0.092839    -0.127842     -0.131151   -0.015922    0.0239119  -0.0217185  -0.15638     0.0529336    0.000238958  -0.0640435    0.0415091   -0.00840358  -0.0230055    -0.0372633  -0.0220149     0.0339973  -0.0154154    0.0652337    0.215328     0.174245    0.110672    0.113781   -0.0708769    0.0594064    0.217749
 -0.182042   -0.457098    -0.556906     -0.55917    -0.143416   -0.252544   -0.500477   -0.160524    0.493708     0.366078      0.37383     -0.377398    -0.502194    -0.439041      0.196133   -0.220091      0.105037    0.0696386   -0.169085    -0.171179    -0.680712    0.167104    0.107093   -0.141143    -0.416924     0.150338
 -0.642492   -0.0582852   -0.597548     -0.515202   -0.295124    0.0663641   0.333853    0.188321   -0.0449049   -0.585379     -0.156498    -0.701796    -0.201705    -0.423692      0.328396    0.296926     -0.169031   -0.134598     0.00164363  -0.150994    -0.4344      0.0555134   0.0675882  -0.355236     0.136349    -0.648244
  0.236542    0.122816    -0.062286      0.0216417   0.270754    0.0379109   0.0261195  -0.329397   -0.310011     0.814927      0.0588313    0.859488    -0.0291      -0.00706587    0.491923   -0.357264     -0.0709129  -0.0359646    0.245586     0.0119282   -0.75097    -0.391616    0.186976   -0.0643943    0.00293812  -0.764166
  0.143983   -0.129224    -0.0979519    -0.144612   -0.404986    0.204587   -0.17413    -0.130009   -0.451529     0.0431078     0.0474912    0.676866     0.0364596   -0.0734242     0.0232351   0.0215625    -0.11618     0.340505     0.0822779   -0.12659     -0.551688   -0.0273694   0.145717    0.00398233  -0.481938    -0.0289032
 -0.037174   -0.732766     0.195997      0.503674    0.333899   -0.27225    -0.365322   -0.472605    0.110655    -0.108722      0.0115325   -0.37375     -0.132221     0.559541      0.546038   -0.209634     -0.028921    0.154764     0.152991    -0.156807    -0.165973    0.506241   -0.124586    0.105468     0.0999508   -0.098769
  0.347916   -0.189778     0.201199      0.187168    0.097044   -0.418431   -0.344986    0.592476   -0.0714439    0.0987532     0.259317    -0.167855    -0.383264     0.000438827   0.297667    0.094611     -0.119127   -0.125041    -0.207779    -0.187536     0.344292   -0.0346747   0.0626032  -0.380757     0.290204     0.0532357
  0.0508534  -0.112887     0.276795      0.282728   -0.0357325  -0.0381438   0.0701201   0.0269451  -0.380917     0.0726167    -0.00514282  -0.0841205    0.0502479   -0.129794      0.177204   -0.141683      0.0303209  -0.052345     0.0621318   -0.163556    -0.270999   -0.264917    0.0765777   0.191554    -0.0431512   -0.23911
  0.144444    0.181672    -0.097265      0.233306    0.424654   -0.30771     0.413204    0.471344    0.256827     0.132083     -0.0951387   -0.362552    -0.0336358   -0.303909     -0.0107958  -0.223293      0.299702    0.246252     0.2506       0.0342852   -0.359925   -0.551611   -0.238146    0.282411    -0.128292    -0.0330177
 -0.805919   -0.463411     0.377098      0.0989388   0.0218263  -0.173646    0.245073   -0.349721    0.320163     0.422821     -0.146147     0.20595      0.186779     0.533924      0.384922   -0.000613105  -0.298235   -0.0696539   -0.285993     0.318565     0.0598827   0.101271   -0.0502305  -0.032734    -0.00752972  -0.12617
  0.332206    0.27506     -0.0770716     0.0540024  -0.03258     0.0823155  -0.0690792   0.0532475  -0.126936    -0.188623      0.315614    -0.0489523   -0.193826    -0.27084      -0.130817    0.0501032    -0.0344575   0.18202      0.0038292    0.010172    -0.0853308  -0.235573   -0.0986641  -0.015672     0.110249     0.0156884
 -1.0924      0.23016     -0.270979     -0.640431   -0.137272   -0.086248   -0.225131   -0.53276     0.345732     0.3109       -0.0108029    1.03014      0.385437     0.368117     -0.0339913   0.133707     -0.115876    0.189109     0.415407     0.331193     0.483066    0.115029   -0.140561   -0.0428776    0.0433309    0.213854
  0.173282   -0.287357    -0.0952195    -0.252626   -0.0841238   0.145201   -0.459058    0.305966    9.33766e-5  -0.0873559     0.184614     0.638462    -0.284553     0.942626     -0.0717071   0.131514     -0.890365   -0.0260109    0.0656319    0.193531     0.675825    0.528658    0.163      -0.144445    -0.0915134    0.560776
  0.384601   -0.462642     0.473642      0.634787    0.0338135  -0.224953   -0.0130913   0.248234   -1.09441      0.219152     -0.362579    -0.422575     0.718213    -0.0770806     0.450707   -0.310239      0.027701   -0.318957     0.10851      0.00597855  -0.381244    0.0360986   0.70577    -0.036231     0.210556     0.288377
 -0.668188   -0.512338     0.517554      0.25181    -0.386961   -0.648938   -0.430404    0.47022     0.0539944    0.175918      0.1147       0.136325     0.632417    -0.15539       0.197691    0.0375406    -0.0465948   0.276836     0.43404     -0.212885    -0.279718   -0.749908   -0.205429   -0.35514      0.0928958    0.197929
 -0.210093    0.144017    -0.177763      0.117884    0.353795    0.146959    0.68974     0.229569    0.437221    -0.40392      -0.704134     0.166997     0.444563    -0.0960169     0.487642    0.367044      0.788786   -0.00383302   0.183819     0.227732     0.492878   -0.14069     0.0482879  -0.0677385    0.448144     0.674483
 -0.105373   -0.747304    -0.0623206     0.334979    0.822686   -0.338361    0.251583    0.222011    0.65243      1.06721      -0.691342    -0.0364187    0.342985     0.225265      1.09094     0.243193      0.685629    0.119055    -0.549541    -0.119563     0.336078   -0.553539   -0.55133     0.898519     0.185571     0.0522142
 -0.458287    0.0588585    0.128675      0.11235     0.371566   -0.455982   -0.0270765   0.0153662  -0.0270404    0.306863      0.0172843   -0.657967    -0.42466     -0.417144     -0.156314   -0.18729      -0.0772118  -0.695178     0.178121     0.282756     0.365298   -0.350375   -0.35641     0.215223     0.064501    -0.603968
 -0.82001    -0.276394    -0.608483     -0.0638409   0.0482609   0.0461541  -0.096641    0.316016    0.242781    -0.37169      -0.181144    -0.467792     0.205949    -0.0749167    -0.608269   -0.414877      0.0804126  -0.448761     0.518103     0.0408493    0.97541     0.257046    0.168814    0.476719    -0.11174      0.827849
  0.234739    0.48969     -0.501647      0.279955    0.573946    0.175565   -0.232616   -0.240537   -0.5867      -0.262437      0.255958    -0.500131     0.0272967   -0.560604     -0.116801    0.129407      0.209115    0.00963428   0.0286566   -0.748183    -0.904768   -0.261116   -0.378863    0.00124281   0.0444626   -0.450214
  0.796849   -0.110563    -0.559468      0.143663    0.447539    0.617709    0.164234    0.26161    -0.0431487    0.0588734    -0.67332     -0.13391     -0.333015     0.123029      0.207796   -0.218178      0.754056   -0.661984     0.215659    -0.43644     -0.0638674   0.613587    0.0769433   0.301872    -0.29226     -0.297294
  0.659636    0.619421     0.0396216    -0.36845    -0.371504    0.0611017  -0.369654   -0.167832   -0.720291    -0.270415      0.538293    -0.109014    -0.244873    -0.390629     -0.93497    -0.334987     -0.243071   -0.255044     0.404083     0.0194047   -0.122795    0.161464    0.696597   -0.528797     0.137013     0.148406
  0.545108    0.191713     0.15339      -0.246407   -0.20742    -0.0306431   0.273942   -0.0564411  -0.365662    -0.722911     -0.193618    -0.411394    -0.421067    -0.485982     -0.439278    0.227029      0.744368    0.750818    -0.0892428   -0.397264     0.0263905   0.48947     0.551432    0.444313    -0.213947    -0.0203438
  0.273118    1.03551     -0.221934     -0.286107   -0.427231    0.134567    0.312717   -0.163555    0.452616     0.249009      0.0987297    0.489884    -0.619497    -0.365228     -0.593334    0.258091      0.138892    0.0660408   -0.811493     0.160495     0.862261    0.502307    0.0690663  -0.0591575   -0.470907    -0.292355
  0.340945   -0.00244882  -0.000954768  -0.368063   -0.604037    0.232634    0.177663    0.560867    0.667971    -0.158131     -0.124923     0.2759       0.515248    -0.0390997    -0.12576    -0.0306112     0.600758    0.910187    -0.15468     -0.497942    -0.121736    0.200736    0.0191961  -0.52684      0.0141683    0.4452[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411578
[ Info: iteration 2, average log likelihood -1.411563
[ Info: iteration 3, average log likelihood -1.411547
[ Info: iteration 4, average log likelihood -1.411532
[ Info: iteration 5, average log likelihood -1.411517
[ Info: iteration 6, average log likelihood -1.411503
[ Info: iteration 7, average log likelihood -1.411488
[ Info: iteration 8, average log likelihood -1.411474
[ Info: iteration 9, average log likelihood -1.411460
[ Info: iteration 10, average log likelihood -1.411446
┌ Info: EM with 100000 data points 10 iterations avll -1.411446
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.149421e+05
      1       7.090985e+05      -2.058436e+05 |       32
      2       6.954681e+05      -1.363031e+04 |       32
      3       6.894224e+05      -6.045744e+03 |       32
      4       6.863683e+05      -3.054096e+03 |       32
      5       6.845693e+05      -1.799033e+03 |       32
      6       6.832655e+05      -1.303746e+03 |       32
      7       6.822822e+05      -9.832792e+02 |       32
      8       6.814820e+05      -8.002106e+02 |       32
      9       6.808224e+05      -6.596886e+02 |       32
     10       6.802843e+05      -5.380007e+02 |       32
     11       6.798009e+05      -4.834301e+02 |       32
     12       6.794155e+05      -3.853799e+02 |       32
     13       6.790695e+05      -3.460552e+02 |       32
     14       6.787679e+05      -3.016076e+02 |       32
     15       6.785061e+05      -2.618243e+02 |       32
     16       6.782556e+05      -2.504416e+02 |       32
     17       6.780498e+05      -2.057979e+02 |       32
     18       6.778594e+05      -1.904446e+02 |       32
     19       6.776819e+05      -1.774708e+02 |       32
     20       6.775142e+05      -1.676727e+02 |       32
     21       6.773646e+05      -1.495971e+02 |       32
     22       6.772187e+05      -1.459276e+02 |       32
     23       6.770619e+05      -1.567587e+02 |       32
     24       6.769009e+05      -1.610909e+02 |       32
     25       6.767652e+05      -1.356669e+02 |       32
     26       6.766295e+05      -1.356740e+02 |       32
     27       6.765005e+05      -1.289859e+02 |       32
     28       6.763977e+05      -1.028454e+02 |       32
     29       6.762836e+05      -1.141012e+02 |       32
     30       6.761724e+05      -1.111767e+02 |       32
     31       6.760737e+05      -9.867903e+01 |       32
     32       6.759766e+05      -9.715811e+01 |       32
     33       6.758819e+05      -9.463869e+01 |       32
     34       6.758026e+05      -7.934270e+01 |       32
     35       6.757283e+05      -7.424587e+01 |       32
     36       6.756506e+05      -7.776499e+01 |       32
     37       6.755820e+05      -6.860484e+01 |       32
     38       6.755175e+05      -6.448779e+01 |       32
     39       6.754623e+05      -5.521720e+01 |       32
     40       6.754101e+05      -5.211092e+01 |       32
     41       6.753556e+05      -5.457425e+01 |       32
     42       6.753085e+05      -4.707634e+01 |       32
     43       6.752680e+05      -4.048491e+01 |       32
     44       6.752366e+05      -3.138111e+01 |       32
     45       6.752008e+05      -3.588086e+01 |       32
     46       6.751601e+05      -4.062780e+01 |       32
     47       6.751245e+05      -3.564099e+01 |       32
     48       6.750908e+05      -3.365246e+01 |       32
     49       6.750623e+05      -2.848735e+01 |       32
     50       6.750335e+05      -2.881641e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 675033.5274234668)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423033
[ Info: iteration 2, average log likelihood -1.417984
[ Info: iteration 3, average log likelihood -1.416419
[ Info: iteration 4, average log likelihood -1.415188
[ Info: iteration 5, average log likelihood -1.414087
[ Info: iteration 6, average log likelihood -1.413294
[ Info: iteration 7, average log likelihood -1.412828
[ Info: iteration 8, average log likelihood -1.412560
[ Info: iteration 9, average log likelihood -1.412387
[ Info: iteration 10, average log likelihood -1.412258
[ Info: iteration 11, average log likelihood -1.412154
[ Info: iteration 12, average log likelihood -1.412066
[ Info: iteration 13, average log likelihood -1.411990
[ Info: iteration 14, average log likelihood -1.411922
[ Info: iteration 15, average log likelihood -1.411863
[ Info: iteration 16, average log likelihood -1.411810
[ Info: iteration 17, average log likelihood -1.411763
[ Info: iteration 18, average log likelihood -1.411720
[ Info: iteration 19, average log likelihood -1.411682
[ Info: iteration 20, average log likelihood -1.411647
[ Info: iteration 21, average log likelihood -1.411615
[ Info: iteration 22, average log likelihood -1.411587
[ Info: iteration 23, average log likelihood -1.411560
[ Info: iteration 24, average log likelihood -1.411535
[ Info: iteration 25, average log likelihood -1.411512
[ Info: iteration 26, average log likelihood -1.411491
[ Info: iteration 27, average log likelihood -1.411471
[ Info: iteration 28, average log likelihood -1.411452
[ Info: iteration 29, average log likelihood -1.411434
[ Info: iteration 30, average log likelihood -1.411417
[ Info: iteration 31, average log likelihood -1.411401
[ Info: iteration 32, average log likelihood -1.411386
[ Info: iteration 33, average log likelihood -1.411371
[ Info: iteration 34, average log likelihood -1.411357
[ Info: iteration 35, average log likelihood -1.411343
[ Info: iteration 36, average log likelihood -1.411330
[ Info: iteration 37, average log likelihood -1.411318
[ Info: iteration 38, average log likelihood -1.411305
[ Info: iteration 39, average log likelihood -1.411294
[ Info: iteration 40, average log likelihood -1.411282
[ Info: iteration 41, average log likelihood -1.411271
[ Info: iteration 42, average log likelihood -1.411261
[ Info: iteration 43, average log likelihood -1.411251
[ Info: iteration 44, average log likelihood -1.411241
[ Info: iteration 45, average log likelihood -1.411231
[ Info: iteration 46, average log likelihood -1.411222
[ Info: iteration 47, average log likelihood -1.411213
[ Info: iteration 48, average log likelihood -1.411204
[ Info: iteration 49, average log likelihood -1.411196
[ Info: iteration 50, average log likelihood -1.411188
┌ Info: EM with 100000 data points 50 iterations avll -1.411188
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.85335    -0.175419    0.468691     0.101713   -0.54469     -0.744395     -0.0988797   -0.0744179  -0.145867    0.138488     0.385622     0.193499    0.341777   -0.298993    0.150894    0.201724     -0.358563     0.202129     0.188576     0.193972   -0.172005   -0.782949    -0.137811   -0.323725   -0.0133033   -0.339012
  0.387476   -0.257975    0.0015218    0.106907   -0.00105103  -0.251914     -0.343732     0.538449   -0.232805    0.33712      0.782219     0.59089    -0.257117    0.436077   -0.0664244  -0.0509964    -0.697146    -0.0986398    0.332848     0.0129001   0.383457   -0.0606617    0.240155   -0.322075    0.0745632    0.201663
 -0.1967     -0.723294    0.0227988    0.225698    0.464982    -0.289876      0.496198     0.382359    0.582515    0.7362      -0.738674     0.142293    0.525985    0.118961    1.12787     0.351363      0.737959     0.100804    -0.322199     0.0239273   0.53562    -0.556183    -0.427893    0.607338    0.0328298    0.0193693
  0.135372   -0.158764   -0.201211    -0.240796   -0.196236     0.367476      0.0618788   -0.0857022  -0.345038    0.0771941   -0.28217      0.342234    0.140512   -0.061597   -0.0691039  -0.133121      0.306735     0.0765049    0.27992     -0.235147   -0.678027    0.117912     0.0543616   0.276586   -0.839839    -0.388988
 -0.571968   -0.366874   -0.67014     -0.658554   -0.245992    -0.117789     -0.104472     0.0140272   0.35199    -0.137367     0.178155    -0.814742   -0.398682   -0.403824    0.380772    0.0898223    -0.00244584  -0.0716457   -0.116114    -0.329779   -0.665884    0.159804     0.217755   -0.386433   -0.0536137   -0.359583
  0.111853    0.595842   -0.311163     0.413082    0.00983043   0.233845      0.173328     0.2631      0.345129   -0.562361    -0.522556     0.267408    0.462603   -0.62666     0.453965    0.306499      0.954313     0.511076     0.320321    -0.328767   -0.0490973  -0.24401      0.297347   -0.213291    0.780492     0.622686
 -1.03639     0.185103   -0.291082    -0.561859   -0.037104    -0.0766394    -0.0243861   -0.382441    0.506696    0.309151    -0.145615     0.938198    0.284412    0.442089   -0.0121282  -0.000356607  -0.0992356    0.0969553    0.317915     0.34807     0.546516    0.14736     -0.103802   -0.206505    0.105094     0.195452
  0.404814    0.105848    0.20238      0.113357    0.0878028    0.0164672    -0.0641418   -0.474121   -0.367998    0.379105     0.244097     0.697722   -0.0792462  -0.0937758   0.492887   -0.0173348    -0.0796211    0.313589    -0.0222389   -0.255889   -1.08001    -0.36338      0.0130133  -0.256144    0.035737    -0.605055
  0.39054    -0.0800798   0.20726      0.0217757  -0.336801    -0.0121563     0.218581     0.11886    -0.857019    0.215803    -0.0379739   -0.0656142   0.643106   -0.339838   -0.259859   -0.0495947     0.133076    -0.0579953    0.00853533   0.0100025  -0.499296   -0.143171     1.0873     -0.300176    0.516968     0.523451
 -0.251183    0.169538   -0.588067    -0.200991    0.187388     0.0310583     0.138024     0.839117   -0.0707033  -0.600033    -0.571764    -0.679562   -0.144185   -0.312042    0.147431   -0.125303      0.00046505  -0.635068     0.204013     0.201314    0.80332     0.33938     -0.197058    0.109383   -0.0053135    0.421059
 -0.227346    0.239463   -0.030614    -0.32169     0.505921    -0.09456      -0.214896     0.361293    0.940323    0.0112739    0.0639463   -0.269884   -0.565864    0.230739   -0.183861    0.137183      0.0373653   -0.151705    -0.12694      0.0238001   0.739483   -0.0434684   -1.05469    -0.107249   -0.16453     -0.492293
  0.448473   -0.056312   -0.0871968   -0.40639    -0.202497     0.0927098     0.305303     0.320866    0.129585   -0.806247    -0.0679328   -0.440753   -0.210266   -0.155301   -0.669254    0.0878723     0.825419     0.762726     0.0342159   -0.312189    0.306145    0.458354     0.271041    0.196512   -0.117479     0.280573
 -0.227313   -0.860481    0.244068     0.528698    0.708549    -0.314086     -0.22351     -0.310337   -0.430009    0.129366    -0.252431    -0.589808    0.326768    0.527391    0.876054   -0.467649     -0.150963    -0.191274     0.190828     0.0737379  -0.46817     0.0815543    0.0255041   0.225708    0.275122     0.0101911
 -0.0389634  -0.600492    0.308534    -0.120797   -0.750826    -0.156605     -0.448508     0.881342    0.525676    0.00621511  -0.035479     0.387968    0.523407    0.103782    0.170088   -0.147533      0.193545     0.754368     0.00228867  -0.378449   -0.22673    -0.029086    -0.378831   -0.284223   -0.0278608    0.762113
  0.493949   -0.156398   -0.463604     0.305824    0.761484     0.420774      0.166935     0.0726058   0.302147    0.483266    -0.515133     0.249302   -0.36955     0.483849    0.276647   -0.140061      0.599126    -0.466147     0.0632606   -0.531285    0.0408657   0.575698     0.105559    0.177851    0.0491458   -0.366245
 -1.3512     -0.811197   -0.4052       0.277894    0.110771     0.139934     -0.549265    -0.135372    0.16533    -0.0503243    0.141271    -0.0272998   0.548921   -0.174658   -0.839022   -0.286641     -0.0323383   -0.246019     1.29104     -0.218726    0.653662    0.0901113    0.201701    0.477607   -0.606164     0.739713
  0.40613     0.259129   -0.536159    -0.579446    0.0932952   -0.0611616    -0.506751    -0.577498    0.143336    0.0397444    0.366075     0.0420814  -0.331736   -0.113229   -0.286625   -0.103752     -0.0114322    0.0465371   -0.188004     0.162985   -0.0587926   0.469868     0.348629   -0.166012    0.0132143    0.517111
  0.0463774  -0.25424     0.326656     0.139202   -0.381305     0.26906      -0.233302    -0.470632    0.0207804  -0.296359    -0.036647     0.126483   -0.0384704   0.844225    0.035856    0.0453066    -0.594553     0.0778182   -0.419694     0.181276    0.311704    0.449297     0.0169683  -0.0284105  -0.0929344    0.328515
 -0.263649   -0.0350645   0.111059     0.244978    0.562539    -0.130614      0.462206    -0.550684    0.119874   -0.0121196    0.447364    -0.133375   -0.0836765   0.127448    0.307466   -0.116692     -0.28675     -0.0170662   -0.486448     0.595484    0.442071   -0.113799     0.243294   -0.19018     0.650377     0.0714999
  0.354812    0.147254   -0.221398     0.162821    0.204878     0.342951      0.127551     0.196644   -0.0690303  -0.215826     0.162744    -0.418798   -0.705446   -0.246425   -0.0967368  -0.116709     -0.0761546   -0.0833685    0.080797    -0.412177   -0.297322    0.0216095   -0.311304    0.346103    0.0180658   -0.358833
  0.410283   -0.102126    0.763595     0.652539    0.111335    -0.564591     -0.114059     0.412821   -0.405408    0.138668    -0.128823    -0.418441   -0.0555449  -0.435993    0.146111   -0.112179      0.141501    -0.105648    -0.10279     -0.0748867  -0.033501   -0.316165     0.0899126   0.114229   -0.0580254   -0.182752
 -0.358992    0.111827    0.292637     0.0763663  -0.0960525   -0.0165628     0.122779    -0.468603    0.456082   -0.203       -0.181872    -1.22538     0.29569    -0.151904   -0.727778    0.353139      0.195066    -0.449242    -0.225002     0.062924    0.210902   -0.00574986  -0.1185      0.196015   -0.196401     0.119525
  0.181317   -0.229384    0.755395    -0.454067   -0.425285     0.168622     -0.538999    -0.771748   -1.22378    -0.573335     0.498254     0.438445   -0.225872   -0.679356    0.680294    0.556738     -0.211577    -0.39126     -0.197523    -0.546457    0.612675    0.465548     0.930898   -0.219344    0.357757    -0.358222
  0.29555     0.571052    0.364167     0.442739    0.269271     0.476387      0.461602     0.306119   -0.645442   -0.144507    -0.360622     0.499281    0.481075    0.0729509  -0.208193   -0.0381136     0.00699317  -0.187441     0.258262     0.312319    0.549282   -0.510813    -0.369628    0.315983    0.185817     0.20616
 -0.0182845  -0.278986    0.0154213    0.122592    0.0967359   -0.280187      0.0193824    0.186983    0.137325    0.0829414   -0.00986806  -0.083865   -0.011128    0.173997    0.183648   -0.0713719     0.240929     0.0979632    0.138885    -0.213414   -0.0142942   0.036705     0.0718704  -0.188133    0.0993404    0.0187283
 -0.14859     0.164504   -0.0365973   -0.134955   -0.170117     0.297064      0.146058     0.10218     0.163629   -0.204037    -0.206665    -0.0512154   0.0563491   0.022836   -0.354679    0.276867     -0.068605    -0.0285385   -0.132944    -0.0766444   0.379984    0.103562    -0.0198591  -0.178706    0.00182825   0.0201804
  0.437989    0.59196    -0.266385     0.133572    0.154057     0.115885     -0.201194     0.0384106  -0.592415   -0.281049     0.194451    -0.598976   -0.301973   -0.689157   -0.336819   -0.0774128     0.115693    -0.227835     0.181004    -0.343825   -0.301403   -0.17228     -0.113488    0.0143239   0.0764691   -0.362825
 -0.232659   -0.116562    0.122573    -0.0932634  -0.0958801    0.000368641   0.128737    -0.152012    0.301427    0.17733      0.0672931    0.322382    0.132502    0.391854    0.0767693   0.00962572   -0.161501     0.0954132   -0.184294     0.284669    0.12542     0.0979968    0.0101693  -0.191029   -0.0300281    0.126942
 -0.338614    0.544185   -0.343199     0.0126806  -0.321127     0.323088      0.0801943   -0.470122   -0.43699     0.0893165   -0.432551     0.136249   -0.547171   -0.554251   -0.3614      0.304344     -0.662196    -0.123468    -0.387006     0.741985    0.591205   -0.130713     0.175957    0.875246   -0.200166    -0.0519332
  0.425659    0.907913    0.00863797  -0.291432   -0.71448      0.188756      0.416953     0.219325    0.285265    0.230836     0.131571     0.632298   -0.203791   -0.393706   -0.533215    0.175135      0.290727     0.259449    -0.514046    -0.0677422   0.629322    0.33836      0.159443   -0.425772   -0.403984    -0.167092
 -0.217374    0.265356   -0.497371    -0.0140356   0.575355    -0.115097      0.217921     0.210479    0.299934    0.638931    -0.0319949   -0.0448086   0.0398911  -0.56838     0.0445366  -0.359778      0.0327595    0.284927     0.008374     0.238333   -0.900846   -0.838649    -0.587083    0.240521   -0.222041     0.240451
  0.0371899   0.192773   -0.0270824   -0.0015231   0.0050945    0.0821039     0.00477165  -0.265721   -0.24663     0.166116     0.0419749    0.191609    0.0765672  -0.12864     0.0718953  -0.192916     -0.130548    -0.00212362   0.0310679    0.330001   -0.0852544  -0.22119      0.0423629   0.0715378  -0.0477839   -0.0405943[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411180
[ Info: iteration 2, average log likelihood -1.411172
[ Info: iteration 3, average log likelihood -1.411165
[ Info: iteration 4, average log likelihood -1.411158
[ Info: iteration 5, average log likelihood -1.411151
[ Info: iteration 6, average log likelihood -1.411145
[ Info: iteration 7, average log likelihood -1.411138
[ Info: iteration 8, average log likelihood -1.411132
[ Info: iteration 9, average log likelihood -1.411126
[ Info: iteration 10, average log likelihood -1.411120
┌ Info: EM with 100000 data points 10 iterations avll -1.411120
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
