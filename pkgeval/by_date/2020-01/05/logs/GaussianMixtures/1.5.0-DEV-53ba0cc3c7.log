Julia Version 1.5.0-DEV.3
Commit 53ba0cc3c7 (2020-01-02 23:13 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed SortingAlgorithms ── v0.3.1
 Installed GaussianMixtures ─── v0.3.0
 Installed URIParser ────────── v0.4.0
 Installed Rmath ────────────── v0.6.0
 Installed OrderedCollections ─ v1.1.0
 Installed StatsFuns ────────── v0.9.3
 Installed DataStructures ───── v0.17.7
 Installed Clustering ───────── v0.13.3
 Installed BinDeps ──────────── v1.0.0
 Installed Distances ────────── v0.8.2
 Installed JLD ──────────────── v0.9.1
 Installed LegacyStrings ────── v0.4.1
 Installed StaticArrays ─────── v0.12.1
 Installed Missings ─────────── v0.4.3
 Installed NearestNeighbors ─── v0.4.4
 Installed Compat ───────────── v2.2.0
 Installed BinaryProvider ───── v0.5.8
 Installed FillArrays ───────── v0.8.2
 Installed Blosc ────────────── v0.5.1
 Installed OpenBLAS_jll ─────── v0.3.7+2
 Installed ScikitLearnBase ──── v0.5.0
 Installed DataAPI ──────────── v1.1.0
 Installed Arpack ───────────── v0.4.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed CMakeWrapper ─────── v0.2.3
 Installed QuadGK ───────────── v2.3.1
 Installed SpecialFunctions ─── v0.9.0
 Installed PDMats ───────────── v0.9.10
 Installed Parameters ───────── v0.12.0
 Installed CMake ────────────── v1.1.2
 Installed FileIO ───────────── v1.2.1
 Installed HDF5 ─────────────── v0.12.5
 Installed StatsBase ────────── v0.32.0
 Installed Distributions ────── v0.21.12
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.12
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+2
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_AB64iH/Project.toml`
 [no changes]
  Updating `/tmp/jl_AB64iH/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_8vqpiN/Project.toml`
 [no changes]
  Updating `/tmp/jl_8vqpiN/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_CNJ0xr/Project.toml`
 [no changes]
  Updating `/tmp/jl_CNJ0xr/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_CTOQWR/Project.toml`
 [no changes]
  Updating `/tmp/jl_CTOQWR/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_MdNiuM/Project.toml`
 [no changes]
  Updating `/tmp/jl_MdNiuM/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_MdNiuM/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.12
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.3403264688309669e6, [482.62681721382205, 99517.37318278618], [-989.6072560642056 120.66387708110207 -42.593892344383825; 702.4802584332897 422.6741617135519 87.52942827642934], [[2130.562417224056 -205.27056449645357 140.20128850713198; -205.27056449645357 493.7241486390201 162.17297518804267; 140.20128850713198 162.17297518804267 84.89534920896509], [98010.87139239773 917.5629442467515 -374.65180140041485; 917.5629442467517 99319.85280326549 -235.58148046612703; -374.65180140041485 -235.58148046612706 99606.84063420155]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.206638e+03
      1       9.943173e+02      -2.123208e+02 |        5
      2       8.791748e+02      -1.151425e+02 |        3
      3       8.172084e+02      -6.196644e+01 |        2
      4       8.008054e+02      -1.640299e+01 |        0
      5       8.008054e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 800.8053721033343)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.055018
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.794397
[ Info: iteration 2, lowerbound -3.655912
[ Info: iteration 3, lowerbound -3.499275
[ Info: iteration 4, lowerbound -3.320231
[ Info: iteration 5, lowerbound -3.144450
[ Info: iteration 6, lowerbound -2.996120
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.881360
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.783376
[ Info: iteration 9, lowerbound -2.709539
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.645592
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.574483
[ Info: iteration 12, lowerbound -2.501981
[ Info: iteration 13, lowerbound -2.439042
[ Info: iteration 14, lowerbound -2.388826
[ Info: iteration 15, lowerbound -2.351231
[ Info: iteration 16, lowerbound -2.324376
[ Info: iteration 17, lowerbound -2.309555
[ Info: iteration 18, lowerbound -2.308553
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302915
[ Info: iteration 20, lowerbound -2.299259
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Jan  5 19:03:57 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Jan  5 19:04:07 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Sun Jan  5 19:04:10 2020: EM with 272 data points 0 iterations avll -2.055018
5.8 data points per parameter
, Sun Jan  5 19:04:12 2020: GMM converted to Variational GMM
, Sun Jan  5 19:04:23 2020: iteration 1, lowerbound -3.794397
, Sun Jan  5 19:04:23 2020: iteration 2, lowerbound -3.655912
, Sun Jan  5 19:04:23 2020: iteration 3, lowerbound -3.499275
, Sun Jan  5 19:04:23 2020: iteration 4, lowerbound -3.320231
, Sun Jan  5 19:04:23 2020: iteration 5, lowerbound -3.144450
, Sun Jan  5 19:04:23 2020: iteration 6, lowerbound -2.996120
, Sun Jan  5 19:04:24 2020: dropping number of Gaussions to 7
, Sun Jan  5 19:04:24 2020: iteration 7, lowerbound -2.881360
, Sun Jan  5 19:04:24 2020: dropping number of Gaussions to 5
, Sun Jan  5 19:04:24 2020: iteration 8, lowerbound -2.783376
, Sun Jan  5 19:04:24 2020: iteration 9, lowerbound -2.709539
, Sun Jan  5 19:04:24 2020: dropping number of Gaussions to 4
, Sun Jan  5 19:04:24 2020: iteration 10, lowerbound -2.645592
, Sun Jan  5 19:04:24 2020: dropping number of Gaussions to 3
, Sun Jan  5 19:04:24 2020: iteration 11, lowerbound -2.574483
, Sun Jan  5 19:04:24 2020: iteration 12, lowerbound -2.501981
, Sun Jan  5 19:04:24 2020: iteration 13, lowerbound -2.439042
, Sun Jan  5 19:04:24 2020: iteration 14, lowerbound -2.388826
, Sun Jan  5 19:04:24 2020: iteration 15, lowerbound -2.351231
, Sun Jan  5 19:04:24 2020: iteration 16, lowerbound -2.324376
, Sun Jan  5 19:04:24 2020: iteration 17, lowerbound -2.309555
, Sun Jan  5 19:04:24 2020: iteration 18, lowerbound -2.308553
, Sun Jan  5 19:04:24 2020: dropping number of Gaussions to 2
, Sun Jan  5 19:04:24 2020: iteration 19, lowerbound -2.302915
, Sun Jan  5 19:04:24 2020: iteration 20, lowerbound -2.299259
, Sun Jan  5 19:04:24 2020: iteration 21, lowerbound -2.299256
, Sun Jan  5 19:04:24 2020: iteration 22, lowerbound -2.299254
, Sun Jan  5 19:04:24 2020: iteration 23, lowerbound -2.299254
, Sun Jan  5 19:04:24 2020: iteration 24, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 25, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 26, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 27, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 28, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 29, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 30, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 31, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 32, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 33, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 34, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 35, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 36, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 37, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 38, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 39, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 40, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 41, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 42, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 43, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 44, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 45, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 46, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 47, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 48, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 49, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: iteration 50, lowerbound -2.299253
, Sun Jan  5 19:04:24 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260141, 95.95490777398591]
β = [178.0450922260141, 95.95490777398591]
m = [4.250300733269907 79.28686694436182; 2.000229257775368 53.851987172461264]
ν = [180.0450922260141, 97.95490777398591]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484594 -0.007644049042327515; 0.0 0.008581705166333456], [0.3758763611948462 -0.008953123827346154; 0.0 0.012748664777409258]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9981945678175852
avll from llpg:  -0.9981945678175846
avll direct:     -0.9981945678175848
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9920396090748766
avll from llpg:  -0.9920396090748766
avll direct:     -0.9920396090748766
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.12374     -0.17138      0.0662231    0.146132     0.0879426   -0.0390626    -0.000919328   0.0284374   -0.0782568    0.0453955   -0.00676243  -0.0201185   -0.0454852   -0.0952563     0.0562922    0.211062    -0.0622054    0.0574226    -0.197883      0.131552    0.152256    -0.211185     0.0801613   -0.149187    -0.0721925    0.0841546
  0.227744    -0.0814275    0.0189229   -0.0233258    0.0635415   -0.0871712    -0.132515      0.0186416   -0.0252003   -0.106405     0.0323214   -0.0426709    0.0968727    0.0615858     0.028773    -0.164448     0.101905     0.0397339     0.0144794     0.0869684  -0.0513533    0.060303    -0.054675    -0.0302355    0.178935     0.107823
 -0.120828    -0.0333759   -0.108595     0.0337277   -0.0978642    0.0655822    -0.0819213     0.0416343    0.0926466   -0.105519    -0.197932     0.0361837    0.125187    -0.173085      0.0983508    0.0560842    0.0148649    0.0274513    -0.0693447     0.127281    0.0783513   -0.14729      0.0647655   -0.123864    -0.0939552    0.0269737
  0.0454534    0.0336763   -0.00121387  -0.00892314   0.0460892   -0.108122     -0.160807      0.067048     0.136619    -0.0598367   -0.0155999   -0.0106902   -0.0333182    0.11565       0.116874    -0.0540163    0.121849    -0.095318      0.00612256   -0.0439782   0.00404161   0.124245    -0.194611    -0.209367     0.00138772  -0.0519234
 -0.133551     0.104992     0.101692    -0.0293092   -0.0947647   -0.000976496   0.064645      0.078462     0.022837     0.134282    -0.0918489   -0.0363932    0.0316449    0.0533529    -0.0680213    0.0736362    0.0725785   -0.0740729     0.0272612    -0.139655   -0.022019    -0.211745     0.0307391   -0.0582559    0.0871323    0.04701
 -0.00620378   0.00770472  -0.0075115   -0.0567794    0.126366     0.162123      0.094304     -0.0192593   -0.0163318   -0.0686976    0.0645332   -0.0603346   -0.028488    -0.0607292     0.178218     0.0287339    0.0206758   -0.0397801     0.0105099    -0.0542825  -0.0855072    0.137933     0.103511     0.206395     0.0672062   -0.136449
  0.0797131   -0.0597211    0.111697    -0.0559628   -0.0448865   -0.025285     -0.0426173     0.0234623    0.291778     0.0562565   -0.0256942   -0.0874193    0.124301     0.0172919     0.137507    -0.0507484    0.148553    -0.120754     -0.024902     -0.0902039   0.0915498   -0.11833      0.0821873    0.0619429    0.0971337    0.0863743
 -0.104678    -0.0755192    0.00698046  -0.258134     0.0961762    0.0652146     0.0713565     0.133103     0.134972    -0.153452     0.0449423   -0.0697169    0.195689    -0.0406335    -0.0446626    0.0713716   -0.203463     0.0504889    -0.104894      0.0601364  -0.0899339   -0.107374    -0.0804674   -0.015877    -0.0505692   -0.0768844
 -0.0713707   -0.0935769    0.123919    -0.111398     0.0211519    0.0820087    -0.0973285     0.0081899   -0.0897664    0.00904275  -0.0431199   -0.0923138    0.0563237   -0.00251467   -0.238924     0.046573    -0.109003     0.102429      0.227185      0.0499165  -0.0605534   -0.0090638   -0.184143     0.301148     0.0674474   -0.0564524
  0.0121585   -0.0623989   -0.0687942    0.114333    -0.0457585   -0.141132      0.167635      0.0669678    0.0533668   -0.0613978   -0.115831     0.112834    -0.0428234    0.066813     -0.0269575    0.109936     0.0167766    0.0233169    -0.0457501    -0.0603536   0.0659328   -0.194556    -0.010019     0.0267316   -0.0951527    0.149343
  0.174395    -0.136478    -0.157439     0.10707     -0.00904686   0.0259879     0.0179053     0.0350677   -0.0354218   -0.00848217  -0.0620622    0.048248    -0.017311    -0.110366      0.10064      0.0206094   -0.125615    -0.0807198    -0.0826358    -0.0652472  -0.147382    -0.0182078   -0.0204247   -0.12637     -0.0296593    0.0182989
 -0.0563187   -0.0588099   -0.114652    -0.0442001   -0.0580665    0.0386693     0.262856      0.106911     0.108228    -0.0122954   -0.178757     0.00892082  -0.0186105   -0.000732045   0.0936548    0.136756    -0.143315    -0.121593      0.0340983     0.137695   -0.10118     -0.0205811   -0.0246594   -0.115841     0.0795637    0.0470145
 -0.073801     0.0114173    0.0394142    0.136299     0.082428    -0.08269      -0.0379971     0.0424861   -0.0579812    0.0405273   -0.0429612    0.0788578    0.031443    -0.0304058    -0.00661978   0.0527698    0.0756708   -0.0805357     0.0357352    -0.0131911   0.0899085    0.00858316   1.21832e-5   0.0430244    0.203665    -0.043338
  0.0801345    0.0590431   -0.112407     0.0306307   -0.026217    -0.0103776    -0.0102149    -0.0542203    0.112756     0.176709    -0.002235     0.0724911   -0.132837     0.0511741     0.0628284    0.0421161    0.00367144   0.0180524     0.007427      0.023913   -0.0185308   -0.135313    -0.159679     0.011395     0.0255955   -0.0106966
 -0.046702    -0.0656042    0.0148332    0.154984    -0.029619     0.0571664    -0.0396271     0.0502272   -0.00731486   0.0149916   -0.0323141   -0.156828    -0.0147087    0.0469628     0.123577    -0.177713    -0.178175    -0.148132      0.133492     -0.142963   -0.0616248    0.0558504   -0.0152773    0.0114033   -0.0800794    0.159737
  0.0581633   -0.0553072   -0.0762203   -0.0466592   -0.0623537   -0.0561177     0.0647917     0.0296504   -0.0237419   -0.0536863   -0.124016    -0.063238     0.053229    -0.103887      0.172423     0.0679689    0.0628884   -0.0971823     0.0171819    -0.0490969   0.0205371   -0.124817    -0.0481259    0.0482824   -0.169521     0.110459
  0.0787894   -0.180417     0.0736258   -0.184709     0.0394113   -0.0470782    -0.00948659   -0.0582574    0.0978082    0.0420513   -0.0281379    0.0927783   -0.0353351   -0.142803      0.0281204   -0.220277    -0.0495081    0.0795306     0.078335      0.173436    0.0450668   -0.00084951   0.0352611    0.0861567   -0.0443207    0.0619661
 -0.0136432    0.169644    -0.0491624    0.00905179   0.066681    -0.0631984    -0.0372101     0.00877332  -0.111167     0.220571    -0.117799    -0.0311392    0.0310837    0.0610314    -0.0443927    0.0282438   -0.0628747   -0.0489582     0.228705     -0.106375    0.130897    -0.0432335    0.0361095    0.0476523    0.0424821    0.217316
 -0.0386564   -0.0136969    0.13137      0.0710078    0.145797    -0.0180174    -0.0971017    -0.04412     -0.120389     0.095198     0.0685654   -0.197669     0.137433    -0.0870891    -0.0108067    0.0548145   -0.0272307    0.114194     -0.00673226    0.159698   -0.0306714   -0.0527154    0.179032     0.0528336   -0.00189188   0.0176481
 -0.0466347   -0.0730095    0.0786411    0.0438274   -0.0895611    0.103178     -0.0752908    -0.050962    -0.124185     0.0603062   -0.259456    -0.0457762   -0.0400603    0.0522819    -0.120813    -0.0213562    0.140123     0.123865      0.048917     -0.24292    -0.018289    -0.0160764   -0.278479     0.0908736    0.132832    -0.0319678
 -0.0910377   -0.217917     0.0719359    0.0670767    0.048867    -0.214688     -0.0516407     0.0484894    0.0378312   -0.0099889   -0.0827445    0.0534369   -0.101241     0.0812206    -0.0659006    0.153679     0.0424366    0.000862823   0.105275      0.0712408   0.108705     0.00194468  -0.203287    -0.0112748   -0.0914215    0.235796
 -0.0261512   -0.239086    -0.0455628    0.0838715    0.0442766   -0.0257286     0.198746      0.0116404   -0.143154    -0.0641739    0.0712548   -0.0808318   -0.245501     0.0604802    -0.135646    -0.00122325   0.00782762   0.159844      0.0112976    -0.0429564  -0.119198    -0.0295847   -0.183587     0.0242909   -0.0596597   -0.129767
  0.0378371    0.00482993   0.174532    -0.119832    -0.251553    -0.0664288    -0.0492156     0.0549586   -0.0279331    0.0289396   -0.100761     0.0464043   -0.00767576   0.0826705    -0.00378029  -0.0398817   -0.0818804   -0.0367652     0.155257      0.149257    0.0658165   -0.0421976   -0.0200966   -0.022017     0.0164941    0.0377128
  0.0245431   -0.0102572   -0.12298     -0.0573014   -0.056366    -0.0763696     0.05392      -0.0721222   -0.115965     0.0581927   -0.126212    -0.111429     0.197425     0.0470524     0.00548277   0.106954     0.0302732    0.0422724    -0.0242053    -0.162007    0.0104845   -0.00414791   0.0449675   -0.0125553    0.123852    -0.0186758
  0.0793912   -0.0587888   -0.0145667    0.0461697    0.114702     0.0488684     0.123365     -0.0938215    0.0686724   -0.0744913   -0.036625    -0.0295379   -0.085725    -0.0143674     0.0604748    0.122168     0.0633197    0.123354     -0.14011      -0.03043    -0.170616     0.0684491   -0.0729475   -0.107554    -0.0569361    0.0877335
  0.164681     0.0534787    0.0603263   -0.010969     0.0624499   -0.0868374    -0.0812456     0.0494851    0.109232    -0.0869615    0.0776346   -0.0969579   -0.147837    -0.0474176     0.099696    -0.0564456   -0.0310692    0.0833128    -0.0604792    -0.070115   -0.0574155    0.084988     0.0863242   -0.0155202   -0.0692883   -0.145528
 -0.181856    -0.175056     0.211697     0.100345     0.00684302  -0.116061     -0.00152373    0.234757    -0.0672024    0.092973     0.0251461    0.0920161    0.156765     0.0338089     0.230395     0.00534451  -0.00621665   0.047726     -0.000930992   0.0575391   0.12759     -0.0345909   -0.147989    -0.0851697   -0.142624    -0.22866
 -0.191742    -0.0849879    0.114767     0.0934335   -0.0239837   -0.0859557    -0.130776      0.106014    -0.0253514   -0.0265641    0.060277    -0.121978    -0.119761    -0.0303137     0.0195568   -0.0830162    0.114434     0.0483643     0.0649336    -0.0647269   0.0651579    0.0621968    0.0611688    0.087559    -0.0860658   -0.174559
 -0.0151681   -0.00413652  -0.197871    -0.116214    -0.139876    -0.0265697     0.0116027     0.0294994    0.0598034   -0.217939     0.0185354    0.139223     0.102417     0.0919911    -0.191923    -0.184335     0.0436139   -0.0321348    -0.102946     -0.175078    0.0835554   -0.289789     0.0489571   -0.0188978   -0.0722288    0.060486
  0.292493     0.0443673   -0.170764    -0.0739801    0.126619    -0.0294981    -0.0653707     0.0829515    0.0729329   -0.018998    -0.122974     0.158333     0.162825     0.0403946    -0.0230724   -0.0214652    0.0482816    0.148152     -3.64363e-5    0.191884    0.0697967   -0.00858404   0.0265827    0.156785     0.0848297   -0.0553932
 -0.0205661   -0.116182     0.120914    -0.0559553    0.0258906   -0.0480808    -0.0456865     0.129393    -0.156626    -0.0295803    0.00938673   0.0952533   -0.0325595   -0.0764686    -0.0309263    0.010557    -0.060236    -0.160253      0.0306873     0.199102    0.0275362    0.0305486   -0.133448    -0.00919943   0.0865152    0.113245
  0.107053    -0.134319     0.0100806    0.061208    -0.183779    -0.0618555    -0.0116739     0.117394    -0.0188858    0.0264961    0.0277712    0.0170305    0.0156422    0.0997271     0.167091     0.0841969    0.0312411    0.0134588     0.0995795     0.139371   -0.0770248    0.119336     0.138877    -0.0235737   -0.0254556    0.0531484kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4301395517184403
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.430205
[ Info: iteration 2, average log likelihood -1.430121
[ Info: iteration 3, average log likelihood -1.429147
[ Info: iteration 4, average log likelihood -1.420127
[ Info: iteration 5, average log likelihood -1.403157
[ Info: iteration 6, average log likelihood -1.396639
[ Info: iteration 7, average log likelihood -1.395037
[ Info: iteration 8, average log likelihood -1.394332
[ Info: iteration 9, average log likelihood -1.393948
[ Info: iteration 10, average log likelihood -1.393731
[ Info: iteration 11, average log likelihood -1.393602
[ Info: iteration 12, average log likelihood -1.393524
[ Info: iteration 13, average log likelihood -1.393473
[ Info: iteration 14, average log likelihood -1.393438
[ Info: iteration 15, average log likelihood -1.393414
[ Info: iteration 16, average log likelihood -1.393397
[ Info: iteration 17, average log likelihood -1.393384
[ Info: iteration 18, average log likelihood -1.393374
[ Info: iteration 19, average log likelihood -1.393366
[ Info: iteration 20, average log likelihood -1.393360
[ Info: iteration 21, average log likelihood -1.393356
[ Info: iteration 22, average log likelihood -1.393352
[ Info: iteration 23, average log likelihood -1.393349
[ Info: iteration 24, average log likelihood -1.393346
[ Info: iteration 25, average log likelihood -1.393344
[ Info: iteration 26, average log likelihood -1.393342
[ Info: iteration 27, average log likelihood -1.393340
[ Info: iteration 28, average log likelihood -1.393339
[ Info: iteration 29, average log likelihood -1.393338
[ Info: iteration 30, average log likelihood -1.393336
[ Info: iteration 31, average log likelihood -1.393335
[ Info: iteration 32, average log likelihood -1.393334
[ Info: iteration 33, average log likelihood -1.393333
[ Info: iteration 34, average log likelihood -1.393332
[ Info: iteration 35, average log likelihood -1.393331
[ Info: iteration 36, average log likelihood -1.393330
[ Info: iteration 37, average log likelihood -1.393329
[ Info: iteration 38, average log likelihood -1.393329
[ Info: iteration 39, average log likelihood -1.393328
[ Info: iteration 40, average log likelihood -1.393327
[ Info: iteration 41, average log likelihood -1.393326
[ Info: iteration 42, average log likelihood -1.393326
[ Info: iteration 43, average log likelihood -1.393325
[ Info: iteration 44, average log likelihood -1.393325
[ Info: iteration 45, average log likelihood -1.393324
[ Info: iteration 46, average log likelihood -1.393324
[ Info: iteration 47, average log likelihood -1.393323
[ Info: iteration 48, average log likelihood -1.393323
[ Info: iteration 49, average log likelihood -1.393322
[ Info: iteration 50, average log likelihood -1.393322
┌ Info: EM with 100000 data points 50 iterations avll -1.393322
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4302050584324801
│     -1.430120716347091
│      ⋮
└     -1.3933221239221116
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.393421
[ Info: iteration 2, average log likelihood -1.393320
[ Info: iteration 3, average log likelihood -1.392889
[ Info: iteration 4, average log likelihood -1.389221
[ Info: iteration 5, average log likelihood -1.377414
[ Info: iteration 6, average log likelihood -1.366524
[ Info: iteration 7, average log likelihood -1.361916
[ Info: iteration 8, average log likelihood -1.359255
[ Info: iteration 9, average log likelihood -1.357220
[ Info: iteration 10, average log likelihood -1.355606
[ Info: iteration 11, average log likelihood -1.354386
[ Info: iteration 12, average log likelihood -1.353451
[ Info: iteration 13, average log likelihood -1.352630
[ Info: iteration 14, average log likelihood -1.351869
[ Info: iteration 15, average log likelihood -1.351323
[ Info: iteration 16, average log likelihood -1.350950
[ Info: iteration 17, average log likelihood -1.350677
[ Info: iteration 18, average log likelihood -1.350462
[ Info: iteration 19, average log likelihood -1.350282
[ Info: iteration 20, average log likelihood -1.350130
[ Info: iteration 21, average log likelihood -1.349996
[ Info: iteration 22, average log likelihood -1.349865
[ Info: iteration 23, average log likelihood -1.349714
[ Info: iteration 24, average log likelihood -1.349537
[ Info: iteration 25, average log likelihood -1.349357
[ Info: iteration 26, average log likelihood -1.349209
[ Info: iteration 27, average log likelihood -1.349099
[ Info: iteration 28, average log likelihood -1.349020
[ Info: iteration 29, average log likelihood -1.348965
[ Info: iteration 30, average log likelihood -1.348927
[ Info: iteration 31, average log likelihood -1.348900
[ Info: iteration 32, average log likelihood -1.348881
[ Info: iteration 33, average log likelihood -1.348866
[ Info: iteration 34, average log likelihood -1.348854
[ Info: iteration 35, average log likelihood -1.348844
[ Info: iteration 36, average log likelihood -1.348835
[ Info: iteration 37, average log likelihood -1.348827
[ Info: iteration 38, average log likelihood -1.348820
[ Info: iteration 39, average log likelihood -1.348814
[ Info: iteration 40, average log likelihood -1.348807
[ Info: iteration 41, average log likelihood -1.348801
[ Info: iteration 42, average log likelihood -1.348795
[ Info: iteration 43, average log likelihood -1.348790
[ Info: iteration 44, average log likelihood -1.348784
[ Info: iteration 45, average log likelihood -1.348779
[ Info: iteration 46, average log likelihood -1.348773
[ Info: iteration 47, average log likelihood -1.348768
[ Info: iteration 48, average log likelihood -1.348762
[ Info: iteration 49, average log likelihood -1.348757
[ Info: iteration 50, average log likelihood -1.348752
┌ Info: EM with 100000 data points 50 iterations avll -1.348752
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.393420795069898
│     -1.3933195857770753
│      ⋮
└     -1.3487517543506833
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.348901
[ Info: iteration 2, average log likelihood -1.348730
[ Info: iteration 3, average log likelihood -1.347966
[ Info: iteration 4, average log likelihood -1.341083
[ Info: iteration 5, average log likelihood -1.321286
[ Info: iteration 6, average log likelihood -1.308082
[ Info: iteration 7, average log likelihood -1.303258
[ Info: iteration 8, average log likelihood -1.301060
[ Info: iteration 9, average log likelihood -1.299980
[ Info: iteration 10, average log likelihood -1.299365
[ Info: iteration 11, average log likelihood -1.298909
[ Info: iteration 12, average log likelihood -1.298488
[ Info: iteration 13, average log likelihood -1.297992
[ Info: iteration 14, average log likelihood -1.297258
[ Info: iteration 15, average log likelihood -1.296259
[ Info: iteration 16, average log likelihood -1.295320
[ Info: iteration 17, average log likelihood -1.294711
[ Info: iteration 18, average log likelihood -1.294355
[ Info: iteration 19, average log likelihood -1.294128
[ Info: iteration 20, average log likelihood -1.293971
[ Info: iteration 21, average log likelihood -1.293856
[ Info: iteration 22, average log likelihood -1.293766
[ Info: iteration 23, average log likelihood -1.293689
[ Info: iteration 24, average log likelihood -1.293622
[ Info: iteration 25, average log likelihood -1.293562
[ Info: iteration 26, average log likelihood -1.293510
[ Info: iteration 27, average log likelihood -1.293464
[ Info: iteration 28, average log likelihood -1.293426
[ Info: iteration 29, average log likelihood -1.293394
[ Info: iteration 30, average log likelihood -1.293369
[ Info: iteration 31, average log likelihood -1.293347
[ Info: iteration 32, average log likelihood -1.293327
[ Info: iteration 33, average log likelihood -1.293307
[ Info: iteration 34, average log likelihood -1.293282
[ Info: iteration 35, average log likelihood -1.293249
[ Info: iteration 36, average log likelihood -1.293203
[ Info: iteration 37, average log likelihood -1.293131
[ Info: iteration 38, average log likelihood -1.293003
[ Info: iteration 39, average log likelihood -1.292741
[ Info: iteration 40, average log likelihood -1.292149
[ Info: iteration 41, average log likelihood -1.290742
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.288179
[ Info: iteration 43, average log likelihood -1.302330
[ Info: iteration 44, average log likelihood -1.296198
[ Info: iteration 45, average log likelihood -1.294576
[ Info: iteration 46, average log likelihood -1.293851
[ Info: iteration 47, average log likelihood -1.293537
[ Info: iteration 48, average log likelihood -1.293423
[ Info: iteration 49, average log likelihood -1.293375
[ Info: iteration 50, average log likelihood -1.293346
┌ Info: EM with 100000 data points 50 iterations avll -1.293346
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3489006395622312
│     -1.3487299378948745
│      ⋮
└     -1.2933456644478487
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.293539
[ Info: iteration 2, average log likelihood -1.293263
[ Info: iteration 3, average log likelihood -1.292007
[ Info: iteration 4, average log likelihood -1.279355
[ Info: iteration 5, average log likelihood -1.250815
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.218313
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.214441
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.209275
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.208691
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.212843
[ Info: iteration 11, average log likelihood -1.210164
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.197845
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.204151
[ Info: iteration 14, average log likelihood -1.216227
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.203342
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.209791
[ Info: iteration 17, average log likelihood -1.207850
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.195609
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.215488
[ Info: iteration 20, average log likelihood -1.212235
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.200127
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.206493
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.204161
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.205364
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.210810
[ Info: iteration 26, average log likelihood -1.208894
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.196901
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.203331
[ Info: iteration 29, average log likelihood -1.214726
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.201893
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.208644
[ Info: iteration 32, average log likelihood -1.206995
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.194733
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.213896
[ Info: iteration 35, average log likelihood -1.210472
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.198397
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.204908
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.202731
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.203252
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.208917
[ Info: iteration 41, average log likelihood -1.207157
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.195178
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.201675
[ Info: iteration 44, average log likelihood -1.212451
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.199512
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.206200
[ Info: iteration 47, average log likelihood -1.204337
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.191814
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.210951
[ Info: iteration 50, average log likelihood -1.208016
┌ Info: EM with 100000 data points 50 iterations avll -1.208016
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.293539390861639
│     -1.2932627313145928
│      ⋮
└     -1.2080163264779467
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.196372
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.192200
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.188860
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.164485
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.122492
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.088124
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     17
│     18
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.144469
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.112131
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      9
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.095570
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.129574
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.117162
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.102296
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.121989
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.119073
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.100465
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│     17
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.134432
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│      8
│     13
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.110028
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      9
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.097948
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.131328
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.121058
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.089680
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      7
│     14
│     17
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.133025
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.115020
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      9
│     10
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.106032
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│      8
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.125063
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│     14
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.116078
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      8
│      9
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.102347
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│     17
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.127957
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.111802
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.095953
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      8
│     17
│     18
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.139124
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.112012
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      9
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.096082
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│      8
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.129902
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.116964
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.102433
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.122341
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.119233
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.100420
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│     17
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.134485
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│      7
│     13
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.110139
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      9
│      ⋮
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.097814
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.131332
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.119368
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.087633
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│     14
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.132225
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.103300
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│      9
│      ⋮
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.099526
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.118372
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│     10
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.111782
┌ Info: EM with 100000 data points 50 iterations avll -1.111782
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1963717236104106
│     -1.1921998060556842
│      ⋮
└     -1.1117816945723509
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4301395517184403
│     -1.4302050584324801
│     -1.430120716347091
│     -1.429147236549401
│      ⋮
│     -1.0995257825984173
│     -1.1183723739158158
└     -1.1117816945723509
32×26 Array{Float64,2}:
  0.0638789   -0.0556205    -0.0616618    0.129975    -0.0352836   -0.148987     0.157011     0.0757001   0.0367231  -0.0281152   -0.115905     0.117846    -0.0643276    0.0877149    -0.0434278    0.122367     0.0346568    0.0359675    -0.0139253    -0.0619601    0.0754509    -0.178408    -0.0441494    0.0187683    -0.103391     0.146943
  0.0443709   -0.0643608    -0.0804614   -0.0563488   -0.0918868   -0.0385557    0.0326444    0.0173994  -0.0296106  -0.0435374   -0.133458    -0.077367     0.0655223   -0.145463      0.207461     0.036042    -0.0382626   -0.110202     -0.0209144    -0.0461857   -0.00867179   -0.136943    -0.040254     0.0524632    -0.17909      0.0951507
 -0.200508    -0.221625      0.138408     0.0559211    0.0302157   -0.61045      0.0583278    0.0574081   0.0609231  -0.049355    -0.0822922    0.0747875   -0.178122     0.07538      -0.165658     0.0974343    0.111526     0.00203055    0.0575283     0.0904618    0.102336     -0.00919505  -0.00448354  -0.0628515    -0.0634783    0.559773
 -0.0181483   -0.216808      0.0215839    0.0791415    0.117156     0.1544      -0.124324     0.0385133   0.0204152   0.0418394   -0.0845827    0.0322468   -0.0205758    0.0637107     0.00925321   0.249003     0.0460543   -0.000699158   0.151022      0.05021      0.0635679     0.0124875   -0.430094    -0.0122734    -0.102981    -0.0508892
 -0.184921    -0.0906432     0.112079     0.0881278   -0.0288627   -0.0660459   -0.143191     0.106331   -0.0194318  -0.0394439    0.0631458   -0.135305    -0.134742    -0.0269117     0.0147886   -0.105536     0.146797     0.0469658     0.0717571    -0.0650233    0.0779066     0.0504253    0.0620589    0.0935491    -0.111454    -0.164264
 -0.120365    -0.169279      0.0613828    0.147357     0.106386    -0.0408257   -0.00282976   0.0523135  -0.0787262   0.0386568   -0.00914892  -0.0123007   -0.0503755   -0.0694842     0.067464     0.21659     -0.0810265    0.0579022    -0.195771      0.128311     0.149762     -0.221039     0.0787291   -0.14506      -0.0458891    0.067981
 -0.0570975    0.00663013    0.0484547    0.133571     0.0813421   -0.0698079   -0.0510404    0.0398907  -0.049611    0.0391876   -0.0548359    0.0622332    0.0263196   -0.0278691     0.00480216   0.0533265    0.0744787   -0.0831526     0.0238396    -0.00851285   0.087736      0.00619751  -0.00354064   0.0441977     0.250299     0.000703824
  0.22901     -0.0991427     0.00563074  -0.0321536    0.0486217   -0.103339    -0.119899     0.030989   -0.0168698  -0.0954354    0.0395128   -0.0545452    0.125745     0.0350341     0.0288352   -0.129317     0.104789     0.0683425     0.0155145     0.0973693   -0.0821513     0.0605392   -0.0473755    0.00715272    0.161803     0.109066
  0.115502    -0.117514      0.0110163    0.0264623   -0.176831    -0.0632377   -0.0377166    0.153788   -0.0124513   0.0266171    0.0279124    0.0269702   -0.00871232   0.0990836     0.154151     0.0809233    0.0303141    0.00751347    0.0770286     0.125501    -0.074501      0.10795      0.150684    -0.0176262    -0.0103058    0.0488158
 -0.082518    -0.0109974    -0.195951    -0.0952399   -0.141287    -0.050897    -0.0392036    0.0141882   0.0498379  -0.234006     0.0120181    0.135586     0.115734     0.0920283    -0.190747    -0.182754     0.0430399   -0.0329038    -0.0888702    -0.177809     0.0769637    -0.29986      0.0501948   -0.0187008    -0.0600452    0.0638203
  0.290853     0.0192013    -0.166685    -0.0735201    0.117727    -0.0247442   -0.0576946    0.082947    0.0762116  -0.0047882   -0.101688     0.169106     0.125224     0.043604     -0.0241683   -0.0218468    0.0500714    0.155452     -0.0101624     0.205542     0.0814059    -0.0020741    0.0199304    0.157423      0.160222    -0.0483928
  0.168668    -0.129489     -0.17343      0.100553    -0.00982858   0.0403072   -0.00321794   0.036717   -0.0273586  -0.00923941  -0.0272835    0.0603139    0.0215871   -0.0988193     0.0951456    0.0296809   -0.100418    -0.0891207    -0.050367     -0.0192106   -0.135636     -0.00144838  -0.0430858   -0.111883     -0.0224592   -0.00134634
 -0.0496859   -0.112793     -0.15429     -0.0196175   -0.0406526    0.0228676    0.254808     0.0867219   0.0716994  -0.0236344   -0.112472    -0.00974719  -0.0653705    0.00719752    0.0466052    0.12791     -0.140145    -0.0337043     0.0414593     0.11305     -0.127239     -0.0373082   -0.0434908   -0.0966925     0.0588751    0.0407038
 -0.126997     0.106303      0.100764    -0.0258877   -0.121425    -0.0194137    0.0642869    0.0823228   0.0186001   0.147085    -0.0954715   -0.00772478   0.0377304    0.046765     -0.0820391    0.0720078    0.092275    -0.0426195     0.0281335    -0.139611    -0.0162536    -0.249944     0.0436005   -0.0566502     0.0841138    0.0386931
 -0.0598269   -0.129665      0.0780133    0.0475852    0.124383    -0.057541     0.00881469  -0.0175516  -0.13982     0.0353457    0.0624999   -0.1866      -0.0147645   -0.043295     -0.0419976    0.0399844    0.00752514   0.126805      0.00193289    0.0852858   -0.0707828    -0.0347938    0.0293437    0.0585281    -0.0163105   -0.0119514
 -0.0292331   -0.119191      0.0823656    0.0329046    0.00329585   0.0435377   -0.0465026    0.0832878  -0.0932155   0.0064894    0.0129357   -0.0249794   -0.0326564   -0.000140163   0.0207703   -0.0848437   -0.0918863   -0.137393      0.068104      0.0323848   -0.0029417     0.0336822   -0.0803379   -0.000834391   0.00699855   0.12454
 -0.11865     -0.080885     -0.0757786    0.0464668   -0.148979     0.0555014   -0.29518     -0.0243824   0.111476   -0.200319    -0.206753     0.0432527    0.170028    -0.195423      0.101146     0.0735293   -0.00257196   0.0247632    -0.053342      0.125268    -0.329115     -0.192119     0.0648443   -0.245459     -0.100087     0.0958359
 -0.120762     0.000637681  -0.102405     0.0156758   -0.18003      0.0751249    0.20005      0.140288    0.094439    0.0516716   -0.187856     0.0284421    0.0650426   -0.148703      0.0969601    0.0191972    0.0826195    0.0277832    -0.140592      0.12997      0.600438     -0.0589462    0.0648255    0.0163023    -0.072108     0.0290618
 -0.00877027   0.164793     -0.0447753    0.0270088    0.0213063    0.101269    -0.0522247   -0.0284108  -0.0234639   0.296068    -0.216252     0.105649     0.0303129    0.0121649    -0.21722      0.00494067  -0.0703785   -0.101505      0.227489     -0.105941     0.110136     -0.00779997   0.0523721    0.117151      0.0483726    0.184621
 -0.00961055   0.169408     -0.0462327    0.00366232   0.0786504   -0.202804    -0.0327847    0.0147165  -0.121039    0.238814    -0.0828369   -0.186757     0.0168356    0.111573      0.114096     0.0459282    0.0316854   -0.00636966    0.26127      -0.105439     0.192161     -0.0620325    0.0507966   -0.0034652     0.0255627    0.230009
  0.159026     0.0545067    -0.0675988   -0.00891387   0.146634    -0.0663339   -0.189158     0.0495749   0.0945518  -0.140665    -0.0329596   -0.65774     -0.161662     0.0657414     0.0957764   -0.0796316   -0.035156     0.0819741    -0.103905     -0.0358784   -0.112852      0.0665411    0.113665    -0.0321454    -0.0492965   -0.117482
  0.179893     0.0541744     0.158103     0.0165898    0.0180564   -0.116355     0.0872117    0.0664768   0.129223    0.0346045    0.19635      0.536241    -0.187421    -0.142359      0.101956    -0.0388875   -0.0272438    0.0651764    -0.0426645    -0.086918    -0.0573439     0.0629769   -0.00408837  -0.00476859   -0.107268    -0.164167
 -0.105056    -0.0895306    -0.0028558   -0.260336     0.12484      0.0646791    0.0842806    0.131958    0.133779   -0.100397     0.0426774   -0.012046     0.194867    -0.0458419    -0.0429829    0.0769102   -0.205852     0.0539259    -0.105432      0.0593709   -0.0882985    -0.11177     -0.0763036   -0.0129004    -0.0422046   -0.0829211
 -0.0502866   -0.0553327     0.0869342    0.0407118   -0.0786502    0.104495    -0.0571144   -0.0564262  -0.123539    0.0656897   -0.255817    -0.0482385   -0.0295534    0.0856218    -0.116983    -0.0243387    0.136533     0.123074      0.0286824    -0.24341     -0.0212081    -0.0282439   -0.255228     0.0863058     0.138843    -0.0459882
 -0.0117716    0.00969332   -0.00256534  -0.016652     0.127163     0.167189     0.0860847   -0.0150073  -0.0220915  -0.0484064    0.0721176   -0.0842897   -0.0361778   -0.0844423     0.178888     0.0288055    0.0321568   -0.120057     -0.00508082    0.0205439   -0.0811226     0.129863     0.0984771    0.203442      0.0652034   -0.161765
  0.084606    -0.163377      0.074759    -0.186522     0.0127829   -0.0506588   -0.00920009  -0.0556945   0.124974    0.0357799   -0.0215331    0.117183    -0.0436725   -0.137406      0.0148404   -0.236334    -0.0397063    0.0868114     0.0888131     0.205467     0.0310594    -0.0468461    0.0319679    0.0854168    -0.0369595    0.068394
 -0.00466898  -0.0862614     0.125878    -0.0767843    0.021484     0.0464126   -0.085949     0.0155853   0.057384    0.00291471  -0.0394988   -0.0900743    0.083961     0.0128853    -0.0837117    0.0105067   -0.00239507   0.020115      0.11577      -0.00799609  -0.00405434   -0.0526641   -0.0735354    0.198569      0.0787321    0.00393371
  0.0491778    0.0273881     0.0794244   -0.0384271   -0.0961444   -0.0834652   -0.115871     0.0600294   0.0620942   0.0113698   -0.0717884    0.0177138   -0.0148609    0.113649      0.0696144   -0.0481455    0.0365244   -0.0667073     0.086854      0.0311736    0.0282983     0.0426034   -0.103607    -0.115773      0.00900447   0.0353418
  0.0811126    0.0717155    -0.113982     0.020245    -0.0296664   -0.00797866  -0.00380734  -0.0762614   0.11125     0.156201     0.0100981    0.0649992   -0.151457     0.0611173     0.0736152    0.0514911    0.00738648   0.0275614     0.000567418   0.0487729   -0.0344697    -0.130504    -0.162811     0.00497117    0.00107435  -0.00122074
  0.079772    -0.0758533    -0.0460686    0.0202216    0.1259       0.00609036   0.110459    -0.0795617   0.0685625  -0.0553351   -0.0435358    0.00315048  -0.0488129   -0.0141036     0.0546552    0.136077     0.0876152    0.121753     -0.144509     -0.0677652   -0.164281      0.0914935   -0.0862102   -0.100786     -0.0471789    0.103086
  0.0230417   -0.00888326   -0.134646    -0.0305531   -0.0607578   -0.0759903    0.0805806   -0.010939   -0.11163     0.0559997   -0.122822    -0.111937     0.197803     0.038628      0.00516915   0.106013     0.0293012    0.0159187    -0.0147525    -0.156368     0.000504073   0.00323623   0.0276148   -0.00734184    0.125288    -0.0157878
 -0.180063    -0.177264      0.199937     0.0809291   -0.00583533  -0.0966539    0.00817863   0.215219   -0.0562756   0.1031       0.0282897    0.0842837    0.150061     0.0377711     0.351306     0.00210603  -0.00463369   0.0316808     0.0050889     0.0395913    0.12698      -0.0364232   -0.141269    -0.0955715    -0.136026    -0.228383[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      6
│      7
│      9
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.100062
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.081737
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.093175
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.078814
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      6
│      7
│      9
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.100156
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.081163
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.092816
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.081934
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.098953
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.083785
┌ Info: EM with 100000 data points 10 iterations avll -1.083785
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.436396e+05
      1       7.104683e+05      -2.331713e+05 |       32
      2       6.809024e+05      -2.956591e+04 |       32
      3       6.642494e+05      -1.665300e+04 |       32
      4       6.516123e+05      -1.263713e+04 |       32
      5       6.435011e+05      -8.111204e+03 |       32
      6       6.393042e+05      -4.196893e+03 |       32
      7       6.374823e+05      -1.821909e+03 |       32
      8       6.366776e+05      -8.046735e+02 |       32
      9       6.362643e+05      -4.132537e+02 |       32
     10       6.359886e+05      -2.757154e+02 |       32
     11       6.357775e+05      -2.111302e+02 |       32
     12       6.355983e+05      -1.792227e+02 |       32
     13       6.354248e+05      -1.734512e+02 |       32
     14       6.352334e+05      -1.913917e+02 |       32
     15       6.349354e+05      -2.980124e+02 |       32
     16       6.343561e+05      -5.792575e+02 |       32
     17       6.332730e+05      -1.083098e+03 |       32
     18       6.323659e+05      -9.071582e+02 |       31
     19       6.321367e+05      -2.291508e+02 |       32
     20       6.320913e+05      -4.541507e+01 |       31
     21       6.320788e+05      -1.249482e+01 |       27
     22       6.320730e+05      -5.835306e+00 |       27
     23       6.320678e+05      -5.182733e+00 |       20
     24       6.320659e+05      -1.900342e+00 |       23
     25       6.320625e+05      -3.411715e+00 |       24
     26       6.320597e+05      -2.810320e+00 |       16
     27       6.320582e+05      -1.437410e+00 |       16
     28       6.320570e+05      -1.222369e+00 |       19
     29       6.320557e+05      -1.287603e+00 |       20
     30       6.320548e+05      -9.196395e-01 |       12
     31       6.320542e+05      -6.421037e-01 |       14
     32       6.320536e+05      -5.304750e-01 |       12
     33       6.320531e+05      -5.560384e-01 |       16
     34       6.320522e+05      -8.842551e-01 |       15
     35       6.320515e+05      -6.808088e-01 |       17
     36       6.320510e+05      -4.906675e-01 |        9
     37       6.320507e+05      -3.473158e-01 |        5
     38       6.320506e+05      -1.191713e-01 |        4
     39       6.320504e+05      -1.991012e-01 |        6
     40       6.320501e+05      -2.912287e-01 |        2
     41       6.320500e+05      -4.180063e-02 |        2
     42       6.320500e+05      -3.220674e-02 |        0
     43       6.320500e+05       0.000000e+00 |        0
K-means converged with 43 iterations (objv = 632050.0044566977)
┌ Info: K-means with 32000 data points using 43 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.341097
[ Info: iteration 2, average log likelihood -1.308342
[ Info: iteration 3, average log likelihood -1.277900
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.243507
[ Info: iteration 5, average log likelihood -1.223082
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.170732
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.141048
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.136738
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.151944
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.131182
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.118636
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     12
│     13
│     18
│     21
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.085189
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      5
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.142951
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.133480
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.137541
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     12
│     13
│     21
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.092576
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│     15
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.115188
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.150412
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.119133
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     15
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.104713
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     11
│     12
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.137877
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.122243
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     18
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.101302
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     13
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.119274
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      5
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.130811
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.122750
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     15
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.092906
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.135188
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.118416
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.119481
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.111496
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.129259
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.115572
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     12
│     15
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.106579
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.135935
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     11
│     13
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.111891
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.127918
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.122854
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.119816
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     13
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.117810
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.132071
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.119979
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.111691
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     13
│     15
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.095874
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.136937
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│     18
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.113394
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.140643
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     13
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.100951
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     11
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.123165
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.103191
┌ Info: EM with 100000 data points 50 iterations avll -1.103191
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.117764    -0.168598      0.0610144    0.147291     0.104363    -0.0381139   -0.000222181   0.0519552   -0.0785392    0.0381501   -0.0117867   -0.00871662  -0.0541762   -0.063881    0.0655706    0.216151    -0.0752972    0.0544414   -0.199162      0.128636    0.150344    -0.213612     0.0798143    -0.143291    -0.0444442     0.0654473
  0.169929     0.0539771     0.0406419    0.00219014   0.0828196   -0.0910262   -0.0543555     0.0582578    0.110419    -0.05598      0.0768704   -0.0751526   -0.170949    -0.0379324   0.0988517   -0.0582779   -0.0314832    0.0721801   -0.074339     -0.059537   -0.0844121    0.0650446    0.0566728    -0.0186843   -0.076179     -0.137764
  0.0796224   -0.0711151     0.0939168   -0.061682    -0.0228076   -0.0254763   -0.04903       0.0208256    0.258413     0.0366581   -0.0626889   -0.0912109    0.128531     0.0166005   0.108114    -0.0340529    0.137569    -0.0830997   -0.0248605    -0.0886652   0.0792155   -0.105204     0.0839533     0.0692099    0.0976227     0.0920275
 -0.011226     0.0089095     0.00339295  -0.0211931    0.136143     0.169706     0.0884877    -0.00738785  -0.022653    -0.0506557    0.0709966   -0.0821336   -0.0358174   -0.0866104   0.176365     0.0342269    0.0323809   -0.126772    -0.00700736    0.0229255  -0.0820751    0.143822     0.0975482     0.202755     0.0652604    -0.157781
  0.0793665   -0.0685381    -0.049931     0.0178505    0.118615    -0.00625384   0.116811     -0.0902943    0.0711192   -0.0767671   -0.0397739    0.00848994  -0.0472408   -0.0151457   0.0462381    0.123922     0.0852333    0.123432    -0.14248      -0.0596186  -0.166028     0.0893654   -0.0845061    -0.10759     -0.0538614     0.0929998
 -0.0702449   -0.109049      0.147725    -0.106219     0.0468728    0.0989867   -0.102623      0.00752245  -0.103604     0.00733998  -0.0244836   -0.0881898    0.0565586    0.0190546  -0.243284     0.0420676   -0.118041     0.109331     0.228064      0.0483412  -0.0602195   -0.00474044  -0.185223      0.295883     0.0644987    -0.0442107
  0.174443    -0.131217     -0.182171     0.105004    -0.00860064   0.0451346   -0.00161545    0.0335145   -0.0255324   -0.0100799   -0.035838     0.0533039    0.0218403   -0.0981687   0.0947619    0.0246174   -0.106969    -0.0891292   -0.0579902    -0.0279822  -0.142825     0.00139667  -0.0375733    -0.112219    -0.0263987     0.000147726
 -0.0815543   -0.118714      0.169417     0.161349    -0.0290751    0.171553    -0.0855842     0.0469459    0.0139317    0.0684715   -0.0263877   -0.133649    -0.0287632    0.0352431   0.104057    -0.131347    -0.284671    -0.147953     0.110916     -0.109495   -0.0641737    0.0455794   -0.02507      -0.023062    -0.0428756     0.211935
 -0.0862128   -0.0942455     0.0335679    0.0272841   -0.0307722   -0.0851322    0.048554      0.10385     -0.0842485    0.076927    -0.0395386   -0.00793139   0.174965     0.0363721   0.197796     0.0530677    0.0108781    0.0145924   -0.00215557   -0.0556115   0.0626508   -0.0128581   -0.0545918    -0.0534673   -0.00551647   -0.136454
  0.0848461   -0.16985       0.0747075   -0.186028     0.0128618   -0.0519576   -0.00906231   -0.0560599    0.124731     0.0329593   -0.0198524    0.119537    -0.0453727   -0.148622    0.00914216  -0.233778    -0.0403991    0.0869352    0.0902866     0.21805     0.0332574   -0.0511184    0.0330859     0.0866661   -0.0360545     0.0688543
 -0.0444473   -0.0179584     0.089935     0.03405     -0.0577908    0.0586867   -0.0383548    -0.0525484   -0.113472     0.013926    -0.195793    -0.0613373   -0.0265093    0.0462403  -0.139637    -0.0259073    0.121768     0.095595    -0.0217583    -0.108156   -0.0226553    0.00215739  -0.200479      0.0187204    0.0985145    -0.00227495
 -0.0939982   -0.0826131     0.127788     0.239601    -0.0964444    0.0589655   -0.18082       0.10417     -0.00393913  -0.00107874   0.00438608  -0.14745     -0.0127035    0.0457851   0.152751    -0.164865    -0.123889    -0.118285     0.132421     -0.102846    0.00684077   0.016499     0.00715533    0.0171162   -0.0858623     0.0733571
  0.107486    -0.121239      0.0102434    0.0401503   -0.181822    -0.0711306   -0.0415268     0.173839    -0.0180716    0.021749     0.0284567    0.0126973   -0.0160882    0.097297    0.159239     0.0737138    0.0335249    0.00974959   0.0918781     0.12117    -0.0709422    0.107534     0.15254      -0.015765    -0.0107548     0.044568
  0.0477925    0.0205939     0.156209    -0.0819128   -0.248262    -0.0592388   -0.058212      0.0573024   -0.0294989    0.0940443   -0.0915982    0.0605286   -0.00305148   0.0747368   0.00694029  -0.0267599   -0.0911955   -0.043645     0.178478      0.126559    0.0631125   -0.0458783   -0.0209956    -0.0162295    0.0228126     0.040235
 -0.115627    -0.0329497    -0.0873571    0.0329515   -0.148138     0.0624766   -0.0502255     0.0519141    0.0947204   -0.0721691   -0.194881     0.0326375    0.120008    -0.164464    0.0956647    0.0432926    0.0422895    0.0249528   -0.0809845     0.115761    0.130896    -0.116589     0.0638078    -0.0992808   -0.0847478     0.0629456
 -0.045844    -0.291657     -0.0645254    0.057545     0.0235606   -0.0750303    0.19632      -0.00105641  -0.15758     -0.0678446    0.0952385   -0.0977429   -0.242463     0.0711214  -0.137577     0.00794198   0.00536389   0.135335     0.0111462    -0.0345746  -0.143723    -0.021315    -0.171284      0.0193273   -0.058652     -0.113133
 -0.0499449   -0.0547351     0.086756     0.0408171   -0.0791515    0.104513    -0.0596539    -0.0558443   -0.123427     0.064954    -0.256564    -0.0478696   -0.0294631    0.0853072  -0.117381    -0.0239464    0.136265     0.122135     0.0283099    -0.243403   -0.0205721   -0.0280543   -0.256077      0.0863946    0.138178     -0.0463396
 -0.105398    -0.0902063    -0.00425224  -0.25993      0.125968     0.0641921    0.0835002     0.130096     0.132895    -0.100408     0.0420854   -0.0127728    0.1943      -0.0436094  -0.0421493    0.0771782   -0.20524      0.0533119   -0.106156      0.0588154  -0.0877728   -0.110936    -0.0762549    -0.0127747   -0.0421617    -0.0820205
  0.228217    -0.0985719     0.00423928  -0.0298539    0.0444676   -0.0982167   -0.125776      0.024776    -0.0149373   -0.0945358    0.0407121   -0.0538535    0.128167     0.033917    0.0297982   -0.127665     0.102754     0.0646239    0.0155944     0.0957838  -0.0843143    0.0606006   -0.0460951     0.00567431   0.165324      0.112348
 -0.0412568    0.000467669  -0.4834       0.0295314   -0.10199     -0.0375567    0.485181      0.00187552   0.168478    -0.0205497   -0.234991     0.0778783   -0.0597198    0.089439   -0.52031      0.269071    -0.00843229   0.0048525   -0.115422      0.149661   -0.0350581   -0.00713983   0.00813514   -0.128652     0.103889      0.200348
 -0.12626     -0.0397055     0.0824845    0.110724     0.0373262   -0.0725033   -0.101446      0.0756218   -0.039119     0.00088734   0.00984741  -0.0392955   -0.0517787   -0.0340983   0.00846805  -0.0236367    0.111028    -0.0171175    0.0486761    -0.0406322   0.0854864    0.0233524    0.0308356     0.0627894    0.0791554    -0.0833657
  0.0558404   -0.0592108    -0.0705149    0.0498517   -0.0591222   -0.0999571    0.100309      0.0480923    0.00721196  -0.0356416   -0.123484     0.0293429   -0.00255805  -0.0151104   0.0685347    0.0834037    0.003378    -0.0280425   -0.0213861    -0.0558132   0.0390865   -0.159651    -0.0432524     0.0329493   -0.135067      0.122108
  0.00525392  -0.111383      0.11215     -0.0831962    0.0301564   -0.0204357   -0.0356226     0.129608    -0.162477    -0.0373562    0.0385908    0.0916743   -0.0276591   -0.0720613  -0.0235751    0.0194254   -0.0401273   -0.136802     0.0330314     0.21676     0.0319737    0.023482    -0.134119     -0.0165486    0.0745109     0.122894
 -0.0650382   -0.0970573    -0.275724    -0.0312176   -0.039417     0.0250537    0.274273      0.134912     0.116496    -0.00640381  -0.131862    -0.0159376   -0.0108959   -0.0116324   0.188656     0.107958    -0.152366    -0.102525     0.0532419     0.126077   -0.111156    -0.00609441   0.000926261  -0.0911938    0.050716      0.0717858
  0.0464626    0.0282623     0.0116307    0.0014185    0.0413173   -0.111888    -0.168234      0.0705086    0.133569    -0.0619645   -0.0452762   -0.0117922   -0.0293816    0.143173    0.121497    -0.0548492    0.162262    -0.0839362    0.000984711  -0.0498231  -0.00629876   0.137063    -0.195638     -0.204854    -0.000871148   0.011518
 -0.0560067   -0.0164802     0.135456     0.02901      0.188589    -0.0189481   -0.0895983    -0.0242559   -0.115236     0.0771084    0.021048    -0.205414     0.112378    -0.0905262  -0.00897054   0.0565876   -0.0277164    0.115276    -0.00203894    0.154798   -0.0371329   -0.0410326    0.139398      0.0749462    0.0181379     0.0286769
 -0.105524    -0.218425      0.0786326    0.0680664    0.0771686   -0.213922    -0.0363986     0.0479464    0.0396212   -0.00227615  -0.083224     0.0519148   -0.0954927    0.0701572  -0.0757436    0.175723     0.0792057    0.00138409   0.105427      0.0687709   0.0817329    0.00249684  -0.224767     -0.0347237   -0.0835938     0.239702
 -0.12406      0.10649       0.0986773   -0.0250402   -0.122368    -0.0185093    0.06675       0.0791998    0.018252     0.149037    -0.0979902   -0.00635639   0.0345625    0.0459629  -0.0833209    0.0731149    0.0954495   -0.0430218    0.0271211    -0.138917   -0.0160257   -0.256243     0.0412005    -0.0566956    0.0842422     0.0393647
  0.0791531    0.0629318    -0.0986476    0.0265091   -0.0153069   -0.00506932  -0.0100096    -0.0560792    0.110201     0.177203     0.00164379   0.0568682   -0.140052     0.0636118   0.0822553    0.0573636    0.00797474   0.0231299   -0.00114896    0.0316154  -0.0264531   -0.124553    -0.160482      0.0125568    7.72345e-5    0.00678482
 -0.0216511    0.19284      -0.0522373    0.0201567    0.058073    -0.0934512   -0.0350485    -0.00293609  -0.0884622    0.300494    -0.136699    -0.0526488    0.0243278    0.0617139  -0.0638069    0.0155461    0.00261771  -0.0707126    0.30056      -0.0918656   0.16409     -0.0495722    0.101441      0.0404505    0.0355169     0.215873
  0.292278     0.0227006    -0.164988    -0.0711663    0.120288    -0.0222097   -0.0583582     0.0793719    0.0764093   -0.0101228   -0.101281     0.16821      0.123678     0.0463101  -0.0215918   -0.0181678    0.051723     0.146917    -0.0193392     0.209643    0.0810566   -0.00147235   0.0236464     0.153483     0.161278     -0.0465565
 -0.0685661   -0.011787     -0.18543     -0.0871428   -0.138384    -0.0436222   -0.0342055     0.00351059   0.0470474   -0.224743     0.0114527    0.133083     0.111365     0.0911909  -0.182749    -0.171237     0.0428367   -0.0317599   -0.0882003    -0.16835     0.0747741   -0.285524     0.0491978    -0.0168894   -0.0608689     0.0648322[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.119132
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     13
│     15
│     17
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.088056
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     13
│     15
│     17
│     18
│     20
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.069697
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│     12
│     13
│     15
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.075809
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     15
│     17
│     18
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.095145
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      8
│     11
│     13
│      ⋮
│     18
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.076787
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     12
│     13
│     15
│     17
│     18
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.086250
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     13
│     15
│     17
│     18
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.067792
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      8
│     13
│     15
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.082138
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     13
│     15
│     17
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.099701
┌ Info: EM with 100000 data points 10 iterations avll -1.099701
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.122368     -0.0415315   -0.0494982     0.0241587   -0.108086     -0.0843969     0.261571    -0.0901914   -0.0669976     0.178481     -0.115198    -0.154535    -0.0458346    0.0120793   -0.115022     0.00116843   0.0766561    0.0125722   -0.0284737   -0.0186098    -0.043227   -0.0893588   -0.151215     0.0463708    0.0343363   -0.171285
 -0.00652432    0.0091065   -0.206065     -0.0256967    0.0685509    -0.13046      -0.0645712   -0.0965038   -0.00924301   -0.0314087     0.0817196    0.0440366    0.076708    -0.0762253   -0.0815378   -0.173667    -0.00648501  -0.087523     0.057103     0.0628874    -0.137637   -0.0667757    0.014744    -0.0884329    0.0147405    0.139342
  0.0531898     0.043957    -0.00661952   -0.0328965    0.0294457     0.0394988    -0.155976    -0.0218575   -0.0085291    -0.0629757     0.124424    -0.0520934    0.181429    -0.213586    -0.125078    -0.0779433    0.00436258   0.0206059    0.029147    -0.0591803    -0.0930323  -0.146035    -0.0538573    0.0328517   -0.0247455    0.0214722
 -0.0867875    -0.130951    -0.128855      0.144697     0.112978     -0.152294     -0.0257008    0.0562436    0.100479      0.0251238    -0.0355473   -0.0499503    0.107287     0.014779    -0.166388    -0.0386666    0.069709     0.04255      0.0797305    0.0891881     0.0648459   0.133143     0.177485     0.117715     0.0267995    0.0206571
  0.0164233     0.0345746   -0.049475     -0.154206     0.0910451     0.00941979   -0.0434465    0.0721187   -0.034777     -0.0553247     0.0197494    0.0699245    0.023562    -0.166029     0.0388937   -0.0453548    0.0185597    0.0989021   -0.0610879    0.105368      0.143667   -0.138401     0.0385426    0.160652     0.0374596    0.0274159
  0.0089269     0.124428     0.0679612    -0.189566     0.00653906   -0.026214      0.116687    -0.0384912   -0.0901915     0.0220111     0.134432     0.134627     0.0545295   -0.0597519   -0.193983     0.0661934   -0.143182     0.0112735   -0.0569939    0.0295512    -0.043453    0.0896409    0.0897368   -0.0341777   -0.0492557    0.0960296
 -0.0518684    -0.122734    -0.0267665     0.0344608    0.0367054    -0.0496383    -0.0485312    0.0830643    0.000154997  -0.037783      0.087047     0.0265759   -0.0298308   -0.0254922    0.0695228    0.134449     0.0244039   -0.130005    -0.0234998    0.104349     -0.0917997  -0.138259    -0.00433837   0.00639185  -0.0515571    0.125315
  0.125271      0.194182    -0.137297      0.041283     0.228431      0.000797106  -0.017877     0.0791206    0.00068387    0.151024     -0.0209896   -0.0462503    0.153379     0.0565037   -0.0177532   -0.196333     0.010227     0.0500659   -0.0751245   -0.131838      0.0685699   0.00890501   0.00486724  -0.200525     0.0440253   -0.00878334
 -0.13811      -0.15991      0.199422      0.114629    -0.000614698   0.0653842    -0.00907697  -0.20949      0.126806      0.0151623     0.0334504    0.0314091    0.0413958   -0.133497     0.266008     0.231787    -0.04335      0.0447927    0.0164604   -0.179914     -0.0103652  -0.066293    -0.0122577   -0.0994283    0.0146553   -0.0506534
  0.000125318  -0.00661948   0.0408898    -0.0373182    0.0316767    -0.0852721    -0.00874553  -0.0502358    0.0660693    -0.193257     -0.0135477   -0.0486051   -0.0338971    0.0920957   -0.0489379   -0.0249793    0.0771417    0.189232     0.0291401    0.0056304    -0.0123974  -0.0766661   -0.138282     0.0209505   -0.0403147   -0.144233
 -0.00381414   -0.0733278    0.100062     -0.0759767   -0.0884294    -0.0793877     0.0797988   -0.00382263   0.0926833    -0.0252236     0.144495     0.0819329   -0.111302    -0.0503452    0.164488     0.172251    -0.0799205   -0.024672    -0.00650581   0.0338508    -0.0512474   0.0647349    0.0661463    0.0588496    0.0432911   -0.0722172
  0.184789     -0.0310489    0.0372605     0.0623245   -0.0815451    -0.112621      0.15337     -0.212048    -0.0473477     0.0148613    -0.159891    -0.117082     0.00459338  -0.186304     0.10441      0.0665445    0.126725    -0.0100809   -0.136138     0.0570933    -0.170262    0.0936885    0.0652659   -0.0678296    0.0978679    0.0411074
  0.200364     -0.0250351    0.180631      0.110057     0.0650767     0.140075     -0.157759     0.0126606    0.105288     -0.159749      0.00520911  -0.188623     0.0861358    0.13498     -0.041719     0.0389927    0.187653    -0.191035     0.0528746    0.0787872     0.0770167  -0.0675537   -0.0426827    0.134641    -0.104316     0.0131798
 -0.12643       0.0459142   -0.0356668     0.170856    -0.203628      0.0826755     0.0277198   -0.220762     0.0513237     0.000622859   0.172564     0.0971158    0.0907965   -0.166508    -0.0908607    0.1017      -0.0761062    0.00429916   0.0322264   -0.0318438     0.0762791   0.0322136    0.0057414   -0.0494394   -0.0553231    0.162708
 -0.0070511     0.0478936    0.0720908    -0.324459     0.143118      0.0548969    -0.0402706   -0.00908877  -0.0196788     0.0459554     0.0583938   -0.059702    -0.0495718    0.14676      0.0991162   -0.0415796   -0.0526357    0.131766    -0.00631591  -0.0851052    -0.126088   -0.145411     0.0898111    0.02412     -0.0426829    0.00317854
 -0.0327485    -0.0748571    0.237794     -0.066727     0.121246     -0.0173468     0.0223635    0.0729438    0.0758692     0.101712      0.00462907  -0.120821    -0.123022    -0.0364809   -0.0696442    0.0646115   -0.02883     -0.00484406  -0.126039    -0.00507252   -0.0259636   0.0209904   -0.0237378    0.0712431   -0.0218855   -0.119205
  0.0451956     0.0979642   -0.144822     -0.0936866   -0.0767674     0.0903323    -0.038809     0.0380536    0.23678      -0.0603457     0.0935851    0.10596      0.0996392   -0.0153876   -0.0182118    0.0230311   -0.269627    -0.165746    -0.116629     0.0858578    -0.0325815   0.00525318   0.0758393   -0.0410878    0.0644412   -0.315267
  0.0270775     0.215702     0.0588132     0.0266199    0.306465      0.012431     -0.128532     0.0608546   -0.120959      0.0174168    -0.0030586   -0.118391    -0.0282155    0.0694292   -0.00304352   0.0817928    0.104232     0.00502488   0.057852     0.0930501     0.107653    0.10588     -0.134492    -0.0865561   -0.0662679    0.0206763
  0.0988217     0.128502     0.0563744    -0.0235719   -0.103812      0.04817       0.069907     0.147165    -0.0445929    -0.00970635    0.143671    -0.0509513   -0.0495445   -0.00213995   0.0329947   -0.0604304    0.143125     0.0114012    0.210635     0.000531165  -0.140446   -0.0160325   -0.242267     0.0368775   -0.0603409   -0.173505
 -0.10312      -0.150249    -0.0824821    -0.12303     -0.0910536     0.0568609    -0.0651031   -0.0393372   -0.117678      0.00253515   -0.0287304    0.167344     0.133987    -0.0282554    0.137167    -0.0703318   -0.00438335   0.0339802   -0.0322953    0.147687      0.0771242   0.0993591    0.0140359    0.0430955   -0.0948167   -0.0352064
  0.0782374    -0.0396514   -0.186013     -0.0938478    0.000166354   0.172967      0.0136366    0.0261093    0.0309082    -0.109956      0.0517791    0.00608105  -0.00880225  -0.00406036  -0.0333439    0.0616297   -0.0633032    0.067094    -0.0422666    0.0160926    -0.0464159  -0.0987851    0.137355     0.0225619    0.250452    -0.0154206
 -0.0535371     0.106713    -0.108455     -0.0287044    0.0726637     0.0474193     0.0350012   -0.176095    -0.0242185    -0.222589     -0.164302    -0.0383132    0.010092     0.0493101   -0.110505    -0.021233    -0.0807658    0.0904337    0.201209     0.0759461    -0.021581    0.219458    -0.0244376    0.0909556   -0.160595     0.0654584
  0.0986083     0.177973    -0.0554077     0.0600882   -0.0502333     0.0131058     0.073643     0.0659511   -0.0772029     0.00930512    0.0427017   -0.0998524   -0.0532473   -0.0554256    0.162076     0.0261742    0.138871     0.136782    -0.00701156  -0.175539      0.0376057   0.0111322    0.0190576   -0.10095     -0.037928    -0.153074
 -0.008301     -0.10376     -0.000472852   0.163003     0.136013      0.0782098     0.0123135    0.0046325    0.0868456     0.0906349     0.095387    -0.0698307    0.112586     0.0262517    0.00586232  -0.121795     0.0369053    0.107559     0.0739826   -0.11376       0.0373982  -0.059338     0.074343    -0.00027192   0.0373501    0.0975473
  0.0872453    -0.00120014  -0.126032      0.133703    -0.0990596     0.000529091   0.0190676    0.0376535   -0.00337023    0.0680852     0.153959     0.068585    -0.020047     0.0668618    0.101449     0.00468414   0.00404501  -0.209904     0.0162276   -0.0740591    -0.0930576  -0.204098    -0.011001    -0.190862     0.0412515    0.0339894
 -0.136688     -0.00713331  -0.0842922     0.0149777    0.0213378     0.0324046     0.0445852   -0.103636     0.0115297     0.0143416    -0.118227     0.122345    -0.0450499   -0.0445093   -0.00939267   0.0800578    0.109246     0.00416605  -0.166592     0.0720861    -0.0291686   0.0506536   -0.120075     0.0174996    0.0259556   -0.12631
 -0.129331     -0.0390354    0.0469904    -0.00744525  -0.13519      -0.126031     -0.0295136   -0.0971686    0.0149168    -0.072558      0.0879547   -0.047924     0.00896418   0.0530032   -0.175067    -0.0421091   -0.107691    -0.223408    -0.182019     0.145648      0.125243   -0.0167328   -0.153141    -0.0300673    0.202127    -0.042012
  0.0808133    -0.0573289   -0.0689071    -0.0662481   -0.0036357     0.181483      0.0271124   -0.0030065    0.0145046    -0.0242654    -0.216722    -0.036883     0.0704734    0.0233245    0.0102052    0.161721     0.104741     0.0610011    0.104277    -0.0223163     0.0222729   0.00614366  -0.0155487    0.0458473   -0.103214     0.0142535
 -0.12971       0.205469     0.194752     -0.117406     0.11136      -0.0402524     0.142263     0.00959263  -0.184448     -0.0581675    -0.0280491    0.0246416    0.0297538    0.115204    -0.145392    -0.132271    -0.100552    -0.0347715    5.36804e-5  -0.068932     -0.0175786   0.0179684    0.185494    -0.0576892    0.224582     0.0251185
 -0.285154     -0.0191206    0.0788881     0.123613    -0.103357     -0.0195592     0.108        0.0272384   -0.176525      0.00296615   -0.0730863    0.00724777  -0.158705     0.218986     0.0373846    0.0115595    0.177497    -0.0808492   -0.120881     0.0174907    -0.0201351  -0.0167986    0.0662062   -0.0711523    0.102949     0.0110562
  0.120715      0.0211734   -0.141463     -0.0700863   -0.0312539    -0.119646      0.109268     0.0300854   -0.0150409    -0.112378     -0.112152    -0.112532    -0.172165    -0.0574768   -0.0626219   -0.00792162   0.00322421  -0.0424193   -0.139901    -0.155107     -0.148433    0.0734237    0.0149327   -0.0119086    0.00286227  -0.231863
  0.0778176    -0.12157      0.0742236     0.0413764    0.00843374    0.0250645    -0.0348874    0.0234694   -0.288822     -0.0456069     0.0114518    0.0714879    0.00234875  -0.119887    -0.0645543    0.164177    -0.00680991   0.0332428    0.17209      0.119783      0.0539251   0.0178407    0.0479916   -0.0639433    0.0412345   -0.0361464kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4225721326892964
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422591
[ Info: iteration 2, average log likelihood -1.422529
[ Info: iteration 3, average log likelihood -1.422483
[ Info: iteration 4, average log likelihood -1.422427
[ Info: iteration 5, average log likelihood -1.422355
[ Info: iteration 6, average log likelihood -1.422264
[ Info: iteration 7, average log likelihood -1.422149
[ Info: iteration 8, average log likelihood -1.421996
[ Info: iteration 9, average log likelihood -1.421759
[ Info: iteration 10, average log likelihood -1.421337
[ Info: iteration 11, average log likelihood -1.420595
[ Info: iteration 12, average log likelihood -1.419531
[ Info: iteration 13, average log likelihood -1.418445
[ Info: iteration 14, average log likelihood -1.417691
[ Info: iteration 15, average log likelihood -1.417305
[ Info: iteration 16, average log likelihood -1.417138
[ Info: iteration 17, average log likelihood -1.417069
[ Info: iteration 18, average log likelihood -1.417040
[ Info: iteration 19, average log likelihood -1.417028
[ Info: iteration 20, average log likelihood -1.417023
[ Info: iteration 21, average log likelihood -1.417021
[ Info: iteration 22, average log likelihood -1.417020
[ Info: iteration 23, average log likelihood -1.417019
[ Info: iteration 24, average log likelihood -1.417019
[ Info: iteration 25, average log likelihood -1.417018
[ Info: iteration 26, average log likelihood -1.417018
[ Info: iteration 27, average log likelihood -1.417018
[ Info: iteration 28, average log likelihood -1.417018
[ Info: iteration 29, average log likelihood -1.417018
[ Info: iteration 30, average log likelihood -1.417018
[ Info: iteration 31, average log likelihood -1.417017
[ Info: iteration 32, average log likelihood -1.417017
[ Info: iteration 33, average log likelihood -1.417017
[ Info: iteration 34, average log likelihood -1.417017
[ Info: iteration 35, average log likelihood -1.417017
[ Info: iteration 36, average log likelihood -1.417017
[ Info: iteration 37, average log likelihood -1.417017
[ Info: iteration 38, average log likelihood -1.417017
[ Info: iteration 39, average log likelihood -1.417017
[ Info: iteration 40, average log likelihood -1.417017
[ Info: iteration 41, average log likelihood -1.417017
[ Info: iteration 42, average log likelihood -1.417017
[ Info: iteration 43, average log likelihood -1.417017
[ Info: iteration 44, average log likelihood -1.417017
[ Info: iteration 45, average log likelihood -1.417017
[ Info: iteration 46, average log likelihood -1.417017
[ Info: iteration 47, average log likelihood -1.417017
[ Info: iteration 48, average log likelihood -1.417017
[ Info: iteration 49, average log likelihood -1.417017
[ Info: iteration 50, average log likelihood -1.417017
┌ Info: EM with 100000 data points 50 iterations avll -1.417017
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4225905051155037
│     -1.4225293575823976
│      ⋮
└     -1.4170165873406737
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417035
[ Info: iteration 2, average log likelihood -1.416972
[ Info: iteration 3, average log likelihood -1.416924
[ Info: iteration 4, average log likelihood -1.416866
[ Info: iteration 5, average log likelihood -1.416793
[ Info: iteration 6, average log likelihood -1.416704
[ Info: iteration 7, average log likelihood -1.416606
[ Info: iteration 8, average log likelihood -1.416508
[ Info: iteration 9, average log likelihood -1.416422
[ Info: iteration 10, average log likelihood -1.416353
[ Info: iteration 11, average log likelihood -1.416301
[ Info: iteration 12, average log likelihood -1.416263
[ Info: iteration 13, average log likelihood -1.416233
[ Info: iteration 14, average log likelihood -1.416210
[ Info: iteration 15, average log likelihood -1.416191
[ Info: iteration 16, average log likelihood -1.416174
[ Info: iteration 17, average log likelihood -1.416159
[ Info: iteration 18, average log likelihood -1.416146
[ Info: iteration 19, average log likelihood -1.416134
[ Info: iteration 20, average log likelihood -1.416123
[ Info: iteration 21, average log likelihood -1.416113
[ Info: iteration 22, average log likelihood -1.416104
[ Info: iteration 23, average log likelihood -1.416096
[ Info: iteration 24, average log likelihood -1.416088
[ Info: iteration 25, average log likelihood -1.416080
[ Info: iteration 26, average log likelihood -1.416073
[ Info: iteration 27, average log likelihood -1.416067
[ Info: iteration 28, average log likelihood -1.416060
[ Info: iteration 29, average log likelihood -1.416054
[ Info: iteration 30, average log likelihood -1.416048
[ Info: iteration 31, average log likelihood -1.416042
[ Info: iteration 32, average log likelihood -1.416035
[ Info: iteration 33, average log likelihood -1.416029
[ Info: iteration 34, average log likelihood -1.416023
[ Info: iteration 35, average log likelihood -1.416017
[ Info: iteration 36, average log likelihood -1.416010
[ Info: iteration 37, average log likelihood -1.416004
[ Info: iteration 38, average log likelihood -1.415997
[ Info: iteration 39, average log likelihood -1.415991
[ Info: iteration 40, average log likelihood -1.415984
[ Info: iteration 41, average log likelihood -1.415978
[ Info: iteration 42, average log likelihood -1.415972
[ Info: iteration 43, average log likelihood -1.415965
[ Info: iteration 44, average log likelihood -1.415959
[ Info: iteration 45, average log likelihood -1.415953
[ Info: iteration 46, average log likelihood -1.415948
[ Info: iteration 47, average log likelihood -1.415943
[ Info: iteration 48, average log likelihood -1.415938
[ Info: iteration 49, average log likelihood -1.415933
[ Info: iteration 50, average log likelihood -1.415928
┌ Info: EM with 100000 data points 50 iterations avll -1.415928
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4170347375989176
│     -1.4169718079663283
│      ⋮
└     -1.4159284809395571
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415935
[ Info: iteration 2, average log likelihood -1.415863
[ Info: iteration 3, average log likelihood -1.415791
[ Info: iteration 4, average log likelihood -1.415699
[ Info: iteration 5, average log likelihood -1.415581
[ Info: iteration 6, average log likelihood -1.415438
[ Info: iteration 7, average log likelihood -1.415282
[ Info: iteration 8, average log likelihood -1.415131
[ Info: iteration 9, average log likelihood -1.414999
[ Info: iteration 10, average log likelihood -1.414891
[ Info: iteration 11, average log likelihood -1.414805
[ Info: iteration 12, average log likelihood -1.414737
[ Info: iteration 13, average log likelihood -1.414683
[ Info: iteration 14, average log likelihood -1.414641
[ Info: iteration 15, average log likelihood -1.414606
[ Info: iteration 16, average log likelihood -1.414579
[ Info: iteration 17, average log likelihood -1.414556
[ Info: iteration 18, average log likelihood -1.414537
[ Info: iteration 19, average log likelihood -1.414520
[ Info: iteration 20, average log likelihood -1.414506
[ Info: iteration 21, average log likelihood -1.414493
[ Info: iteration 22, average log likelihood -1.414481
[ Info: iteration 23, average log likelihood -1.414471
[ Info: iteration 24, average log likelihood -1.414461
[ Info: iteration 25, average log likelihood -1.414451
[ Info: iteration 26, average log likelihood -1.414442
[ Info: iteration 27, average log likelihood -1.414433
[ Info: iteration 28, average log likelihood -1.414424
[ Info: iteration 29, average log likelihood -1.414415
[ Info: iteration 30, average log likelihood -1.414406
[ Info: iteration 31, average log likelihood -1.414397
[ Info: iteration 32, average log likelihood -1.414387
[ Info: iteration 33, average log likelihood -1.414377
[ Info: iteration 34, average log likelihood -1.414367
[ Info: iteration 35, average log likelihood -1.414357
[ Info: iteration 36, average log likelihood -1.414346
[ Info: iteration 37, average log likelihood -1.414336
[ Info: iteration 38, average log likelihood -1.414325
[ Info: iteration 39, average log likelihood -1.414314
[ Info: iteration 40, average log likelihood -1.414303
[ Info: iteration 41, average log likelihood -1.414292
[ Info: iteration 42, average log likelihood -1.414282
[ Info: iteration 43, average log likelihood -1.414271
[ Info: iteration 44, average log likelihood -1.414261
[ Info: iteration 45, average log likelihood -1.414252
[ Info: iteration 46, average log likelihood -1.414243
[ Info: iteration 47, average log likelihood -1.414234
[ Info: iteration 48, average log likelihood -1.414226
[ Info: iteration 49, average log likelihood -1.414218
[ Info: iteration 50, average log likelihood -1.414211
┌ Info: EM with 100000 data points 50 iterations avll -1.414211
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4159353279700715
│     -1.4158630512772936
│      ⋮
└     -1.4142107896666645
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414212
[ Info: iteration 2, average log likelihood -1.414157
[ Info: iteration 3, average log likelihood -1.414108
[ Info: iteration 4, average log likelihood -1.414053
[ Info: iteration 5, average log likelihood -1.413987
[ Info: iteration 6, average log likelihood -1.413906
[ Info: iteration 7, average log likelihood -1.413809
[ Info: iteration 8, average log likelihood -1.413699
[ Info: iteration 9, average log likelihood -1.413580
[ Info: iteration 10, average log likelihood -1.413461
[ Info: iteration 11, average log likelihood -1.413348
[ Info: iteration 12, average log likelihood -1.413247
[ Info: iteration 13, average log likelihood -1.413158
[ Info: iteration 14, average log likelihood -1.413080
[ Info: iteration 15, average log likelihood -1.413014
[ Info: iteration 16, average log likelihood -1.412956
[ Info: iteration 17, average log likelihood -1.412905
[ Info: iteration 18, average log likelihood -1.412860
[ Info: iteration 19, average log likelihood -1.412819
[ Info: iteration 20, average log likelihood -1.412782
[ Info: iteration 21, average log likelihood -1.412748
[ Info: iteration 22, average log likelihood -1.412716
[ Info: iteration 23, average log likelihood -1.412687
[ Info: iteration 24, average log likelihood -1.412659
[ Info: iteration 25, average log likelihood -1.412632
[ Info: iteration 26, average log likelihood -1.412607
[ Info: iteration 27, average log likelihood -1.412584
[ Info: iteration 28, average log likelihood -1.412561
[ Info: iteration 29, average log likelihood -1.412540
[ Info: iteration 30, average log likelihood -1.412520
[ Info: iteration 31, average log likelihood -1.412501
[ Info: iteration 32, average log likelihood -1.412483
[ Info: iteration 33, average log likelihood -1.412466
[ Info: iteration 34, average log likelihood -1.412450
[ Info: iteration 35, average log likelihood -1.412434
[ Info: iteration 36, average log likelihood -1.412419
[ Info: iteration 37, average log likelihood -1.412405
[ Info: iteration 38, average log likelihood -1.412392
[ Info: iteration 39, average log likelihood -1.412379
[ Info: iteration 40, average log likelihood -1.412367
[ Info: iteration 41, average log likelihood -1.412355
[ Info: iteration 42, average log likelihood -1.412343
[ Info: iteration 43, average log likelihood -1.412332
[ Info: iteration 44, average log likelihood -1.412322
[ Info: iteration 45, average log likelihood -1.412312
[ Info: iteration 46, average log likelihood -1.412302
[ Info: iteration 47, average log likelihood -1.412292
[ Info: iteration 48, average log likelihood -1.412282
[ Info: iteration 49, average log likelihood -1.412273
[ Info: iteration 50, average log likelihood -1.412264
┌ Info: EM with 100000 data points 50 iterations avll -1.412264
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4142116547427117
│     -1.4141572161540983
│      ⋮
└     -1.4122640827503998
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412263
[ Info: iteration 2, average log likelihood -1.412192
[ Info: iteration 3, average log likelihood -1.412121
[ Info: iteration 4, average log likelihood -1.412032
[ Info: iteration 5, average log likelihood -1.411918
[ Info: iteration 6, average log likelihood -1.411775
[ Info: iteration 7, average log likelihood -1.411605
[ Info: iteration 8, average log likelihood -1.411417
[ Info: iteration 9, average log likelihood -1.411223
[ Info: iteration 10, average log likelihood -1.411033
[ Info: iteration 11, average log likelihood -1.410857
[ Info: iteration 12, average log likelihood -1.410696
[ Info: iteration 13, average log likelihood -1.410553
[ Info: iteration 14, average log likelihood -1.410428
[ Info: iteration 15, average log likelihood -1.410318
[ Info: iteration 16, average log likelihood -1.410222
[ Info: iteration 17, average log likelihood -1.410138
[ Info: iteration 18, average log likelihood -1.410065
[ Info: iteration 19, average log likelihood -1.410001
[ Info: iteration 20, average log likelihood -1.409944
[ Info: iteration 21, average log likelihood -1.409894
[ Info: iteration 22, average log likelihood -1.409848
[ Info: iteration 23, average log likelihood -1.409807
[ Info: iteration 24, average log likelihood -1.409770
[ Info: iteration 25, average log likelihood -1.409735
[ Info: iteration 26, average log likelihood -1.409703
[ Info: iteration 27, average log likelihood -1.409673
[ Info: iteration 28, average log likelihood -1.409645
[ Info: iteration 29, average log likelihood -1.409619
[ Info: iteration 30, average log likelihood -1.409594
[ Info: iteration 31, average log likelihood -1.409570
[ Info: iteration 32, average log likelihood -1.409547
[ Info: iteration 33, average log likelihood -1.409526
[ Info: iteration 34, average log likelihood -1.409505
[ Info: iteration 35, average log likelihood -1.409486
[ Info: iteration 36, average log likelihood -1.409467
[ Info: iteration 37, average log likelihood -1.409449
[ Info: iteration 38, average log likelihood -1.409431
[ Info: iteration 39, average log likelihood -1.409415
[ Info: iteration 40, average log likelihood -1.409399
[ Info: iteration 41, average log likelihood -1.409384
[ Info: iteration 42, average log likelihood -1.409369
[ Info: iteration 43, average log likelihood -1.409355
[ Info: iteration 44, average log likelihood -1.409341
[ Info: iteration 45, average log likelihood -1.409328
[ Info: iteration 46, average log likelihood -1.409315
[ Info: iteration 47, average log likelihood -1.409303
[ Info: iteration 48, average log likelihood -1.409291
[ Info: iteration 49, average log likelihood -1.409279
[ Info: iteration 50, average log likelihood -1.409268
┌ Info: EM with 100000 data points 50 iterations avll -1.409268
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4122632082279463
│     -1.4121923393461786
│      ⋮
└     -1.4092678180314113
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4225721326892964
│     -1.4225905051155037
│     -1.4225293575823976
│     -1.4224831628645696
│      ⋮
│     -1.4092908319275776
│     -1.4092791717141424
└     -1.4092678180314113
32×26 Array{Float64,2}:
 -0.105577    -0.357526     0.0880717   0.135509    -0.473941    0.266033    0.216258     0.50811    -0.45737    -0.768511     0.675389     -0.443228    0.192308     -0.474088   -0.204881    0.78705     -0.293951   -0.0157957   0.0809475   -0.42767      -0.864977     0.0605741   -0.192942     0.277032     0.423997    -0.378792
  0.479976    -0.275345     0.435668    0.208119     0.635597    0.0588597  -0.658958     0.356143   -0.118331   -0.0297229   -0.429659     -0.228621    0.466339     -0.361846    0.232293    0.326731    -0.158778   -0.414207   -0.147023    -0.172034     -0.943794    -0.158006     0.472564     0.12249      0.142002    -0.0556633
  0.425526    -0.288969     0.136328   -0.292944    -0.473216   -0.101691   -0.665585     0.201954    0.347642   -0.424777     0.250498      0.0363686   0.621545     -0.181362    0.256203    0.0943307    0.0427691  -0.569493    0.0408411   -0.954927      0.0186474    0.814993     0.407347    -0.589549     0.162481     0.271847
  0.00339075  -0.304973    -0.256755   -0.253568    -0.220964   -0.658589   -0.0328163    0.143522    0.565436   -0.170371     0.314669     -0.0872517   0.314003      0.0156119   0.0886944  -0.0196797   -0.329604    0.163773   -0.431324     0.28848      -0.261592     0.679143    -0.220206     0.813361     0.580116     0.223552
 -0.411386    -0.800208     0.0613272   0.184366    -0.0890965   0.28381    -0.440642    -0.619339   -0.217355    0.104691     0.156823      0.377308    0.0387984     0.860948    0.330656   -0.154321    -0.244486   -0.109009   -0.902162     0.0305272    -0.0556343    0.0883182    0.111061    -0.203814    -0.127572     0.102269
  0.334594    -0.624593    -0.232559    0.119524     0.499063   -0.237961   -0.164011     0.320403   -0.519062   -0.411477    -0.00239665    0.136376   -0.000103609   0.138156    0.820983   -0.0259138   -0.125557    0.127822   -0.385415    -0.275971      0.307236    -0.286521     0.243382    -0.135418     0.324625     0.499158
  0.196371     0.237838    -0.532892    0.417531     0.91118     0.106121   -0.302388     0.422465    0.283486   -0.44452      0.243781     -0.131072   -0.180903      0.106561   -0.306402   -0.363004     0.0413176   0.270084   -0.180217     0.186646     -0.137791    -0.213625     0.135566    -0.156758     0.249575     0.404265
 -0.508819    -0.213163    -0.406936    0.606387     0.536767   -0.356451    0.564364    -0.286775   -0.435968    0.320788    -0.156475      0.310853   -0.434885     -0.0118762  -0.400227   -0.36629     -0.281905    0.0404034  -0.0627503    0.669467     -0.242415    -0.440842    -0.770637     0.318917    -0.0696271    0.209539
 -0.159266    -0.43106     -0.991598    0.231502    -0.67073    -0.465762    0.631958    -0.23896     0.379165   -0.2302      -0.997061     -0.046802    0.426244      0.353718   -0.216174    0.7184      -0.134774    1.06034    -0.21024      0.536741      0.477791     0.245039     0.0840171   -0.401716    -0.347719    -0.610199
 -0.129001    -0.220617    -0.612548   -0.624057    -0.824745   -0.370866    0.413628    -0.459833   -0.436505    0.38894      0.478508     -0.237824    0.12755       0.207204   -0.136582    0.931755    -0.566122    0.263486    0.182033    -0.0825623     0.237329     0.405845    -0.182256    -0.413674     0.00391502  -0.0652029
  0.0724543    0.103075    -0.843463   -0.0960633   -0.421388   -0.254817    0.139555    -0.89094     0.625905   -0.119951     0.228524      0.536053    0.191656      0.381192    0.273879   -0.106733    -0.650063   -0.165015    0.770388     0.201957     -0.0743095   -0.0263453    0.210814     0.239714    -0.0678807   -0.0454512
  0.0620343    0.220258     0.677379   -0.787287    -0.736554    0.115626    0.489547    -0.461232   -0.165955    0.495469    -0.265632      0.163872    0.609538     -0.293947    0.0765549  -0.00539814  -0.0200537  -0.110344    0.0782847   -0.168214      0.131094     0.133489     0.025885     0.21896     -0.459492    -0.612445
  0.140681     0.231883    -0.0572376   0.461809     0.178667    0.721245    0.185783    -0.0575283  -0.696275   -0.0709415   -0.254587     -0.0784833  -0.434347     -0.13124    -0.193312    0.011024     0.457511   -0.179079    0.348164    -0.195187      0.084806    -0.672541     0.118658    -0.748143    -0.556784    -0.342209
 -0.322187     0.0203149    0.0337294   0.264466    -0.103741    0.531755   -0.830004    -0.586688   -0.130281    0.385534     0.231259      0.0373808   0.170629      0.233643   -0.690197    0.636076    -0.0602362  -0.652373    0.353942    -0.0126879     0.305671    -0.351405     0.0214248   -0.601343     0.0550436   -0.788795
 -0.117992     0.246327    -0.183006   -0.0638945   -0.0147335  -0.0491225   0.098993     0.23844     0.020335    0.0184251    0.00583515   -0.847292    0.083174     -0.150727   -0.140603    0.10657      0.0844778  -0.0224635  -0.0246477    0.0822851    -0.0770955   -0.00150628  -0.202376    -0.155674     0.0704715   -0.0514051
  0.0922741   -0.00881621   0.0930344   0.0466997    0.227827    0.0992408  -0.0664013   -0.166445    0.0396062  -0.00103145  -0.0384198     0.869683   -0.267943      0.224823    0.161914   -0.340038     0.120175    0.161766    0.0667196    0.029315      0.236673    -0.28042      0.0889631    0.177886    -0.103704     0.0803763
 -0.348675     0.10849      0.0258283  -0.582656     0.353302    0.0183674  -0.00808357  -0.579067   -0.0498199  -0.432591    -0.0123378    -0.787773    0.584121      0.0807454   0.473852    0.0883996    0.323953   -0.234609    0.0200375   -0.0505289    -0.00012622  -0.162541     0.515688    -0.180685     0.0638744   -0.182134
  0.528275     0.984252     0.124943   -0.880629     0.028674   -0.119925    0.417327     0.515696    0.338544   -0.0252327    0.113277     -0.656242    0.221244     -0.661971   -0.0739579   0.294813     0.038814    0.0658645   0.856593     0.140173      0.0181446   -0.24673      0.258658    -0.0297823    0.26746     -0.133236
  0.533856    -0.119578     0.0427165  -0.106288     0.0810056   0.136534    0.704536     0.585722    0.310081   -0.164675    -0.459105      0.106999   -0.903801     -0.124112    0.775964   -0.560145     0.258622    0.747059    0.0146756    0.1369       -0.0992236    0.016014    -0.0805294    0.60711     -0.0519908    0.239186
 -0.0305171    0.0361697   -0.203245   -0.620186     0.275448   -0.381181    0.387997     0.342168    0.0711236  -0.257875    -0.27212       0.0834774   0.694493     -0.0681214   0.134352   -0.299539    -0.0226351   0.417657    0.0259218   -0.157132     -0.3697       0.109378     0.288643     0.131619    -0.341668     0.510258
  0.0161055   -0.0271306    0.0801324   0.0820746    0.313582    0.131143   -0.0735171    0.127637   -0.280737   -0.249439    -0.000120255   0.0722121  -0.0514123    -0.315575   -0.0804819  -0.182189    -0.0841657  -0.151458   -0.090147    -0.0558815    -0.225372    -0.21845     -0.00328751  -0.0514351   -0.0651524    0.156777
  0.0464102    0.0744602   -0.0172348  -0.0938911    0.0390152  -0.0209417  -0.0384595   -0.0685841   0.236358    0.0524482    0.120167      0.0310183   0.0492682     0.13278    -0.0486693  -0.0130129    0.0865696   0.193      -0.0246487    0.0816933     0.125596     0.0609725    0.0880088    0.00354038   0.0850408   -0.0757469
 -0.0945338   -0.221983    -0.254059    0.240919    -0.455324   -0.0681209   0.171635     0.120626    0.0419379   0.0714008    0.028627     -0.402958   -0.0248092     0.155516    0.228727    0.520884    -0.150727   -0.139357    0.154646    -0.0736637    -0.128735     0.297018    -0.28627     -0.00239687  -0.0722237   -0.185243
 -0.342574    -0.319534    -0.0261701  -0.334779    -0.325909   -0.166071   -0.00935775  -0.434746   -0.437781    0.00689395  -0.17419       0.479907    0.369685     -0.0560374   0.0392466   0.272339    -0.138294   -0.0284349   0.112232    -0.0198879     0.242692     0.170095    -0.0726372   -0.126753    -0.00853601  -0.126275
 -0.418214     0.0796593    1.04569     0.541498    -0.305542    0.766344   -0.156104    -0.530162   -0.659971   -0.660738     0.462913     -0.186188   -0.309724      0.223578   -0.173735   -0.554504     0.358914   -0.919232    0.0313325    0.0810071     0.16184      0.152486    -1.02543      0.351891    -0.167118     0.479286
 -0.758505     0.0442195    0.600628    0.23586     -0.273964    0.0217766   0.0824754    0.400516   -0.0495026   0.62018     -0.146025     -0.445784   -0.295359     -0.365234   -0.31553     0.178276     0.274228   -0.514693   -0.465879     0.0144208    -0.41123      0.297069    -0.292499     0.215876    -0.303505     0.0779864
 -0.184663     0.0451672    0.0683028  -0.00202075   0.0683185   0.262971   -0.00372006   0.0395908   0.213481   -0.191709     0.519616      0.217746   -0.439295     -0.116635   -0.821982    0.3296      -0.134596    0.673357   -0.00941402   0.631836      0.292251     0.252707    -0.167551    -0.0707775    0.0819392    0.0248507
 -0.573958    -0.294694     0.658264    0.0144535    0.0988863   0.231496    0.233083     0.364958   -0.17068    -0.151985     0.12853      -0.0769686  -0.189557     -0.104302   -0.27712     0.0752141    0.814623    0.496065   -0.0690845    0.145066      0.571569     0.299435     0.0698684   -0.289274     0.219581     0.0405208
  0.627548    -0.0790213    0.0311518   0.393976    -0.265537    0.45642     0.0451291   -0.180498    0.339859    0.175965     0.284468      0.0809471  -0.24527       0.317556    0.0835573  -0.289277     0.168348   -0.218121   -0.300054    -0.272965     -0.202797    -0.278423     0.213378     0.340744     0.205799    -0.551907
  0.574296     0.150996     0.620089    0.0839282   -0.288603    0.101673   -0.0288639    0.195701   -0.0662669   0.498891     0.265081      0.93229    -0.671741     -0.402194   -0.0277709  -0.14102     -0.0746214  -0.478453    0.217094    -0.383118     -0.120989     0.0768363   -0.00527382   0.196569     0.239666     0.300183
  0.342529     0.787062    -0.21396    -0.0359682   -0.164661   -0.371854   -0.203998    -0.281909   -0.0588021   0.50073     -0.21054      -0.233408   -0.00312995    0.180544   -0.153148   -0.192445    -0.446897   -0.127685   -0.146066     0.185578      0.050123    -0.452356    -0.258368     0.0133042    0.223385    -0.35348
  0.0994874    0.712241    -0.090177    0.110131     0.296741   -0.180936   -0.0252327   -0.199479    0.458897    0.316541    -0.479121     -0.031283   -0.211774     -0.0230489  -0.071483   -0.311337     0.601828    0.0402722   0.427845    -0.000287971   0.482359    -0.174211    -0.143717    -0.144601    -0.364185    -0.257383[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409257
[ Info: iteration 2, average log likelihood -1.409246
[ Info: iteration 3, average log likelihood -1.409235
[ Info: iteration 4, average log likelihood -1.409225
[ Info: iteration 5, average log likelihood -1.409215
[ Info: iteration 6, average log likelihood -1.409205
[ Info: iteration 7, average log likelihood -1.409195
[ Info: iteration 8, average log likelihood -1.409185
[ Info: iteration 9, average log likelihood -1.409176
[ Info: iteration 10, average log likelihood -1.409166
┌ Info: EM with 100000 data points 10 iterations avll -1.409166
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.210680e+05
      1       7.063341e+05      -2.147339e+05 |       32
      2       6.917221e+05      -1.461194e+04 |       32
      3       6.862144e+05      -5.507792e+03 |       32
      4       6.833677e+05      -2.846653e+03 |       32
      5       6.815634e+05      -1.804299e+03 |       32
      6       6.802997e+05      -1.263725e+03 |       32
      7       6.792602e+05      -1.039491e+03 |       32
      8       6.784042e+05      -8.560111e+02 |       32
      9       6.777489e+05      -6.553086e+02 |       32
     10       6.772253e+05      -5.235755e+02 |       32
     11       6.768036e+05      -4.216818e+02 |       32
     12       6.764146e+05      -3.889834e+02 |       32
     13       6.760667e+05      -3.479679e+02 |       32
     14       6.757713e+05      -2.953461e+02 |       32
     15       6.754950e+05      -2.763206e+02 |       32
     16       6.752502e+05      -2.447705e+02 |       32
     17       6.750208e+05      -2.293883e+02 |       32
     18       6.748223e+05      -1.985768e+02 |       32
     19       6.746431e+05      -1.791630e+02 |       32
     20       6.744872e+05      -1.558524e+02 |       32
     21       6.743455e+05      -1.417818e+02 |       32
     22       6.742117e+05      -1.337621e+02 |       32
     23       6.740793e+05      -1.324274e+02 |       32
     24       6.739541e+05      -1.251798e+02 |       32
     25       6.738339e+05      -1.201511e+02 |       32
     26       6.737148e+05      -1.190928e+02 |       32
     27       6.736032e+05      -1.115978e+02 |       32
     28       6.734919e+05      -1.113595e+02 |       32
     29       6.733804e+05      -1.114396e+02 |       32
     30       6.732643e+05      -1.161397e+02 |       32
     31       6.731613e+05      -1.029954e+02 |       32
     32       6.730756e+05      -8.569044e+01 |       32
     33       6.729989e+05      -7.668761e+01 |       32
     34       6.729250e+05      -7.395240e+01 |       32
     35       6.728521e+05      -7.291134e+01 |       32
     36       6.727874e+05      -6.469771e+01 |       32
     37       6.727290e+05      -5.834870e+01 |       32
     38       6.726755e+05      -5.351832e+01 |       32
     39       6.726232e+05      -5.232064e+01 |       32
     40       6.725820e+05      -4.117126e+01 |       32
     41       6.725396e+05      -4.236665e+01 |       32
     42       6.725023e+05      -3.734585e+01 |       32
     43       6.724677e+05      -3.463744e+01 |       32
     44       6.724331e+05      -3.458460e+01 |       32
     45       6.723971e+05      -3.595469e+01 |       32
     46       6.723577e+05      -3.942079e+01 |       32
     47       6.723217e+05      -3.604357e+01 |       32
     48       6.722875e+05      -3.411987e+01 |       32
     49       6.722582e+05      -2.931617e+01 |       32
     50       6.722302e+05      -2.801123e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672230.2122094559)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421142
[ Info: iteration 2, average log likelihood -1.416258
[ Info: iteration 3, average log likelihood -1.414947
[ Info: iteration 4, average log likelihood -1.413950
[ Info: iteration 5, average log likelihood -1.412858
[ Info: iteration 6, average log likelihood -1.411834
[ Info: iteration 7, average log likelihood -1.411140
[ Info: iteration 8, average log likelihood -1.410759
[ Info: iteration 9, average log likelihood -1.410546
[ Info: iteration 10, average log likelihood -1.410411
[ Info: iteration 11, average log likelihood -1.410313
[ Info: iteration 12, average log likelihood -1.410236
[ Info: iteration 13, average log likelihood -1.410170
[ Info: iteration 14, average log likelihood -1.410113
[ Info: iteration 15, average log likelihood -1.410061
[ Info: iteration 16, average log likelihood -1.410013
[ Info: iteration 17, average log likelihood -1.409967
[ Info: iteration 18, average log likelihood -1.409923
[ Info: iteration 19, average log likelihood -1.409879
[ Info: iteration 20, average log likelihood -1.409836
[ Info: iteration 21, average log likelihood -1.409793
[ Info: iteration 22, average log likelihood -1.409750
[ Info: iteration 23, average log likelihood -1.409707
[ Info: iteration 24, average log likelihood -1.409665
[ Info: iteration 25, average log likelihood -1.409624
[ Info: iteration 26, average log likelihood -1.409586
[ Info: iteration 27, average log likelihood -1.409550
[ Info: iteration 28, average log likelihood -1.409518
[ Info: iteration 29, average log likelihood -1.409487
[ Info: iteration 30, average log likelihood -1.409460
[ Info: iteration 31, average log likelihood -1.409435
[ Info: iteration 32, average log likelihood -1.409412
[ Info: iteration 33, average log likelihood -1.409390
[ Info: iteration 34, average log likelihood -1.409370
[ Info: iteration 35, average log likelihood -1.409352
[ Info: iteration 36, average log likelihood -1.409335
[ Info: iteration 37, average log likelihood -1.409318
[ Info: iteration 38, average log likelihood -1.409303
[ Info: iteration 39, average log likelihood -1.409288
[ Info: iteration 40, average log likelihood -1.409274
[ Info: iteration 41, average log likelihood -1.409261
[ Info: iteration 42, average log likelihood -1.409249
[ Info: iteration 43, average log likelihood -1.409237
[ Info: iteration 44, average log likelihood -1.409226
[ Info: iteration 45, average log likelihood -1.409215
[ Info: iteration 46, average log likelihood -1.409205
[ Info: iteration 47, average log likelihood -1.409195
[ Info: iteration 48, average log likelihood -1.409186
[ Info: iteration 49, average log likelihood -1.409178
[ Info: iteration 50, average log likelihood -1.409170
┌ Info: EM with 100000 data points 50 iterations avll -1.409170
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.166732   -0.0971437   0.125551    0.241386    -0.0719437    0.208802      0.0433649   0.678634   -0.140021    -0.724544    0.385987    -0.569862     0.0928485  -0.672742    -0.258943    0.72116      -0.241936   -0.0330776   0.218471    -0.406285   -0.867149    -0.0300079   -0.174469     0.324387    0.420424    -0.517818
 -0.27743     0.285556    0.0932463  -0.608074     0.215486     0.111765      0.0763854  -0.712618   -0.112895    -0.315901   -0.0389511   -0.818004     0.449954    0.229298     0.666709    0.0416333     0.358721   -0.504242    0.0924291   -0.227704    0.0776437   -0.279268     0.277178    -0.139238    0.100641    -0.29053
  0.0646597  -0.920868    0.593542    0.337817     0.0532162    0.0690998    -0.575095   -0.381368   -0.168628     0.214636    0.0711499   -0.209131     0.518599    0.116206     0.132784    0.437152     -0.504493   -0.559971   -0.587629    -0.0244209  -0.655589     0.277237     0.399329    -0.130638   -0.0572246   -0.106415
 -0.169602   -0.223553   -0.789291    0.128096    -0.358275    -0.239021      0.384977   -0.35142     0.199657    -0.108017   -0.348158    -0.140779     0.238781    0.317493    -0.274645    0.723849     -0.16335     0.922501   -0.293697     0.665996    0.403046     0.175711     0.0948705   -0.284255   -0.139652    -0.309978
  0.340553    0.941898    0.615474   -0.926119    -0.29031     -0.12017       0.304872    0.195583    0.0461997    0.286149   -0.115677    -0.322646     0.265227   -0.96034     -0.455517    0.221651     -0.0784924  -0.0624172   0.723069     0.271903    0.0362607   -0.0788489    0.0813231    0.203734    0.0895192   -0.368141
  0.189404    0.152351   -1.11112     0.0812157   -0.296484    -0.143517      0.0475222  -0.910587    0.382951    -0.292099    0.115798     0.475728     0.226062    0.25263      0.0941183  -0.0199332    -0.523197   -0.288707    0.78612      0.267025    0.00309329  -0.0696297    0.120527     0.205726    0.0186954    0.205098
  0.130909   -0.136448   -0.75073    -0.850606    -0.290862    -0.550826      0.207045   -0.124352    0.222217     0.0416747  -0.0212728   -0.148843     0.55474     0.149967     0.42984     0.277952     -0.414045    0.226068    0.182102    -0.196235    0.308949     0.17676      0.308504    -0.347968    0.0396858   -0.11133
 -0.723696   -0.410099    0.617881    0.116836    -0.266188     0.593899      0.0534556   0.0142311  -0.496168    -0.324365    0.568997    -0.0131585   -0.413903    0.0539791   -0.383161   -0.10871       0.27119    -0.20354    -0.476946     0.347816    0.504876     0.19159     -0.549585    -0.0031325   0.228537     0.359446
  0.383932    0.281414   -0.0583555   1.01085      0.240917     0.936862     -0.224432   -0.155946   -0.292909    -0.685497    0.0169043   -0.282646    -0.0929733   0.104505    -0.389638   -0.303853      0.438881   -0.422576   -0.236417     0.227388   -0.403902    -0.502204     0.0498739   -0.49721    -0.307894    -0.514456
 -0.404842   -0.355577   -0.194167   -0.0180951   -0.934876    -0.230955      0.258978   -0.029766   -0.475912     0.207873    0.274285    -0.295274     0.130091    0.0426708   -0.115745    0.803713     -0.317842   -0.0848519   0.160768    -0.292942   -0.212255     0.513802    -0.497491    -0.251628   -0.232806    -0.138755
  0.749964   -0.143803   -0.0235529   0.363863    -0.621427     0.405272      0.170393   -0.209031    0.00660794   0.418427    0.281052     0.437088    -0.609725    0.291116     0.0245594   0.125046     -0.096477   -0.140228    0.10534     -0.402737    0.0303113   -0.253265    -0.00550351   0.0843157   0.336367    -0.653525
  0.600173    0.0149615   0.0399227  -0.00934909   0.231046     0.0184307     0.441495    0.626517    0.310627    -0.133139   -0.558565     0.378819    -0.558853   -0.0705159    0.538743   -0.690491      0.250749    0.607055    0.0249816    0.0684171  -0.0706855   -0.14613     -0.140084     0.575694   -0.140162     0.361264
 -0.426073   -0.780963    0.793876    0.169793     0.125683     0.180541      0.352953    0.159489    0.0081009   -0.0600238  -0.263266     0.142171    -0.0130198  -0.123434     0.214225    0.286751      0.819997    0.363144    0.292128    -0.0173565   0.326564     0.522216     0.252483    -0.234876   -0.308034    -0.169591
  0.366364    0.494407   -0.545943    0.162397     0.340679    -0.117748     -0.446272    0.0280979  -0.106015     0.254791   -0.104672    -0.180429    -0.180091    0.217636    -0.032872   -0.377961     -0.451826   -0.0402689  -0.366432     0.233518   -0.017425    -0.487261    -0.0173488   -0.218022    0.336106     0.0124798
 -0.624793    0.169094    0.0248318   0.0826375   -0.0146113    0.555675     -0.50807    -0.409877   -0.0998899    0.519171   -0.0877895    0.129193     0.121635    0.195887    -0.60882     0.676824      0.169044   -0.621034    0.550606     0.0913824   0.280734    -0.385646     0.0958062   -0.753799   -0.261779    -0.532533
 -0.120431    0.303227    0.823338    0.422505     0.0351407    0.53129      -0.0736179   0.147515   -0.170343     0.34305     0.247355     0.395336    -0.793673   -0.408098    -0.177858   -0.295817      0.150003   -0.863128   -0.0129514   -0.0280659  -0.51394      0.121126    -0.228272     0.483332    0.0559574    0.512386
  0.0448027  -0.133308    0.0331817  -0.218697     0.0616518   -0.0369523     0.18038     0.097315   -0.258413    -0.121928   -0.151745     0.108705     0.169818   -0.265908     0.134455   -0.059315     -0.074173    0.0501908  -0.0381061   -0.164447   -0.15545     -0.111755     0.127863    -0.0046075  -0.136838     0.165461
  0.586518    0.252241   -0.413262   -0.609482     0.0536071    0.0266501     0.276022    0.401634    0.573102    -0.08894     0.212043    -0.170153     0.410073    0.294654     0.278515    0.173191      0.130506    0.515978    0.351143    -0.261223   -0.0393343    0.0258079    0.806619    -0.287552    0.0110901    0.0327047
 -0.0409771   0.0392354   0.173788    0.225992     0.169531     0.192111     -0.0902979   0.0144971  -0.112901     0.0256895   0.00979252   0.0346149   -0.158048   -0.0280055   -0.116424   -0.000994597   0.0560147  -0.0566882  -0.0622233    0.032176   -0.101527    -0.182639     0.00336631   0.0589784   0.06204     -0.0574081
 -0.522822   -0.321694    0.249126   -0.72536     -0.682567    -0.0761077    -0.112908   -0.579378   -0.209845     0.252982   -0.136613     0.622691     0.35994     0.321111     0.459012   -0.152953     -0.244631    0.0148802  -0.359314     0.110389    0.291042     0.205574    -0.0780046    0.10691    -0.00706567  -0.172195
 -0.559427   -0.333451   -0.290228    0.736079     0.714344    -0.37873       0.354331   -0.141968   -0.338846     0.192562   -0.232329     0.365672    -0.352163   -0.0545543   -0.477001   -0.307683     -0.305514    0.0545203  -0.0790622    0.676589   -0.245811    -0.35596     -0.69642      0.213215    0.0163102    0.225408
 -0.0271962   0.0517157   0.317736   -0.0700903    0.649988    -0.0200646    -0.458547    0.650129   -0.303435    -0.660268   -0.172126    -0.522632     0.237765    0.00910305  -0.412718   -0.00802386    0.509493    0.710938   -0.217897    -0.0545011   0.611305    -0.0231979    0.072319    -0.534995    0.32991      0.330356
  0.371626    0.0721408   0.566834   -0.380142    -0.098574     0.0279213    -0.43804     0.154344   -0.113492    -0.157798    0.367606     0.230337     0.13786    -0.369408     0.366041   -0.294035      0.0925457  -0.909427    0.304144    -1.17755    -0.0275125   -0.00551422   0.294855    -0.218991    0.161671     0.426836
  0.433319   -0.525904   -0.55823     0.199714     0.191499    -0.0350461    -0.393058    0.694438    0.12797     -0.0244967   0.0541485   -0.173031     0.0492624   0.00320192   0.742657    0.562115      0.283747   -0.459788   -0.477495     0.21159    -0.231427     0.152645    -0.182606    -0.0999554   0.444747     0.764588
 -0.336131   -0.0401316  -0.298126   -0.529269     0.577775    -0.197045      0.0390491   0.209938    0.0450037   -0.50216     0.107115    -0.391797     0.721262   -0.152567     0.0739402  -0.047755     -0.12842     0.212255   -0.259685     0.204237   -0.490585     0.233477     0.445845     0.280679   -0.126256     0.504574
  0.452446    0.597531    0.191274    0.217819    -0.0474911   -0.343833     -0.031428   -0.338995    0.348326     0.646567   -0.67341     -0.284049     0.228446    0.0565843    0.106061   -0.178826      0.255986   -0.361004    0.0761132   -0.349796    0.13123     -0.278944     0.0299334    0.0288544  -0.378393    -0.576357
  0.217838    0.234865    0.409637   -0.0939731    0.607205     0.0230831    -0.359785   -0.47439     0.282753    -0.185259    0.296011     0.569785    -0.164774   -0.157342    -0.20529    -0.322007      0.0896247   0.195946    0.00747294   0.253456    0.221887    -0.173328     0.475063     0.044632    0.229145     0.0300025
 -0.139123    0.636218   -0.431327    0.197477     0.360045     0.211794      0.415893    0.586657   -0.0252945    0.172527   -0.237068    -0.262916    -0.553276   -0.361144    -0.105982   -0.0763444     0.584405    0.284468    0.446059     0.104302    0.209744    -0.115002     0.017923    -0.376523   -0.263476     0.0246715
  0.118064   -0.155874   -0.0939409  -0.0512014   -0.383774    -0.669086      0.212497    0.283451    0.499913    -0.182266    0.317174    -0.106063     0.185822    0.0105225   -0.250537   -0.249399     -0.361376    0.268335   -0.416856     0.0842966  -0.317023     0.658394    -0.422334     0.747603    0.516519     0.198097
 -0.108307   -0.812213   -0.346737    0.575674     0.464857     0.000476146  -0.267298   -0.105159   -0.259453    -0.427369    0.196764     0.554669    -0.386006    0.718216     0.540255   -0.422748     -0.183768    0.314101   -0.734786    -0.562937   -0.0101347   -0.218508     0.216676    -0.0639114  -0.295722     0.386919
 -0.319818    0.762866   -0.0813569  -0.38392     -0.00901969  -0.136944      0.327717   -0.579968    0.180538     0.34003     0.187139     0.00500617  -0.486777    0.123939    -0.560075   -0.451436      0.390011    0.454778    0.516343     0.411872    0.513607    -0.399939    -0.817679     0.0627218  -0.371108    -0.503834
 -0.0961554   0.0631946  -0.0280543   0.102884    -0.0737548    0.0123775    -0.051189   -0.0499238   0.160867     0.0415779   0.13765     -0.0473549   -0.0648068   0.116601    -0.138393    0.0884881     0.0665555   0.0133211   0.0275078    0.122075    0.0932278    0.131789    -0.16447      0.0294304   0.0579119   -0.138279[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409162
[ Info: iteration 2, average log likelihood -1.409155
[ Info: iteration 3, average log likelihood -1.409148
[ Info: iteration 4, average log likelihood -1.409141
[ Info: iteration 5, average log likelihood -1.409135
[ Info: iteration 6, average log likelihood -1.409130
[ Info: iteration 7, average log likelihood -1.409124
[ Info: iteration 8, average log likelihood -1.409119
[ Info: iteration 9, average log likelihood -1.409114
[ Info: iteration 10, average log likelihood -1.409109
┌ Info: EM with 100000 data points 10 iterations avll -1.409109
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
