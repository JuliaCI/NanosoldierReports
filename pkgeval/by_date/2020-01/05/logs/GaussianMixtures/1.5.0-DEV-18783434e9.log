Julia Version 1.5.0-DEV.11
Commit 18783434e9 (2020-01-04 00:48 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Blosc ────────────── v0.5.1
 Installed CMake ────────────── v1.1.2
 Installed JLD ──────────────── v0.9.1
 Installed BinDeps ──────────── v1.0.0
 Installed QuadGK ───────────── v2.3.1
 Installed StatsFuns ────────── v0.9.3
 Installed Missings ─────────── v0.4.3
 Installed Parameters ───────── v0.12.0
 Installed Rmath ────────────── v0.6.0
 Installed OrderedCollections ─ v1.1.0
 Installed DataAPI ──────────── v1.1.0
 Installed SpecialFunctions ─── v0.9.0
 Installed HDF5 ─────────────── v0.12.5
 Installed CMakeWrapper ─────── v0.2.3
 Installed ScikitLearnBase ──── v0.5.0
 Installed URIParser ────────── v0.4.0
 Installed NearestNeighbors ─── v0.4.4
 Installed SortingAlgorithms ── v0.3.1
 Installed Arpack ───────────── v0.4.0
 Installed LegacyStrings ────── v0.4.1
 Installed Compat ───────────── v2.2.0
 Installed StatsBase ────────── v0.32.0
 Installed Clustering ───────── v0.13.3
 Installed DataStructures ───── v0.17.7
 Installed FillArrays ───────── v0.8.2
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed OpenBLAS_jll ─────── v0.3.7+2
 Installed BinaryProvider ───── v0.5.8
 Installed FileIO ───────────── v1.2.1
 Installed Distributions ────── v0.21.12
 Installed PDMats ───────────── v0.9.10
 Installed StaticArrays ─────── v0.12.1
 Installed Distances ────────── v0.8.2
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.12
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+2
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_K0dNDd/Project.toml`
 [no changes]
  Updating `/tmp/jl_K0dNDd/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_H45AQL/Project.toml`
 [no changes]
  Updating `/tmp/jl_H45AQL/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_swuOck/Project.toml`
 [no changes]
  Updating `/tmp/jl_swuOck/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_97Ouj7/Project.toml`
 [no changes]
  Updating `/tmp/jl_97Ouj7/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_gz0xOj/Project.toml`
 [no changes]
  Updating `/tmp/jl_gz0xOj/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_gz0xOj/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.12
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -964351.2487040905, [14380.413979695235, 85619.58602030479], [3884.147383513158 -6398.337254914808 -20679.43000284025; -3365.671231098385 6644.2409330489645 20466.14604960427], [[16450.462206912984 -937.2932934036875 -3730.2898682386885; -937.2932934036875 17490.791934656332 5422.867588178062; -3730.2898682386885 5422.867588178062 34265.59185331871], [84184.40761434886 1056.8579765138968 3711.9842539328574; 1056.857976513897 82543.19163683483 -5763.076134576109; 3711.984253932858 -5763.076134576109 64503.99145641714]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.393204e+03
      1       1.012761e+03      -3.804429e+02 |        4
      2       9.924663e+02      -2.029459e+01 |        2
      3       9.909491e+02      -1.517132e+00 |        0
      4       9.909491e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 990.9491202605213)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.060149
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.684282
[ Info: iteration 2, lowerbound -3.528716
[ Info: iteration 3, lowerbound -3.387207
[ Info: iteration 4, lowerbound -3.258745
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.148710
[ Info: iteration 6, lowerbound -3.063364
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.996718
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.932568
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.843287
[ Info: iteration 10, lowerbound -2.735445
[ Info: iteration 11, lowerbound -2.620720
[ Info: iteration 12, lowerbound -2.515663
[ Info: iteration 13, lowerbound -2.436555
[ Info: iteration 14, lowerbound -2.387596
[ Info: dropping number of Gaussions to 3
[ Info: iteration 15, lowerbound -2.348025
[ Info: iteration 16, lowerbound -2.319990
[ Info: iteration 17, lowerbound -2.308183
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.303084
[ Info: iteration 19, lowerbound -2.299264
[ Info: iteration 20, lowerbound -2.299258
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Jan  5 12:29:06 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Jan  5 12:29:15 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Sun Jan  5 12:29:17 2020: EM with 272 data points 0 iterations avll -2.060149
5.8 data points per parameter
, Sun Jan  5 12:29:19 2020: GMM converted to Variational GMM
, Sun Jan  5 12:29:27 2020: iteration 1, lowerbound -3.684282
, Sun Jan  5 12:29:27 2020: iteration 2, lowerbound -3.528716
, Sun Jan  5 12:29:27 2020: iteration 3, lowerbound -3.387207
, Sun Jan  5 12:29:27 2020: iteration 4, lowerbound -3.258745
, Sun Jan  5 12:29:27 2020: dropping number of Gaussions to 7
, Sun Jan  5 12:29:27 2020: iteration 5, lowerbound -3.148710
, Sun Jan  5 12:29:27 2020: iteration 6, lowerbound -3.063364
, Sun Jan  5 12:29:27 2020: dropping number of Gaussions to 6
, Sun Jan  5 12:29:27 2020: iteration 7, lowerbound -2.996718
, Sun Jan  5 12:29:27 2020: dropping number of Gaussions to 5
, Sun Jan  5 12:29:27 2020: iteration 8, lowerbound -2.932568
, Sun Jan  5 12:29:27 2020: dropping number of Gaussions to 4
, Sun Jan  5 12:29:27 2020: iteration 9, lowerbound -2.843287
, Sun Jan  5 12:29:27 2020: iteration 10, lowerbound -2.735445
, Sun Jan  5 12:29:27 2020: iteration 11, lowerbound -2.620720
, Sun Jan  5 12:29:27 2020: iteration 12, lowerbound -2.515663
, Sun Jan  5 12:29:27 2020: iteration 13, lowerbound -2.436555
, Sun Jan  5 12:29:27 2020: iteration 14, lowerbound -2.387596
, Sun Jan  5 12:29:27 2020: dropping number of Gaussions to 3
, Sun Jan  5 12:29:27 2020: iteration 15, lowerbound -2.348025
, Sun Jan  5 12:29:27 2020: iteration 16, lowerbound -2.319990
, Sun Jan  5 12:29:27 2020: iteration 17, lowerbound -2.308183
, Sun Jan  5 12:29:27 2020: dropping number of Gaussions to 2
, Sun Jan  5 12:29:27 2020: iteration 18, lowerbound -2.303084
, Sun Jan  5 12:29:27 2020: iteration 19, lowerbound -2.299264
, Sun Jan  5 12:29:27 2020: iteration 20, lowerbound -2.299258
, Sun Jan  5 12:29:27 2020: iteration 21, lowerbound -2.299255
, Sun Jan  5 12:29:27 2020: iteration 22, lowerbound -2.299254
, Sun Jan  5 12:29:27 2020: iteration 23, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 24, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 25, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 26, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 27, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 28, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 29, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 30, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 31, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 32, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 33, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 34, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 35, lowerbound -2.299253
, Sun Jan  5 12:29:27 2020: iteration 36, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 37, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 38, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 39, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 40, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 41, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 42, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 43, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 44, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 45, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 46, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 47, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 48, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 49, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: iteration 50, lowerbound -2.299253
, Sun Jan  5 12:29:28 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601405, 95.95490777398594]
β = [178.04509222601405, 95.95490777398594]
m = [4.250300733269909 79.28686694436183; 2.000229257775368 53.85198717246126]
ν = [180.04509222601405, 97.95490777398594]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547485115 -0.007644049042327731; 0.0 0.00858170516633361], [0.3758763611948397 -0.00895312382734581; 0.0 0.012748664777409125]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9760051748390761
avll from llpg:  -0.9760051748390765
avll direct:     -0.9760051748390765
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0129730546870264
avll from llpg:  -1.012973054687026
avll direct:     -1.012973054687026
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.102979     -0.131482     0.136007     -0.0108524    0.152381    -0.109498    0.0344114    0.00793047   0.0438681   -0.127633     0.0345799   -0.0688546    -0.0393536   -0.148617     0.0289509   -0.0054108    0.108539     0.0469107    0.0805034    0.100837     0.151127     0.111692     0.0582871   -0.0895505   -0.0331627    -0.0424991
  0.229659      0.138188    -0.076739      0.0558043    0.0199306    0.0199815  -0.0361888   -0.0442613    0.162933    -0.0997381    0.0391664   -0.0283345     0.0534655   -0.0209855    0.112013     0.008902    -0.0739129   -0.0263854    0.139621     0.0685503   -0.0535946   -0.143633     0.0236167   -0.0543938    0.0835909     0.0192556
  0.0373083    -0.0816502    0.0340919    -0.00516423   0.118876     0.0223151   0.0933225   -0.0805311    0.0118466    0.134557     0.0703916    0.121647      0.187442     0.130063    -0.0424563    0.100477     0.0942695    0.0157018   -0.118846    -0.0844607   -0.0292943    0.0882047    0.019143    -0.0731357    0.244375     -0.0281303
  0.106567     -0.0195601    0.0634847    -0.0456031    0.0534184    0.0243291  -0.123854    -0.172738    -0.0416032    0.0358725    0.131095    -0.0591717    -0.0367478    0.038787     0.0553948   -0.12507      0.0184352    0.0982084    0.114695    -0.0628733   -0.0553417   -0.0474745    0.0712267   -0.126601     0.0198307    -0.13793
 -0.0249846     0.0512943    0.116133     -0.126792    -0.247328    -0.0183639  -0.0229776   -0.0345667   -0.053886     0.171174     0.070879    -0.00231317    0.00231642  -0.0668118   -0.0701013    0.290167     0.0973677   -0.126152    -0.0320941   -0.0323952   -0.118976    -0.114638     0.0758832    0.0807944    0.0243369    -0.0686817
 -0.134371     -0.143252     0.0343169    -0.0546626    0.0193892   -0.118788    0.151776     0.0698338   -0.064343     0.0835266    0.138212     0.0428661     0.0473137    0.0335506    0.102593     0.043393     0.0551296   -0.0561581   -0.172827     0.0165537   -0.0412146    0.0075202   -0.132149     0.0728696    0.0369684     0.00324417
 -0.121893     -0.0291618    0.100149     -0.123708    -0.00944923   0.0641785  -0.115718    -0.186798    -0.00365796  -0.204689    -0.0815375   -0.0515525    -0.0426885    0.0701863    0.0275224    0.0865362    0.0286929    0.087396     0.00153609   0.0254151   -0.123109    -0.0736032    0.0510524   -0.00842337   0.0354049    -0.0208891
 -0.0353292     0.0239742    0.00509696   -0.0326998   -0.0367881    0.21608    -0.0308742    0.00825305  -0.136187     0.110378     0.0216354   -0.03028      -0.00822451   0.144913    -0.0196321    0.0768932   -0.0382866   -0.111342     0.031987     0.0179142   -0.0221241   -0.0498704   -0.155912    -0.0499903   -0.0437684    -0.0897633
 -0.0699506    -0.087079     0.0407645    -0.0478049    0.0442591   -0.0762695  -0.0236291   -0.0292825    0.0669786   -0.0152203    0.0742208    0.0542777     0.0182173    0.121332    -0.0821402   -0.0950235    0.0577069    0.0869753   -0.0687141   -0.128691    -0.0141028    0.10931     -0.217211    -0.0280652    0.0255102    -0.0638204
 -0.00102798    0.163841     0.190554      0.00581556  -0.072511    -0.0536622  -0.153387    -0.14794      0.0288317    0.138622     0.0379439    0.0548093     0.0325525    0.116415    -0.132484     0.0394881    0.193158    -0.0249698    0.0949596    0.0967838    0.0740511   -0.205368    -0.170539     0.203421    -0.163115     -0.173879
 -0.0160315    -0.0422003   -0.16446       0.122546     0.0505091   -0.10947     0.012302    -0.106724     0.035317     0.0427945    0.119126     0.178393     -0.0175537    0.0235242   -0.199992    -0.0360886    0.0571594    0.101254    -0.0708245    0.0166872   -0.00668384  -0.0983209   -0.0189959    0.0991767   -0.0545112     0.0407762
 -0.0988541    -0.0762313    0.0128435    -7.61172e-5  -0.0131156   -0.0228106  -0.0240255    0.117163     0.0738294   -0.116673    -0.141654    -0.027537     -0.0622956   -0.107414    -0.185415     0.0137406    0.00120425   0.0825505   -0.1183       0.16681      0.0742551    0.0234432   -0.0408582   -0.250575    -0.00343679    0.183452
  0.120297     -0.179941     0.185628     -0.0141814   -0.058746     0.0350639  -0.0534434    0.183173     0.00163494   0.0153774   -0.0634803    0.0974226    -0.120709     0.122744    -0.111885    -0.041837    -0.0937675   -0.0769917   -0.0691809   -0.0126243    0.100618    -0.0200727    0.0253365    0.111714     0.100198      0.0449117
 -0.112808      0.00628762   0.103057      0.0649622   -0.0296428    0.0461916   0.0397834   -0.148053    -0.174064     0.00738028  -0.00659609  -0.00748502   -0.125775     0.080648     0.0453961   -0.0293277   -0.0313131    0.0696332   -0.00183365  -0.125448    -0.0663257   -0.0268314   -0.125795    -0.0219214    0.0228344    -0.112852
 -0.0687333     0.202881    -0.0726987    -0.13713      0.178203    -0.05494    -0.157623     0.0612988    0.0840889   -0.042639    -0.00787577  -0.204048      0.0929087   -0.0541979    0.0977708    0.116696    -0.054538     0.0395706   -0.00144783   0.0342718    0.0747131   -0.127325     0.104012    -0.143672    -0.000690921  -0.113687
  0.0108371    -0.037383    -0.0140851    -0.145248     0.0063362   -0.21449     0.132656     0.0741383    0.196164    -0.0862093    0.0779537    0.0904718     0.142127     0.0860927    0.0210748    0.0481058    0.0707089    0.0693177    0.0455862   -0.219782     0.0666727   -0.189529    -0.0309302   -0.12072      0.0417153    -0.0227808
 -0.0849094     0.07523      0.117101      0.041122     0.184959    -0.0269482  -0.182138    -0.0278197    0.0306527    0.0554773   -0.062458     0.0307818     0.116172     0.0356546   -0.00599511  -0.0351973   -0.0364345   -0.0400969    0.129323     0.0944393    0.0274476   -0.196039     0.0967033    0.00931109  -0.104822      0.1575
  0.150263     -0.178141    -0.107994     -0.0117965    0.0588235   -0.0359789  -0.0375075   -0.0824336    0.0555451   -0.0283952    0.12324      0.0152558    -0.0154652    0.0257964   -0.122058    -0.113172    -0.0945643   -0.0322489    0.145587     0.141492     0.0176662    0.0526186    0.153994    -0.078812    -0.212872      0.128157
  0.239843      0.111628    -0.146665     -0.0252682    0.0848879   -0.0789026   0.0842108   -0.0815362    0.145103     0.081421    -0.0764653   -0.0890713     0.02365      0.0084473    0.129176     0.123869    -0.242256     0.0228974    0.011292     0.212578    -0.166629     0.119799     0.0537817    0.0940817    0.0466182     0.0895158
 -0.1135        0.0719239    0.162051      0.0836078   -0.0115118    0.26096    -0.00911573  -0.0175635    0.0354817   -0.0754074    0.144677     0.148759      0.202674     0.112507    -0.16457      0.0286128   -0.162956     0.00668865   0.0860183    0.0228      -0.00845852  -0.0393531    0.187364    -0.0310043    0.0754655    -0.0236716
  0.0862065    -0.0407361    0.066447     -0.175682     0.174204    -0.091297    0.0213559   -0.126632    -0.0911428    0.101041     0.130661     0.0513156     0.0660938    0.104497    -0.0917507    0.00537786   0.022298    -0.097253     0.0704855    0.185565    -0.0236299    0.0548598   -0.106691    -0.135064    -0.00893094    0.0184709
 -0.0691186    -0.0908209   -0.0386047    -0.0230374    0.0705962   -0.165513   -0.0511324   -0.00200115   0.128398     0.129654     0.127847     0.0863604     0.297678    -0.00849677  -0.185375     0.0555671   -0.125987     0.234584     0.0616598    0.0516922    0.167519    -0.0377025    0.0192217    0.0607536   -0.0159092    -0.0713811
  0.0628821    -0.114195     0.0201221    -0.00743225  -0.00171676  -0.037648   -0.035309     0.0603183   -0.104748     0.107056     0.030654     0.101548     -0.0512197   -0.013693    -0.0402055    0.19064      0.00790936  -0.101336    -0.0323183   -0.0446763    0.0300241    0.0772775    0.0435661    0.0363903    0.0913305     0.0131705
  0.118001      0.0947442    0.0784884     0.157934    -0.0520711   -0.0742721   0.0173347    0.0327726    0.00379632  -0.215848     0.101581    -0.20705       0.0347464   -0.144365    -0.0700776   -0.00698989  -0.0482872    0.0968337   -0.146432    -0.00532442   0.0845545    0.00644802   0.00157754   0.0434384   -0.113685     -0.088059
  0.0257958     0.150378     0.157192      0.00863224  -0.0558738    0.069056    0.0995453    0.0704732    0.0424231   -0.01239      0.0428105    0.0993021    -0.170412     0.0296752   -0.0131909   -0.0307846    0.054723    -0.0372975    0.00183542  -0.152009    -0.0244994    0.123964    -0.144433     0.0680522    0.00754558    0.0655928
  0.000459447  -0.0905602   -0.202454     -0.0363535   -0.0370757   -0.0664498   0.153203    -0.0806159    0.0527938    0.0740444    0.0100105    0.000338361   0.116481     0.00155784  -0.171449    -0.112131    -0.0469295   -0.0645194    0.122574     0.0246943    0.0389311    0.0681273   -0.0216764    0.0807782    0.0523107     0.00785275
 -0.10082       0.050751     0.0661057    -0.0310747    0.0768099   -0.0150166   0.101368     0.268228    -0.093006    -0.0223553    0.128142     0.0947218    -0.0175754   -0.0382669   -0.281011    -0.0253225    0.0800114    0.0647761   -0.011006     0.0333856    0.0503638   -0.077888     0.0804493   -0.212267    -0.03263       0.0191076
 -0.0117488    -0.0987963    0.00113734    0.025783    -0.0707274   -0.0827903   0.188656    -0.018701    -0.141246     0.175163     0.0638203    0.0315734     0.00156509  -0.132431     0.112606    -0.084286     0.0550279    0.026341    -0.014303     0.0814771   -0.022345    -0.0582626   -0.038629     0.0840365   -0.116511     -0.00219594
 -0.0157095     0.13479      0.0604359     0.186035     0.0711012   -0.130899    0.171365    -0.103492     0.00598804   0.0606935    0.216135     0.0949167    -0.0753374   -0.0472353    0.0129265    0.0505431    0.267361    -0.103814    -0.00232173  -0.10605     -0.0707295    0.0921843    0.188854     0.0238576    0.0853827     0.143278
 -0.105819      0.156553     0.000464303  -0.0038243   -0.195578    -0.165482   -0.0300349    0.0948499    0.101444     0.154482    -0.0897565    0.0767638     0.0112327    0.215916     0.125156    -0.00206394  -0.146981    -0.0284889   -0.00174972  -0.0239518    0.111815     0.0981597   -0.00323303   0.0349031    0.182436      0.0374904
  0.11636       0.058684     0.107787      0.127686    -0.062669    -0.0335231   0.0688787    0.0440632    0.0463031    0.0455064    0.0509499   -0.0953578     0.16434      0.0352888   -0.0696775   -0.0618116   -0.0394288    0.18903      0.0895608   -0.120677     0.0558488    0.285277     0.096002     0.0328207   -0.066343      0.0512802
  0.0585009    -0.0378996    0.0947471     0.00992089  -0.219436    -0.0262067  -0.001549    -0.0192254   -0.168933    -0.0742844   -0.0382274   -0.054645      0.081683     0.18881     -0.159162    -0.012984     0.034414    -0.0679617   -0.127351     0.0374704    0.0661057   -0.16185     -0.116521    -0.086221    -0.215204      0.0358255kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3855263698124807
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.385600
[ Info: iteration 2, average log likelihood -1.385539
[ Info: iteration 3, average log likelihood -1.385108
[ Info: iteration 4, average log likelihood -1.378797
[ Info: iteration 5, average log likelihood -1.362294
[ Info: iteration 6, average log likelihood -1.354039
[ Info: iteration 7, average log likelihood -1.351170
[ Info: iteration 8, average log likelihood -1.349332
[ Info: iteration 9, average log likelihood -1.347533
[ Info: iteration 10, average log likelihood -1.346082
[ Info: iteration 11, average log likelihood -1.345598
[ Info: iteration 12, average log likelihood -1.345414
[ Info: iteration 13, average log likelihood -1.345315
[ Info: iteration 14, average log likelihood -1.345246
[ Info: iteration 15, average log likelihood -1.345192
[ Info: iteration 16, average log likelihood -1.345148
[ Info: iteration 17, average log likelihood -1.345111
[ Info: iteration 18, average log likelihood -1.345080
[ Info: iteration 19, average log likelihood -1.345053
[ Info: iteration 20, average log likelihood -1.345031
[ Info: iteration 21, average log likelihood -1.345012
[ Info: iteration 22, average log likelihood -1.344996
[ Info: iteration 23, average log likelihood -1.344982
[ Info: iteration 24, average log likelihood -1.344970
[ Info: iteration 25, average log likelihood -1.344959
[ Info: iteration 26, average log likelihood -1.344951
[ Info: iteration 27, average log likelihood -1.344944
[ Info: iteration 28, average log likelihood -1.344937
[ Info: iteration 29, average log likelihood -1.344932
[ Info: iteration 30, average log likelihood -1.344928
[ Info: iteration 31, average log likelihood -1.344924
[ Info: iteration 32, average log likelihood -1.344921
[ Info: iteration 33, average log likelihood -1.344919
[ Info: iteration 34, average log likelihood -1.344917
[ Info: iteration 35, average log likelihood -1.344915
[ Info: iteration 36, average log likelihood -1.344913
[ Info: iteration 37, average log likelihood -1.344912
[ Info: iteration 38, average log likelihood -1.344911
[ Info: iteration 39, average log likelihood -1.344910
[ Info: iteration 40, average log likelihood -1.344909
[ Info: iteration 41, average log likelihood -1.344908
[ Info: iteration 42, average log likelihood -1.344907
[ Info: iteration 43, average log likelihood -1.344907
[ Info: iteration 44, average log likelihood -1.344906
[ Info: iteration 45, average log likelihood -1.344906
[ Info: iteration 46, average log likelihood -1.344906
[ Info: iteration 47, average log likelihood -1.344905
[ Info: iteration 48, average log likelihood -1.344905
[ Info: iteration 49, average log likelihood -1.344905
[ Info: iteration 50, average log likelihood -1.344905
┌ Info: EM with 100000 data points 50 iterations avll -1.344905
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.385599746854737
│     -1.3855391078462505
│      ⋮
└     -1.3449046556716076
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.345028
[ Info: iteration 2, average log likelihood -1.344930
[ Info: iteration 3, average log likelihood -1.344603
[ Info: iteration 4, average log likelihood -1.341185
[ Info: iteration 5, average log likelihood -1.329313
[ Info: iteration 6, average log likelihood -1.317494
[ Info: iteration 7, average log likelihood -1.312701
[ Info: iteration 8, average log likelihood -1.310653
[ Info: iteration 9, average log likelihood -1.309411
[ Info: iteration 10, average log likelihood -1.308465
[ Info: iteration 11, average log likelihood -1.307645
[ Info: iteration 12, average log likelihood -1.306957
[ Info: iteration 13, average log likelihood -1.306385
[ Info: iteration 14, average log likelihood -1.305920
[ Info: iteration 15, average log likelihood -1.305552
[ Info: iteration 16, average log likelihood -1.305258
[ Info: iteration 17, average log likelihood -1.305023
[ Info: iteration 18, average log likelihood -1.304836
[ Info: iteration 19, average log likelihood -1.304682
[ Info: iteration 20, average log likelihood -1.304542
[ Info: iteration 21, average log likelihood -1.304402
[ Info: iteration 22, average log likelihood -1.304236
[ Info: iteration 23, average log likelihood -1.304022
[ Info: iteration 24, average log likelihood -1.303693
[ Info: iteration 25, average log likelihood -1.303020
[ Info: iteration 26, average log likelihood -1.301888
[ Info: iteration 27, average log likelihood -1.301185
[ Info: iteration 28, average log likelihood -1.300882
[ Info: iteration 29, average log likelihood -1.300726
[ Info: iteration 30, average log likelihood -1.300620
[ Info: iteration 31, average log likelihood -1.300534
[ Info: iteration 32, average log likelihood -1.300457
[ Info: iteration 33, average log likelihood -1.300386
[ Info: iteration 34, average log likelihood -1.300318
[ Info: iteration 35, average log likelihood -1.300254
[ Info: iteration 36, average log likelihood -1.300193
[ Info: iteration 37, average log likelihood -1.300135
[ Info: iteration 38, average log likelihood -1.300080
[ Info: iteration 39, average log likelihood -1.300027
[ Info: iteration 40, average log likelihood -1.299973
[ Info: iteration 41, average log likelihood -1.299919
[ Info: iteration 42, average log likelihood -1.299864
[ Info: iteration 43, average log likelihood -1.299806
[ Info: iteration 44, average log likelihood -1.299742
[ Info: iteration 45, average log likelihood -1.299672
[ Info: iteration 46, average log likelihood -1.299595
[ Info: iteration 47, average log likelihood -1.299511
[ Info: iteration 48, average log likelihood -1.299420
[ Info: iteration 49, average log likelihood -1.299321
[ Info: iteration 50, average log likelihood -1.299217
┌ Info: EM with 100000 data points 50 iterations avll -1.299217
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3450276171951405
│     -1.3449298466392765
│      ⋮
└     -1.2992167100645986
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.299260
[ Info: iteration 2, average log likelihood -1.299030
[ Info: iteration 3, average log likelihood -1.298620
[ Info: iteration 4, average log likelihood -1.295397
[ Info: iteration 5, average log likelihood -1.282260
[ Info: iteration 6, average log likelihood -1.267231
[ Info: iteration 7, average log likelihood -1.259376
[ Info: iteration 8, average log likelihood -1.255878
[ Info: iteration 9, average log likelihood -1.253661
[ Info: iteration 10, average log likelihood -1.251221
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.247446
[ Info: iteration 12, average log likelihood -1.258749
[ Info: iteration 13, average log likelihood -1.253279
[ Info: iteration 14, average log likelihood -1.251256
[ Info: iteration 15, average log likelihood -1.249449
[ Info: iteration 16, average log likelihood -1.246933
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.242997
[ Info: iteration 18, average log likelihood -1.251050
[ Info: iteration 19, average log likelihood -1.245135
[ Info: iteration 20, average log likelihood -1.242892
[ Info: iteration 21, average log likelihood -1.241156
[ Info: iteration 22, average log likelihood -1.239937
[ Info: iteration 23, average log likelihood -1.239231
[ Info: iteration 24, average log likelihood -1.238641
[ Info: iteration 25, average log likelihood -1.237959
[ Info: iteration 26, average log likelihood -1.236988
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.235302
[ Info: iteration 28, average log likelihood -1.242259
[ Info: iteration 29, average log likelihood -1.237509
[ Info: iteration 30, average log likelihood -1.236153
[ Info: iteration 31, average log likelihood -1.235441
[ Info: iteration 32, average log likelihood -1.235021
[ Info: iteration 33, average log likelihood -1.234767
[ Info: iteration 34, average log likelihood -1.234613
[ Info: iteration 35, average log likelihood -1.234517
[ Info: iteration 36, average log likelihood -1.234451
[ Info: iteration 37, average log likelihood -1.234390
[ Info: iteration 38, average log likelihood -1.234317
[ Info: iteration 39, average log likelihood -1.234206
[ Info: iteration 40, average log likelihood -1.233998
[ Info: iteration 41, average log likelihood -1.233521
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.232260
[ Info: iteration 43, average log likelihood -1.240478
[ Info: iteration 44, average log likelihood -1.236199
[ Info: iteration 45, average log likelihood -1.235265
[ Info: iteration 46, average log likelihood -1.234855
[ Info: iteration 47, average log likelihood -1.234631
[ Info: iteration 48, average log likelihood -1.234501
[ Info: iteration 49, average log likelihood -1.234418
[ Info: iteration 50, average log likelihood -1.234350
┌ Info: EM with 100000 data points 50 iterations avll -1.234350
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2992599848317667
│     -1.29903014873036
│      ⋮
└     -1.234349699097281
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.234460
[ Info: iteration 2, average log likelihood -1.234137
[ Info: iteration 3, average log likelihood -1.232230
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.213906
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.204949
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.181125
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.175206
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.159144
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.152434
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.160534
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.165644
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.153260
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.147435
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.169012
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.156943
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.157529
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.148703
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.159223
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.155187
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.146331
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.151342
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.159262
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.156026
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.148789
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.143110
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.151766
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.159909
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.161596
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.150530
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.158695
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.152536
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.154854
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.147026
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.158066
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.153959
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.145027
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.150844
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.158888
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.155392
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.147396
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.141021
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.162553
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.156083
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.148631
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.143120
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.152360
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.159732
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.149407
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.144598
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.154864
┌ Info: EM with 100000 data points 50 iterations avll -1.154864
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2344599198346937
│     -1.2341373865571548
│      ⋮
└     -1.1548635139822971
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.149914
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.139306
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.142045
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.134780
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│      8
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.103514
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      7
│      8
│     17
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.074208
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      7
│      8
│     19
│     20
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.072776
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     19
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.063333
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      7
│      8
│     17
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.056286
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.053832
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.082397
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.050567
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.065418
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.056489
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.070041
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.061556
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.060622
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.053855
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.077248
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.056348
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     22
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.059017
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.060893
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.071834
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.054649
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.066335
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.055533
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.070198
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.061912
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.061126
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.053617
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.077386
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.056720
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     22
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.059599
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.060673
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.071985
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.055006
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.067103
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.043186
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.078811
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.056234
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.068151
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     24
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.043820
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.081736
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.053355
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.067056
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     24
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.051572
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.076901
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.047224
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.076485
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     24
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.046824
┌ Info: EM with 100000 data points 50 iterations avll -1.046824
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1499137737112473
│     -1.1393056885020512
│      ⋮
└     -1.0468240782015288
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3855263698124807
│     -1.385599746854737
│     -1.3855391078462505
│     -1.3851077954956474
│      ⋮
│     -1.0472240397395713
│     -1.0764849834394488
└     -1.0468240782015288
32×26 Array{Float64,2}:
  0.117024    -0.172355     0.18031      0.000146378  -0.0530856    0.034266   -0.0535205    0.101829    -0.0138338   -0.00270657  -0.0861478    0.0880289   -0.0954732     0.123788    -0.0955454    -0.0502515   -0.110192    -0.0791676   -0.0806841   -0.01287      0.1039      -0.0383018    0.0323702    0.101262     0.139708     0.0679981
  0.0292321    0.134532     0.00356719   0.00601829    0.0668081   -0.0652454  -0.0771181    0.0552419    0.0549295   -0.120493     0.0279092   -0.216845     0.070213     -0.0965312    0.00911083    0.0606221   -0.0727148    0.0761927   -0.0747184   -0.0229484    0.0754703   -0.0730803    0.0591894   -0.0594496   -0.0686571   -0.0936822
 -0.024221    -0.0660939   -0.150123     0.121316      0.0646745   -0.108502    0.0631126   -0.100968     0.050732     0.0346377    0.131094     0.176812    -0.0143079    -0.0362755   -0.18307      -0.0340487    0.0639186    0.107412    -0.0722977    0.0153124    0.00234614  -0.0996322   -0.0166499    0.0832859   -0.073429    -0.00343358
  0.106094    -0.0207295    0.0415235   -0.00529652    0.0471727    0.0238066  -0.107044    -0.174397    -0.00698279   0.0291136    0.129142    -0.0817276   -0.0579519     0.0348102    0.0576622    -0.100707     0.00439924   0.0766858    0.111375    -0.0635868   -0.0640213   -0.0429617    0.0772703   -0.12594      0.0265027   -0.122551
 -0.0816994    0.104144     0.169336     0.0878488    -0.0430857    0.292662    0.0123827   -0.0481818    0.0344661   -0.195225     0.119313     0.115477     0.202981     -0.670889    -0.194195      0.00530664  -0.162737     0.00089705   0.19114      0.0567499    0.10576     -0.0422118    0.213528    -0.0833873    0.00924079   0.0734508
 -0.142972     0.0689981    0.155332     0.0810663    -0.00504053   0.221749    0.00396096   0.00286807   0.0356769    0.0066569    0.095913     0.151464     0.199215      0.704523    -0.126125      0.0846599   -0.156861     0.00990382   0.00119027  -0.0160315   -0.0831774   -0.0402985    0.16896      0.023978     0.0728095   -0.0906793
 -0.167623     0.0135811    0.1243      -0.123617      0.0704304    0.0641257  -0.23512     -0.183316     0.315297    -0.200557    -0.305358    -0.111232    -0.0411702     0.0538458    0.0733908     0.107871    -0.0293195    0.0725526   -0.69031      0.14524     -0.132255    -0.0692536    0.00318691  -0.0452719    0.0356232   -0.0299901
 -0.0495222   -0.22623      0.087302    -0.124095     -0.0867476    0.064881    0.00172803  -0.18168     -0.393209    -0.230674     0.14279      0.0471203    0.000211626   0.0759819   -0.0180638     0.061554     0.0969677    0.0951932    0.467932    -0.0879651   -0.0992374   -0.0767898    0.0435413    0.00709886   0.035385    -0.0191393
  0.037248     0.0237301    0.103899    -0.00280928   -0.0357478   -0.0606871  -0.104798    -0.0499641   -0.0319221    0.108287     0.0304728    0.0742442   -0.0127608     0.0470653   -0.0831527     0.119856     0.0894687   -0.0518604    0.0271012    0.0282954    0.0576789   -0.0680275   -0.0636918    0.127421    -0.0309839   -0.0792906
  0.236198     0.105128    -0.136894    -0.0257286     0.0866157   -0.0780701   0.0812051   -0.0926663    0.149592     0.0631604   -0.0763421   -0.0979358    0.0432055     0.00345641   0.12203       0.122904    -0.204855     0.0375011    0.0117043    0.209607    -0.197463     0.0902638    0.0153313    0.10016      0.0504902    0.0911988
  0.107122     0.0441066    0.0457953    0.124312     -0.0339905   -0.543744    0.0897574    0.0452766    0.116193     0.158632     0.133615    -0.0582722   -0.0330638     0.0300415   -0.16816      -0.0667275   -0.0675928    0.251241     0.0756486   -0.264591     0.037508     0.329229     0.0832307    0.0307632    0.0205653    0.0545714
  0.08472      0.0913838    0.178686     0.179678     -0.102271     0.562476    0.0367335    0.0433134   -0.0219438    0.018011     0.0255014   -0.166655     0.265284      0.0381449    0.00602789   -0.0602088   -0.00059216   0.134315     0.0959852   -0.0148389    0.100885     0.252793     0.145278     0.0180155   -0.062475     0.0490042
  0.0260112    0.0599699    0.0680168   -0.0840961    -0.0343271   -0.0777206   0.130842     0.0619097    0.101792    -0.0473604    0.0672546    0.096852    -0.0714949     0.0661661    0.000210549   0.0219299    0.083319     0.0106966    0.0049942   -0.183284     0.00759228  -0.0309055   -0.0540644   -0.0269508    0.0241199    0.0274775
  0.0876152   -0.134849    -0.167784    -0.0196495     0.0354979   -0.0531373   0.0590527   -0.0754589    0.0513999    9.32121e-5   0.0791382    0.0044535    0.0436632     0.0144212   -0.144795     -0.106617    -0.0525302   -0.0442387    0.100013     0.0804216    0.0399893    0.0572157    0.0702772    0.00937789  -0.0923171    0.0727728
  0.0773016   -0.130982     0.142035    -0.0110148     0.162497    -0.113989    0.0167739    0.00892094   0.049446    -0.123153     0.0300086   -0.0629605   -0.0430568    -0.148253     0.0218468    -0.0271766    0.0612913    0.0393846    0.0971494    0.105017     0.150828     0.110663     0.0707463   -0.0957724   -0.0217595   -0.0407524
  0.0630109   -0.082519     0.0377625   -0.00473052    0.149734     0.0167214   0.0914193   -0.0818222    0.0155711    0.135298     0.074006     0.116223     0.192063      0.125247    -0.0327489     0.0745409    0.132158     0.0135133   -0.0937381   -0.084646    -0.0153306    0.0795185    0.0316122   -0.0466831    0.245166    -0.0304411
  0.0875849   -0.0944399    0.048452    -0.188058      0.175289    -0.0923127  -0.00445097  -0.16304     -0.076718     0.133788     0.0901844   -0.0119073    0.0665244     0.109282    -0.0806975     0.00877154   0.0316578   -0.11005      0.0426006    0.326922     0.238352     0.053585    -0.106522    -0.128918    -0.00823158   0.0138545
  0.0840858    0.0169037    0.11952     -0.1449        0.160408    -0.0919797   0.113559    -0.0638199   -0.104904     0.0411523    0.155576     0.134257     0.0672101     0.0953424   -0.103533      0.0216572    0.023597    -0.0746894    0.107396    -0.0596187   -0.41863      0.0540421   -0.102966    -0.135843    -0.00765492   0.0220167
  0.0586192   -0.269419     0.0956006    0.0028625    -0.219757    -0.123369    0.0139556   -0.0192603   -0.384128    -0.0787259   -0.00379438  -0.0546499    0.0712324     0.305844    -0.162004     -0.0128373    0.0305358   -0.0615294   -0.127556     0.0383819    0.0695568   -0.123929    -0.0732914    0.287718    -0.114962    -0.101344
  0.0584602    0.174296     0.092271     0.00724062   -0.220137     0.0493933  -0.00399216  -0.0199972    0.046008    -0.0729352   -0.0316093   -0.0537162    0.0836343     0.0627347   -0.162225     -0.0115959    0.0267471   -0.0649321   -0.129849     0.0398758    0.065082    -0.212372    -0.180606    -0.521818    -0.294192     0.230019
 -0.0589885    0.050313     0.11807     -0.194319     -0.247794    -0.0187341  -0.0182926   -0.0248059   -0.0605713    0.162727     0.117595    -0.00802034   0.0022418    -0.090596    -0.0959887     0.294167     0.0959074   -0.491661    -0.0521843    0.255719    -0.101772    -0.110846     0.0711654    0.0850042    0.083248    -0.163182
 -0.00178964   0.0504735    0.113945    -0.0501083    -0.247027    -0.0152604  -0.003645    -0.0283062   -0.0530391    0.166817     0.0668178    0.00469314  -0.0186836    -0.0591521   -0.0624824     0.293284     0.0952365    0.20382     -0.018077    -0.261166    -0.109484    -0.114141     0.0668495    0.0877128   -0.0030197   -0.0159904
 -0.10537      0.18069     -0.118874    -0.00525606   -0.195703    -0.162161   -0.0211329    0.110831     0.101639     0.211179    -0.0604897    0.0934541    0.0536723     0.200463     0.126405     -0.00203085  -0.162606    -0.0285473   -0.00362768  -0.0207552    0.0968944    0.107919     0.638382     0.0428096    0.221514    -0.00417787
 -0.105545     0.140572     0.111361    -0.0110835    -0.196142    -0.174726   -0.0280639    0.0852117    0.10182      0.107064    -0.104677     0.0629842   -0.00525083    0.234428     0.123864     -0.00176102  -0.172057    -0.0271007    0.00234965  -0.0267146    0.163525     0.099701    -0.681488    -0.0379682    0.149836     0.0636023
 -0.0370037    0.0159872   -0.0160628   -0.033496     -0.0304433    0.184206   -0.0232308    0.0124825   -0.101262     0.0617841    0.00401971  -0.033669     0.006861      0.135613    -0.0712999     0.0814092   -0.0207102   -0.0469664    0.0342453    0.0259993   -0.0278032   -0.0383583   -0.142551    -0.0708748    0.00139751  -0.0546171
 -0.0894682    0.00933223   0.0909909    0.0110848     0.143303    -0.0151107  -0.12206      0.0356719    0.0592096   -0.0269967   -0.0915677    0.0128213    0.0448627    -0.0247804   -0.100577     -0.0207271   -0.0200372    0.0126846    0.0373136    0.134053     0.0691349   -0.115323     0.0362873   -0.0903209   -0.0433435    0.196848
  0.0986279    0.138588    -0.00279281   0.115106      0.0378217   -0.056252    0.0728346   -0.0480628    0.0995523    0.0014279    0.147333     0.0407035   -0.0193066    -0.0444497    0.0775444     0.0389983    0.105029    -0.0284157    0.059409    -0.0210539   -0.046821    -0.0242287    0.10883     -0.00424932   0.0879848    0.123543
 -0.0133924    0.00173968  -0.0764256   -0.028329      0.116777    -0.205076   -0.0451502   -0.0142892    0.133889     0.138244     0.124892     0.0856854    0.29649      -0.00774014  -0.186747      0.0492492   -0.16932      0.187812     0.049019     0.052941     0.171721     0.00343493   0.021797     0.0733866   -0.01536     -0.0943863
 -0.0782905   -0.0191883    0.0685795    0.0140267     0.00490127  -0.0237472  -0.0094161   -0.0837069   -0.0493148   -0.0180331    0.0276894    0.0252182   -0.0562356     0.0755087   -0.0107498    -0.0606924    0.0147991    0.0688461   -0.0408031   -0.145512    -0.0481008    0.0225779   -0.166976    -0.0282393    0.0183491   -0.0519414
 -0.0306733   -0.10546     -0.0236417    0.0472718    -0.0757307   -0.0743348   0.210323    -0.0208463   -0.13317      0.176859     0.0672554    0.0379715   -0.00864416   -0.133202     0.10683      -0.0959705    0.0615984    0.0156366   -0.0263111    0.0605521   -0.0294427   -0.0430296    0.0133083    0.104027    -0.131385     0.0364443
 -0.145056    -0.12279      0.0309968   -0.0511822     0.0488598   -0.112192    0.150675     0.0661556   -0.0512866    0.0896035    0.105554     0.0353791    0.074547      0.00546504   0.0996412     0.0661865    0.0514806   -0.0709663   -0.170184     0.00434556  -0.0400451    0.00400026  -0.123481     0.0117543    0.0421317    0.00510387
 -0.0856595    0.038773     0.067672    -0.0287021     0.0728734   -0.0341568   0.101642     0.274874    -0.102824    -0.0235329    0.144785     0.089332    -0.0015114     0.033342    -0.290107     -0.0203547    0.0775972    0.0558548   -0.0107903    0.0427824    0.024397    -0.0870545    0.0717573   -0.183214    -0.0316683    0.0224879[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.075848
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.047749
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.066428
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.043265
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.075802
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.047297
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.066263
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.043034
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.075808
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.047257
┌ Info: EM with 100000 data points 10 iterations avll -1.047257
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.149157e+05
      1       6.506563e+05      -1.642594e+05 |       32
      2       6.224269e+05      -2.822942e+04 |       32
      3       6.044924e+05      -1.793445e+04 |       32
      4       5.946614e+05      -9.831067e+03 |       32
      5       5.896350e+05      -5.026381e+03 |       32
      6       5.865060e+05      -3.128982e+03 |       32
      7       5.843694e+05      -2.136598e+03 |       32
      8       5.827638e+05      -1.605612e+03 |       32
      9       5.814558e+05      -1.308013e+03 |       32
     10       5.803929e+05      -1.062836e+03 |       32
     11       5.797846e+05      -6.083156e+02 |       32
     12       5.795279e+05      -2.567159e+02 |       32
     13       5.794208e+05      -1.071052e+02 |       32
     14       5.793762e+05      -4.463517e+01 |       32
     15       5.793502e+05      -2.594203e+01 |       31
     16       5.793212e+05      -2.902480e+01 |       32
     17       5.792905e+05      -3.069285e+01 |       29
     18       5.792518e+05      -3.876477e+01 |       29
     19       5.792172e+05      -3.457514e+01 |       31
     20       5.791846e+05      -3.254150e+01 |       31
     21       5.791311e+05      -5.348509e+01 |       29
     22       5.789964e+05      -1.347119e+02 |       31
     23       5.786265e+05      -3.699182e+02 |       32
     24       5.778210e+05      -8.054859e+02 |       32
     25       5.768207e+05      -1.000334e+03 |       31
     26       5.763061e+05      -5.145697e+02 |       32
     27       5.761459e+05      -1.602551e+02 |       32
     28       5.761030e+05      -4.290290e+01 |       31
     29       5.760893e+05      -1.364615e+01 |       27
     30       5.760837e+05      -5.620691e+00 |       25
     31       5.760805e+05      -3.226630e+00 |       22
     32       5.760781e+05      -2.343481e+00 |       21
     33       5.760767e+05      -1.402483e+00 |       11
     34       5.760763e+05      -4.275388e-01 |        6
     35       5.760762e+05      -9.683305e-02 |        6
     36       5.760760e+05      -1.587093e-01 |        4
     37       5.760759e+05      -1.090904e-01 |        5
     38       5.760759e+05      -9.015102e-02 |        4
     39       5.760758e+05      -7.362979e-02 |        4
     40       5.760757e+05      -1.228796e-01 |        0
     41       5.760757e+05       0.000000e+00 |        0
K-means converged with 41 iterations (objv = 576075.6540028478)
┌ Info: K-means with 32000 data points using 41 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.289904
[ Info: iteration 2, average log likelihood -1.258903
[ Info: iteration 3, average log likelihood -1.227574
[ Info: iteration 4, average log likelihood -1.194690
[ Info: iteration 5, average log likelihood -1.154268
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.104311
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.091261
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.086318
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.055542
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     20
│     21
│     22
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.021487
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.076229
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     14
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.045623
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.048366
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     22
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.034525
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.043822
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     16
│     18
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.038865
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     22
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.053907
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     14
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.039318
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     19
│     20
│     21
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.030842
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.072028
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.045096
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     18
│     19
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.027963
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     22
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.049735
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.053140
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     16
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.022798
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.053119
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     18
│     22
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.023020
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.057173
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     16
│     19
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.036042
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.046147
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     14
│     18
│     20
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.006196
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.071097
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.061272
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.016914
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      9
│     16
│     18
│      ⋮
│     23
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -0.985418
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.087798
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.067533
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.035150
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     18
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.034804
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      5
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.035643
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.044792
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.052106
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     20
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.020249
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     19
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.048544
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.069573
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     20
│     21
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.011144
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     14
│     16
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.043348
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.072044
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     18
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.019228
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.043480
┌ Info: EM with 100000 data points 50 iterations avll -1.043480
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0891677    -0.0370114    0.0672905  -0.0877949   -0.0748509   -0.0642614   0.0662882    0.0172515   -0.0535508    0.122299     0.0978671    0.0229288     0.039155    -0.0228382    0.0202881    0.177275     0.0703787   -0.0932432    -0.106139    -0.00719995  -0.0636147   -0.0583953   -0.0258419     0.0418558    0.039164    -0.0345086
 -0.112842      0.0844838    0.161632    0.0841931   -0.0229691    0.253322    0.00659261  -0.0212931    0.0354668   -0.0887761    0.106079     0.133614      0.200265     0.0412303   -0.157616     0.0465767   -0.159241     0.00540149    0.0938593    0.0196206    0.010399    -0.0413688    0.189056     -0.0274718    0.0422417   -0.0112281
  0.0181548    -0.0308812   -0.0342742  -0.183189     0.0146471   -0.221383    0.118961     0.0505162    0.180111    -0.0777334    0.0893242    0.0887971     0.0735913    0.0845111    0.0328576    0.0620713    0.0947792    0.0752166     0.0136849   -0.199289     0.0484908   -0.188956     0.0450807    -0.120574     0.0416185    0.00509905
 -0.0572752     0.195031    -0.070422   -0.117716     0.197091    -0.0531567  -0.183507     0.0442305    0.0839989   -0.0274878   -0.0132194   -0.206692      0.108762    -0.0295802    0.0740289    0.0900587   -0.0587805    0.0275691     0.0214942    0.030374     0.070426    -0.110788     0.0847617    -0.151921    -0.0123644   -0.139854
  0.0579854    -0.102866     0.0942782  -0.228952     0.171493    -0.0752718   0.056965    -0.12072     -0.0945452    0.0869695    0.123426     0.0612372     0.0752728    0.0992869   -0.0731534    0.0203857    0.0290819   -0.0981472     0.0837587    0.171385    -0.0470512    0.0232669   -0.0544711    -0.158089     0.0032153    0.0463091
  0.233948      0.105167    -0.138152   -0.0275765    0.0880127   -0.0775332   0.0774991   -0.0960373    0.152171     0.0721068   -0.0740209   -0.0980756     0.0558005    0.00618129   0.121404     0.123071    -0.206554     0.0349969     0.0130226    0.205985    -0.196954     0.0888875    0.0143682     0.100334     0.0493076    0.0909681
  0.0510622     0.143753     0.154322    0.0215621   -0.0508809    0.0791576   0.098034     0.0711917    0.0394565   -0.0156602    0.0434079    0.089359     -0.19414      0.0411521   -0.0128775   -0.0414851    0.0559003   -0.0427109     0.00212627  -0.168798    -0.0429927    0.125745    -0.127252      0.0732827    0.00613117   0.0537919
  0.108326      0.0752329    0.0670729   0.115904    -0.0256899   -0.0548209  -0.00253477   0.0059827   -0.00794255  -0.159172     0.0815683   -0.260547      0.0546737   -0.123555    -0.0479252    0.00282217  -0.0779298    0.104795     -0.106201    -0.0190302    0.060935    -0.0106278    0.0149288     0.0175018   -0.133761    -0.0791891
  0.073466     -0.117505     0.0321603  -0.00865082   0.00248221  -0.0558175  -0.0289659    0.0497048   -0.0878456    0.0973175    0.0236652    0.0952618    -0.050602    -0.0112302   -0.0485398    0.187319    -0.00107257  -0.0765161    -0.0373154   -0.0385139    0.0316596    0.054525     0.0366088     0.0359176    0.0878878    0.00795529
  0.0770934    -0.130982     0.142522   -0.0111455    0.162051    -0.113987    0.0164457    0.00885444   0.0502808   -0.123091     0.0289778   -0.0628848    -0.0427133   -0.148281     0.0218807   -0.0275578    0.0613388    0.0396797     0.0980525    0.104802     0.150957     0.110646     0.0697229    -0.0958842   -0.0216541   -0.0417073
 -0.0862502     0.0362041    0.0693034  -0.0252692    0.0736257   -0.0348815   0.101039     0.273244    -0.102165    -0.0235652    0.145161     0.0876444    -0.00254151   0.0297813   -0.286393    -0.0225672    0.0777157    0.055579     -0.0107484    0.0426306    0.0236452   -0.0883212    0.0721185    -0.181695    -0.0342124    0.0223837
 -0.0974931    -0.0713689    0.0307716  -0.008071     0.0408421   -0.0182908  -0.0270466    0.129029     0.076321    -0.104557    -0.124957    -0.0285461    -0.0736541   -0.1042      -0.192787     0.00692378   0.00633876   0.0730002    -0.0811546    0.160033     0.0692351    0.0101002   -0.0305655    -0.238786    -0.0143232    0.185773
  0.108563     -0.155078     0.175687    0.00233485  -0.0468798    0.035326   -0.0663611    0.0931792   -0.00810135  -0.00164637  -0.0708452    0.0878901    -0.0930593    0.115211    -0.0856879   -0.0565329   -0.104012    -0.0755096    -0.0640538   -0.0133506    0.102061    -0.0418163    0.0324793     0.0963704    0.129272     0.072288
 -0.00209678    0.151594     0.174247   -0.00116522  -0.0647671   -0.0759946  -0.173486    -0.167668     0.0216829    0.140906     0.0557917    0.0602374     0.0319659    0.112189    -0.111879     0.045598     0.185162    -0.000774888   0.0945502    0.115746     0.076317    -0.19097     -0.168667      0.210078    -0.156349    -0.162563
 -0.00318038    0.117289     0.0587336   0.186395     0.0539918   -0.121935    0.190894    -0.0606238    0.0333841    0.0810974    0.251734     0.105996     -0.0777416   -0.0567687    0.0118983    0.0518304    0.266773    -0.0785008     0.00375369  -0.103821    -0.0432901    0.106854     0.188394      0.0233716    0.0934274    0.128806
 -0.000689086  -0.0915481   -0.246738   -0.036186    -0.0215589   -0.0734124   0.149124    -0.117989     0.0491594    0.0358568    0.052845     0.0156867     0.11502     -0.00296651  -0.167839    -0.0910571   -0.0591503   -0.0606091     0.11817      0.00913191   0.0537234    0.0524953   -0.0209834     0.117977     0.0420834    0.0106086
  0.175988     -0.178263    -0.0903517  -0.0154871    0.0848481   -0.0318061  -0.030136    -0.04769      0.0563222   -0.0261213    0.11697      0.000152551  -0.014074     0.0378643   -0.117029    -0.122306    -0.0377265   -0.0208204     0.10156      0.141665     0.0314928    0.0603537    0.153874     -0.0623927   -0.212342     0.131651
 -0.00739708    0.0980905    0.18051    -0.0436377   -0.0203155    0.102168   -0.0769777   -0.057419    -0.0736306    0.0968756    0.0285264   -0.00264751    0.034137     0.134076    -0.0956928    0.0681434    0.0436935   -0.078993      0.0890208    0.0435136    0.0104641   -0.107499    -0.150458     -0.0116175   -0.0963545   -0.106712
 -0.067207     -0.0399963    0.0401402  -0.0696645    0.0178009   -0.0779414  -0.0515338   -0.0262467    0.0686649   -0.032813     0.0669751    0.0551969     0.0105631    0.0908004   -0.0688655   -0.0948955    0.0578884    0.0723776    -0.0725667   -0.123275    -0.0156888    0.0944936   -0.195413     -0.0375461    0.0283841   -0.0405489
 -0.106759     -0.108557     0.104969   -0.123879    -0.0102794    0.0635106  -0.11273     -0.182621    -0.0506163   -0.215816    -0.0749177   -0.0304812    -0.0193618    0.0656692    0.0267793    0.0827025    0.0372815    0.0848437    -0.0929169    0.0265748   -0.117088    -0.072522     0.0235487    -0.0173736    0.0354623   -0.0215738
 -0.0191891     0.0139276   -0.186959   -0.0376734    0.0386073    0.204274   -0.0472431    0.00159865  -0.174122     0.0873049   -0.00211428  -0.0331878     0.0294427    0.186083    -0.0335322    0.0678063   -0.039572    -0.0766569     0.0390152    0.0294867   -0.0479955    0.0354901   -0.105375     -0.0593009    0.100221    -0.070246
 -0.016287     -0.00115897  -0.074427   -0.0321117    0.116973    -0.204104   -0.0469425   -0.0132065    0.130291     0.137769     0.124288     0.0858267     0.295753    -0.00826658  -0.188016     0.0516831   -0.165833     0.187802      0.0485381    0.053095     0.172787     0.00758145   0.0204003     0.072373    -0.014868    -0.0913224
  0.0753597    -0.0340516    0.0662279   0.0143515    0.0653764    0.0134134  -0.127634    -0.23123     -0.0270777    0.029725     0.106398    -0.100963     -0.177861     0.0343577    0.0401464   -0.132383     0.00192784   0.0730562     0.117134    -0.0417547   -0.081117    -0.0376211    0.0935098    -0.156217     0.0560247   -0.166941
  0.0631964    -0.0801983    0.0269726  -0.0151799    0.147885     0.0165155   0.0910549   -0.0822806    0.0111348    0.134275     0.0791865    0.118115      0.196321     0.125579    -0.0323854    0.0762798    0.135239     0.0129238    -0.0957602   -0.0801312   -0.0208998    0.0833044    0.032384     -0.0461069    0.246853    -0.0336441
 -0.0515462     0.0856873    0.124848    0.0469116    0.18274     -0.0129534  -0.176033    -0.0280706    0.0820963    0.0322933   -0.0475588    0.0553127     0.111596     0.0631261    0.00119881  -0.0306772   -0.065408    -0.0328965     0.131417     0.0889243    0.0490766   -0.218331     0.0844232    -0.00421548  -0.0685404    0.282527
 -0.0128587    -0.0714873   -0.132093    0.120365     0.072214    -0.106571    0.0642218   -0.104114     0.0331209    0.0447887    0.130598     0.170616     -0.00759455  -0.025132    -0.168913    -0.0353925    0.0644203    0.082861     -0.0593658    0.0158447   -0.00237625  -0.0882616   -0.0223833     0.0614698   -0.0660257    0.00380894
 -0.0272035    -0.11148     -0.02408     0.0512857   -0.0762779   -0.0772236   0.214148    -0.0285606   -0.138945     0.18117      0.0696175    0.0379347    -0.00884316  -0.129529     0.107896    -0.100033     0.0619162    0.0181617    -0.0257217    0.0729456   -0.033585    -0.0504971    0.0200822     0.0965366   -0.132275     0.0301433
  0.095801      0.0639206    0.115364    0.146054    -0.0642763    0.021985    0.0619986    0.0437714    0.0405018    0.0861536    0.0822436   -0.109045      0.120565     0.0355706   -0.077244    -0.0636565   -0.0314304    0.190354      0.0860707   -0.131327     0.0688853    0.284604     0.109441      0.0207673   -0.0213976    0.0514465
 -0.0247295     0.0560786    0.0446463  -0.00166307  -0.207272    -0.104579   -0.0104883    0.0396752   -0.0350433    0.0451838   -0.047777     0.0132622     0.0529931    0.201754    -0.0149166   -0.0066863   -0.0718003   -0.044187     -0.0642449    0.00605601   0.0981581   -0.0292172   -0.0647894    -0.0472582   -0.00407379   0.0442255
 -0.0989892     0.00481573   0.101332    0.0965619   -0.00132766   0.0410578   0.0378829   -0.152204    -0.18301     -0.0034514   -0.0196344   -0.00595411   -0.123586     0.0458802    0.0556353   -0.0195982   -0.0360493    0.0578114    -0.0014829   -0.163572    -0.0847512   -0.0586603   -0.132022     -0.0203424    0.0121911   -0.0816196
  0.210838      0.149075    -0.0666438   0.0429639    0.0263399    0.0221329  -0.0331513   -0.0285512    0.147253    -0.0726666    0.0374003   -0.0254817     0.0503493   -0.0228004    0.130554     0.021259    -0.0835583    0.00268592    0.110821     0.0613066   -0.0575544   -0.155213     0.0240472    -0.0286459    0.0857992    0.127555
 -0.0165095    -0.0184436    0.0174535  -0.0744812    0.108251    -0.0662755  -0.100526    -0.0627197    0.0662818    0.0248653    0.0270879    0.0571598     0.0397331    0.0350892   -0.0622964   -0.0447163    0.0235106   -0.0239628     0.00476061  -0.0149828    0.0354427   -0.0480809    0.000725386  -0.109044     0.0480693   -0.131242[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.042195
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     14
│     16
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.986089
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      9
│     14
│     16
│      ⋮
│     22
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.981968
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      9
│     14
│     16
│     19
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.006260
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     14
│     16
│     18
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.012504
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      9
│     14
│     16
│      ⋮
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.977020
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      9
│     14
│     16
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.000281
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     14
│     16
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.007570
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     14
│     16
│     18
│     20
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.996255
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      9
│     14
│     16
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.994603
┌ Info: EM with 100000 data points 10 iterations avll -0.994603
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.00283085   0.242133   -0.0734103    0.0978103   -0.0779903   -0.0359186    0.159979     0.148168    -0.00687254   0.0718239   -0.00168471    0.0267754  -0.170486     0.0598501    0.0198103   -0.0702422   -0.0555114   -0.161913    -0.15444      0.055124    -0.0861071    -0.163889     0.0049129    -0.112546     0.0165226    0.0460877
  0.109767     0.133104   -0.104282    -0.0619085   -0.0592744   -0.0800545   -0.111891    -0.0436704   -0.085895    -0.0274371   -0.0312999     0.0394172  -0.0497036    0.120485     0.0481933    0.00224263   0.161839     0.145555     0.041665     0.138041     0.00701777    0.104918    -0.0110506    -0.0160589   -0.19105     -0.0770464
  0.164815     0.0273237  -0.0210006    0.015899     0.0598847   -0.00109604  -0.20995     -0.0124418    0.155917    -0.101561    -0.105161      0.0178002   0.164475    -0.0308821   -0.121757    -0.134974    -0.0383446    0.0916902    0.0281386    0.234169     0.0997127    -0.0105951   -0.0120959    -0.124928     0.0172355    0.0861009
  0.0713578    0.0196417  -0.176521     0.21781      0.0212549    0.00227161  -0.103644     0.0828914    0.142921    -0.121527     0.0544383    -0.0927197   0.00516168   0.224118     0.00623054   0.0698368   -0.149662    -0.0539583    0.198829     0.0265483    0.0412812     0.140072     0.10491       0.0806509    0.0162145    0.161502
  0.0726936   -0.0436686  -0.0634098    0.0469868    0.0658444   -0.0855604    0.0402111   -0.0795859   -0.143026    -0.017141     0.0509104    -0.120163    0.00249499  -0.177611     0.101228     0.108223    -0.0682205    0.145549    -0.0814249   -0.058758    -0.112608      0.028595     0.0121073     0.0769995   -0.05799     -0.100831
  0.114716     0.0434672  -0.0396527   -0.163054    -0.0801907   -0.198433     0.119734    -0.118645    -0.0817643   -0.0475682    0.0786141     0.0550828  -0.0309283   -0.0434285    0.155722    -0.00265865   0.120594     0.0180689    0.0374107    0.0643537    0.0149039     0.0331277    0.0747071     0.0916774   -0.0730513    0.0985876
  0.0313391   -0.0780564  -0.125951     0.234914    -0.0170577   -0.101904     0.0634975    0.040209     0.1226       0.215246     0.128682     -0.113537   -0.0192873   -0.110605     0.129       -0.14247     -0.121317     0.0871254   -0.0670677    0.121966    -0.000315436  -0.0186779   -0.0999773    -0.045442    -0.188616    -0.0956296
 -0.00436834  -0.0107923   0.0819862    0.0233461   -0.0506455    0.0984843   -0.107528    -0.0511672   -0.130267     0.0686724    0.0444342    -0.11299     0.0680778   -0.11014     -0.0313053    0.0350599    0.00435102  -0.0555405    0.00552019   0.132813     0.0061101    -0.136243     0.0830024    -0.184736     0.0330335   -0.123076
 -0.112207    -0.039733   -0.16291     -0.0334082   -0.0874203    0.0132217    0.016953    -0.0035004    0.0386052    0.0606285   -0.000737368   0.141058   -0.130609     0.0866758   -0.167411    -0.036898    -0.0584206   -0.0252375   -0.0977456   -0.172766     0.0107195     0.0724631    0.198515     -0.0136872    0.00357014   0.0285612
 -0.0432241   -0.0371015  -0.00493279  -0.0326301    0.211098     0.0458514   -0.124717     0.176327    -0.129879    -0.140053     0.126441     -0.0233536   0.15161     -0.0491497    0.0721113    0.0681008   -0.0143472   -0.0926185    0.0482576    0.0141588   -0.045473      0.0681291   -0.019426     -0.070397    -0.0212802   -0.0343963
 -0.0614759   -0.0840641   0.110263     0.197939    -0.0509077    0.084552     0.0120732    0.104997     0.00437113   0.0862247    0.0828212    -0.0301034   0.114228     0.0229596    0.0908714   -0.102468    -0.0493265   -0.010008    -0.0334569    0.0529759   -0.0698337    -0.0923813    0.0905344     0.0406524   -0.0825343    0.152341
  0.0909841    0.0597908   0.0305524   -0.0244752    0.0229475    0.0438809   -0.108605    -0.109656     0.156533    -0.145447     0.0212598     0.0720016  -0.00533179   0.206908    -0.0208895    0.0188652   -0.101939     0.00351502  -0.0808125    0.0682787    0.0314471    -0.13671      0.13715       0.229853    -0.142319     0.0886622
 -0.0434021    0.067793   -0.0417811   -0.0652499   -0.0988391    0.220151    -0.0332603    0.00728474  -0.0683555    0.0332077    0.091861      0.033317    0.082825     0.110677    -0.259966    -0.167433    -0.188885     0.0412446   -0.066432     0.231119    -0.046249      0.18749     -0.0239089    -0.0810118    0.0333608    0.0286276
 -0.0622358   -0.190655   -0.0119475    0.0698911    0.173518    -0.244414    -0.0921708   -0.266005    -0.118959    -0.00706397   0.0764089     0.133766   -0.0150804    0.102538     0.145496     0.0810159    0.160129    -0.123803    -0.151909     0.184858    -0.032925     -0.0104127   -0.0237165     0.0176116   -0.0123853   -0.123124
 -0.0233368   -0.129549    0.0916394    0.101238     0.00134063  -0.0238601    0.0795553    0.0536731   -0.0119499    0.106693    -0.0878362     0.0345737  -0.0275895    0.112636    -0.139486    -0.0658183   -0.124836    -0.0195053    0.0611712    0.125245     0.0290499    -0.00436298  -0.0837721    -0.175019     0.130235    -0.0464925
  0.0274677    0.0306693   0.0937337   -0.0987027    8.89099e-5   0.0810859   -0.0223419   -0.0141299    0.0540511    0.0149493    0.107559     -0.125605    0.0506057   -0.079535    -0.14805     -0.219522    -0.127423     0.140891     0.0665642   -0.170891    -0.0090516     0.100642    -0.11099       0.0286808    0.00513812   0.13524
 -0.103058    -0.107133   -0.0577614   -0.00842692  -0.0419346    0.0721382    0.0151889   -0.0782899   -0.0245784   -0.0141637    0.121748     -0.101838    0.0252673    0.00873629  -0.0285902    0.154726     0.0474623   -0.0517044    0.0916165   -0.0694336    0.00940477   -0.0314376   -0.022092      0.0267585    0.108395     0.026894
 -0.144174     0.137463    0.0347316    0.0168478   -0.0508277    0.107333    -0.0263069    0.0345777   -0.0684385    0.0128783    0.0299102    -0.115941   -0.0153931   -0.0319534    0.0595484   -0.054661    -0.107976     0.0170253   -0.0876105   -0.192408     0.0336032    -0.0534183   -0.0645469    -0.14012     -0.0479563   -0.0302799
 -0.00795086   0.0436289   0.0573302    0.0332774    0.0678181    0.0494558   -0.0196924    0.118996     0.0285266    0.0195922   -0.136383     -0.0881618  -0.108709    -0.15096      0.0298162    0.0929343   -0.0556131    0.121038     0.0905995    0.0572178    0.0731584     0.0198367   -0.0493104    -0.107797     0.113236     0.0632456
  0.184604     0.0137635  -0.0855386    0.0641192   -0.109781    -0.0889619   -0.127313    -0.160429     0.0695508   -0.0612891   -0.0873243    -0.0473254   0.0470877    0.0200247   -0.0312032   -0.0125983    0.00826339  -0.120032     0.121886    -0.122975    -0.129348      0.0354826   -0.037923     -0.00684831  -0.0478287   -0.0152618
  0.0153999   -0.0408454  -0.100662    -0.0959027   -0.0317148    0.0322509    0.00160905  -0.0163782   -0.0903769    0.0323447   -0.0163942     0.0133928  -0.0508622    0.0798444    0.0446149   -0.055587    -0.124038    -0.0677378    0.0450976    0.0686007    0.0541235     0.00486445   0.108265      0.0296287    0.091989    -0.0140529
  0.0808397   -0.0755911  -0.0399712    0.0377977    0.0767021   -0.0135588   -0.0502703    0.0316063    0.0607028   -0.0532902   -0.122448      0.159084   -0.035656     0.0904248   -0.0873641    0.188763    -0.0413858   -0.157056     0.126693    -0.033721     0.0280721    -0.0947169    0.11999       0.0106174    0.0659032    0.175611
  0.00472982   0.0793413  -0.00365207   0.0797273   -0.0432082   -0.123591    -0.100351    -0.0961135   -0.095207    -0.116971     0.133083     -0.0428941  -0.174144     0.113537    -0.0374428   -0.220748    -0.139476     0.0896815    0.121806    -0.0147185   -0.105674      0.0656447   -0.167682     -0.0803553    0.119848     0.0104679
  0.0788715   -0.295051   -0.135034     0.0211948   -0.0186053   -0.068582    -0.137925     0.0104695   -0.025609     0.0323016    0.0647632    -0.186141   -0.062672    -0.0392447    0.0466529   -0.0663487    0.0800494   -0.056339    -0.128093    -0.00526819   0.0972299     0.184657     0.0690355     0.086349    -0.106208     0.0119464
  0.0724039   -0.101733    0.137998     0.197242    -0.0328826    0.137031     0.0451116   -0.0530563   -0.0612539   -0.0113141   -0.0057309     0.214873    0.0393237   -0.11918     -0.018895    -0.0352942    0.0936964   -0.00250664   0.0495313   -0.134002    -0.242101     -0.0794052   -0.0166248    -0.0406341    0.00251     -0.0568394
  0.0837269   -0.127697   -0.107438    -0.19441      0.129088     0.0281929   -0.0151675   -0.0734419    0.178761    -0.0859792    0.211652     -0.0395503   0.122146    -0.0849943    0.0629461    0.221862     0.101893    -0.0688299    0.0470846   -0.0628978   -0.0331769     0.225864    -0.0440585     0.0353381   -0.0140727    0.0893882
 -0.152891    -0.108031   -0.0745845    0.03715      0.0338567    0.0333565   -0.0477904   -0.0323748   -0.102398    -0.189916    -0.00835954    0.0901857   0.236422    -0.101149     0.169032     0.0715336   -0.0340889    0.00752892  -0.0134009   -0.0772437    0.132965      0.114592    -0.00552793    0.0157603    0.044524    -0.00834212
 -0.0855056    0.0631345   0.142897     0.00859411   0.0458514    0.00734228  -0.0486822   -0.102272    -0.0540784   -0.163231    -0.0854572    -0.0660896  -0.222319    -0.138825    -0.0689368    0.0428626    0.0496701   -0.0222801   -0.175728     0.0020066    0.176506     -0.0697023    0.000112216  -0.181903    -0.0737671    0.046905
 -0.00259307   0.0193093   0.147405     0.018557     0.0920502    0.0075311   -0.0325133   -0.161495    -0.00913541   0.113117    -0.215805      0.0949768  -0.120315     0.102348     0.13295      0.201553     0.215243    -0.0198185    0.00497627  -0.219234     0.0247634     0.100832     0.0687439     0.0761767   -0.0357749    0.13291
 -0.0189097    0.108994   -0.108178     0.109933     0.0501752   -0.0391112   -0.13088     -0.169323    -0.0205972    0.107194    -0.0567424     0.133124    0.0580143    0.0880404    0.122218    -0.131748    -0.00108761   0.111139     0.0481479   -0.0753265    0.258204     -0.166711    -0.00487287    0.0284567   -0.0416504    0.112993
 -0.00413544   0.244253   -0.073659     0.106577    -0.0986074    0.104211     0.0174152    0.0762966   -0.041412    -0.0663285    0.016158      0.0203213  -0.314522     0.0455761   -0.0598127    0.0384949   -0.13479     -0.084601    -0.145917    -0.0111378   -0.0518079     0.0275496    0.0249247    -0.0348054    0.0611676    0.0873391
 -0.131958    -0.0104829  -0.0659152   -0.0179626    0.100569     0.120011    -0.0720898   -0.0475487   -0.0603656   -0.0270836    0.189919      0.0800917  -0.0387261   -0.0415565    0.0903307    0.110235    -0.0108638    0.0843417   -0.0816604   -0.00302119   0.0045724    -0.0930169   -0.0640228    -0.093431    -0.170197    -0.195693kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.418340900793801
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418359
[ Info: iteration 2, average log likelihood -1.418310
[ Info: iteration 3, average log likelihood -1.418275
[ Info: iteration 4, average log likelihood -1.418232
[ Info: iteration 5, average log likelihood -1.418173
[ Info: iteration 6, average log likelihood -1.418084
[ Info: iteration 7, average log likelihood -1.417927
[ Info: iteration 8, average log likelihood -1.417614
[ Info: iteration 9, average log likelihood -1.416986
[ Info: iteration 10, average log likelihood -1.415933
[ Info: iteration 11, average log likelihood -1.414694
[ Info: iteration 12, average log likelihood -1.413768
[ Info: iteration 13, average log likelihood -1.413306
[ Info: iteration 14, average log likelihood -1.413121
[ Info: iteration 15, average log likelihood -1.413051
[ Info: iteration 16, average log likelihood -1.413023
[ Info: iteration 17, average log likelihood -1.413012
[ Info: iteration 18, average log likelihood -1.413008
[ Info: iteration 19, average log likelihood -1.413005
[ Info: iteration 20, average log likelihood -1.413004
[ Info: iteration 21, average log likelihood -1.413004
[ Info: iteration 22, average log likelihood -1.413003
[ Info: iteration 23, average log likelihood -1.413003
[ Info: iteration 24, average log likelihood -1.413002
[ Info: iteration 25, average log likelihood -1.413002
[ Info: iteration 26, average log likelihood -1.413002
[ Info: iteration 27, average log likelihood -1.413001
[ Info: iteration 28, average log likelihood -1.413001
[ Info: iteration 29, average log likelihood -1.413001
[ Info: iteration 30, average log likelihood -1.413001
[ Info: iteration 31, average log likelihood -1.413001
[ Info: iteration 32, average log likelihood -1.413001
[ Info: iteration 33, average log likelihood -1.413000
[ Info: iteration 34, average log likelihood -1.413000
[ Info: iteration 35, average log likelihood -1.413000
[ Info: iteration 36, average log likelihood -1.413000
[ Info: iteration 37, average log likelihood -1.413000
[ Info: iteration 38, average log likelihood -1.413000
[ Info: iteration 39, average log likelihood -1.413000
[ Info: iteration 40, average log likelihood -1.413000
[ Info: iteration 41, average log likelihood -1.413000
[ Info: iteration 42, average log likelihood -1.413000
[ Info: iteration 43, average log likelihood -1.413000
[ Info: iteration 44, average log likelihood -1.413000
[ Info: iteration 45, average log likelihood -1.413000
[ Info: iteration 46, average log likelihood -1.413000
[ Info: iteration 47, average log likelihood -1.413000
[ Info: iteration 48, average log likelihood -1.413000
[ Info: iteration 49, average log likelihood -1.412999
[ Info: iteration 50, average log likelihood -1.412999
┌ Info: EM with 100000 data points 50 iterations avll -1.412999
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.418359315501316
│     -1.4183099468578795
│      ⋮
└     -1.4129994727786237
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413014
[ Info: iteration 2, average log likelihood -1.412945
[ Info: iteration 3, average log likelihood -1.412883
[ Info: iteration 4, average log likelihood -1.412806
[ Info: iteration 5, average log likelihood -1.412710
[ Info: iteration 6, average log likelihood -1.412596
[ Info: iteration 7, average log likelihood -1.412470
[ Info: iteration 8, average log likelihood -1.412343
[ Info: iteration 9, average log likelihood -1.412223
[ Info: iteration 10, average log likelihood -1.412117
[ Info: iteration 11, average log likelihood -1.412028
[ Info: iteration 12, average log likelihood -1.411960
[ Info: iteration 13, average log likelihood -1.411909
[ Info: iteration 14, average log likelihood -1.411874
[ Info: iteration 15, average log likelihood -1.411849
[ Info: iteration 16, average log likelihood -1.411831
[ Info: iteration 17, average log likelihood -1.411817
[ Info: iteration 18, average log likelihood -1.411806
[ Info: iteration 19, average log likelihood -1.411797
[ Info: iteration 20, average log likelihood -1.411790
[ Info: iteration 21, average log likelihood -1.411784
[ Info: iteration 22, average log likelihood -1.411778
[ Info: iteration 23, average log likelihood -1.411773
[ Info: iteration 24, average log likelihood -1.411769
[ Info: iteration 25, average log likelihood -1.411765
[ Info: iteration 26, average log likelihood -1.411762
[ Info: iteration 27, average log likelihood -1.411759
[ Info: iteration 28, average log likelihood -1.411757
[ Info: iteration 29, average log likelihood -1.411754
[ Info: iteration 30, average log likelihood -1.411752
[ Info: iteration 31, average log likelihood -1.411750
[ Info: iteration 32, average log likelihood -1.411749
[ Info: iteration 33, average log likelihood -1.411747
[ Info: iteration 34, average log likelihood -1.411746
[ Info: iteration 35, average log likelihood -1.411744
[ Info: iteration 36, average log likelihood -1.411743
[ Info: iteration 37, average log likelihood -1.411742
[ Info: iteration 38, average log likelihood -1.411741
[ Info: iteration 39, average log likelihood -1.411740
[ Info: iteration 40, average log likelihood -1.411740
[ Info: iteration 41, average log likelihood -1.411739
[ Info: iteration 42, average log likelihood -1.411738
[ Info: iteration 43, average log likelihood -1.411737
[ Info: iteration 44, average log likelihood -1.411737
[ Info: iteration 45, average log likelihood -1.411736
[ Info: iteration 46, average log likelihood -1.411735
[ Info: iteration 47, average log likelihood -1.411735
[ Info: iteration 48, average log likelihood -1.411734
[ Info: iteration 49, average log likelihood -1.411734
[ Info: iteration 50, average log likelihood -1.411733
┌ Info: EM with 100000 data points 50 iterations avll -1.411733
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4130142906869045
│     -1.4129450442133598
│      ⋮
└     -1.4117332177313546
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411745
[ Info: iteration 2, average log likelihood -1.411700
[ Info: iteration 3, average log likelihood -1.411663
[ Info: iteration 4, average log likelihood -1.411621
[ Info: iteration 5, average log likelihood -1.411571
[ Info: iteration 6, average log likelihood -1.411509
[ Info: iteration 7, average log likelihood -1.411438
[ Info: iteration 8, average log likelihood -1.411357
[ Info: iteration 9, average log likelihood -1.411273
[ Info: iteration 10, average log likelihood -1.411188
[ Info: iteration 11, average log likelihood -1.411108
[ Info: iteration 12, average log likelihood -1.411035
[ Info: iteration 13, average log likelihood -1.410969
[ Info: iteration 14, average log likelihood -1.410912
[ Info: iteration 15, average log likelihood -1.410862
[ Info: iteration 16, average log likelihood -1.410818
[ Info: iteration 17, average log likelihood -1.410780
[ Info: iteration 18, average log likelihood -1.410746
[ Info: iteration 19, average log likelihood -1.410717
[ Info: iteration 20, average log likelihood -1.410690
[ Info: iteration 21, average log likelihood -1.410667
[ Info: iteration 22, average log likelihood -1.410645
[ Info: iteration 23, average log likelihood -1.410626
[ Info: iteration 24, average log likelihood -1.410608
[ Info: iteration 25, average log likelihood -1.410592
[ Info: iteration 26, average log likelihood -1.410577
[ Info: iteration 27, average log likelihood -1.410563
[ Info: iteration 28, average log likelihood -1.410550
[ Info: iteration 29, average log likelihood -1.410538
[ Info: iteration 30, average log likelihood -1.410527
[ Info: iteration 31, average log likelihood -1.410517
[ Info: iteration 32, average log likelihood -1.410507
[ Info: iteration 33, average log likelihood -1.410498
[ Info: iteration 34, average log likelihood -1.410490
[ Info: iteration 35, average log likelihood -1.410482
[ Info: iteration 36, average log likelihood -1.410474
[ Info: iteration 37, average log likelihood -1.410466
[ Info: iteration 38, average log likelihood -1.410459
[ Info: iteration 39, average log likelihood -1.410452
[ Info: iteration 40, average log likelihood -1.410445
[ Info: iteration 41, average log likelihood -1.410438
[ Info: iteration 42, average log likelihood -1.410432
[ Info: iteration 43, average log likelihood -1.410425
[ Info: iteration 44, average log likelihood -1.410418
[ Info: iteration 45, average log likelihood -1.410411
[ Info: iteration 46, average log likelihood -1.410404
[ Info: iteration 47, average log likelihood -1.410397
[ Info: iteration 48, average log likelihood -1.410390
[ Info: iteration 49, average log likelihood -1.410383
[ Info: iteration 50, average log likelihood -1.410375
┌ Info: EM with 100000 data points 50 iterations avll -1.410375
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4117448379187867
│     -1.4116997667295923
│      ⋮
└     -1.4103751783672536
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410376
[ Info: iteration 2, average log likelihood -1.410325
[ Info: iteration 3, average log likelihood -1.410280
[ Info: iteration 4, average log likelihood -1.410229
[ Info: iteration 5, average log likelihood -1.410171
[ Info: iteration 6, average log likelihood -1.410102
[ Info: iteration 7, average log likelihood -1.410022
[ Info: iteration 8, average log likelihood -1.409932
[ Info: iteration 9, average log likelihood -1.409836
[ Info: iteration 10, average log likelihood -1.409738
[ Info: iteration 11, average log likelihood -1.409642
[ Info: iteration 12, average log likelihood -1.409551
[ Info: iteration 13, average log likelihood -1.409467
[ Info: iteration 14, average log likelihood -1.409392
[ Info: iteration 15, average log likelihood -1.409327
[ Info: iteration 16, average log likelihood -1.409270
[ Info: iteration 17, average log likelihood -1.409221
[ Info: iteration 18, average log likelihood -1.409179
[ Info: iteration 19, average log likelihood -1.409143
[ Info: iteration 20, average log likelihood -1.409111
[ Info: iteration 21, average log likelihood -1.409083
[ Info: iteration 22, average log likelihood -1.409058
[ Info: iteration 23, average log likelihood -1.409034
[ Info: iteration 24, average log likelihood -1.409013
[ Info: iteration 25, average log likelihood -1.408992
[ Info: iteration 26, average log likelihood -1.408972
[ Info: iteration 27, average log likelihood -1.408954
[ Info: iteration 28, average log likelihood -1.408935
[ Info: iteration 29, average log likelihood -1.408918
[ Info: iteration 30, average log likelihood -1.408901
[ Info: iteration 31, average log likelihood -1.408884
[ Info: iteration 32, average log likelihood -1.408868
[ Info: iteration 33, average log likelihood -1.408852
[ Info: iteration 34, average log likelihood -1.408837
[ Info: iteration 35, average log likelihood -1.408822
[ Info: iteration 36, average log likelihood -1.408808
[ Info: iteration 37, average log likelihood -1.408795
[ Info: iteration 38, average log likelihood -1.408782
[ Info: iteration 39, average log likelihood -1.408769
[ Info: iteration 40, average log likelihood -1.408757
[ Info: iteration 41, average log likelihood -1.408746
[ Info: iteration 42, average log likelihood -1.408735
[ Info: iteration 43, average log likelihood -1.408724
[ Info: iteration 44, average log likelihood -1.408714
[ Info: iteration 45, average log likelihood -1.408705
[ Info: iteration 46, average log likelihood -1.408695
[ Info: iteration 47, average log likelihood -1.408687
[ Info: iteration 48, average log likelihood -1.408678
[ Info: iteration 49, average log likelihood -1.408670
[ Info: iteration 50, average log likelihood -1.408662
┌ Info: EM with 100000 data points 50 iterations avll -1.408662
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4103760244093255
│     -1.4103252546060345
│      ⋮
└     -1.4086621912251707
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408663
[ Info: iteration 2, average log likelihood -1.408603
[ Info: iteration 3, average log likelihood -1.408547
[ Info: iteration 4, average log likelihood -1.408481
[ Info: iteration 5, average log likelihood -1.408400
[ Info: iteration 6, average log likelihood -1.408298
[ Info: iteration 7, average log likelihood -1.408175
[ Info: iteration 8, average log likelihood -1.408033
[ Info: iteration 9, average log likelihood -1.407880
[ Info: iteration 10, average log likelihood -1.407724
[ Info: iteration 11, average log likelihood -1.407573
[ Info: iteration 12, average log likelihood -1.407432
[ Info: iteration 13, average log likelihood -1.407304
[ Info: iteration 14, average log likelihood -1.407190
[ Info: iteration 15, average log likelihood -1.407091
[ Info: iteration 16, average log likelihood -1.407004
[ Info: iteration 17, average log likelihood -1.406929
[ Info: iteration 18, average log likelihood -1.406863
[ Info: iteration 19, average log likelihood -1.406805
[ Info: iteration 20, average log likelihood -1.406753
[ Info: iteration 21, average log likelihood -1.406707
[ Info: iteration 22, average log likelihood -1.406665
[ Info: iteration 23, average log likelihood -1.406626
[ Info: iteration 24, average log likelihood -1.406591
[ Info: iteration 25, average log likelihood -1.406558
[ Info: iteration 26, average log likelihood -1.406527
[ Info: iteration 27, average log likelihood -1.406498
[ Info: iteration 28, average log likelihood -1.406470
[ Info: iteration 29, average log likelihood -1.406443
[ Info: iteration 30, average log likelihood -1.406417
[ Info: iteration 31, average log likelihood -1.406392
[ Info: iteration 32, average log likelihood -1.406368
[ Info: iteration 33, average log likelihood -1.406344
[ Info: iteration 34, average log likelihood -1.406321
[ Info: iteration 35, average log likelihood -1.406299
[ Info: iteration 36, average log likelihood -1.406278
[ Info: iteration 37, average log likelihood -1.406258
[ Info: iteration 38, average log likelihood -1.406238
[ Info: iteration 39, average log likelihood -1.406219
[ Info: iteration 40, average log likelihood -1.406201
[ Info: iteration 41, average log likelihood -1.406184
[ Info: iteration 42, average log likelihood -1.406167
[ Info: iteration 43, average log likelihood -1.406152
[ Info: iteration 44, average log likelihood -1.406137
[ Info: iteration 45, average log likelihood -1.406122
[ Info: iteration 46, average log likelihood -1.406109
[ Info: iteration 47, average log likelihood -1.406096
[ Info: iteration 48, average log likelihood -1.406083
[ Info: iteration 49, average log likelihood -1.406071
[ Info: iteration 50, average log likelihood -1.406059
┌ Info: EM with 100000 data points 50 iterations avll -1.406059
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4086633014055758
│     -1.4086032031913651
│      ⋮
└     -1.4060589099925054
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.418340900793801
│     -1.418359315501316
│     -1.4183099468578795
│     -1.4182749050394505
│      ⋮
│     -1.406082849065924
│     -1.4060706626835169
└     -1.4060589099925054
32×26 Array{Float64,2}:
 -0.188771    0.294413    -0.121956     -0.168288   -0.214402    0.06534      0.278318     0.146761   -0.162812    -0.151662    0.139474    -0.185565     0.111661   -0.782571    0.068717    0.0184772   -0.423392    0.0223918  -0.11559     0.0936537   -0.132721    -0.191697     0.187493   -0.365521    -0.109991    -0.110099
  0.0929367   0.019399    -0.304276      0.255152    0.132255    0.118315     0.033628    -0.0584691  -0.121379     0.143828   -0.0757273   -0.123826     0.154509    0.10632    -0.0624846  -0.160302    -0.113683   -0.101637    0.23343     0.327405    -0.171442     0.0778955   -0.132135   -0.419613     0.142838    -0.0232171
  0.0465217  -0.106202     0.0801841     0.0329748  -0.126925   -0.326683    -0.0438002   -0.0137981   0.063744    -0.115899    0.00342391  -0.00691765  -0.0337848   0.0892344   0.0417187   0.104343     0.127937   -0.0588412  -0.0776553  -0.158133     0.0624241    0.0227233   -0.0213385   0.125218    -0.0941996    0.22205
  0.0167325  -0.161498    -0.149914     -0.186907    0.0300672   0.434388    -0.00256679   0.227225   -0.0368922    0.136365    0.100621     0.0340348   -0.23231    -0.0705918  -0.109608    0.157882    -0.252112    0.158942    0.0327188  -0.0233907    0.283604     0.0371465    0.177834    0.3578      -0.0935949   -0.155643
  0.185069    0.412155     0.024932     -0.859654    0.299626   -0.245611    -0.0610864    0.160139    0.140462     0.890704    0.382405    -0.273956     0.077939   -0.339433   -0.312868    0.0579628    0.0683551   0.32785     0.266116    0.0477961   -0.179281     0.496778    -0.395322   -0.0122037    0.142593    -0.0525292
  0.213809    0.027099     0.0648703     0.0547227  -0.0898177   0.101885    -0.166689     0.617464    0.392071     0.383901   -0.133913    -0.500263    -0.0759395  -0.318446   -0.40844     0.601279    -0.206423    0.0854897   0.373957    0.394946     0.805899     0.0592182   -0.468452    4.90656e-5  -0.19169     -0.109466
  0.1975      0.222003    -0.191086      0.231426    0.275163   -0.11345     -0.351776     0.113534   -0.139854    -0.122075   -0.214679     0.57794      0.278437    0.545156    0.0829843   0.119034    -0.252316    0.377172    0.30647     0.0852676   -0.126069     0.149275    -0.730576    0.142463    -0.00241453   0.594277
  0.124881   -0.147785     0.302502      0.120982    0.408971   -0.374468    -0.572421    -0.297071    0.150773     0.522492   -0.161038     0.214829    -0.0325984   0.776976    0.0441892  -0.0634029    0.829055    0.0601232  -0.0436867   0.0148516    0.287742     0.480015    -0.308105    0.506706    -0.17136     -0.0520615
  0.0173504  -0.2785       0.829921      0.367674   -0.318435    0.178852     0.059675    -0.499541   -0.206994     0.348028   -0.0332418   -0.320318     0.184125   -0.289396   -0.0818192   0.0651497    0.316185    0.0760666  -0.474469   -0.102914     0.429032     0.032477     0.324824   -0.0308955   -0.110503    -0.649336
  0.0732119   0.134784    -0.0777566     0.26027     0.400338    0.459448    -0.449937    -0.76508    -0.422238     0.0559338   0.0520759   -0.36611     -0.205227   -0.0469312  -0.146772   -0.280379     0.0515921   0.104751    0.246536   -0.0231996    0.592599    -0.2974       0.265781    0.0364785   -0.199048    -0.100184
 -0.013432    0.296887     0.220983      0.150894   -0.0528935   0.265556    -0.820878    -0.271656    0.181649    -0.0374245   0.0760884    0.17526      0.0170072   0.20469    -0.625929   -0.0663483    0.186491   -0.0274951  -0.22656    -0.333233    -0.573295    -0.0278065   -0.307869   -0.42718      0.0127281   -0.38709
 -0.474807    0.36525      0.000154977   0.120107   -0.256341    0.423116    -0.345613    -0.193374    0.510721    -0.0658675   0.0398478    0.439132    -0.502381    0.0722351  -0.188642    0.165114     0.432409   -0.0276051   0.0572417  -0.349886     0.00937871   0.400297     0.912718    0.101541     0.01753     -0.318618
  0.0747658   0.35704      0.144106      0.0978316  -0.0733162  -1.1575       0.238364    -0.505338   -0.0217495   -0.0986879   0.091161    -0.04763      0.105639    0.11556    -0.140864   -0.033788     0.257755   -0.241495   -0.0876258   0.37417      0.0634587    0.0983579   -0.352267   -0.881802     0.28436      0.605552
  0.449289   -0.364237    -0.314799      0.0831692   0.273329   -0.531016    -0.309379    -0.240882   -0.326328    -0.536758    0.228411     0.0172816    0.376655    0.0781344   0.348108   -0.158428     0.576503   -0.251763   -0.218225    0.187621    -0.665663     0.374308     0.324079    0.049898     0.342042    -0.0244353
 -0.172359   -0.101523     0.155984     -0.071903   -0.0284119   0.0341884    0.279307    -0.471111   -0.0912868   -0.311209   -0.529497     0.46707      0.0691981   0.0847531   0.568716   -0.467147     0.144571   -0.362699   -0.45826    -0.261226    -0.424454    -0.174016     0.081986   -0.439568    -0.0863673   -0.0526062
 -0.0119914   0.0247253    0.32041       0.166815    0.118112    0.0886689    0.306492    -0.093867    0.186535    -0.0497735   0.396714     0.484612     0.315209    0.333783    0.710098   -0.113978    -0.359452    0.199313   -0.320566   -0.459655    -0.202769    -0.00227674  -0.0645523   0.408154    -0.12357      0.0124691
  0.0910495  -0.103471    -0.0861769     0.332689   -0.0253682   0.189174     0.913576     0.348392   -0.417652    -0.359629    0.144976    -0.311462     0.531728   -0.551217    0.367415   -0.00413958  -0.815084   -0.44587     0.0462972   0.501869    -0.202473    -0.41679     -0.220421   -0.596964     0.24615      0.0905673
 -0.201267   -0.00708921  -0.0400399    -0.171418    0.33191     0.0829423    0.439836    -0.358714   -0.600317    -0.361369    0.255579    -0.00416876  -0.0775209   0.276251   -0.0298651  -0.59891     -0.497384   -0.277909    0.34865    -0.14358     -0.17805     -0.388393     0.328318   -0.00878283   0.688973    -0.207667
 -0.3651     -0.576357    -0.286704     -0.17172    -0.529198    0.463264     0.1952       0.60029     0.194478     0.360103    0.264161    -0.0784168   -0.129929   -0.278495    0.341237    0.193499    -0.395189    0.336799   -0.0793426   0.334796    -0.804387     0.182663     0.0921283  -0.032694    -0.00746874  -0.159191
 -0.519058   -0.025592    -0.565864     -0.259777    0.121636    0.536169     0.119243     0.323385    0.376159    -0.0272872  -0.372028    -0.0328152    0.279419   -0.47849    -0.039748   -0.161722    -0.688597    0.242763    0.209158   -0.203838     0.643932    -0.0323358    0.0220288   0.141365    -0.438939    -0.193137
 -0.179301    0.394704    -0.994953     -0.457803    0.167827    0.0955597    0.0982723    0.195886    0.17167     -0.339602    0.00715405   0.00984007  -0.377989    0.242551    0.0350529   0.0991215   -0.243198   -0.105996    0.719144   -0.475376    -0.395518    -0.00814732   0.090693   -0.309485    -0.410851     0.679091
 -0.0497234  -0.295698    -0.539863      0.0339341   0.0163536  -0.203026     0.185526     0.494543   -0.00459239  -0.24264    -0.104467    -0.387041    -0.558071   -0.191884   -0.027051    0.316731    -0.0998078   0.221097    0.311268    0.46887      0.829794     0.0655543    0.372286    0.338673     0.119284     0.527526
  0.0631258   0.362063    -0.791601      0.105957   -0.455749   -0.104136    -0.281885    -0.210292   -0.0578702    0.0596022  -0.446084    -0.632881    -0.251734   -0.306003   -0.507257   -0.369958    -0.156499    0.0272458   0.315369    0.620862    -0.117903    -0.210972     0.144387   -0.822129    -0.128587    -0.165368
  0.0381252  -0.0402681   -0.283503      0.643609    0.253653    0.662769     0.33093     -0.203097    0.187786     0.011381   -0.738828     0.432366     0.187428    0.555867   -0.93238    -0.165247    -0.531338   -0.611547    0.143715    0.189497    -0.0160745    0.747728     0.0421159  -0.640453     0.523512     0.335263
  0.102395   -0.665441     0.502834     -0.0561492  -0.158487   -0.302807     0.093578     0.214327    0.0279369   -0.481398    0.11406     -0.178339    -0.284566    0.0210198   0.361377   -0.133174     0.184498   -0.708192   -0.160931    0.00222578   0.385164    -0.391896     0.251691    0.609064     0.0337602    0.416916
  0.282712    0.720021    -0.00127533    0.351346   -0.299268   -0.572577    -0.334808     0.491552    0.340355    -0.0642709   0.194144    -0.206106    -0.323537   -0.0996704   0.248653    0.0902884    0.347252   -0.0185152  -0.275029    0.113728    -0.0161905   -0.997519     0.154099    0.185198    -0.375748     0.284382
 -0.188272   -0.591107     0.119016     -0.518811    0.0888037  -0.330402     0.250878     0.31358    -0.250477     0.327756    0.168307    -0.375005    -0.434047    0.26521     0.194358    1.02747      0.552324    0.0696716  -0.367191   -0.492648     0.241406     0.256607    -0.546655    0.59955     -0.418071     0.654608
  0.263082    0.0409781    0.190925      0.206687   -0.242504    0.00926724   0.142052     0.541282    0.634055     0.166913   -0.249293     0.311044    -0.0800042   0.016821    0.0936787   0.855258     0.124763    0.0681127  -0.329724   -0.087205     0.123278     0.246874    -0.147465    0.0471115   -0.552182    -0.00619883
  0.135719   -0.144698    -0.0388679    -0.296138    0.644666    0.0100004   -0.406076     0.39366    -0.195321     0.0991414   0.564059     0.717552     0.316204   -0.3179     -0.0273909  -0.287053     0.148941   -0.0357695  -0.121158    0.305934     0.0148002    0.189192    -0.410865    0.401368     0.907485    -0.128759
  0.573209   -0.202005     0.545364      0.137488    0.157174    0.0625119   -0.21994     -0.372623   -0.482948    -0.140707    0.774481     0.323697     0.719134    0.711869   -0.178288    0.0502065   -0.319559    0.167229    0.105096   -0.259956    -0.0778942    0.452892    -0.557057    0.292589     0.50317     -0.23502
 -0.0238606   0.180045     0.187064      0.0233944  -0.0885953   0.0643896    0.291768    -0.478584   -0.12545      0.0579268   0.367669     0.09314     -0.0354246   0.120964    0.540167   -0.144149    -0.0973917  -0.0148736  -0.196295   -0.286196    -0.477069    -0.152376     0.373934   -0.0600244    0.00635688  -0.189098
 -0.136637   -0.0750796    0.161085      0.185306    0.0306948  -0.0446273   -0.80862     -0.627567   -0.282979    -0.222902   -0.0600063   -0.148685    -0.24438     0.372313   -0.514121   -0.235312     0.241934    0.265273    0.155348    0.00242518   0.275778    -0.0251776    0.120928    0.15371     -0.144643     0.174338[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406048
[ Info: iteration 2, average log likelihood -1.406037
[ Info: iteration 3, average log likelihood -1.406026
[ Info: iteration 4, average log likelihood -1.406016
[ Info: iteration 5, average log likelihood -1.406005
[ Info: iteration 6, average log likelihood -1.405996
[ Info: iteration 7, average log likelihood -1.405986
[ Info: iteration 8, average log likelihood -1.405977
[ Info: iteration 9, average log likelihood -1.405967
[ Info: iteration 10, average log likelihood -1.405958
┌ Info: EM with 100000 data points 10 iterations avll -1.405958
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.488869e+05
      1       7.012885e+05      -2.475984e+05 |       32
      2       6.868785e+05      -1.440995e+04 |       32
      3       6.813670e+05      -5.511519e+03 |       32
      4       6.785541e+05      -2.812901e+03 |       32
      5       6.768634e+05      -1.690684e+03 |       32
      6       6.757112e+05      -1.152156e+03 |       32
      7       6.748213e+05      -8.899341e+02 |       32
      8       6.741033e+05      -7.180180e+02 |       32
      9       6.735482e+05      -5.550646e+02 |       32
     10       6.730684e+05      -4.798308e+02 |       32
     11       6.726358e+05      -4.325802e+02 |       32
     12       6.722692e+05      -3.666526e+02 |       32
     13       6.719380e+05      -3.312159e+02 |       32
     14       6.716100e+05      -3.279573e+02 |       32
     15       6.713026e+05      -3.073796e+02 |       32
     16       6.709957e+05      -3.069141e+02 |       32
     17       6.707110e+05      -2.846779e+02 |       32
     18       6.704551e+05      -2.559314e+02 |       32
     19       6.702352e+05      -2.198745e+02 |       32
     20       6.700365e+05      -1.986957e+02 |       32
     21       6.698419e+05      -1.946288e+02 |       32
     22       6.696763e+05      -1.656209e+02 |       32
     23       6.695362e+05      -1.400330e+02 |       32
     24       6.694128e+05      -1.234511e+02 |       32
     25       6.693064e+05      -1.063636e+02 |       32
     26       6.692192e+05      -8.722171e+01 |       32
     27       6.691426e+05      -7.663525e+01 |       32
     28       6.690798e+05      -6.278453e+01 |       32
     29       6.690195e+05      -6.032044e+01 |       32
     30       6.689600e+05      -5.947390e+01 |       32
     31       6.689035e+05      -5.653587e+01 |       32
     32       6.688447e+05      -5.871016e+01 |       32
     33       6.687903e+05      -5.447493e+01 |       32
     34       6.687430e+05      -4.727356e+01 |       32
     35       6.686989e+05      -4.407614e+01 |       32
     36       6.686619e+05      -3.701215e+01 |       32
     37       6.686281e+05      -3.385288e+01 |       32
     38       6.686020e+05      -2.605493e+01 |       32
     39       6.685776e+05      -2.438142e+01 |       32
     40       6.685518e+05      -2.580027e+01 |       32
     41       6.685251e+05      -2.667037e+01 |       32
     42       6.684977e+05      -2.741628e+01 |       32
     43       6.684720e+05      -2.574197e+01 |       32
     44       6.684497e+05      -2.232096e+01 |       32
     45       6.684294e+05      -2.022756e+01 |       32
     46       6.684071e+05      -2.236522e+01 |       32
     47       6.683836e+05      -2.346799e+01 |       32
     48       6.683538e+05      -2.977763e+01 |       32
     49       6.683289e+05      -2.497345e+01 |       32
     50       6.683055e+05      -2.336213e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 668305.4941142775)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417918
[ Info: iteration 2, average log likelihood -1.412884
[ Info: iteration 3, average log likelihood -1.411597
[ Info: iteration 4, average log likelihood -1.410753
[ Info: iteration 5, average log likelihood -1.409873
[ Info: iteration 6, average log likelihood -1.408925
[ Info: iteration 7, average log likelihood -1.408090
[ Info: iteration 8, average log likelihood -1.407520
[ Info: iteration 9, average log likelihood -1.407185
[ Info: iteration 10, average log likelihood -1.406988
[ Info: iteration 11, average log likelihood -1.406859
[ Info: iteration 12, average log likelihood -1.406765
[ Info: iteration 13, average log likelihood -1.406691
[ Info: iteration 14, average log likelihood -1.406629
[ Info: iteration 15, average log likelihood -1.406577
[ Info: iteration 16, average log likelihood -1.406530
[ Info: iteration 17, average log likelihood -1.406488
[ Info: iteration 18, average log likelihood -1.406450
[ Info: iteration 19, average log likelihood -1.406414
[ Info: iteration 20, average log likelihood -1.406381
[ Info: iteration 21, average log likelihood -1.406351
[ Info: iteration 22, average log likelihood -1.406321
[ Info: iteration 23, average log likelihood -1.406293
[ Info: iteration 24, average log likelihood -1.406267
[ Info: iteration 25, average log likelihood -1.406241
[ Info: iteration 26, average log likelihood -1.406216
[ Info: iteration 27, average log likelihood -1.406192
[ Info: iteration 28, average log likelihood -1.406169
[ Info: iteration 29, average log likelihood -1.406147
[ Info: iteration 30, average log likelihood -1.406125
[ Info: iteration 31, average log likelihood -1.406104
[ Info: iteration 32, average log likelihood -1.406083
[ Info: iteration 33, average log likelihood -1.406063
[ Info: iteration 34, average log likelihood -1.406044
[ Info: iteration 35, average log likelihood -1.406025
[ Info: iteration 36, average log likelihood -1.406006
[ Info: iteration 37, average log likelihood -1.405988
[ Info: iteration 38, average log likelihood -1.405970
[ Info: iteration 39, average log likelihood -1.405953
[ Info: iteration 40, average log likelihood -1.405936
[ Info: iteration 41, average log likelihood -1.405919
[ Info: iteration 42, average log likelihood -1.405903
[ Info: iteration 43, average log likelihood -1.405887
[ Info: iteration 44, average log likelihood -1.405872
[ Info: iteration 45, average log likelihood -1.405857
[ Info: iteration 46, average log likelihood -1.405842
[ Info: iteration 47, average log likelihood -1.405828
[ Info: iteration 48, average log likelihood -1.405814
[ Info: iteration 49, average log likelihood -1.405800
[ Info: iteration 50, average log likelihood -1.405786
┌ Info: EM with 100000 data points 50 iterations avll -1.405786
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.535883    -0.0720012   0.335142   -0.0276396     0.10361      0.451479    0.324886   -0.110146     -0.0468764    0.357459    0.849989    0.298437     0.598609     0.210705    0.589815   -0.00457945  -0.685616     0.391       -0.049446   -0.378617   -0.474381    0.0963121    0.104104     0.492474    0.0459845   -0.498556
 -0.406051    -0.125554   -0.675716   -0.296286     -0.0389172    0.707667    0.277039    0.476244      0.252459     0.12275    -0.416198   -0.032099     0.12526     -0.450133    0.0937365  -0.0288006   -0.560211     0.216933     0.254215   -0.0978095   0.157368   -0.00526159   0.252152     0.210745   -0.405434    -0.262698
  0.40811     -0.027735   -0.724961    0.0627793     0.0755544    0.0615176  -0.0794626  -0.357485     -0.614125    -0.182326   -0.203629   -0.41819     -0.012601     0.183071   -0.371924   -0.834682    -0.480739     0.258145     0.510511    0.645015   -0.101734    0.114701     0.479109    -0.494788    0.693735    -0.460895
  0.0366045   -0.37268     0.376464   -0.230234      0.292054    -0.479827   -0.377767   -0.08915      -0.133936     0.657801    0.110394   -0.0474676   -0.16598      0.613543   -0.170872    0.285843     0.885951     0.227781    -0.23352    -0.255826    0.494632    0.338295    -0.377791     0.899261   -0.297739    -0.031393
 -0.277832    -0.364447    0.0646103   0.442738     -0.628158    -0.363841    0.221047   -0.280379     -0.0672376    0.254976    0.205712   -0.205579    -0.447587     0.287078    0.936684    0.264149     0.25423      0.325873    -0.295213    0.244477   -0.850154    0.753553     0.308237     0.128538   -0.0657618    0.397272
 -0.308425     0.545839   -0.189093    0.203114      0.0375985    0.037265   -0.844789   -0.237138      0.194639    -0.353902    0.092515    0.0545016   -0.34523     -0.0662072  -0.603502   -0.230578     0.196606     0.161853    -0.0725586  -0.34316    -0.350923   -0.499656     0.00531574  -0.482151   -0.0746804   -0.351088
  0.13327      0.230884    0.17906     0.317395      0.279594     0.39636    -0.313743   -0.672761     -0.590862     0.179144    0.0611574  -0.487657    -0.0215972   -0.201675   -0.166484   -0.289846     0.0890246    0.0282163    0.29676    -0.106921    0.600778   -0.38237      0.233598     0.094653   -0.293355    -0.279324
  0.0907446   -0.391145    0.320051   -0.0861955    -0.203852     0.147042   -0.248943    0.000463861   0.232256     0.256336    0.0909498  -0.275393     0.0608324   -0.316523   -0.160119    0.557964     0.113782     0.67137     -0.326428   -0.322081    0.164774    0.072833    -0.107749     0.195029   -0.144357    -0.172517
 -0.0254577    0.0548101  -0.185561    0.129424     -0.0100065   -0.222166    0.387538   -0.175621     -0.300561    -0.286623   -0.172081   -0.260085     0.360607    -0.440066    0.311126    0.0077523   -0.0790731   -0.204294    -0.108216    0.0857771  -0.222957   -0.182229    -0.0825221   -0.647782   -0.176077    -0.0394488
  0.354942     0.614953   -0.171447   -0.118906     -0.600618     0.228032   -0.559033   -0.259566      0.425762     0.713922   -0.0682804  -0.177288     0.100205     0.109289   -0.221344   -0.257426     0.244627    -0.128568    -0.337576    0.53206    -0.615271    0.192858    -0.121778    -0.492078   -0.772662    -0.35431
  0.210836    -0.208769   -0.0911343   0.0681331     0.0476559   -0.106363   -0.602759   -0.505129     -0.307331    -0.0914022   0.189954   -0.0129569   -0.279535     0.410462   -0.931607    0.0862023    0.142226     0.00215724  -0.0390381  -0.0584614  -0.0585276   0.508049     0.113606     0.0973307   0.0182939    0.0579286
 -0.194542    -0.0146704   0.451123    0.117077     -0.0456617    0.375927    0.166188   -0.648776     -0.204513    -0.216919   -0.247998    0.495905     0.055598     0.25236     0.309122   -0.311227     0.0493367   -0.144439    -0.592657   -0.403769   -0.33733    -0.182844     0.359685    -0.342514   -0.0103238   -0.434488
 -0.157002     0.353112   -0.28261     0.35409      -0.198595    -0.505233    0.0260729  -0.225915      0.271377    -0.0373878  -0.581266   -0.119039    -0.231579     0.375719   -0.248312   -0.0965154    0.360375    -0.0378872    0.172115    0.372303    0.477743   -0.0700361    0.162691    -0.522624   -0.283755     0.757271
  0.264569     0.0427317  -0.169495   -0.636274      0.342479    -0.0320799   0.0225637   0.537566      0.106236     0.600932    0.333641    0.00160937   0.0431342   -0.196164   -0.266434    0.440591     0.00647247   0.111336     0.271891    0.246627    0.0393178   0.647173    -0.398476    -0.149528    0.288444     0.199098
 -0.0301488    0.0737961  -0.127141   -0.000220434  -0.00123132   0.0796967  -0.0301091   0.0828435     0.0123682    0.0347571   0.0935558  -0.0034561   -0.0720512   -0.0493537  -0.0257198   0.00625951  -0.149156     0.0163709    0.0708475   0.0075662   0.0032983  -0.0307648    0.0516388    0.0264763  -0.0109137   -0.0261643
  0.218393    -0.0144698   0.208924   -0.0205832    -0.0841075   -0.776947   -0.112068    0.51746      -0.00297929  -0.626755    0.469141   -0.123467    -0.165676    -0.12211     0.468618    0.326888     0.215294    -0.190214    -0.0519269  -0.101237   -0.0051467  -0.624815     0.349289     0.665432   -0.0144723    0.478339
 -0.0771938    0.168329    0.221354    0.273012      0.356788    -0.0450351  -0.486664   -0.176212     -0.245234    -0.386453    0.423804    0.484933     0.858357     0.488092    0.0332721  -0.416382    -0.151899     0.126877    -0.0237868  -0.560011   -0.236029    0.393791    -0.578848     0.328969    0.430185     0.258979
  0.016346    -0.0621194  -0.148655    0.0804744    -0.0524019   -0.108026    0.158376   -0.0406291    -0.0804151   -0.135334   -0.164752   -0.130626    -0.0419672   -0.129626   -0.0272072   0.0633887   -0.0576293   -0.103742     0.0899691   0.167328    0.157536    0.00476001   0.0265212   -0.2823     -0.00956403   0.154804
  0.00491965  -0.324279    0.0735002   0.644698      0.291716     0.78648    -0.184542   -0.246026      0.27967      0.277339   -0.875461    0.190759     0.0613111    0.437046   -0.494693   -0.291293    -0.0285484   -0.532101     0.192868   -0.0344333  -0.0218068   0.568409    -0.208704    -0.401244    0.401748    -0.167742
  0.263535     0.253389   -0.194626    0.406133      0.266409     0.0318194  -0.356099    0.120681     -0.191474    -0.0691213  -0.439273    0.726118     0.206497     0.682994    0.0482045   0.245664    -0.424073     0.515686     0.610077    0.105402   -0.0276139   0.0762688   -0.869721     0.0781288   0.0392768    0.620807
 -0.236415     0.220074    0.581144    0.097123     -0.661725     0.327767   -0.483411   -0.236669      0.692952    -0.558505    0.065194    0.079113    -0.513884     0.0931769   0.114853    0.456802     0.601778    -0.377448     0.230434   -0.919285    0.0686102   0.292251     0.488804     0.32747    -0.358215    -0.434573
  0.165288    -0.518705    0.185533   -0.0357669     0.0033269    0.0435598   0.719691    0.0706151    -0.176087    -0.197681   -0.0136105  -0.211388    -0.177022     0.122871    0.527097    0.0660732   -0.3114      -0.506527    -0.234128    0.0966402   0.834641   -0.0780239   -0.00839284   0.563727   -0.162267     0.480874
  0.115564    -0.382135    0.102584    0.133851      0.459337    -0.384376   -0.700189   -0.00623081   -0.38621     -0.137624    0.24747     0.694031     0.349763    -0.312402    0.297789   -0.391583     0.542245    -0.102941    -0.363144    0.854561   -0.241493    0.454896    -0.338461     0.339937    0.893766    -0.194465
 -0.364637    -0.229199   -0.146839   -0.0797198     0.415139     0.875356   -0.550541   -0.144931      0.247326     0.0170966   0.442958    0.297712    -0.590453     0.0636545   0.205391    0.147686    -0.0958443    0.461507    -0.0837974   0.346638    1.05965     0.195263     0.585929     0.203802    0.13323     -0.177658
 -0.357539    -0.164707   -0.124585   -0.386799      0.404273    -0.218924    0.341837   -0.391299     -0.154785    -0.381413    0.110224    0.0912873    0.00522286  -0.0298227   0.337078   -1.04397     -0.0036837   -0.531297    -0.0890365  -0.306706   -0.246639   -0.393851     0.302567     0.0366726   0.566769     0.199266
  0.195558    -0.176119    0.129037    0.067933      0.150348    -0.383815   -0.219836   -0.105179      0.0778915   -0.0935482  -0.162997    0.318563     0.108531     0.515104    0.3345     -0.175093     0.510641    -0.123125    -0.0482587  -0.0808465  -0.0272343   0.158868    -0.0947045    0.312558   -0.121842     0.220311
 -0.0553912    0.0692642  -0.394727    0.135335     -0.217269    -0.203453   -0.0936486   0.596377      0.229635     0.175419   -0.185917   -0.773372    -0.385241    -0.410238   -0.383101    0.358361    -0.282043     0.161799     0.362168    0.60082     0.645539   -0.218815     0.0327618    0.0523612  -0.234466     0.141096
  0.479143     0.406863    0.650462    0.0167919     0.0810804   -0.706415   -0.0375388  -0.562284     -0.149525     0.0842792   0.57486    -0.121178     0.19133      0.29721    -0.380191    0.0267199    0.040114    -0.350096    -0.0301493   0.249991   -0.0364589  -0.102644    -0.286186    -0.542064    0.627009     0.0937986
 -0.0135942    0.0793154   0.249664    0.19256      -0.063312    -0.428381    0.490373    0.549081      0.475064     0.159023   -0.239259    0.498081     0.108999    -0.0182982   0.303047    0.611785     0.138671    -0.137753    -0.729094   -0.290499   -0.262245   -0.0939869   -0.372998    -0.188921   -0.454976     0.144039
 -0.276971     0.326252   -0.889199   -0.580396      0.14911      0.0919852   0.212423    0.0757579     0.0177452   -0.344408    0.221655    0.114227    -0.407249     0.203943    0.108505    0.20348     -0.411479    -0.0125524    0.528641   -0.493701   -0.440654    0.0757118    0.0804462   -0.248741   -0.269968     0.629115
 -0.100354    -0.0952458   0.682306   -0.0397774    -0.785331     0.290354    0.283006    0.593627     -0.0547568    0.235906    0.363062    0.145864    -0.207754    -0.688159    0.0264441  -0.312797    -0.173113    -0.0271438   -0.226996    0.211903    0.0974844  -0.402047     0.0228902    0.539683    0.29947     -0.52957
 -0.116696    -0.173922   -0.247544    0.320162     -0.189592     0.694942    0.422634    0.399668     -0.085675    -0.430294    0.436279   -0.0353507    0.252936    -0.354752   -0.0560741  -0.0758708   -1.00285     -0.311773     0.0494787   0.67427    -0.629896   -0.398788    -0.121458    -0.715316    0.47572      0.0570459[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405773
[ Info: iteration 2, average log likelihood -1.405761
[ Info: iteration 3, average log likelihood -1.405748
[ Info: iteration 4, average log likelihood -1.405736
[ Info: iteration 5, average log likelihood -1.405724
[ Info: iteration 6, average log likelihood -1.405713
[ Info: iteration 7, average log likelihood -1.405702
[ Info: iteration 8, average log likelihood -1.405691
[ Info: iteration 9, average log likelihood -1.405681
[ Info: iteration 10, average log likelihood -1.405671
┌ Info: EM with 100000 data points 10 iterations avll -1.405671
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
