Julia Version 1.5.0-DEV.104
Commit 372a7a726d (2020-01-18 18:35 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed PDMats ───────────── v0.9.10
 Installed GaussianMixtures ─── v0.3.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed ScikitLearnBase ──── v0.5.0
 Installed CMake ────────────── v1.1.2
 Installed FileIO ───────────── v1.2.1
 Installed HDF5 ─────────────── v0.12.5
 Installed DataStructures ───── v0.17.9
 Installed URIParser ────────── v0.4.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed Blosc ────────────── v0.5.1
 Installed SortingAlgorithms ── v0.3.1
 Installed OrderedCollections ─ v1.1.0
 Installed BinDeps ──────────── v1.0.0
 Installed StatsFuns ────────── v0.9.3
 Installed Clustering ───────── v0.13.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed QuadGK ───────────── v2.3.1
 Installed DataAPI ──────────── v1.1.0
 Installed Compat ───────────── v2.2.0
 Installed LegacyStrings ────── v0.4.1
 Installed Arpack ───────────── v0.4.0
 Installed SpecialFunctions ─── v0.9.0
 Installed Missings ─────────── v0.4.3
 Installed Distances ────────── v0.8.2
 Installed Distributions ────── v0.22.3
 Installed Parameters ───────── v0.12.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed NearestNeighbors ─── v0.4.4
 Installed StaticArrays ─────── v0.12.1
 Installed StatsBase ────────── v0.32.0
 Installed FillArrays ───────── v0.8.4
 Installed Rmath ────────────── v0.6.0
 Installed BinaryProvider ───── v0.5.8
 Installed JLD ──────────────── v0.9.1
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_hhlsW8/Project.toml`
 [no changes]
  Updating `/tmp/jl_hhlsW8/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_4OHlFy/Project.toml`
 [no changes]
  Updating `/tmp/jl_4OHlFy/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_7nQEeW/Project.toml`
 [no changes]
  Updating `/tmp/jl_7nQEeW/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_cNooPE/Project.toml`
 [no changes]
  Updating `/tmp/jl_cNooPE/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_ZbvBVG/Project.toml`
 [no changes]
  Updating `/tmp/jl_ZbvBVG/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_ZbvBVG/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -6.468219891888716e6, [80659.73955506913, 19340.260444930882], [-17034.565945612434 -21199.842259678073 -820.7197268430327; 16919.179586573813 21588.67638675189 1152.7033106139859], [[72147.29677804615 -12043.93070199952 -829.6541583941622; -12043.930701999521 66386.98266761852 -1087.4080711296601; -829.6541583941621 -1087.40807112966 80984.85826565478], [27957.80514155851 11724.248328240054 188.99895910981186; 11724.248328240054 34080.38324936619 1025.9211481666512; 188.99895910981184 1025.9211481666512 19084.085443730055]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.420766e+03
      1       9.999039e+02      -4.208617e+02 |        7
      2       9.697503e+02      -3.015361e+01 |        0
      3       9.697503e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 969.7502852101079)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.078096
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.795199
[ Info: iteration 2, lowerbound -3.663965
[ Info: iteration 3, lowerbound -3.525373
[ Info: iteration 4, lowerbound -3.368265
[ Info: iteration 5, lowerbound -3.199616
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -3.025085
[ Info: iteration 7, lowerbound -2.854944
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.699405
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.561528
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.459585
[ Info: iteration 11, lowerbound -2.387469
[ Info: iteration 12, lowerbound -2.343982
[ Info: dropping number of Gaussions to 3
[ Info: iteration 13, lowerbound -2.318799
[ Info: iteration 14, lowerbound -2.307414
[ Info: dropping number of Gaussions to 2
[ Info: iteration 15, lowerbound -2.302952
[ Info: iteration 16, lowerbound -2.299262
[ Info: iteration 17, lowerbound -2.299257
[ Info: iteration 18, lowerbound -2.299255
[ Info: iteration 19, lowerbound -2.299254
[ Info: iteration 20, lowerbound -2.299253
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sat Jan 18 20:11:11 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sat Jan 18 20:11:18 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Sat Jan 18 20:11:20 2020: EM with 272 data points 0 iterations avll -2.078096
5.8 data points per parameter
, Sat Jan 18 20:11:22 2020: GMM converted to Variational GMM
, Sat Jan 18 20:11:30 2020: iteration 1, lowerbound -3.795199
, Sat Jan 18 20:11:30 2020: iteration 2, lowerbound -3.663965
, Sat Jan 18 20:11:30 2020: iteration 3, lowerbound -3.525373
, Sat Jan 18 20:11:30 2020: iteration 4, lowerbound -3.368265
, Sat Jan 18 20:11:30 2020: iteration 5, lowerbound -3.199616
, Sat Jan 18 20:11:30 2020: dropping number of Gaussions to 7
, Sat Jan 18 20:11:30 2020: iteration 6, lowerbound -3.025085
, Sat Jan 18 20:11:30 2020: iteration 7, lowerbound -2.854944
, Sat Jan 18 20:11:30 2020: dropping number of Gaussions to 6
, Sat Jan 18 20:11:30 2020: iteration 8, lowerbound -2.699405
, Sat Jan 18 20:11:30 2020: dropping number of Gaussions to 5
, Sat Jan 18 20:11:30 2020: iteration 9, lowerbound -2.561528
, Sat Jan 18 20:11:30 2020: dropping number of Gaussions to 4
, Sat Jan 18 20:11:30 2020: iteration 10, lowerbound -2.459585
, Sat Jan 18 20:11:30 2020: iteration 11, lowerbound -2.387469
, Sat Jan 18 20:11:30 2020: iteration 12, lowerbound -2.343982
, Sat Jan 18 20:11:30 2020: dropping number of Gaussions to 3
, Sat Jan 18 20:11:30 2020: iteration 13, lowerbound -2.318799
, Sat Jan 18 20:11:30 2020: iteration 14, lowerbound -2.307414
, Sat Jan 18 20:11:30 2020: dropping number of Gaussions to 2
, Sat Jan 18 20:11:30 2020: iteration 15, lowerbound -2.302952
, Sat Jan 18 20:11:30 2020: iteration 16, lowerbound -2.299262
, Sat Jan 18 20:11:30 2020: iteration 17, lowerbound -2.299257
, Sat Jan 18 20:11:30 2020: iteration 18, lowerbound -2.299255
, Sat Jan 18 20:11:30 2020: iteration 19, lowerbound -2.299254
, Sat Jan 18 20:11:30 2020: iteration 20, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 21, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 22, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 23, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 24, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 25, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 26, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 27, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 28, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 29, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 30, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 31, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 32, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 33, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 34, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 35, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 36, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 37, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 38, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 39, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 40, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 41, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 42, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 43, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 44, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 45, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 46, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 47, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 48, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 49, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: iteration 50, lowerbound -2.299253
, Sat Jan 18 20:11:30 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601388, 95.95490777398618]
β = [178.04509222601388, 95.95490777398618]
m = [4.250300733269908 79.28686694436183; 2.0002292577753704 53.8519871724613]
ν = [180.04509222601388, 97.95490777398618]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484194 -0.007644049042327396; 0.0 0.008581705166333407], [0.37587636119483925 -0.008953123827346093; 0.0 0.012748664777409381]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000007
avll from stats: -0.9782522109648274
avll from llpg:  -0.9782522109648271
avll direct:     -0.9782522109648271
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9938380280899171
avll from llpg:  -0.9938380280899171
avll direct:     -0.9938380280899171
sum posterior: 100000.00000000001
32×26 Array{Float64,2}:
 -0.16267      0.0210016   -0.0546516   -0.179755    -0.0274105    0.0946959   -0.20009     -0.083812     0.0665554   -0.0993513    0.0302922  -0.0205871   -0.0523837    -0.116022     0.0335895    -0.167689    -0.145264    -0.153791     0.0642134    0.0494332   -0.0711593   -0.033222   -0.243372   -0.0613474    0.00546609   0.0179901
 -0.0605346   -0.0136717   -0.0919238    0.0926693    0.0602411    0.00998512  -0.064113    -0.00713083   0.0415657   -0.179019     0.022165    0.116913     0.0747223    -0.0221946    0.144039      0.0241291    0.0707271    0.237704     0.0506036    0.141152     0.0506308   -0.0418983   0.0145628   0.139533    -0.130072    -0.0208346
 -0.0902525    0.109424    -0.0483728    0.123678    -0.0108713    0.0406758    0.102218    -0.146931     0.0173689    0.0538988    0.0633001  -0.0139063   -0.0885253     0.129346    -0.0874124     0.175347     0.103854    -0.156089     0.0394879    0.119108    -0.02594     -0.0830562   0.0488782  -0.0827526    0.18914      0.108927
 -0.00777254   0.00450464  -0.00285715   0.059587    -0.0627312   -0.00532438  -0.0442589    0.154213     0.170527    -0.0712558   -0.0496275  -0.0135073    0.016461      0.11817     -0.0134832     0.0907287   -0.0476386    0.0830111   -0.172577    -0.106573    -0.145239     0.0036359  -0.030683    0.160211     0.0575411   -0.255155
  0.132205    -0.0818881   -0.0501028   -0.0473813   -0.102131    -0.0603964    0.132866    -0.0148174    0.0844269    0.00378327  -0.0531051   0.0334815   -0.0382575     0.0890392    0.196784      0.154747    -0.177058     0.0988212    0.148026     0.130444    -0.00722798   0.101763   -0.0620136  -0.0157961    0.0945156   -0.0558943
  0.00334084  -0.0460055    0.0296607    0.172528    -0.0332135   -0.0532243   -0.0900461   -0.0157257   -0.062402    -0.202793     0.170916    0.0229774   -0.0923738     0.00918524  -0.288172      0.0522374   -0.149896    -0.0219704   -0.229425    -0.0994087   -0.0943948    0.0578405   0.0809432  -0.128215     0.126516     0.0492616
 -0.100346    -0.0572475    0.0293601   -0.0721668   -0.167854    -0.0256846    0.0682007    0.0579073    0.110258     0.0579357    0.11457    -0.0657771    0.137718     -0.00901832  -0.0132604     0.151045     0.0190267   -0.00996876   0.0784094   -0.078248     0.0323491   -0.080359    0.0644841  -0.00701827  -0.109013    -0.0836509
 -0.152437     0.123913    -0.117519     0.0353035   -0.0523132   -0.0465207    0.116574    -0.0544184   -0.315698     0.227056     0.0106476  -0.210783     0.0655852    -0.117774     0.0382884    -0.019812     0.196543    -0.151526     0.0957639    0.105864     0.137977    -0.0528293  -0.100264   -0.0255661   -0.0587755    0.198179
 -0.0158817    0.308995    -0.0349482   -0.0758786    0.0803823   -0.188393     0.0852519    0.0522824   -0.152068     0.0547399    0.111034    0.0699813   -0.0195571     0.205617     0.179291     -0.0300154   -0.0735528    0.0242994   -0.0636811    0.159167     0.0352814    0.0923602  -0.0719342   0.0346286   -0.0229979   -0.0811696
  0.123784    -0.102663    -0.0443031   -0.207981    -0.109806     0.0462268   -0.0299686    0.00581511  -0.0190021   -0.144789    -0.0755466   0.11526     -0.130534      0.0107112    0.15427      -0.0568558   -0.0674614   -0.0656555    0.233081     0.0127807   -0.0299542    0.19294     0.153839    0.128958    -0.0500227   -0.091127
  0.0219056   -0.0317802    0.00425239   0.181875    -0.220625    -0.0060262    0.132615     0.0205695    0.029311     0.0427744    0.0403928  -0.233351     0.0276723     0.0762869   -0.084062     -0.0329759   -0.00508942   0.0389769   -0.124616    -0.110778     0.0896226   -0.124017   -0.141902    0.0470848   -0.0418685    0.181632
 -0.0372068    0.0331358    0.0201521    0.00167039  -0.0402127    0.148851    -0.043998    -0.165291    -0.0439235   -0.00766567  -0.0168218  -0.270915     0.0631367     0.0336751    0.222095      0.124236    -0.0254416   -0.13292      0.17249     -0.070105     0.003405     0.0850624  -0.152519   -0.115043    -0.0549412    0.0724195
 -0.0619839   -0.0851127   -0.124829     0.210983    -0.0743371    0.0345131    0.0568509   -0.0289168   -0.017781    -0.0671645   -0.024354   -0.175878    -0.0265761    -0.00179267  -0.113876     -0.0165067   -0.0109938   -0.0644538    0.108842    -0.0212215    0.164603    -0.0105839   0.122327   -0.0930181    0.0200209    0.145207
 -0.0224808    0.196627    -0.0360659   -0.0841217    0.209267    -0.0607795   -0.0247047   -0.0379248    0.0262487    0.0307909    0.0273194   0.028741     0.0177931     0.0934343   -0.129357      0.151747    -0.17444      0.0950953    0.0117915    0.0714419   -0.0659587    0.115325   -0.0319559  -0.0708072   -0.260912    -0.0875693
  0.0651773   -0.00659282   0.0749156    0.052442     0.0895964   -0.133743    -0.00540946   0.0682265    0.011552    -0.023159    -0.16443     0.0826354   -0.0167451    -0.226026     0.015476     -0.0966459   -0.194087     0.103853     0.00302434   0.0603726   -0.124422    -0.121503    0.0883202   0.110473     0.164087     0.000232625
 -0.0601596   -0.101968    -0.135207    -0.00185309   0.00155952  -0.0724427   -0.00177406  -0.0740957   -0.181451    -0.0385504   -0.0113581   0.174873    -0.0314481    -0.0410188   -0.0149329    -0.030347    -0.0833968   -0.0140553   -0.0587843   -0.0962423    0.198717     0.0231016   0.0576549   0.0217347   -0.123021     0.120226
  0.00231456  -0.0772692    0.03534      0.0254933   -0.131097    -0.128589     0.0855778    0.07609     -0.0346879    0.0823973    0.0317422   0.02424     -0.0744424    -0.110122     0.128017      0.00250015  -0.017523    -0.150077     0.0117871   -0.0449096    0.183654     0.126966    0.12307     0.0221691    0.0241053    0.0395088
 -0.122681     0.0535589   -0.148988    -0.0907492   -0.109626     0.0544524   -0.0492001   -0.0140842    0.0405713   -0.0622461    0.134324    0.124937     0.0792704    -0.035814     0.0829359     0.0213195    0.0487701    0.0818139   -0.372931    -0.140338     0.13452     -0.0718675  -0.0359261  -0.118901    -0.162873    -0.00919785
  0.00276179   0.133578    -0.0304157   -0.0231674    0.0254524   -0.0163272   -9.85836e-5   0.0392602    0.0378713    0.0853842    0.0748787   0.00857222  -0.0416152     0.138355     0.0608316    -0.0679962    0.00676402  -0.0903799    0.210499    -0.139563     0.143387    -0.0853855  -0.0697705   0.00344709   0.00192513  -0.0640052
  0.145962     0.125699     0.0916171   -0.0879352   -0.10429      0.00112382   0.193627     0.0189037    0.00253931   0.114303     0.0560014  -0.116456    -0.104995      0.0245282   -0.104247      0.178873    -0.0626507    0.178796    -0.00548378   0.0756073    0.0985828    0.0549085   0.172011    0.0307536   -0.0880837    0.187827
 -0.105478    -0.00802335   0.100319    -0.0937374   -0.114165    -4.39954e-5  -0.0218098    0.062721    -0.029528    -0.00674783   0.0760468   0.094859     0.0373792    -0.087617     0.0365857     0.0304334    0.0555238    0.204184     0.190766     0.0213446   -0.100979    -0.114007    0.0787966   0.0679664   -0.10523     -0.0707328
  0.151281    -0.0824366    0.00300231  -0.134638     0.0127764   -0.0678561    0.0864438   -0.0322093    0.111607     0.0912566    0.0762205  -0.0382481    0.0376656    -0.0667398   -0.0327587    -0.177735    -0.0942319    0.0668517    0.0424029    0.0589249    0.00735675   0.132648   -0.0309358   0.131936    -0.0341412    0.00204775
  0.233572     0.0605966    0.168255     0.0289118   -0.277262     0.0653646    0.0991239    0.0458039    0.0584233   -0.0710348    0.106154   -0.0987228   -0.0402145     0.165642     0.0365785    -0.0537828   -0.0205789    0.156067     0.176477     0.10468     -0.0987357    0.0591101   0.0528625  -0.110812     0.0240929   -0.132462
 -0.0675593   -0.209575     0.0323498    0.165781     0.0825598   -0.147728     0.0827735    0.198106     0.0646842    0.187428     0.0870446  -0.0949414   -0.0574074     0.0721812    0.00249484   -0.0151324   -0.0455629   -0.108479     0.104965    -0.115618    -0.0909671    0.026244   -0.0106262   0.0186823   -0.077057    -0.0659436
  0.00397887   0.106251     0.046804     0.00821971   0.0324128   -0.00944991  -0.0579726    0.16537      0.13559      0.118083     0.0849808  -0.00258961  -0.0612755    -0.0114332   -0.0738906    -0.165997    -0.157698    -0.0123739   -0.0213723   -0.109231     0.112927     0.19267    -0.082101   -0.0824495   -0.020264    -0.0309582
 -0.067315    -0.0599182    0.166555     0.178117    -0.0753599   -0.0932069   -0.104506    -0.162201     0.146265     0.0801719   -0.0558186  -0.10099     -0.100009      0.0456498    0.00385183    0.0867955   -0.105691    -0.170757     0.0709675   -0.0277801   -0.274528     0.0574211  -0.0105595   0.14375     -0.0952545    0.157282
 -0.0665459    0.092368    -0.17594     -0.149826    -0.0408855   -0.0849172   -0.0197158    0.0205278   -0.196826     0.023369     0.0280892   0.127302     0.168423     -0.0647595    0.00883258   -0.0107459   -0.0674665    0.160673     0.152815    -0.02762     -0.237244    -0.090885    0.131257   -0.0581626    0.120714    -0.0871946
  0.138795    -0.107514     0.0726944   -0.0816458   -0.14486      0.140218    -0.072277     0.0407452   -0.0720914   -0.0692246    0.0157718  -0.18481      0.0775368    -0.0494793    0.155663     -0.0175895   -0.0176119    0.0914842   -0.0976773    0.00773624  -0.0431901    0.0132757  -0.0535452   0.0553773   -0.0124677   -0.0168245
 -0.248842     0.104495    -0.0320241    0.0693755    0.11607     -0.113154     0.0031148   -0.042132     0.12266     -0.071286    -0.0323866   0.125631     0.137758      0.0294112    0.0222548    -0.0747346    0.0257964   -0.0250165   -0.0207691   -0.0453216    0.089136     0.0374257  -0.0249908   0.027185     0.0491234   -0.00375788
 -0.11699     -0.123274     0.150807     0.253658    -0.146625     0.083404    -0.0264036    0.130464     0.0237445    0.0132847   -0.202689   -0.128386     0.0270984     0.030271     0.0613989    -0.0420918    0.0161123   -0.146611     0.165821    -0.128698     0.0880598    0.0441321   0.210342    8.34355e-5  -0.233116    -0.139758
  0.0189663    0.00264889   0.0436368    0.0209131    0.137557    -0.0635676    0.0790662    0.0884129    0.0099092    0.169934    -0.0219711   0.112744    -0.000792827   0.065462    -0.0384181    -0.0474251   -0.0814941   -0.328201    -0.0795581   -0.0873038    0.113177     0.132306   -0.0971257  -0.0949525    0.0858575    0.0817801
  0.0384426   -0.164596     0.0770531   -0.0283764   -0.0114851    0.0175846   -0.0377799    0.072784     0.0898467   -0.0214482    0.0506159   0.178558     0.0624881     0.0298912   -0.000339312   0.222832     0.019567     0.0834034    0.133093    -0.174416     0.0374536   -0.106474   -0.10134     0.129643    -0.122122    -0.0765147kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4234590150902666
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423540
[ Info: iteration 2, average log likelihood -1.423470
[ Info: iteration 3, average log likelihood -1.422865
[ Info: iteration 4, average log likelihood -1.415354
[ Info: iteration 5, average log likelihood -1.397218
[ Info: iteration 6, average log likelihood -1.390264
[ Info: iteration 7, average log likelihood -1.389227
[ Info: iteration 8, average log likelihood -1.388793
[ Info: iteration 9, average log likelihood -1.388515
[ Info: iteration 10, average log likelihood -1.388308
[ Info: iteration 11, average log likelihood -1.388140
[ Info: iteration 12, average log likelihood -1.387984
[ Info: iteration 13, average log likelihood -1.387798
[ Info: iteration 14, average log likelihood -1.387393
[ Info: iteration 15, average log likelihood -1.386144
[ Info: iteration 16, average log likelihood -1.385187
[ Info: iteration 17, average log likelihood -1.384884
[ Info: iteration 18, average log likelihood -1.384757
[ Info: iteration 19, average log likelihood -1.384677
[ Info: iteration 20, average log likelihood -1.384614
[ Info: iteration 21, average log likelihood -1.384558
[ Info: iteration 22, average log likelihood -1.384504
[ Info: iteration 23, average log likelihood -1.384448
[ Info: iteration 24, average log likelihood -1.384384
[ Info: iteration 25, average log likelihood -1.384302
[ Info: iteration 26, average log likelihood -1.384186
[ Info: iteration 27, average log likelihood -1.384029
[ Info: iteration 28, average log likelihood -1.383880
[ Info: iteration 29, average log likelihood -1.383779
[ Info: iteration 30, average log likelihood -1.383717
[ Info: iteration 31, average log likelihood -1.383675
[ Info: iteration 32, average log likelihood -1.383642
[ Info: iteration 33, average log likelihood -1.383614
[ Info: iteration 34, average log likelihood -1.383588
[ Info: iteration 35, average log likelihood -1.383562
[ Info: iteration 36, average log likelihood -1.383537
[ Info: iteration 37, average log likelihood -1.383513
[ Info: iteration 38, average log likelihood -1.383489
[ Info: iteration 39, average log likelihood -1.383465
[ Info: iteration 40, average log likelihood -1.383442
[ Info: iteration 41, average log likelihood -1.383419
[ Info: iteration 42, average log likelihood -1.383395
[ Info: iteration 43, average log likelihood -1.383367
[ Info: iteration 44, average log likelihood -1.383337
[ Info: iteration 45, average log likelihood -1.383304
[ Info: iteration 46, average log likelihood -1.383266
[ Info: iteration 47, average log likelihood -1.383223
[ Info: iteration 48, average log likelihood -1.383173
[ Info: iteration 49, average log likelihood -1.383115
[ Info: iteration 50, average log likelihood -1.383050
┌ Info: EM with 100000 data points 50 iterations avll -1.383050
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.423540038741485
│     -1.423470453547848
│      ⋮
└     -1.3830500521591094
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.383072
[ Info: iteration 2, average log likelihood -1.382882
[ Info: iteration 3, average log likelihood -1.381663
[ Info: iteration 4, average log likelihood -1.371513
[ Info: iteration 5, average log likelihood -1.352535
[ Info: iteration 6, average log likelihood -1.344815
[ Info: iteration 7, average log likelihood -1.342420
[ Info: iteration 8, average log likelihood -1.340894
[ Info: iteration 9, average log likelihood -1.339619
[ Info: iteration 10, average log likelihood -1.338539
[ Info: iteration 11, average log likelihood -1.337635
[ Info: iteration 12, average log likelihood -1.336921
[ Info: iteration 13, average log likelihood -1.336367
[ Info: iteration 14, average log likelihood -1.335905
[ Info: iteration 15, average log likelihood -1.335476
[ Info: iteration 16, average log likelihood -1.335152
[ Info: iteration 17, average log likelihood -1.334976
[ Info: iteration 18, average log likelihood -1.334871
[ Info: iteration 19, average log likelihood -1.334805
[ Info: iteration 20, average log likelihood -1.334761
[ Info: iteration 21, average log likelihood -1.334731
[ Info: iteration 22, average log likelihood -1.334711
[ Info: iteration 23, average log likelihood -1.334697
[ Info: iteration 24, average log likelihood -1.334687
[ Info: iteration 25, average log likelihood -1.334680
[ Info: iteration 26, average log likelihood -1.334674
[ Info: iteration 27, average log likelihood -1.334670
[ Info: iteration 28, average log likelihood -1.334667
[ Info: iteration 29, average log likelihood -1.334665
[ Info: iteration 30, average log likelihood -1.334662
[ Info: iteration 31, average log likelihood -1.334660
[ Info: iteration 32, average log likelihood -1.334659
[ Info: iteration 33, average log likelihood -1.334657
[ Info: iteration 34, average log likelihood -1.334656
[ Info: iteration 35, average log likelihood -1.334654
[ Info: iteration 36, average log likelihood -1.334653
[ Info: iteration 37, average log likelihood -1.334652
[ Info: iteration 38, average log likelihood -1.334650
[ Info: iteration 39, average log likelihood -1.334649
[ Info: iteration 40, average log likelihood -1.334648
[ Info: iteration 41, average log likelihood -1.334646
[ Info: iteration 42, average log likelihood -1.334645
[ Info: iteration 43, average log likelihood -1.334644
[ Info: iteration 44, average log likelihood -1.334643
[ Info: iteration 45, average log likelihood -1.334642
[ Info: iteration 46, average log likelihood -1.334641
[ Info: iteration 47, average log likelihood -1.334640
[ Info: iteration 48, average log likelihood -1.334639
[ Info: iteration 49, average log likelihood -1.334638
[ Info: iteration 50, average log likelihood -1.334637
┌ Info: EM with 100000 data points 50 iterations avll -1.334637
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3830723786466075
│     -1.3828820024628095
│      ⋮
└     -1.3346368036002274
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.334807
[ Info: iteration 2, average log likelihood -1.334634
[ Info: iteration 3, average log likelihood -1.333674
[ Info: iteration 4, average log likelihood -1.324261
[ Info: iteration 5, average log likelihood -1.304722
[ Info: iteration 6, average log likelihood -1.291550
[ Info: iteration 7, average log likelihood -1.285072
[ Info: iteration 8, average log likelihood -1.280960
[ Info: iteration 9, average log likelihood -1.278309
[ Info: iteration 10, average log likelihood -1.276491
[ Info: iteration 11, average log likelihood -1.275151
[ Info: iteration 12, average log likelihood -1.274087
[ Info: iteration 13, average log likelihood -1.273166
[ Info: iteration 14, average log likelihood -1.272366
[ Info: iteration 15, average log likelihood -1.271702
[ Info: iteration 16, average log likelihood -1.271181
[ Info: iteration 17, average log likelihood -1.270767
[ Info: iteration 18, average log likelihood -1.270389
[ Info: iteration 19, average log likelihood -1.269962
[ Info: iteration 20, average log likelihood -1.269378
[ Info: iteration 21, average log likelihood -1.268532
[ Info: iteration 22, average log likelihood -1.267437
[ Info: iteration 23, average log likelihood -1.266445
[ Info: iteration 24, average log likelihood -1.265998
[ Info: iteration 25, average log likelihood -1.265857
[ Info: iteration 26, average log likelihood -1.265764
[ Info: iteration 27, average log likelihood -1.265680
[ Info: iteration 28, average log likelihood -1.265600
[ Info: iteration 29, average log likelihood -1.265524
[ Info: iteration 30, average log likelihood -1.265448
[ Info: iteration 31, average log likelihood -1.265369
[ Info: iteration 32, average log likelihood -1.265291
[ Info: iteration 33, average log likelihood -1.265215
[ Info: iteration 34, average log likelihood -1.265145
[ Info: iteration 35, average log likelihood -1.265085
[ Info: iteration 36, average log likelihood -1.265039
[ Info: iteration 37, average log likelihood -1.265006
[ Info: iteration 38, average log likelihood -1.264983
[ Info: iteration 39, average log likelihood -1.264967
[ Info: iteration 40, average log likelihood -1.264958
[ Info: iteration 41, average log likelihood -1.264952
[ Info: iteration 42, average log likelihood -1.264948
[ Info: iteration 43, average log likelihood -1.264945
[ Info: iteration 44, average log likelihood -1.264944
[ Info: iteration 45, average log likelihood -1.264943
[ Info: iteration 46, average log likelihood -1.264942
[ Info: iteration 47, average log likelihood -1.264941
[ Info: iteration 48, average log likelihood -1.264941
[ Info: iteration 49, average log likelihood -1.264941
[ Info: iteration 50, average log likelihood -1.264940
┌ Info: EM with 100000 data points 50 iterations avll -1.264940
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3348073473187367
│     -1.3346342988139148
│      ⋮
└     -1.2649403903986947
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.265190
[ Info: iteration 2, average log likelihood -1.264858
[ Info: iteration 3, average log likelihood -1.262421
[ Info: iteration 4, average log likelihood -1.238124
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.199499
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.187958
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.175514
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.172737
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.164253
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.177250
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.172670
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.168823
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.171699
[ Info: iteration 14, average log likelihood -1.174945
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.156579
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.170309
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.167539
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.171295
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.165977
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.173809
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.163093
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.172572
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.162764
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.160432
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.175629
[ Info: iteration 26, average log likelihood -1.175318
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.157398
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.172374
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.170544
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.163837
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.160974
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.168106
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.167541
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.174058
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.165112
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.164161
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.169706
[ Info: iteration 38, average log likelihood -1.172383
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.153419
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.167378
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.175124
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.165898
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.163885
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.172137
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.161669
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.171804
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.162520
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.160326
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.158805
[ Info: iteration 50, average log likelihood -1.182651
┌ Info: EM with 100000 data points 50 iterations avll -1.182651
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2651895338433932
│     -1.264858468812031
│      ⋮
└     -1.182650501096761
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.158170
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.154955
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.155259
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     20
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.144401
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     10
│     17
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.125853
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     14
│     17
│      ⋮
│     20
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.114650
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│      9
│     10
│     17
│     18
│     19
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.107424
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     20
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.099872
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      9
│     10
│     14
│      ⋮
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.091009
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.102132
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.080830
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     14
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.075698
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.108119
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     20
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.081770
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.082760
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      9
│     10
│     14
│     17
│     18
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.080010
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.098863
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     20
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.085425
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.087052
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      9
│     10
│     14
│      ⋮
│     20
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.071940
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.100656
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.091475
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.080027
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     12
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.072873
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.107859
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.082107
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.082561
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      9
│     10
│     12
│      ⋮
│     18
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.079155
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.099214
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     20
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.085287
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.087137
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      9
│     10
│     12
│      ⋮
│     20
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.071837
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.100703
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     12
│     17
│     18
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.091394
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.079793
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      9
│     10
│     14
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.072994
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     12
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.107576
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.082147
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     14
│     17
│      ⋮
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.081910
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      9
│     10
│     12
│      ⋮
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.085250
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.090042
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      9
│     10
│     12
│     14
│      ⋮
│     24
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.073242
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.095464
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      9
│     10
│     17
│      ⋮
│     20
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.074118
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     12
│     14
│      ⋮
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.096727
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.093482
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     12
│     17
│     18
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.081786
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      9
│     10
│     14
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.073702
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.103068
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     12
│     17
│      ⋮
│     24
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.072931
┌ Info: EM with 100000 data points 50 iterations avll -1.072931
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1581695489982544
│     -1.1549551381607892
│      ⋮
└     -1.072931185450372
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4234590150902666
│     -1.423540038741485
│     -1.423470453547848
│     -1.4228648444545395
│      ⋮
│     -1.0737022014953714
│     -1.1030678441640578
└     -1.072931185450372
32×26 Array{Float64,2}:
  0.0524332    0.0724716    0.0579801   -0.10924     -0.141969    -0.0132645    0.0950747    0.0271631    -0.0238824    0.0616239    0.0620025  -0.0381805   -0.0296388    -0.0168065   -0.0441196    0.119267    -0.0311289    0.172649     0.0797862    0.0571689  -0.00986463  -0.00161298   0.146976     0.0398602   -0.0850829    0.0765433
 -0.0211281   -0.0218909   -0.00638019   0.0434528   -0.0528331   -0.00273389  -0.0409621    0.142741      0.178749    -0.0703466   -0.043442   -0.0155526    0.00234857    0.116215    -0.0138469    0.0685115   -0.0284077    0.0829014   -0.16486     -0.103696   -0.138347     0.00999181  -0.0231701    0.191964     0.0631521   -0.257722
 -0.0256899   -0.135752    -0.002281     0.175921     0.0105004   -0.0854326   -0.00301445   0.103058     -0.0094944   -0.0308487    0.121807   -0.0259855   -0.0663677     0.0410529   -0.124029     0.012469    -0.111051    -0.0663265   -0.0434977   -0.093351   -0.0734054    0.059357     0.0032866   -0.0536443    0.0201014   -0.00934017
  0.00798558  -0.0356497   -0.0407911   -0.00575928  -0.0239433   -0.0068349    0.0212478   -0.0193032    -0.0407469   -0.0359811    0.0137209  -0.0407383    0.000461376  -0.00756068   0.0294918    0.0497355   -0.0874599    0.038634     0.0238885    0.0311779   0.0613555    0.0297166    0.0112066   -0.0275979   -0.0657615    0.0248855
 -0.122539     0.0602598   -0.144153    -0.108058    -0.105157     0.0342739   -0.0533621   -0.0199154     0.0327668   -0.0608574    0.136957    0.119871     0.0773578    -0.0617627    0.0912105   -0.0334721    0.04313      0.0752009   -0.359114    -0.137381    0.131708    -0.0607017   -0.0893105   -0.117186    -0.161434     0.019403
 -0.0143971    0.0300408   -0.0846962   -0.00412303  -0.135164    -0.0420344    0.0483047    0.011537     -0.104333     0.032508     0.0123185  -0.0557963    0.098328      0.00937934  -0.0385361   -0.0159774   -0.0252948    0.0965183    0.0246291   -0.0727539  -0.102653    -0.0950221   -0.00602383  -0.00687292   0.0154141    0.050393
 -0.0987305   -0.0680062    0.0451812   -0.0919056    0.0331459   -0.0571446    0.0570449    0.0631344     0.239172     0.0915617    0.0773083  -0.0395653    0.16652      -0.049786    -0.0454907    0.182545    -0.0117043   -0.56079      0.126832    -0.0753533  -0.0311494   -0.195982     0.0891344   -0.0150558   -0.0719102   -0.191392
 -0.110693    -0.0437412    0.022522    -0.0415903   -0.294933    -0.0118191    0.0698947    0.0537248     0.0135233    0.0226002    0.147871   -0.119755     0.140824      0.0261445   -0.0111141    0.106496    -0.0125357    0.505644     0.0544687   -0.0748966   0.109986    -0.126767     0.0449813    0.0142444   -0.123794    -0.0176512
  0.00228071   0.132307    -0.0221194   -0.0131175    0.0429322    0.121314     0.145497     0.0558776     0.0326079    0.0721643    0.328161    0.0742735   -0.0410492     0.173818    -0.0281689   -0.0668489    0.00684139  -0.0904253    0.179914    -0.613826    0.141566    -0.101852    -0.0594697    0.0752149    0.260194    -0.059811
  0.00256949   0.134517    -0.0527966   -0.0388299   -0.0189508   -0.0578101   -0.12651     -0.0145534     0.0395414    0.0801996   -0.278986   -0.0484116   -0.0397086     0.112416     0.160003    -0.0679364    0.00681271  -0.0896647    0.237969     0.18304     0.144929    -0.0726528   -0.093613    -0.0625301   -0.17585     -0.0628737
 -0.118805    -0.112669     0.0319951   -0.00414123  -0.188225    -0.164794     0.138475     0.0589961    -0.0315227    0.054454    -0.0632602  -0.116963    -0.072366     -0.0705936    0.209634     0.00220019  -0.00127511  -0.198693     0.0233123   -0.0831163   0.176711     0.125226     0.144216     0.0223501    0.120539    -0.30443
  0.110524    -0.0667531    0.0653381    0.0448517   -0.0777083   -0.0636274    0.0748983    0.0883626    -0.0377357    0.0732776    0.113793    0.203131    -0.0837354    -0.139748     0.0431478    0.00277869  -0.0258838   -0.114302     0.00114932  -0.0108006   0.185785     0.125701     0.105427     0.0218693   -0.0494083    0.330934
 -0.207197     0.129575    -0.0333077    0.0583518    0.112895    -0.0896285    0.00276532  -0.044622      0.118715    -0.0578733   -0.0311659   0.0747493    0.105279     -0.0061993    0.0396993   -0.0062416    0.0346573   -0.0205117   -0.0222865   -0.0273729   0.0554808    0.00362497  -0.04274      0.0246628    2.8113e-5    0.00913144
  0.00972324   0.102145     0.0404026   -0.00657928  -0.00439393   0.016288    -0.0605023    0.161812      0.137738     0.147524     0.0691749   1.76151e-5  -0.0661611    -0.0174828   -0.0802805   -0.149755    -0.167035    -0.0300662   -0.00761703  -0.0965911   0.134479     0.187901    -0.0983163   -0.0802488   -0.032989    -0.0348039
  0.148064    -0.0982331    0.0228575   -0.139275     0.16131     -0.0943851    0.0473085   -0.0614658     0.072872     0.111715    -1.06216    -0.114966     0.0109922    -0.0265562    0.00582254  -0.223652    -0.0952596    0.0696183    0.0550603    0.0790358   0.0126708    0.0921851   -0.175627     0.134522    -0.242147     0.0415337
  0.158265    -0.0666186   -0.0401638   -0.127107    -0.0473663   -0.032488     0.139383     0.000913819   0.122169     0.0664831    1.25369     0.015473     0.0644162    -0.135175    -0.0530008    0.0149772   -0.0979672    0.0653969    0.0258051    0.0111648  -0.00190166   0.168632     0.00830662   0.129264     0.103227    -0.0220332
  0.197161    -0.0603407    0.220146     0.326646    -0.292503    -0.0338812   -0.5209      -0.205337      0.146659     0.152913    -0.058992   -0.103427    -0.100684      0.0240836    0.00873011   0.0866255   -0.873061    -0.139615     0.0562741   -0.0497278  -0.279419     0.0275097   -0.00112126   0.153478    -0.153482     0.152724
 -0.236268    -0.0588075    0.12166      0.117121     0.233514    -0.167363     0.134707    -0.107947      0.147856     0.0161689   -0.0515723  -0.0522736   -0.0983316     0.0606694    0.00924853   0.0866941    0.602765    -0.227784     0.169755    -0.036469   -0.263874     0.0969377   -0.0022895    0.122011    -0.0364942    0.156844
 -0.118999     0.109639    -0.0453394    0.0916758   -0.0104281   -0.0641972   -0.120749    -0.228011      0.0166631    0.0670364    0.0629346   0.0809825   -0.0801415     0.133163    -0.194452     0.23494      0.0924955   -0.15338     -0.0637758   -0.074322   -0.0390703   -0.0913893    0.145758    -0.0396409    0.235044    -0.108792
 -0.0975594    0.102485    -0.0479334    0.137389    -0.00547315   0.0550278    0.0702466   -0.134558      0.0173835    0.0587889    0.065925    0.0152012   -0.0924165     0.111913    -0.0445863    0.168679     0.11083     -0.155302     0.0831878    0.119184   -0.0262694   -0.0838614   -0.00229011  -0.109131     0.160307     0.196473
 -0.0222964    0.0359159    0.00637676   0.00770326  -0.0364038    0.139731     0.0385481   -0.206885     -8.711e-5    -0.0314047   -0.0246065  -0.265777     0.0938686    -0.0545685    0.257099     0.124612     0.0582308   -0.0839244    0.124262    -0.072865    0.0377474    0.0828254   -0.175277    -0.660889    -0.0831845    0.126195
 -0.0587605    0.0340749    0.0397765    0.0231739   -0.048126     0.157525    -0.108076    -0.146378     -0.0709529    0.00115638  -0.0137786  -0.273322     0.0305179     0.0938387    0.156413     0.129972    -0.110406    -0.17967      0.246919    -0.0654949  -0.0353574    0.0851123   -0.121107     0.426698    -0.0445908    0.019653
 -0.0594449   -0.0235452   -0.0878243    0.0671249    0.0608382    0.0172491   -0.0695752    0.00880159    0.0456982   -0.189656     0.0322707   0.117867     0.0618027    -0.0253283    0.145673     0.0230098    0.0555142    0.223775     0.0566965    0.14514     0.0464476   -0.0368629   -0.00110008   0.151876    -0.15        -0.0243079
  0.122283    -0.10591     -0.0426046   -0.201107    -0.108904     0.0429321   -0.0224539    0.0889161    -0.0209531   -0.141956    -0.0840865   0.115291    -0.135237      0.00869303   0.154491    -0.0712234   -0.0708946   -0.0681678    0.235901     0.0101718  -0.0454815    0.190354     0.153063     0.130331    -0.047267    -0.0894513
 -0.0552666   -0.0963894    0.006109    -0.0919435   -0.0159265    0.0494898   -0.101051     0.0247494     0.0806942   -0.0450067    0.0530435   0.0676469    0.00430572   -0.0180876    0.0263893    0.0345938   -0.0487983   -0.00823681   0.100629    -0.0787801  -0.0116045   -0.0786655   -0.158758     0.0301673   -0.080362    -0.0380424
  0.0855938   -0.0131238    0.0729925    0.0431603    0.0733368   -0.134735    -0.0188078    0.060689      0.0153653   -0.0100221   -0.148661    0.0880242   -0.0159684    -0.229623     0.0418865   -0.0932754   -0.194128     0.072262    -0.0397825    0.0618942  -0.125589    -0.114638     0.0811242    0.106352     0.164175    -0.0169072
  0.176252     0.133799     0.160017     0.0209244   -0.275707     0.0878923    0.0821378    0.0268917    -0.137847     0.00175089   0.0872813  -0.112855    -0.0672063     0.157866     0.0207713   -0.115786    -0.023558     0.152704    -0.0132387    0.118177   -0.110648    -0.426001    -0.0444949   -0.22756      0.022307    -0.239607
  0.271377    -0.00742854   0.21308      0.0371592   -0.278885     0.037467     0.107898     0.0620951     0.261338    -0.130707     0.0911102  -0.0470951   -0.0645463     0.170714     0.0528296    0.00234125  -0.0107742    0.16929      0.30963      0.0921257  -0.0929116    0.528804     0.117824    -0.10616      0.0298507    0.00701651
 -0.0356803    0.31209     -0.0436539   -0.0725044    0.0810447   -0.184001     0.0724225    0.0753463    -0.15299      0.0572886    0.115956    0.0364363    0.0249091     0.215785     0.179048    -0.0281316   -0.103224     0.0194468   -0.0701495    0.152202    0.02703      0.0914148   -0.0729433    0.0477252   -0.00885296  -0.0978715
 -0.14037      0.128076    -0.120088     0.0247668   -0.0321047   -0.0467886    0.128288    -0.0384314    -0.282452     0.18986      0.0106699  -0.229276     0.0505293    -0.0984063    0.0349531   -0.0216422    0.204238    -0.172456     0.0939142    0.12666     0.137349    -0.0534988   -0.119445    -0.0329579   -0.065017     0.205816
  0.0131632    0.0117152    0.0415604    0.0294735    0.137524    -0.0777901    0.0871936    0.104441      0.00970177   0.171276    -0.0110795   0.119025     0.0283355     0.0618117   -0.0416561   -0.0215327   -0.118145    -0.318364    -0.105191    -0.0900222   0.115276     0.142475    -0.105159    -0.0670752    0.090995     0.0765873
 -0.138798    -0.121409     0.155439     0.283928    -0.155773     0.108117    -0.0167497    0.127644      0.0242525    0.0131474   -0.19174    -0.132047     0.0500687     0.0426058    0.0692153   -0.0476949    0.0275003   -0.140152     0.166111    -0.123104    0.0717816    0.0361377    0.209375     0.0519396   -0.261835    -0.123374[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.083224
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      9
│     10
│     12
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.064587
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     14
│     17
│     18
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.081215
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      9
│     10
│     14
│      ⋮
│     19
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.073955
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     12
│     14
│      ⋮
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.072441
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     14
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.072867
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     14
│     17
│     18
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.076264
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      9
│     10
│     12
│      ⋮
│     24
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.064305
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     14
│     17
│     18
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.082303
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     12
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.066171
┌ Info: EM with 100000 data points 10 iterations avll -1.066171
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.853573e+05
      1       6.883638e+05      -1.969934e+05 |       32
      2       6.625821e+05      -2.578171e+04 |       32
      3       6.502532e+05      -1.232896e+04 |       32
      4       6.428568e+05      -7.396372e+03 |       32
      5       6.378702e+05      -4.986569e+03 |       32
      6       6.344711e+05      -3.399146e+03 |       32
      7       6.318535e+05      -2.617543e+03 |       32
      8       6.294129e+05      -2.440679e+03 |       32
      9       6.274535e+05      -1.959364e+03 |       32
     10       6.257833e+05      -1.670235e+03 |       32
     11       6.240641e+05      -1.719130e+03 |       32
     12       6.225480e+05      -1.516178e+03 |       32
     13       6.213286e+05      -1.219328e+03 |       32
     14       6.204037e+05      -9.249171e+02 |       32
     15       6.197937e+05      -6.099715e+02 |       32
     16       6.193056e+05      -4.881832e+02 |       32
     17       6.189031e+05      -4.024306e+02 |       32
     18       6.185913e+05      -3.118583e+02 |       32
     19       6.183626e+05      -2.286548e+02 |       32
     20       6.181435e+05      -2.190982e+02 |       32
     21       6.178915e+05      -2.520365e+02 |       32
     22       6.176291e+05      -2.624151e+02 |       32
     23       6.173602e+05      -2.688904e+02 |       32
     24       6.170282e+05      -3.319863e+02 |       32
     25       6.165786e+05      -4.495961e+02 |       32
     26       6.159640e+05      -6.145593e+02 |       32
     27       6.154803e+05      -4.836840e+02 |       32
     28       6.152788e+05      -2.015719e+02 |       31
     29       6.152007e+05      -7.810179e+01 |       32
     30       6.151629e+05      -3.778760e+01 |       30
     31       6.151421e+05      -2.078567e+01 |       31
     32       6.151312e+05      -1.085974e+01 |       30
     33       6.151225e+05      -8.764389e+00 |       27
     34       6.151173e+05      -5.197625e+00 |       20
     35       6.151144e+05      -2.856875e+00 |       23
     36       6.151128e+05      -1.637777e+00 |       21
     37       6.151114e+05      -1.363484e+00 |       16
     38       6.151108e+05      -6.703902e-01 |       17
     39       6.151102e+05      -5.497227e-01 |       11
     40       6.151091e+05      -1.104077e+00 |       15
     41       6.151078e+05      -1.319104e+00 |       12
     42       6.151070e+05      -7.764801e-01 |       12
     43       6.151065e+05      -4.930444e-01 |       12
     44       6.151061e+05      -4.026904e-01 |       13
     45       6.151055e+05      -5.707261e-01 |       11
     46       6.151051e+05      -4.383933e-01 |        9
     47       6.151049e+05      -1.875492e-01 |        6
     48       6.151048e+05      -1.326643e-01 |        4
     49       6.151047e+05      -1.166673e-01 |        6
     50       6.151045e+05      -1.746634e-01 |        8
K-means terminated without convergence after 50 iterations (objv = 615104.485472426)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.325180
[ Info: iteration 2, average log likelihood -1.286611
[ Info: iteration 3, average log likelihood -1.247461
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.209493
[ Info: iteration 5, average log likelihood -1.180989
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     13
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.124709
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.115299
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.076276
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     13
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.073670
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.083899
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.076981
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.072880
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.047609
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     14
│     17
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.061965
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.105903
[ Info: iteration 16, average log likelihood -1.084442
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      3
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.045425
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     13
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.072336
[ Info: iteration 19, average log likelihood -1.086084
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│     17
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.038949
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.082913
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.085426
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.052794
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     14
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.042591
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.079582
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.076685
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     13
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.060601
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.065382
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.052592
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     13
│     17
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.038196
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.106172
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.068792
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     13
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.038814
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│     14
│     17
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.047313
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.091805
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.070866
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.058939
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     14
│     17
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.045347
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.083118
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.069711
[ Info: iteration 41, average log likelihood -1.070826
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     11
│     13
│     14
│     17
│     18
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.013424
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.109528
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.089657
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.042192
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│     11
│     14
│      ⋮
│     22
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.012658
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.118949
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.078528
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.055425
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     11
│     14
│     17
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.042414
┌ Info: EM with 100000 data points 50 iterations avll -1.042414
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.159631     0.00322408  -0.0565266   -0.167923    -0.0247593    0.0890643    -0.195537    -0.0990087    0.0642049   -0.0690971    0.0460618   -0.0133502  -0.0527939   -0.108202     0.03541      -0.182765    -0.146076    -0.115801    0.0526541   0.0497518   -0.0665543   -0.0276754   -0.243282    -0.0592289  -0.00389657   0.0506122
 -0.12301      0.0516696   -0.143385    -0.112612    -0.100556     0.0231433    -0.0493056   -0.0131109    0.0366254   -0.0601779    0.126952     0.123511    0.0718036   -0.065496     0.0889643    -0.0272672    0.0591199    0.0816126  -0.373831   -0.132553     0.126605    -0.0568542   -0.0914422   -0.111215   -0.162119     0.0103806
  0.015188     0.105684     0.0489831   -0.00733698  -0.012545     0.0255568    -0.0595113    0.171571     0.141954     0.162774     0.0766036   -0.0124897  -0.0613854   -0.0126604   -0.0801561    -0.16752     -0.163845    -0.04032    -0.0237685  -0.109484     0.143013     0.191928    -0.096363    -0.0802433  -0.027564    -0.0301598
 -0.019352     0.189987    -0.0332531   -0.0933003    0.204965    -0.112768      0.00620637  -0.0414441    0.0250534    0.113254     0.0687686   -0.125597   -0.0256117    0.0965419   -0.117021      0.15854     -0.15175      0.0329761   0.0117122   0.0701147   -0.0511054    0.121989    -0.0235614   -0.0735089  -0.267016    -0.0809714
  0.0125564    0.0103465    0.0424213    0.0378978    0.137717    -0.0771337     0.0865852    0.105918     0.0103554    0.16953     -0.0121217    0.118362    0.0301941    0.0648477   -0.039848     -0.0236578   -0.115988    -0.320207   -0.105571   -0.0947112    0.116813     0.140203    -0.100233    -0.065931    0.0876721    0.0779872
 -0.00977153  -0.0625063   -0.0629311    0.066208    -0.115032    -0.0320352     0.0650772   -0.0325045   -0.074439     0.00259199   0.0149292   -0.0491997  -0.0107181    0.0251831   -0.0567259    -0.031434    -0.0412205    0.0103895  -0.0838962  -0.085719     0.186455    -0.0639173   -0.0466144    0.0261169  -0.0995634    0.156764
  0.158902    -0.0695728   -0.0251375   -0.128255    -0.0177039   -0.0364568     0.135451    -0.0079263    0.123036     0.0727311    1.12477      0.0232587   0.0725459   -0.137805    -0.0446125     0.00738836  -0.0959464    0.0644268   0.0276187   0.0412419    0.00243683   0.164173    -0.00794512   0.130025    0.100966    -0.0152609
  0.131657    -0.253198     0.149903     0.21811      0.0803405   -0.189153      0.0883153    0.374194     0.0431808    0.17731      0.119198    -0.168033   -0.0849446    0.113094    -0.272257     -0.0189344   -0.0574347   -0.23626     0.0810671  -0.0857436   -0.121762     0.0783175   -0.127887     0.129591   -0.0931548   -0.0293541
  0.0718048    0.0475323    0.0150788   -0.0332997   -0.0822173   -0.0171486     0.0701679    0.0801008    0.0808374    0.0150573    0.00684176  -0.0647887  -0.0377103    0.0663603   -0.0688677     0.125828    -0.0571208    0.128118   -0.0766011  -0.00717125  -0.0227738    0.0400948    0.0825968    0.114952   -0.0155028   -0.0343515
 -0.11018      0.0229847    0.099124    -0.0864892   -0.17321      0.000157625  -0.0212626    0.0344397   -0.0429624   -0.00359989   0.0686455    0.0980359   0.0532199   -0.0885974    0.0451684     0.029904     0.0571237    0.197562    0.189989    0.0207522   -0.107484    -0.114608     0.0783201    0.0657545  -0.0937796   -0.0703674
  0.129812    -0.136342     0.0717839   -0.0783538   -0.140681     0.133528     -0.0655322    0.0861225   -0.0861072   -0.0770775    0.00652473  -0.23062     0.0977634   -0.0890021    0.265325     -0.0195596   -0.0409616    0.0929758  -0.0997316   0.0437579   -0.042595    -0.00553747  -0.0411098    0.0554784  -0.0122491   -0.00325072
 -0.14709     -0.0731965    0.0305475   -0.0423264   -0.208319    -0.0607118     0.0694207    0.0618613    0.0327523    0.0058983    0.131999    -0.144424    0.109116     0.0380128   -0.000289686   0.133351    -0.0582192    0.0997308   0.0563291  -0.0735429    0.0731479   -0.137652     0.0568058    0.0135933  -0.0396082   -0.0130599
 -0.143155    -0.118538     0.156042     0.291649    -0.160339     0.113086     -0.0158501    0.128867     0.0239519    0.0124554   -0.188512    -0.133827    0.0521561    0.0422942    0.0680661    -0.0458615    0.0231047   -0.141058    0.159583   -0.126548     0.0645819    0.0374772    0.20532      0.0561915  -0.252287    -0.117655
 -0.026952     0.191144    -0.0373329   -0.0813864    0.166393    -0.0456524    -0.0546221   -0.0276793    0.0401802    0.0722268    0.0437381    0.196885    0.0167663    0.0420773   -0.201413      0.141562    -0.207939     0.17539     0.0127079   0.070563    -0.0656914    0.136085    -0.0221128   -0.0598221  -0.258825    -0.117727
 -0.0345435    0.312053    -0.0439189   -0.0719893    0.0816348   -0.186879      0.0730589    0.0766118   -0.152462     0.0591837    0.115711     0.041613    0.0258885    0.216663     0.17918      -0.0277282   -0.0979389    0.0187381  -0.0714933   0.153075     0.0283572    0.0913996   -0.071915     0.048486   -0.0100316   -0.103018
  0.00245608   0.0269301    0.00445733  -0.00423506  -0.0569722   -0.0391587     0.0562038    0.0490794    0.00179564   0.0713005    0.0267902    0.0335111  -0.0564601    0.0212694    0.0946264    -0.0337915   -0.0017677   -0.120989    0.111101   -0.134724     0.161544     0.0154192    0.0213731    0.0137522   0.0382685   -0.0275032
 -0.0667622   -0.0785741   -0.100186     0.232851    -0.0577849    0.0336581     0.0491408   -0.0358983   -0.0130392   -0.0831941    0.0449417   -0.174344   -0.0292641   -0.0246494   -0.113612     -0.0050608   -0.0149048   -0.112951    0.109145   -0.0237899    0.159611     0.0217713    0.136715    -0.104321    0.0194985    0.145324
  0.0235763   -0.167387     0.0515248   -0.0285361   -0.0121136    0.0152948    -0.0295909    0.111547     0.0838957   -0.029903     0.0498995    0.128832    0.0468582    0.0337386    0.0228253     0.21691      0.0196754    0.0916475   0.132287   -0.171701     0.0306696   -0.118811    -0.095615     0.100335   -0.125321    -0.0935501
  0.146728    -0.100697     0.0194846   -0.145497     0.153609    -0.0989897     0.0395862   -0.0530989    0.0703087    0.109195    -1.22335     -0.138077   -0.00635347  -0.0101046    0.00337521   -0.248183    -0.0995793    0.0715822   0.0556596   0.056383     0.0123444    0.0882463   -0.18553      0.132268   -0.283701     0.042077
 -0.0404755    0.0346274    0.0228016    0.0160734   -0.0422906    0.148487     -0.0332887   -0.177627    -0.034349    -0.0161987   -0.019321    -0.26969     0.0626696    0.018895     0.206821      0.127961    -0.0245083   -0.131682    0.183727   -0.0692301    0.00202418   0.0836503   -0.148613    -0.127181   -0.0639473    0.0740571
  0.00618499  -0.037043     0.0189974    0.186739    -0.0322348   -0.0430878    -0.0950581   -0.00170409  -0.107705    -0.235247     0.166927     0.0366425  -0.0923652    0.0144362   -0.297338      0.0401212   -0.155799    -0.0357964  -0.226728   -0.102217    -0.07615      0.0613194    0.0842809   -0.135832    0.121265     0.0478532
 -0.0693129    0.0925301   -0.175368    -0.154206    -0.0480166   -0.0861681    -0.0238858    0.017575    -0.23129      0.0241748   -0.0177491    0.131363    0.176948    -0.0620799    0.0257896    -0.00257955  -0.0497643    0.161855    0.151595   -0.0413064   -0.277387    -0.0943786    0.120371    -0.0612211   0.0764732   -0.0840506
  0.131368    -0.0804694   -0.049915    -0.0731041   -0.0976541   -0.0604954     0.160486    -0.0226985    0.0856812   -0.0724548   -0.0373566    0.0349057  -0.0420066    0.0730268    0.173029      0.160834    -0.175112     0.100071    0.141858    0.135196    -0.0181713    0.0676474   -0.0757816   -0.0337035   0.088672    -0.0389731
 -0.329835    -0.201019    -0.231545     0.133279     0.0774898   -0.0866112     0.0789071    0.0215755    0.126109     0.187364     0.0431343    0.0205488   0.00558435   0.0198283    0.393379     -0.0108591   -0.0367945    0.0647224   0.149539   -0.127649    -0.0497237    0.0259271    0.0231395   -0.124273   -0.0545791   -0.146566
  0.23115      0.0617887    0.192427     0.0305148   -0.277524     0.0633644     0.0987945    0.0447019    0.0629386   -0.0654463    0.093424    -0.0773314  -0.0666038    0.16941      0.037611     -0.054963    -0.0153103    0.162951    0.146089    0.107053    -0.101624     0.0513255    0.0405503   -0.167463    0.0260339   -0.120146
 -0.0302396   -0.0578021    0.169787     0.238063    -0.0137151   -0.103311     -0.170996    -0.145908     0.147374     0.0731126   -0.0530877   -0.0749687  -0.0948223    0.0471658    0.0175366     0.0828362   -0.124252    -0.19256     0.135036   -0.0522387   -0.275567     0.0618841    0.00704929   0.133722   -0.103294     0.137378
  0.0411788   -0.0751097   -0.0629279   -0.0717059   -0.0315014    0.0262146    -0.0405711    0.0546336    0.0116184   -0.162059    -0.029663     0.117188   -0.0469195   -0.00517271   0.154698     -0.0262106   -0.00700315   0.074223    0.160047    0.0701329   -0.00169769   0.0925182    0.0924531    0.149361   -0.0998487   -0.0631891
 -0.0397215   -0.0275606    0.0393326   -0.101928    -0.0163288    0.00722046    0.0545517    0.0531352    0.268004     0.135026     0.0813871    0.016672    0.220781    -0.0908327   -0.0639052     0.165652     0.056647    -0.24023     0.142789   -0.078018    -0.0166525   -0.194673     0.0839156   -0.0236066  -0.182283    -0.248745
  0.0916504   -0.0125271    0.0755064    0.0466958    0.075602    -0.140741     -0.00736883   0.0632181    0.0157781   -0.0123028   -0.154844     0.0891291  -0.0154559   -0.224206     0.0436971    -0.0896346   -0.192434     0.076643   -0.0363768   0.0709745   -0.12634     -0.114577     0.0903832    0.111846    0.163959    -0.0204549
 -0.225793     0.138035    -0.0351102    0.0660863    0.125326    -0.0845341     0.00303474  -0.0454827    0.137226    -0.0549163   -0.0329982    0.0803378   0.123952     0.00860161   0.0450212    -0.00260402   0.0439595   -0.0234019  -0.026826   -0.0369264    0.0672763    0.0237154   -0.0403707    0.0238623   0.0112771    0.0128762
 -0.133265     0.124586    -0.115687     0.0251301   -0.0316238   -0.0400967     0.131723    -0.0294873   -0.260162     0.167559     0.0122764   -0.214553    0.049283    -0.0925814    0.0380369    -0.0179836    0.193703    -0.153046    0.0874239   0.119967     0.131678    -0.0567976   -0.114633    -0.0237183  -0.0683205    0.195413
 -0.115871     0.0919351   -0.0407126    0.128472     0.00237357   0.019536     -0.00797588  -0.154962     0.0298599    0.0465983    0.053687     0.0278095  -0.0898837    0.113212    -0.0756705     0.175976     0.113137    -0.143768    0.0312527   0.0599683   -0.0337173   -0.0752048    0.0297745   -0.0695934   0.172808     0.116983[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.086790
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│     13
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.046582
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     13
│     17
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.020171
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│     11
│     13
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.043842
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     13
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.060458
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      4
│     13
│     17
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.018039
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     13
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.042216
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│     11
│     13
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.040778
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.035614
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│     13
│     22
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.027116
┌ Info: EM with 100000 data points 10 iterations avll -1.027116
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.112126   -0.0848971   -0.0655632     0.0251513   -0.192762     0.0807526   -0.0167702     0.126126     0.113237    -0.0176677     0.00413129  -0.00519288   0.159322     -0.0223891    0.0138473    -0.0664037    -0.143999    -0.0014776   0.0214115    0.0175087   -0.00847783    0.048877     0.0259855  -0.0405982    0.089539    -0.0720818
 -0.127042    0.101249     0.00119248    0.0308842    0.00128615   0.0170181    0.156602      0.216429     0.00959691   0.114249      0.0537893    0.0771064   -0.22779      -0.0229579    0.0114766    -0.0146286     0.0425662   -0.155486    0.100121     0.00969862  -0.220056      0.226498     0.0214705  -0.101731    -0.139642    -0.147334
 -0.184115   -0.0403586    0.0814621    -0.0702716    0.26046      0.0258527    0.000843856   0.0890355   -0.0163923   -0.0693426    -0.0887695   -0.00262587  -0.101518      0.152195    -0.0670335    -0.00470312    0.0858076    0.0326513   0.076415    -0.0794551   -0.0589131     0.100786     0.0758221  -0.110181     0.0144196   -0.0201782
  0.051973    0.0290842    0.0595927    -0.0736683    0.0791694   -0.0264082   -0.0648158     0.0188862    0.112701     0.0156471    -0.0348827    0.132192    -0.0520602     0.0993308   -0.074705      0.132203     -0.00525809  -0.0656625  -0.102667    -0.0583923   -0.0446034     0.078925     0.0597752  -0.21643     -0.111343     0.072558
 -0.0102891  -0.0345219   -0.160306      0.0980739   -0.0325839    0.0290946    0.153658     -0.00297749  -0.0651569    0.0391363    -0.120572     0.0542748   -0.114674     -0.150979     0.0383554     0.0624244     0.010432    -0.0474042  -0.048423    -0.159017     0.0718041     0.0102199   -0.0972792  -0.0547598   -0.0852779   -0.0463206
  0.0785576  -0.152621    -0.0882212    -0.130218    -0.024334     0.054435     0.161401      0.0566588    0.146141    -0.221499      0.0232393    0.0395177    0.0493508     0.26981     -0.135853     -0.0612229    -0.0661114   -0.0914927   0.110583    -0.0986648   -0.0714969    -0.122358     0.13369    -0.074103     0.0320713    0.00277656
 -0.0055438   0.0627114    0.0444158     0.13712     -0.0159914   -0.0744244    0.0668802     0.0496311    0.0465015    0.0293722    -0.0351577    0.0581067    0.129701      0.0760319    0.068866     -0.0642355     0.12333     -0.0733742  -0.135109    -0.020774    -0.0209576    -0.159577    -0.0328665  -0.0716251   -0.326283     0.184278
  0.304925   -0.00955627   0.0421808    -0.0420568   -0.0584938   -0.0428218   -0.148522     -0.0577596   -0.0534302   -0.10368       0.122692     0.193482     0.0302935     0.037535    -0.0508714    -0.000703767  -0.0187443    0.0478242   0.104414     0.0785676   -0.0186835     0.0163285    0.117871    0.0727247   -0.0194046   -0.0549518
 -0.104257   -0.0871533   -0.0478298     0.135112     0.166863    -0.111061    -0.165968      0.132357    -0.0278561    0.0195534    -0.0675432    0.0690647    0.0131651    -0.0250932    0.0144149    -0.0410199     0.142918     0.15143     0.0733911    0.0600225   -0.0394511    -0.0479685   -0.0923998  -0.0451556   -0.0903406   -0.114597
 -0.170025    0.0408528    0.000586834  -0.0716219   -0.0184416    0.169358    -0.0700251     0.0257017   -0.138524     0.0529783    -0.120187    -0.0880862   -0.111634      0.0990887    0.0157249    -0.0433595    -0.07406      0.0631214  -0.0812679    0.0545878   -0.125582      0.0891044   -0.143236    0.139092    -0.211351     0.14595
 -0.0331285  -0.157422    -0.186461      0.00391517  -0.0725027    0.150541    -0.0588346     0.0952355    0.0320737   -0.116614     -0.0158822    0.0566774    0.0556934     0.0543466    0.00825232   -0.0280353    -0.0315104    0.074197    0.0608326    0.0627393   -0.0287245    -0.0380107   -0.132209    0.0660585   -0.0284964    0.155605
  0.0963235  -0.0971625   -0.0619322     0.0255277    0.0309069    0.0377054   -0.198234      0.0401966    0.0226432    0.048774     -0.0172383   -0.0169361    0.0438256    -0.0412977   -0.0340674    -0.0198691     0.0310502    0.121478    0.0803687   -0.0792295    0.101412     -0.00901644  -0.100648    0.0224938    0.157393     0.105663
 -0.0580093   0.0140934   -0.12067      -0.190619     0.0625068   -0.0553611    0.0543146    -0.0650496    0.151449    -0.00828415   -0.0619775   -0.0579836   -0.262874      0.112795     0.0722479    -0.0952817     0.0660349   -0.148922    0.0229017   -0.0950761    0.201851      0.0241799   -0.0167305  -0.0372247    0.0380775   -0.0658675
  0.200529   -0.00539912   0.0449928    -0.0628513   -0.147815    -0.0351085   -0.177705      0.0402554    0.0603755    0.0358068     0.0900383   -0.0160555    0.0640797     0.0314786    0.0265505     0.137009      0.0534395   -0.0275841  -0.0633412   -0.15144     -0.0563245     0.0623972   -0.0312395   0.0195371    0.113699     0.0650272
 -0.0882637  -0.0656523   -0.0887037    -0.078621    -0.0788036    0.119868     0.0367975     0.154038    -0.200149    -0.0079314    -0.0444336    0.126799     0.0280292    -0.00982457   0.147238     -0.054787      0.130826    -0.178473    0.0017388    0.0752814    0.150895     -0.06001      0.027273   -0.0200074   -0.0568564   -0.0104746
 -0.0231924  -0.0507282   -0.0719964    -0.0191422   -0.0351723   -0.0270477    0.0383262    -0.115203     0.0531489   -0.116155     -0.151312     0.0648564    0.145884      0.114983    -0.217087     -0.0365758     0.0200059   -0.128736    0.0608319    0.0360945   -0.022993     -0.150932     0.163645    0.0202255   -0.121882     0.0305739
 -0.115299   -0.0620765   -0.0707348    -0.0463935    0.0418983    0.00995199   0.0921378     0.0405184   -0.0507527    0.0325616    -0.077998    -0.0740701    0.0882706     0.035432     0.0329619     0.117608      0.0249639    0.121431   -0.1293       0.00992751   0.00632571   -0.029965    -0.0835322  -0.0263759   -0.0684898   -0.152531
 -0.21643    -0.0753849    0.085021      0.108581    -0.00469366   0.00973949   0.122045      0.0503604    0.139595    -0.0219766     0.187418     0.261146     0.00842246    0.043788    -0.0946628    -0.0851611    -0.00771022  -0.0257034  -0.0313974   -0.00404209   0.196228      0.136649     0.0358462   0.11833     -0.117577    -0.0010197
  0.0592149  -0.158118    -0.130962     -0.0411686   -0.0379788    0.102674     0.0224088     0.238474    -0.0898794    0.0357809     0.166356     0.221585     0.127245     -0.0520775    0.000335559  -0.0990673    -0.0198554   -0.0618197   0.151129    -0.251004    -0.000823306  -0.0531086   -0.0137143  -0.100387    -0.154615     0.0509983
  0.159369   -0.0340614    0.0541689    -0.107307    -0.0481101    0.138441     0.133197      0.190559    -0.160002     0.0436239    -0.0497175    0.0726141    0.23637       0.0355068   -0.105909      0.000347839   0.23504      0.0392129   0.0435649    0.0279732   -0.0880808    -0.0357348    0.0729334  -0.0600823   -0.0371359   -0.0439374
 -0.101071    0.130285    -0.0165963     0.0254209   -0.0458267    0.203161     0.202528     -0.0744488    0.0947252    0.0438933     0.0329168   -0.00899088  -0.000209253   0.0880417   -0.0528379     0.0691132     0.0262752    0.0261041  -0.030952    -0.199611    -0.029577     -0.331594     0.0950083   0.0518269    0.0384089   -0.0319152
  0.100184   -0.0542015   -0.141191      0.0568194   -0.125938    -0.0908159    0.0717266    -0.0553388    0.0201426   -0.154805     -0.0712889    0.127859    -0.0274635    -0.0589753    0.0881183     0.0712548     0.0829061    0.102397   -0.0347007    0.109339    -0.113433     -0.219838     0.0790886  -0.0364908    0.142004    -0.0790685
 -0.0279907  -0.00566747  -0.0946732     0.108404    -0.0719911   -0.110292     0.219017     -0.049687    -0.0244318    0.137268      0.10429     -0.0316894   -0.0357818     0.0696014    0.153939      0.281928      0.0144686   -0.037198   -0.00261774  -0.107473    -0.0101108    -0.106306     0.0308606  -0.0163742   -0.150467     0.109096
  0.137749   -0.0209266   -0.0940435     0.00796696   0.0552924   -0.230596    -0.0673074    -0.137663    -0.0335091   -0.0294339     0.168031    -0.0484223    0.00818713    0.0773996   -0.05288       0.0212913    -0.112518     0.108484    0.070513    -0.118618     0.042089      0.0545675   -0.0320615   0.0850615   -0.156148    -0.0951784
 -0.0648275  -0.132415    -0.0788712    -0.0248434    0.0817631    0.0808807    0.047372      0.112762     0.164683     0.0513788     0.21281      0.13007      0.105808      0.03278      0.136031     -0.0607845     0.0764118   -0.0352168  -0.126747    -0.194178     0.0172171    -0.130791     0.0419001   0.05938      0.0403752    0.0132728
 -0.177293   -0.0365035    0.00171449   -0.00377767   0.0271304    0.153807     0.0103084     0.173954     0.0464834   -0.0772887     0.088945    -0.191944     0.193724      0.0184846   -0.00705897    0.141868     -0.0511966    0.0662713   0.0085256    0.0317383   -0.0598394    -0.194353    -0.013017    0.0172794   -0.109814    -0.019779
  0.233138    0.110523     0.021156     -0.116008     0.158497     0.0434859    0.092803      0.0397211    0.0363535    0.128569     -0.0367606   -0.0311529    0.0116494    -0.0131198   -0.00698002   -0.0990213    -0.059264     0.127466    0.00498271  -0.2219      -0.00132919   -0.0365173    0.059264   -0.0195687    0.0202143    0.147512
  0.117658    0.120202    -0.0988692     0.0949083    0.0604679   -0.0859692    0.0761728     0.0562284    0.115137     0.000399544   0.195737     0.0625371    0.0123842     0.0272071   -0.082854     -0.0406025     0.0481391   -0.0518451   0.0760789    0.0157545    0.0112685     0.013906    -0.0551419   0.0202751   -0.135763     0.0718375
  0.0254794  -0.199283    -0.05455       0.133688     0.0956198    0.0732149   -0.174546      0.0451439    0.00269389   0.0795466     0.171651    -0.0168438    0.0524792    -0.161166    -0.0106021     0.0220013    -0.100013    -0.174107    0.0972355    0.109535    -0.0355722     0.179619     0.0232251   0.0849459    0.125694     0.00121721
 -0.124738    0.148354     0.0173704    -0.00298615  -0.0508755   -0.0734881   -0.0349989     0.0655289    0.0849284   -0.0686022    -0.0611154   -0.148552     0.0127322     0.00394855   0.130771     -0.0572697    -0.0742986   -0.245068    0.0350276    0.011904     0.0313127    -0.0239534    0.027595   -0.0781258   -0.0252511   -0.127019
  0.0763863   0.0373487    0.0807027     0.0366905   -0.18439     -0.0948783   -0.132862      0.0361822    0.109726    -0.057498     -0.099856     0.0412053    0.199918      0.0166248   -0.0664651     0.0141969     0.0467374    0.0941885  -0.104932    -0.23967     -0.0430672    -0.196455    -0.143455    0.0536523   -0.0929883   -0.0716328
 -0.0583755  -0.183577    -0.024388      0.0152995    0.0459464   -0.16906     -0.0046769    -0.0312684   -0.0675893    0.110841     -0.0507952    0.073466     0.0986622    -0.0457122    0.0256177    -0.000698757  -0.0686494    0.0177593   0.170102     0.0295395    0.0061426    -0.0539185   -0.0778047   0.00341856  -0.00571184  -0.0188713kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.425612688179147
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425632
[ Info: iteration 2, average log likelihood -1.425539
[ Info: iteration 3, average log likelihood -1.425450
[ Info: iteration 4, average log likelihood -1.425338
[ Info: iteration 5, average log likelihood -1.425198
[ Info: iteration 6, average log likelihood -1.425037
[ Info: iteration 7, average log likelihood -1.424858
[ Info: iteration 8, average log likelihood -1.424644
[ Info: iteration 9, average log likelihood -1.424342
[ Info: iteration 10, average log likelihood -1.423864
[ Info: iteration 11, average log likelihood -1.423138
[ Info: iteration 12, average log likelihood -1.422212
[ Info: iteration 13, average log likelihood -1.421311
[ Info: iteration 14, average log likelihood -1.420669
[ Info: iteration 15, average log likelihood -1.420316
[ Info: iteration 16, average log likelihood -1.420151
[ Info: iteration 17, average log likelihood -1.420079
[ Info: iteration 18, average log likelihood -1.420049
[ Info: iteration 19, average log likelihood -1.420036
[ Info: iteration 20, average log likelihood -1.420030
[ Info: iteration 21, average log likelihood -1.420027
[ Info: iteration 22, average log likelihood -1.420026
[ Info: iteration 23, average log likelihood -1.420025
[ Info: iteration 24, average log likelihood -1.420025
[ Info: iteration 25, average log likelihood -1.420025
[ Info: iteration 26, average log likelihood -1.420024
[ Info: iteration 27, average log likelihood -1.420024
[ Info: iteration 28, average log likelihood -1.420024
[ Info: iteration 29, average log likelihood -1.420024
[ Info: iteration 30, average log likelihood -1.420024
[ Info: iteration 31, average log likelihood -1.420024
[ Info: iteration 32, average log likelihood -1.420024
[ Info: iteration 33, average log likelihood -1.420023
[ Info: iteration 34, average log likelihood -1.420023
[ Info: iteration 35, average log likelihood -1.420023
[ Info: iteration 36, average log likelihood -1.420023
[ Info: iteration 37, average log likelihood -1.420023
[ Info: iteration 38, average log likelihood -1.420023
[ Info: iteration 39, average log likelihood -1.420023
[ Info: iteration 40, average log likelihood -1.420023
[ Info: iteration 41, average log likelihood -1.420023
[ Info: iteration 42, average log likelihood -1.420023
[ Info: iteration 43, average log likelihood -1.420023
[ Info: iteration 44, average log likelihood -1.420023
[ Info: iteration 45, average log likelihood -1.420023
[ Info: iteration 46, average log likelihood -1.420023
[ Info: iteration 47, average log likelihood -1.420023
[ Info: iteration 48, average log likelihood -1.420023
[ Info: iteration 49, average log likelihood -1.420023
[ Info: iteration 50, average log likelihood -1.420023
┌ Info: EM with 100000 data points 50 iterations avll -1.420023
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4256318976676527
│     -1.425538598936481
│      ⋮
└     -1.420022852120577
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420038
[ Info: iteration 2, average log likelihood -1.419945
[ Info: iteration 3, average log likelihood -1.419849
[ Info: iteration 4, average log likelihood -1.419726
[ Info: iteration 5, average log likelihood -1.419573
[ Info: iteration 6, average log likelihood -1.419406
[ Info: iteration 7, average log likelihood -1.419246
[ Info: iteration 8, average log likelihood -1.419109
[ Info: iteration 9, average log likelihood -1.419001
[ Info: iteration 10, average log likelihood -1.418920
[ Info: iteration 11, average log likelihood -1.418863
[ Info: iteration 12, average log likelihood -1.418824
[ Info: iteration 13, average log likelihood -1.418799
[ Info: iteration 14, average log likelihood -1.418782
[ Info: iteration 15, average log likelihood -1.418772
[ Info: iteration 16, average log likelihood -1.418765
[ Info: iteration 17, average log likelihood -1.418761
[ Info: iteration 18, average log likelihood -1.418758
[ Info: iteration 19, average log likelihood -1.418755
[ Info: iteration 20, average log likelihood -1.418753
[ Info: iteration 21, average log likelihood -1.418751
[ Info: iteration 22, average log likelihood -1.418750
[ Info: iteration 23, average log likelihood -1.418748
[ Info: iteration 24, average log likelihood -1.418747
[ Info: iteration 25, average log likelihood -1.418746
[ Info: iteration 26, average log likelihood -1.418745
[ Info: iteration 27, average log likelihood -1.418744
[ Info: iteration 28, average log likelihood -1.418743
[ Info: iteration 29, average log likelihood -1.418742
[ Info: iteration 30, average log likelihood -1.418742
[ Info: iteration 31, average log likelihood -1.418741
[ Info: iteration 32, average log likelihood -1.418740
[ Info: iteration 33, average log likelihood -1.418739
[ Info: iteration 34, average log likelihood -1.418739
[ Info: iteration 35, average log likelihood -1.418738
[ Info: iteration 36, average log likelihood -1.418738
[ Info: iteration 37, average log likelihood -1.418737
[ Info: iteration 38, average log likelihood -1.418736
[ Info: iteration 39, average log likelihood -1.418736
[ Info: iteration 40, average log likelihood -1.418735
[ Info: iteration 41, average log likelihood -1.418735
[ Info: iteration 42, average log likelihood -1.418734
[ Info: iteration 43, average log likelihood -1.418734
[ Info: iteration 44, average log likelihood -1.418733
[ Info: iteration 45, average log likelihood -1.418733
[ Info: iteration 46, average log likelihood -1.418733
[ Info: iteration 47, average log likelihood -1.418732
[ Info: iteration 48, average log likelihood -1.418732
[ Info: iteration 49, average log likelihood -1.418731
[ Info: iteration 50, average log likelihood -1.418731
┌ Info: EM with 100000 data points 50 iterations avll -1.418731
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4200382394860525
│     -1.4199446417809831
│      ⋮
└     -1.4187309567019537
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418741
[ Info: iteration 2, average log likelihood -1.418687
[ Info: iteration 3, average log likelihood -1.418640
[ Info: iteration 4, average log likelihood -1.418584
[ Info: iteration 5, average log likelihood -1.418516
[ Info: iteration 6, average log likelihood -1.418433
[ Info: iteration 7, average log likelihood -1.418336
[ Info: iteration 8, average log likelihood -1.418229
[ Info: iteration 9, average log likelihood -1.418118
[ Info: iteration 10, average log likelihood -1.418009
[ Info: iteration 11, average log likelihood -1.417908
[ Info: iteration 12, average log likelihood -1.417818
[ Info: iteration 13, average log likelihood -1.417739
[ Info: iteration 14, average log likelihood -1.417673
[ Info: iteration 15, average log likelihood -1.417618
[ Info: iteration 16, average log likelihood -1.417572
[ Info: iteration 17, average log likelihood -1.417533
[ Info: iteration 18, average log likelihood -1.417501
[ Info: iteration 19, average log likelihood -1.417473
[ Info: iteration 20, average log likelihood -1.417449
[ Info: iteration 21, average log likelihood -1.417428
[ Info: iteration 22, average log likelihood -1.417409
[ Info: iteration 23, average log likelihood -1.417393
[ Info: iteration 24, average log likelihood -1.417377
[ Info: iteration 25, average log likelihood -1.417363
[ Info: iteration 26, average log likelihood -1.417350
[ Info: iteration 27, average log likelihood -1.417337
[ Info: iteration 28, average log likelihood -1.417326
[ Info: iteration 29, average log likelihood -1.417314
[ Info: iteration 30, average log likelihood -1.417303
[ Info: iteration 31, average log likelihood -1.417293
[ Info: iteration 32, average log likelihood -1.417283
[ Info: iteration 33, average log likelihood -1.417273
[ Info: iteration 34, average log likelihood -1.417264
[ Info: iteration 35, average log likelihood -1.417254
[ Info: iteration 36, average log likelihood -1.417246
[ Info: iteration 37, average log likelihood -1.417237
[ Info: iteration 38, average log likelihood -1.417229
[ Info: iteration 39, average log likelihood -1.417221
[ Info: iteration 40, average log likelihood -1.417214
[ Info: iteration 41, average log likelihood -1.417206
[ Info: iteration 42, average log likelihood -1.417199
[ Info: iteration 43, average log likelihood -1.417192
[ Info: iteration 44, average log likelihood -1.417185
[ Info: iteration 45, average log likelihood -1.417179
[ Info: iteration 46, average log likelihood -1.417172
[ Info: iteration 47, average log likelihood -1.417166
[ Info: iteration 48, average log likelihood -1.417160
[ Info: iteration 49, average log likelihood -1.417154
[ Info: iteration 50, average log likelihood -1.417148
┌ Info: EM with 100000 data points 50 iterations avll -1.417148
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4187408076555386
│     -1.4186873888168947
│      ⋮
└     -1.4171477647113901
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417150
[ Info: iteration 2, average log likelihood -1.417093
[ Info: iteration 3, average log likelihood -1.417038
[ Info: iteration 4, average log likelihood -1.416974
[ Info: iteration 5, average log likelihood -1.416896
[ Info: iteration 6, average log likelihood -1.416800
[ Info: iteration 7, average log likelihood -1.416688
[ Info: iteration 8, average log likelihood -1.416565
[ Info: iteration 9, average log likelihood -1.416439
[ Info: iteration 10, average log likelihood -1.416316
[ Info: iteration 11, average log likelihood -1.416199
[ Info: iteration 12, average log likelihood -1.416090
[ Info: iteration 13, average log likelihood -1.415990
[ Info: iteration 14, average log likelihood -1.415898
[ Info: iteration 15, average log likelihood -1.415816
[ Info: iteration 16, average log likelihood -1.415743
[ Info: iteration 17, average log likelihood -1.415678
[ Info: iteration 18, average log likelihood -1.415621
[ Info: iteration 19, average log likelihood -1.415571
[ Info: iteration 20, average log likelihood -1.415525
[ Info: iteration 21, average log likelihood -1.415485
[ Info: iteration 22, average log likelihood -1.415448
[ Info: iteration 23, average log likelihood -1.415414
[ Info: iteration 24, average log likelihood -1.415383
[ Info: iteration 25, average log likelihood -1.415354
[ Info: iteration 26, average log likelihood -1.415327
[ Info: iteration 27, average log likelihood -1.415302
[ Info: iteration 28, average log likelihood -1.415279
[ Info: iteration 29, average log likelihood -1.415257
[ Info: iteration 30, average log likelihood -1.415236
[ Info: iteration 31, average log likelihood -1.415217
[ Info: iteration 32, average log likelihood -1.415199
[ Info: iteration 33, average log likelihood -1.415181
[ Info: iteration 34, average log likelihood -1.415165
[ Info: iteration 35, average log likelihood -1.415150
[ Info: iteration 36, average log likelihood -1.415135
[ Info: iteration 37, average log likelihood -1.415121
[ Info: iteration 38, average log likelihood -1.415108
[ Info: iteration 39, average log likelihood -1.415095
[ Info: iteration 40, average log likelihood -1.415083
[ Info: iteration 41, average log likelihood -1.415072
[ Info: iteration 42, average log likelihood -1.415061
[ Info: iteration 43, average log likelihood -1.415050
[ Info: iteration 44, average log likelihood -1.415040
[ Info: iteration 45, average log likelihood -1.415030
[ Info: iteration 46, average log likelihood -1.415021
[ Info: iteration 47, average log likelihood -1.415012
[ Info: iteration 48, average log likelihood -1.415003
[ Info: iteration 49, average log likelihood -1.414994
[ Info: iteration 50, average log likelihood -1.414986
┌ Info: EM with 100000 data points 50 iterations avll -1.414986
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4171504126723529
│     -1.417092847360177
│      ⋮
└     -1.4149857431662565
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414986
[ Info: iteration 2, average log likelihood -1.414923
[ Info: iteration 3, average log likelihood -1.414862
[ Info: iteration 4, average log likelihood -1.414791
[ Info: iteration 5, average log likelihood -1.414703
[ Info: iteration 6, average log likelihood -1.414595
[ Info: iteration 7, average log likelihood -1.414467
[ Info: iteration 8, average log likelihood -1.414324
[ Info: iteration 9, average log likelihood -1.414172
[ Info: iteration 10, average log likelihood -1.414020
[ Info: iteration 11, average log likelihood -1.413875
[ Info: iteration 12, average log likelihood -1.413740
[ Info: iteration 13, average log likelihood -1.413618
[ Info: iteration 14, average log likelihood -1.413508
[ Info: iteration 15, average log likelihood -1.413411
[ Info: iteration 16, average log likelihood -1.413325
[ Info: iteration 17, average log likelihood -1.413248
[ Info: iteration 18, average log likelihood -1.413181
[ Info: iteration 19, average log likelihood -1.413121
[ Info: iteration 20, average log likelihood -1.413067
[ Info: iteration 21, average log likelihood -1.413020
[ Info: iteration 22, average log likelihood -1.412977
[ Info: iteration 23, average log likelihood -1.412938
[ Info: iteration 24, average log likelihood -1.412902
[ Info: iteration 25, average log likelihood -1.412869
[ Info: iteration 26, average log likelihood -1.412839
[ Info: iteration 27, average log likelihood -1.412811
[ Info: iteration 28, average log likelihood -1.412784
[ Info: iteration 29, average log likelihood -1.412759
[ Info: iteration 30, average log likelihood -1.412736
[ Info: iteration 31, average log likelihood -1.412713
[ Info: iteration 32, average log likelihood -1.412692
[ Info: iteration 33, average log likelihood -1.412671
[ Info: iteration 34, average log likelihood -1.412651
[ Info: iteration 35, average log likelihood -1.412633
[ Info: iteration 36, average log likelihood -1.412615
[ Info: iteration 37, average log likelihood -1.412598
[ Info: iteration 38, average log likelihood -1.412581
[ Info: iteration 39, average log likelihood -1.412565
[ Info: iteration 40, average log likelihood -1.412550
[ Info: iteration 41, average log likelihood -1.412536
[ Info: iteration 42, average log likelihood -1.412522
[ Info: iteration 43, average log likelihood -1.412509
[ Info: iteration 44, average log likelihood -1.412496
[ Info: iteration 45, average log likelihood -1.412484
[ Info: iteration 46, average log likelihood -1.412473
[ Info: iteration 47, average log likelihood -1.412462
[ Info: iteration 48, average log likelihood -1.412451
[ Info: iteration 49, average log likelihood -1.412441
[ Info: iteration 50, average log likelihood -1.412432
┌ Info: EM with 100000 data points 50 iterations avll -1.412432
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4149856984799607
│     -1.4149225924465358
│      ⋮
└     -1.4124317693269872
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.425612688179147
│     -1.4256318976676527
│     -1.425538598936481
│     -1.4254499665908191
│      ⋮
│     -1.4124514575097127
│     -1.4124414002257726
└     -1.4124317693269872
32×26 Array{Float64,2}:
  0.0764132    -0.153551    0.204766   -0.876446    0.0573785    0.348532    0.271133    -0.222737    -0.0318243  -0.51928     0.249296    -0.319313   -0.50116     0.0766333  -0.136059   -0.529096    -0.505628   -0.125987     -0.0180673  -0.175459     0.564731     -0.0638616   0.142369    -0.261699    -0.165043    -0.117072
 -0.546304     -0.0508237   0.191617   -0.270092   -0.675166    -0.138204    0.294477    -0.363155     0.213591   -0.619761   -0.46508     -0.217573    0.121438    0.324446   -0.139158   -0.466623     0.104081    0.410532      0.248776   -0.0323304    0.663174      0.394602    0.457705     0.49508     -0.0745246   -0.232604
 -0.442528      0.317279    0.398544   -0.227593   -0.306639    -0.223554   -0.557009    -0.424315    -0.169593   -0.317212   -0.192319     0.112417   -0.455405   -0.62528     0.235454    0.786122    -0.639804   -0.110166      0.0950014   0.0137308    0.408202      0.637764   -0.220433     0.613515     0.373639     0.554545
  0.287803      0.0302582   0.209053    0.0460857  -0.240423     0.0932898  -0.123184    -0.334173     0.915823    0.118059   -0.119351    -0.275064    0.287862   -0.404931    0.535891    0.73306     -0.44328    -0.540072      0.59254    -0.509568    -0.00451673    0.854462    0.437437     0.0866239    0.135523     0.0526293
 -0.110792      0.0311881   0.107898   -0.0234635   0.0841255   -0.0491619   0.102914    -0.0709894    0.125509   -0.479344    0.0809423    0.153621   -0.218992   -0.254842   -0.0287887  -0.0950134   -0.0951413   0.0548883     0.0731891  -0.205943     0.00842117    0.0775734  -0.18222     -0.116654    -0.00934978  -0.00223146
 -0.115787     -0.150644   -0.442695    0.16162    -0.050162     0.112471   -0.154069     0.285031     0.0332456   0.835396   -0.222268    -0.363412    0.382083    0.319834   -0.151363   -0.0723269   -0.133955   -0.13141       0.0720473   0.277253    -0.0645975    -0.084326    0.202771     0.183898    -0.303153    -0.279894
 -0.53718      -0.0765625   0.280831    0.876414   -0.114436    -0.0879535  -0.109675     0.688302     0.333821   -0.563189   -0.785474     0.570957   -0.397576   -0.24108    -0.297298    0.165246     0.471557    0.000505289  -0.29226    -0.401689    -0.412769     -0.504102    0.398417    -0.0429745   -0.524592    -0.0222863
  0.14462       0.431247    0.239162    0.392656   -0.291328    -0.0505469  -0.318097     0.138322     0.269071    0.0660539  -0.397146     0.299208    0.370661    0.215213    0.118618    0.507682     1.0921      0.473356      0.173458   -0.156478    -0.0675906     0.142672    0.318599     0.470411    -0.274994     0.387362
 -0.0123396     0.172867   -0.630686    0.0378941  -0.884273    -0.028229    0.649916     0.0393607   -0.264042   -0.836932    0.410641     0.124014   -0.156305    0.290426   -0.680055    0.143695     0.126962   -0.369083      0.0298711  -0.590332    -0.725793      0.198221   -0.380006    -0.115342     0.102285    -0.535117
 -0.0916551    -0.215908   -0.318       0.0242368  -0.198029    -0.745538    0.416112    -0.158618    -0.856505   -0.29482     0.391839     0.728427   -0.0901646   0.295266   -0.573519   -0.41935      0.251323    0.268491     -0.155235    0.37647      0.161968     -0.509631   -0.685286    -0.0390286    0.294696     0.0566562
  0.0164379     0.0789741   0.547169   -0.0753023   0.938637    -0.646282   -0.238614     0.159734     0.178584   -0.248124    0.461066     0.562725   -0.298756   -0.274       0.0151611   0.247081     0.375256    0.0446365     0.1245     -0.145259    -0.0178142    -0.573971   -0.0685832   -0.373355     0.398805     0.387363
 -0.0633108     0.0218593  -0.0172319   0.269396    0.221022    -0.173644    0.444958    -0.160533    -0.696303   -0.39321    -0.00119389   0.472744    0.0268438  -0.0818244   0.628332    0.470845    -0.0633082  -0.229708     -0.216606   -0.494669    -0.086856     -0.0326968   0.138543    -0.531351     0.370094     1.29712
  0.0421379    -0.474825    0.556656    0.0807542   0.492821    -0.369245   -0.30161      0.0262543   -0.384548    0.705129   -0.233148     0.0101543   0.327252   -0.465659   -0.328484   -0.152796    -0.0568142   0.386796     -0.0960298   0.491001     0.704471     -0.467449    0.19644     -0.183559    -0.495307     0.463593
  0.262398     -0.0799998   0.200179   -0.837471   -0.00783009  -0.215161   -0.0903996    0.105853     1.06982     0.0175966  -0.0034434    0.255122    0.336974   -0.16635     0.102289   -0.111436    -0.446188    0.527308     -1.03539     0.0644169    0.0704938    -0.189103   -0.210788    -0.00518805  -0.427988     0.328927
  0.149824      0.288728    0.423462   -0.182155    0.204793     0.239893    0.00437443  -0.0555584    0.294573    0.353699   -0.335143     0.113399    0.621849    0.414725    0.603697    0.0148362   -0.205789   -0.150623     -0.0351118   0.33603      0.406266     -0.393867    0.78001      0.300771     0.407383     0.22986
  0.556635      0.168212   -0.121742   -0.613469   -0.0268008    0.0855963   0.0190294   -0.379369    -0.208674    0.710131    0.641384    -0.290097    0.465405    0.360152    0.268915   -0.00424535  -0.209465   -0.256952      0.135175    0.43724      0.300979      0.488258   -0.394583     0.0383717    0.397833     0.137849
  0.373574     -0.581234    0.0289076  -0.121345   -0.232083     0.624636   -0.153293     0.398414    -0.0403659  -0.0412607   0.1353      -0.0865366  -0.377536    0.175939   -0.256296   -0.770007     0.529052    0.151429      0.114417    0.143645    -0.410731      0.264087    0.0254873   -0.0142719   -1.11357     -0.992254
  0.451355     -0.0760968  -0.46415    -0.144136    0.349098     0.459465    0.594014     0.395161    -0.368597    0.308485    0.358045    -0.220332   -0.107366    0.759572    0.0171061  -0.911582     0.695299    0.0888501    -0.172359   -0.0509499   -0.140029     -0.35158     0.0720404   -0.172361    -0.217018     0.0301236
 -0.342839     -0.104746    0.032176    0.174182    0.0957159    0.277866   -0.500439    -0.18056      0.183911   -0.0589941   0.27544      0.163069   -0.108246   -0.105691   -0.113532    0.185111    -0.394011   -0.358501     -0.0795796  -0.194008    -0.458921      0.313773   -0.512371    -0.330007     0.147102    -0.539825
 -0.31564      -0.297233    0.357988   -0.128655   -0.097361     0.325639    0.147335    -0.207244    -0.537806   -0.111509    0.39763     -0.292999    0.968427    0.413627    0.218047   -0.0844992   -0.449664   -0.268013      0.0132174   0.125568    -0.575285     -0.340164    0.00663671  -0.0390167   -0.140222    -0.430058
 -0.393207     -0.0281571  -0.395241    0.311819    0.096054     0.0964922  -0.199033    -0.207183     0.280127   -0.318261   -0.772517    -0.0667386  -0.275984   -0.233137   -0.343225   -0.170294     0.0926375   0.418044      0.13064    -0.440832    -0.0672354     0.190227   -0.387082    -0.163159    -0.628788    -0.0780022
 -0.260677     -0.165934   -0.337737    0.0379477   0.166492     0.27346     0.438925     0.280081    -0.0606139  -0.414919    0.0114227    0.0580466  -0.480987   -0.430784   -0.19026    -0.363992    -0.168612   -0.0142056    -0.0787867  -0.595919    -0.0419973    -0.394335    0.0126112   -0.303824    -0.336927    -0.083997
 -0.89541       0.0876492  -0.576126   -0.0836405  -0.238825    -0.532199    0.170861     0.632087     0.103346    0.379022   -0.526102    -0.164904   -0.450973    0.0528092   0.0819775  -0.318108    -0.267024   -0.703072     -0.0209401  -0.00650836   0.507275     -0.255142    0.152918    -0.913169    -0.492335     0.0719588
  0.0912398    -0.0080019  -0.353138   -0.209729   -0.172326    -0.31431     0.285355     0.417753     0.135832    0.108774   -0.00415581   0.191496   -0.114541   -0.362864    0.183602   -0.276362    -0.140675    0.163102      0.643664    0.18341      0.421416     -0.246105    0.11164      0.788395    -0.0184788    0.20102
  0.395807      0.0805534  -0.179119   -0.0267421  -0.750497     0.165063    0.0981725    0.173312     0.143758    0.146424   -0.394469    -0.614285   -0.0656772   0.0439638   0.0645415   0.264225    -0.0226386   0.116708     -0.189957    0.227274     0.224804      0.48478     0.315244     0.284599    -0.276013    -0.308692
  0.000442558   0.254938   -0.0503865   0.310815   -0.442631    -0.101293   -0.119638     0.0743623    0.14939    -0.0887512  -0.365219     0.339824    0.166857    0.139315    0.119039    0.235537     0.217135   -0.0948453     0.0652262  -0.0521492   -0.0201968    -0.0103024   0.085912     0.297953    -0.0239869    0.0288203
 -0.0750657    -0.0948753   0.0406307  -0.182762   -0.111755    -0.022177    0.184722    -0.0805612   -0.0906993  -0.323244    0.222572    -0.0760049   0.0132037   0.0318527  -0.186111   -0.0630239    0.038022   -0.126231      0.111042   -0.0180103   -0.0066251     0.0631174  -0.0339459   -0.227418    -0.107863    -0.0723117
  0.123874     -0.0846709  -0.0168809  -0.0862759   0.344206    -0.023564   -0.0320994    0.181657     0.0619877   0.468215    0.0983922    0.0598625   0.184734    0.0868073   0.241818   -0.0162315   -0.019128    0.142577     -0.135432    0.0735327    0.000862596  -0.18185     0.0794729   -0.0225653    0.109653     0.10736
  0.113573      0.124893    0.300949    0.393505    0.160072     0.595397   -0.406312    -0.235936     0.162946   -0.170044   -0.0443285   -0.163936    0.416779    0.603259   -0.152091    0.373095     0.599422    0.100546     -0.555438   -0.0416615   -0.336477     -0.106427    0.0994153   -0.183144     0.172295    -0.282229
 -0.0966196    -0.382831    0.0936033   0.898878    0.42349     -0.0107851  -0.105641    -0.00152398  -0.521735    0.0665786   0.25261      0.116856    0.192079    0.191794   -0.165857    0.238478     0.588457   -0.177788      0.706225    0.104727    -0.324445      0.0522852   0.217442     0.188722     0.307484    -0.247896
  0.313029     -0.33736    -0.564241    0.146572    0.658086    -0.0684402  -0.057718     0.43488     -0.15059     0.389795    0.784589     0.351336   -0.0475263  -0.169615    0.274504    0.29527     -0.356936   -0.717673     -0.13254     0.0372291   -0.645652     -0.581417   -0.340502    -0.34729      0.298622    -0.228842
  0.294727      0.117353   -0.583329    0.293561    0.32766     -0.0652865  -0.385885     0.377972    -0.0303216   0.591394    0.236454     0.0125675   0.12025    -0.321308   -0.0873403   0.344023     0.0834069   0.408812     -0.0651714  -0.145716    -0.498893     -0.0579099  -0.683229    -0.121616     0.0483813    0.529842[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412423
[ Info: iteration 2, average log likelihood -1.412414
[ Info: iteration 3, average log likelihood -1.412405
[ Info: iteration 4, average log likelihood -1.412397
[ Info: iteration 5, average log likelihood -1.412389
[ Info: iteration 6, average log likelihood -1.412382
[ Info: iteration 7, average log likelihood -1.412375
[ Info: iteration 8, average log likelihood -1.412368
[ Info: iteration 9, average log likelihood -1.412361
[ Info: iteration 10, average log likelihood -1.412355
┌ Info: EM with 100000 data points 10 iterations avll -1.412355
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.531398e+05
      1       7.030928e+05      -2.500470e+05 |       32
      2       6.920361e+05      -1.105678e+04 |       32
      3       6.872557e+05      -4.780306e+03 |       32
      4       6.848433e+05      -2.412495e+03 |       32
      5       6.833566e+05      -1.486648e+03 |       32
      6       6.822780e+05      -1.078632e+03 |       32
      7       6.814477e+05      -8.303022e+02 |       32
      8       6.807638e+05      -6.838258e+02 |       32
      9       6.801717e+05      -5.921065e+02 |       32
     10       6.796843e+05      -4.874760e+02 |       32
     11       6.792706e+05      -4.137047e+02 |       32
     12       6.789122e+05      -3.583608e+02 |       32
     13       6.785967e+05      -3.154673e+02 |       32
     14       6.783083e+05      -2.884253e+02 |       32
     15       6.780559e+05      -2.524356e+02 |       32
     16       6.778514e+05      -2.044770e+02 |       32
     17       6.776534e+05      -1.980028e+02 |       32
     18       6.774678e+05      -1.856194e+02 |       32
     19       6.773045e+05      -1.632369e+02 |       32
     20       6.771729e+05      -1.316755e+02 |       32
     21       6.770521e+05      -1.207340e+02 |       32
     22       6.769334e+05      -1.187729e+02 |       32
     23       6.768120e+05      -1.213493e+02 |       32
     24       6.766995e+05      -1.125173e+02 |       32
     25       6.765856e+05      -1.138850e+02 |       32
     26       6.764803e+05      -1.053044e+02 |       32
     27       6.763780e+05      -1.023283e+02 |       32
     28       6.762800e+05      -9.794256e+01 |       32
     29       6.761907e+05      -8.933555e+01 |       32
     30       6.761142e+05      -7.653711e+01 |       32
     31       6.760392e+05      -7.498488e+01 |       32
     32       6.759724e+05      -6.671998e+01 |       32
     33       6.759167e+05      -5.576296e+01 |       32
     34       6.758571e+05      -5.954769e+01 |       32
     35       6.758048e+05      -5.234026e+01 |       32
     36       6.757581e+05      -4.669206e+01 |       32
     37       6.757108e+05      -4.726236e+01 |       32
     38       6.756666e+05      -4.423574e+01 |       32
     39       6.756228e+05      -4.376084e+01 |       32
     40       6.755855e+05      -3.735566e+01 |       32
     41       6.755430e+05      -4.250848e+01 |       32
     42       6.755029e+05      -4.005106e+01 |       32
     43       6.754616e+05      -4.128290e+01 |       32
     44       6.754252e+05      -3.640311e+01 |       32
     45       6.753855e+05      -3.978985e+01 |       32
     46       6.753443e+05      -4.112584e+01 |       32
     47       6.753047e+05      -3.965613e+01 |       32
     48       6.752631e+05      -4.158351e+01 |       32
     49       6.752221e+05      -4.100110e+01 |       32
     50       6.751836e+05      -3.850855e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 675183.5776140769)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424715
[ Info: iteration 2, average log likelihood -1.419532
[ Info: iteration 3, average log likelihood -1.418055
[ Info: iteration 4, average log likelihood -1.416891
[ Info: iteration 5, average log likelihood -1.415726
[ Info: iteration 6, average log likelihood -1.414780
[ Info: iteration 7, average log likelihood -1.414197
[ Info: iteration 8, average log likelihood -1.413877
[ Info: iteration 9, average log likelihood -1.413684
[ Info: iteration 10, average log likelihood -1.413547
[ Info: iteration 11, average log likelihood -1.413438
[ Info: iteration 12, average log likelihood -1.413346
[ Info: iteration 13, average log likelihood -1.413264
[ Info: iteration 14, average log likelihood -1.413191
[ Info: iteration 15, average log likelihood -1.413125
[ Info: iteration 16, average log likelihood -1.413065
[ Info: iteration 17, average log likelihood -1.413009
[ Info: iteration 18, average log likelihood -1.412958
[ Info: iteration 19, average log likelihood -1.412911
[ Info: iteration 20, average log likelihood -1.412867
[ Info: iteration 21, average log likelihood -1.412826
[ Info: iteration 22, average log likelihood -1.412788
[ Info: iteration 23, average log likelihood -1.412752
[ Info: iteration 24, average log likelihood -1.412718
[ Info: iteration 25, average log likelihood -1.412686
[ Info: iteration 26, average log likelihood -1.412655
[ Info: iteration 27, average log likelihood -1.412627
[ Info: iteration 28, average log likelihood -1.412600
[ Info: iteration 29, average log likelihood -1.412574
[ Info: iteration 30, average log likelihood -1.412550
[ Info: iteration 31, average log likelihood -1.412526
[ Info: iteration 32, average log likelihood -1.412504
[ Info: iteration 33, average log likelihood -1.412483
[ Info: iteration 34, average log likelihood -1.412463
[ Info: iteration 35, average log likelihood -1.412444
[ Info: iteration 36, average log likelihood -1.412426
[ Info: iteration 37, average log likelihood -1.412409
[ Info: iteration 38, average log likelihood -1.412393
[ Info: iteration 39, average log likelihood -1.412378
[ Info: iteration 40, average log likelihood -1.412363
[ Info: iteration 41, average log likelihood -1.412349
[ Info: iteration 42, average log likelihood -1.412336
[ Info: iteration 43, average log likelihood -1.412323
[ Info: iteration 44, average log likelihood -1.412311
[ Info: iteration 45, average log likelihood -1.412300
[ Info: iteration 46, average log likelihood -1.412289
[ Info: iteration 47, average log likelihood -1.412279
[ Info: iteration 48, average log likelihood -1.412269
[ Info: iteration 49, average log likelihood -1.412259
[ Info: iteration 50, average log likelihood -1.412250
┌ Info: EM with 100000 data points 50 iterations avll -1.412250
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.407851   -0.0977613    0.264867   -0.311162   -0.457758    -0.381965     0.265988    0.037173     0.339007    -0.275468   -0.387191     0.0617324   0.158034    -0.00354653   0.41674     -0.149029   -0.0935627   0.121496     0.51435      0.297919    0.706602    0.223553     0.529795    0.749783      0.138603   -0.0878822
 -0.222474    0.312744     0.24244     0.540942   -0.645622    -0.126755    -0.0581956   0.410705    -0.078294    -0.640886   -0.938393     0.630316   -0.308648    -0.0384334   -0.148704     0.349998    0.420868   -0.189195    -0.207562    -0.450875   -0.189755   -0.203252     0.302588    0.345857     -0.328929    0.229872
  0.068518    0.0630034   -0.142017    0.448676   -0.30574     -0.0306884   -0.061883    0.361461    -0.0218622    0.570231   -0.211656    -0.0741487   0.557966     0.0922033   -0.166802     0.327224    0.411163   -0.238333    -0.403581    -0.0825816  -0.777917    0.0190387    0.25793    -0.561807     -0.328085    0.0523542
  0.351026    0.10583     -0.0838275  -0.269731   -0.400886     0.214265     0.412727   -0.643286     0.216444     0.818807   -0.0130696   -0.540899    0.780633     0.141544     0.570126     0.190756   -0.591986   -0.599686     0.587158    -0.311471    0.0792131   0.743831     0.486836    0.0604648    -0.21582     0.149938
  0.416448    0.427345     0.122945   -0.56324     0.144932     0.0799133    0.0710107  -0.220081     0.170306     0.290117    0.482919     0.0492288   0.388811     0.293313     0.162105    -0.0974974  -0.24034    -0.139863    -0.209852     0.272282    0.321026   -0.118417     0.0318077  -0.135675      0.633518    0.08775
 -0.0382399   0.0396434   -0.0389872   0.305243    0.241328    -0.245252     0.38265    -0.148324    -0.717392    -0.434456   -0.152132     0.468027    0.0490836   -0.0396707    0.922811     0.491143   -0.0504826  -0.188966    -0.31391     -0.418752   -0.133001    0.0388655    0.277541   -0.569317      0.354582    1.57768
  0.108806    0.906873     0.375156    0.521051   -0.355984    -0.0303272    0.0097458  -0.0613422    0.577424    -0.119746   -0.262167    -0.117071   -0.117578    -0.898146     0.143392     0.858892   -0.296428    0.543424     0.192341    -0.538655    0.715364    0.284583     0.130968   -0.0201697     0.592546    0.268089
  0.330115   -0.130406     0.0291956  -0.0409749  -0.00695883   0.193007    -0.494253    0.00105815   0.470909    -0.312434    0.209205     0.144564   -0.315296    -0.25653      0.744467     0.728695   -0.0812274  -0.837923     0.538494    -0.263057   -0.298608    0.750621    -0.095863    0.194456      0.260983    0.0161553
 -0.303498    0.614795     0.198363   -0.683459   -0.289998    -0.0512782   -0.275906   -0.494032    -0.582392    -0.206772    0.072574    -0.175736   -0.643312     0.0586209    0.169339     0.265868   -0.851678   -0.257531    -0.187184     0.21471     0.508782    0.265245    -0.490339    0.723         0.514732    0.788437
 -0.0363685  -0.242559    -0.483953    0.117834   -0.552378     0.350636    -0.194503    0.26466      0.0824631    0.507341   -0.556314    -0.713298    0.455111     0.559155    -0.114005    -0.0285319  -0.266066   -0.158409    -0.00458813   0.298069    0.0882865   0.118717     0.390963    0.661319     -0.358765   -0.553462
 -0.110589    0.141944     0.0739669  -0.223257   -0.610899     0.193701     0.151282   -0.530514     0.224983    -0.781617   -0.540477    -0.650146   -0.252042     0.36485     -0.353304    -0.419394    0.312115    0.551331     0.0159442   -0.292351    0.380981    0.46744      0.0529936   0.000753453  -0.222266   -0.277332
 -0.0526111   0.0834218   -0.214501   -0.0382618  -0.402241     0.0679333    0.238714   -0.0158686    0.00380282  -0.34174    -0.14673     -0.0184216  -0.209674    -0.118089    -0.150425    -0.0927582   0.0792434   0.00482122   0.122623    -0.168966    0.150837    0.171007    -0.0187422   0.0321458    -0.25311    -0.00670675
 -0.126885   -0.0536867   -0.429026   -0.119796   -0.419353    -0.199071     0.716406   -0.15928     -0.378789    -0.685867    0.458384     0.384392   -0.0942668    0.183955    -0.592417    -0.162117   -0.032648   -0.179298     0.0259147   -0.237731   -0.337636    0.00998353  -0.418576   -0.0540727     0.177288   -0.314629
  0.377823   -0.366923    -0.145822   -0.520838    0.203728     0.409046     0.309574    0.259341    -0.448431     0.240112    0.394455    -0.221024   -0.114206     0.776727     0.00667701  -0.851363    0.398761   -0.0639308   -0.151385     0.282501   -0.332928   -0.0372267   -0.0584785  -0.133573     -0.574256   -0.344512
  0.422418   -0.216831    -0.480323    0.1811      0.65049     -0.0569537   -0.186664    0.431173    -0.134927     0.442913    0.771591     0.335113    0.0815124   -0.159164     0.155867     0.359265   -0.236355   -0.386624    -0.37965     -0.0535984  -0.723934   -0.648239    -0.537358   -0.447933      0.277726   -0.0557674
 -0.0094018   0.0321121    0.482802    0.642944    0.218214     0.289329    -0.389571   -0.295992    -0.0481824   -0.0658231   0.0268134    0.130458    0.755841     0.541095     0.122261     0.451597    0.613509    0.0896404    0.0170342    0.233691   -0.410867   -0.169543     0.285669    0.270622      0.298855   -0.158779
  0.595714    0.310761    -0.324934    0.0681668   0.0547229    0.0244766   -0.0190505   0.524372     0.275497     0.629647   -0.268751     0.0808524   0.00898664   0.15387      0.299624     0.0681555   0.508381    0.598287     0.0686564    0.126758    0.175654   -0.151295     0.205867    0.778615     -0.193056    0.259637
  0.127868   -0.235582    -0.0705834   0.716021    0.0119691    0.284622     0.360578    0.187218    -0.830624     0.0454672   0.398581    -0.186936   -0.248181     0.485373    -0.0507788    0.053726    0.815806   -0.264483     0.530302    -0.375897    0.22865     0.0804385    0.117359   -0.248222      0.428545   -0.110145
  0.197851   -0.542881     0.348798    0.0558143   0.0147074   -0.5553       0.146763   -0.0526002   -0.544914     0.267367    0.159166     0.182284    0.370325    -0.204183    -0.405836    -0.228136    0.108578    0.336343     0.168409     0.717469    0.461435   -0.333511     0.0442864   0.132337     -0.25388     0.3201
 -0.110266   -0.106384    -0.614084    0.361874    0.134585    -0.222374    -0.146103    0.439629    -0.318442     0.319452    0.481717     0.227441   -0.0490853   -0.317074     0.185763    -0.165934   -0.193186   -0.134805     0.746373     0.330924   -0.257141   -0.0108905   -0.381078    0.414134      0.323031    0.0371598
 -0.106243   -0.213766    -0.110965    0.11662     0.759       -0.0892189    0.0412065   0.328794    -0.0760868    0.174239    0.218525     0.163865   -0.174142    -0.153859     0.128535    -0.0128257  -0.0681192   0.0513353   -0.146393    -0.17916    -0.263225   -0.373896    -0.142396   -0.311762      0.177024    0.176789
 -0.845487    0.0411799   -0.472933   -0.154931   -0.133966    -0.600465     0.176791    0.674745     0.167491     0.360322   -0.572144    -0.132284   -0.544647     0.0197424    0.0311526   -0.431356   -0.317187   -0.442118    -0.109847     0.0514107   0.686631   -0.350535     0.036576   -0.934032     -0.493782    0.0741959
  0.0218955   0.0256914    0.167672   -0.14363     0.237768    -0.00482722  -0.177002    0.0237361    0.142426     0.351132   -0.043164    -0.0388866   0.320249     0.110225     0.213837    -0.08147    -0.066065    0.0594779    0.0597153    0.277737    0.260556   -0.126783     0.136398    0.0698614     0.0234148   0.0980121
 -0.227084    0.340029     0.430726   -0.0658761   0.87597     -0.516356    -0.210683   -0.147551    -0.0901897   -0.213566    0.0137965    0.774878   -0.048685    -0.522243    -0.329033    -0.0853124   0.686106    0.271055     0.227142    -0.313461    0.347175   -0.604122    -0.154528   -0.472348     -0.0239138   0.698512
  0.104727   -0.00309484   0.0527456  -0.0489929  -0.0860993   -0.00376904  -0.0714554   0.0894892    0.0765725    0.243164    0.00908487  -0.0172715   0.297295     0.154381     0.2207       0.145702    0.0282169   0.0321791   -0.0273107    0.151563    0.0307391  -0.0248397    0.14651     0.144524      0.0365026   0.0252109
  0.431738    0.210865    -0.868074   -0.0621412   0.256702    -0.0533944   -0.308689   -0.244765     0.0122935    0.383699   -0.00155492  -0.451752   -0.0860106   -0.357565    -0.680976     0.235356   -0.21278     0.530974    -0.153621    -0.470607   -0.0474721   0.247449    -0.817848   -0.171926     -0.480127    0.559883
 -0.410448   -0.32695     -0.0375814   0.711499    0.15421      0.10988     -0.140011    0.566739     0.527107    -0.38491    -0.220055     0.128179   -0.383001    -0.357826    -0.315602    -0.193805    0.544498    0.340346    -0.0467695   -0.343155   -0.564313   -0.180773     0.125337   -0.147577     -0.91173    -0.288702
 -0.296643   -0.175301     0.12663    -0.0281234  -0.112606     0.19997     -0.0923252  -0.239685    -0.172251    -0.333232    0.439501    -0.0402509   0.189499     0.137698    -0.174329     0.111493   -0.208756   -0.348162    -0.0656025   -0.168746   -0.427913    0.0846027   -0.357005   -0.445552      0.0310198  -0.474626
 -0.0346205  -0.361958    -0.0652329  -0.518822    0.0229473    0.290042     0.455325    0.0471416   -0.0159026   -0.352997    0.137568    -0.160589   -0.375404    -0.286725    -0.0598309   -0.495127   -0.54573    -0.190318     0.00503398  -0.362212    0.335781   -0.284242     0.278877   -0.237075     -0.384121   -0.191323
 -0.281269    0.0212943   -0.22201     0.445041    0.15802      0.0521983   -0.37894     0.0634056    0.443518    -0.171382   -0.436144     0.297787   -0.166665     0.0404767   -0.311118    -0.0345603   0.236418    0.0819982    0.0352943   -0.216172   -0.325273   -0.0245503   -0.191784   -0.0251917    -0.209419   -0.392115
  0.165445   -0.250223     0.487927   -0.879193    0.0660439    0.0440133   -0.119703   -0.090994     1.07822     -0.167284   -0.0751309    0.190031    0.356751    -0.0894382    0.0690887   -0.0809117  -0.277136    0.631608    -0.906627     0.0683126   0.143135   -0.0612884   -0.027681    0.0913691    -0.585299    0.288719
 -0.527164   -0.262047     0.448139   -0.0588596   0.117637    -0.367964    -0.97296    -0.329444     0.175286     0.099442   -0.302072     0.140892   -0.0814645   -0.690156    -0.0354014    1.02996    -0.731052   -0.0695542    0.15509     -0.0705744   0.14162     0.561739    -0.121341    0.162738      0.177313    0.249199[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412241
[ Info: iteration 2, average log likelihood -1.412232
[ Info: iteration 3, average log likelihood -1.412224
[ Info: iteration 4, average log likelihood -1.412216
[ Info: iteration 5, average log likelihood -1.412208
[ Info: iteration 6, average log likelihood -1.412200
[ Info: iteration 7, average log likelihood -1.412192
[ Info: iteration 8, average log likelihood -1.412185
[ Info: iteration 9, average log likelihood -1.412178
[ Info: iteration 10, average log likelihood -1.412171
┌ Info: EM with 100000 data points 10 iterations avll -1.412171
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
