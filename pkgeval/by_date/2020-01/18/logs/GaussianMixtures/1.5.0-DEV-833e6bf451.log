Julia Version 1.5.0-DEV.84
Commit 833e6bf451 (2020-01-17 18:45 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed DataAPI ──────────── v1.1.0
 Installed PDMats ───────────── v0.9.10
 Installed GaussianMixtures ─── v0.3.0
 Installed OrderedCollections ─ v1.1.0
 Installed QuadGK ───────────── v2.3.1
 Installed StatsBase ────────── v0.32.0
 Installed Clustering ───────── v0.13.3
 Installed SortingAlgorithms ── v0.3.1
 Installed FillArrays ───────── v0.8.4
 Installed DataStructures ───── v0.17.9
 Installed Distributions ────── v0.22.3
 Installed Arpack ───────────── v0.4.0
 Installed BinDeps ──────────── v1.0.0
 Installed HDF5 ─────────────── v0.12.5
 Installed JLD ──────────────── v0.9.1
 Installed CMake ────────────── v1.1.2
 Installed URIParser ────────── v0.4.0
 Installed Distances ────────── v0.8.2
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Parameters ───────── v0.12.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Missings ─────────── v0.4.3
 Installed Blosc ────────────── v0.5.1
 Installed StaticArrays ─────── v0.12.1
 Installed SpecialFunctions ─── v0.9.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed StatsFuns ────────── v0.9.3
 Installed BinaryProvider ───── v0.5.8
 Installed Rmath ────────────── v0.6.0
 Installed Compat ───────────── v2.2.0
 Installed LegacyStrings ────── v0.4.1
 Installed FileIO ───────────── v1.2.1
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed NearestNeighbors ─── v0.4.4
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_evf9sJ/Project.toml`
 [no changes]
  Updating `/tmp/jl_evf9sJ/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_2vKl9M/Project.toml`
 [no changes]
  Updating `/tmp/jl_2vKl9M/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_6xrx1S/Project.toml`
 [no changes]
  Updating `/tmp/jl_6xrx1S/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_mobI3j/Project.toml`
 [no changes]
  Updating `/tmp/jl_mobI3j/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_Shsdw5/Project.toml`
 [no changes]
  Updating `/tmp/jl_Shsdw5/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_Shsdw5/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -3.0259794442606037e6, [99998.99489176972, 1.0051082302698167], [192.35387897293649 -185.93726928607157 160.5459559180993; -0.947806851890688 1.12448541606003 4.547228107196471], [[100252.55077188245 -284.51449363646753 284.85671392198697; -284.51449363646753 100565.98547872517 -190.38454218335073; 284.85671392198697 -190.38454218335073 100268.72567928344], [0.9116785569243978 -1.0572822444225263 -4.293644989404281; -1.0572822444225263 1.2586222280490276 5.086250108772458; -4.293644989404281 5.086250108772458 20.57411203310133]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.155110e+03
      1       8.586103e+02      -2.964995e+02 |        6
      2       8.473691e+02      -1.124115e+01 |        0
      3       8.473691e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 847.3691244196789)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.082976
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.876054
[ Info: iteration 2, lowerbound -3.798202
[ Info: iteration 3, lowerbound -3.723300
[ Info: iteration 4, lowerbound -3.630189
[ Info: iteration 5, lowerbound -3.517443
[ Info: iteration 6, lowerbound -3.387715
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.249236
[ Info: iteration 8, lowerbound -3.123519
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -3.029207
[ Info: iteration 10, lowerbound -2.963431
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.905739
[ Info: iteration 12, lowerbound -2.854360
[ Info: iteration 13, lowerbound -2.823214
[ Info: iteration 14, lowerbound -2.807653
[ Info: dropping number of Gaussions to 3
[ Info: iteration 15, lowerbound -2.798527
[ Info: iteration 16, lowerbound -2.787206
[ Info: iteration 17, lowerbound -2.776441
[ Info: iteration 18, lowerbound -2.761146
[ Info: iteration 19, lowerbound -2.739832
[ Info: iteration 20, lowerbound -2.711200
[ Info: iteration 21, lowerbound -2.674656
[ Info: iteration 22, lowerbound -2.630879
[ Info: iteration 23, lowerbound -2.582091
[ Info: iteration 24, lowerbound -2.531752
[ Info: iteration 25, lowerbound -2.483560
[ Info: iteration 26, lowerbound -2.440094
[ Info: iteration 27, lowerbound -2.402006
[ Info: iteration 28, lowerbound -2.368503
[ Info: iteration 29, lowerbound -2.339374
[ Info: iteration 30, lowerbound -2.317448
[ Info: iteration 31, lowerbound -2.307663
[ Info: dropping number of Gaussions to 2
[ Info: iteration 32, lowerbound -2.303000
[ Info: iteration 33, lowerbound -2.299262
[ Info: iteration 34, lowerbound -2.299257
[ Info: iteration 35, lowerbound -2.299255
[ Info: iteration 36, lowerbound -2.299254
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Jan 19 01:35:25 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Jan 19 01:35:33 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Sun Jan 19 01:35:36 2020: EM with 272 data points 0 iterations avll -2.082976
5.8 data points per parameter
, Sun Jan 19 01:35:37 2020: GMM converted to Variational GMM
, Sun Jan 19 01:35:45 2020: iteration 1, lowerbound -3.876054
, Sun Jan 19 01:35:45 2020: iteration 2, lowerbound -3.798202
, Sun Jan 19 01:35:45 2020: iteration 3, lowerbound -3.723300
, Sun Jan 19 01:35:45 2020: iteration 4, lowerbound -3.630189
, Sun Jan 19 01:35:45 2020: iteration 5, lowerbound -3.517443
, Sun Jan 19 01:35:45 2020: iteration 6, lowerbound -3.387715
, Sun Jan 19 01:35:46 2020: dropping number of Gaussions to 7
, Sun Jan 19 01:35:46 2020: iteration 7, lowerbound -3.249236
, Sun Jan 19 01:35:46 2020: iteration 8, lowerbound -3.123519
, Sun Jan 19 01:35:46 2020: dropping number of Gaussions to 6
, Sun Jan 19 01:35:46 2020: iteration 9, lowerbound -3.029207
, Sun Jan 19 01:35:46 2020: iteration 10, lowerbound -2.963431
, Sun Jan 19 01:35:46 2020: dropping number of Gaussions to 4
, Sun Jan 19 01:35:46 2020: iteration 11, lowerbound -2.905739
, Sun Jan 19 01:35:46 2020: iteration 12, lowerbound -2.854360
, Sun Jan 19 01:35:46 2020: iteration 13, lowerbound -2.823214
, Sun Jan 19 01:35:46 2020: iteration 14, lowerbound -2.807653
, Sun Jan 19 01:35:46 2020: dropping number of Gaussions to 3
, Sun Jan 19 01:35:46 2020: iteration 15, lowerbound -2.798527
, Sun Jan 19 01:35:46 2020: iteration 16, lowerbound -2.787206
, Sun Jan 19 01:35:46 2020: iteration 17, lowerbound -2.776441
, Sun Jan 19 01:35:46 2020: iteration 18, lowerbound -2.761146
, Sun Jan 19 01:35:46 2020: iteration 19, lowerbound -2.739832
, Sun Jan 19 01:35:46 2020: iteration 20, lowerbound -2.711200
, Sun Jan 19 01:35:46 2020: iteration 21, lowerbound -2.674656
, Sun Jan 19 01:35:46 2020: iteration 22, lowerbound -2.630879
, Sun Jan 19 01:35:46 2020: iteration 23, lowerbound -2.582091
, Sun Jan 19 01:35:46 2020: iteration 24, lowerbound -2.531752
, Sun Jan 19 01:35:46 2020: iteration 25, lowerbound -2.483560
, Sun Jan 19 01:35:46 2020: iteration 26, lowerbound -2.440094
, Sun Jan 19 01:35:46 2020: iteration 27, lowerbound -2.402006
, Sun Jan 19 01:35:46 2020: iteration 28, lowerbound -2.368503
, Sun Jan 19 01:35:46 2020: iteration 29, lowerbound -2.339374
, Sun Jan 19 01:35:46 2020: iteration 30, lowerbound -2.317448
, Sun Jan 19 01:35:46 2020: iteration 31, lowerbound -2.307663
, Sun Jan 19 01:35:46 2020: dropping number of Gaussions to 2
, Sun Jan 19 01:35:46 2020: iteration 32, lowerbound -2.303000
, Sun Jan 19 01:35:46 2020: iteration 33, lowerbound -2.299262
, Sun Jan 19 01:35:46 2020: iteration 34, lowerbound -2.299257
, Sun Jan 19 01:35:46 2020: iteration 35, lowerbound -2.299255
, Sun Jan 19 01:35:46 2020: iteration 36, lowerbound -2.299254
, Sun Jan 19 01:35:46 2020: iteration 37, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 38, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 39, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 40, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 41, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 42, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 43, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 44, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 45, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 46, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 47, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 48, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 49, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: iteration 50, lowerbound -2.299253
, Sun Jan 19 01:35:46 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509223725123, 95.9549077627489]
β = [178.04509223725123, 95.9549077627489]
m = [4.250300733178765 79.28686694302141; 2.0002292576809797 53.85198717196971]
ν = [180.04509223725123, 97.9549077627489]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155546228268 -0.007644049043525018; 0.0 0.008581705164648535], [0.3758763613517425 -0.008953123829208837; 0.0 0.012748664777886779]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9996193283152469
avll from llpg:  -0.9996193283152466
avll direct:     -0.9996193283152469
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9991731253540556
avll from llpg:  -0.9991731253540557
avll direct:     -0.9991731253540557
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0712161   -0.182618      0.0322838     0.0582276    0.016299    0.0858535    0.00360984  -0.0819625    0.0177677    0.0567865    0.0040184    -0.107317     -0.0746348   0.0705822   -0.0150922    0.012263    6.82256e-5  -0.127306     0.121462     -0.0808175   -0.106585    -0.0207801   -0.198866     0.0453292  -0.0372561   -0.122013
 -0.0506008    0.0232761    -0.0553709     0.147463    -0.167236   -0.113975     0.0633356   -0.0120004    0.180631     0.162248    -0.0278343    -0.238849     -0.0259996  -0.0489121    0.0459822    0.0150963   0.0220413   -0.104486    -0.23966       0.0291914    0.0981812   -0.041395    -0.00732887   0.0118632   0.0709844   -0.0520061
 -0.0949414    0.0918966     0.0458089    -0.0738719    0.0219135  -0.0743145    0.0110551   -0.0293961   -0.0235924   -0.00595046   0.0727304     0.0755089    -0.0744143   0.0586327   -0.0266216   -0.0223658  -0.0234697   -0.176927     0.0324046    -0.0646399   -0.0368998   -0.125907     0.116641     0.158155   -0.122535     0.0285991
 -0.0590705   -0.00508842    0.171664     -0.0271682    0.0697819  -0.0224495   -0.0629214   -0.0480238    0.0111567   -0.117646     0.0684452    -0.136576      0.0345481   0.1913      -0.186463    -0.0287709  -0.0156389    0.0557973   -0.0236008    -0.0135907   -0.0621817    0.0818468    0.00653899  -0.0284552  -0.042153     0.0605434
 -0.0943931   -0.173983      0.0589779     0.0562572   -0.166761    0.00407032   0.0141854   -0.105785     0.260481     0.0493638    0.0348308     0.0589834     0.0472643   0.143565    -0.144978     0.0975783  -0.0478806    0.0901558    0.0540766    -0.165521     0.00981391  -0.0658502    0.0306217    0.139376   -0.041436     0.121006
 -0.0825382   -0.0571526     0.0445886     0.0253137   -0.0484348   0.00728045  -0.0005029   -0.0104948   -0.0280586    0.0593885   -0.0925929     0.0450045    -0.0660211  -0.0940322   -0.069078    -0.0680263   0.0807932    0.227213     0.103864     -0.0530425   -0.0544572    0.133221     0.100115    -0.138794   -0.124722     0.00768449
  0.0182432   -0.131189     -0.0443306    -0.130731     0.12309     0.0993836    0.0563866   -0.0571971   -0.0537194    0.100447     0.0502955     0.0842719    -0.0348756  -0.0870168   -0.0594423   -0.0621393   0.0395652    0.00462708  -0.121322      0.0512236   -0.0365582    0.118571     0.0955073   -0.0709148   0.200787     0.0762804
  0.0863523   -0.111337      0.0750482     0.150291    -0.160311    0.0329781    0.013224     0.00404373   0.0278646    0.0496582    0.100476      0.137881      0.17987     0.0910383   -0.098679    -0.0873467   0.0921948    0.0867007    0.0337991     0.144729    -0.0512122   -0.0346408   -0.083128    -0.0793189   0.0410946   -0.0641595
 -0.113735     0.056029      0.0389882    -0.00667294   0.175131    0.0655594   -0.00126675  -0.196248    -0.00300592   0.032378     0.0568875     0.181768      0.114294    0.0886648    0.0562353    0.0957646  -0.133676    -0.142706     0.00245085    0.104772    -0.116498    -0.0735877    0.0789896   -0.0718799   0.0164797   -0.208384
 -0.017792     0.05135      -0.0193        0.105925     0.148399   -0.0408182   -0.105908     0.0610819   -0.0688388    0.00360472   0.0172941     0.0416836    -0.0901862  -0.0258669   -0.097976     0.0611987  -0.164146    -0.0728962    0.0969943    -0.0697083   -0.0759341    0.166429    -0.00976029  -0.179319    0.0784781   -0.0924778
 -0.0937882   -0.0216863    -0.0818762     0.0243526    0.216538    0.11389     -0.230564    -0.0522523    0.0799423   -0.0490988   -0.00380198    0.198585      0.0282553  -0.0239271   -0.0258345   -0.220008   -0.104887     0.100326    -0.123053      0.130999    -0.00817886   0.209598    -0.037816     0.1401     -0.109158     0.0151883
  0.0534656   -0.101798     -0.0877353     0.0960455    0.0924576  -0.0822354    0.014053    -0.0982758   -0.0142352   -0.0664224   -0.0297795     0.129698     -0.101621    0.0990319   -0.0165124   -0.0125462   0.0241179    0.16856      0.0645333     0.0419766   -0.0523467   -0.122204    -0.0611648    0.0913909  -0.0677765   -0.00255395
  0.0963194   -0.0905427    -0.032051     -0.101088     0.112211   -0.203539     0.0305668    0.0450991   -0.067462     0.158835    -0.0263564    -0.0375282     0.213484    0.127153    -0.0349518   -0.0153131   0.00114681  -0.0454047   -0.0991245    -0.104399     0.0886229    0.0367592    0.0858258   -0.0432546  -0.0395802   -0.00832179
 -0.0615997   -0.111397      0.0245621    -0.0986842    0.116071   -0.0321422   -0.0959725   -0.111169     0.022297     0.00206246   0.0941101    -0.0863837     0.2513     -0.0953848   -0.109229     0.0757321   0.142523    -0.143965    -0.00858287   -0.0600577   -0.0467521   -0.0728521   -0.0255277    0.0630015  -0.0357717   -0.143312
 -0.288559    -0.20241      -0.0034164     0.00390404  -0.0543592   0.0367363   -0.0170259   -0.0668286   -0.0207618    0.128379     0.0820344    -0.207884      0.0564002  -0.0195541   -0.0837996   -0.104971   -0.0780937    0.0233694    0.148346     -0.00960589  -0.00551581   0.101414    -0.060146    -0.0677496  -0.111545    -0.00176227
  0.0936757   -0.0234852    -0.0203383    -0.0153089   -0.164055    0.0347952   -0.076999    -0.0242385   -0.0261503    0.00245416  -0.123812      0.168986     -0.105085    0.089808    -0.0793891    0.0300376  -0.0477115   -0.0867136   -0.141735      0.0291694   -0.10405     -0.0896146   -0.0490964    0.0130039   0.167581    -0.00734202
 -0.070905    -0.138359      0.00386936   -0.00887566  -0.11363     0.0672396   -0.0961869   -0.0285041    0.211441     0.0946957    0.130889      0.111791     -0.0787266  -0.0466578    0.0121252   -0.092804    0.204207     0.035299     0.041194     -0.00694682   0.058723     0.0473155   -0.0332342   -0.0853772  -0.0519718   -0.135112
  0.121666     0.0500471    -0.0172279    -0.0286084   -0.0240649  -0.0234866    0.00331072  -0.0581948   -0.0137532   -0.0915512    0.0475614     0.142781     -0.0453635   0.112519     0.0998399    0.112301   -0.167615    -0.0772381   -0.000918856   0.100668     0.177705    -0.0837259    0.0144164   -0.0546003   0.0736637   -0.0623718
  0.0770638   -0.0399495     0.0882064     0.0128816   -0.0186071   0.0630931    0.00429871  -0.0342061    0.00330951  -0.156815    -0.000664172   0.000965475  -0.0132343   0.0730553    0.127794    -0.0136788   0.0822242   -0.0202493    0.102314      0.0353402    0.133244    -0.133811    -0.0244062   -0.167444    0.0318526   -0.0220729
 -0.11803     -0.112015     -0.197947      0.0144128    0.0835     -0.0246679    0.0448472    0.0154084   -0.04879     -0.0748045   -0.00433385   -0.0183981     0.10281     0.126055    -0.119259     0.088956   -0.0216269   -0.0613098   -0.165304     -0.134798    -0.10804     -0.119212    -0.0159176   -0.151729   -0.0233254   -0.0184424
 -0.0221805    0.105907      0.0893154     0.12032      0.112008    0.0521624    0.0066824   -0.149101    -0.0615103   -0.0627887    0.0608057     0.0851653     0.0167034   0.0730813   -0.0094136   -0.020327    0.0946023    0.019075    -0.0652852     0.0813962    0.201927     0.00723137   0.00413779   0.149587   -0.0327444   -0.0351911
 -0.130229    -0.0105329    -0.114654      0.0957607   -0.0358084   0.0898898   -0.169727     0.160725     0.0893744    0.0244741    0.120062     -0.1935        0.0958267   0.00601822  -0.0748491    0.116799    0.0448988   -0.146494     0.0211401    -0.110237     0.0586247    0.0114938    0.142211     0.110739    0.158346    -0.270853
  0.0420831   -0.0962262     0.117456     -0.048435    -0.0941918  -0.0881849   -0.299724     0.0398406   -0.0570803    0.0522467   -0.0521736     0.0679504     0.0214805  -0.0887585    0.0384877    0.0945442   0.00497029  -0.0558776    0.0463169    -0.072511     0.211993     0.167713     0.0399034    0.0455742  -0.00703785  -0.114576
  0.0987341   -0.127223     -0.222507     -0.142409    -0.0668148  -0.0266518   -0.0572017   -0.058405     0.213737    -0.122828     0.00119342    0.0314084     0.0530011   0.00461919   0.0248085   -0.123802    0.117165    -0.0399314    0.0861282    -0.0521195   -0.197186     0.0239535    0.124145    -0.0431838   0.0155054    0.0772577
 -0.0528703   -0.11077       0.141378     -0.0679349   -0.0555563  -0.021637    -0.0826904   -0.0527441   -0.12423      0.105392    -0.0161458    -0.215857     -0.107961    0.00864594   0.240671    -0.115536   -0.113397    -0.105047    -0.130168      0.0214514   -0.127005    -0.0622425   -0.0184321   -0.101314   -0.00554141   0.00206237
  0.038176     0.00916034   -0.0863346    -0.0371853   -0.0194527  -0.188858    -0.0144131    0.113945    -0.0747542   -0.0727446   -0.0753463     0.119145     -0.0629067   0.0277888   -0.00763344  -0.120404   -0.028789     0.149665    -0.0828208    -0.113026     0.0327489    0.0865427    0.0459488    0.0899522  -0.0122206   -0.0408614
 -0.156945     0.144917      0.0461533    -0.107802     0.125807   -0.0721267   -0.20004     -0.0645078   -0.0402551    0.0963641    0.0348955    -0.129389      0.0527576   0.0286928    0.0853944    0.0429864   0.0356401    0.0778425    0.150883     -0.0161326   -0.142153     0.0549589    0.0435275    0.175667    0.0861693    0.0467722
  0.140908    -0.0366675    -0.0332131    -0.0791001    0.0229224   0.1274       0.0280651    0.0450624    0.100746    -0.0421101   -0.00603953   -0.100828      0.0601804  -0.081136     0.0874066    0.0582168  -0.0803166   -0.0512273    0.0400386    -0.0822965    0.0488925   -0.066806    -0.132268    -0.0609572  -0.0057431    0.0722957
 -0.259227    -0.0612988     0.0261437     0.0596066   -0.100487    0.150514     0.0430174    0.104171    -0.0112242   -0.126163    -0.0496583    -0.094647      0.0993862  -0.0980438   -0.0404459    0.205584    0.168776     0.0517702    0.151424      0.0515213    0.141458     0.110297    -0.101524    -0.204509   -0.0754872   -0.0647575
  0.00501081  -0.156162      0.00317982   -0.0167583   -0.161952   -0.0332601   -0.0302879   -0.103523    -0.0771149    0.0423702   -0.0616418     0.0911953     0.0256566  -0.145521     0.0264122    0.0631932   0.162115     0.118816    -0.0110695     0.0832995    0.14884     -0.00346236   0.0596671    0.0875413  -0.0565322    0.0795958
  0.0204074    0.0779652     0.000751614   0.0385278    0.0484503   0.0221532    0.137759    -0.251177     0.0158233    0.00802145  -0.0889383     0.0376356    -0.118032    0.140889     0.069628     0.0090967  -0.129227    -0.0402169    0.185727     -0.146126     0.145297    -0.0633139   -0.126129     0.0597461   0.0456271   -0.0420699
 -0.173185     0.000874445  -0.164718     -0.0650102    0.14062     0.153372     0.0821832    0.0201411   -0.034753     0.190794     0.0304254     0.0505467     0.0416348  -0.136218    -0.054075    -0.0271606   0.0277003    0.100929    -0.0281987    -0.11825     -0.153366     0.0355859   -0.134762     0.108646    0.00806677  -0.111392kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4295956685993854
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.429686
[ Info: iteration 2, average log likelihood -1.429618
[ Info: iteration 3, average log likelihood -1.429365
[ Info: iteration 4, average log likelihood -1.426455
[ Info: iteration 5, average log likelihood -1.414324
[ Info: iteration 6, average log likelihood -1.403995
[ Info: iteration 7, average log likelihood -1.401099
[ Info: iteration 8, average log likelihood -1.399700
[ Info: iteration 9, average log likelihood -1.398737
[ Info: iteration 10, average log likelihood -1.398112
[ Info: iteration 11, average log likelihood -1.397714
[ Info: iteration 12, average log likelihood -1.397457
[ Info: iteration 13, average log likelihood -1.397286
[ Info: iteration 14, average log likelihood -1.397163
[ Info: iteration 15, average log likelihood -1.397068
[ Info: iteration 16, average log likelihood -1.396991
[ Info: iteration 17, average log likelihood -1.396924
[ Info: iteration 18, average log likelihood -1.396860
[ Info: iteration 19, average log likelihood -1.396790
[ Info: iteration 20, average log likelihood -1.396693
[ Info: iteration 21, average log likelihood -1.396527
[ Info: iteration 22, average log likelihood -1.396147
[ Info: iteration 23, average log likelihood -1.395549
[ Info: iteration 24, average log likelihood -1.395112
[ Info: iteration 25, average log likelihood -1.394843
[ Info: iteration 26, average log likelihood -1.394623
[ Info: iteration 27, average log likelihood -1.394416
[ Info: iteration 28, average log likelihood -1.394201
[ Info: iteration 29, average log likelihood -1.393957
[ Info: iteration 30, average log likelihood -1.393694
[ Info: iteration 31, average log likelihood -1.393449
[ Info: iteration 32, average log likelihood -1.393262
[ Info: iteration 33, average log likelihood -1.393136
[ Info: iteration 34, average log likelihood -1.393050
[ Info: iteration 35, average log likelihood -1.392989
[ Info: iteration 36, average log likelihood -1.392943
[ Info: iteration 37, average log likelihood -1.392909
[ Info: iteration 38, average log likelihood -1.392884
[ Info: iteration 39, average log likelihood -1.392866
[ Info: iteration 40, average log likelihood -1.392853
[ Info: iteration 41, average log likelihood -1.392844
[ Info: iteration 42, average log likelihood -1.392837
[ Info: iteration 43, average log likelihood -1.392832
[ Info: iteration 44, average log likelihood -1.392829
[ Info: iteration 45, average log likelihood -1.392827
[ Info: iteration 46, average log likelihood -1.392825
[ Info: iteration 47, average log likelihood -1.392824
[ Info: iteration 48, average log likelihood -1.392823
[ Info: iteration 49, average log likelihood -1.392822
[ Info: iteration 50, average log likelihood -1.392822
┌ Info: EM with 100000 data points 50 iterations avll -1.392822
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4296860858672176
│     -1.429617677677147
│      ⋮
└     -1.3928216261159487
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.392982
[ Info: iteration 2, average log likelihood -1.392856
[ Info: iteration 3, average log likelihood -1.392614
[ Info: iteration 4, average log likelihood -1.390234
[ Info: iteration 5, average log likelihood -1.379221
[ Info: iteration 6, average log likelihood -1.366796
[ Info: iteration 7, average log likelihood -1.362282
[ Info: iteration 8, average log likelihood -1.360234
[ Info: iteration 9, average log likelihood -1.358596
[ Info: iteration 10, average log likelihood -1.357152
[ Info: iteration 11, average log likelihood -1.355842
[ Info: iteration 12, average log likelihood -1.354699
[ Info: iteration 13, average log likelihood -1.353726
[ Info: iteration 14, average log likelihood -1.352947
[ Info: iteration 15, average log likelihood -1.352342
[ Info: iteration 16, average log likelihood -1.351867
[ Info: iteration 17, average log likelihood -1.351506
[ Info: iteration 18, average log likelihood -1.351242
[ Info: iteration 19, average log likelihood -1.351056
[ Info: iteration 20, average log likelihood -1.350930
[ Info: iteration 21, average log likelihood -1.350845
[ Info: iteration 22, average log likelihood -1.350785
[ Info: iteration 23, average log likelihood -1.350744
[ Info: iteration 24, average log likelihood -1.350714
[ Info: iteration 25, average log likelihood -1.350693
[ Info: iteration 26, average log likelihood -1.350677
[ Info: iteration 27, average log likelihood -1.350666
[ Info: iteration 28, average log likelihood -1.350657
[ Info: iteration 29, average log likelihood -1.350651
[ Info: iteration 30, average log likelihood -1.350645
[ Info: iteration 31, average log likelihood -1.350641
[ Info: iteration 32, average log likelihood -1.350638
[ Info: iteration 33, average log likelihood -1.350635
[ Info: iteration 34, average log likelihood -1.350632
[ Info: iteration 35, average log likelihood -1.350630
[ Info: iteration 36, average log likelihood -1.350628
[ Info: iteration 37, average log likelihood -1.350627
[ Info: iteration 38, average log likelihood -1.350626
[ Info: iteration 39, average log likelihood -1.350625
[ Info: iteration 40, average log likelihood -1.350624
[ Info: iteration 41, average log likelihood -1.350623
[ Info: iteration 42, average log likelihood -1.350622
[ Info: iteration 43, average log likelihood -1.350622
[ Info: iteration 44, average log likelihood -1.350621
[ Info: iteration 45, average log likelihood -1.350621
[ Info: iteration 46, average log likelihood -1.350621
[ Info: iteration 47, average log likelihood -1.350620
[ Info: iteration 48, average log likelihood -1.350620
[ Info: iteration 49, average log likelihood -1.350620
[ Info: iteration 50, average log likelihood -1.350620
┌ Info: EM with 100000 data points 50 iterations avll -1.350620
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3929816172341118
│     -1.3928563617445693
│      ⋮
└     -1.3506196811890516
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.350801
[ Info: iteration 2, average log likelihood -1.350615
[ Info: iteration 3, average log likelihood -1.349890
[ Info: iteration 4, average log likelihood -1.343901
[ Info: iteration 5, average log likelihood -1.326583
[ Info: iteration 6, average log likelihood -1.308531
[ Info: iteration 7, average log likelihood -1.300265
[ Info: iteration 8, average log likelihood -1.296952
[ Info: iteration 9, average log likelihood -1.294934
[ Info: iteration 10, average log likelihood -1.293265
[ Info: iteration 11, average log likelihood -1.291955
[ Info: iteration 12, average log likelihood -1.291029
[ Info: iteration 13, average log likelihood -1.290287
[ Info: iteration 14, average log likelihood -1.289623
[ Info: iteration 15, average log likelihood -1.289008
[ Info: iteration 16, average log likelihood -1.288423
[ Info: iteration 17, average log likelihood -1.287834
[ Info: iteration 18, average log likelihood -1.287230
[ Info: iteration 19, average log likelihood -1.286669
[ Info: iteration 20, average log likelihood -1.286197
[ Info: iteration 21, average log likelihood -1.285828
[ Info: iteration 22, average log likelihood -1.285587
[ Info: iteration 23, average log likelihood -1.285450
[ Info: iteration 24, average log likelihood -1.285366
[ Info: iteration 25, average log likelihood -1.285308
[ Info: iteration 26, average log likelihood -1.285262
[ Info: iteration 27, average log likelihood -1.285224
[ Info: iteration 28, average log likelihood -1.285192
[ Info: iteration 29, average log likelihood -1.285165
[ Info: iteration 30, average log likelihood -1.285144
[ Info: iteration 31, average log likelihood -1.285126
[ Info: iteration 32, average log likelihood -1.285111
[ Info: iteration 33, average log likelihood -1.285099
[ Info: iteration 34, average log likelihood -1.285089
[ Info: iteration 35, average log likelihood -1.285080
[ Info: iteration 36, average log likelihood -1.285073
[ Info: iteration 37, average log likelihood -1.285067
[ Info: iteration 38, average log likelihood -1.285061
[ Info: iteration 39, average log likelihood -1.285056
[ Info: iteration 40, average log likelihood -1.285051
[ Info: iteration 41, average log likelihood -1.285046
[ Info: iteration 42, average log likelihood -1.285042
[ Info: iteration 43, average log likelihood -1.285038
[ Info: iteration 44, average log likelihood -1.285035
[ Info: iteration 45, average log likelihood -1.285031
[ Info: iteration 46, average log likelihood -1.285028
[ Info: iteration 47, average log likelihood -1.285025
[ Info: iteration 48, average log likelihood -1.285022
[ Info: iteration 49, average log likelihood -1.285019
[ Info: iteration 50, average log likelihood -1.285016
┌ Info: EM with 100000 data points 50 iterations avll -1.285016
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3508007297033855
│     -1.3506150967018817
│      ⋮
└     -1.2850163597177278
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.285240
[ Info: iteration 2, average log likelihood -1.285001
[ Info: iteration 3, average log likelihood -1.284255
[ Info: iteration 4, average log likelihood -1.275073
[ Info: iteration 5, average log likelihood -1.241541
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.210690
[ Info: iteration 7, average log likelihood -1.204123
[ Info: iteration 8, average log likelihood -1.192389
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.184793
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.188356
[ Info: iteration 11, average log likelihood -1.197120
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.188564
[ Info: iteration 13, average log likelihood -1.192449
[ Info: iteration 14, average log likelihood -1.184130
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.179585
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.185735
[ Info: iteration 17, average log likelihood -1.195244
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.187522
[ Info: iteration 19, average log likelihood -1.192523
[ Info: iteration 20, average log likelihood -1.184676
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.180103
[ Info: iteration 22, average log likelihood -1.186010
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.179848
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.192727
[ Info: iteration 25, average log likelihood -1.195253
[ Info: iteration 26, average log likelihood -1.187599
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.183140
[ Info: iteration 28, average log likelihood -1.188594
[ Info: iteration 29, average log likelihood -1.181194
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.177538
[ Info: iteration 31, average log likelihood -1.200387
[ Info: iteration 32, average log likelihood -1.189959
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.185505
[ Info: iteration 34, average log likelihood -1.191704
[ Info: iteration 35, average log likelihood -1.184111
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.179474
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.185598
[ Info: iteration 38, average log likelihood -1.194946
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.187389
[ Info: iteration 40, average log likelihood -1.193459
[ Info: iteration 41, average log likelihood -1.187252
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.183519
[ Info: iteration 43, average log likelihood -1.189104
[ Info: iteration 44, average log likelihood -1.181559
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.177639
[ Info: iteration 46, average log likelihood -1.199965
[ Info: iteration 47, average log likelihood -1.189414
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.185257
[ Info: iteration 49, average log likelihood -1.192336
[ Info: iteration 50, average log likelihood -1.186552
┌ Info: EM with 100000 data points 50 iterations avll -1.186552
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2852404274358704
│     -1.2850014146649587
│      ⋮
└     -1.1865524877972025
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.184117
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.183457
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.182732
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.176828
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.149100
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.114772
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.104424
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     16
│     22
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.093165
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.123152
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.093520
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.100637
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.094823
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.100924
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.101785
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.109265
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     16
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.083393
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.109321
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.102202
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.099284
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     16
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.090322
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.118072
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.091396
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.098864
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.100900
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.105953
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.098055
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.108405
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     16
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.082719
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.107548
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.108861
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.096494
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     16
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.089726
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.117925
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.091465
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.098872
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.100964
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.105940
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.098195
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.108959
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     16
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.084103
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.109856
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.103339
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.099281
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     16
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.090580
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.118169
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.091610
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.098577
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.092250
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.098843
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.091624
┌ Info: EM with 100000 data points 50 iterations avll -1.091624
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.184117211990254
│     -1.183456744996127
│      ⋮
└     -1.091623514580322
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4295956685993854
│     -1.4296860858672176
│     -1.429617677677147
│     -1.429365080912383
│      ⋮
│     -1.0922498876573312
│     -1.0988428486828468
└     -1.091623514580322
32×26 Array{Float64,2}:
 -0.086708    -0.174053      0.0682659    0.143793    -0.176309     0.011527    -0.128168    -0.0300611   0.258971    -0.00275238  -0.0164397     0.0427011   0.196447     0.179607    -0.230488     0.0424344   0.0582103    0.0940188    0.0672715   -0.163341     0.00767853   -0.0420149    0.0150084    0.122936    -0.168556    -0.741608
 -0.108571    -0.171576      0.0436855   -0.111103    -0.173079     0.0033332    0.0392829   -0.200868    0.262537     0.0833431    0.0891856     0.0669414  -0.0868833    0.105297    -0.0839163    0.218861   -0.212135     0.0982984    0.0454612   -0.15465      0.0100138    -0.0705703    0.0330624    0.197126     0.104556     0.674747
 -0.0736317   -0.0380464    -0.318597     0.0218324   -0.0422103    0.10951     -0.0145711   -0.109035   -0.00613065   0.0461649   -0.303757      0.122742   -0.136373     0.00247968  -0.0640536   -0.0612772   0.0414556    0.210352     0.107929    -0.0538233   -0.133128      0.109169     0.101364    -0.0884568   -0.249543     0.0838635
 -0.146792    -0.0591397     0.405033     0.0417262   -0.0664292   -0.0965131    0.022885     0.0202708  -0.0482939    0.0617702    0.0745471     0.0227659   0.0425123   -0.110477    -0.0821478   -0.0640971   0.137458     0.21793      0.0982734   -0.0515506    0.040474      0.175309     0.161339    -0.184498    -0.0104921    0.0144866
 -0.106644    -0.18839      -0.24025      0.0476511    0.0819162   -0.0174312    0.0431473   -0.0136823  -0.0445831   -0.0600117   -0.00784733   -0.0166368   0.113162     0.125222    -0.220204     0.0870293  -0.0101123   -0.0681665   -0.165242    -0.148411    -0.0988524    -0.0817251   -0.0141462   -0.138819    -0.0442578   -0.044027
 -0.186511    -0.000894392  -0.0373994    0.0333665    0.0282508    0.0970359   -0.0325018    0.0123491   0.0217646   -0.0275747    0.0417244    -0.0289869   0.110559     0.0154837   -0.0248514    0.137492    0.0293378   -0.0645233    0.0801602    0.0193592   -0.00438693    0.0168916    0.0461501   -0.0602095    0.0251168   -0.165542
  0.122725    -0.0268602     0.114655    -0.0470584   -0.0768817   -0.0875134   -0.282636     0.0489388  -0.042073     0.0716575   -0.0178553     0.0563306   0.0219826   -0.0866733    0.0287408    0.0833364   0.007937    -0.0620794    0.0466543   -0.0749049    0.196403      0.163373     0.046019     0.0386985    0.0124744   -0.076404
 -0.0223903    0.0510948    -0.017892     0.10939      0.156523    -0.0261515   -0.135663     0.0598179  -0.0534597    0.00605068  -0.0121344     0.0761728  -0.0749782   -0.0246136   -0.155828     0.0399015  -0.143773    -0.0764155    0.115651    -0.0668298   -0.0384975     0.180724    -0.0305257   -0.192255     0.0407927   -0.0587182
  0.0557299    0.13426       0.0327094   -0.113219     0.122941    -0.0697084   -0.220947    -0.0485609  -0.0411809    0.208625     0.191301     -0.163483    0.243355     0.176682     0.0617039    0.0548622   0.0390554    0.215322     0.093931    -0.0161126   -0.136608      0.0322499   -0.00303295  -0.255274     0.127906     0.0667728
 -0.550738     0.150846      0.0698328   -0.102173     0.131722    -0.0679992   -0.179247    -0.0831742  -0.0339427   -0.0158487   -0.0362551    -0.097006   -0.119749    -0.0669596    0.108901     0.0540031   0.0351345   -0.0844512    0.200997    -0.0159816   -0.143216      0.0726097    0.125637     0.547575     0.0736414    0.0129017
 -0.0254461    0.104708      0.118407     0.12798      0.120568     0.0552061    0.0280929   -0.148756   -0.236828    -0.138152    -0.0178517     0.0660731   0.0197663    0.0410464   -0.16432     -0.0320377   0.0800545    0.0709905   -0.191185    -0.498192     0.215286      0.135163    -0.011482     0.246072    -0.0252606   -0.0703512
 -0.0249593    0.113143      0.0920082    0.113945     0.100944     0.0216207   -0.0338004   -0.120074    0.0713149   -0.0151028    0.158511      0.0820016   0.0467277    0.0642053    0.15415     -0.0167803   0.104206    -0.0685448   -0.0559575    0.591405     0.188741     -0.0856185    0.0150355    0.169504    -0.0660987   -0.0561726
  0.065846    -0.129127      0.0580669    0.149678    -0.169968     0.0663849    0.011839     0.0130095   0.0139053    0.0486232    0.101682      0.156638    0.168741     0.102842    -0.0952159   -0.0750477   0.102529     0.0750497    0.0347057    0.134463    -0.039459     -0.036374    -0.0810721   -0.0579155    0.0606324   -0.0705794
  0.0827004   -0.135343     -0.23211     -0.0955007   -0.0642064   -0.0389508   -0.0534143   -0.0635539   0.220706    -0.111897     0.0161976     0.0337936   0.0486228    0.00159023   0.0265027   -0.122776    0.0792161   -0.136795     0.0786135   -0.0410775   -0.186791      0.0168759    0.1407      -0.0455272    0.0141853    0.066412
  0.0499442   -0.109708      0.00658011  -0.0963599    0.119283    -0.133233    -0.0198263   -0.0221738  -0.0502648    0.0861301    0.0276077    -0.0535142   0.214049     0.035171    -0.0688292    0.0111109   0.0899336   -0.0895987   -0.0493656   -0.0296626    0.0225653    -0.00540678   0.00389086   0.0090418   -0.0268218   -0.068161
  0.0794275   -0.0148705     0.00206622  -0.019739    -0.016944     0.00732511  -0.0186879   -0.0440141   0.0162107   -0.0845132    0.0632013     0.109247    0.00365612   0.115726     0.0816224    0.0901435  -0.141212    -0.0766495    0.0264149    0.0678767    0.164969     -0.054728     0.0228065   -0.0557643    0.0775511   -0.0558046
  0.0441357    0.100876     -0.0454979    0.0190075    0.0965938    0.112976    -0.229006    -0.38683     0.0648239   -0.0785488   -0.00737946    0.156612    0.0185602   -0.0286495    0.0485592   -0.0605751   0.0304948    0.103683    -0.155015     0.0978687    0.00835567    0.0899208   -0.0507187    0.0768301   -0.0816964   -0.12431
 -0.212414    -0.0298369    -0.0962002    0.0311691    0.289266     0.114695    -0.20959      0.210353    0.168281    -0.0190183   -0.00213736    0.240233    0.0345972   -0.0207975   -0.117193    -0.361256   -0.184822     0.0901264   -0.077701     0.122038    -0.00891481    0.313417    -0.0171403    0.106179    -0.125781     0.0756898
 -0.0241675   -0.106813     -0.212305    -0.0155916   -0.0914236    0.0606765   -0.516747     0.0573912   0.212217     0.162484     0.142182      0.0754485  -0.0434789   -0.0399545    0.0127245   -0.173816    0.224373    -0.092285     0.0367923   -0.0045723    0.0556995    -0.0349626   -0.0539895   -0.11748     -0.0595      -0.177789
 -0.224487    -0.153664      0.172014    -0.0108496   -0.126222     0.0728402    0.192827    -0.0853955   0.211165     0.0504279    0.115028      0.12892    -0.129106    -0.0547387    0.00568985  -0.0131735   0.209712     0.133931     0.0530033   -0.0176356    0.0628666     0.112399     0.0467245   -0.0618338   -0.0483027   -0.0838025
 -0.285234    -0.209003      0.00141997   0.00343827  -0.0359736    0.0337257   -0.0443573   -0.102649   -0.021062     0.112233     0.081693     -0.19316     0.0532011   -0.0202747   -0.0834402   -0.098471   -0.122805     0.0227514    0.159692    -0.0107511    0.00159145    0.108686    -0.0700661   -0.0654168   -0.114097     0.00458786
  0.00524178  -0.0871987    -0.00216878   0.104979    -0.0743819   -0.0068429    0.0046357   -0.0314377   0.0793462    0.114141     0.0018373    -0.165461   -0.0589997    0.0178216    0.00285624   0.0229909   0.0130924   -0.126452    -0.0407204   -0.0346044    0.00732597   -0.0355784   -0.108344     0.0331369    0.0319156   -0.0955263
 -0.163736     0.0178837    -0.162545    -0.0641619    0.130912     0.133521     0.0707046    0.0107812   0.00203786   0.189657     0.0290961     0.0737392   0.0476417   -0.136163    -0.0933754   -0.0334366   0.0284511    0.103603    -0.0285169   -0.112929    -0.152854     -0.0198997   -0.137219     0.107655     0.0100728   -0.150172
 -0.0523481   -0.137556      0.140641    -0.0666061   -0.0611384   -0.0157134   -0.083044    -0.0449864  -0.102361     0.101028    -0.0214873    -0.217283   -0.111256     0.00963683   0.262556    -0.106277   -0.119547    -0.105684    -0.142046     0.00955541  -0.117154     -0.016505    -0.0158285   -0.0977578   -0.00752441   0.0392861
 -0.0353033    0.0475254    -0.0185444   -0.0565929    0.00304888  -0.127551    -0.00521227   0.0404049  -0.0244553   -0.041366    -0.000479494   0.112213   -0.0633785    0.0361901   -0.018115    -0.0518038  -0.0336131   -0.0172292   -0.0305488   -0.0559052   -0.0228073    -0.0231987    0.0793028    0.119979    -0.0743582   -0.00799724
  0.0595154   -0.100279     -0.096137     0.069596     0.069589    -0.0908814    0.0532626   -0.1292     -0.0106468   -0.0699632   -0.0275145     0.129041   -0.0955738    0.0770062   -0.0106289   -0.0125134   0.0621563    0.159423     0.156289     0.032855    -0.0329949    -0.101878    -0.0613299    0.120349    -0.0536593   -0.00473326
  0.0653746    0.0260235    -0.0167698    0.0131359    0.0362013    0.0597545    0.0955407   -0.0964255   0.0564238   -0.0178281   -0.0483934    -0.026071   -0.02859      0.0293642    0.068081     0.0386242  -0.0923822   -0.0437907    0.108988    -0.113902     0.0829196    -0.0722723   -0.121726     0.00800067   0.0151486    0.0153024
  0.0384509   -0.0337887     0.0796064    0.00747543  -0.0561936    0.0438216   -0.0262555   -0.0428187   0.00553732  -0.0967862   -0.0370275    -0.011202   -0.0271032    0.117125    -0.0369812   -0.0108718   0.00205394  -0.0294601   -0.00752952   0.0228416   -0.000592207  -0.0749219   -0.0428321   -0.0667542    0.0575268    0.0100034
  0.0338182   -0.177225      0.0366188   -0.00194852   0.0169672   -0.0358202   -0.0432939   -0.0437437  -0.0771414    0.0430589   -0.0472381     0.140972   -0.353936    -0.0384358    0.0359195    0.0631751   0.154048     0.126873    -0.00841766   0.172308     0.12128      -0.00052639   0.171359     0.0140287   -0.146285     0.111232
 -0.0357114   -0.13796      -0.0319935   -0.0272998   -0.355565    -0.0290881   -0.0242687   -0.0914293  -0.0758872    0.0345145   -0.0589785     0.081123    0.2252      -0.284627     0.0162871    0.0635228   0.165249     0.110873    -0.0114079    0.0468786    0.189597     -0.00815412  -0.0364391    0.15887     -0.0189206    0.0434106
 -0.0267771   -0.136329     -0.0543965   -0.133332     0.100206    -0.0395717   -0.186247    -0.0298908  -0.0468954    0.0771512    0.144713      0.053708    0.121591    -0.108186    -0.0482251   -0.153834    0.0521246   -0.00517057  -0.0822284    0.736556    -0.478026      0.18992     -0.0284809   -0.122166     0.122838     0.0647797
  0.0270844   -0.123935     -0.0170602   -0.1295       0.12073      0.209025     0.280245    -0.104472   -0.0633784    0.141652    -0.0103912     0.109454   -0.0163762   -0.110144    -0.0724288   -0.056292    0.0512614    0.00755079  -0.135275    -0.49271      0.485255      0.0340393    0.245836    -0.0166729    0.152625     0.0844799[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.102230
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     16
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.077544
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.088323
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     16
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.086902
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.092170
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     16
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.072511
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.102174
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     16
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.076900
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.088204
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     16
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.086854
┌ Info: EM with 100000 data points 10 iterations avll -1.086854
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.186275e+05
      1       7.206283e+05      -1.979992e+05 |       32
      2       6.844985e+05      -3.612977e+04 |       32
      3       6.661558e+05      -1.834266e+04 |       32
      4       6.559583e+05      -1.019759e+04 |       32
      5       6.488130e+05      -7.145217e+03 |       32
      6       6.441022e+05      -4.710793e+03 |       32
      7       6.409330e+05      -3.169266e+03 |       32
      8       6.386405e+05      -2.292521e+03 |       32
      9       6.367719e+05      -1.868560e+03 |       32
     10       6.353605e+05      -1.411380e+03 |       32
     11       6.344678e+05      -8.927222e+02 |       32
     12       6.339027e+05      -5.651221e+02 |       32
     13       6.334889e+05      -4.137394e+02 |       32
     14       6.331800e+05      -3.089693e+02 |       32
     15       6.329403e+05      -2.396496e+02 |       32
     16       6.326932e+05      -2.470727e+02 |       31
     17       6.324260e+05      -2.672101e+02 |       32
     18       6.321395e+05      -2.865552e+02 |       32
     19       6.318325e+05      -3.069286e+02 |       32
     20       6.315687e+05      -2.638202e+02 |       32
     21       6.313784e+05      -1.903264e+02 |       32
     22       6.312420e+05      -1.363897e+02 |       32
     23       6.311702e+05      -7.177313e+01 |       32
     24       6.311275e+05      -4.278490e+01 |       31
     25       6.310929e+05      -3.455980e+01 |       32
     26       6.310670e+05      -2.585004e+01 |       31
     27       6.310509e+05      -1.611506e+01 |       32
     28       6.310405e+05      -1.042412e+01 |       28
     29       6.310282e+05      -1.234826e+01 |       28
     30       6.310137e+05      -1.449420e+01 |       28
     31       6.310033e+05      -1.036340e+01 |       28
     32       6.309965e+05      -6.821026e+00 |       29
     33       6.309915e+05      -4.938817e+00 |       25
     34       6.309823e+05      -9.252295e+00 |       27
     35       6.309701e+05      -1.215010e+01 |       29
     36       6.309583e+05      -1.188313e+01 |       28
     37       6.309444e+05      -1.380989e+01 |       30
     38       6.309292e+05      -1.524769e+01 |       29
     39       6.309110e+05      -1.823864e+01 |       28
     40       6.308895e+05      -2.148882e+01 |       27
     41       6.308629e+05      -2.655599e+01 |       27
     42       6.308171e+05      -4.577259e+01 |       31
     43       6.307022e+05      -1.149419e+02 |       32
     44       6.304681e+05      -2.341270e+02 |       32
     45       6.301233e+05      -3.447568e+02 |       32
     46       6.297031e+05      -4.201786e+02 |       32
     47       6.293554e+05      -3.477572e+02 |       32
     48       6.291257e+05      -2.297168e+02 |       32
     49       6.289822e+05      -1.434532e+02 |       32
     50       6.288715e+05      -1.107160e+02 |       31
K-means terminated without convergence after 50 iterations (objv = 628871.4901495138)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.340110
[ Info: iteration 2, average log likelihood -1.311001
[ Info: iteration 3, average log likelihood -1.278854
[ Info: iteration 4, average log likelihood -1.239565
[ Info: iteration 5, average log likelihood -1.190439
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.132481
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.123087
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.118249
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.108332
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     17
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.079472
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.091530
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.062632
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.083246
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.067912
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.061223
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      8
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.064516
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.092584
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.068118
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.070066
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      3
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.075586
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.078655
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.061931
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.073027
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      3
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.062916
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.079946
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      8
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.063778
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.070402
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.050912
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.086365
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.078881
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.073365
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      3
│      8
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.057837
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.078491
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.093819
[ Info: iteration 35, average log likelihood -1.073441
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      3
│      8
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.027069
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.096879
[ Info: iteration 38, average log likelihood -1.104292
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.060404
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│      8
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.042733
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.096517
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.070641
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.080239
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      3
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.061446
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.073301
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.074699
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.080653
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.066095
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.062219
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     23
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.067458
┌ Info: EM with 100000 data points 50 iterations avll -1.067458
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.06314      -0.0987695   -0.101036     0.0714357    0.0678816   -0.09445      0.0489764   -0.127537   -0.0119929   -0.0727804   -0.0275107    0.129824   -0.0955149   0.0747009   -0.0089401   -0.0128286   0.061655     0.164575      0.159466     0.0343574   -0.0338932    -0.101667    -0.0609078    0.119284     -0.0585593   -0.00424512
 -0.256469      0.142978     0.0506595   -0.107619     0.125901    -0.068129    -0.19934     -0.064613   -0.0378394    0.0952365    0.0754088   -0.131185    0.0577648   0.0518293    0.0849718    0.0562015   0.0366266    0.0628131     0.150091    -0.0158393   -0.140338      0.0513865    0.0648894    0.157407      0.101291     0.0396107
  0.179547     -0.0206031   -0.00785657  -0.024079    -0.0242101    0.00255707  -0.0114748   -0.048025    0.0257348   -0.0835418    0.0548       0.139106   -0.0474722   0.133843     0.116024     0.0972099  -0.165402    -0.0732116     0.0925586    0.105369     0.187404     -0.0475739    0.0218793   -0.0650217     0.106813    -0.0621364
 -0.0248744     0.108801     0.103971     0.119715     0.109636     0.0369526   -0.00507079  -0.133741   -0.0760001   -0.0741281    0.0729666    0.0743131   0.0348824   0.0513697    0.00312731  -0.0243762   0.0922566    0.000622968  -0.116484     0.058835     0.200987      0.0178621    0.00238795   0.201333     -0.0461385   -0.0575784
 -0.330421     -0.0685566    0.0232199    0.0534466   -0.0749938    0.134733     0.0551973    0.094412   -0.00754194  -0.129416    -0.0359578   -0.0779302   0.108567   -0.0733656   -0.0679288    0.21077     0.172349     0.0716073     0.169071     0.0496769    0.0919076     0.117528    -0.0810994   -0.201362     -0.0739204   -0.0276646
 -0.11298      -0.0484315    0.0415879    0.0331251   -0.0566686    0.0107916    0.00357518  -0.0434621  -0.0279355    0.054013    -0.121038     0.0755017  -0.0473258  -0.0577799   -0.072876    -0.0645261   0.0879847    0.216962      0.103111    -0.0520794   -0.0438811     0.145373     0.131167    -0.139528     -0.132028     0.0482989
  0.00289775   -0.127404    -0.0349364   -0.131477     0.111898     0.0960367    0.0626843   -0.0690001  -0.0576651    0.109676     0.0580327    0.0826818   0.0435711  -0.122542    -0.0606127   -0.103243    0.0518992    0.00747371   -0.111209     0.0571587    0.0349539     0.106957     0.119901    -0.0648933     0.139261     0.0757355
  0.0721813    -0.0567686    0.120807     0.0296721   -0.0324988    0.067987     0.0675097   -0.0540697  -0.0242813   -0.152587    -0.0232841   -0.0224046  -0.0155081   0.0718697    0.140731    -0.0377183   0.0442001   -0.0102231     0.0824946    0.0476944    0.16473      -0.150372    -0.0307481   -0.144583      0.0406625   -0.0174574
 -0.0778547     0.0382413    0.106928    -0.0400037    0.043279    -0.0518169   -0.0365847   -0.0339917   0.0136897   -0.0605704    0.0480029   -0.0242849  -0.0222008   0.123024    -0.0936609   -0.0270962  -0.0145878   -0.0708769    -0.00441467  -0.0398624   -0.0789567    -0.0269765    0.0608424    0.0600255    -0.0879752    0.0417545
 -0.106243     -0.188633    -0.244383     0.0473835    0.0823797   -0.0189525    0.0450689   -0.0141634  -0.0450258   -0.0612132   -0.00949628  -0.0158825   0.114275    0.126087    -0.224424     0.0839289  -0.0104639   -0.0651095    -0.164327    -0.148565    -0.099911     -0.0826117   -0.0142211   -0.13988      -0.0361452   -0.0423775
 -0.0886982     0.0282336   -0.0735146    0.0268186    0.199667     0.115475    -0.216437    -0.0819223   0.123799    -0.0494098   -0.00297933   0.20425     0.0283158  -0.0222393   -0.0417077   -0.213617   -0.0835703    0.101145     -0.117203     0.109406    -0.000248891   0.20699     -0.0310186    0.0907061    -0.10312     -0.0187778
 -0.0974267    -0.172878     0.0559106    0.01732     -0.174284     0.0075018   -0.0449269   -0.114208    0.26073      0.0398944    0.0355636    0.0555962   0.0553374   0.143075    -0.157447     0.129789   -0.075204     0.0961433     0.0566513   -0.160735     0.0087566    -0.0552462    0.023788     0.159828     -0.0335497   -0.0414833
 -0.0393082     0.0102487   -0.049894     0.153797    -0.209246    -0.111721     0.0729441    0.0161494   0.150694     0.170173    -0.0124422   -0.239159   -0.0190344  -0.0460224    0.0715492    0.017153    0.00266189  -0.116256     -0.22577      0.0256703    0.109839     -0.0536724   -0.0509482    0.0143106     0.080741    -0.0591871
 -0.000817135   0.0743032    0.0168582    0.0818492    0.0558052    0.0152068    0.15103     -0.256793    0.0159143    0.00718311  -0.0861069    0.0304999  -0.119007    0.141595     0.106155     0.0100724  -0.13226     -0.0334075     0.18153     -0.145279     0.145217     -0.0605533   -0.111724     0.060085      0.022649    -0.0385443
  0.115407     -0.0140675   -0.0511139   -0.0421244    0.0459792    0.10008      0.0415848    0.0479975   0.0967881   -0.0461764   -0.00257483  -0.114437    0.0658764  -0.0841933    0.0799006    0.0547132  -0.0580093   -0.0453108     0.0663777   -0.0876039    0.0481173    -0.072654    -0.126739    -0.0311268    -0.0123979    0.0693748
 -0.286409     -0.21038      0.00164143   0.00396602  -0.0361158    0.0346014   -0.0439358   -0.104315   -0.0203107    0.113477     0.0808098   -0.194524    0.0535577  -0.0201974   -0.0838634   -0.0986122  -0.122835     0.0229963     0.159628    -0.010601     0.0011069     0.109311    -0.0726342   -0.0663773    -0.113186     0.00514218
  0.0338741     0.0123467   -0.0993645   -0.0236212   -0.0187821   -0.224923     0.0208666    0.12273    -0.0556373   -0.0706947   -0.0619017    0.221179   -0.0616582  -0.00563734  -0.0248518   -0.122158   -0.0515364    0.1619       -0.0960757   -0.0748514    0.0347852     0.118326     0.0379105    0.0945892    -0.0295672   -0.0413217
  0.0820362    -1.2149       0.0532916    0.154761    -0.195288     0.00418462   0.033795     0.0151067   0.0191357    0.0612157    0.107908     0.109849    0.123504    0.107012    -0.0870711   -0.0833598   0.0700631    0.0874809     0.0352925    0.119001    -0.0138435    -0.0130292   -0.0669312   -0.0230729     0.0997474   -0.0651632
  0.0831397    -0.134586    -0.232676    -0.096431    -0.0656947   -0.0391308   -0.055615    -0.0604391   0.222046    -0.113385     0.0147969    0.0337677   0.0474767   0.00226865   0.0274772   -0.123171    0.0790764   -0.136534      0.0786019   -0.0409025   -0.187415      0.0188914    0.140331    -0.0460111     0.0144751    0.0676544
  0.0463512     1.87499      0.0689262    0.145211    -0.12602      0.199287    -0.0260959    0.0102593   0.00487578   0.0203428    0.0933476    0.238001    0.260304    0.101878    -0.11129     -0.0732379   0.180358     0.0434908     0.0300453    0.173457    -0.083746     -0.0678341   -0.0989766   -0.131227     -0.00090025  -0.0794493
 -0.117051      0.0454774    0.00794588  -0.0286519    0.190938     0.0544626   -8.08158e-5  -0.218964   -0.0272151    0.048472     0.0537228    0.200204    0.100937    0.104127     0.018484     0.0857798  -0.128708    -0.150085      0.0145834    0.10278     -0.221127     -0.0715584    0.0961175   -0.0971325    -0.0312392   -0.186992
 -0.111557     -0.0595735   -0.0228327   -0.0660335    0.0381501    0.0632432   -0.00232641  -0.0173966  -0.0533934    0.150408     0.00495404  -0.0665496  -0.0308199  -0.0688356    0.072228    -0.067444   -0.0413011    0.00794549   -0.0839487   -0.0575139   -0.142119     -0.0228901   -0.0817853    0.010734      0.00321757  -0.0625292
  0.10315      -0.0137886   -0.0655369   -0.0229122   -0.18933      0.0527798   -0.0728999   -0.0216618  -0.00472057  -0.00543495  -0.113181     0.168875   -0.098161    0.086282    -0.0832566    0.0313874  -0.0391996   -0.0968042    -0.0848747    0.0121711   -0.0960428    -0.118005    -0.0704627   -0.000357239   0.162918    -0.00857302
  0.123778     -0.0216559    0.113273    -0.048911    -0.0788123   -0.0851024   -0.286302     0.0470896  -0.0430439    0.0719868   -0.0220316    0.060457    0.0221236  -0.0856318    0.0315298    0.0858275   0.00716385  -0.0621318     0.0472464   -0.0706868    0.194625      0.162054     0.0491583    0.0324096     0.0110816   -0.0829247
 -0.122521     -0.129328    -0.0230739   -0.0132345   -0.108158     0.0666325   -0.169133    -0.0120443   0.211765     0.107629     0.129738     0.102339   -0.084985   -0.0471801    0.00961527  -0.0953326   0.217172     0.0178026     0.0446529   -0.0107873    0.0592036     0.0362053   -0.00392878  -0.0902833    -0.054069    -0.131678
  0.000142212  -0.158596     0.00325646  -0.0145464   -0.165516    -0.0324818   -0.0342039   -0.0665245  -0.0764416    0.0390109   -0.0531992    0.112142   -0.0710101  -0.158903     0.0268922    0.0633728   0.160031     0.119221     -0.00985658   0.111375     0.15474      -0.00402804   0.0688702    0.0845523    -0.0835648    0.0782664
 -0.0201813     0.0502134   -0.0196861    0.104751     0.15836     -0.024162    -0.140154     0.0628472  -0.0542138    0.00608622  -0.00842162   0.0767386  -0.0775114  -0.0269933   -0.163857     0.0409617  -0.146579    -0.0717513     0.116418    -0.0691493   -0.0329873     0.191617    -0.0317365   -0.202044      0.0424807   -0.0618914
 -0.119695     -0.00531231  -0.132871     0.0734369   -0.00822416   0.0887273   -0.148984     0.140277    0.0733088    0.0123894    0.106461    -0.17925     0.0772988   0.0260359   -0.0242555    0.102313    0.0137529   -0.123636      0.0308658   -0.0792074    0.0901245     0.00494043   0.12746      0.0934487     0.155848    -0.244776
  0.114401     -0.0848736   -0.0253768   -0.0997522    0.108522    -0.207317     0.02732      0.0423058  -0.0888713    0.157775    -0.0306237   -0.032417    0.19983     0.150502    -0.0325924   -0.0296874   0.0178902   -0.0559976    -0.0953989    0.00448491   0.103262      0.0399272    0.0182102   -0.0386263    -0.0401925   -0.0117325
  0.0647579    -0.178849     0.0667026    0.0596106    0.0505965    0.0753449   -0.028337    -0.0778042   0.0162143    0.0566206    6.65763e-5  -0.103281   -0.0915938   0.0765124   -0.0553385    0.0128078   0.00507644  -0.124502      0.124088    -0.0846089   -0.0986826    -0.0217925   -0.217689     0.0413715    -0.0429592   -0.129961
 -0.0131568    -0.114788     0.0448471   -0.0901711    0.102292    -0.0411873   -0.0637792   -0.0879028   0.0102397   -0.00552728   0.0751548   -0.0791832   0.205308   -0.0737845   -0.103605     0.0610097   0.141371    -0.10997      -0.00209688  -0.0481315   -0.0340165    -0.0627755    0.00125875   0.0738697     0.00081226  -0.121184
 -0.143559      0.0437854   -0.0110926   -0.0261567   -0.0220753    0.0534107   -0.025694     0.0211302  -0.00887573  -0.118822     0.0674347    0.14642     0.0621266   0.112743     0.136331     0.0997617  -0.164308    -0.0710886    -0.121142     0.0632007    0.128916     -0.0841102    0.00914516  -0.0229093     0.0228469   -0.0622837[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.066665
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      8
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.028004
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      3
│     17
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.020150
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      8
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.037776
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.030519
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      8
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.002710
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.045383
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      8
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.026073
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      3
│     17
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.014620
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      8
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.033723
┌ Info: EM with 100000 data points 10 iterations avll -1.033723
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.204109      0.152679     0.114583     0.040109    0.0507531   -0.152733     0.0174948    0.0168011   0.0896004    0.116744     0.0845969    0.0299531    -0.0624028    0.10759     -0.154566     0.0557396   -0.168405     0.0952417    -0.175529    -0.0831737    0.170471     0.0571488    0.00904983   0.0950388   -0.0218127    0.0861998
 -0.136235     -0.281546    -0.113896    -0.084896   -0.0594871    0.0277901   -0.0951571    0.167963    0.0932229   -0.225563    -0.0460499   -0.110415      0.0137615   -0.0361798   -0.0830825    0.195503     0.00551021  -0.103084     -0.0553183   -0.0527894   -0.0649916   -0.203682    -0.0142407    0.0785043    0.25416     -0.0182858
  0.0916129     0.00471822  -0.160963    -0.100381   -0.0118792    0.172139    -0.101868    -0.0326317   0.0642405    0.0117633    0.0422244   -0.036441      0.15856     -0.119038    -0.0361635    0.0860494   -0.030813     0.088252     -0.0114436    0.0349115    0.21652      0.0473841   -0.124558     0.217736    -0.195057    -0.144428
 -0.0301443     0.0850212   -0.106033    -0.0845231  -0.0827956    0.154788    -0.00608257  -0.0287487  -0.0332158   -0.0233297   -0.130821     0.0187212    -0.041293     0.265388     0.00302013  -0.0497022   -0.00323668   0.0249898     0.0500355    0.00628243  -0.081637     0.00932899  -0.174365     0.00981848  -0.178211    -0.190003
 -0.165733     -0.0120552    0.093926     0.0592447  -0.210329     0.183884     0.132597    -0.0874081  -0.0058218    0.126643     0.0320333    0.0875946    -0.051581    -0.00579181   0.124447    -0.00779149  -0.0749985   -0.0138946    -0.0966352   -0.022329    -0.0108894    0.0533986    0.0121573    0.00596821   0.153726     0.0555803
  0.00410148   -0.0333366    0.0195811    0.195854    0.0671112   -0.0103924    0.272955    -0.219502   -0.0861663    0.0783923    0.0575772   -0.199284      0.169737    -0.075048     0.0254171    0.00985726   0.0267883    0.125164     -0.110312    -0.0851032    0.151024     0.0920995    0.010875     0.144787     0.15355     -0.0829757
  0.0106009    -0.0837588    0.107275     0.169947   -0.050439     0.179983    -0.065982    -0.133885   -0.0997941    0.181791     0.00694308  -0.0285034    -0.0525006   -0.10052      0.130494     0.141635    -0.133783    -0.184754     -0.0360472    0.313572     0.0487038   -0.275206    -0.234648    -0.172926     0.241001     0.168514
  0.0603698    -0.0107702    0.0186876    0.0824033  -0.142006     0.13529      0.00175309  -0.175939   -0.11623     -0.0836588   -0.104936    -0.240264     -0.0209562    0.146725     0.0922239    0.0575251    0.0216508   -0.0764926    -0.0934135    0.0353436   -0.139072    -0.0163664   -0.0611772   -0.130849     0.0324964    0.150953
  0.104508      0.109595    -0.110723     0.112636    0.044835    -0.00530706   0.0520418    0.152698   -0.126385     0.107485    -0.0896431    0.186652     -0.0973613    0.0781142   -0.142891     0.0784149   -0.103987     0.0880851    -0.0495635   -0.196182     0.0277124   -0.055576    -0.18787      0.0182021   -0.0977965   -0.0560938
  0.00933566   -0.0289908    0.131959    -0.0517439  -0.0333565    0.0945154    0.0568698   -0.0649083  -0.156788    -0.0028238    0.0388204   -0.0493866    -0.018066     0.0234838    0.0463217    0.0113224   -0.134252    -0.0523307     0.00200742   0.00669438  -0.141444    -0.115747    -0.0195474   -0.0347707   -0.0637183   -0.245106
  0.0709636    -0.212834    -0.00780678   0.0724351  -0.0442241    0.125718    -0.00113697  -0.0627913  -0.0198286    0.0462799    0.0366444    0.00682755    0.0125546    0.165835     0.122924    -0.138657     0.078524    -0.1139        0.0491292    0.0179324   -0.0419745   -0.02699      0.0388398   -0.0781365    0.0905563    0.12007
  0.000471428  -0.0789604    0.164452     0.171306   -0.0222438    0.209367    -0.103348     0.0439505  -0.00613123  -0.0148314   -0.148402     0.000115512   0.14434      0.0548746    0.0211842   -0.0679118    0.0185447   -0.14862      -0.0158876    0.0505197   -0.0864691    0.0394974    0.0888963   -0.0208208   -0.0606562    0.123485
 -0.050358      0.044665     0.11199     -0.111409    0.0307957    0.0503328    0.0916517    0.0320632   0.0283407   -0.00967721   0.0620421    0.0651269     0.0138157    0.163828    -0.0128045    0.081422    -0.0990455    0.218527     -0.129336    -0.123694    -0.0455783    0.0666957    0.135775     0.0796969   -0.0193825   -0.0597685
 -0.0882333     0.13124     -0.0420968    0.116525    0.00924332  -0.169772     0.139942    -0.0827227   0.0642955    0.108584    -0.0513279    0.0408714     0.00210497  -0.0559039   -0.148768     0.0439404   -0.0261297    0.129993      0.0837804    0.0300384   -0.0109707   -0.00281411   0.0104745    0.132536    -0.183936    -0.183018
  0.123817      0.00238455  -0.0107573    0.1018      0.0328593   -0.0417402   -0.107915     0.181609   -0.00223626  -0.0523492    0.0985922    0.0875035    -0.170883     0.134466     0.058518     0.0991023    0.108035    -0.198603     -0.0279005    0.144156    -0.0568469   -0.0590837   -0.0119421    0.0207209    0.0226223   -0.0628239
 -0.03025      -0.177703    -0.0731692   -0.113884   -0.0194988   -0.0687181   -0.0872131   -0.0224209   0.00941395   0.0578271    0.0638749    0.0338674    -0.0537561    0.0128195   -0.0286333   -0.0993823   -0.0265635   -0.0478925    -0.00787936  -0.136286     0.0332676    0.207338     0.0798205   -0.237448    -0.0738643    0.242906
  0.0538196    -0.0995851    0.069275     0.0654574   0.0679572    0.0896625    0.0167471   -0.0171123  -0.0419795    0.0996013    0.133429     0.0365432    -0.0809149   -0.0156032    0.0135125   -0.0129923   -0.0982268    0.0197687     0.0148363    0.0491478    0.246051     0.0519498   -0.0501084   -0.102361     0.189373    -0.223929
 -0.132597      0.119991    -0.068091     0.115686    0.0106289    0.070503     0.080269    -0.0180386  -0.031864     0.00459147  -0.02521     -0.0106149     0.107149     0.149702    -0.0141772    0.09677     -0.0617534    0.140202     -0.0609941   -0.222388     0.0888183   -0.14044     -0.16519      0.0689364    0.142595     0.0265727
  0.0466822    -0.0898755    0.0247137   -0.018379    0.0182844   -0.118002     0.0239761    0.0673285   0.003687    -0.11799     -0.0831307    0.0946873    -0.0610839   -0.205614     0.100484    -0.11932     -0.103469    -0.0119343     0.153667     0.0789807    0.0041419   -0.0373011   -0.156528     0.0741304   -0.00475816   0.0519093
 -0.07108       0.228255     0.00805637  -0.135746    0.0707895   -0.0782955    0.047748    -0.0778124   0.044464    -0.0765512    0.00827194   0.0519532    -0.00573715  -0.0303408   -0.0569861    0.0801903   -0.0203256   -0.000441335   0.0228991    0.0453753   -0.164041    -0.129751    -0.132169     0.0124001   -0.102814     0.0359634
  0.0361913     0.216651    -0.125525    -0.107881    0.0259945    0.0178637    0.0875994   -0.0357127   0.119725     0.0638485   -0.135556    -0.0122244    -0.00848142   0.0458258   -0.0744088    0.0710734   -0.146999    -0.00220234   -0.115422    -0.0367225   -0.202806    -0.0658745   -0.100111    -0.0580378    0.131499    -0.0391896
  0.0683417    -0.0796021   -0.158262    -0.0959829  -0.0470733   -0.126202     0.024218    -0.0225144   0.0951166   -0.0145416    0.17483     -0.16595       0.123291     0.0501899   -0.162589     0.11217      0.0612821    0.0481811     0.124089    -0.111448     0.0913881   -0.0925831   -0.156959     0.00704892  -0.0427633   -0.0293716
  0.110152     -0.0641104   -0.249953     0.0340024  -0.0855812    0.105003     0.0134374   -0.0472254   0.0517235    0.0527597    0.100114    -0.022158      0.0382264    0.0287778   -0.0197529    0.126354    -0.0599873    0.0355526    -0.0120838    0.17633     -0.274985     0.0930054    0.0844141    0.186761     0.120652     0.144301
 -0.0608689     0.0281462   -0.0315623   -0.0507898  -0.139264    -0.0378293    0.0429486   -0.115643    0.0991589   -0.133068    -0.0312011   -0.195177     -0.0131151    0.142649    -0.071613     0.0666698    0.0761771   -0.0726994    -0.0481713    0.077917     0.0217219   -0.0774975   -0.0684674    0.00776745   0.0906464    0.148142
  0.0936558     0.00289485  -0.0694509    0.279457   -0.0458361    0.0615958   -0.132757    -0.0848772  -0.132814    -0.0673714    0.135528     0.0396484     0.147181     0.0597834   -0.14085      0.0924482    0.0353827   -0.0860987    -0.167207     0.0132794    0.0668475   -0.0422695    0.242053    -0.135358     0.122354    -0.114061
 -0.0453741     0.135647     0.1256      -0.0506611   0.060391     0.148217    -0.0818239    0.132803   -0.0398491   -0.134147    -0.215398     0.0864886    -0.154339     0.049038    -0.173875     0.0786355    0.0744222   -0.0922178    -0.0490783    0.032224    -0.12436     -0.0654229   -0.132536     0.055165    -0.00184884  -0.0825259
  0.160735     -0.106032     0.16918      0.0041349   0.0580477    0.00593333  -0.0443357   -0.160959    0.145182     0.0410142    0.137711    -0.0379906    -0.0812772    0.103805    -0.0301955    0.0885499   -0.0912612    0.0104048     0.0251784   -0.0428333    0.0832478   -0.122281    -0.0101958   -0.0864946    0.0181271    0.0343268
  0.111526     -0.139963    -0.252644    -0.247419   -0.0305678    0.158109     0.0314168    0.065842   -0.00953968   0.147157    -0.00596634   0.0236736    -0.0578549   -0.011512    -0.0704248    0.0592631    0.0365877   -0.0936175    -0.00638561  -0.115236     0.127753    -0.0775689    0.0142646    0.0493077   -0.00297132  -0.209514
  0.0931559     0.0061082   -0.100802    -0.019028    0.164787     0.0986311    0.0136169    0.112063    0.155002     0.00721671  -0.172667     0.0194112    -0.0581655    0.226988     0.0885724    0.0863552    0.0222847    0.20956      -0.0285189   -0.10435     -0.0526498    0.0721978    0.0155925   -0.0919593    0.00108456  -0.107431
  0.028302      0.0406131    0.033816     0.156313   -0.0813397    0.171809     0.0956611   -0.0310418   0.088612    -0.164972     0.142426     0.0522126     0.230719    -0.0900172    0.0935854   -0.00911665  -0.038427     0.201739     -0.00569695   0.0915135    0.00623001   0.145096     0.0775997   -0.126706     0.194272     0.12918
  0.00860485    0.191105     0.0671009    0.0450982  -0.170316     0.0714562    0.0286249   -0.041473    0.029685     0.036897     0.0980183    0.00618493   -0.0876391    0.0296445   -0.0558013   -0.0637328   -0.115737    -0.0602825    -0.109732    -0.102536    -0.00759106   0.11925      0.0165359   -0.0469212    0.0232415   -0.0783663
 -0.0363949     0.0431396   -0.135169    -0.0115283  -0.0471646   -0.0835787   -0.0433076   -0.0345789  -0.12023      0.146547    -0.0786383    0.123581      0.182067     0.0564436    0.168335     0.0521719    0.0419128    0.0230819    -0.0649986   -0.147999    -0.0422102   -0.00339773  -0.075906     0.114616    -0.0555806   -0.0136228kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4201802268178658
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420201
[ Info: iteration 2, average log likelihood -1.420117
[ Info: iteration 3, average log likelihood -1.420046
[ Info: iteration 4, average log likelihood -1.419960
[ Info: iteration 5, average log likelihood -1.419858
[ Info: iteration 6, average log likelihood -1.419746
[ Info: iteration 7, average log likelihood -1.419638
[ Info: iteration 8, average log likelihood -1.419546
[ Info: iteration 9, average log likelihood -1.419475
[ Info: iteration 10, average log likelihood -1.419423
[ Info: iteration 11, average log likelihood -1.419377
[ Info: iteration 12, average log likelihood -1.419320
[ Info: iteration 13, average log likelihood -1.419227
[ Info: iteration 14, average log likelihood -1.419053
[ Info: iteration 15, average log likelihood -1.418725
[ Info: iteration 16, average log likelihood -1.418157
[ Info: iteration 17, average log likelihood -1.417317
[ Info: iteration 18, average log likelihood -1.416359
[ Info: iteration 19, average log likelihood -1.415572
[ Info: iteration 20, average log likelihood -1.415098
[ Info: iteration 21, average log likelihood -1.414869
[ Info: iteration 22, average log likelihood -1.414769
[ Info: iteration 23, average log likelihood -1.414726
[ Info: iteration 24, average log likelihood -1.414709
[ Info: iteration 25, average log likelihood -1.414701
[ Info: iteration 26, average log likelihood -1.414698
[ Info: iteration 27, average log likelihood -1.414696
[ Info: iteration 28, average log likelihood -1.414695
[ Info: iteration 29, average log likelihood -1.414694
[ Info: iteration 30, average log likelihood -1.414694
[ Info: iteration 31, average log likelihood -1.414694
[ Info: iteration 32, average log likelihood -1.414693
[ Info: iteration 33, average log likelihood -1.414693
[ Info: iteration 34, average log likelihood -1.414693
[ Info: iteration 35, average log likelihood -1.414693
[ Info: iteration 36, average log likelihood -1.414692
[ Info: iteration 37, average log likelihood -1.414692
[ Info: iteration 38, average log likelihood -1.414692
[ Info: iteration 39, average log likelihood -1.414692
[ Info: iteration 40, average log likelihood -1.414692
[ Info: iteration 41, average log likelihood -1.414692
[ Info: iteration 42, average log likelihood -1.414692
[ Info: iteration 43, average log likelihood -1.414692
[ Info: iteration 44, average log likelihood -1.414691
[ Info: iteration 45, average log likelihood -1.414691
[ Info: iteration 46, average log likelihood -1.414691
[ Info: iteration 47, average log likelihood -1.414691
[ Info: iteration 48, average log likelihood -1.414691
[ Info: iteration 49, average log likelihood -1.414691
[ Info: iteration 50, average log likelihood -1.414691
┌ Info: EM with 100000 data points 50 iterations avll -1.414691
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.420201439564405
│     -1.420117270931123
│      ⋮
└     -1.414691146606673
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414712
[ Info: iteration 2, average log likelihood -1.414625
[ Info: iteration 3, average log likelihood -1.414550
[ Info: iteration 4, average log likelihood -1.414460
[ Info: iteration 5, average log likelihood -1.414352
[ Info: iteration 6, average log likelihood -1.414238
[ Info: iteration 7, average log likelihood -1.414129
[ Info: iteration 8, average log likelihood -1.414040
[ Info: iteration 9, average log likelihood -1.413972
[ Info: iteration 10, average log likelihood -1.413924
[ Info: iteration 11, average log likelihood -1.413889
[ Info: iteration 12, average log likelihood -1.413863
[ Info: iteration 13, average log likelihood -1.413841
[ Info: iteration 14, average log likelihood -1.413822
[ Info: iteration 15, average log likelihood -1.413805
[ Info: iteration 16, average log likelihood -1.413787
[ Info: iteration 17, average log likelihood -1.413770
[ Info: iteration 18, average log likelihood -1.413752
[ Info: iteration 19, average log likelihood -1.413734
[ Info: iteration 20, average log likelihood -1.413714
[ Info: iteration 21, average log likelihood -1.413693
[ Info: iteration 22, average log likelihood -1.413672
[ Info: iteration 23, average log likelihood -1.413650
[ Info: iteration 24, average log likelihood -1.413628
[ Info: iteration 25, average log likelihood -1.413607
[ Info: iteration 26, average log likelihood -1.413586
[ Info: iteration 27, average log likelihood -1.413567
[ Info: iteration 28, average log likelihood -1.413550
[ Info: iteration 29, average log likelihood -1.413535
[ Info: iteration 30, average log likelihood -1.413522
[ Info: iteration 31, average log likelihood -1.413511
[ Info: iteration 32, average log likelihood -1.413501
[ Info: iteration 33, average log likelihood -1.413493
[ Info: iteration 34, average log likelihood -1.413487
[ Info: iteration 35, average log likelihood -1.413481
[ Info: iteration 36, average log likelihood -1.413477
[ Info: iteration 37, average log likelihood -1.413473
[ Info: iteration 38, average log likelihood -1.413470
[ Info: iteration 39, average log likelihood -1.413467
[ Info: iteration 40, average log likelihood -1.413465
[ Info: iteration 41, average log likelihood -1.413463
[ Info: iteration 42, average log likelihood -1.413462
[ Info: iteration 43, average log likelihood -1.413460
[ Info: iteration 44, average log likelihood -1.413459
[ Info: iteration 45, average log likelihood -1.413458
[ Info: iteration 46, average log likelihood -1.413457
[ Info: iteration 47, average log likelihood -1.413456
[ Info: iteration 48, average log likelihood -1.413455
[ Info: iteration 49, average log likelihood -1.413454
[ Info: iteration 50, average log likelihood -1.413453
┌ Info: EM with 100000 data points 50 iterations avll -1.413453
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4147121288759203
│     -1.4146250184858529
│      ⋮
└     -1.4134532996470484
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413465
[ Info: iteration 2, average log likelihood -1.413412
[ Info: iteration 3, average log likelihood -1.413366
[ Info: iteration 4, average log likelihood -1.413313
[ Info: iteration 5, average log likelihood -1.413249
[ Info: iteration 6, average log likelihood -1.413174
[ Info: iteration 7, average log likelihood -1.413093
[ Info: iteration 8, average log likelihood -1.413011
[ Info: iteration 9, average log likelihood -1.412934
[ Info: iteration 10, average log likelihood -1.412867
[ Info: iteration 11, average log likelihood -1.412808
[ Info: iteration 12, average log likelihood -1.412758
[ Info: iteration 13, average log likelihood -1.412713
[ Info: iteration 14, average log likelihood -1.412673
[ Info: iteration 15, average log likelihood -1.412636
[ Info: iteration 16, average log likelihood -1.412601
[ Info: iteration 17, average log likelihood -1.412569
[ Info: iteration 18, average log likelihood -1.412538
[ Info: iteration 19, average log likelihood -1.412509
[ Info: iteration 20, average log likelihood -1.412481
[ Info: iteration 21, average log likelihood -1.412454
[ Info: iteration 22, average log likelihood -1.412427
[ Info: iteration 23, average log likelihood -1.412401
[ Info: iteration 24, average log likelihood -1.412376
[ Info: iteration 25, average log likelihood -1.412350
[ Info: iteration 26, average log likelihood -1.412325
[ Info: iteration 27, average log likelihood -1.412301
[ Info: iteration 28, average log likelihood -1.412276
[ Info: iteration 29, average log likelihood -1.412252
[ Info: iteration 30, average log likelihood -1.412228
[ Info: iteration 31, average log likelihood -1.412204
[ Info: iteration 32, average log likelihood -1.412181
[ Info: iteration 33, average log likelihood -1.412159
[ Info: iteration 34, average log likelihood -1.412138
[ Info: iteration 35, average log likelihood -1.412118
[ Info: iteration 36, average log likelihood -1.412099
[ Info: iteration 37, average log likelihood -1.412081
[ Info: iteration 38, average log likelihood -1.412064
[ Info: iteration 39, average log likelihood -1.412048
[ Info: iteration 40, average log likelihood -1.412033
[ Info: iteration 41, average log likelihood -1.412019
[ Info: iteration 42, average log likelihood -1.412006
[ Info: iteration 43, average log likelihood -1.411993
[ Info: iteration 44, average log likelihood -1.411982
[ Info: iteration 45, average log likelihood -1.411971
[ Info: iteration 46, average log likelihood -1.411960
[ Info: iteration 47, average log likelihood -1.411950
[ Info: iteration 48, average log likelihood -1.411941
[ Info: iteration 49, average log likelihood -1.411932
[ Info: iteration 50, average log likelihood -1.411923
┌ Info: EM with 100000 data points 50 iterations avll -1.411923
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4134651378829655
│     -1.413411629404047
│      ⋮
└     -1.4119231270798984
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411925
[ Info: iteration 2, average log likelihood -1.411871
[ Info: iteration 3, average log likelihood -1.411823
[ Info: iteration 4, average log likelihood -1.411768
[ Info: iteration 5, average log likelihood -1.411701
[ Info: iteration 6, average log likelihood -1.411622
[ Info: iteration 7, average log likelihood -1.411528
[ Info: iteration 8, average log likelihood -1.411423
[ Info: iteration 9, average log likelihood -1.411312
[ Info: iteration 10, average log likelihood -1.411199
[ Info: iteration 11, average log likelihood -1.411089
[ Info: iteration 12, average log likelihood -1.410984
[ Info: iteration 13, average log likelihood -1.410886
[ Info: iteration 14, average log likelihood -1.410794
[ Info: iteration 15, average log likelihood -1.410708
[ Info: iteration 16, average log likelihood -1.410630
[ Info: iteration 17, average log likelihood -1.410559
[ Info: iteration 18, average log likelihood -1.410494
[ Info: iteration 19, average log likelihood -1.410437
[ Info: iteration 20, average log likelihood -1.410385
[ Info: iteration 21, average log likelihood -1.410338
[ Info: iteration 22, average log likelihood -1.410297
[ Info: iteration 23, average log likelihood -1.410259
[ Info: iteration 24, average log likelihood -1.410226
[ Info: iteration 25, average log likelihood -1.410195
[ Info: iteration 26, average log likelihood -1.410167
[ Info: iteration 27, average log likelihood -1.410142
[ Info: iteration 28, average log likelihood -1.410118
[ Info: iteration 29, average log likelihood -1.410097
[ Info: iteration 30, average log likelihood -1.410077
[ Info: iteration 31, average log likelihood -1.410059
[ Info: iteration 32, average log likelihood -1.410043
[ Info: iteration 33, average log likelihood -1.410027
[ Info: iteration 34, average log likelihood -1.410013
[ Info: iteration 35, average log likelihood -1.410000
[ Info: iteration 36, average log likelihood -1.409987
[ Info: iteration 37, average log likelihood -1.409976
[ Info: iteration 38, average log likelihood -1.409965
[ Info: iteration 39, average log likelihood -1.409955
[ Info: iteration 40, average log likelihood -1.409945
[ Info: iteration 41, average log likelihood -1.409936
[ Info: iteration 42, average log likelihood -1.409927
[ Info: iteration 43, average log likelihood -1.409919
[ Info: iteration 44, average log likelihood -1.409910
[ Info: iteration 45, average log likelihood -1.409903
[ Info: iteration 46, average log likelihood -1.409895
[ Info: iteration 47, average log likelihood -1.409888
[ Info: iteration 48, average log likelihood -1.409881
[ Info: iteration 49, average log likelihood -1.409874
[ Info: iteration 50, average log likelihood -1.409867
┌ Info: EM with 100000 data points 50 iterations avll -1.409867
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4119249351413805
│     -1.4118711604734338
│      ⋮
└     -1.409866762659624
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409869
[ Info: iteration 2, average log likelihood -1.409803
[ Info: iteration 3, average log likelihood -1.409740
[ Info: iteration 4, average log likelihood -1.409663
[ Info: iteration 5, average log likelihood -1.409567
[ Info: iteration 6, average log likelihood -1.409446
[ Info: iteration 7, average log likelihood -1.409303
[ Info: iteration 8, average log likelihood -1.409144
[ Info: iteration 9, average log likelihood -1.408977
[ Info: iteration 10, average log likelihood -1.408813
[ Info: iteration 11, average log likelihood -1.408658
[ Info: iteration 12, average log likelihood -1.408515
[ Info: iteration 13, average log likelihood -1.408385
[ Info: iteration 14, average log likelihood -1.408268
[ Info: iteration 15, average log likelihood -1.408162
[ Info: iteration 16, average log likelihood -1.408066
[ Info: iteration 17, average log likelihood -1.407979
[ Info: iteration 18, average log likelihood -1.407899
[ Info: iteration 19, average log likelihood -1.407827
[ Info: iteration 20, average log likelihood -1.407761
[ Info: iteration 21, average log likelihood -1.407701
[ Info: iteration 22, average log likelihood -1.407646
[ Info: iteration 23, average log likelihood -1.407595
[ Info: iteration 24, average log likelihood -1.407548
[ Info: iteration 25, average log likelihood -1.407505
[ Info: iteration 26, average log likelihood -1.407464
[ Info: iteration 27, average log likelihood -1.407427
[ Info: iteration 28, average log likelihood -1.407392
[ Info: iteration 29, average log likelihood -1.407359
[ Info: iteration 30, average log likelihood -1.407328
[ Info: iteration 31, average log likelihood -1.407299
[ Info: iteration 32, average log likelihood -1.407272
[ Info: iteration 33, average log likelihood -1.407246
[ Info: iteration 34, average log likelihood -1.407221
[ Info: iteration 35, average log likelihood -1.407198
[ Info: iteration 36, average log likelihood -1.407175
[ Info: iteration 37, average log likelihood -1.407154
[ Info: iteration 38, average log likelihood -1.407134
[ Info: iteration 39, average log likelihood -1.407115
[ Info: iteration 40, average log likelihood -1.407097
[ Info: iteration 41, average log likelihood -1.407079
[ Info: iteration 42, average log likelihood -1.407063
[ Info: iteration 43, average log likelihood -1.407047
[ Info: iteration 44, average log likelihood -1.407032
[ Info: iteration 45, average log likelihood -1.407018
[ Info: iteration 46, average log likelihood -1.407004
[ Info: iteration 47, average log likelihood -1.406991
[ Info: iteration 48, average log likelihood -1.406978
[ Info: iteration 49, average log likelihood -1.406966
[ Info: iteration 50, average log likelihood -1.406955
┌ Info: EM with 100000 data points 50 iterations avll -1.406955
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4098685305974974
│     -1.409803498110876
│      ⋮
└     -1.4069548580551074
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4201802268178658
│     -1.420201439564405
│     -1.420117270931123
│     -1.4200457408225424
│      ⋮
│     -1.4069783178809827
│     -1.406966327102629
└     -1.4069548580551074
32×26 Array{Float64,2}:
 -0.267521     0.0329987  -0.398157    0.769257   -0.363972    -0.125552    0.407685    0.0703258   0.250991    -0.317623    -0.573474   -0.344008    -0.0432875    0.521639    0.0774714    0.411996    0.332236   -0.123311   -0.183503    -0.517434   -0.394232    -0.091584    0.0203556  -0.166528     0.384061    -0.568449
 -0.226254    -0.0452766   0.044473    0.415199   -0.124281    -0.308934    0.217625    0.503246   -0.432792    -0.358392     0.681246    0.205336    -0.0631152    0.380564    0.581952     0.0732411  -0.371509   -0.0508881  -0.906664    -0.29794    -0.745158     0.0288527  -0.411721   -0.054891    -0.0264745   -0.397843
 -0.145857    -0.19399    -0.211253    0.0338061  -0.0941652    0.41374    -0.294593    0.401872   -0.245204     0.609655    -0.606612   -0.277397    -0.545689     0.360796    0.0541217   -0.176885    0.0500316  -0.249208   -0.00230371  -0.245474   -0.246305    -0.376971   -0.238881    0.214115    -0.21519     -0.498057
  0.133586    -0.143905    0.442688    0.0277983  -0.00439391  -0.378256   -0.0922628  -0.0693641  -0.182748    -0.0691984   -0.109932   -0.56116     -0.267758     0.169877   -0.363336    -0.0586166  -0.146135   -0.247942   -0.0668804   -0.10564     0.0554351   -0.620641   -0.337972   -0.243471     0.452389    -0.365977
  0.197253     0.430143   -0.410246    0.560714   -0.313093    -0.490025    0.570558   -0.516642    0.536177     0.0689821    0.363834    0.0560609   -0.813438     0.499973    0.262069     0.100444   -0.182164    0.151233    0.460091    -0.0680718  -0.158189    -0.0172546  -0.448608    0.00765692   0.323115     0.0974227
  0.0981497    0.135945   -0.382681   -0.117248   -0.31982     -0.44364    -0.185741    0.0439111   0.234151     0.324798     0.179956    0.679257    -0.0402722   -0.184631    0.00774515   0.0227755  -0.368367    0.38953     0.135114    -0.114263    0.0102345   -0.585545   -0.254095    0.363117    -0.193175    -0.285279
 -0.647759    -0.0654889  -0.436791    0.49148    -0.528078    -0.233728   -0.196033   -0.613972   -0.436407    -0.388123     0.195499   -0.0918931    0.0935577   -0.156987    0.179122    -0.363399   -0.137366   -0.269713    0.101006     0.254374   -0.116351     0.0689808  -0.102351    0.341202     0.111683    -0.0849491
 -0.83648      0.0862054  -0.0617438  -0.123662   -0.250108     0.198453   -0.238203   -0.301368   -0.0289534    0.436983    -0.0537091   0.0530121   -0.0581295   -0.231863    0.850316     0.0955979  -0.0331011  -0.018479    0.124641    -0.0151186  -0.00219496   0.370243    0.272053    0.0960231    0.0157074    0.43492
  0.19939      0.143771    0.375344    0.16647     0.202035     0.388027    0.216559    0.125077   -0.508646     0.132499     0.110413   -0.116639    -0.432573    -0.295905    0.149368     0.170421    0.0577375  -0.0832362  -0.216134    -0.101603    0.494305    -0.0484108  -0.167182   -0.329289    -0.332364     0.395661
  0.233296     0.247457   -0.0778688  -0.0762713   0.403679     0.27331     0.109675    0.151177   -0.070573    -0.498923     0.310452    0.250797     0.447054    -0.172743    0.113633     0.233964    0.164088   -0.103489   -0.0827967    0.506928    0.334152     0.380905    0.135553   -0.00478359  -0.237697    -0.14223
  0.441913     0.132608   -0.118482   -0.0782279   0.0771743    0.416785    0.283722    0.460789    0.607414    -0.113771    -0.0573073   0.11679     -0.00353354   0.773189   -0.12792      0.159301    0.347433    0.148538   -0.890258    -0.333403    0.362619    -0.0742884   0.0266867  -0.655038     0.0827462   -0.00710135
  0.379735    -0.0217981  -0.356608   -0.529935    0.245764     0.311177    0.350379    0.101529    0.631556     0.00564074  -0.0733372   0.217012     0.14062      0.329812   -0.341186     0.0122854  -0.431244    0.41354     0.207344     0.120682   -0.0581766    0.253938    0.0366057  -0.263099    -0.0651668    0.255631
  0.0448278    0.0287529  -0.209487    0.134058    0.0502443    0.108795    0.10276     0.0666737  -0.0085045   -0.0458208   -0.0441024   0.0230026   -0.102717     0.263507   -0.0553267    0.0812843   0.0798357  -0.0634723  -0.146995    -0.0700023  -0.0209732   -0.0574879  -0.245578   -0.03788      0.0150877   -0.187513
 -0.106937     0.134151    0.127903   -0.145643   -0.153242    -0.0890485   0.0485708  -0.220102    0.0939287    0.108854     0.0710878  -0.00913118   0.141727    -0.151997   -0.00573907  -0.0133588  -0.281281    0.122383    0.15476      0.0364691  -0.0151571   -0.150057    0.114658   -0.0632257    0.156552     0.289566
 -0.0893684   -0.362048    0.149924   -0.0743462  -0.0255773    0.139623   -0.169517    0.0513377   0.264081     0.0219728    0.073976   -0.265336     0.464719     0.163274    0.0893206   -0.0726859   0.311065   -0.0916135  -0.423169    -0.18603    -0.360369     0.418848    0.415557    0.191651     0.0093561    0.189414
  0.024772    -0.33301    -0.0261074   0.051924    0.025984     0.251414   -0.347262    0.0186284  -0.00141899  -0.339977    -0.392585   -0.338614    -0.149986    -0.0577291  -0.359404    -0.184181    0.0474242  -0.075923    0.605367     0.143628   -0.266444     0.612217    0.451068    0.220767     0.118971     0.0343659
 -0.591983    -0.191806    0.784104    0.737328    0.623151     0.0019471   0.254957    0.538563   -0.585135     0.115641    -0.391697    0.567627     0.756466    -0.070565    0.747576     0.858831   -0.60182    -0.24735     0.207256    -1.8653     -0.0828133   -0.976545   -0.149569    0.0363214    0.613164     0.980304
 -0.111245     0.412811    0.415982   -0.180911    0.0189879   -0.0414551   0.515724   -0.271242   -0.77142      0.407131    -0.232443   -0.281749     0.0132946   -0.0638067   0.241904     0.15557    -0.559355    0.150441    0.20077      0.239579    0.370731    -0.795822   -0.86638    -0.7902       0.196522     0.0231641
 -0.156648     0.0282958  -0.33993     0.0115177  -0.212512     0.264973   -0.0350862   0.223842    0.190271     0.0997045   -0.762624    0.0541793   -0.333256     0.447801    0.0245262    0.133714   -0.199791    0.0014401  -0.172081    -0.073471    0.0648021   -0.298659   -0.117012   -0.0595839   -0.0322376   -0.192987
 -0.104097    -0.190074    0.0180697  -0.0403305  -0.547018    -0.646451   -0.225986   -0.207629    0.108713     0.0703601    0.841045    0.186587    -0.0999241    0.154499    0.171733     0.130463   -0.0281927   0.0407898  -0.310922     0.0583619   0.166591    -0.419797   -0.202038   -0.0631845   -0.00617853  -0.108522
 -0.570342    -0.0786922   0.153535   -0.350238    0.0831737    0.242933   -0.435931   -0.189943    0.0930246    0.200637     0.207406    0.616121     0.565094    -0.46699    -0.120044     0.484928    0.0368885  -0.42212    -0.983161     0.292904    0.164929    -0.516495   -0.121927   -0.253111     0.223318     0.612835
 -0.0275264   -0.35145     0.0594785  -0.673347   -0.175726     0.0668181  -0.223998   -0.272367   -0.478304    -0.205573     0.116895    0.475555    -0.365886     0.29911    -0.483108     0.566441   -0.26316     0.598521   -0.114926     0.454114    0.195752    -0.325373   -0.719247    0.452498     0.0636682    0.273068
 -0.57918     -1.20326     0.144882   -0.34826     0.204488     0.218279   -0.0970559   0.72559    -1.11332      0.0295128   -0.405656   -0.440318     1.16869     -0.780492   -0.475219     0.128339    0.284304    0.575924   -0.582881    -0.235984    0.0589142    0.135851    0.385102    0.457084    -0.137902    -0.593437
  0.650892     0.216829    0.243951    0.0311358   0.376936     0.319282    0.458539   -0.135729   -0.419201    -0.0231512    0.604499    0.113592     1.0492      -0.10152    -0.526875     0.72709    -0.0325512   0.409967   -0.288491    -0.0370354   0.294497     0.0720394   0.230413   -0.319193     0.34956      0.187706
  0.650134    -0.266827    0.0282196  -0.106417    0.721346     0.275752    0.10784    -0.193926   -0.267455    -0.244549     0.120461   -0.507676    -0.399013     0.408045   -0.495315    -0.0263787   0.456722   -0.026574   -0.173447     0.153578    0.153823     0.654936   -0.465582   -0.208109    -0.562293    -0.0979398
  0.532329     0.386119    0.295039    0.987599   -0.0409722    0.178106   -0.0471746   0.149401   -0.113852     0.405568    -0.301194    0.180818    -0.325814     0.0980337  -0.886404    -0.081762    0.0512043  -0.214292    0.20881      0.0949985   0.274592     0.529846   -0.897885    0.754211    -0.121818     0.112725
  0.174452    -0.35468    -0.411816    0.550721   -0.237797     0.323257   -0.526286    0.335201    0.615731    -0.379525     0.233252    0.431437    -0.299747    -0.15812    -0.121785    -0.366878    0.410994   -0.138445    0.0125848   -0.114777   -0.367782     0.732461    0.695827    1.08129     -0.111128    -0.173532
 -0.0793794    0.025296    0.0358312  -0.0272626   0.505917     0.508282   -0.0249002   0.138574   -0.305394    -0.315485    -0.451038   -0.208233     0.0410173   -0.39541     0.23144     -0.0723056   0.281925   -0.128392    0.493144     0.128569   -0.169975     0.828817    0.385899    0.433365    -0.0631894    0.0320446
 -0.106007    -0.0414688   0.069334   -0.339471   -0.421549    -0.593193    0.0358024  -0.0800446   0.482019     0.111685    -0.0751622  -0.0238583    0.475214    -0.175999   -0.0257575   -0.466512   -0.403694    0.251128    0.479127    -0.347755   -0.619236    -0.408159    0.937015   -0.111575     0.261385     0.0213325
  0.166706    -0.179116    0.283419   -0.617625   -0.0333502    0.317743   -0.384649   -0.66065     0.333157     0.459391    -0.363489   -0.310964     0.351856    -0.26732    -0.54564     -0.246127    0.0107971   0.0360495   0.782097     0.308841    0.53364     -0.0299649   0.293365    0.261555    -0.0138296    0.247801
  0.00233644   0.755781   -0.176227    0.698668    0.39505      0.0617661   0.437788    0.20047     0.620963     0.147131    -0.021268   -0.556667     0.386117    -0.424166    0.519262    -0.760933    0.191907   -0.671502    0.0799884   -0.232822    0.0198797    0.300961    0.710002   -0.830683    -0.132285    -0.198482
  0.312155     0.469437    0.858172   -0.116926    0.198699    -0.490641   -0.250773   -0.359715    0.0519416   -0.0294313    0.804732   -0.264311     0.248515    -0.604945    0.329925    -0.336964    0.118041   -0.459894    0.293532    -0.29413    -0.356888     0.0344327   0.214944   -0.12098      0.0369504   -0.320327[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406944
[ Info: iteration 2, average log likelihood -1.406933
[ Info: iteration 3, average log likelihood -1.406923
[ Info: iteration 4, average log likelihood -1.406914
[ Info: iteration 5, average log likelihood -1.406905
[ Info: iteration 6, average log likelihood -1.406896
[ Info: iteration 7, average log likelihood -1.406887
[ Info: iteration 8, average log likelihood -1.406879
[ Info: iteration 9, average log likelihood -1.406871
[ Info: iteration 10, average log likelihood -1.406864
┌ Info: EM with 100000 data points 10 iterations avll -1.406864
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.440712e+05
      1       7.022126e+05      -2.418586e+05 |       32
      2       6.891298e+05      -1.308284e+04 |       32
      3       6.834699e+05      -5.659926e+03 |       32
      4       6.802387e+05      -3.231137e+03 |       32
      5       6.782413e+05      -1.997415e+03 |       32
      6       6.768931e+05      -1.348203e+03 |       32
      7       6.758982e+05      -9.948793e+02 |       32
      8       6.751271e+05      -7.711236e+02 |       32
      9       6.745088e+05      -6.183280e+02 |       32
     10       6.739828e+05      -5.259681e+02 |       32
     11       6.735162e+05      -4.666271e+02 |       32
     12       6.730840e+05      -4.321833e+02 |       32
     13       6.727011e+05      -3.829237e+02 |       32
     14       6.723669e+05      -3.341993e+02 |       32
     15       6.721030e+05      -2.638491e+02 |       32
     16       6.718380e+05      -2.650021e+02 |       32
     17       6.715886e+05      -2.494206e+02 |       32
     18       6.713459e+05      -2.427595e+02 |       32
     19       6.711490e+05      -1.968741e+02 |       32
     20       6.709887e+05      -1.602529e+02 |       32
     21       6.708294e+05      -1.593429e+02 |       32
     22       6.706722e+05      -1.571627e+02 |       32
     23       6.705292e+05      -1.430436e+02 |       32
     24       6.703983e+05      -1.308732e+02 |       32
     25       6.702678e+05      -1.304746e+02 |       32
     26       6.701454e+05      -1.224109e+02 |       32
     27       6.700328e+05      -1.125889e+02 |       32
     28       6.699324e+05      -1.004037e+02 |       32
     29       6.698351e+05      -9.729771e+01 |       32
     30       6.697284e+05      -1.067694e+02 |       32
     31       6.696286e+05      -9.973528e+01 |       32
     32       6.695411e+05      -8.756413e+01 |       32
     33       6.694605e+05      -8.053471e+01 |       32
     34       6.693825e+05      -7.804117e+01 |       32
     35       6.693137e+05      -6.876202e+01 |       32
     36       6.692420e+05      -7.169219e+01 |       32
     37       6.691827e+05      -5.929581e+01 |       32
     38       6.691265e+05      -5.625256e+01 |       32
     39       6.690674e+05      -5.910727e+01 |       32
     40       6.690166e+05      -5.082127e+01 |       32
     41       6.689704e+05      -4.619804e+01 |       32
     42       6.689268e+05      -4.360922e+01 |       32
     43       6.688855e+05      -4.121583e+01 |       32
     44       6.688508e+05      -3.470576e+01 |       32
     45       6.688161e+05      -3.470615e+01 |       32
     46       6.687779e+05      -3.818068e+01 |       32
     47       6.687380e+05      -3.994210e+01 |       32
     48       6.687009e+05      -3.708275e+01 |       32
     49       6.686613e+05      -3.957304e+01 |       32
     50       6.686165e+05      -4.481069e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 668616.5361081194)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419122
[ Info: iteration 2, average log likelihood -1.414006
[ Info: iteration 3, average log likelihood -1.412572
[ Info: iteration 4, average log likelihood -1.411508
[ Info: iteration 5, average log likelihood -1.410425
[ Info: iteration 6, average log likelihood -1.409453
[ Info: iteration 7, average log likelihood -1.408785
[ Info: iteration 8, average log likelihood -1.408407
[ Info: iteration 9, average log likelihood -1.408194
[ Info: iteration 10, average log likelihood -1.408059
[ Info: iteration 11, average log likelihood -1.407959
[ Info: iteration 12, average log likelihood -1.407879
[ Info: iteration 13, average log likelihood -1.407811
[ Info: iteration 14, average log likelihood -1.407751
[ Info: iteration 15, average log likelihood -1.407697
[ Info: iteration 16, average log likelihood -1.407648
[ Info: iteration 17, average log likelihood -1.407602
[ Info: iteration 18, average log likelihood -1.407560
[ Info: iteration 19, average log likelihood -1.407520
[ Info: iteration 20, average log likelihood -1.407482
[ Info: iteration 21, average log likelihood -1.407447
[ Info: iteration 22, average log likelihood -1.407413
[ Info: iteration 23, average log likelihood -1.407381
[ Info: iteration 24, average log likelihood -1.407350
[ Info: iteration 25, average log likelihood -1.407321
[ Info: iteration 26, average log likelihood -1.407294
[ Info: iteration 27, average log likelihood -1.407267
[ Info: iteration 28, average log likelihood -1.407242
[ Info: iteration 29, average log likelihood -1.407218
[ Info: iteration 30, average log likelihood -1.407194
[ Info: iteration 31, average log likelihood -1.407172
[ Info: iteration 32, average log likelihood -1.407151
[ Info: iteration 33, average log likelihood -1.407130
[ Info: iteration 34, average log likelihood -1.407109
[ Info: iteration 35, average log likelihood -1.407090
[ Info: iteration 36, average log likelihood -1.407071
[ Info: iteration 37, average log likelihood -1.407052
[ Info: iteration 38, average log likelihood -1.407034
[ Info: iteration 39, average log likelihood -1.407017
[ Info: iteration 40, average log likelihood -1.406999
[ Info: iteration 41, average log likelihood -1.406982
[ Info: iteration 42, average log likelihood -1.406966
[ Info: iteration 43, average log likelihood -1.406950
[ Info: iteration 44, average log likelihood -1.406934
[ Info: iteration 45, average log likelihood -1.406918
[ Info: iteration 46, average log likelihood -1.406903
[ Info: iteration 47, average log likelihood -1.406888
[ Info: iteration 48, average log likelihood -1.406874
[ Info: iteration 49, average log likelihood -1.406859
[ Info: iteration 50, average log likelihood -1.406845
┌ Info: EM with 100000 data points 50 iterations avll -1.406845
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.129568    0.00334159  -0.664344    -0.682913    0.139215    0.104723     0.210165    -0.021092    0.622415   -0.267275    -0.325706    0.100735    0.603082    0.111166   -0.322483   -0.420851    -0.523933    0.508132    0.319879     0.228639    -0.470754     0.277015    0.454798    0.0202803    0.172929     0.143202
  0.60612     0.438529     0.00772276  -0.238568    0.304422    0.248262     0.0858874   -0.643559    0.183077   -0.0507381    0.216923    0.0913266   0.555547   -0.62095    -0.277984    0.311282    -0.0704209   0.183649    0.492308     0.322722     0.345647     0.508673    0.0775033  -0.152301    -0.0225292    0.519431
  0.0757132  -0.134987     0.152772    -0.0964251  -0.0888384   0.210444    -0.328734    -0.229841    0.0559116   0.204194    -0.59322    -0.285054   -0.0224896  -0.202962   -0.358784   -0.203555    -0.144552   -0.11516     0.46517      0.152572     0.229683    -0.0547875   0.240173    0.242645    -0.0521636    0.125702
 -0.469277   -0.0677125    0.62654      0.544335    0.207676   -0.00272574   0.216034     0.418554   -0.463051    0.237959    -0.315815    0.417031    0.490154   -0.269953    0.655711    0.739221    -0.235367   -0.322158    0.072818    -1.34431      0.00323683  -0.756188   -0.121104   -0.0835829    0.557463     0.624734
  0.553715   -0.0714388   -0.238536     0.418406   -0.146956    0.405302     0.00747756  -0.389654   -0.136536    0.335662     0.572216    0.895349    0.0218579   0.103167   -0.387831    0.341433     0.0959473  -0.16346    -1.19776      0.0148175    0.167999    -0.943743   -0.0663336  -0.508466     0.0931542    0.162391
  0.395291   -0.107838    -0.364787     0.0494615   0.718935    0.226098    -0.276675    -0.496823    0.0254729  -0.216615     0.0975125  -0.397312   -0.541317    0.889735   -0.690755   -0.0794757    0.449509    0.0959327  -0.212557     0.938517     0.23451      1.0838     -0.553916   -0.0538168   -0.367932    -0.192625
  0.288919    0.561849     0.473984     0.0440187   0.0364971   0.175478     0.243109    -0.358966   -0.589486    0.234628    -0.193702   -0.645431    0.0286581  -0.0118557  -0.212109    0.0435152   -0.53408     0.0955245   0.188063     0.181334     0.251236    -0.767922   -0.763923   -0.66338      0.366266    -0.438242
 -0.0721433  -0.351398     0.153614    -0.806565    0.0260554   0.22966     -0.438728    -0.212569   -0.547483   -0.120734     0.140238    0.551747   -0.251594    0.114491   -0.401999    0.492549    -0.196096    0.313494   -0.140826     0.531708     0.375863    -0.366091   -0.793643    0.651107    -0.0850774    0.238382
 -0.290555   -0.710809     0.0457711   -0.367342   -0.11773     0.0373592   -0.363207    -0.0818835  -0.117405    0.789624    -0.0281171  -0.498429    0.382762   -0.282436    0.260658   -0.523711     0.110909    0.281155   -0.00717757  -0.233888    -0.688225    -0.474345    0.381938    0.477315     0.0071987   -0.420529
  0.377093    0.975965    -0.451549     0.796289   -0.233649   -0.389884     0.601194    -0.746398    0.784334   -0.0253946    0.36806     0.21848    -1.03971     0.713359    0.490388    0.0694089   -0.0280354  -0.0861492   0.427061     0.00960685  -0.0270044    0.108285   -0.567589   -0.00304339   0.337505     0.156143
  0.361149   -0.216361    -0.290543     0.653115   -0.0713926   0.30633     -0.520952     0.439287    0.454733   -0.159064     0.0425693   0.544685   -0.246941   -0.178212   -0.167483   -0.138138     0.23268    -0.137756    0.248105    -0.16371     -0.239488     0.586023    0.366882    0.859241    -0.261101    -0.291896
 -0.729292    0.0440543   -0.246315     0.365882   -0.544511    0.0744655   -0.339693    -0.532792   -0.327818   -0.222599     0.113984    0.0726491  -0.0186083  -0.276248    0.516242   -0.232003    -0.0785767  -0.14417     0.0229163    0.277807     0.0763608    0.270502   -0.0264168   0.472841    -0.132178     0.153064
 -0.164763   -0.656776     0.305052    -0.108776    0.428607    0.381955     0.0964781    0.537156   -0.804468    0.0144875   -0.0945726  -0.0713892   1.06839    -0.558653   -0.34128     0.409667     0.300827    0.475912   -0.452173     0.0286019    0.451823     0.471456    0.6342      0.229069    -0.27239      0.0259804
 -0.172386   -0.144731     0.286347     0.404731   -0.172542   -0.477234     0.0560573    0.233349   -0.453915   -0.402366     0.938878    0.190915    0.0562076   0.380433    0.508982   -0.187929    -0.295575   -0.208938   -0.843116    -0.262256    -0.923073     0.129195   -0.412061    0.0437307    0.101085    -0.374479
 -0.252426   -0.0657361   -0.331123     0.540953   -0.435379   -0.441037     0.267215    -0.186163    0.0217262  -0.00993921  -0.243991   -0.400243   -0.166263    0.274851   -0.26666     0.00286632   0.0394045  -0.134637    0.115577    -0.280462    -0.388734    -0.295808   -0.261324    0.0336401    0.702842    -0.454879
  0.0510648  -0.078803     0.148874    -0.296877   -0.633267    0.143077     0.424059    -0.16797     0.354985   -0.00434852   0.66514     0.128382    0.0297451   0.0251229  -0.0859122   0.0562558   -0.012518    0.316885    0.131493     0.0825116   -0.363434     0.660135   -0.0199804   0.328002     0.157665     0.648141
 -0.0852426  -0.303596     1.35835      0.0674895  -0.26551    -0.280982    -0.199699    -0.0502844  -0.125735    0.105722     0.184937   -0.661821    0.242056   -0.428046   -0.61524     0.289886     0.0976629  -0.430124   -0.8081      -0.198032     0.303217    -0.277354   -0.61125    -0.271067     0.00819136   0.440276
 -0.210265   -0.178543    -0.0159267    0.130013    0.0465281   0.159895    -0.0980748    0.0366473   0.105701   -0.118958    -0.102398   -0.194566    0.154079    0.17        0.136568    0.105357     0.203986   -0.216522   -0.202229    -0.109033    -0.231959     0.36624     0.290783   -0.0643281    0.0998238    0.112822
  0.708526   -0.702089     0.284381    -0.349454    0.0406953  -0.247202     0.180129    -0.110133    0.631405   -0.554688     0.0424145  -0.158946    0.241811    0.910725   -0.554257    0.161873     0.138744    0.100616    0.010125    -0.0749354    0.527147    -0.193851   -0.0673001  -0.386243     0.0116079   -0.209287
 -0.193297    0.0127045   -0.0908064   -0.115014   -0.236061   -0.0865503   -0.0905693   -0.102468    0.100859    0.122903     0.0276344   0.110124    0.0177493   0.104559    0.0863017   0.115703    -0.0419067   0.0623063  -0.0203441    0.0546021    0.0583763   -0.186212    0.0216979  -0.0192646    0.0782312   -0.0360493
  0.577286    0.342921    -0.120494     0.0685399   0.837756    0.661519     0.908817     0.382464   -0.706783   -0.320465    -0.392371   -0.156883   -0.527428   -0.379095   -0.295533   -0.032205     0.176412   -0.257023    0.113913    -0.111363    -0.176926     0.457103   -0.277044    0.276296    -0.260898    -0.0771258
 -0.0168285  -0.15577     -0.18203      0.137902   -0.248282    0.584466    -0.28154      0.308222   -0.106431    0.387944    -0.779842   -0.315302   -0.710222    0.811438   -0.218193   -0.130315     0.291232   -0.306268   -0.193858    -0.288882    -0.115143    -0.127106   -0.599809    0.0726428   -0.216564    -0.234959
 -0.234316    0.0655655   -0.457185     0.252688   -0.130134   -0.250662     0.206202     0.688872    0.140133   -0.202405    -0.31802     0.0309407  -0.466881    0.613075    0.469221    0.399053    -0.368039   -0.0369774  -0.664905    -0.335044    -0.205742    -0.591694    0.0443319  -0.180317    -0.250769    -0.734822
  0.146944    0.305549    -0.409178     0.262872    0.149446    0.608978     0.479825     0.479643    0.125307   -0.37986      0.226546    0.0407763   0.394789    0.46023     0.0609622   0.382931     0.409213    0.207      -0.664775    -0.0613082    0.368107     0.593293   -0.0726087  -0.19073     -0.0040087   -0.0896152
 -0.011118    0.596985     0.0290978    0.499693    0.042319   -0.237107     0.20311     -0.0443455   0.462389    0.0820647    0.19322    -0.395087    0.318159   -0.42006     0.500887   -0.716602     0.132479   -0.48042     0.202113    -0.446163    -0.233333     0.132614    1.01393    -0.581029    -0.0981553   -0.227908
  0.136453    0.126527    -0.216676     0.020876   -0.0610167   0.0292199    0.139432     0.0347661   0.058397    0.0439701    0.10714     0.180976   -0.0951971   0.077698   -0.0679582   0.0222529   -0.146901    0.207215   -0.0304772   -0.0439873    0.0490315   -0.175305   -0.202701    0.0417349   -0.0629762   -0.0784391
 -0.318426   -0.437178     0.264639    -0.167056    0.140564    0.113911    -0.585526     0.0900135  -0.0409834  -0.289919    -0.475297   -0.664371   -0.193156   -0.316763    0.0334658  -0.224472     0.330665   -0.287879    0.643106     0.13929     -0.268449     0.730578    0.681658    0.405705     0.0456896    0.0534104
 -0.0647308   0.176239    -0.19297     -0.262505   -0.453246   -0.71324     -0.310714    -0.179716    0.257549    0.213876     0.216432    0.729557    0.0184464  -0.198194   -0.0358903   0.0363059   -0.421335    0.381953    0.21826     -0.081047    -0.144765    -0.695235   -0.0497849   0.383272     0.0580162   -0.155505
  0.394841    0.270619     0.344233    -0.576506    0.579356    0.650961    -0.0821009    0.558112    0.301765    0.22999     -0.0398937   0.106129    0.372876    0.129366   -0.0216884   0.00513807   0.0910628  -0.156913   -0.441487     0.0352645    0.158809     0.103649    0.161413   -0.42949      0.0120807    0.185331
  0.472594   -0.436179     0.304582    -0.0429993   0.0952711  -0.493975     0.544772     0.0861069  -0.157179    0.510953     0.265191   -0.529713   -0.975792    0.297598    0.134928   -0.111441    -0.560545    0.478843    0.613749    -0.49279      0.0614246   -0.171895   -0.161447   -0.246151    -0.135862     0.226132
 -0.687078    0.122437     0.0432515   -0.405372   -0.018662   -0.105223     0.132618    -0.315247   -0.022045    0.352939     0.0205828   0.327547    0.114615   -0.0084382   0.366298    0.439943    -0.276448    0.0467975  -0.275158     0.241721     0.345698    -0.467851   -0.256251   -0.717191     0.23101      0.588351
  0.139207    0.165038     0.289337     0.0385248   0.37114    -0.0399854    0.0510838   -0.0111025  -0.435844   -0.185193     0.341017   -0.0863242   0.0240563  -0.214533    0.151496    0.110336     0.051881   -0.239403    0.0420985    0.192767     0.145313    -0.072206   -0.120279   -0.292367    -0.0641349   -0.0897821[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406832
[ Info: iteration 2, average log likelihood -1.406818
[ Info: iteration 3, average log likelihood -1.406806
[ Info: iteration 4, average log likelihood -1.406793
[ Info: iteration 5, average log likelihood -1.406781
[ Info: iteration 6, average log likelihood -1.406769
[ Info: iteration 7, average log likelihood -1.406758
[ Info: iteration 8, average log likelihood -1.406747
[ Info: iteration 9, average log likelihood -1.406737
[ Info: iteration 10, average log likelihood -1.406727
┌ Info: EM with 100000 data points 10 iterations avll -1.406727
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
