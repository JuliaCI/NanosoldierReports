Julia Version 1.5.0-DEV.152
Commit c4a0c8379c (2020-01-26 14:50 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed CMakeWrapper ─────── v0.2.3
 Installed LegacyStrings ────── v0.4.1
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed StatsFuns ────────── v0.9.3
 Installed BinDeps ──────────── v1.0.0
 Installed DataStructures ───── v0.17.9
 Installed StatsBase ────────── v0.32.0
 Installed Missings ─────────── v0.4.3
 Installed OrderedCollections ─ v1.1.0
 Installed Arpack ───────────── v0.4.0
 Installed Parameters ───────── v0.12.0
 Installed Blosc ────────────── v0.5.1
 Installed Compat ───────────── v2.2.0
 Installed PDMats ───────────── v0.9.11
 Installed Distances ────────── v0.8.2
 Installed CMake ────────────── v1.1.2
 Installed JLD ──────────────── v0.9.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed StaticArrays ─────── v0.12.1
 Installed SortingAlgorithms ── v0.3.1
 Installed Clustering ───────── v0.13.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed HDF5 ─────────────── v0.12.5
 Installed NearestNeighbors ─── v0.4.4
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed BinaryProvider ───── v0.5.8
 Installed QuadGK ───────────── v2.3.1
 Installed FileIO ───────────── v1.2.1
 Installed URIParser ────────── v0.4.0
 Installed SpecialFunctions ─── v0.9.0
 Installed FillArrays ───────── v0.8.4
 Installed Rmath ────────────── v0.6.0
 Installed DataAPI ──────────── v1.1.0
 Installed Distributions ────── v0.22.3
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_FD1FXR/Project.toml`
 [no changes]
  Updating `/tmp/jl_FD1FXR/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_8QeC2r/Project.toml`
 [no changes]
  Updating `/tmp/jl_8QeC2r/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_dCLnN0/Project.toml`
 [no changes]
  Updating `/tmp/jl_dCLnN0/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_iECr1T/Project.toml`
 [no changes]
  Updating `/tmp/jl_iECr1T/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_5QVKZ7/Project.toml`
 [no changes]
  Updating `/tmp/jl_5QVKZ7/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_5QVKZ7/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.6647348054374412e6, [84347.62762803314, 15652.37237196686], [4392.504767753051 -3155.3058210464305 17380.846164674615; -4571.578590779655 3804.662291283857 -17197.29819758406], [[88706.31251867057 5510.158657732384 -540.9890480309198; 5510.158657732384 85569.5731719498 3695.215172498136; -540.9890480309198 3695.215172498136 77797.15778746577], [11101.896562195469 -4904.249357589007 770.3094921855572; -4904.249357589007 13555.32417190699 -3811.432298638379; 770.3094921855572 -3811.432298638379 22437.413632396143]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.439369e+03
      1       1.060570e+03      -3.787983e+02 |        8
      2       9.541051e+02      -1.064652e+02 |        4
      3       9.288529e+02      -2.525211e+01 |        2
      4       9.057661e+02      -2.308683e+01 |        0
      5       9.057661e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 905.7661023264673)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.076842
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.741659
[ Info: iteration 2, lowerbound -3.585538
[ Info: iteration 3, lowerbound -3.431046
[ Info: iteration 4, lowerbound -3.265392
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.099739
[ Info: iteration 6, lowerbound -2.958049
[ Info: iteration 7, lowerbound -2.868441
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.815039
[ Info: iteration 9, lowerbound -2.791795
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.777217
[ Info: iteration 11, lowerbound -2.760206
[ Info: iteration 12, lowerbound -2.746634
[ Info: iteration 13, lowerbound -2.728036
[ Info: iteration 14, lowerbound -2.703404
[ Info: iteration 15, lowerbound -2.672202
[ Info: iteration 16, lowerbound -2.634707
[ Info: iteration 17, lowerbound -2.592226
[ Info: iteration 18, lowerbound -2.547061
[ Info: iteration 19, lowerbound -2.502067
[ Info: iteration 20, lowerbound -2.459761
[ Info: iteration 21, lowerbound -2.421410
[ Info: iteration 22, lowerbound -2.386846
[ Info: iteration 23, lowerbound -2.355575
[ Info: iteration 24, lowerbound -2.328989
[ Info: iteration 25, lowerbound -2.311622
[ Info: iteration 26, lowerbound -2.307745
[ Info: dropping number of Gaussions to 2
[ Info: iteration 27, lowerbound -2.302918
[ Info: iteration 28, lowerbound -2.299259
[ Info: iteration 29, lowerbound -2.299256
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299254
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Jan 28 09:31:41 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Jan 28 09:31:50 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Tue Jan 28 09:31:52 2020: EM with 272 data points 0 iterations avll -2.076842
5.8 data points per parameter
, Tue Jan 28 09:31:55 2020: GMM converted to Variational GMM
, Tue Jan 28 09:32:04 2020: iteration 1, lowerbound -3.741659
, Tue Jan 28 09:32:04 2020: iteration 2, lowerbound -3.585538
, Tue Jan 28 09:32:04 2020: iteration 3, lowerbound -3.431046
, Tue Jan 28 09:32:04 2020: iteration 4, lowerbound -3.265392
, Tue Jan 28 09:32:04 2020: dropping number of Gaussions to 7
, Tue Jan 28 09:32:04 2020: iteration 5, lowerbound -3.099739
, Tue Jan 28 09:32:04 2020: iteration 6, lowerbound -2.958049
, Tue Jan 28 09:32:04 2020: iteration 7, lowerbound -2.868441
, Tue Jan 28 09:32:05 2020: dropping number of Gaussions to 5
, Tue Jan 28 09:32:05 2020: iteration 8, lowerbound -2.815039
, Tue Jan 28 09:32:05 2020: iteration 9, lowerbound -2.791795
, Tue Jan 28 09:32:05 2020: dropping number of Gaussions to 3
, Tue Jan 28 09:32:05 2020: iteration 10, lowerbound -2.777217
, Tue Jan 28 09:32:05 2020: iteration 11, lowerbound -2.760206
, Tue Jan 28 09:32:05 2020: iteration 12, lowerbound -2.746634
, Tue Jan 28 09:32:05 2020: iteration 13, lowerbound -2.728036
, Tue Jan 28 09:32:05 2020: iteration 14, lowerbound -2.703404
, Tue Jan 28 09:32:05 2020: iteration 15, lowerbound -2.672202
, Tue Jan 28 09:32:05 2020: iteration 16, lowerbound -2.634707
, Tue Jan 28 09:32:05 2020: iteration 17, lowerbound -2.592226
, Tue Jan 28 09:32:05 2020: iteration 18, lowerbound -2.547061
, Tue Jan 28 09:32:05 2020: iteration 19, lowerbound -2.502067
, Tue Jan 28 09:32:05 2020: iteration 20, lowerbound -2.459761
, Tue Jan 28 09:32:05 2020: iteration 21, lowerbound -2.421410
, Tue Jan 28 09:32:05 2020: iteration 22, lowerbound -2.386846
, Tue Jan 28 09:32:05 2020: iteration 23, lowerbound -2.355575
, Tue Jan 28 09:32:05 2020: iteration 24, lowerbound -2.328989
, Tue Jan 28 09:32:05 2020: iteration 25, lowerbound -2.311622
, Tue Jan 28 09:32:05 2020: iteration 26, lowerbound -2.307745
, Tue Jan 28 09:32:05 2020: dropping number of Gaussions to 2
, Tue Jan 28 09:32:05 2020: iteration 27, lowerbound -2.302918
, Tue Jan 28 09:32:05 2020: iteration 28, lowerbound -2.299259
, Tue Jan 28 09:32:05 2020: iteration 29, lowerbound -2.299256
, Tue Jan 28 09:32:05 2020: iteration 30, lowerbound -2.299254
, Tue Jan 28 09:32:05 2020: iteration 31, lowerbound -2.299254
, Tue Jan 28 09:32:05 2020: iteration 32, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 33, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 34, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 35, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 36, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 37, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 38, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 39, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 40, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 41, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 42, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 43, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 44, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 45, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 46, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 47, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 48, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 49, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: iteration 50, lowerbound -2.299253
, Tue Jan 28 09:32:05 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777384462, 178.04509222615533]
β = [95.95490777384462, 178.04509222615533]
m = [2.0002292577741825 53.85198717245512; 4.250300733268764 79.28686694434494]
ν = [97.95490777384462, 180.04509222615533]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119681556 -0.008953123827369352; 0.0 0.012748664777415408], [0.1840415554746956 -0.007644049042342369; 0.0 0.008581705166312032]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.9762272803726244
avll from llpg:  -0.976227280372618
avll direct:     -0.976227280372618
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0073049811276162
avll from llpg:  -1.0073049811276162
avll direct:     -1.0073049811276162
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0831519    0.00662233  -0.00106528   -0.286593     0.100998      0.117949    -0.0377129     0.0882898   -0.17137      0.0431797   -0.129606     -0.0422742    0.0319485   -0.0796971    0.10847      -0.0213832    0.0345149    0.0523711    0.0970702    0.0141641    0.00967592  -0.100681     0.0770822    0.0591291   -0.03803      0.106174
  0.110856     0.0252644   -0.000790281  -0.0953129   -0.0661074    -0.170576     0.0111025    -0.113557    -0.13462     -0.128366    -0.0281884    -0.0371526   -0.0543422    0.0293639   -0.0329945     0.0673717   -0.059529     0.125462    -0.106971     0.0718955   -0.14439      0.0405425    0.0777909   -0.0575602   -0.226803     0.107923
 -0.119502     0.124993    -0.111833      0.0833258   -0.233951      0.119857     0.00568086    0.12184      0.045247    -0.0497157   -0.0248794     0.01216      0.0814589   -0.170719    -0.0319995    -0.0502115    0.104625     0.0525917    0.115386    -0.0176473   -0.165272    -0.0639805   -0.0584033   -0.180952     0.119093     0.0170378
 -0.129069    -0.260275    -0.189904      0.109349     0.166886      0.0373107   -0.0901362    -0.10249      0.0974779    0.0237826   -0.0515752     0.0740848   -0.0492175    0.12563      0.00681704    0.0243362   -0.113981    -0.0222735   -0.0226276   -0.00842936   0.0094295   -0.11473      0.0141117    0.246312    -0.110118     0.0453383
 -0.0116447   -0.0344108    0.0644093     0.11767     -0.0185951     0.00519664  -0.0527099    -0.063527    -0.0906015    0.0184699    0.000917253   0.0917795    0.0728581   -0.0204892    0.0874122    -0.0172833   -0.126011    -0.0540707   -0.0157599   -0.123706    -0.00317745   0.0388276   -0.0906108    0.177225    -0.0331233    0.00688383
 -0.046139     0.109248     0.0821053    -0.0445925    0.0203637     0.010714     0.248213      0.0433365    0.0167572    0.0127273   -0.0742634     0.134874     0.0905448    0.0526235   -0.0790519     0.014298     0.0773093    0.102415    -0.136345    -0.113359     0.0948631    0.0446281    0.20777     -0.0255312    0.0355132   -0.11805
  0.160828    -0.0186884    0.177436     -0.223109    -0.153632     -0.105825    -0.138229     -0.117657    -0.00984526   0.253589    -0.0154754     0.018825    -0.0987972    0.094326    -0.000553378   0.114047    -0.0979357    0.0014063   -0.0728271   -0.0112804   -0.139196    -0.0735821    0.0697421   -0.0790561    0.182465    -0.0532208
 -0.148844     0.120507    -0.0335951    -0.191344    -0.15385       0.124707     0.0659133     0.0661016    0.0525572    0.0168985   -0.0840739     0.0730401    0.0387164   -0.108056     0.0921319    -0.129435    -0.0547662   -0.0295526    0.0990953    0.0609056   -0.0915994   -0.0706168    0.0746733    0.166411    -0.282975    -0.0616226
  0.0685191   -0.138082     0.168018     -0.0809188   -0.116478      0.133056     0.0653873    -0.147655    -0.0691632    0.0589575   -0.175144      0.0162478    0.00479052  -0.0307816   -0.0580287     0.0636986   -0.0516544    0.222753    -0.0579214    0.0928881    0.031107    -0.192274    -0.115105    -0.0359446   -0.0661249   -0.10305
  0.153059    -0.0635471    0.0304653    -0.126635    -0.131433     -0.0447031   -0.0446975    -0.0283913   -0.238555     0.0134788    0.174606      0.011503    -0.0161267   -0.0640989   -0.0007408    -0.116549    -0.0933533    0.00210149   0.0689149    0.0279668    0.0281075    0.143344     0.0083002    0.0980792   -0.0162027   -0.000991004
 -0.134107    -0.140166    -0.08975       0.0309827   -0.0117298    -0.0738188    0.0623941     0.182831    -0.0176457   -0.0116602   -0.114779      0.0745576    0.0610628    0.0183545   -0.0859847    -0.0448651    0.0476249   -0.00221529   0.0380139    0.00923945   0.238238     0.00980744  -0.0352414    0.0954605    0.140849     0.016801
 -0.0419      -0.022456     0.0502059     0.0321265    0.0111944     0.00964997  -0.0450097    -0.169563     0.0233975   -0.0684095    0.145068      0.0925882    0.215766     0.0811746   -0.0924097    -0.00291044  -0.110537    -0.151511     0.0154502   -0.0614339    0.0818195   -0.111774     0.0552531   -0.00473925  -0.180612    -0.0387373
  0.185191    -0.0933747   -0.11688      -0.162292     0.0163301    -0.00545711  -0.0309429     0.149695     0.0806713   -0.142738    -0.0995511    -0.0115467    0.0896722   -0.161993     0.0600154     0.00699639  -0.0512528    0.146669    -0.149967     0.119448     0.0927714   -0.212303    -0.074421     0.066119    -0.0190308   -0.0990077
  0.0838731    0.0108495   -0.0704195    -0.128716     0.142729     -0.0714434    0.0532569     0.207715     0.012688    -0.0410629    0.0155822     0.111593    -0.0527954    0.106344     0.0416024    -0.00956206   0.078723    -0.0515986   -0.083859     0.0784962   -0.0836017    0.0174363   -0.0940783    0.021763    -0.0172565   -0.0364061
 -0.0867372    0.0111135    0.0247352     0.0690873    0.0140703     0.110838     0.014851     -0.0112305   -0.0886453    0.0953687   -0.0276705    -0.0140877    0.109124     0.137503     0.118035     -0.0595406   -0.0141192   -0.0309116    0.24523      0.116045     0.10872      0.0610548   -0.155216    -0.0662864    0.0327092    0.0646294
 -0.106163     0.147241    -0.101166     -0.0785142   -0.0168406    -0.0397519   -0.000677054   0.190908    -0.152606     0.013062    -0.0680553    -0.0391625    0.114119     0.129983    -0.0606434     0.154518    -0.0876299   -0.142166     0.0938905   -0.0123569   -0.0512582   -0.04439      0.174857     0.0896519    0.0959882   -0.0705144
  0.0600913   -0.0510719    0.056243     -0.0489106    0.254576      0.0744998   -0.150033      0.106274    -0.0515742    0.00435678   0.045373      0.0346642   -0.0183359   -0.0211186    0.160616      0.101511     0.0812166    0.0785209    0.133119     0.113118     0.0426711    0.11592     -0.0989711    0.0938925    0.00415668   0.0182988
  0.00898002  -0.250219     0.104824      0.00661331   0.0746336     0.0159576    0.107925      0.116662    -0.182652    -0.016686    -0.0668109     0.0095475   -0.0485432    0.144887     0.0892905     0.039904     0.0432507   -0.0643488    0.103389     0.0456832   -0.164612     0.00125159   0.0750801   -0.0233912   -0.0665868    0.0326083
 -0.0242337   -0.0327551   -0.127563     -0.227696     0.0120562    -0.175545    -0.0490772     0.0490349   -0.079175    -0.0806974   -0.149834     -0.08392     -0.0514966   -0.165494     0.00144594    0.100498     0.122903     0.0119458    0.086245     0.0507415    0.0841636    0.154315    -0.00237346  -0.0770065    0.0787346    0.151373
 -0.157291    -0.07669      0.0999877     0.0782977    0.103894      0.159233    -0.0423689    -0.0671803   -0.139092    -0.0534844   -0.0412127    -0.133946     0.0865995    0.0269651    0.0887865     0.0316994   -0.0978       0.196596    -0.0020985    0.0506091   -0.0381929    0.112579    -0.0679341   -0.124041     0.119609    -0.0197605
 -0.104915     0.098855     0.0699684    -0.0374244   -0.202404      0.068453     0.117348      0.127757    -0.0380233   -0.12733      0.0851092    -0.0332181    0.00185156  -0.0433612    0.108159     -0.118607    -0.00830199   0.0424097   -0.0264472   -0.0333903   -0.0803473    0.12189      0.0781449   -0.103073    -0.094846     0.0794344
 -0.0429206   -0.0942463   -0.0835714     0.0901596   -0.0127302     0.0479293   -0.085013      0.0472224   -0.079134     0.0609632   -0.00800741   -0.0957647    0.105527     0.0615802   -0.143683      0.021642     0.0200886    0.191349     0.207988    -0.0167094    0.0223173    0.169715    -0.12861     -0.169326     0.118365     0.0777505
 -0.0906098    0.0947614    0.176087     -0.00030697   0.0829574    -0.010958    -0.359961     -0.00541131  -0.0465514    0.0134404   -0.118412     -0.0728465    0.122477     0.148823    -0.125121     -0.0280943   -0.0186316    0.111295    -0.00928229   0.062085    -0.0216306   -0.0939531   -0.0379428    0.0668288    0.111835     0.0666971
  0.166899    -0.158346    -0.0420226     0.184408     0.186308      0.0812606   -0.0572411    -0.107679     0.0617832   -0.0567676   -0.0796381     0.0456478   -0.0970891   -0.00166359  -0.160514     -0.346672    -0.0132721    0.125346    -0.0205588   -0.129025     0.00328487   0.116666    -0.164887    -0.0343052    0.224205    -0.211888
  0.114505    -0.0238294   -0.0126109     0.0912708    0.000823041   0.0115087    0.0038686     0.17149     -0.00994129   0.0210945   -0.0465268     0.0712783    0.0258416   -0.0821911    0.147857     -0.153173    -0.131406    -0.135066    -0.0818996    0.0836286   -0.0176558   -0.103143     0.0253259   -0.011069     0.0818002    0.0978979
  0.0120044   -0.150214    -0.163496     -0.0848712   -0.127775     -0.108488    -0.0193446    -0.187074    -0.156992    -0.241259     0.0542428     0.00292382  -0.0651727    0.103927    -0.0220171     0.0285283    0.0040958   -0.095087    -0.0123049   -0.0938216   -0.168876     0.0530391   -0.00285329   0.107171    -0.200855    -0.0893909
  0.149632     0.00761298   0.00458207   -0.0836857    0.0712333     0.0543904   -0.0547703     0.124861     0.125346     0.100076     0.0657974    -0.0324912   -0.0247592    0.0151979    0.0337551    -0.0932553    0.0355549   -0.00623235  -0.213729    -0.0110049   -0.0942667   -0.123619     0.0123613    0.0122322   -0.227335     0.0780416
 -0.0320659    0.0975234    0.0126223    -0.182998     0.0641804    -0.0384218   -0.123546     -0.0659864    0.0631933    0.0032772    0.0707314     0.134723    -0.0556599    0.11343     -0.105559     -0.0369162   -0.122493    -0.01427     -0.18657     -0.0171615    0.0404192   -0.119732    -0.122521     0.0414371   -0.0228991   -0.0953161
  0.11157      0.047639    -0.181479     -0.00415175   0.0456966     0.177714     0.0835287    -0.106744     0.0134559    0.0419188   -0.113436      0.0217882   -0.0350251   -0.116708     0.245174     -0.0289296   -0.125853    -0.0394146   -0.0193039    0.165025     0.00792094  -0.0715621   -0.0336827    0.00529602  -0.0479081   -0.194205
  0.0868951    0.024451    -0.0804578    -0.14362      0.0934947     0.0302927    0.134843     -0.0911788   -0.0372067    0.0581619    0.114095     -0.0788904   -0.0708305    0.145973    -0.0294293    -0.102334     0.126839    -0.118307     0.0563443   -0.131395     0.0744973   -0.0773538   -0.0399554    0.0845748   -0.123067     0.100262
 -0.0669428   -0.110806    -0.0237245    -0.0375197    0.0285812     0.00566082  -0.224576     -0.0195321    0.00139997  -0.00587244  -0.0425921     0.098388    -0.0528681    0.0128694   -0.0162347    -0.0232375   -0.0619053   -0.00953207  -0.0474287   -0.00374493  -0.0316409    0.110637    -0.0747494    0.00249257   0.180909     0.0546449
 -0.0342878    0.0124       0.237045     -0.0303553   -0.0438229     0.00102984  -0.201025      0.207203     0.0367001    0.019741    -0.0655555    -0.0975614    0.0900841   -0.142217    -0.0295835    -0.106715     0.125176    -0.165639     0.114952     0.0314395   -0.0450019    0.329946    -0.300716    -0.00601579   0.0182155    0.0640445kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.44850774138008
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.448567
[ Info: iteration 2, average log likelihood -1.448493
[ Info: iteration 3, average log likelihood -1.447881
[ Info: iteration 4, average log likelihood -1.442155
[ Info: iteration 5, average log likelihood -1.427592
[ Info: iteration 6, average log likelihood -1.421327
[ Info: iteration 7, average log likelihood -1.420321
[ Info: iteration 8, average log likelihood -1.419806
[ Info: iteration 9, average log likelihood -1.419448
[ Info: iteration 10, average log likelihood -1.419191
[ Info: iteration 11, average log likelihood -1.418988
[ Info: iteration 12, average log likelihood -1.418808
[ Info: iteration 13, average log likelihood -1.418631
[ Info: iteration 14, average log likelihood -1.418416
[ Info: iteration 15, average log likelihood -1.418103
[ Info: iteration 16, average log likelihood -1.417677
[ Info: iteration 17, average log likelihood -1.417282
[ Info: iteration 18, average log likelihood -1.416991
[ Info: iteration 19, average log likelihood -1.416769
[ Info: iteration 20, average log likelihood -1.416617
[ Info: iteration 21, average log likelihood -1.416516
[ Info: iteration 22, average log likelihood -1.416447
[ Info: iteration 23, average log likelihood -1.416400
[ Info: iteration 24, average log likelihood -1.416367
[ Info: iteration 25, average log likelihood -1.416345
[ Info: iteration 26, average log likelihood -1.416329
[ Info: iteration 27, average log likelihood -1.416317
[ Info: iteration 28, average log likelihood -1.416309
[ Info: iteration 29, average log likelihood -1.416303
[ Info: iteration 30, average log likelihood -1.416299
[ Info: iteration 31, average log likelihood -1.416296
[ Info: iteration 32, average log likelihood -1.416293
[ Info: iteration 33, average log likelihood -1.416292
[ Info: iteration 34, average log likelihood -1.416291
[ Info: iteration 35, average log likelihood -1.416290
[ Info: iteration 36, average log likelihood -1.416289
[ Info: iteration 37, average log likelihood -1.416288
[ Info: iteration 38, average log likelihood -1.416288
[ Info: iteration 39, average log likelihood -1.416288
[ Info: iteration 40, average log likelihood -1.416287
[ Info: iteration 41, average log likelihood -1.416287
[ Info: iteration 42, average log likelihood -1.416287
[ Info: iteration 43, average log likelihood -1.416287
[ Info: iteration 44, average log likelihood -1.416286
[ Info: iteration 45, average log likelihood -1.416286
[ Info: iteration 46, average log likelihood -1.416286
[ Info: iteration 47, average log likelihood -1.416285
[ Info: iteration 48, average log likelihood -1.416285
[ Info: iteration 49, average log likelihood -1.416285
[ Info: iteration 50, average log likelihood -1.416284
┌ Info: EM with 100000 data points 50 iterations avll -1.416284
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4485671842804095
│     -1.4484926139482293
│      ⋮
└     -1.4162842788257648
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416403
[ Info: iteration 2, average log likelihood -1.416292
[ Info: iteration 3, average log likelihood -1.415863
[ Info: iteration 4, average log likelihood -1.411412
[ Info: iteration 5, average log likelihood -1.395003
[ Info: iteration 6, average log likelihood -1.380918
[ Info: iteration 7, average log likelihood -1.375204
[ Info: iteration 8, average log likelihood -1.372270
[ Info: iteration 9, average log likelihood -1.370865
[ Info: iteration 10, average log likelihood -1.370161
[ Info: iteration 11, average log likelihood -1.369764
[ Info: iteration 12, average log likelihood -1.369508
[ Info: iteration 13, average log likelihood -1.369317
[ Info: iteration 14, average log likelihood -1.369158
[ Info: iteration 15, average log likelihood -1.369016
[ Info: iteration 16, average log likelihood -1.368886
[ Info: iteration 17, average log likelihood -1.368764
[ Info: iteration 18, average log likelihood -1.368652
[ Info: iteration 19, average log likelihood -1.368550
[ Info: iteration 20, average log likelihood -1.368459
[ Info: iteration 21, average log likelihood -1.368376
[ Info: iteration 22, average log likelihood -1.368304
[ Info: iteration 23, average log likelihood -1.368242
[ Info: iteration 24, average log likelihood -1.368189
[ Info: iteration 25, average log likelihood -1.368145
[ Info: iteration 26, average log likelihood -1.368109
[ Info: iteration 27, average log likelihood -1.368078
[ Info: iteration 28, average log likelihood -1.368051
[ Info: iteration 29, average log likelihood -1.368029
[ Info: iteration 30, average log likelihood -1.368010
[ Info: iteration 31, average log likelihood -1.367994
[ Info: iteration 32, average log likelihood -1.367980
[ Info: iteration 33, average log likelihood -1.367968
[ Info: iteration 34, average log likelihood -1.367957
[ Info: iteration 35, average log likelihood -1.367948
[ Info: iteration 36, average log likelihood -1.367940
[ Info: iteration 37, average log likelihood -1.367933
[ Info: iteration 38, average log likelihood -1.367926
[ Info: iteration 39, average log likelihood -1.367920
[ Info: iteration 40, average log likelihood -1.367915
[ Info: iteration 41, average log likelihood -1.367910
[ Info: iteration 42, average log likelihood -1.367906
[ Info: iteration 43, average log likelihood -1.367902
[ Info: iteration 44, average log likelihood -1.367899
[ Info: iteration 45, average log likelihood -1.367896
[ Info: iteration 46, average log likelihood -1.367894
[ Info: iteration 47, average log likelihood -1.367891
[ Info: iteration 48, average log likelihood -1.367890
[ Info: iteration 49, average log likelihood -1.367888
[ Info: iteration 50, average log likelihood -1.367886
┌ Info: EM with 100000 data points 50 iterations avll -1.367886
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4164029861701377
│     -1.4162917393654273
│      ⋮
└     -1.3678863458918582
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.368097
[ Info: iteration 2, average log likelihood -1.367919
[ Info: iteration 3, average log likelihood -1.367633
[ Info: iteration 4, average log likelihood -1.364825
[ Info: iteration 5, average log likelihood -1.352014
[ Info: iteration 6, average log likelihood -1.337465
[ Info: iteration 7, average log likelihood -1.330114
[ Info: iteration 8, average log likelihood -1.325663
[ Info: iteration 9, average log likelihood -1.322173
[ Info: iteration 10, average log likelihood -1.319648
[ Info: iteration 11, average log likelihood -1.317910
[ Info: iteration 12, average log likelihood -1.316685
[ Info: iteration 13, average log likelihood -1.315768
[ Info: iteration 14, average log likelihood -1.314937
[ Info: iteration 15, average log likelihood -1.314045
[ Info: iteration 16, average log likelihood -1.313020
[ Info: iteration 17, average log likelihood -1.311994
[ Info: iteration 18, average log likelihood -1.311100
[ Info: iteration 19, average log likelihood -1.310272
[ Info: iteration 20, average log likelihood -1.309521
[ Info: iteration 21, average log likelihood -1.308919
[ Info: iteration 22, average log likelihood -1.308452
[ Info: iteration 23, average log likelihood -1.308105
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.307885
[ Info: iteration 25, average log likelihood -1.317377
[ Info: iteration 26, average log likelihood -1.313015
[ Info: iteration 27, average log likelihood -1.311092
[ Info: iteration 28, average log likelihood -1.310249
[ Info: iteration 29, average log likelihood -1.309693
[ Info: iteration 30, average log likelihood -1.309223
[ Info: iteration 31, average log likelihood -1.308898
[ Info: iteration 32, average log likelihood -1.308732
[ Info: iteration 33, average log likelihood -1.308658
[ Info: iteration 34, average log likelihood -1.308621
[ Info: iteration 35, average log likelihood -1.308591
[ Info: iteration 36, average log likelihood -1.308557
[ Info: iteration 37, average log likelihood -1.308508
[ Info: iteration 38, average log likelihood -1.308434
[ Info: iteration 39, average log likelihood -1.308320
[ Info: iteration 40, average log likelihood -1.308157
[ Info: iteration 41, average log likelihood -1.307953
[ Info: iteration 42, average log likelihood -1.307741
[ Info: iteration 43, average log likelihood -1.307557
[ Info: iteration 44, average log likelihood -1.307421
[ Info: iteration 45, average log likelihood -1.307325
[ Info: iteration 46, average log likelihood -1.307252
[ Info: iteration 47, average log likelihood -1.307191
[ Info: iteration 48, average log likelihood -1.307133
[ Info: iteration 49, average log likelihood -1.307073
[ Info: iteration 50, average log likelihood -1.307014
┌ Info: EM with 100000 data points 50 iterations avll -1.307014
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3680969001003205
│     -1.3679192143479786
│      ⋮
└     -1.307013799900073
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.307203
[ Info: iteration 2, average log likelihood -1.306895
[ Info: iteration 3, average log likelihood -1.305701
[ Info: iteration 4, average log likelihood -1.290549
[ Info: iteration 5, average log likelihood -1.243259
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.211332
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.220624
[ Info: iteration 8, average log likelihood -1.215782
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.197118
[ Info: iteration 10, average log likelihood -1.224876
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.203235
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.206638
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.217248
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.209787
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.219211
[ Info: iteration 16, average log likelihood -1.220993
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.200598
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.212867
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.222519
[ Info: iteration 20, average log likelihood -1.213349
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.196102
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.224398
[ Info: iteration 23, average log likelihood -1.216060
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.198293
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.212738
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.219530
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.212014
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.208261
[ Info: iteration 29, average log likelihood -1.220688
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.208861
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.217455
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.210868
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.209936
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.206106
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.213786
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.210185
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.222399
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.213443
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.207220
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.219026
[ Info: iteration 41, average log likelihood -1.213507
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.195818
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.222562
[ Info: iteration 44, average log likelihood -1.227024
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.204034
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.203357
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.215699
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.219106
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.212009
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.208443
┌ Info: EM with 100000 data points 50 iterations avll -1.208443
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.307203231706055
│     -1.3068953098442866
│      ⋮
└     -1.2084430099557075
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.207985
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     17
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.193475
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│     17
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.190876
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     13
│     14
│     17
│     18
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.168659
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.129339
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│     13
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.088940
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.087003
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.120681
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     13
│     14
│     17
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.093974
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│     13
│     14
│     17
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.097444
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     13
│     14
│     17
│     18
│     19
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.099330
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     13
│     14
│     17
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.097558
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.086696
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.090903
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     17
│     18
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.095149
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      7
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.100716
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.100133
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.076306
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     13
│     14
│     17
│     18
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.100474
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│     17
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.111142
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.088738
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│     13
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.082766
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     14
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.110280
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     13
│     14
│     17
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.100277
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.098771
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      7
│     13
│     14
│     17
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.096159
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.081320
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.095788
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│     13
│     14
│     17
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.110931
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│     18
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.085288
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.081128
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     14
│     17
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.108937
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.088539
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.086374
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     13
│     14
│     17
│     18
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.094309
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.083487
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.082789
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     13
│     14
│     17
│     18
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.084503
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.074981
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.079294
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     14
│     17
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.096925
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.068667
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.075701
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     13
│     14
│     17
│     18
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.094497
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.081316
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.069356
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     13
│     14
│     17
│     18
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.090818
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.078789
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.082600
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     13
│     14
│     17
│     18
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.084483
┌ Info: EM with 100000 data points 50 iterations avll -1.084483
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2079845204332413
│     -1.1934749575115573
│      ⋮
└     -1.0844826525242075
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.44850774138008
│     -1.4485671842804095
│     -1.4484926139482293
│     -1.447881291813335
│      ⋮
│     -1.078788725950714
│     -1.0826004904134934
└     -1.0844826525242075
32×26 Array{Float64,2}:
 -0.0864439   -0.209921     0.0424189   -0.0189363    -0.000666313   0.119947     0.091144    -0.0405451   -0.114725    -0.00017609   0.12285     -0.0365524    0.111319     0.160164     0.0388308   -0.0704303    -0.035172    -0.0433709    0.27737      0.191229    -0.217799     -0.0464449    -0.595667    -0.00650318  -0.143704      0.163052
 -0.0670454    0.213089     0.00547363   0.121227      0.0316455     0.111532    -0.0433013    0.0337185   -0.072434     0.237627    -0.144526     0.00772725   0.109909     0.0941989    0.142056    -0.0440695     0.0603432   -0.0266494    0.211524     0.0301663    0.171297      0.186246      0.194109    -0.110865     0.206387     -0.025209
 -0.154242    -0.0809833    0.118956     0.0912459     0.109955      0.159547    -0.0439935   -0.063982    -0.136294    -0.0235851   -0.0835831   -0.141201     0.0875079    0.00156499   0.0794939    0.0295059    -0.110558     0.203563    -0.00399443   0.0728868   -0.0363315     0.117991     -0.0849525   -0.118624     0.0815016    -0.0447475
  0.0682574    0.00695631  -0.00863203  -0.299513      0.0961315     0.115125    -0.0385467    0.109631    -0.157614     0.0173544   -0.113457    -0.0394254    0.0113628   -0.0670879    0.114577    -0.0195561     0.0334237    0.0529922    0.0928886    0.0486604   -0.00657892   -0.105106      0.0493442    0.0598268   -0.0332711     0.109677
  0.0988765    0.0279412   -0.00196605  -0.0929921    -0.070716     -0.141747    -0.0227571   -0.124109    -0.139752    -0.125411    -0.0291436   -0.0280802   -0.045706     0.0497191   -0.0160055    0.0163682    -0.0495969    0.0956916   -0.109448     0.075186    -0.150258      0.0881685     0.0900565   -0.0499064   -0.228551      0.1063
 -0.0164919   -0.116649     0.085486     0.168494     -0.0178266    -0.0113463   -0.104425    -0.0252439   -0.0706005    0.0264957    0.0497962    0.0893372    0.113642    -0.0296112    0.0879886   -0.0190705    -0.197549    -0.0581458   -0.00985343  -0.206969     0.0178688     0.00872502   -0.111545     0.197238    -0.0183542     0.0215162
 -0.138031    -0.280212    -0.189013     0.107241      0.156506      0.0374567   -0.0906365   -0.107571     0.0715298    0.0259575   -0.0177105    0.0833423   -0.0443779    0.11914     -0.0248394    0.0451052    -0.127876    -0.012498    -0.00426392  -0.0374386    0.00463394   -0.114461      0.00548667   0.246993    -0.11          0.0595233
 -0.056513    -0.0585186   -0.113011    -0.230586      0.0111703    -0.169522    -0.0465331    0.0806043   -0.0749781   -0.0838591   -0.142429    -0.075251    -0.0352791   -0.14497      0.0157296    0.0892544     0.123987    -0.00672185   0.0986539    0.0565196    0.082421      0.228208      0.0077722   -0.0685309    0.0785828     0.154527
 -0.0381266   -0.090876    -0.0635451    0.0803519    -0.0124934     0.0817144   -0.10276      0.0384538   -0.0883463    0.0427048    0.00376241  -0.101534     0.104268     0.0549792   -0.143599     0.0161142     0.0209909    0.206377     0.210057    -0.00342544   0.0311045     0.169466     -0.10788     -0.178977     0.126683      0.0706939
  0.157246    -0.0325637    0.0266006   -0.125252     -0.130404     -0.0362631   -0.010597    -0.0238301   -0.241696     0.0155217    0.176694     0.0101278   -0.0179563   -0.0960818   -0.00542746  -0.116842     -0.0437637   -0.00359434   0.0745098    0.0441666    0.0294408     0.143442     -0.00731019   0.10001     -0.0111591    -0.000101119
 -0.0280067    0.0585611    0.151803    -0.0938844     0.00830667   -0.0200185   -0.163247     0.0562201    0.0506636    0.00597939  -0.00921601   0.0152356    0.0148306    0.00255491  -0.0638843   -0.0663889     0.00722937  -0.0926237   -0.0530416    0.00887809  -0.00785031    0.119283     -0.212607     0.0288463   -0.00629219   -0.0360831
 -0.124268     0.13023     -0.0900581    0.0831755    -0.219828      0.128214     0.00490754   0.104357     0.0922638   -0.0037134   -0.0254906    0.0107939    0.0760049   -0.18226     -0.024802    -0.0454405     0.0721609    0.0655142    0.160523    -0.0203693   -0.172646     -0.0640226    -0.0665876   -0.175181     0.118054      0.0293382
 -0.047616     0.0178649   -0.0191541   -0.223847     -0.0647477     0.00111478   0.251963     0.123517    -0.54304     -0.00287931  -0.0740331    0.136831     0.173061    -0.0928264   -0.0759156    0.000624541   0.0774506    0.103164    -0.110935    -0.0681125   -0.243875      0.083285      0.315118     0.0326544    0.0156245    -0.0145915
 -0.0487553    0.248976     0.29911      0.170472      0.0863977     0.0407703    0.246561    -0.0639289    0.498046     0.0237335   -0.0701286    0.13647      0.0150488    0.143739    -0.0783558    0.0307168     0.0774492    0.108147    -0.249942    -0.119074     0.342948      0.000631272   0.10473     -0.112142     0.0584928    -0.192795
  0.151822     0.00139285   0.009009    -0.066029      0.07219       0.0543418   -0.0601955    0.0914856    0.130229     0.0923556    0.0675435   -0.037185    -0.0342258    0.0146883    0.0379917   -0.0842828     0.0330604   -0.0329052   -0.194375    -0.0105495   -0.0293346    -0.118349      0.0123242    0.010887    -0.179427      0.0852447
  0.122306    -0.0345139   -0.0200608    0.0912204     0.0166068     0.00762063  -0.0094816    0.14829     -0.00957636   0.00479984  -0.0359702    0.0728205    0.0216908   -0.0877283    0.148843    -0.146019     -0.128081    -0.132197    -0.0844889    0.0861368   -0.0133718    -0.105942      0.0279403   -0.0557047    0.120689      0.101779
 -0.162825    -0.0221521   -0.0614764    0.0326261    -0.132459     -0.106097    -0.539757    -0.151623     0.0223814   -0.0925623    0.146529     0.100273    -0.0465209    0.0764986   -0.0837173    0.00215691   -0.168761    -0.102038     0.0235312   -0.0614817   -0.272925     -0.110445      0.174337     0.00324684  -0.111904     -0.22103
  0.0542911   -0.0279036    0.0264412    0.0290923     0.134651      0.0568626    0.542869    -0.207051     0.0318467   -0.0378128    0.146141     0.101285     0.502743     0.077551    -0.0922731   -0.0193043    -0.115714    -0.186106     0.0210969   -0.0616266    0.329445     -0.110582     -0.0444884   -0.0108206   -0.273392      0.11934
  0.189203    -0.159525    -0.039328     0.194123      0.186144      0.0754396   -0.0571349   -0.102853     0.0725977   -0.0572852   -0.0841123    0.0400242   -0.110311     0.00369887  -0.162135    -0.346149     -0.00342059   0.130854    -0.00851418  -0.124671     0.0112018     0.112699     -0.175207    -0.029438     0.243218     -0.217248
  0.0895635   -0.117408     0.0174973   -0.123212     -0.0734548     0.0682931    0.0239562   -0.0105461   -0.00677991  -0.0418347   -0.12827     -0.0198727    0.0626399   -0.0914254   -0.00654394   0.0311554    -0.042466     0.1876      -0.126867     0.110408     0.0602729    -0.20915      -0.106058     0.0190843    0.000261883  -0.0968297
 -0.00961375   0.0596356   -0.0366997   -0.0891723    -0.0541019     0.0469975    0.12591      0.0286079   -0.0392872   -0.0530316    0.115752    -0.0686837   -0.0387718    0.0373453    0.0524434   -0.0816913     0.0381539   -0.0177819    0.0149079   -0.0859991    0.00165188    0.0191197     0.0201048   -0.00859257  -0.112712      0.072482
 -0.0928275   -0.130984    -0.0516814   -0.0163168     0.00686893   -0.0456058   -0.0671719    0.0822505   -0.00746849  -0.0160856   -0.0710267    0.104464     0.00530619   0.0294024   -0.0591776   -0.0414101    -0.0237695   -0.0518013    0.0151703    0.00851432   0.10473       0.0807452    -0.0553059    0.0326444    0.164306      0.0386037
 -0.13652      0.0937643    0.174855    -0.00531223    0.0846425    -0.00440821  -0.324557    -0.00321745  -0.0483473    0.00091751  -0.118776    -0.0709255    0.121135     0.14082     -0.0703184   -0.0722381    -0.0245051    0.108584    -0.00561195   0.0595969   -0.000607795  -0.0909942    -0.0440252    0.028485     0.122115      0.0813419
 -0.0896814    0.140361    -0.0791338   -0.0878029    -0.0441703    -0.0412072   -0.0235013    0.219629    -0.147404     0.00878515  -0.0659426   -0.0297297    0.114014     0.14479     -0.0531156    0.152438     -0.0966319   -0.146235     0.0929329   -0.0117595   -0.0374249    -0.0275873     0.163292     0.0921763    0.0944994    -0.115366
  0.0127973   -0.156539    -0.20746     -0.0906788    -0.149512     -0.080323    -0.0185926   -0.190484    -0.15639     -0.253437     0.0565607    0.0209379   -0.075066     0.183194    -0.00967168   0.0598612    -0.00450225  -0.125645    -0.0148382   -0.0941572   -0.160804      0.0602819    -0.0253796    0.108922    -0.183226     -0.0849974
 -0.0299107   -0.261747     0.101912    -0.00210057    0.0429157     0.0143694    0.114876     0.116423    -0.171784    -0.0149615   -0.0525803    0.0108045   -0.0456525    0.121749     0.0599918    0.0418237     0.0443398   -0.0985117    0.127566     0.0386391   -0.156678     -0.00892048    0.0725022    0.0231948   -0.0723418     0.0357353
  0.0837064   -0.014869    -0.069648    -0.106317      0.162054     -0.0716856    0.0540662    0.203364     0.00120605  -0.0432021    0.011781     0.111429    -0.131837     0.100569     0.0406553    0.00693257    0.0694691   -0.0648547   -0.0854357    0.0599479   -0.0832795     0.0132933    -0.0960079    0.022246    -0.0166809    -0.0353153
  0.115367     0.0405203   -0.181306     0.000583226   0.00198904    0.173364     0.0966122   -0.121794     0.00768739   0.0420255   -0.105664     0.0221768    0.00846443  -0.122153     0.187968    -0.0296183    -0.114191    -0.0413008   -0.0160543    0.131492    -0.0060424    -0.0651609    -0.0401376    0.0333203   -0.0412877    -0.182913
  0.155093    -0.01796      0.191362    -0.216812     -0.147178     -0.102988    -0.135769    -0.118347    -0.0152788    0.254027     0.00147582   0.0196839   -0.111645     0.11253      0.0606472    0.135191     -0.0844408    0.00634394  -0.0701045   -0.00616741  -0.145463     -0.0807813     0.061513    -0.0782451    0.188953     -0.0781152
  0.0450666   -0.063831     0.0556847   -0.0428767     0.240895      0.0457412   -0.15749      0.0900303   -0.0655439    0.00574725   0.045659     0.00745038  -0.0149264   -0.0294172    0.0969085    0.0872972     0.0881507    0.0796361    0.108909     0.10791      0.0438569     0.112064     -0.0716176    0.110828     0.0227953     0.0355973
 -0.0742218    0.110321    -0.0298793   -0.205483     -0.154639      0.166647     0.119108     0.0780249   -0.00394892  -0.0194412   -0.0842129    0.103046    -0.0797456   -0.283395     0.0924037   -0.120307     -0.173772    -0.0198853    0.0955555    0.07076     -0.0137884    -0.107579      0.073385     0.167045    -0.362952     -0.0588339
 -0.179714     0.12603     -0.0371718   -0.246813     -0.141948      0.0649939   -0.033296     0.0387392    0.177979     0.100574    -0.0844249   -0.00239906   0.615583     0.43588      0.092328    -0.118492      0.32434     -0.0303315    0.0842334    0.0334752   -0.304216     -0.0610115     0.0744671    0.166318    -0.01031      -0.0633225[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.074969
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│     13
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.048479
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.065705
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.054792
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      7
│     13
│     14
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.063999
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.049120
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      7
│     13
│     14
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.071319
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.051890
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│     13
│     14
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.062600
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.057882
┌ Info: EM with 100000 data points 10 iterations avll -1.057882
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.851133e+05
      1       7.261116e+05      -2.590017e+05 |       32
      2       6.959820e+05      -3.012961e+04 |       32
      3       6.815212e+05      -1.446088e+04 |       32
      4       6.736053e+05      -7.915832e+03 |       32
      5       6.686145e+05      -4.990822e+03 |       32
      6       6.648548e+05      -3.759731e+03 |       32
      7       6.622296e+05      -2.625142e+03 |       32
      8       6.603268e+05      -1.902792e+03 |       32
      9       6.587601e+05      -1.566704e+03 |       32
     10       6.576044e+05      -1.155699e+03 |       32
     11       6.566931e+05      -9.113014e+02 |       32
     12       6.559087e+05      -7.844669e+02 |       32
     13       6.553401e+05      -5.685963e+02 |       32
     14       6.550583e+05      -2.817613e+02 |       32
     15       6.549329e+05      -1.254024e+02 |       32
     16       6.548532e+05      -7.971899e+01 |       32
     17       6.547836e+05      -6.962255e+01 |       32
     18       6.547132e+05      -7.039727e+01 |       32
     19       6.546330e+05      -8.014365e+01 |       32
     20       6.545237e+05      -1.093348e+02 |       32
     21       6.543651e+05      -1.585553e+02 |       32
     22       6.540981e+05      -2.669896e+02 |       32
     23       6.537478e+05      -3.503483e+02 |       32
     24       6.533163e+05      -4.314639e+02 |       32
     25       6.529055e+05      -4.108645e+02 |       32
     26       6.525790e+05      -3.264558e+02 |       32
     27       6.523299e+05      -2.490878e+02 |       32
     28       6.521147e+05      -2.152481e+02 |       32
     29       6.518069e+05      -3.078141e+02 |       32
     30       6.513839e+05      -4.229710e+02 |       32
     31       6.509602e+05      -4.236450e+02 |       32
     32       6.506257e+05      -3.345638e+02 |       32
     33       6.503435e+05      -2.822228e+02 |       32
     34       6.501584e+05      -1.850461e+02 |       32
     35       6.500590e+05      -9.939523e+01 |       32
     36       6.499959e+05      -6.306620e+01 |       31
     37       6.499497e+05      -4.624941e+01 |       32
     38       6.499112e+05      -3.854365e+01 |       31
     39       6.498773e+05      -3.386422e+01 |       30
     40       6.498438e+05      -3.345599e+01 |       32
     41       6.498063e+05      -3.757425e+01 |       32
     42       6.497681e+05      -3.819022e+01 |       32
     43       6.497151e+05      -5.292725e+01 |       31
     44       6.496502e+05      -6.492765e+01 |       32
     45       6.495805e+05      -6.969074e+01 |       32
     46       6.495242e+05      -5.630712e+01 |       31
     47       6.494660e+05      -5.820979e+01 |       32
     48       6.494085e+05      -5.753446e+01 |       32
     49       6.493632e+05      -4.523888e+01 |       32
     50       6.493111e+05      -5.215257e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 649311.0806343902)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.358291
[ Info: iteration 2, average log likelihood -1.326775
[ Info: iteration 3, average log likelihood -1.296438
[ Info: iteration 4, average log likelihood -1.256566
[ Info: iteration 5, average log likelihood -1.196446
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     12
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.142116
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     10
│     16
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.135303
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.165900
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     15
│     17
│     19
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.111777
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.156930
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.139382
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.128160
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     12
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.104020
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.128063
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     22
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.098412
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.120219
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.130731
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.102612
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     10
│     12
│     15
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.050112
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.159303
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.141476
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.097488
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     12
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.089013
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.140168
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.101485
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     16
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.104219
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     10
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.097155
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     15
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.123093
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.134278
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.083042
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     10
│     15
│     19
│      ⋮
│     23
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.069785
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.161945
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.125160
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     12
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.094832
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     16
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.099809
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.141244
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.098880
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     12
│     17
│     19
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.077532
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.138187
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     15
│     16
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.096471
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     12
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.103311
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.113229
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.114270
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.128727
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.087686
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      7
│     17
│     19
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.097778
[ Info: iteration 47, average log likelihood -1.150573
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     12
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.086400
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.115985
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     17
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.108590
┌ Info: EM with 100000 data points 50 iterations avll -1.108590
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0326455    0.0116861    0.255534     -0.0391542   -0.0468912   -0.00487665  -0.200876     0.20615      0.0484962     0.00973868  -0.0770751   -0.103884     0.0891525   -0.132467    -0.0281115   -0.10427       0.135442     -0.168255     0.096944     0.047245    -0.0428444    0.342709    -0.295542    -0.00551826   0.0242806   0.0369556
 -0.0178767    0.0954146    0.0382027    -0.16263      0.0628043   -0.0366578   -0.112814    -0.0846476    0.0605153     0.00472672   0.0618778    0.126588    -0.0563138    0.132522    -0.104995    -0.0364993    -0.1158       -0.0186861   -0.20352     -0.02802      0.0243227   -0.0998816   -0.126661     0.0544443   -0.038431   -0.115282
  0.155209    -0.0182548    0.190717     -0.216481    -0.147448    -0.103513    -0.135828    -0.1184      -0.0158974     0.253957     0.00249658   0.0188831   -0.112429     0.113313     0.0597293    0.1352       -0.0852248     0.00629773  -0.0687455   -0.00626887  -0.146589    -0.0801646    0.061736    -0.0782645    0.189583   -0.0765109
 -0.126464    -0.151401    -0.0675234     0.0275878   -0.0163429   -0.0948912    0.124275     0.192256    -0.0164785    -0.0187702   -0.107253     0.0703825    0.0635513    0.0302975   -0.0896653   -0.0629168     0.0493971    -0.0120067    0.0844795    0.0179535    0.240464     0.0152757   -0.0362781    0.0610834    0.152186    0.0179433
  0.153215    -0.0199222   -0.000103116   0.0145322    0.0550121    0.0334603   -0.0416459    0.106556     0.0707139     0.0461049    0.022895     0.00983933  -0.0135768   -0.0322414    0.0842975   -0.122637     -0.0403486    -0.0706305   -0.139776     0.0286117   -0.0245439   -0.1051       0.0129127   -0.0160312   -0.0105652   0.0862187
 -0.130786     0.0945596    0.176091     -0.0050209    0.0888531   -0.00464429  -0.33154     -0.00444212  -0.048264      0.00289683  -0.118798    -0.0661775    0.122379     0.13657     -0.0679327   -0.0722188    -0.0256926     0.113628    -0.00660569   0.0581943   -0.0017395   -0.0921658   -0.045077     0.0259624    0.122329    0.0851287
 -0.0478116    0.131417     0.144047     -0.0313532    0.00891587   0.0156544    0.238943     0.0314676   -0.0134368     0.00120419  -0.0722027    0.131958     0.102051     0.0283557   -0.0700916    0.0108174     0.0685344     0.102291    -0.185008    -0.0855082    0.0730004    0.0266573    0.214245    -0.0321072    0.0382947  -0.098453
  0.0679266   -0.136617     0.133817     -0.0831219   -0.140863     0.129762     0.0587494   -0.165442    -0.043784      0.0581304   -0.161583    -0.0137646    0.0152022   -0.0296636   -0.0605244    0.0575716    -0.0352648     0.231166    -0.133746     0.100496     0.03695     -0.203048    -0.119319    -0.0372678    0.0259397  -0.104757
 -0.105142     0.090372     0.0399374    -0.0340137   -0.198453     0.0490062    0.114444     0.141803    -0.0386394    -0.133853     0.0980897   -0.0431368   -0.00167509  -0.0394162    0.131393    -0.114733     -0.0412069     0.0664263   -0.0214039   -0.0331036   -0.0776842    0.124023     0.0811022   -0.10614     -0.106698    0.0784761
 -0.0618806   -0.106979    -0.0284858    -0.0660747    0.0100133    0.00192267  -0.258388    -0.0224787    0.00229886   -0.0202023   -0.0253546    0.122475    -0.0574241    0.0146706   -0.0288931   -0.0260068    -0.102823     -0.0894987   -0.0418855    0.00867701  -0.0362714    0.149412    -0.077416     0.00156663   0.178764    0.0542733
 -0.136949     0.0802316    0.0813598     0.149462     0.053633     0.130409     0.129963    -0.0381904   -0.129035     -0.0526715   -0.105344     0.0253209   -0.0703751    0.0479515    0.101532    -0.0181473    -0.0297922     0.0205576    0.0611015   -0.060669    -0.149052     0.101506     0.0241687    0.0115781    0.295194   -0.0738911
 -0.0283267   -0.306759     0.0996615     0.016518     0.0549726    0.0210027    0.106443     0.118291    -0.15949      -0.0103048   -0.0404504    0.0158568   -0.0415315    0.111207     0.0582589    0.0398605     0.0388848    -0.0976152    0.13502      0.0386021   -0.147819    -0.00961334   0.0664716    0.0337391   -0.0716746   0.0417962
 -0.0580689   -0.055806    -0.11248      -0.228739     0.013522    -0.168465    -0.0464244    0.0818441   -0.0761119    -0.0840785   -0.141794    -0.0749212   -0.0362971   -0.146303     0.0112378    0.077782      0.123529     -0.00723821   0.0981601    0.0554373    0.0794884    0.229758     0.00744954  -0.0691035    0.0785698   0.15132
 -0.0893323    0.13715     -0.0811131    -0.0877513   -0.048545    -0.0412825   -0.020422     0.217043    -0.149159      0.0108825   -0.0650189   -0.0326281    0.115986     0.144683    -0.0527325    0.15307      -0.0879756    -0.146609     0.0955602   -0.00555775  -0.0390979   -0.0284727    0.163985     0.0929627    0.0932613  -0.112936
 -0.0871052    0.0717732   -0.0163653    -0.135478    -0.100955     0.139114     0.0618852    0.0573919    0.0352608     0.00804348  -0.0774454    0.0799603    0.0760068   -0.0980329    0.072443    -0.127655     -0.0597727    -0.0134041    0.0768231    0.00911052  -0.0578351   -0.0642836    0.0265155    0.157014    -0.253917   -0.0629468
 -0.136432    -0.288912    -0.210686      0.112583     0.164194     0.0384086   -0.0927639   -0.115822     0.0861388     0.0289026   -0.0283237    0.08858     -0.0558824    0.128484    -0.0399797    0.046488     -0.142925     -0.00637571  -0.0178125   -0.0530922    0.00267252  -0.11025      0.012084     0.244557    -0.0987141   0.0570361
  0.0860939    0.0274181   -0.112604     -0.143257     0.094001     0.0461866    0.136598    -0.0849082   -0.0398227     0.0263148    0.123537    -0.0986968   -0.0788864    0.125768    -0.0335258   -0.0436387     0.123941     -0.107466     0.0524579   -0.135393     0.082631    -0.0964017   -0.0433245    0.0859199   -0.115066    0.0600916
 -0.125614     0.130469    -0.0990037     0.0839566   -0.224691     0.129476     0.00635334   0.102919     0.0933492     0.0100585   -0.0262125    0.0135356    0.0739637   -0.182954    -0.0249256   -0.0465653     0.0728132     0.0723892    0.157748    -0.0196857   -0.171379    -0.0700601   -0.0625902   -0.179358     0.119451    0.0286327
 -0.0617568   -0.00119992   0.112538      0.0329625    0.0436741    0.0379057    0.0381194   -0.0886351    0.0329331    -0.0535463    0.13952      0.119777     0.0959686    0.0689845   -0.033077    -0.0127939    -0.125896     -0.109577     0.0460021   -0.0830024   -0.0352117   -0.107051    -0.0176982    0.0862303   -0.198212   -0.0582744
 -0.158559    -0.0956798    0.120558      0.0799521    0.116505     0.160885    -0.0631637   -0.0666974   -0.136662     -0.0184598   -0.0837335   -0.154761     0.0931625   -0.0122888    0.075615     0.0321163    -0.106928      0.224772    -0.0117903    0.0918121   -0.0216242    0.12027     -0.106858    -0.132184     0.0645153  -0.0457175
  0.0459065   -0.0621335    0.0514945    -0.0564449    0.248464     0.0571679   -0.157406     0.0989854   -0.0563919     0.00604218   0.0438446    0.00490106  -0.0182781   -0.0247712    0.113673     0.0924959     0.121596      0.0864192    0.123161     0.112021     0.0402873    0.11493     -0.0690569    0.10832      0.0181508   0.0445569
  0.0684208   -0.00882506   0.0191015    -0.0215985   -0.0539033   -0.0971941   -0.0516044   -0.10306     -0.126486     -0.0845946   -0.0116031    0.00668541  -0.0102142    0.0189025    0.0102722   -0.000777744  -0.0997315     0.0517728   -0.0836376    0.010552    -0.107845     0.0631193    0.0289453    0.0229745   -0.169067    0.0814433
  0.168246    -0.158745    -0.0442881     0.155671     0.180082     0.051621    -0.0558714   -0.0755664    0.0444683    -0.0556797   -0.11195      0.0256341   -0.0594779   -0.00105122  -0.0917872   -0.265378     -0.0503702     0.134115    -0.0165634   -0.11971      0.00522148   0.0952462   -0.169377    -0.00605856   0.152633   -0.223896
 -0.0380189   -0.0903939   -0.0646668     0.0799613   -0.0122751    0.082415    -0.103229     0.0381372   -0.0874915     0.0423667    0.00447807  -0.101849     0.104412     0.0549973   -0.143734     0.0152761     0.0208401     0.2068       0.209973    -0.0034319    0.0321318    0.169496    -0.107654    -0.179238     0.126237    0.0711094
  0.00921627  -0.154235    -0.213428     -0.088944    -0.156274    -0.0747632   -0.0161882   -0.188751    -0.164276     -0.250449     0.0546954    0.0237285   -0.0772211    0.195637    -0.0069562    0.0570428    -0.00201966   -0.127716    -0.0136481   -0.092707    -0.171096     0.0602243   -0.0196741    0.101963    -0.183989   -0.0898762
  0.158054    -0.0327613    0.0272834    -0.124719    -0.130479    -0.0371333   -0.0113952   -0.0249302   -0.24128       0.0158053    0.177249     0.0105204   -0.018125    -0.0945618   -0.00499323  -0.117447     -0.0441647    -0.00392449   0.0757079    0.0461184    0.0290055    0.142791    -0.00588227   0.100039    -0.0116793  -0.00159133
 -0.0484707   -0.0203747   -0.0688581     0.0289886   -0.0198116   -0.0675655   -0.037934    -0.203626     0.0207602    -0.0589116    0.128673     0.0952361    0.323085     0.0739009   -0.0935058   -0.0222282    -0.158925     -0.134939     0.0161782   -0.0651224    0.0465083   -0.113095     0.0681089   -0.0159826   -0.179024   -0.0582266
  0.0827281   -0.0123811   -0.0695737    -0.105584     0.162565    -0.0697167    0.0546469    0.20265     -0.000758675  -0.0444639    0.0117046    0.110941    -0.131462     0.102048     0.0390417    0.00769826    0.0695386    -0.0648941   -0.0846887    0.0603113   -0.0867236    0.0120006   -0.0948181    0.0211896   -0.0170544  -0.0351601
  0.114782     0.0457597   -0.183605      0.00492058   0.0100207    0.176127     0.100825    -0.122604     0.00851696    0.0495191   -0.112396     0.0194977    0.00195477  -0.125871     0.19112     -0.0332654    -0.11351      -0.0404319   -0.0125225    0.162065    -0.00435541  -0.072846    -0.0256518    0.0203807   -0.040755   -0.19441
 -0.0744302    0.00611229   0.0231602     0.0577643    0.0145731    0.115739     0.023917    -0.0015625   -0.0934532     0.119289    -0.00862459  -0.0144126    0.110944     0.129958     0.090856    -0.0572568     0.0184951    -0.0344788    0.247255     0.115494    -0.0196497    0.0700545   -0.197251    -0.0579143    0.0366777   0.0688018
  0.0951908   -0.0374233   -0.0561204    -0.237084     0.0533078    0.0698573   -0.0281304    0.130976    -0.0721635    -0.0648043   -0.103332    -0.0346323    0.0562679   -0.111801     0.084645    -0.00865559    0.000990804   0.0891462   -0.00953103   0.0849833    0.031495    -0.153652    -0.015765     0.0665131   -0.0276951   0.0186009
  0.221366    -0.150965    -0.0370454     0.184675     0.123272     0.0672543   -0.0564824   -0.07185      0.075871     -0.037229    -0.0958804    0.0550444   -0.10831     -0.0179006   -0.164515    -0.349693      0.0061801     0.0834978   -0.0367752   -0.1082       0.0280888    0.056204    -0.224304    -0.010765     0.356079   -0.174921[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.119284
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     10
│     12
│     16
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.077299
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     12
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.070114
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      7
│     10
│     11
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.032906
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     12
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.100750
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     10
│     16
│     19
│     22
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.074259
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     12
│     15
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.064231
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      7
│     10
│     12
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.033466
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     15
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.113020
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     10
│     12
│     16
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.082450
┌ Info: EM with 100000 data points 10 iterations avll -1.082450
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.00807802   0.0884573   -0.111665     0.00761539   0.0790535   -0.0201455   -0.139342     0.138251      0.16165     0.114281    0.155422    0.121027     -0.0682345    -0.0400829     0.113464    -0.0641618   -0.0271676    -0.101089     0.0457004    0.200084    -0.0117532     0.0136608     0.139151    -0.0228052    0.0841655    -0.0985197
  0.140796     0.00450372   0.0520411    0.109717    -0.00712411   0.160746    -0.0198744    0.1055        0.0253002   0.0182614   0.0295327   0.0300668     0.131493      0.0503614     0.0516329   -0.112638     0.0520533    -0.108767    -0.237468    -0.0750091    0.00404506   -0.023601      0.116982    -0.0955631   -0.058968      0.130259
  0.0392212   -0.060415     0.00279422  -0.134722     0.00988613  -0.108678     0.00206034  -0.0244314    -0.057142   -0.0077868  -0.179444   -0.094388      0.000402462  -0.0701108    -0.177218    -0.0192021    0.0278256     0.218404    -0.0918798   -0.122229    -0.0722473     0.118986      0.00897609   0.036344    -0.010176     -0.079875
  0.154204     0.118232     0.11081      0.166204    -0.0931718   -0.134161    -0.0344698    0.0176229     0.0639743  -0.197945    0.0348902   0.000722107  -0.0450114    -0.0522279     0.0600775   -0.057943    -0.169099      0.187398    -0.0370506    0.167371     0.00853643    0.00450179    0.108161     0.156059     0.0472599     0.00591687
 -0.105118    -0.209761     0.0158753    0.0829466    0.0941934   -0.0640673   -0.0712405   -0.0608469     0.009761   -0.160771   -0.259358   -0.00201486    0.160534      0.000742259   0.0446374   -0.134224     0.175387     -0.00340616   0.0382644   -0.0302516   -0.0325531     0.000299304  -0.0667637    0.125187     0.146838      0.171371
  0.0226347   -0.0633891   -0.0468583    0.0376398    0.201708    -0.186339    -0.103311    -0.0408787     0.047994   -0.0216286   0.158736   -0.128386      0.0755092     0.138114     -0.0219802    0.0790566   -0.0868076     0.154258    -0.195057     0.107163     0.0508405    -0.0611998    -0.128623     0.0040727    0.000478543   0.0298037
  0.103164     0.0899004   -0.00437871  -0.10711     -0.0283349   -0.0603161   -0.0732648   -0.122757     -0.191119   -0.0689032  -0.0577566  -0.0940359    -0.105704     -0.112042      0.18623      0.0391474    0.00749122   -0.162017    -0.0565451   -0.156291     0.104686      0.0152133    -0.0322525    0.194706    -0.0817546     0.00585896
 -0.0380868   -0.00441182  -0.133668    -0.00124378  -0.0215918    0.0918055   -0.00462987   0.116167     -0.121792    0.141125    0.185947   -0.150797      0.0371621     0.0868348     0.0374823    0.0756723    0.0399153    -0.0435088    0.125594     0.0624967    0.0225403    -0.0456366    -0.0925118    0.133801    -0.0594333    -0.0182203
 -0.0580616   -0.0278691    0.0944779   -0.0243868   -0.086544     0.152059     0.0141478    0.112331      0.0533816  -0.173512    0.168622   -0.0628701     0.0286334     0.0316216     0.0643486    0.046887     0.00472974   -0.0137934   -0.0206662    0.154006     0.0955199     0.174603      0.0300111   -0.0596122    0.138553     -0.0955388
  0.323158     0.0849058   -0.103718     0.0570671    0.0180516   -0.171214    -0.0543909    0.000588538  -0.153651    0.0862435  -0.16774    -0.0943642     0.0881328     0.0611011    -0.0412892   -0.0379921   -0.059095      0.0135597   -0.114617    -0.12202      0.0453159    -0.101983     -0.0511731    0.0983054   -0.014942     -0.0650227
  0.175376    -0.00967833  -0.080386    -0.0717047   -0.160368    -0.152151     0.0463751   -0.0615635     0.0256221  -0.0630583   0.0508584   0.18031      -0.0345997     0.0389609    -0.0953197    0.0217929   -0.0734086     0.132421    -0.0988303    0.0467475   -0.00217255   -0.0698766     0.164094    -0.00418505   0.0843276    -0.0831156
 -0.0124492    0.014959    -0.0138769   -0.137123     0.0742073   -0.0575099   -0.039855    -0.0345206    -0.141139   -0.131672    0.0978661  -0.0735779     0.119485     -0.180583     -0.0448693   -0.103101    -0.0453701     0.0369324    0.192603    -0.0183564    0.066308     -0.0518816    -0.0333598   -0.016405     0.0583985     0.0780307
 -0.0410934    0.113705     0.193792     0.100822     0.058634     0.0117585   -0.0549627    0.147327      0.060738   -0.0703691  -0.103756    0.120419     -0.0789367     0.117656      0.10507      0.0351544   -0.00992148   -0.0266828    0.0221644    0.0643501   -0.000110354   0.0869941    -0.0352134   -0.168258     0.132131      0.0936538
 -0.111431    -5.32652e-5   0.102478     0.136023     0.001231    -0.00476012  -0.102763     0.0798404    -0.0240955  -0.0167072  -0.235263   -0.00537225   -0.13282      -0.0228478     0.0414693    0.134666    -0.0427773     0.0558496   -0.148494    -0.300076    -0.0414773     0.201275     -0.143701     0.0226801    0.0793998    -0.124211
  0.166395     0.255805    -0.0231563   -0.113189    -0.0192069    0.111188     0.0256067    0.0119545     0.0878241  -0.015066    0.0314403  -0.0312213     0.0590953     0.0462146     0.0721756   -0.15048      0.0382746    -0.0246879    0.0434044   -0.165767    -0.1113       -0.000435733   0.0605134   -0.00164439  -0.110031     -0.187481
 -0.0379442   -0.0544357    0.138709    -0.0610728   -0.0583191    0.0974101   -0.0762058    0.113043      0.1687     -0.106602   -0.101877   -0.0834129    -0.0738307     0.0464219     0.0977847    0.068657    -0.0104465    -0.088528     0.0818959   -0.0738741    0.159647      0.0432511     0.17461      0.096349    -0.0622212     0.0766844
 -0.132169    -0.0017462    0.192069    -0.0721716   -0.207637     0.00466863   0.324484     0.13649      -0.0708311   0.0806339  -0.118054   -0.0534099    -0.00782388    0.149451     -0.0556503   -0.198787    -0.110394      0.177806    -0.0857722   -0.171472    -0.0989083    -0.0523278     0.0600909   -0.0156962    0.0932648     0.178781
 -0.0435969    0.0617933    0.0667227   -0.0634755    0.136387    -0.0475356    0.156681    -0.126428      0.0323772  -0.0185604  -0.0971097  -0.052884     -0.00657925    0.0735133     0.179095     0.0346312   -0.181305      0.0131251    0.0300225    0.0523602    0.0269682    -0.0528369     0.0528626   -0.0416667   -0.0134318     0.0753791
 -0.110942     0.154667    -0.0151242   -0.156295    -0.0739358    0.0469387    0.114765     0.0120367    -0.112084    0.114212   -0.0247461   0.0239116    -0.126952      0.0215651    -0.0916074   -0.137728     0.0435585    -0.136916    -0.0313741    0.0795445    0.0609647     0.128318     -0.0461043    0.145521     0.167231      0.0721864
 -0.110893     0.084081     0.239729     0.0334551    0.0304685    0.113422     0.0275664    0.22608      -0.0684474  -0.214311   -0.192112    0.0376954    -0.0905163     0.0110747    -0.0736161   -0.0608225    0.104726     -0.0340768   -0.0384271    0.0976426    0.0292502    -0.176147     -0.0142361    0.0500865    0.0695305    -0.245832
 -0.00224901  -0.144895     0.068355     0.0428422    0.130997    -0.105054    -0.0483891   -0.0519302     0.108514    0.0510609   0.237185    0.284895      0.0461733     0.189691      0.101342     0.0204801   -0.000527886   0.0475449   -0.247881     0.164675    -0.111391      0.0650464     0.00866781  -0.0448215    0.107987     -0.0503929
  0.0989553   -0.00771554  -0.159827    -0.0595014   -0.00208366   0.0768699   -0.0230549   -0.0673334     0.02451     0.135239    0.1691      0.0906571    -0.107631     -0.109852      0.24872     -0.00309597  -0.145697      0.128318     0.129057     0.117527    -0.0997235    -0.0194608     0.16554     -0.0977159   -0.266216      0.0708389
 -0.0259308    0.027416    -0.0295791   -0.271724     0.0461775    0.0636537    0.165657     0.113205      0.0260718  -0.0467222  -0.102245    0.016274     -0.106045      0.0703269    -0.107425    -0.0633861   -0.0105389     0.0141404   -0.143231    -0.0950325   -0.14406      -0.0675665     0.033999    -0.0986649    0.22225      -0.0578437
  0.0129304    0.0374198   -0.0317591    0.07195     -0.104159    -0.0257981   -0.212215     0.010418     -0.236323    0.0158914   0.0525554  -0.109656      0.0295477    -0.00312101   -0.112561    -0.0983782    0.00328765    0.255266     0.0356882    0.0824576   -0.00272283   -0.16681       0.147179    -0.0188209    0.210814      0.0218756
  0.0673137   -0.12245     -0.0581892    0.0770662    0.121983     0.060885     0.0487866   -0.0456244     0.127561    0.107009   -0.103249    0.169975     -0.0716672    -0.170016     -0.0904495   -0.0716924    0.112321      0.105389    -0.0614001   -0.0616852   -0.00556301    0.0617672    -0.254374    -0.136321     0.11153      -0.124314
 -0.0383098    0.116436     0.06355     -0.0327488   -0.105779     0.0836035    0.202471    -0.216718     -0.0991252   0.0594355   0.0226285   0.114259      0.0125661     0.0473326     0.0324385   -0.13637     -0.171878      0.0177192   -0.0880017   -0.084851     0.0312972    -0.0292785     0.0547801   -0.0165173    0.068827     -0.174951
 -0.234296     0.0111316    0.0370082   -0.0949822    0.056817    -0.0223791   -0.0650174   -0.0482593     0.14781    -0.061333    0.207026    0.181985     -0.110253      0.0709085     0.00551972  -0.0697186    0.012567     -0.190421    -0.0669893   -0.165731    -0.00217643   -0.0246952     0.15284      0.0757081    0.0381509     0.0594528
 -0.0369876   -0.139987     0.0854795    0.0659851    0.235986    -0.00502874  -0.125716    -0.0558643    -0.021409    0.0582848  -0.0121681  -0.0857033     0.192424      0.0106717    -0.204185     0.00885928   0.198925      0.0897575   -0.172417    -0.00496193  -0.0505793    -0.0764938    -0.18652     -0.0965773    0.1414       -0.192273
  0.154022     0.0875349   -0.0575831    0.316806     0.0479012   -0.099948     0.0101799    0.0794323     0.165516    0.133844   -0.0722225   0.0834605     0.0592539    -0.0130769     0.0748167   -0.195786     0.0281949    -0.201654    -0.0367685   -0.0216021    0.0585572     0.0563311     0.030554    -0.0270443    0.218811      0.00673216
  0.0978578    0.0670625    0.0682392   -0.133152     0.0769505   -0.0681549    0.0531257    0.076778     -0.14398    -0.0523602  -0.0394732  -0.0844006    -0.106326      0.104449      0.0706719    0.103453     0.0886225     0.124084     0.00960436   0.0106477    0.0230121     0.0198271    -0.0941909    0.0674561   -0.0593259     0.106267
 -0.0241846    0.0800066   -0.0181359    0.0649468   -0.13349      0.162643     0.0843547    0.134768      0.0140609   0.067862    0.0064589   0.188629     -0.105813      0.125757      0.0309814    0.00873007  -0.122192      0.114953    -0.0196554    0.0771857    0.0414974    -0.0423633     0.0478922    0.0760162    0.174265     -0.0872125
 -0.00200257   0.0603409   -0.00274647   0.071923     0.0531763   -0.123126    -0.0199514    0.19175      -0.028894    0.0826391   0.11588    -0.0444076     0.108398      0.0291338    -0.0760823   -0.160617    -0.292416      0.0451254   -0.184718     0.0207865    0.0336587    -0.100959      0.0272625    0.164195    -0.132885      0.0494031kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4248551373551246
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424874
[ Info: iteration 2, average log likelihood -1.424812
[ Info: iteration 3, average log likelihood -1.424766
[ Info: iteration 4, average log likelihood -1.424714
[ Info: iteration 5, average log likelihood -1.424651
[ Info: iteration 6, average log likelihood -1.424577
[ Info: iteration 7, average log likelihood -1.424488
[ Info: iteration 8, average log likelihood -1.424377
[ Info: iteration 9, average log likelihood -1.424214
[ Info: iteration 10, average log likelihood -1.423929
[ Info: iteration 11, average log likelihood -1.423412
[ Info: iteration 12, average log likelihood -1.422580
[ Info: iteration 13, average log likelihood -1.421560
[ Info: iteration 14, average log likelihood -1.420700
[ Info: iteration 15, average log likelihood -1.420197
[ Info: iteration 16, average log likelihood -1.419966
[ Info: iteration 17, average log likelihood -1.419870
[ Info: iteration 18, average log likelihood -1.419831
[ Info: iteration 19, average log likelihood -1.419816
[ Info: iteration 20, average log likelihood -1.419809
[ Info: iteration 21, average log likelihood -1.419806
[ Info: iteration 22, average log likelihood -1.419805
[ Info: iteration 23, average log likelihood -1.419804
[ Info: iteration 24, average log likelihood -1.419804
[ Info: iteration 25, average log likelihood -1.419804
[ Info: iteration 26, average log likelihood -1.419804
[ Info: iteration 27, average log likelihood -1.419804
[ Info: iteration 28, average log likelihood -1.419803
[ Info: iteration 29, average log likelihood -1.419803
[ Info: iteration 30, average log likelihood -1.419803
[ Info: iteration 31, average log likelihood -1.419803
[ Info: iteration 32, average log likelihood -1.419803
[ Info: iteration 33, average log likelihood -1.419803
[ Info: iteration 34, average log likelihood -1.419803
[ Info: iteration 35, average log likelihood -1.419803
[ Info: iteration 36, average log likelihood -1.419803
[ Info: iteration 37, average log likelihood -1.419803
[ Info: iteration 38, average log likelihood -1.419803
[ Info: iteration 39, average log likelihood -1.419803
[ Info: iteration 40, average log likelihood -1.419803
[ Info: iteration 41, average log likelihood -1.419803
[ Info: iteration 42, average log likelihood -1.419803
[ Info: iteration 43, average log likelihood -1.419803
[ Info: iteration 44, average log likelihood -1.419803
[ Info: iteration 45, average log likelihood -1.419803
[ Info: iteration 46, average log likelihood -1.419803
[ Info: iteration 47, average log likelihood -1.419803
[ Info: iteration 48, average log likelihood -1.419803
[ Info: iteration 49, average log likelihood -1.419803
[ Info: iteration 50, average log likelihood -1.419803
┌ Info: EM with 100000 data points 50 iterations avll -1.419803
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.424874159576622
│     -1.4248118692917577
│      ⋮
└     -1.4198027291734918
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419818
[ Info: iteration 2, average log likelihood -1.419756
[ Info: iteration 3, average log likelihood -1.419706
[ Info: iteration 4, average log likelihood -1.419650
[ Info: iteration 5, average log likelihood -1.419584
[ Info: iteration 6, average log likelihood -1.419508
[ Info: iteration 7, average log likelihood -1.419428
[ Info: iteration 8, average log likelihood -1.419351
[ Info: iteration 9, average log likelihood -1.419283
[ Info: iteration 10, average log likelihood -1.419227
[ Info: iteration 11, average log likelihood -1.419182
[ Info: iteration 12, average log likelihood -1.419147
[ Info: iteration 13, average log likelihood -1.419119
[ Info: iteration 14, average log likelihood -1.419097
[ Info: iteration 15, average log likelihood -1.419080
[ Info: iteration 16, average log likelihood -1.419067
[ Info: iteration 17, average log likelihood -1.419057
[ Info: iteration 18, average log likelihood -1.419049
[ Info: iteration 19, average log likelihood -1.419042
[ Info: iteration 20, average log likelihood -1.419037
[ Info: iteration 21, average log likelihood -1.419032
[ Info: iteration 22, average log likelihood -1.419028
[ Info: iteration 23, average log likelihood -1.419025
[ Info: iteration 24, average log likelihood -1.419021
[ Info: iteration 25, average log likelihood -1.419018
[ Info: iteration 26, average log likelihood -1.419016
[ Info: iteration 27, average log likelihood -1.419013
[ Info: iteration 28, average log likelihood -1.419010
[ Info: iteration 29, average log likelihood -1.419008
[ Info: iteration 30, average log likelihood -1.419005
[ Info: iteration 31, average log likelihood -1.419002
[ Info: iteration 32, average log likelihood -1.419000
[ Info: iteration 33, average log likelihood -1.418997
[ Info: iteration 34, average log likelihood -1.418995
[ Info: iteration 35, average log likelihood -1.418992
[ Info: iteration 36, average log likelihood -1.418989
[ Info: iteration 37, average log likelihood -1.418986
[ Info: iteration 38, average log likelihood -1.418984
[ Info: iteration 39, average log likelihood -1.418981
[ Info: iteration 40, average log likelihood -1.418978
[ Info: iteration 41, average log likelihood -1.418975
[ Info: iteration 42, average log likelihood -1.418971
[ Info: iteration 43, average log likelihood -1.418968
[ Info: iteration 44, average log likelihood -1.418965
[ Info: iteration 45, average log likelihood -1.418961
[ Info: iteration 46, average log likelihood -1.418958
[ Info: iteration 47, average log likelihood -1.418954
[ Info: iteration 48, average log likelihood -1.418951
[ Info: iteration 49, average log likelihood -1.418947
[ Info: iteration 50, average log likelihood -1.418943
┌ Info: EM with 100000 data points 50 iterations avll -1.418943
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4198176319828029
│     -1.4197555189188154
│      ⋮
└     -1.418942818129327
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418948
[ Info: iteration 2, average log likelihood -1.418893
[ Info: iteration 3, average log likelihood -1.418846
[ Info: iteration 4, average log likelihood -1.418791
[ Info: iteration 5, average log likelihood -1.418724
[ Info: iteration 6, average log likelihood -1.418641
[ Info: iteration 7, average log likelihood -1.418539
[ Info: iteration 8, average log likelihood -1.418422
[ Info: iteration 9, average log likelihood -1.418293
[ Info: iteration 10, average log likelihood -1.418162
[ Info: iteration 11, average log likelihood -1.418036
[ Info: iteration 12, average log likelihood -1.417923
[ Info: iteration 13, average log likelihood -1.417828
[ Info: iteration 14, average log likelihood -1.417750
[ Info: iteration 15, average log likelihood -1.417689
[ Info: iteration 16, average log likelihood -1.417641
[ Info: iteration 17, average log likelihood -1.417603
[ Info: iteration 18, average log likelihood -1.417572
[ Info: iteration 19, average log likelihood -1.417546
[ Info: iteration 20, average log likelihood -1.417523
[ Info: iteration 21, average log likelihood -1.417502
[ Info: iteration 22, average log likelihood -1.417483
[ Info: iteration 23, average log likelihood -1.417466
[ Info: iteration 24, average log likelihood -1.417450
[ Info: iteration 25, average log likelihood -1.417435
[ Info: iteration 26, average log likelihood -1.417421
[ Info: iteration 27, average log likelihood -1.417408
[ Info: iteration 28, average log likelihood -1.417396
[ Info: iteration 29, average log likelihood -1.417384
[ Info: iteration 30, average log likelihood -1.417374
[ Info: iteration 31, average log likelihood -1.417364
[ Info: iteration 32, average log likelihood -1.417355
[ Info: iteration 33, average log likelihood -1.417346
[ Info: iteration 34, average log likelihood -1.417338
[ Info: iteration 35, average log likelihood -1.417331
[ Info: iteration 36, average log likelihood -1.417323
[ Info: iteration 37, average log likelihood -1.417316
[ Info: iteration 38, average log likelihood -1.417310
[ Info: iteration 39, average log likelihood -1.417304
[ Info: iteration 40, average log likelihood -1.417298
[ Info: iteration 41, average log likelihood -1.417292
[ Info: iteration 42, average log likelihood -1.417286
[ Info: iteration 43, average log likelihood -1.417281
[ Info: iteration 44, average log likelihood -1.417276
[ Info: iteration 45, average log likelihood -1.417271
[ Info: iteration 46, average log likelihood -1.417265
[ Info: iteration 47, average log likelihood -1.417260
[ Info: iteration 48, average log likelihood -1.417256
[ Info: iteration 49, average log likelihood -1.417251
[ Info: iteration 50, average log likelihood -1.417246
┌ Info: EM with 100000 data points 50 iterations avll -1.417246
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4189484154858063
│     -1.418893272566869
│      ⋮
└     -1.4172460517151106
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417250
[ Info: iteration 2, average log likelihood -1.417193
[ Info: iteration 3, average log likelihood -1.417142
[ Info: iteration 4, average log likelihood -1.417085
[ Info: iteration 5, average log likelihood -1.417017
[ Info: iteration 6, average log likelihood -1.416934
[ Info: iteration 7, average log likelihood -1.416835
[ Info: iteration 8, average log likelihood -1.416723
[ Info: iteration 9, average log likelihood -1.416602
[ Info: iteration 10, average log likelihood -1.416478
[ Info: iteration 11, average log likelihood -1.416357
[ Info: iteration 12, average log likelihood -1.416242
[ Info: iteration 13, average log likelihood -1.416138
[ Info: iteration 14, average log likelihood -1.416047
[ Info: iteration 15, average log likelihood -1.415968
[ Info: iteration 16, average log likelihood -1.415901
[ Info: iteration 17, average log likelihood -1.415845
[ Info: iteration 18, average log likelihood -1.415797
[ Info: iteration 19, average log likelihood -1.415756
[ Info: iteration 20, average log likelihood -1.415721
[ Info: iteration 21, average log likelihood -1.415690
[ Info: iteration 22, average log likelihood -1.415663
[ Info: iteration 23, average log likelihood -1.415638
[ Info: iteration 24, average log likelihood -1.415615
[ Info: iteration 25, average log likelihood -1.415594
[ Info: iteration 26, average log likelihood -1.415575
[ Info: iteration 27, average log likelihood -1.415557
[ Info: iteration 28, average log likelihood -1.415540
[ Info: iteration 29, average log likelihood -1.415524
[ Info: iteration 30, average log likelihood -1.415509
[ Info: iteration 31, average log likelihood -1.415494
[ Info: iteration 32, average log likelihood -1.415480
[ Info: iteration 33, average log likelihood -1.415467
[ Info: iteration 34, average log likelihood -1.415454
[ Info: iteration 35, average log likelihood -1.415442
[ Info: iteration 36, average log likelihood -1.415430
[ Info: iteration 37, average log likelihood -1.415419
[ Info: iteration 38, average log likelihood -1.415407
[ Info: iteration 39, average log likelihood -1.415396
[ Info: iteration 40, average log likelihood -1.415386
[ Info: iteration 41, average log likelihood -1.415375
[ Info: iteration 42, average log likelihood -1.415365
[ Info: iteration 43, average log likelihood -1.415355
[ Info: iteration 44, average log likelihood -1.415345
[ Info: iteration 45, average log likelihood -1.415335
[ Info: iteration 46, average log likelihood -1.415325
[ Info: iteration 47, average log likelihood -1.415316
[ Info: iteration 48, average log likelihood -1.415306
[ Info: iteration 49, average log likelihood -1.415297
[ Info: iteration 50, average log likelihood -1.415287
┌ Info: EM with 100000 data points 50 iterations avll -1.415287
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4172498728853227
│     -1.4171933216635302
│      ⋮
└     -1.4152874175414538
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415286
[ Info: iteration 2, average log likelihood -1.415216
[ Info: iteration 3, average log likelihood -1.415148
[ Info: iteration 4, average log likelihood -1.415067
[ Info: iteration 5, average log likelihood -1.414964
[ Info: iteration 6, average log likelihood -1.414836
[ Info: iteration 7, average log likelihood -1.414680
[ Info: iteration 8, average log likelihood -1.414503
[ Info: iteration 9, average log likelihood -1.414315
[ Info: iteration 10, average log likelihood -1.414128
[ Info: iteration 11, average log likelihood -1.413950
[ Info: iteration 12, average log likelihood -1.413788
[ Info: iteration 13, average log likelihood -1.413646
[ Info: iteration 14, average log likelihood -1.413523
[ Info: iteration 15, average log likelihood -1.413419
[ Info: iteration 16, average log likelihood -1.413330
[ Info: iteration 17, average log likelihood -1.413254
[ Info: iteration 18, average log likelihood -1.413189
[ Info: iteration 19, average log likelihood -1.413133
[ Info: iteration 20, average log likelihood -1.413084
[ Info: iteration 21, average log likelihood -1.413040
[ Info: iteration 22, average log likelihood -1.413001
[ Info: iteration 23, average log likelihood -1.412966
[ Info: iteration 24, average log likelihood -1.412933
[ Info: iteration 25, average log likelihood -1.412903
[ Info: iteration 26, average log likelihood -1.412875
[ Info: iteration 27, average log likelihood -1.412849
[ Info: iteration 28, average log likelihood -1.412825
[ Info: iteration 29, average log likelihood -1.412801
[ Info: iteration 30, average log likelihood -1.412779
[ Info: iteration 31, average log likelihood -1.412757
[ Info: iteration 32, average log likelihood -1.412737
[ Info: iteration 33, average log likelihood -1.412717
[ Info: iteration 34, average log likelihood -1.412698
[ Info: iteration 35, average log likelihood -1.412679
[ Info: iteration 36, average log likelihood -1.412661
[ Info: iteration 37, average log likelihood -1.412644
[ Info: iteration 38, average log likelihood -1.412627
[ Info: iteration 39, average log likelihood -1.412610
[ Info: iteration 40, average log likelihood -1.412594
[ Info: iteration 41, average log likelihood -1.412579
[ Info: iteration 42, average log likelihood -1.412564
[ Info: iteration 43, average log likelihood -1.412549
[ Info: iteration 44, average log likelihood -1.412535
[ Info: iteration 45, average log likelihood -1.412521
[ Info: iteration 46, average log likelihood -1.412507
[ Info: iteration 47, average log likelihood -1.412494
[ Info: iteration 48, average log likelihood -1.412481
[ Info: iteration 49, average log likelihood -1.412468
[ Info: iteration 50, average log likelihood -1.412456
┌ Info: EM with 100000 data points 50 iterations avll -1.412456
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4152863734130239
│     -1.4152160126946345
│      ⋮
└     -1.4124558093213726
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4248551373551246
│     -1.424874159576622
│     -1.4248118692917577
│     -1.4247664631267039
│      ⋮
│     -1.4124807813039801
│     -1.4124681504818153
└     -1.4124558093213726
32×26 Array{Float64,2}:
 -0.240519     0.244334   -0.270873     0.280202    -0.46741      0.415164     0.31015     -0.498458    -0.777919      0.0548947  -0.475657   -0.481293     0.229172    -0.119097    -0.330391    0.549142     -0.166921    -0.468696    0.0687165   0.342482    -0.170038     0.0302964    0.19546      0.588237   -0.370755    0.426719
  1.15725     -0.293784    0.551057     0.477529     0.587366     0.350978    -0.0356071   -0.600027    -0.461523     -0.0292169  -0.0465155  -0.31726      0.301093    -0.176061    -0.415889    0.265473      0.773554    -0.305386    0.277149   -0.118602    -0.945425     0.3333       0.319789     0.440796    0.204103   -0.230652
 -0.304595     0.423515   -0.587703    -0.677455    -0.520263    -0.371842    -0.278027     0.276811    -0.115462     -0.0979309   0.279101   -0.267973    -0.123556     0.270097    -0.651216    0.332814     -0.798867     0.180245    0.310871    0.845594     0.38389      0.548184     0.344113    -0.520625   -0.16177    -0.0700345
 -0.273378     0.450993    0.0420502    0.394225     0.0331787   -0.105829     0.427285    -0.19337      0.0375407     0.385846    0.426477   -0.298441     0.52291      0.320393    -1.12739     0.315118      0.0787017    0.45819     0.0335997   0.156167     0.761812    -0.181745    -0.00710668   0.317112    0.512316   -0.0296548
 -0.626144     0.805402   -0.11116     -0.334119     0.0272588   -0.847175     0.0397256    0.552348    -0.220385      0.706281   -0.238082    0.362013     0.0650803   -0.0107935    0.284071    0.361526      0.182157     0.402678   -0.158835   -0.0563995   -0.15983     -0.127744    -0.00899366   0.195891    0.0160436  -0.0722198
 -0.799403     0.449674   -0.635012    -0.587968    -0.0561089    0.285263     0.114708     0.189884     0.557619     -0.317703   -0.3491      0.495941     0.779303     0.307583     0.567901    0.000628099  -0.08943     -0.268099    0.0913299   0.0100835    0.139048     0.0783167    0.237943     0.8524      0.115556   -0.299421
  0.333498    -0.122456   -0.348505    -0.0961466    0.260535    -0.419857     0.237982     0.304002    -0.676522     -0.311658    0.0970457  -0.284742     0.797923     0.0111656    0.30799     0.0646163    -0.650205    -0.507524   -0.598495   -0.196127    -0.0952127    0.205641     0.170844     0.877095   -0.137321   -0.0483186
  0.309989     0.033927    0.134513    -0.458698     0.394445    -0.217781    -0.0269557    0.462094    -0.125399     -0.390765   -0.041625   -0.148461     0.00102881   0.19995     -0.637596    0.0656884    -0.418561     0.476228    0.391196   -0.164815    -0.296489     0.117332     0.85886      0.780675   -0.0470757  -0.285686
  0.414789    -0.767507   -0.214041    -0.144962    -0.625057    -0.194545    -0.348312    -0.271342     0.393247     -0.18258    -0.17443    -0.17592     -0.374805     0.189872    -0.335477   -0.289753      0.0256699   -0.514372   -0.240714    0.179117    -0.331729     0.286461    -0.382177    -0.485371   -0.243242    0.409362
 -0.0107941   -0.598651   -0.446471    -0.0589925   -0.217065    -0.182405    -0.363298     0.118457    -0.0540023    -0.333716   -0.158225    0.13683      0.0884415   -0.345703     1.2263     -0.339745     -0.218331    -0.188232   -0.410941   -0.225762     0.113607     0.0262488   -0.574714    -0.525235   -0.0217338  -0.205904
  0.411316    -0.083225    0.85541      0.465712    -0.215226     0.426218    -0.27198     -0.0655359    0.236221      0.281149   -0.178525   -0.447703    -0.739601    -0.138088    -0.485866    0.0381194     0.00821417   0.341816   -0.0500368   0.330352     0.103811    -0.112275     0.194017    -0.280339    0.210916    0.319831
  0.0324647    0.0633629   0.139349     0.0352546    0.0307673   -0.0646399    0.14976      0.00908854   0.126436     -0.106368    0.0646112   0.217125     0.207282    -0.0593859   -0.083241   -0.196348     -0.0232645    0.200081    0.0632549   0.0189626   -0.00437031  -0.129439     0.0985694   -0.0458564   0.137693   -0.0359338
  0.241292     0.086243   -0.228655    -0.311814     0.710439     0.219687    -0.0354137    0.332129    -0.392912      0.280005    0.299432    0.30928     -1.02986      0.29109      0.10179     0.306535      0.275989     0.0889956  -0.0247322  -0.330604     0.00325533   0.596082    -0.159769     0.0919089  -0.108965   -0.382503
 -0.384108    -0.305611   -0.0690959    0.500972     0.599734    -0.26806     -0.0673967    0.701415    -0.0354653     0.192446    0.762311    0.66494      0.464437     0.741641     0.740911    0.250735      0.200491     0.0261508   0.0225694   0.266805     0.00667934  -0.0551362   -0.0950744    0.0693935   0.18119     0.00623532
 -0.400887     0.416629    0.173469     0.00865238   0.402415    -0.297038     0.274251    -0.369217     0.0757266     0.0687002   0.704956    0.0353826   -0.00454875   0.589262    -0.134187   -0.91976       0.506828    -0.198928    0.264184   -0.145468    -0.202967    -0.0432692    0.346971     0.0136371   0.226856   -0.159076
 -0.0633319    0.497499    0.104887     0.471341     0.317685     0.0197704   -0.244308     0.0635099    0.0728133    -0.539607    0.578358    0.1125      -0.356954     0.368295    -0.217116   -0.400262      0.759251     0.556137   -0.0980197  -0.021366    -0.426243    -0.228512     0.232203    -0.227655   -0.557927    0.784479
  0.396692     0.474143    0.044941    -0.786539    -0.486006     0.714424    -0.0278452   -0.00841764   0.472838      0.224635   -0.187847    0.0675639   -0.571923     0.159466    -0.309605    0.322191      0.0817858   -0.490859   -0.134825   -0.0788612    0.208298     0.254601    -0.0355707    0.0802935  -0.231203    0.129719
  0.116699     0.130663    0.0576196   -0.831595    -0.0377831    0.0963455   -0.00808368  -0.0897725   -0.19695      -0.0331195  -0.477463    0.407435    -0.61693     -0.117521     0.918586   -0.317119     -0.159962    -0.364296   -0.0420445   0.0295323   -0.658687    -0.00669605   0.165805    -0.0679669  -0.518634    0.0853929
  0.19591     -0.339789   -0.0985425   -0.19469     -0.0928553   -0.187993    -0.525982     0.564595     0.180024     -0.191489    0.642224    0.451121    -0.325344    -0.240274     0.0292272  -0.424659     -0.0370024    0.746162    0.26304    -0.552504     0.0791648    0.113344    -0.15249     -0.430578   -0.0367156  -0.390157
  0.511882     0.0328742  -0.181451    -0.334512     0.178211     0.121403     0.601585     0.0899189   -0.100999     -0.517362    0.378644    0.490216     0.0577153    0.0897883   -0.400218   -0.378635     -0.134254     0.158064   -0.0447028  -0.182546     0.162376     0.0393185   -0.153548    -0.134188   -0.25575     0.0265236
 -0.0293719    0.152101    0.423554     0.0667457   -0.43836      0.303219    -0.435294    -0.109605    -0.264713     -0.174481   -0.0203535  -0.619069     0.313736    -0.402846     0.274607   -0.128056     -0.384007    -0.0974107   0.114332    0.102189     0.430049    -0.188989     0.616036    -0.0541685   0.464496   -0.151797
  0.0292008   -0.263276    0.320119    -0.42639     -0.221957    -0.0294383   -0.088763    -0.0270042   -0.0388206     0.224912   -0.494466    0.429954     0.299418    -0.0222784    0.172591    0.0471184    -0.617414    -0.0123078   0.407786   -0.00481245   0.0183124   -0.20735      0.0947487    0.0214138   0.539789   -1.06835
  0.099039     0.0441506   0.429343    -0.294776     0.00889784   0.217596     0.255225    -0.50198      0.745496     -0.612347   -0.291013   -0.00986389   0.174627    -0.0624062   -0.141731   -0.646792     -0.168623     0.263464    0.0272774   0.0804254   -0.0220403   -0.325188     0.123615    -0.33775     0.302261   -0.0191101
 -0.0680576   -0.388198    0.0154168    0.257003    -0.0576986    0.0731558   -0.440735    -0.188316     0.644631     -0.358095   -0.561615   -0.104175     0.180246     0.00125921   0.326892    0.345098     -0.57743      0.177003   -0.277685   -0.100085     0.682892    -0.0365461   -0.475095    -0.362507    0.0957476   0.292841
 -0.527119     0.0289179   0.521819     0.688259     0.492587    -0.00718841  -0.23588     -0.302364    -0.000377636   0.444439   -0.639122   -0.496315    -0.141852     0.0403137    0.800846    0.328757      0.395465    -0.0689026  -0.270075    0.29318     -0.0173244    0.0230702   -0.201774     0.0450547   0.541145    0.286322
 -0.155259    -0.0657478  -0.275112     0.71807     -0.33879     -0.225904    -0.358033     0.120211    -0.509743      0.649868    0.4359     -0.289288     0.0734067   -0.0280072    0.0441365   0.593948      0.329165    -0.540657   -0.208292   -0.108222     0.126387     0.124251    -0.412264    -0.0658059   0.0513756  -0.0129264
  0.0950021   -0.348026   -0.00713674   0.239086    -0.228583    -0.104347     0.566287     0.0299394    0.174472      0.719601   -0.144483    0.0939184   -0.372677    -0.50926     -0.260113   -0.460788      0.038014     0.227688   -0.338747    0.131315     0.169782    -0.453519    -0.435378    -0.497561    0.452614    0.00558493
  0.112417    -0.105006    0.314335     0.733645     0.571387     0.380699     0.367556     0.212849     0.00501362    0.109348   -0.314899    0.329185     0.053934    -0.503828     0.254637   -0.125926      0.685711     0.379053    0.107636   -0.649746    -0.0276908   -0.541436    -0.336606     0.370524   -0.0075627  -0.331542
  0.00860989  -0.0494496   0.0304159    0.185391    -0.252043    -0.104989    -0.151711    -0.130343    -0.126766     -0.289306   -0.0400387  -0.250906     0.327425     0.0240827    0.141848   -0.282705     -0.203302    -0.520927   -0.117482    0.215523    -0.418387    -0.119685     0.255867     0.153933    0.133557    0.170895
 -0.104072     0.20612    -0.178318     0.343501     0.387706    -0.183645     0.209614     0.0534298   -0.0609119    -0.284625    0.294016   -0.185772     0.112809     0.0708839   -0.0476366  -0.0408571     0.189299     0.128864   -0.49409     0.104557    -0.053761     0.161809     0.0812231    0.106086   -0.198285    0.681137
 -0.0414341    0.079643    0.093001     0.0698738   -0.121157     0.130973     0.0354179   -0.00749698  -0.0323359     0.162939   -0.12637    -0.00538068  -0.0547722   -0.0129271   -0.350771    0.155196      0.0043733    0.297855    0.152025    0.0213554    0.174595    -0.142968     0.0403932    0.0443402   0.083528    0.0097506
 -0.0299639   -0.02491    -0.0732904   -0.185815     0.171549    -0.0899913   -0.137986     0.195762    -0.0176483     0.109242    0.0274923   0.125088    -0.128943     0.19857      0.283322    0.0280092     0.0246765   -0.0849779  -0.0919776  -0.08907     -0.124704     0.253109    -0.03383      0.119983    0.0458849  -0.28521[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412444
[ Info: iteration 2, average log likelihood -1.412432
[ Info: iteration 3, average log likelihood -1.412420
[ Info: iteration 4, average log likelihood -1.412409
[ Info: iteration 5, average log likelihood -1.412398
[ Info: iteration 6, average log likelihood -1.412387
[ Info: iteration 7, average log likelihood -1.412376
[ Info: iteration 8, average log likelihood -1.412366
[ Info: iteration 9, average log likelihood -1.412355
[ Info: iteration 10, average log likelihood -1.412345
┌ Info: EM with 100000 data points 10 iterations avll -1.412345
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.417336e+05
      1       7.134353e+05      -2.282983e+05 |       32
      2       6.975913e+05      -1.584393e+04 |       32
      3       6.915526e+05      -6.038700e+03 |       32
      4       6.884298e+05      -3.122822e+03 |       32
      5       6.865600e+05      -1.869831e+03 |       32
      6       6.852303e+05      -1.329657e+03 |       32
      7       6.842351e+05      -9.952336e+02 |       32
      8       6.834085e+05      -8.265984e+02 |       32
      9       6.827006e+05      -7.079192e+02 |       32
     10       6.821086e+05      -5.919217e+02 |       32
     11       6.815780e+05      -5.306944e+02 |       32
     12       6.810833e+05      -4.946295e+02 |       32
     13       6.806696e+05      -4.137711e+02 |       32
     14       6.803168e+05      -3.527925e+02 |       32
     15       6.800240e+05      -2.928043e+02 |       32
     16       6.797561e+05      -2.678450e+02 |       32
     17       6.795246e+05      -2.315053e+02 |       32
     18       6.793301e+05      -1.945034e+02 |       32
     19       6.791533e+05      -1.768193e+02 |       32
     20       6.790001e+05      -1.531792e+02 |       32
     21       6.788724e+05      -1.277376e+02 |       32
     22       6.787650e+05      -1.073217e+02 |       32
     23       6.786639e+05      -1.011238e+02 |       32
     24       6.785639e+05      -9.999401e+01 |       32
     25       6.784670e+05      -9.688705e+01 |       32
     26       6.783707e+05      -9.631768e+01 |       32
     27       6.782796e+05      -9.117004e+01 |       32
     28       6.781943e+05      -8.526376e+01 |       32
     29       6.781192e+05      -7.506520e+01 |       32
     30       6.780524e+05      -6.681198e+01 |       32
     31       6.779961e+05      -5.634736e+01 |       32
     32       6.779379e+05      -5.821165e+01 |       32
     33       6.778835e+05      -5.436734e+01 |       32
     34       6.778251e+05      -5.837121e+01 |       32
     35       6.777722e+05      -5.288794e+01 |       32
     36       6.777284e+05      -4.384430e+01 |       32
     37       6.776797e+05      -4.866185e+01 |       32
     38       6.776330e+05      -4.668428e+01 |       32
     39       6.775842e+05      -4.885472e+01 |       32
     40       6.775390e+05      -4.517314e+01 |       32
     41       6.774982e+05      -4.079311e+01 |       32
     42       6.774608e+05      -3.737093e+01 |       32
     43       6.774243e+05      -3.651738e+01 |       32
     44       6.773904e+05      -3.396620e+01 |       32
     45       6.773574e+05      -3.299194e+01 |       32
     46       6.773258e+05      -3.154628e+01 |       32
     47       6.772981e+05      -2.770516e+01 |       32
     48       6.772721e+05      -2.600812e+01 |       32
     49       6.772457e+05      -2.639957e+01 |       32
     50       6.772176e+05      -2.811665e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 677217.5911107576)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423909
[ Info: iteration 2, average log likelihood -1.418997
[ Info: iteration 3, average log likelihood -1.417702
[ Info: iteration 4, average log likelihood -1.416774
[ Info: iteration 5, average log likelihood -1.415813
[ Info: iteration 6, average log likelihood -1.414916
[ Info: iteration 7, average log likelihood -1.414272
[ Info: iteration 8, average log likelihood -1.413889
[ Info: iteration 9, average log likelihood -1.413663
[ Info: iteration 10, average log likelihood -1.413514
[ Info: iteration 11, average log likelihood -1.413404
[ Info: iteration 12, average log likelihood -1.413316
[ Info: iteration 13, average log likelihood -1.413241
[ Info: iteration 14, average log likelihood -1.413176
[ Info: iteration 15, average log likelihood -1.413118
[ Info: iteration 16, average log likelihood -1.413065
[ Info: iteration 17, average log likelihood -1.413017
[ Info: iteration 18, average log likelihood -1.412973
[ Info: iteration 19, average log likelihood -1.412932
[ Info: iteration 20, average log likelihood -1.412894
[ Info: iteration 21, average log likelihood -1.412859
[ Info: iteration 22, average log likelihood -1.412826
[ Info: iteration 23, average log likelihood -1.412796
[ Info: iteration 24, average log likelihood -1.412768
[ Info: iteration 25, average log likelihood -1.412741
[ Info: iteration 26, average log likelihood -1.412717
[ Info: iteration 27, average log likelihood -1.412694
[ Info: iteration 28, average log likelihood -1.412673
[ Info: iteration 29, average log likelihood -1.412653
[ Info: iteration 30, average log likelihood -1.412634
[ Info: iteration 31, average log likelihood -1.412617
[ Info: iteration 32, average log likelihood -1.412600
[ Info: iteration 33, average log likelihood -1.412584
[ Info: iteration 34, average log likelihood -1.412570
[ Info: iteration 35, average log likelihood -1.412555
[ Info: iteration 36, average log likelihood -1.412542
[ Info: iteration 37, average log likelihood -1.412529
[ Info: iteration 38, average log likelihood -1.412516
[ Info: iteration 39, average log likelihood -1.412504
[ Info: iteration 40, average log likelihood -1.412492
[ Info: iteration 41, average log likelihood -1.412480
[ Info: iteration 42, average log likelihood -1.412469
[ Info: iteration 43, average log likelihood -1.412458
[ Info: iteration 44, average log likelihood -1.412447
[ Info: iteration 45, average log likelihood -1.412436
[ Info: iteration 46, average log likelihood -1.412425
[ Info: iteration 47, average log likelihood -1.412415
[ Info: iteration 48, average log likelihood -1.412405
[ Info: iteration 49, average log likelihood -1.412394
[ Info: iteration 50, average log likelihood -1.412384
┌ Info: EM with 100000 data points 50 iterations avll -1.412384
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.588667    -0.0920139  -0.0499059   0.448552    -0.195234    -0.0647739   -0.138722    0.212398     -0.750495   -0.497613     0.0203164   -0.542245     0.206962   -0.357809   -0.355222     -0.105916    -0.126935     0.0843719  -0.0141389    0.191113    -0.67025     0.135203     0.930456    0.661062   -0.277027     0.294739
  0.0607973   -0.0755243  -0.318909    0.564282     0.219606    -0.0750215   -0.299296    0.392025     -0.779133    0.515962     0.679221     0.102725    -0.299468    0.188998    0.237267      0.632194     0.444483    -0.160394   -0.191372    -0.351693     0.109754    0.304148    -0.23635     0.0146     -0.0300601   -0.099316
 -0.270841     0.354399    0.124193    0.405585     0.33336     -0.0822268   -0.0351582  -0.000812092   0.256126   -0.220313     0.81942      0.100912    -0.131042    0.526076   -0.137991     -0.611176     0.792382     0.227686   -0.142979    -0.0638711   -0.278525   -0.0717483    0.106063   -0.292074   -0.141596     0.482693
  0.170751    -0.623278   -0.157149    0.609873     0.0848851    0.00430488   0.457761    0.276946      0.0395812   0.400404     0.0441209    0.271337    -0.531515   -0.45342    -0.415254     -0.637121    -0.0465057    0.302602   -0.253287    -0.309148    -0.239001   -0.35583     -0.814205   -0.298158    0.201966    -0.129676
 -0.15457     -0.161091   -0.0747672  -0.496342    -1.07574     -0.232006     0.0147585   0.371015      0.264008    0.316477    -0.307452    -0.147591     0.260998   -0.480798   -0.000395414  -0.205411    -0.663494     0.19364    -0.0548214    0.233622     0.127943   -0.268064     0.186686   -0.590238    0.778618    -0.380152
  0.607253     0.119956    0.338944   -0.464864    -0.507707     0.332247     0.0701983  -0.279453      0.638614    0.195501    -0.442604     0.0195866   -0.707489    0.0126034  -0.282447      0.00726841   0.217115     0.0236976  -0.311002     0.161964     0.0082526  -0.0130023   -0.150756   -0.394379   -0.0867223    0.150788
 -0.291742     0.230194   -0.163839    0.358286    -0.38419      0.306429     0.144524   -0.612084     -0.5058      0.176388    -0.390064    -0.636091     0.332483    0.117554   -0.139897      0.607532     0.0440197   -0.711443   -0.129567     0.425068    -0.268898   -0.0290532   -0.0225155   0.419457   -0.0477725    0.411293
  0.0365911    0.306895    0.0585038   0.144726    -0.253324     0.628706     0.591853   -0.258102     -0.206409    0.577428    -0.0920958    0.0961178    0.0243687  -0.509282   -0.65104       0.177338     0.0498892    0.239271    0.305722    -0.19902      1.02037    -0.250155    -0.261694    0.14091     0.0851771   -0.0962218
 -0.0183703   -0.536578   -0.0750281   0.251184    -0.303521     0.375966    -0.164435   -0.7032        0.276534   -0.677017    -0.276754    -0.191332     0.217422   -0.214939   -0.0197423    -0.349137    -0.420185     0.156549    0.0680508    0.201404     0.453877   -0.241856    -0.161219   -0.401045   -0.0199973    0.318582
  0.255085    -0.689984   -0.359562   -0.285691    -0.672384    -0.0950575   -0.752169    0.21309       0.120578   -0.257988    -0.673317    -0.036974    -0.240383   -0.230811    0.361171      0.305374     0.0285389   -0.858857   -0.412045    -0.240496    -0.153035    0.478251    -0.440854   -0.180422   -0.433337     0.436808
  0.139015    -0.0456101   0.215416    0.112724     0.0889786    0.0837017   -0.0285826  -0.110395     -0.0125836   0.0378928   -0.0367955    0.0113514   -0.081749   -0.0367449  -0.0851028    -0.0325089    0.0807405    0.0548719   0.0695972    0.0770727   -0.109268    0.0413462    0.0948342   0.0143062   0.0731085   -0.0481528
  0.00234835  -0.221869    0.107344   -0.109282    -0.0568688    0.151896    -0.18219    -0.0454885     0.410281    0.0931272   -0.256049     0.00559996   0.105088    0.242988    0.186169      0.0665117   -0.0943239   -0.15076     0.0192364   -0.0572036   -0.0562855   0.092559    -0.199707    0.132748    0.264304    -0.299993
 -0.258887     0.141518   -0.152592    0.357353     0.534547    -0.407468     0.119596    0.155071     -0.0944674  -0.14618      0.15274     -0.082622     0.381267    0.320576    0.462815      0.163868    -0.110532     0.0261171  -0.684569     0.183681    -0.13625     0.251997     0.050033    0.446038   -0.124872     0.41724
 -0.0775239    0.401355   -0.284387   -0.852279    -0.133639    -0.0398031   -0.217404    0.131556     -0.0838246   0.00896253   0.383842    -0.275027    -0.402067    0.677158   -0.399258      0.301331    -0.352033    -0.244922    0.244893     0.54836     -0.0693842   0.827705     0.391322   -0.101414   -0.0255477   -0.0505858
  0.168228     0.152869    0.596736   -0.542735     0.0947442    0.0978759    0.266802   -0.31429       0.408104   -0.47945     -0.198227     0.129684     0.331815    0.156248   -0.208119     -0.515337    -0.267264     0.301253    0.256338     0.0127049   -0.126268   -0.281158     0.3619     -0.103931    0.476327    -0.361048
 -0.0214792   -0.0584546  -0.0256368  -0.116049     0.0268227    0.0295915   -0.101164    0.374013     -0.265714    0.218348     0.056343     0.0860631   -0.189626   -0.163412    0.033541      0.0382325   -0.00860748   0.182836    0.180081    -0.265358     0.240997    0.145739     0.0180785   0.0319962   0.00709379  -0.605524
  0.312675    -0.245608    0.538899    0.76513      0.591007     0.501045     0.228391   -0.0349906     0.0425649   0.0746407   -0.341804     0.184496     0.0615515  -0.390254    0.553491     -0.161797     0.945677     0.0643337  -0.00580062  -0.469946    -0.280511   -0.514511    -0.155822    0.441635    0.126714    -0.0907024
 -0.0497994    0.166947    0.121373   -0.81997      0.0932351    0.207366     0.0150441  -0.113962     -0.337223    0.0262194   -0.44498      0.391246    -0.655      -0.10574     0.908627     -0.357856    -0.25883     -0.443148    0.0722282   -0.0518127   -0.734048   -0.0307285    0.333375    0.0546831  -0.516341    -0.0390515
  0.100929    -0.0638305   0.245184   -0.0757991    0.00459948  -0.100013    -0.325277    0.321503     -0.798144   -0.12533     -0.238163     0.0973442    0.596565   -0.163323    0.387852      0.461329    -0.93046      0.0185801   0.263806     0.0224405    0.250138   -0.143618     0.415207    0.653036    0.477926    -0.621443
 -0.475811     0.315813    0.0812678   0.123318     0.159545    -0.122116    -0.449011    0.227192     -0.0788321   0.261991    -0.176764     0.196255    -0.208014    0.242579   -0.284463      0.387859     0.0914869    0.612167    0.32483      0.109173    -0.269417   -0.29354      0.379163    0.29726    -0.0352982    0.0442208
 -0.554329    -0.173065    0.479884    0.727482     0.472772     0.025811    -0.379698   -0.0512078     0.532629    0.12469     -0.560691    -0.198394    -0.0655748   0.16613     0.740666      0.190228    -0.0143572    0.229314   -0.387751    -0.0327838    0.350012    0.033419    -0.477546   -0.432166    0.616924     0.224618
 -0.595854     0.580414   -0.286363   -0.341316     0.262597    -0.0965679    0.496937    0.340803      0.0335989   0.0631671   -0.210959     0.175388     0.35616     0.35681     0.0252764    -0.114688     0.0692802    0.0436968  -0.0555786   -0.616677     0.0420982  -0.0474455    0.455862    1.17454     0.153279    -0.359249
 -0.361703     0.176314    0.0580472  -0.376015     0.139582    -0.877507     0.18861     0.230913     -0.26481     0.81258     -0.301368     0.447798    -0.044853   -0.0551138   0.519459      0.364232     0.508924     0.194869   -0.073818     0.22705     -0.142027   -0.110565    -0.788064   -0.193175   -0.00515341  -0.0789897
 -0.26078      0.307193   -0.0650943   0.513416     0.00593431  -0.352813     0.18807    -0.0457551     0.110252    0.249112     0.564807    -0.38106      0.658855    0.444369   -1.0808        0.446643     0.00142996   0.517308   -0.0363791    0.262216     0.83218    -0.187661    -0.0937392   0.219172    0.468631     0.00807621
 -0.207646     0.267311    0.388362    0.569896    -0.0735781   -0.231645     0.15287    -0.240033     -0.0661513   0.420435    -0.178275    -0.594485    -0.0537121  -0.493691    0.133913     -0.223785     0.275276    -0.251437   -0.213943     0.424412     0.33789    -0.287479     0.304603   -0.240494    0.572242     0.203944
  0.0341791   -0.169268    0.419635    0.314569    -0.14039      0.379235    -0.850593    0.228813      0.411164   -0.306703     0.00828452  -0.428312    -0.350506   -0.300571    0.192968      0.396286    -0.767606     0.0501238   0.0480153    0.011181     0.71589     0.0345762   -0.201222   -0.471871   -0.211286     0.352291
  0.696927    -0.537333   -0.378644   -0.415648     0.275784    -0.270778     0.490202    0.0966519    -0.298565   -0.193304     0.108168    -0.159297     0.534089   -0.135778    0.558649     -0.0434449   -0.560834    -0.79484    -0.79611     -0.167435     0.205347    0.369655    -0.442536    0.36681     0.0374557   -0.264968
  0.464635    -0.334219   -0.0940848  -0.535648     0.107831    -0.246746    -0.438686    0.561428      0.274524   -0.374182     0.664051     0.641566    -0.357663   -0.0534451   0.201488     -0.58264     -0.118561     0.813624    0.176456    -0.50113      0.0123256   0.149952    -0.0856466  -0.41901    -0.146591    -0.4532
 -0.182701    -0.192879   -0.178169    0.214618    -0.138049    -0.584891    -0.358081    0.0698544    -0.151582   -0.00819221   0.24606      0.152375     0.679828    0.226322    0.224435     -0.578398    -0.210153    -0.719662    0.249411     0.00404854  -0.551132   -0.0998088    0.31839     0.0233874   0.292331    -0.326913
  0.776602     0.396437   -0.0964514  -0.384667     0.584799     0.198546     0.741756    0.0646554    -0.192552   -0.555609     0.352503     0.374293    -0.199702    0.164744   -0.46248      -0.0370537   -0.171442     0.240582   -0.067969    -0.093228     0.166423    0.0171435    0.16472     0.249424   -0.648085     0.214911
  0.0885579    0.0799232  -0.0803015  -0.00101754  -0.00709118  -0.0211865    0.135268   -0.00324992   -0.0257191  -0.205833     0.137827     0.041799    -0.0096698   0.0210948  -0.138958     -0.177239     0.00819305   0.0321243  -0.134956    -0.00532354  -0.0403462   0.0176262    0.0197963  -0.0971659  -0.0380236    0.250876
 -0.707215     0.355296   -1.2228     -0.714886    -0.154464    -0.144836    -0.107858    0.331554      0.362347   -0.599731    -0.0723598    0.571479     0.443782   -0.110376    0.680271     -0.110161    -0.53642     -0.102079   -0.0718125   -0.00217521   0.480937   -0.00903459  -0.246965   -0.20521    -0.312906    -0.113712[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412375
[ Info: iteration 2, average log likelihood -1.412365
[ Info: iteration 3, average log likelihood -1.412355
[ Info: iteration 4, average log likelihood -1.412346
[ Info: iteration 5, average log likelihood -1.412337
[ Info: iteration 6, average log likelihood -1.412328
[ Info: iteration 7, average log likelihood -1.412319
[ Info: iteration 8, average log likelihood -1.412310
[ Info: iteration 9, average log likelihood -1.412301
[ Info: iteration 10, average log likelihood -1.412293
┌ Info: EM with 100000 data points 10 iterations avll -1.412293
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
