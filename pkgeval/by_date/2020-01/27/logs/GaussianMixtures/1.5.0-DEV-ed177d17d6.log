Julia Version 1.5.0-DEV.158
Commit ed177d17d6 (2020-01-27 16:45 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed SortingAlgorithms ── v0.3.1
 Installed GaussianMixtures ─── v0.3.0
 Installed Blosc ────────────── v0.5.1
 Installed Compat ───────────── v2.2.0
 Installed Arpack ───────────── v0.4.0
 Installed QuadGK ───────────── v2.3.1
 Installed StatsFuns ────────── v0.9.3
 Installed Distributions ────── v0.22.3
 Installed CMakeWrapper ─────── v0.2.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed OrderedCollections ─ v1.1.0
 Installed BinaryProvider ───── v0.5.8
 Installed SpecialFunctions ─── v0.9.0
 Installed JLD ──────────────── v0.9.1
 Installed URIParser ────────── v0.4.0
 Installed Parameters ───────── v0.12.0
 Installed Distances ────────── v0.8.2
 Installed FileIO ───────────── v1.2.1
 Installed BinDeps ──────────── v1.0.0
 Installed Missings ─────────── v0.4.3
 Installed NearestNeighbors ─── v0.4.4
 Installed StatsBase ────────── v0.32.0
 Installed DataStructures ───── v0.17.9
 Installed StaticArrays ─────── v0.12.1
 Installed LegacyStrings ────── v0.4.1
 Installed DataAPI ──────────── v1.1.0
 Installed PDMats ───────────── v0.9.11
 Installed ScikitLearnBase ──── v0.5.0
 Installed Rmath ────────────── v0.6.0
 Installed FillArrays ───────── v0.8.4
 Installed CMake ────────────── v1.1.2
 Installed Clustering ───────── v0.13.3
 Installed HDF5 ─────────────── v0.12.5
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_ysZ4SJ/Project.toml`
 [no changes]
  Updating `/tmp/jl_ysZ4SJ/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_rrio7h/Project.toml`
 [no changes]
  Updating `/tmp/jl_rrio7h/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_0o3NuP/Project.toml`
 [no changes]
  Updating `/tmp/jl_0o3NuP/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_BSwDBC/Project.toml`
 [no changes]
  Updating `/tmp/jl_BSwDBC/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_KD8c9S/Project.toml`
 [no changes]
  Updating `/tmp/jl_KD8c9S/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_KD8c9S/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.243525661851811e6, [31181.692003654836, 68818.30799634517], [-12806.997369647597 -4080.5869749776016 -27703.17233501684; 12259.911738921586 3893.54900916705 27802.40561490047], [[40142.32218649949 -1404.0958742654207 -3640.735134776002; -1404.095874265421 26880.48914678063 1186.6182074529565; -3640.7351347760014 1186.6182074529565 52187.456177808155], [60388.17575408489 1773.0260458033067 3759.1564720618608; 1773.026045803307 73259.42833297886 -1402.2111860431723; 3759.1564720618608 -1402.2111860431726 47463.7752787667]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.201718e+03
      1       9.936826e+02      -2.080350e+02 |        7
      2       9.350447e+02      -5.863788e+01 |        4
      3       9.207832e+02      -1.426152e+01 |        0
      4       9.207832e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 920.7832013808952)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.075993
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.733189
[ Info: iteration 2, lowerbound -3.572341
[ Info: iteration 3, lowerbound -3.409497
[ Info: iteration 4, lowerbound -3.243624
[ Info: iteration 5, lowerbound -3.092873
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.962005
[ Info: iteration 7, lowerbound -2.864485
[ Info: dropping number of Gaussions to 4
[ Info: iteration 8, lowerbound -2.788327
[ Info: iteration 9, lowerbound -2.716177
[ Info: iteration 10, lowerbound -2.660723
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.597352
[ Info: iteration 12, lowerbound -2.525521
[ Info: iteration 13, lowerbound -2.459429
[ Info: iteration 14, lowerbound -2.404523
[ Info: iteration 15, lowerbound -2.362833
[ Info: iteration 16, lowerbound -2.332340
[ Info: iteration 17, lowerbound -2.313074
[ Info: iteration 18, lowerbound -2.307463
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302927
[ Info: iteration 20, lowerbound -2.299261
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299255
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Jan 28 03:17:31 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Jan 28 03:17:38 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Tue Jan 28 03:17:41 2020: EM with 272 data points 0 iterations avll -2.075993
5.8 data points per parameter
, Tue Jan 28 03:17:43 2020: GMM converted to Variational GMM
, Tue Jan 28 03:17:51 2020: iteration 1, lowerbound -3.733189
, Tue Jan 28 03:17:51 2020: iteration 2, lowerbound -3.572341
, Tue Jan 28 03:17:51 2020: iteration 3, lowerbound -3.409497
, Tue Jan 28 03:17:51 2020: iteration 4, lowerbound -3.243624
, Tue Jan 28 03:17:51 2020: iteration 5, lowerbound -3.092873
, Tue Jan 28 03:17:52 2020: dropping number of Gaussions to 7
, Tue Jan 28 03:17:52 2020: iteration 6, lowerbound -2.962005
, Tue Jan 28 03:17:52 2020: iteration 7, lowerbound -2.864485
, Tue Jan 28 03:17:52 2020: dropping number of Gaussions to 4
, Tue Jan 28 03:17:52 2020: iteration 8, lowerbound -2.788327
, Tue Jan 28 03:17:52 2020: iteration 9, lowerbound -2.716177
, Tue Jan 28 03:17:52 2020: iteration 10, lowerbound -2.660723
, Tue Jan 28 03:17:52 2020: dropping number of Gaussions to 3
, Tue Jan 28 03:17:52 2020: iteration 11, lowerbound -2.597352
, Tue Jan 28 03:17:52 2020: iteration 12, lowerbound -2.525521
, Tue Jan 28 03:17:52 2020: iteration 13, lowerbound -2.459429
, Tue Jan 28 03:17:52 2020: iteration 14, lowerbound -2.404523
, Tue Jan 28 03:17:52 2020: iteration 15, lowerbound -2.362833
, Tue Jan 28 03:17:52 2020: iteration 16, lowerbound -2.332340
, Tue Jan 28 03:17:52 2020: iteration 17, lowerbound -2.313074
, Tue Jan 28 03:17:52 2020: iteration 18, lowerbound -2.307463
, Tue Jan 28 03:17:52 2020: dropping number of Gaussions to 2
, Tue Jan 28 03:17:52 2020: iteration 19, lowerbound -2.302927
, Tue Jan 28 03:17:52 2020: iteration 20, lowerbound -2.299261
, Tue Jan 28 03:17:52 2020: iteration 21, lowerbound -2.299256
, Tue Jan 28 03:17:52 2020: iteration 22, lowerbound -2.299255
, Tue Jan 28 03:17:52 2020: iteration 23, lowerbound -2.299254
, Tue Jan 28 03:17:52 2020: iteration 24, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 25, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 26, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 27, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 28, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 29, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 30, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 31, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 32, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 33, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 34, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 35, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 36, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 37, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 38, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 39, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 40, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 41, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 42, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 43, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 44, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 45, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 46, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 47, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 48, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 49, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: iteration 50, lowerbound -2.299253
, Tue Jan 28 03:17:52 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398587, 178.04509222601416]
β = [95.95490777398587, 178.04509222601416]
m = [2.0002292577753678 53.85198717246127; 4.250300733269906 79.2868669443618]
ν = [97.95490777398587, 180.04509222601416]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948439 -0.008953123827345952; 0.0 0.012748664777409213], [0.18404155547484305 -0.007644049042327302; 0.0 0.008581705166333406]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9937462784649723
avll from llpg:  -0.9937462784649729
avll direct:     -0.9937462784649729
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9691502663716817
avll from llpg:  -0.9691502663716817
avll direct:     -0.9691502663716817
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.108967     0.233349     0.0500746    0.0522581   -0.0414321  -0.196489   -0.128251     0.0368258   -0.0968523   -0.148342     0.169471    -0.0790659     0.00199254   0.048553    -0.0778757    0.0402103    0.0401094  -0.24567     -0.0231297   -0.0609959    -0.0186362    0.0378457   -0.121584     -0.026861    -0.0486349    0.012128
 -0.0473196   -0.138138     0.138566    -0.0254161   -0.167193   -0.0269308   0.147767    -0.0129934    0.0158617   -0.0165851    0.00640244   0.0485086     0.0692778    0.0282992    0.0364728    0.0340013    0.0734403  -0.0365197   -0.228383    -0.0481892     0.144057    -0.0655562   -0.0585287    -0.0595308   -0.0727751    0.0925982
 -0.030343     0.173852     0.0407519    0.0881245   -0.14793    -0.0913987  -0.143194    -0.139968    -0.0463971    0.00867594   0.110929    -0.0681857     0.00332275   0.054026     0.0697563    0.0496016    0.0654931  -0.0717576   -0.0479553   -0.012562      0.0107013    0.109501    -0.123915     -0.00880906  -0.0693757    0.0188087
  0.0604371    0.0606132    0.221592     0.182863    -0.0854356   0.133475    0.0355844   -0.1353       0.106157    -0.0537306    0.0950073   -0.12612       0.08172     -0.0549938   -0.214441    -0.202488    -0.0201722   0.148132     0.0501102   -0.0485407     0.0948126   -0.0744886   -0.105254      0.0260154    0.092478    -0.101725
  0.0690149   -0.243275     0.00199091  -0.0325652   -0.105175   -0.0710225   0.0279661   -0.057876     0.0444136    0.00956763   0.107729     0.11523       0.0345694   -0.0882866    0.0111306    0.221068    -0.136349   -0.162503    -0.233489    -0.127448     -0.136755     0.0277845   -0.0374566    -0.0040287    0.0515703   -0.232952
 -0.0813871    0.1498       0.154872    -0.067792    -0.0373406  -0.210384   -0.0221866   -0.206123    -0.155587     0.0638881   -0.100971     0.0570188     0.142555     0.0917967    0.0516821   -0.0753145    0.111227    0.00444208   0.106372    -0.0314094    -0.171242    -0.0290883    0.0667531    -0.0265315   -0.0671392   -0.0177945
  0.126943    -0.182731    -0.0734622    0.0980453    0.045337   -0.0525243  -0.0364757   -0.233972     0.0438466   -0.0588831   -0.0825111    0.138592     -0.0672485   -0.00597518  -0.0911153   -0.0199903    0.129746   -0.0877407    0.123949    -0.0521804    -0.0603629   -0.016942     0.180193      0.135152     0.0755      -0.00724082
  0.011702     0.0126928   -0.00629729  -0.105114    -0.0847451  -0.0119345   0.0238293    0.0340443   -0.14631      0.15604     -0.0370952   -0.0505956     0.0139983   -0.0353337    0.178788     0.0328405    0.0797775   0.113181    -0.051905     0.0701608    -0.0466372    0.0965213    0.0781956     0.0114029    0.202393     0.0589023
 -0.0333723   -0.094191     0.0256034    0.106       -0.0651239  -0.0676315  -0.0392682   -0.125145     0.043488     0.0270521   -0.0955718    0.0135018     0.127048     0.239877     0.0392272   -0.110559     0.112811   -0.193133    -0.159141    -0.15492       0.0636649    0.17233     -0.0877677    -0.0199659    0.0234571   -0.023304
 -0.00895828  -0.177941     0.102628    -0.0188148    0.0148267   0.0732394   0.115173    -0.042878     0.032496    -0.0439769    0.0865949    0.0469399    -0.0209117    0.0733743    0.203035    -0.0707741   -0.039972   -0.00868265  -0.0112817   -0.000511129  -0.0435948   -0.129081     0.1185        0.0416635    0.0675656   -0.0923414
 -0.0570024   -0.0208625   -0.121596    -0.112029     0.0390307   0.138167   -0.0432544   -0.133523     0.0382979    0.0323461    0.0199599   -0.108752      0.21569     -0.0716422    0.0344318    0.15444      0.0321685   0.0402198   -0.116976     0.0318468     0.312795    -0.0668573    0.10853      -0.0905205    0.0217086    0.0648903
 -0.10976     -0.162328     0.0145038    0.00200158   0.150401   -0.0057699   0.0166805   -0.0567183   -0.0140293    0.0284401    0.0639722    0.0279855     0.0372743    0.152303    -0.0417298   -0.16335     -0.0297984  -0.0375992    0.0569506   -0.0636775    -0.0168449   -0.0782354    0.0270666    -0.245998    -0.0449171   -0.0795821
  0.0435213   -0.074577    -0.196689     0.0647536    0.187126   -0.0548892  -0.117132    -0.0953531    0.132211     0.121169    -0.245897    -0.0879173     0.0292222    0.124241     0.0777019    0.0468577    0.102155   -0.138791     0.048389     0.162605     -0.053809    -0.00341463  -0.246189      0.0602008    0.0684995   -0.0497971
  0.0979217    0.0249874   -0.0613896   -0.138608    -0.0657322   0.144481    0.0483856    0.00626405   0.132257     0.257977    -0.0274251    0.133274     -0.0376558    0.0696055    0.0587665    0.0283722    0.237567    0.0376999   -0.144147    -0.0646598     0.0318595   -0.04896     -0.0125068     0.055695    -0.0703116    0.0353656
  0.153532     0.0306569    0.0966938    0.163596    -0.108689   -0.179078   -0.00416104  -0.0785177   -0.00175077   0.0802216    0.0741085    0.0264565    -0.00742877  -0.148651    -0.00543879  -0.0185422    0.0374104   0.0314872    0.0100683   -0.00580165    0.136626     0.0425911   -0.247532     -0.0634999   -0.0128575   -0.0719662
 -0.0495285   -0.0766509    0.27567      0.0329212   -0.0879975   0.0264555   0.0611954    0.00245947   0.0615065    0.00394245   0.0302002   -0.0660909     0.0632679    0.158006     0.0232532   -0.0250853    0.247443   -0.114107     0.031151    -0.126058     -0.00522802   0.292864    -0.0454439    -0.0636205    0.0130488    0.0742103
 -0.00123498  -0.047744     0.0685414   -0.0495101   -0.0287602   0.0108511   0.118651     0.102579    -0.0448139    0.0392027   -0.00390092   0.0971336     0.0682516    0.0292279   -0.188524    -0.2211       0.0950093  -0.0322186   -0.0567281   -0.149166     -0.0681269    0.185498     0.116517      0.0259689   -0.00783342   0.0592591
  0.0563246    0.170344    -0.048856     0.0137325   -0.129737   -0.236428    0.142526    -0.0795479    0.0330383   -0.137411     0.0735906   -0.273693     -0.0704704    0.0680192    0.0686604   -0.112982    -0.256207   -0.0667135   -0.204624     0.0126597     0.153245     0.023739     0.112089      0.173666    -0.0173287    0.112334
  0.0255742   -0.133167     0.0392733   -0.0372692   -0.127449   -0.0543659  -0.136128     0.105434     0.0614219   -0.0166683    0.00795118  -0.0823908    -0.030065    -0.164587    -0.0208818   -0.0753054    0.137084   -0.0253254    0.00439367   0.0261955    -0.0458147   -0.0590715    0.0600798    -0.0583157    0.159437     0.118119
  0.0701411   -0.071191     0.0330177    0.138982     0.035499    0.126841   -0.0721042    0.0750373    0.0884616   -0.0213101   -0.253495    -0.124353     -0.0481693    0.0959193    0.0137763   -0.0682406    0.105069   -0.127218    -0.05387     -0.0328048    -0.0907491    0.107834    -0.12431       0.00866844   0.143891     0.0518005
 -0.234127    -0.106408    -0.121999     0.0498944   -0.0795946  -0.0123246   0.0210656    0.0362054   -0.027727     0.0177066   -0.111689    -0.00119216    0.0526339    0.122858    -0.168558    -0.0965876   -0.0108153  -0.0396105   -0.111053     0.126923      0.0454096   -0.0391068    0.0162049    -0.00346839  -0.156517    -0.0405301
  0.204988     0.160994     0.0666302   -0.138032    -0.147408   -0.112061   -0.0518006   -0.00124183  -0.32772     -0.0416993   -0.100697     0.0205333     0.0202917    0.191645    -0.0369      -0.1102      -0.110709    0.0541644    0.0164289   -0.16874       0.0234962    0.0697833    7.0476e-6     0.0712135   -0.10828      0.0381164
  0.0490964    0.0861895   -0.032176     0.145749     0.0306356   0.0104722   0.0649731    0.0741884   -0.0159585   -0.199107     0.0080574   -0.0763818    -0.00716467   0.0869242   -0.0183584   -0.0218283    0.0214279   0.0748471    0.166854     0.234158      0.115177     0.198555     0.0777027     0.00968974  -0.109346    -0.199385
  0.0646018   -0.097554    -0.0937634    0.0237548    0.0612171   0.0532037   0.0555328   -0.137988     0.0411864   -0.0471883   -0.188512     0.0223245    -0.0940244    0.0338921    0.0822881    0.0433591    0.0773744   0.185074     0.080252     0.127921     -0.0174476    0.0853675   -0.0711229    -0.0440088    0.0174602    0.0859916
  0.0772528    0.0391098   -0.090493    -0.0488904   -0.167597    0.0435971  -0.0123482    0.170047     0.127842     0.0381747   -0.0424429    0.148162     -0.0610842    0.044196     0.0860678   -0.0281374   -0.1413      0.0257926    0.0501159   -0.216443     -0.0207523    0.123985     0.00452375    0.025173     0.070382    -0.112732
 -0.129252    -0.0667775   -0.0699912   -0.0285897   -0.0790998   0.0381835  -0.131511     0.0296096    0.057606    -0.0440886    0.151105     0.192333      0.00780588  -0.160719     0.0256598   -0.0408948   -0.113099   -0.15847     -0.0169396   -0.00273454   -0.0372471   -0.0895828    0.000636551  -0.034495     0.104585     0.0638425
  0.165389    -0.00579891   0.0410841    0.136134    -0.0952511  -0.0145864  -0.15939     -0.0775148   -0.0628003    0.158971    -0.144757     0.0370353     0.0749713    0.0142234    0.0644017    0.00687403   0.0415404   0.0165123   -0.0597543   -0.219014     -0.0831566    0.0236786   -0.0862731     0.00812933  -0.0486472   -0.0262698
  0.00116103  -0.179038     0.185252     0.035293    -0.0364107   0.0860718  -0.0196456   -0.0762045   -0.102041     0.0294989   -0.134766     0.0105135     0.157091     0.0884792    0.00917171   0.0191068    0.122497    0.0725879   -0.0575464   -0.0689926     0.0270566    0.0142014   -0.13348      -0.0174721    0.0353899   -0.0821215
 -0.0417562   -0.179657     0.167913    -0.0944665   -0.0492023  -0.0924497   0.0400579    0.0364693    0.149924     0.0151427    0.0960148    0.0417341     0.0263536    0.106912     0.0802484   -0.0398393    0.177767   -0.179819     0.0480999   -0.0988527    -0.0721733    0.128388     0.171761      0.0113364    0.116463     0.086327
  0.00933596  -0.156152    -0.105206    -0.027919     0.0437013  -0.109663    0.0888511   -0.164654     0.191603    -0.00402829  -0.053385    -0.013288      0.308008     0.00771663  -0.0466858    0.0560205   -0.166217   -0.0128185   -0.0017663   -0.00948136   -0.0476377    0.0963554    0.0408309     0.116717     0.0226259    0.0229333
 -0.0319915    0.0787999    0.00394801  -0.160784    -0.0546166   0.104509   -0.064931    -0.0999014   -0.0561315    0.180914    -0.162803    -0.0820723     0.167844    -0.0878098   -0.123932     0.0188832   -0.0436654   0.013224     0.0253543    0.153659      0.0604107    0.170756    -0.200532     -0.00934825  -0.0990286    0.0492621
  0.0348562    0.0518257    0.00831023  -0.0217983    0.117467   -0.0354686  -0.13264     -0.142625    -0.0439363   -0.0219859   -0.0451511   -0.000971871   0.0798605   -0.0157164    0.0854878   -0.0399876   -0.0104834  -0.116943    -0.0220586   -0.0921962     0.0506115    0.060535     0.148386      0.0836595   -0.123262     0.0910682kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3958887342331638
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.395981
[ Info: iteration 2, average log likelihood -1.395893
[ Info: iteration 3, average log likelihood -1.394712
[ Info: iteration 4, average log likelihood -1.387598
[ Info: iteration 5, average log likelihood -1.375318
[ Info: iteration 6, average log likelihood -1.369294
[ Info: iteration 7, average log likelihood -1.367752
[ Info: iteration 8, average log likelihood -1.366757
[ Info: iteration 9, average log likelihood -1.365815
[ Info: iteration 10, average log likelihood -1.364825
[ Info: iteration 11, average log likelihood -1.363710
[ Info: iteration 12, average log likelihood -1.361679
[ Info: iteration 13, average log likelihood -1.358876
[ Info: iteration 14, average log likelihood -1.357845
[ Info: iteration 15, average log likelihood -1.357498
[ Info: iteration 16, average log likelihood -1.357341
[ Info: iteration 17, average log likelihood -1.357251
[ Info: iteration 18, average log likelihood -1.357191
[ Info: iteration 19, average log likelihood -1.357145
[ Info: iteration 20, average log likelihood -1.357108
[ Info: iteration 21, average log likelihood -1.357077
[ Info: iteration 22, average log likelihood -1.357052
[ Info: iteration 23, average log likelihood -1.357031
[ Info: iteration 24, average log likelihood -1.357014
[ Info: iteration 25, average log likelihood -1.357001
[ Info: iteration 26, average log likelihood -1.356990
[ Info: iteration 27, average log likelihood -1.356981
[ Info: iteration 28, average log likelihood -1.356975
[ Info: iteration 29, average log likelihood -1.356970
[ Info: iteration 30, average log likelihood -1.356966
[ Info: iteration 31, average log likelihood -1.356963
[ Info: iteration 32, average log likelihood -1.356960
[ Info: iteration 33, average log likelihood -1.356958
[ Info: iteration 34, average log likelihood -1.356957
[ Info: iteration 35, average log likelihood -1.356956
[ Info: iteration 36, average log likelihood -1.356955
[ Info: iteration 37, average log likelihood -1.356955
[ Info: iteration 38, average log likelihood -1.356954
[ Info: iteration 39, average log likelihood -1.356954
[ Info: iteration 40, average log likelihood -1.356953
[ Info: iteration 41, average log likelihood -1.356953
[ Info: iteration 42, average log likelihood -1.356953
[ Info: iteration 43, average log likelihood -1.356953
[ Info: iteration 44, average log likelihood -1.356953
[ Info: iteration 45, average log likelihood -1.356953
[ Info: iteration 46, average log likelihood -1.356953
[ Info: iteration 47, average log likelihood -1.356953
[ Info: iteration 48, average log likelihood -1.356953
[ Info: iteration 49, average log likelihood -1.356953
[ Info: iteration 50, average log likelihood -1.356953
┌ Info: EM with 100000 data points 50 iterations avll -1.356953
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3959807979056538
│     -1.395892914474682
│      ⋮
└     -1.3569527896032254
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.357072
[ Info: iteration 2, average log likelihood -1.356972
[ Info: iteration 3, average log likelihood -1.356517
[ Info: iteration 4, average log likelihood -1.351328
[ Info: iteration 5, average log likelihood -1.335512
[ Info: iteration 6, average log likelihood -1.323888
[ Info: iteration 7, average log likelihood -1.318707
[ Info: iteration 8, average log likelihood -1.315168
[ Info: iteration 9, average log likelihood -1.312181
[ Info: iteration 10, average log likelihood -1.310017
[ Info: iteration 11, average log likelihood -1.308863
[ Info: iteration 12, average log likelihood -1.308232
[ Info: iteration 13, average log likelihood -1.307868
[ Info: iteration 14, average log likelihood -1.307656
[ Info: iteration 15, average log likelihood -1.307521
[ Info: iteration 16, average log likelihood -1.307420
[ Info: iteration 17, average log likelihood -1.307335
[ Info: iteration 18, average log likelihood -1.307255
[ Info: iteration 19, average log likelihood -1.307175
[ Info: iteration 20, average log likelihood -1.307091
[ Info: iteration 21, average log likelihood -1.307001
[ Info: iteration 22, average log likelihood -1.306908
[ Info: iteration 23, average log likelihood -1.306812
[ Info: iteration 24, average log likelihood -1.306717
[ Info: iteration 25, average log likelihood -1.306627
[ Info: iteration 26, average log likelihood -1.306545
[ Info: iteration 27, average log likelihood -1.306476
[ Info: iteration 28, average log likelihood -1.306419
[ Info: iteration 29, average log likelihood -1.306372
[ Info: iteration 30, average log likelihood -1.306333
[ Info: iteration 31, average log likelihood -1.306301
[ Info: iteration 32, average log likelihood -1.306274
[ Info: iteration 33, average log likelihood -1.306253
[ Info: iteration 34, average log likelihood -1.306234
[ Info: iteration 35, average log likelihood -1.306219
[ Info: iteration 36, average log likelihood -1.306206
[ Info: iteration 37, average log likelihood -1.306194
[ Info: iteration 38, average log likelihood -1.306185
[ Info: iteration 39, average log likelihood -1.306176
[ Info: iteration 40, average log likelihood -1.306169
[ Info: iteration 41, average log likelihood -1.306163
[ Info: iteration 42, average log likelihood -1.306158
[ Info: iteration 43, average log likelihood -1.306153
[ Info: iteration 44, average log likelihood -1.306149
[ Info: iteration 45, average log likelihood -1.306146
[ Info: iteration 46, average log likelihood -1.306143
[ Info: iteration 47, average log likelihood -1.306140
[ Info: iteration 48, average log likelihood -1.306138
[ Info: iteration 49, average log likelihood -1.306136
[ Info: iteration 50, average log likelihood -1.306134
┌ Info: EM with 100000 data points 50 iterations avll -1.306134
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3570724633913802
│     -1.356971620861692
│      ⋮
└     -1.3061342023049085
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.306339
[ Info: iteration 2, average log likelihood -1.306131
[ Info: iteration 3, average log likelihood -1.305493
[ Info: iteration 4, average log likelihood -1.299582
[ Info: iteration 5, average log likelihood -1.281626
[ Info: iteration 6, average log likelihood -1.268720
[ Info: iteration 7, average log likelihood -1.263849
[ Info: iteration 8, average log likelihood -1.260901
[ Info: iteration 9, average log likelihood -1.258146
[ Info: iteration 10, average log likelihood -1.255108
[ Info: iteration 11, average log likelihood -1.252385
[ Info: iteration 12, average log likelihood -1.251078
[ Info: iteration 13, average log likelihood -1.250362
[ Info: iteration 14, average log likelihood -1.249621
[ Info: iteration 15, average log likelihood -1.248469
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.246656
[ Info: iteration 17, average log likelihood -1.259127
[ Info: iteration 18, average log likelihood -1.251799
[ Info: iteration 19, average log likelihood -1.249540
[ Info: iteration 20, average log likelihood -1.248303
[ Info: iteration 21, average log likelihood -1.247722
[ Info: iteration 22, average log likelihood -1.247387
[ Info: iteration 23, average log likelihood -1.247089
[ Info: iteration 24, average log likelihood -1.246780
[ Info: iteration 25, average log likelihood -1.246471
[ Info: iteration 26, average log likelihood -1.246196
[ Info: iteration 27, average log likelihood -1.245999
[ Info: iteration 28, average log likelihood -1.245878
[ Info: iteration 29, average log likelihood -1.245809
[ Info: iteration 30, average log likelihood -1.245767
[ Info: iteration 31, average log likelihood -1.245736
[ Info: iteration 32, average log likelihood -1.245710
[ Info: iteration 33, average log likelihood -1.245687
[ Info: iteration 34, average log likelihood -1.245662
[ Info: iteration 35, average log likelihood -1.245634
[ Info: iteration 36, average log likelihood -1.245602
[ Info: iteration 37, average log likelihood -1.245564
[ Info: iteration 38, average log likelihood -1.245518
[ Info: iteration 39, average log likelihood -1.245464
[ Info: iteration 40, average log likelihood -1.245397
[ Info: iteration 41, average log likelihood -1.245314
[ Info: iteration 42, average log likelihood -1.245211
[ Info: iteration 43, average log likelihood -1.245083
[ Info: iteration 44, average log likelihood -1.244927
[ Info: iteration 45, average log likelihood -1.244743
[ Info: iteration 46, average log likelihood -1.244547
[ Info: iteration 47, average log likelihood -1.244352
[ Info: iteration 48, average log likelihood -1.244151
[ Info: iteration 49, average log likelihood -1.243926
[ Info: iteration 50, average log likelihood -1.243648
┌ Info: EM with 100000 data points 50 iterations avll -1.243648
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3063389583769014
│     -1.3061308289794478
│      ⋮
└     -1.2436480541741382
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.243545
[ Info: iteration 2, average log likelihood -1.242855
[ Info: iteration 3, average log likelihood -1.240859
[ Info: iteration 4, average log likelihood -1.225783
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.189864
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.171817
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.163767
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.154159
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.165013
[ Info: iteration 10, average log likelihood -1.162770
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.143314
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.152396
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.155957
[ Info: iteration 14, average log likelihood -1.147695
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.135269
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.162379
[ Info: iteration 17, average log likelihood -1.151832
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.136350
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      5
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.137299
[ Info: iteration 20, average log likelihood -1.156087
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.136989
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.136966
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.137347
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.147904
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.142372
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.140606
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     4
│     5
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.136040
[ Info: iteration 28, average log likelihood -1.155665
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.137808
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.136792
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.138266
[ Info: iteration 32, average log likelihood -1.147454
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.133237
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.141769
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.140157
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.140322
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.139025
[ Info: iteration 38, average log likelihood -1.139252
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.128156
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.141499
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.150249
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.140503
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.137926
[ Info: iteration 44, average log likelihood -1.149173
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.134350
[ Info: iteration 46, average log likelihood -1.145403
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.132265
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.134508
[ Info: iteration 49, average log likelihood -1.154019
[ Info: iteration 50, average log likelihood -1.136096
┌ Info: EM with 100000 data points 50 iterations avll -1.136096
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2435445789139463
│     -1.2428546455260294
│      ⋮
└     -1.1360964901579165
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     10
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.126843
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     10
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.125849
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│     10
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.121879
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│      9
│     10
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.097596
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│     10
│     17
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.083348
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.053195
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     17
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.054974
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.041228
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      7
│      8
│      ⋮
│     22
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.053155
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│      9
│     10
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.059273
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.047840
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.045712
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     18
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.043070
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.041718
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.059570
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.050601
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.048248
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.041667
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     22
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.050640
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.045162
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     18
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.062451
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.043208
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.041213
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.048666
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.054639
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.048967
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.055872
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.036937
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.048663
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.052339
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.057539
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.041391
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.048576
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.043668
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.051965
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.055541
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.050203
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.034423
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     22
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.055587
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.047696
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.055847
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.048901
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.043842
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.041746
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.059220
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.050594
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.048330
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.041730
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     22
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.050611
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.045068
┌ Info: EM with 100000 data points 50 iterations avll -1.045068
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1268427026607764
│     -1.1258491615230983
│      ⋮
└     -1.0450675285757862
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3958887342331638
│     -1.3959807979056538
│     -1.395892914474682
│     -1.3947118141244133
│      ⋮
│     -1.0417301291026575
│     -1.0506108010764674
└     -1.0450675285757862
32×26 Array{Float64,2}:
  0.0725376   -0.245106     0.00364409  -0.030786     -0.13325     -0.0642387     0.0239839   -0.0311648     0.0686927     0.0140469    0.106319     0.137494     0.0442171   -0.0859101    0.0208779    0.22082     -0.116114   -0.167064     -0.234092    -0.127216    -0.111927     0.0206064  -0.0348298   -0.00485008    0.0473948   -0.248865
 -0.131167    -0.0754909   -0.0681957   -0.0275945    -0.0719949    0.0118434    -0.12897      0.0476105     0.0237927    -0.0476734    0.156684     0.179569     0.0165996   -0.136012    -0.00330887  -0.0474859   -0.117233   -0.153205     -0.0254389   -0.00480548  -0.0147899   -0.100447    0.023744    -0.0343019     0.113133     0.0503267
  0.100268    -0.06419     -0.0160062    0.0822975     0.00682937   0.0202822    -0.054079    -0.119205     -0.00970247    0.0461904   -0.168814     0.0279326    0.00987703   0.0359698    0.0720906    0.0413269    0.0729864   0.114822      0.0199317   -0.0389368   -0.0398231    0.0558436  -0.0800639   -0.00638195   -0.0125478    0.0409647
 -0.00857682   0.142105    -0.0218378    0.0238508    -0.116339    -0.0729846    -0.0778314    0.104757      0.000892405  -0.0481749    0.0617748    0.0328364   -0.0295938    0.0507759   -0.00737943   0.011135    -0.0584019  -0.10293       0.0254603   -0.126792    -0.0084781    0.0615649  -0.0826695   -0.000434288   0.00978007  -0.0407418
  0.0644243    0.192218    -0.0563788    0.0137299    -0.172188    -0.216669      0.123932    -0.652478     -0.0203103    -0.143865     0.1703      -0.223598    -0.0515878    0.0968606    0.126503    -0.0699085   -0.255566   -0.0118645    -0.151835     0.0102889    0.0444238    0.0386123   0.115357     0.19063      -0.00931738   0.0980083
  0.0844892    0.149024    -0.0320687    0.0121536    -0.104397    -0.239518      0.215867     0.256695      0.0770945    -0.13132     -0.0134983   -0.309054    -0.0687491    0.037085     0.0188834   -0.131324    -0.254921   -0.0778962    -0.218384     0.011574     0.254988     0.0356911   0.0910702    0.157895     -0.0210179    0.144842
 -0.00949799   0.14479      0.226257     0.0612951    -0.131548    -0.120828     -0.143583    -0.299855      0.135098      0.0089966    0.0957189    0.0621132    0.00553681  -0.369653     0.0816784    0.150308     0.0651986  -0.0854988    -0.0473623   -0.013101     0.00311204   0.0942231  -0.0938488    0.00303164   -0.0641251   -0.0275808
 -0.0287368    0.226197    -0.154645     0.107153     -0.185515    -0.0578868    -0.14489      0.0226535    -0.241696      0.00879102   0.138049    -0.210122     0.0018353    0.525786     0.0647723    0.0119901    0.0652422  -0.0684967    -0.0471692   -0.0128002    0.0021615    0.0875049  -0.132512    -0.0534424    -0.0656013    0.0926712
  0.0132062   -0.0837156   -0.187404     0.0627463     0.125111    -0.0452107    -0.117642    -0.111687      0.0973271     0.145454    -0.248808    -0.0790955    0.0319734    0.124323     0.0120998   -0.00288032   0.101717   -0.112435      0.0262771    0.159074    -0.0263709   -0.0246944  -0.192489     0.0571332     0.0542922   -0.0525138
 -0.289053    -0.106241    -0.118214     0.0516126    -0.071828    -0.0254752     0.0563476    0.0917279    -0.0212437     0.00738136  -0.00230614   0.0202158    0.0562632    0.123105    -0.157571    -0.149826    -0.0498486  -0.0213433    -0.128698     0.113604     0.057892    -0.0747568   0.0202527   -0.0181816    -0.237558    -0.0384501
  0.130684    -0.0738975    0.0345097    0.150465      0.0512649    0.118971     -0.0657302    0.0647784     0.0879974    -0.0341578   -0.24939     -0.136334    -0.0482373    0.107665    -0.0130616   -0.0668162    0.107858   -0.153491     -0.0591714   -0.0352417   -0.0802418    0.104224   -0.126862     0.00581517    0.140207     0.0519956
  0.0518293    0.0106483   -0.016675    -0.101176     -0.0854447   -0.00773574    0.0347973    0.0318551    -0.147078      0.138074    -0.0320062   -0.0490472    0.0121467   -0.0364356    0.191856     0.0301938    0.078894    0.113845     -0.0760753    0.107586    -0.0404373    0.0964375   0.0782787    0.0118609     0.194286     0.0670396
 -0.0156968   -0.113743     0.0943566   -0.0206495     0.00409957   0.0574416     0.105936    -0.0405556     0.0263259    -0.046435     0.0944691    0.0117585   -0.0172324    0.0592463    0.203533    -0.0686168   -0.028409   -0.0117031     0.0673184   -0.00151657  -0.01534     -0.126762    0.114596     0.0403267     0.0650026   -0.0879558
 -0.0416898   -0.155855     0.166626    -0.0963079    -0.0393089   -0.0930279     0.0285655    0.0336549     0.131374      0.0198762    0.122794     0.0300835   -0.00314929   0.0836134    0.0759047   -0.041499     0.180332   -0.25234       0.0827367   -0.0989071   -0.074208     0.144962    0.192269     0.0183511     0.119788     0.0647102
  0.0208029   -0.105876     0.0116353   -0.0270836    -0.0856417   -0.0276499    -0.125514     0.0966631     0.0618771    -0.0359661   -0.00827086  -0.0631634   -0.0217261   -0.165902    -0.00958454  -0.050748     0.141054   -0.00668407   -0.0231038    0.0225337   -0.0254878   -0.0583497   0.0856933   -0.0680022     0.146112     0.110501
  0.143304     0.00604582   0.085459     0.166189     -0.1067      -0.155431     -0.0224363   -0.0793255    -0.0215486     0.0937246    0.0595473    0.0289664   -0.00216694  -0.148512    -0.00130816   0.00349092   0.0279978   0.0193411     0.0301196   -0.0241699    0.156082     0.0371097  -0.210437    -0.0510555    -0.0206291   -0.0743773
 -0.088714    -0.131615     0.127072    -0.0258932    -0.386877     0.0934145     0.323719    -0.137113      0.00760844   -0.043114     0.0132194    0.0589178    0.0707322    0.0349777   -0.181695     0.0709823   -0.0259593  -0.0603336    -0.445134    -0.332163     0.143981    -0.146534   -0.0820064    0.0891819    -0.366994     0.147019
  0.0261145   -0.11951      0.175855    -0.025937      0.0761221   -0.157918     -0.0742186    0.0760556     0.0222547     0.0119649    0.00427105   0.037176     0.0529268    0.0102813    0.451031     0.0280303    0.0774431  -0.0364993     0.0248861    0.178817     0.143793     0.0175886  -0.0433313   -0.139737      0.119581     0.0526807
  0.05882     -0.0787323    0.171735     0.0324608    -0.277522     0.148319      0.0519369   -0.000614343   0.0658106     0.0450528   -0.0046183   -0.0453661    0.080133     0.150068     0.00156481  -0.160729     0.247631    0.000717521   0.0519299   -0.125805    -0.0319187    0.33385    -0.00448892  -0.565094      0.00463447   0.0753627
 -0.0439919   -0.0960459    0.349376     0.0453764     0.21432     -0.212086      0.052186     0.013097      0.0527952    -0.0249314    0.0306155   -0.089346     0.0530216    0.111318     0.067352    -0.00441975   0.245848   -0.276486      0.0201323   -0.125497     0.0375986    0.266559   -0.11306      0.360464      0.0315491    0.0354324
 -0.013437    -0.0682942    0.0969291   -0.0458588    -0.130828     0.0859122    -0.0397091   -0.0847304    -0.0852053     0.120778    -0.150781    -0.0390425    0.163386    -0.00639159  -0.0848076    0.0121848    0.0350378   0.0517337    -0.00514123   0.0615811    0.0250216    0.11731    -0.17307     -0.0230125    -0.0444053   -0.0406577
 -0.0740744   -0.0614975   -0.0733561   -0.0933236     0.0813196    0.129486     -0.0371949   -0.142353      0.00992999    0.0383848    0.0283425   -0.0876354    0.219371    -0.0437924    0.00953573   0.127882     0.0271895   0.0443304    -0.10534     -0.0194795    0.260936    -0.0677296   0.0926413   -0.0910165     0.0197559    0.0796798
  0.0278181    0.0775706   -0.0211266    0.137709      0.0361641    0.0323576     0.0624408    0.0777461    -0.0256436    -0.198827    -0.00829714  -0.0924377    0.00817283   0.0913022   -0.0215222   -0.0210101    0.0108527   0.0603165     0.2306       0.233751     0.106469     0.209114    0.0691517    0.00113432   -0.0889098   -0.192707
  0.0692315    0.0536141    0.197722     0.151432     -0.0714825    0.123492      0.0330239   -0.144816      0.0961924    -0.0507883    0.0870529   -0.113045     0.0558575   -0.0855925   -0.21861     -0.201602    -0.032619    0.156352      0.0189063   -0.0778734    0.0916511   -0.0585076  -0.111609    -0.00033663    0.0977982   -0.092097
 -0.014333     0.0515877   -0.00332479  -0.0398511     0.106697    -0.025047     -0.13248     -0.140879     -0.0448601    -0.0530785   -0.043757    -0.00850567   0.0846754   -0.00778907   0.082511    -0.0135907    0.0112225  -0.113271     -0.00544407  -0.089602     0.0546807    0.062129    0.147091     0.0595679    -0.12678      0.0869311
 -0.0495139   -0.0992063    0.04391      0.000534496   0.0451469    0.022273      0.0778237    0.0158776    -0.0259677     0.0351295    0.0252196    0.0567448    0.0542689    0.0768365   -0.136186    -0.199821     0.0240248  -0.0486278    -0.00132212  -0.129052    -0.0272986    0.0661175   0.0743005   -0.0949383    -0.0200242   -0.00454253
  0.0361552   -0.137019    -0.0368752    0.104491     -0.0211637   -0.0643169    -0.0516295   -0.156157      0.0725615    -0.00149449  -0.114297     0.0699035    0.049331     0.114908    -0.0392874   -0.0664819    0.0765931  -0.152618     -0.0345049   -0.0914594   -0.0315311    0.0768887   0.0343651    0.0585357     0.0563424   -0.0159762
  0.105034     0.0273698   -0.0458939   -0.142921     -0.0703364    0.145759      0.0467773   -0.022866      0.126672      0.257198    -0.0124069    0.12571     -0.0221045    0.0669044    0.0562525    0.0116602    0.231552    0.0331916    -0.140364    -0.0292777    0.0496046   -0.061123   -0.00209694   0.0519779    -0.092326     0.0338498
 -0.0184623    0.138659     0.142124    -0.137215     -0.0979321   -0.248479     -0.147843    -0.211755     -0.352461      0.0771399   -0.130431     0.0444553    0.104474     0.112383     0.0632632   -0.0736443    0.108566   -0.00205788    0.106816     0.0846286   -0.106738     0.0853355   0.0210533   -0.0669748    -0.104709    -0.0196525
 -0.16476      0.157161     0.156154     0.003339      0.0585412   -0.247831      0.0594199   -0.222869      0.188918      0.0614088   -0.133036     0.0768585    0.181703     0.0743202    0.0508902   -0.0976943    0.112815    0.00161429    0.114148    -0.0798167   -0.265286    -0.163639    0.241843     0.0202196     0.00602203  -0.0179812
  0.205845     0.157164     0.0675363   -0.133021     -0.142706    -0.0783899    -0.00613267   0.0128008    -0.336302     -0.041853    -0.091976     0.00738255   0.0322302    0.165818    -0.0207511   -0.109897    -0.11099     0.0767475     0.0164564   -0.156047     0.023728     0.0804361   0.0131007    0.05349      -0.114216     0.0217207
  0.00982883  -0.170408    -0.104629    -0.022404     -0.00950282   0.000136269   0.103599    -0.158801      0.174719     -0.0227874   -0.057852    -0.0193363    0.307494     0.0222466   -0.0566584    0.0760587   -0.165053   -0.00210495   -0.00159388  -0.0179387   -0.05666      0.0941489   0.0225959    0.114351      0.0239515    0.0416859[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     18
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.062421
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.034518
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.041241
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.033161
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.045890
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.037037
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     18
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.051361
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.027840
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.044828
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.034875
┌ Info: EM with 100000 data points 10 iterations avll -1.034875
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.460582e+05
      1       6.629005e+05      -1.831577e+05 |       32
      2       6.354030e+05      -2.749749e+04 |       32
      3       6.172410e+05      -1.816200e+04 |       32
      4       6.052719e+05      -1.196910e+04 |       32
      5       5.983675e+05      -6.904398e+03 |       32
      6       5.950002e+05      -3.367368e+03 |       32
      7       5.937221e+05      -1.278089e+03 |       32
      8       5.932748e+05      -4.472403e+02 |       32
      9       5.930518e+05      -2.230461e+02 |       32
     10       5.929201e+05      -1.316744e+02 |       32
     11       5.928212e+05      -9.889537e+01 |       32
     12       5.927118e+05      -1.093857e+02 |       32
     13       5.925540e+05      -1.578379e+02 |       32
     14       5.922670e+05      -2.869664e+02 |       32
     15       5.915315e+05      -7.355645e+02 |       32
     16       5.904392e+05      -1.092268e+03 |       32
     17       5.899138e+05      -5.253817e+02 |       32
     18       5.897008e+05      -2.129593e+02 |       32
     19       5.895012e+05      -1.996286e+02 |       32
     20       5.892872e+05      -2.140416e+02 |       32
     21       5.890211e+05      -2.660357e+02 |       32
     22       5.887045e+05      -3.166621e+02 |       32
     23       5.883190e+05      -3.854457e+02 |       32
     24       5.879288e+05      -3.902675e+02 |       32
     25       5.875139e+05      -4.148797e+02 |       32
     26       5.871771e+05      -3.367497e+02 |       31
     27       5.869546e+05      -2.224910e+02 |       32
     28       5.868086e+05      -1.460491e+02 |       31
     29       5.867205e+05      -8.808114e+01 |       32
     30       5.866733e+05      -4.722688e+01 |       32
     31       5.866483e+05      -2.500044e+01 |       30
     32       5.866275e+05      -2.082034e+01 |       31
     33       5.866106e+05      -1.687426e+01 |       31
     34       5.866006e+05      -1.002007e+01 |       26
     35       5.865944e+05      -6.144089e+00 |       27
     36       5.865893e+05      -5.157539e+00 |       25
     37       5.865850e+05      -4.270713e+00 |       25
     38       5.865822e+05      -2.769750e+00 |       22
     39       5.865800e+05      -2.187172e+00 |       20
     40       5.865786e+05      -1.395365e+00 |       18
     41       5.865777e+05      -9.149016e-01 |       14
     42       5.865767e+05      -1.047166e+00 |       13
     43       5.865754e+05      -1.307643e+00 |       16
     44       5.865741e+05      -1.264245e+00 |       17
     45       5.865731e+05      -9.625946e-01 |       17
     46       5.865724e+05      -7.301358e-01 |        9
     47       5.865721e+05      -2.891158e-01 |        8
     48       5.865719e+05      -2.708198e-01 |        9
     49       5.865715e+05      -3.355495e-01 |       12
     50       5.865710e+05      -4.800326e-01 |       10
K-means terminated without convergence after 50 iterations (objv = 586571.0409329789)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.306063
[ Info: iteration 2, average log likelihood -1.267722
[ Info: iteration 3, average log likelihood -1.232937
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.192155
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.138965
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     14
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.091282
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     17
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.102712
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     10
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.097887
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.088901
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      7
│     11
│     14
│     15
│     20
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.053272
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.104470
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.071387
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     10
│     14
│     20
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.065000
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     11
│     15
│     17
│     21
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.071156
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.111298
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     14
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.072705
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.083716
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      7
│     10
│     15
│      ⋮
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.011419
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.117781
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.116563
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     11
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.056876
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     10
│     14
│     15
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.044022
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.112069
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.114749
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     14
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.061059
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     10
│     17
│     21
│     22
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.040756
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     20
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.094412
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      5
│     11
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.079610
[ Info: iteration 29, average log likelihood -1.093431
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     17
│     20
│     21
│     22
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.021489
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     14
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.088362
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     11
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.086634
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│     15
│     20
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.054698
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     14
│     17
│     22
│     23
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.073638
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.106200
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.066695
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│     14
│     17
│     21
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.051868
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     15
│     23
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.086607
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.077416
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     22
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.062184
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      7
│     14
│     17
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.063755
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     20
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.076188
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     10
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.099482
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     21
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.066405
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│     15
│     17
│     20
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.059124
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     11
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.085879
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     14
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.085800
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     20
│     21
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.077297
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│      7
│     17
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.067957
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     14
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.063205
┌ Info: EM with 100000 data points 50 iterations avll -1.063205
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.21668     -0.111454   -0.103086     0.0620149   -0.0884137   -0.00209045   0.00850892   0.032888    -0.0396972     0.0199101   -0.0784118   -0.0117969     0.0399671    0.145939    -0.16064     -0.132661     -0.00555257  -0.0801228   -0.113641     0.130951     0.0257498   -0.124231     0.00543359  -0.00732573   -0.214559     -0.0554528
  0.14806     -0.0366224   0.0444714    0.152284    -0.0914902   -0.0305283   -0.145734    -0.091358    -0.0802761     0.136853    -0.121107     0.0355735     0.0771807    0.0167711    0.0628664    0.0158789     0.0392256    0.0294055   -0.0310762   -0.19467     -0.0730582    0.0249645   -0.0935737    0.0120246    -0.0403501    -0.0271349
 -0.128475    -0.0506686  -0.0736178   -0.0108707   -0.0833342   -0.00557217  -0.127079     0.0344707    0.0263364    -0.0407756    0.149981     0.173187      0.0179601   -0.144288     0.00603974  -0.0450629    -0.0925807   -0.147952    -0.0326021   -0.0039857   -0.0118097   -0.0791283    0.0101616   -0.0345096     0.0849826     0.0525192
  0.0655007   -0.0619173   0.038792     0.0619006   -0.00447212   0.0680988    0.0294119    0.0727382    0.0200287    -0.0220238   -0.141       -0.0347003     0.00384397   0.0566839   -0.118542    -0.14464       0.0984347   -0.086043    -0.0567209   -0.0918526   -0.0682988    0.139246    -0.00329387   0.0198039     0.0621073     0.0537795
  0.12016      0.0443577   0.0865734    0.171753    -0.11506     -0.22514     -0.0177409   -0.0747316   -0.00406886    0.0960303    0.0963697    0.0198854    -0.027115    -0.354028    -0.0397657   -0.0511343     0.028961     0.0239589    0.0593771    0.00373207   0.364476     0.0402487   -0.249794    -0.0495459    -0.0183287    -0.0779785
 -0.00994406   0.149792   -0.0176284    0.0241161   -0.118053    -0.0772203   -0.0766346    0.110906    -0.000208921  -0.0496701    0.0673538    0.0303627    -0.0290106    0.0493464   -0.00539638   0.00911451   -0.0566114   -0.107381     0.0231159   -0.134277    -0.00582896   0.06349     -0.0841906   -0.000980145   0.00841399   -0.0421922
 -0.0248854    0.254634    0.106488     0.092779    -0.180336    -0.136893    -0.114441    -0.126762    -0.122164      0.00218235   0.128357    -0.107598      0.00528328   0.159988     0.0445537    0.0861782     0.0487501   -0.0732744   -0.0434124   -0.0237296   -0.0107256    0.0803549   -0.131047    -0.0269624    -0.0539585     0.00635111
 -0.0869239    0.144439    0.141846    -0.0660156   -0.0231103   -0.2367      -0.0374204   -0.221812    -0.0730821     0.0650665   -0.129913     0.0592985     0.143507     0.0941924    0.0573752   -0.0710674     0.110286     0.0062618    0.108716     0.00854281  -0.18496     -0.0301312    0.120634    -0.0273923    -0.0470741    -0.0188718
 -0.110882    -0.162243    0.0213796    0.0282262    0.144725     0.0127304    0.023436    -0.0524402   -0.00450077    0.0769215    0.0644766    0.0229159     0.0388628    0.150636    -0.0457851   -0.156037     -0.0362207   -0.06409      0.0501664   -0.0632587    0.029167    -0.0534126    0.0273566   -0.230688     -0.0376487    -0.0764698
  0.103099     0.0326796  -0.0404544   -0.13495     -0.0765798    0.139598     0.0460676   -0.0219424    0.124148      0.256259    -0.0156954    0.12343      -0.0228225    0.0726413    0.0543012    0.0139045     0.227031     0.0339272   -0.137359    -0.0209071    0.0568866   -0.0603581   -0.0171874    0.049293     -0.0942619     0.0345181
  0.203245     0.154168    0.0640079   -0.128368    -0.144066    -0.0750339   -0.00799925   0.00947824  -0.309955     -0.0412691   -0.0851575    0.00323583    0.0331303    0.144891    -0.027023    -0.110428     -0.110155     0.0746266    0.0164066   -0.150012     0.0226444    0.0743367    0.00887546   0.0479465    -0.109975      0.0183535
  0.0200874   -0.122184    0.0170702   -0.00492401  -0.0937655   -0.0491267   -0.124476     0.0887925    0.0623814    -0.0283499   -0.0104389   -0.053667     -0.0308349   -0.171531    -0.0279165   -0.0674306     0.139752    -0.0108867   -0.0172817    0.0255931   -0.0534175   -0.0550111    0.0543832   -0.0659418     0.142277      0.0891716
  0.00188562  -0.196667    0.164668     0.0604302   -0.0628946    0.0773497   -0.0200571   -0.0619402   -0.101747      0.0166686   -0.103776     0.000815783   0.158829     0.0839441    0.00815606   0.0124521     0.120864     0.0756471   -0.0512487   -0.0672948    0.0370106    0.00770684  -0.117042    -0.0310188     0.0307686    -0.0786134
 -0.0107199   -0.109348    0.0932654   -0.0180187   -0.0034474    0.0555716    0.10699     -0.0377565    0.0241324    -0.0431172    0.0914429    0.00972449   -0.0179372    0.0543843    0.199818    -0.0674037    -0.0288087   -0.013456     0.067125     0.00177335   0.00242375  -0.124643     0.107093     0.0389903     0.0606455    -0.091638
 -0.0276389    0.0290666  -0.00805645  -0.141458    -0.119559     0.103484    -0.0588976   -0.114679    -0.0526689     0.165712    -0.153204    -0.0809603     0.166093    -0.0895227   -0.125163     0.033331     -0.0440974    0.0213517    0.0172325    0.152953     0.0580556    0.164213    -0.194588    -0.0130757    -0.0952549     0.0403255
  0.00916113  -0.0869937   0.253837     0.0393681   -0.0457578   -0.02369      0.0522999    0.00608779   0.0593724     0.0103676    0.0120632   -0.066701      0.0669373    0.131948     0.0371336   -0.087011      0.24662     -0.130469     0.0369765   -0.125721     0.0010571    0.301288    -0.0566422   -0.125289      0.0172447     0.0561236
  0.0467912   -0.0531477  -0.0808438    0.0392572    0.0559612    0.0527327    0.0168303   -0.115891     0.0464839    -0.01953     -0.12111      0.0111467    -0.12791      0.057528     0.0675496    0.0942542     0.0669324    0.149686     0.0503643    0.116111    -0.0153392    0.0922884   -0.0983102   -0.0449602    -0.000795807   0.0838838
  0.0731574    0.168252   -0.0434345    0.0128411   -0.133291    -0.226998     0.171417    -0.14987      0.030483     -0.133743     0.0710734   -0.265294     -0.0594036    0.0738839    0.0666094   -0.101106     -0.251666    -0.0454788   -0.185214     0.0108494    0.15724      0.0358597    0.0998236    0.170846     -0.0162907     0.121041
  0.0659087    0.0569055   0.208401     0.174387    -0.0681957    0.127372     0.0314185   -0.14127      0.0956157    -0.0479865    0.0870646   -0.109521      0.0425476   -0.0821374   -0.219152    -0.207338     -0.0328961    0.171801     0.0214425   -0.0629057    0.093948    -0.0627178   -0.108487     0.00413975    0.110452     -0.0908962
  0.0721257   -0.240955    0.00610385  -0.0266323   -0.131142    -0.0693427    0.0199386   -0.0375994    0.0657316     0.0153885    0.106528     0.135307      0.043295    -0.0850418    0.0219178    0.215898     -0.107575    -0.159327    -0.229854    -0.122611    -0.115348     0.0228937   -0.0352181   -0.00430317    0.042562     -0.234882
  0.0215039    0.0845602  -0.0226072    0.141461     0.0339176    0.0329048    0.0612098    0.0941477   -0.0436205    -0.21825     -0.00933485  -0.0941502     0.0062187    0.0947712   -0.0135007   -0.0272426     0.0202984    0.0676249    0.238721     0.240247     0.108268     0.21955      0.0703844    0.00795331   -0.101054     -0.190303
  0.0521234    0.0110462  -0.0169579   -0.102236    -0.0857626   -0.00762514   0.0350239    0.0319698   -0.147292      0.139045    -0.0319303   -0.048646      0.0119346   -0.0369766    0.191946     0.0301154     0.078995     0.112813    -0.0761016    0.106767    -0.0403083    0.096442     0.0782146    0.0118117     0.194545      0.0674089
  0.00136248  -0.175741   -0.09259      0.00116867  -0.0374711   -0.0303325    0.111512    -0.158942     0.202801     -0.0209289   -0.0485944   -0.0211218     0.301017     0.0510019   -0.05988      0.0353907    -0.114849     0.00306098  -0.00649996  -0.018913    -0.0801584    0.0783303    0.0126809    0.125859      0.0138821     0.0404657
 -0.0207343    0.0529605  -0.00935289  -0.037913     0.112804    -0.0252035   -0.126546    -0.146114    -0.0363128    -0.0713986   -0.0488318   -0.00751727    0.0756346   -0.00372482   0.0780811   -0.0207355     0.0137341   -0.115862    -0.00283822  -0.0926305    0.0483064    0.0516128    0.145247     0.0586057    -0.130882      0.0858309
  0.117176    -0.182795   -0.0836414    0.0994214    0.032317    -0.0520461   -0.0388833   -0.233474     0.0861341    -0.0579541   -0.0828892    0.131115     -0.0687418    0.00142412  -0.123997    -0.0290798     0.118034    -0.104264     0.118978    -0.054714    -0.110881    -0.0244035    0.170168     0.143628      0.0873341    -0.00399318
 -0.147806     0.0113997  -0.00319842  -0.0730145   -0.100939     0.104399    -0.00538247  -0.0670748   -0.024789      0.304554    -0.129779    -0.050558      0.105417    -0.00314507  -0.205893    -0.0667893    -0.0375801    0.0550523   -0.021974     0.129659     0.073182     0.13334     -0.092276    -0.00721389   -0.118783      0.00784199
 -0.074041    -0.0236184  -0.119667    -0.103962     0.0659678    0.136566    -0.0391456   -0.138448     0.0397174     0.0368579    0.0460401   -0.0989927     0.22636     -0.0691666    0.0126852    0.14781       0.0104627    0.038915    -0.117133     0.0202399    0.296202    -0.070284     0.142127    -0.0993374     0.019155      0.0732291
 -0.0297009   -0.12316     0.149983    -0.0238581   -0.163465    -0.0354787    0.124855    -0.0296841    0.0165059    -0.018395     0.0075064    0.0475881     0.0596739    0.0241376    0.121069     0.0477948     0.0254423   -0.0503137   -0.210796    -0.0785949    0.144355    -0.0644771   -0.059833    -0.0200129    -0.13178       0.0969031
  0.00619769  -0.166291   -0.101397    -0.0157755    0.077352     0.103027     0.0615534   -0.104878     0.0802697    -0.0443754   -0.0802174    0.0168554     0.284222    -0.00283536  -0.0593213    0.156952     -0.15745     -0.0151469   -0.00743209  -0.0518319    0.0144813    0.0898937   -0.0288132    0.0283835     0.016546      0.0175554
 -0.0455691   -0.15487     0.165315    -0.0956697   -0.0382486   -0.0929962    0.0283309    0.0334607    0.13101       0.0188477    0.122917     0.0293106    -0.00735824   0.0845512    0.077081    -0.0426041     0.179021    -0.247148     0.0856719   -0.0963747   -0.0738731    0.140319     0.188288     0.0196455     0.120403      0.0613367
 -0.0286266   -0.0955303   0.0153703    0.101985    -0.0622561   -0.0719322   -0.0565713   -0.0910686    0.0768511     0.0321908   -0.134214     0.0148123     0.147923     0.209339     0.0320835   -0.106603      0.0448791   -0.168017    -0.148521    -0.0916332    0.0303006    0.170318    -0.0773858   -0.0226821     0.025998     -0.0235022
  0.0427912   -0.0751928  -0.201548     0.0694301    0.185641    -0.0624544   -0.129869    -0.095442     0.116574      0.171762    -0.243343    -0.0820388     0.0299438    0.124609     0.0652122    0.000855652   0.0995566   -0.124602     0.0374739    0.1602      -0.0401682   -0.0120433   -0.242401     0.0570128     0.0757368    -0.049201[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     20
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.073122
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     10
│     15
│     20
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.024494
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.976569
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     20
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.070364
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     10
│     15
│     20
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.022767
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.978358
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     20
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.070261
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     10
│     15
│     20
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.023916
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.978313
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     20
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.067028
┌ Info: EM with 100000 data points 10 iterations avll -1.067028
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.175921     0.117127    0.0541282    0.115947    -0.145066    -0.0192986   -0.107218     0.112532    -0.0669397   0.0446047   -0.0326559  -0.104772     -0.142423    -0.19495     -0.179962     0.0155536    0.0825899   -0.129818    -0.106693    -0.0913003    -0.165331     -0.0818286    0.106572     0.0702751   -0.00427119   0.076409
 -0.0810519   -0.0500055  -0.132025    -0.00329953   0.0692947    0.0880448   -0.0617893   -0.134736    -0.124887   -0.0706507   -0.0658085  -0.0679721    -0.212168     0.0869806   -0.0216152    0.0146341    0.119458     0.0655021    0.0954657    0.0679715    -0.158547      0.0329505    0.129345    -0.0256019   -0.0986928    0.120395
  0.00396852  -0.0301909   0.0286387    0.00297578   0.0211281   -0.222039     0.0258686   -0.00074196  -0.0170564  -2.29201e-5   0.112019    0.120543     -0.00209069   0.0531773   -0.0876435   -0.0401585   -0.0235444    0.0112917   -0.0696865    0.122434     -0.0541904     0.0146019   -0.0333361   -0.00151661  -0.151926     0.130608
  0.009215     0.134583   -0.0868739    0.0904345   -0.0461526    0.0539425   -0.108498    -0.0259521    0.0768631  -0.139285    -0.0234533  -0.0941043     0.0115653   -0.138913     0.176633     0.101458     0.00528062  -0.0875245    0.236046     0.0394988    -0.0729452     0.243419    -0.195081     0.0761873   -0.102025     0.0181986
 -0.111802     0.0884528   0.0135087    0.142531     0.0295686    0.0397031    0.121372     0.00469456   0.0991538  -0.0857607   -0.132852   -0.00853037    0.0395084   -0.0925572   -0.0350979   -0.0119651    0.0443871   -0.131051     0.214965    -0.0819286     0.0219376    -0.0938127   -0.0404553    0.0459364   -0.0532973   -0.0689959
  0.0724428    0.0814374   0.0323513    0.0253995   -0.188285    -0.0337585    0.0392489   -0.0215404    0.0726064  -0.0485327    0.15406    -0.0807098     0.0952319   -0.00654744   0.107792    -0.0460442    0.0244504    0.056376     0.0974528   -0.00384273   -0.0575804    -0.172727     0.0024513    0.109278    -0.0699183   -0.0142807
 -0.0715482   -0.0893239  -0.213012    -0.0517224   -0.123461     0.00801133  -0.0619462   -0.0782321    0.100239    0.0224104    0.0794719  -0.0282443    -0.202252    -0.157719     0.15279     -0.145864     0.0285126    0.0708943    0.0791999    0.0471359    -0.0123649     0.017134     0.132865    -0.0253662   -0.0692356   -0.0293948
  0.0514235   -0.0634677  -0.0142499    0.0776742    0.058216    -0.113528    -0.01962      0.142509    -0.0775933   0.0713671   -0.014448   -0.0322466    -0.0542979    0.0187458   -0.0282441   -0.00874313  -0.00754914  -0.04249     -0.0651234    0.0542353    -0.0279249    -0.0322231   -0.0371741   -0.083885    -0.134903    -0.0158253
  0.111677     0.0165826   0.0341918    0.0856383    0.0766592   -0.105265     0.114251    -0.0167865    0.0716208   0.0529492   -0.0161749  -0.000905467   0.13777     -0.141638    -0.0588581   -0.210137     0.0613671   -0.0271423   -0.0891324   -0.0322703    -0.0925295    -0.0987871    0.00069008   0.0635626   -0.00866759  -0.146666
  0.0756268    0.0188528   0.0634369   -0.0589427   -0.0808233   -0.252946    -0.185554     0.12025      0.0468998   0.00491227   0.160491   -0.0490957    -0.0854839    0.0349049    0.044047    -0.0256809   -0.0610471   -0.120854    -0.00299976  -0.127788     -0.102409     -0.139176    -0.0683693    0.153047    -0.104098     0.0293735
  0.0249566   -0.0652918  -0.170486     0.0477772    0.0741456   -0.0203812   -0.0637007   -0.0488843    0.060332    0.0233629    0.0468017   0.0303329    -0.0536581   -0.00632592   0.00733449   0.080481    -0.0714846    0.0224825   -0.026699    -0.165825     -0.0250318    -0.129754    -0.0221216   -0.127619     0.0979167   -0.05582
  0.0204314    0.0266562   0.0042409    0.117754    -0.0168719   -0.203786     0.133176     0.0757315   -0.0390518  -0.264592    -0.0567482  -0.0370815    -0.0345379    0.147797    -0.121229    -0.0718424   -0.138058    -0.13825      0.0138278   -0.104944      0.0465204    -0.117846    -0.0879189   -0.0740885   -0.00726771   0.29516
 -0.0207808    0.0632648  -0.127547    -0.0974628   -0.188746    -0.0601533   -0.0603502   -0.0902874   -0.0287347   0.107029     0.133011    0.059423      0.0455845   -0.00926601   0.292473    -0.0550522   -0.0279181   -0.193656     0.0487645    0.0162118    -0.13333       0.0852234    0.0800731    0.0838374    0.0528383    0.00605377
  0.0186062    0.0872645   0.0617094   -0.229756    -0.0906682    0.0487519   -0.011821     0.0467266   -0.0109829  -0.11661     -0.0107374   0.075104     -0.0158423    0.218204    -0.0599497    0.045083    -0.111684    -0.0583716   -0.106042    -0.000279622   0.000694712   0.0663288   -0.0378338    0.0858336    0.0199168    0.0883363
 -0.00567039  -0.116224    0.155093    -0.163179    -0.16666     -0.0284433   -0.0124931    0.0856983   -0.0236521  -0.0799409   -0.0310838   0.171262      0.213003     0.0298148    0.0920619   -0.127453     0.0471823    0.0311754   -0.0654466    0.0520644     0.179344      0.00384947  -0.116979     0.0710221    0.0363003   -0.21628
  0.0276304    0.0332308   0.0591826    0.126397     0.0926446    0.0305751   -0.0124155    0.0760881    0.0428736   0.00542578  -0.0989006   0.0583555    -0.0625761    0.21982     -0.119317    -0.0778558    0.177366    -0.0632509   -0.104047     0.0180048    -0.0134568     0.0412539   -0.138043    -0.0798165    0.0016532   -0.164138
 -0.0768547    0.0565203  -0.0227789    0.107108     0.0438833   -0.084681     0.0484426   -0.0706126   -0.0249658   0.0601114   -0.0210378   0.126766      0.0936286    0.0473064   -0.114358    -0.0617182    0.0391619    0.0363158   -0.0518953   -0.0847298    -0.130655     -0.0552898    0.0883774   -0.00832717  -0.106204     0.00529606
  0.120612    -0.0846827   0.0887714    0.0660514   -0.10691      0.295772     0.00885228   0.0359796    0.0638927   0.0239708   -0.0105544   0.060514     -0.0661744   -0.14439      0.0631601   -0.0304104    0.0961354   -0.126641     0.188943    -0.16796      -0.09154      -0.00335155   0.114218    -0.121921    -0.124356    -0.0223515
 -0.114647    -0.0613141  -0.00853584   0.0604874   -0.0453529    0.0807965    0.101683    -0.139282    -0.111789    0.0420316    0.268527    0.0861481    -0.126579    -0.103187     0.0414445    0.0599227   -0.120814     0.212575     0.0180645   -0.0177691     0.00756827    0.219101    -0.0206459    0.0424023   -0.0514038    0.0277606
 -0.13019      0.0700183   0.0719395   -0.130406     0.11719      0.120996     0.102696    -0.111165    -0.0537628   0.0559658   -0.0217589  -0.0625907    -0.00106902   0.150176     0.0713672    0.116273    -0.0676501   -0.0977142    0.0963902   -0.0314656    -0.0250467    -0.287857    -0.10219      0.0238801    0.0248172    0.130537
 -0.0140443    0.0166893   0.0749434    0.168458    -0.0785055    0.0952745   -0.0534123   -0.0935849    0.038037    0.0294939    0.0494295   0.0486492     0.0284324   -0.0218063    0.0566083    0.127391     0.314137     0.132636    -0.056588     0.154864      0.0408977     0.18496      0.0388579    0.0837145    0.107627     0.0356968
  0.10309      0.0465347   0.00693144  -0.170752     0.170426     0.02797      0.0342027    0.0470484    0.159806   -0.0229343   -0.0263619  -0.0737744     0.0247179    0.0274265   -0.0413871    0.0416402    0.0958229    0.0399967   -0.0021594    0.0163812    -0.139389     -0.0478952    0.106721    -0.046975    -0.154752    -0.0649623
 -0.0912544    0.164764    0.0273321    0.206536    -0.0787175    0.302091    -0.0415792   -0.191607    -0.160075   -0.0362865    0.0341696  -0.0537353    -0.0639837    0.0260982    0.0088421   -0.204725    -0.115024    -0.0243836    0.0191528   -0.0434532     0.0289232    -0.0422575   -0.0737324   -0.0596726    0.12167     -0.159471
 -0.00329528   0.108962    0.123195     0.0233252    0.0100403   -0.014908     0.0226309    0.17928     -0.009133   -0.0543441    0.0117622  -0.00215991   -0.0543318   -0.0435721    0.14482      0.223004    -0.00344599  -0.0117061   -0.0182009   -0.23796       0.0316248    -0.12698      0.0179232    0.10071     -0.160931    -0.0673722
 -0.102415     0.14414    -0.0199526    0.0495079   -0.0952642   -0.119482    -0.00144971   0.0106242   -0.0753467   0.144096     0.0493686   0.0973503    -0.0426107   -0.00333546  -0.0437282    0.0297377   -0.0087807   -0.0890397   -0.00551527  -0.00610899   -0.0740362    -0.0402468   -0.272379     0.0554135   -0.146871    -0.0636572
 -0.0891516    0.155432    0.130648    -0.0293073   -0.00542464   0.0491619    0.0144576    0.0423016    0.0581691   0.122627     0.0678646   0.0853682     0.0206365    0.0728091    0.00827037   0.213787     0.178783    -0.0186474   -0.130072    -0.102184     -0.0257505     0.0207064   -0.206428    -0.0890534    0.00230785  -0.102286
 -0.0388103   -0.0149828  -0.0616313   -0.00698467   0.145323     0.0251156    0.0553025   -0.00407647   0.0219145   0.201205    -0.0216671   0.103015      0.0182957    0.15611     -0.112065    -0.00796499  -0.0844555    0.0865318   -0.0704997    0.100312     -0.052326      0.0643961   -0.0201277    0.00226905   0.0450562   -0.0535201
 -0.0465941   -0.0380233  -0.0120525   -0.0912226    0.16256     -0.0433358    0.0254421    0.209764    -0.018198    0.0484813   -0.0251614   0.131301     -0.0970235    0.0367582    0.107648     0.0102828   -0.11632      0.124421    -0.119062     0.130712     -0.131972     -0.195523    -0.135997     0.0915991    0.0752767    0.127989
  0.104123     0.224831   -0.0936613    0.093315     0.0659109   -0.150635     0.209773     0.0373302   -0.0755514  -0.0611515    0.082206    0.0545948     0.101866    -0.0234763    0.0364009   -0.135125    -0.00305239   0.0046744   -0.0272412    0.00642915   -0.0204601     0.0673132    0.0379439   -0.0438601   -0.0858699   -0.0117247
  0.19981     -0.213558   -0.0586023    0.0579159    0.0437774   -0.0127228   -0.0812967    0.11222     -0.0878108   0.0592506   -0.118256    0.00587731    0.0236574   -0.0518176   -0.0950158    0.0609911    0.00597428  -0.0260504   -0.0594401    0.164606     -0.0925446     0.0386368   -0.074425    -0.114784     0.212757     0.20627
  0.102685     0.0785403  -0.0452597    0.0911847    0.110788    -0.0463841    0.0196954   -0.0410296   -0.0403558  -0.0370812    0.123039    0.0198954    -0.0658631   -0.0415541    0.0675873   -0.0286222    0.0194121    0.00510303   0.0185224    0.0978939    -0.00621362    0.0348353    0.0213231    0.114167    -0.246794     0.0488973
  0.0904904    0.015148   -0.202661     0.135688     0.046447     0.0446573   -0.0287953   -0.132339     0.0777449  -0.112116    -0.0908625   0.0667932     0.118867    -0.161522    -0.0774998   -0.140713    -0.106796    -0.0944652    0.0897029    0.0660276     0.096524      0.0305773    0.123449    -0.0845642    0.0471045   -0.0390227kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4285093310305752
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428528
[ Info: iteration 2, average log likelihood -1.428462
[ Info: iteration 3, average log likelihood -1.428408
[ Info: iteration 4, average log likelihood -1.428340
[ Info: iteration 5, average log likelihood -1.428246
[ Info: iteration 6, average log likelihood -1.428098
[ Info: iteration 7, average log likelihood -1.427837
[ Info: iteration 8, average log likelihood -1.427343
[ Info: iteration 9, average log likelihood -1.426490
[ Info: iteration 10, average log likelihood -1.425350
[ Info: iteration 11, average log likelihood -1.424309
[ Info: iteration 12, average log likelihood -1.423670
[ Info: iteration 13, average log likelihood -1.423376
[ Info: iteration 14, average log likelihood -1.423258
[ Info: iteration 15, average log likelihood -1.423211
[ Info: iteration 16, average log likelihood -1.423192
[ Info: iteration 17, average log likelihood -1.423184
[ Info: iteration 18, average log likelihood -1.423180
[ Info: iteration 19, average log likelihood -1.423178
[ Info: iteration 20, average log likelihood -1.423177
[ Info: iteration 21, average log likelihood -1.423177
[ Info: iteration 22, average log likelihood -1.423176
[ Info: iteration 23, average log likelihood -1.423176
[ Info: iteration 24, average log likelihood -1.423176
[ Info: iteration 25, average log likelihood -1.423175
[ Info: iteration 26, average log likelihood -1.423175
[ Info: iteration 27, average log likelihood -1.423175
[ Info: iteration 28, average log likelihood -1.423174
[ Info: iteration 29, average log likelihood -1.423174
[ Info: iteration 30, average log likelihood -1.423174
[ Info: iteration 31, average log likelihood -1.423174
[ Info: iteration 32, average log likelihood -1.423174
[ Info: iteration 33, average log likelihood -1.423174
[ Info: iteration 34, average log likelihood -1.423173
[ Info: iteration 35, average log likelihood -1.423173
[ Info: iteration 36, average log likelihood -1.423173
[ Info: iteration 37, average log likelihood -1.423173
[ Info: iteration 38, average log likelihood -1.423173
[ Info: iteration 39, average log likelihood -1.423173
[ Info: iteration 40, average log likelihood -1.423173
[ Info: iteration 41, average log likelihood -1.423173
[ Info: iteration 42, average log likelihood -1.423173
[ Info: iteration 43, average log likelihood -1.423173
[ Info: iteration 44, average log likelihood -1.423173
[ Info: iteration 45, average log likelihood -1.423173
[ Info: iteration 46, average log likelihood -1.423173
[ Info: iteration 47, average log likelihood -1.423173
[ Info: iteration 48, average log likelihood -1.423173
[ Info: iteration 49, average log likelihood -1.423173
[ Info: iteration 50, average log likelihood -1.423173
┌ Info: EM with 100000 data points 50 iterations avll -1.423173
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4285284214707794
│     -1.4284617334349186
│      ⋮
└     -1.4231726061743333
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423188
[ Info: iteration 2, average log likelihood -1.423129
[ Info: iteration 3, average log likelihood -1.423084
[ Info: iteration 4, average log likelihood -1.423032
[ Info: iteration 5, average log likelihood -1.422969
[ Info: iteration 6, average log likelihood -1.422895
[ Info: iteration 7, average log likelihood -1.422812
[ Info: iteration 8, average log likelihood -1.422727
[ Info: iteration 9, average log likelihood -1.422646
[ Info: iteration 10, average log likelihood -1.422576
[ Info: iteration 11, average log likelihood -1.422519
[ Info: iteration 12, average log likelihood -1.422475
[ Info: iteration 13, average log likelihood -1.422444
[ Info: iteration 14, average log likelihood -1.422421
[ Info: iteration 15, average log likelihood -1.422405
[ Info: iteration 16, average log likelihood -1.422393
[ Info: iteration 17, average log likelihood -1.422384
[ Info: iteration 18, average log likelihood -1.422377
[ Info: iteration 19, average log likelihood -1.422371
[ Info: iteration 20, average log likelihood -1.422366
[ Info: iteration 21, average log likelihood -1.422361
[ Info: iteration 22, average log likelihood -1.422356
[ Info: iteration 23, average log likelihood -1.422352
[ Info: iteration 24, average log likelihood -1.422348
[ Info: iteration 25, average log likelihood -1.422343
[ Info: iteration 26, average log likelihood -1.422339
[ Info: iteration 27, average log likelihood -1.422335
[ Info: iteration 28, average log likelihood -1.422330
[ Info: iteration 29, average log likelihood -1.422326
[ Info: iteration 30, average log likelihood -1.422321
[ Info: iteration 31, average log likelihood -1.422316
[ Info: iteration 32, average log likelihood -1.422311
[ Info: iteration 33, average log likelihood -1.422306
[ Info: iteration 34, average log likelihood -1.422301
[ Info: iteration 35, average log likelihood -1.422295
[ Info: iteration 36, average log likelihood -1.422289
[ Info: iteration 37, average log likelihood -1.422283
[ Info: iteration 38, average log likelihood -1.422276
[ Info: iteration 39, average log likelihood -1.422269
[ Info: iteration 40, average log likelihood -1.422261
[ Info: iteration 41, average log likelihood -1.422253
[ Info: iteration 42, average log likelihood -1.422245
[ Info: iteration 43, average log likelihood -1.422236
[ Info: iteration 44, average log likelihood -1.422227
[ Info: iteration 45, average log likelihood -1.422217
[ Info: iteration 46, average log likelihood -1.422208
[ Info: iteration 47, average log likelihood -1.422198
[ Info: iteration 48, average log likelihood -1.422188
[ Info: iteration 49, average log likelihood -1.422178
[ Info: iteration 50, average log likelihood -1.422168
┌ Info: EM with 100000 data points 50 iterations avll -1.422168
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4231877392915664
│     -1.423129360195036
│      ⋮
└     -1.4221676047384029
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422169
[ Info: iteration 2, average log likelihood -1.422106
[ Info: iteration 3, average log likelihood -1.422049
[ Info: iteration 4, average log likelihood -1.421985
[ Info: iteration 5, average log likelihood -1.421910
[ Info: iteration 6, average log likelihood -1.421822
[ Info: iteration 7, average log likelihood -1.421725
[ Info: iteration 8, average log likelihood -1.421623
[ Info: iteration 9, average log likelihood -1.421522
[ Info: iteration 10, average log likelihood -1.421427
[ Info: iteration 11, average log likelihood -1.421339
[ Info: iteration 12, average log likelihood -1.421261
[ Info: iteration 13, average log likelihood -1.421193
[ Info: iteration 14, average log likelihood -1.421136
[ Info: iteration 15, average log likelihood -1.421089
[ Info: iteration 16, average log likelihood -1.421051
[ Info: iteration 17, average log likelihood -1.421021
[ Info: iteration 18, average log likelihood -1.420998
[ Info: iteration 19, average log likelihood -1.420979
[ Info: iteration 20, average log likelihood -1.420964
[ Info: iteration 21, average log likelihood -1.420952
[ Info: iteration 22, average log likelihood -1.420941
[ Info: iteration 23, average log likelihood -1.420932
[ Info: iteration 24, average log likelihood -1.420924
[ Info: iteration 25, average log likelihood -1.420917
[ Info: iteration 26, average log likelihood -1.420910
[ Info: iteration 27, average log likelihood -1.420904
[ Info: iteration 28, average log likelihood -1.420898
[ Info: iteration 29, average log likelihood -1.420893
[ Info: iteration 30, average log likelihood -1.420888
[ Info: iteration 31, average log likelihood -1.420883
[ Info: iteration 32, average log likelihood -1.420879
[ Info: iteration 33, average log likelihood -1.420874
[ Info: iteration 34, average log likelihood -1.420870
[ Info: iteration 35, average log likelihood -1.420865
[ Info: iteration 36, average log likelihood -1.420861
[ Info: iteration 37, average log likelihood -1.420857
[ Info: iteration 38, average log likelihood -1.420853
[ Info: iteration 39, average log likelihood -1.420849
[ Info: iteration 40, average log likelihood -1.420845
[ Info: iteration 41, average log likelihood -1.420841
[ Info: iteration 42, average log likelihood -1.420837
[ Info: iteration 43, average log likelihood -1.420833
[ Info: iteration 44, average log likelihood -1.420828
[ Info: iteration 45, average log likelihood -1.420824
[ Info: iteration 46, average log likelihood -1.420820
[ Info: iteration 47, average log likelihood -1.420816
[ Info: iteration 48, average log likelihood -1.420811
[ Info: iteration 49, average log likelihood -1.420806
[ Info: iteration 50, average log likelihood -1.420802
┌ Info: EM with 100000 data points 50 iterations avll -1.420802
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4221687038037267
│     -1.4221056804002057
│      ⋮
└     -1.4208017738606067
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420808
[ Info: iteration 2, average log likelihood -1.420752
[ Info: iteration 3, average log likelihood -1.420704
[ Info: iteration 4, average log likelihood -1.420652
[ Info: iteration 5, average log likelihood -1.420590
[ Info: iteration 6, average log likelihood -1.420516
[ Info: iteration 7, average log likelihood -1.420429
[ Info: iteration 8, average log likelihood -1.420331
[ Info: iteration 9, average log likelihood -1.420228
[ Info: iteration 10, average log likelihood -1.420123
[ Info: iteration 11, average log likelihood -1.420021
[ Info: iteration 12, average log likelihood -1.419926
[ Info: iteration 13, average log likelihood -1.419839
[ Info: iteration 14, average log likelihood -1.419760
[ Info: iteration 15, average log likelihood -1.419688
[ Info: iteration 16, average log likelihood -1.419624
[ Info: iteration 17, average log likelihood -1.419567
[ Info: iteration 18, average log likelihood -1.419516
[ Info: iteration 19, average log likelihood -1.419469
[ Info: iteration 20, average log likelihood -1.419427
[ Info: iteration 21, average log likelihood -1.419387
[ Info: iteration 22, average log likelihood -1.419351
[ Info: iteration 23, average log likelihood -1.419317
[ Info: iteration 24, average log likelihood -1.419285
[ Info: iteration 25, average log likelihood -1.419255
[ Info: iteration 26, average log likelihood -1.419227
[ Info: iteration 27, average log likelihood -1.419200
[ Info: iteration 28, average log likelihood -1.419174
[ Info: iteration 29, average log likelihood -1.419149
[ Info: iteration 30, average log likelihood -1.419126
[ Info: iteration 31, average log likelihood -1.419103
[ Info: iteration 32, average log likelihood -1.419081
[ Info: iteration 33, average log likelihood -1.419060
[ Info: iteration 34, average log likelihood -1.419040
[ Info: iteration 35, average log likelihood -1.419021
[ Info: iteration 36, average log likelihood -1.419002
[ Info: iteration 37, average log likelihood -1.418984
[ Info: iteration 38, average log likelihood -1.418967
[ Info: iteration 39, average log likelihood -1.418950
[ Info: iteration 40, average log likelihood -1.418934
[ Info: iteration 41, average log likelihood -1.418919
[ Info: iteration 42, average log likelihood -1.418904
[ Info: iteration 43, average log likelihood -1.418889
[ Info: iteration 44, average log likelihood -1.418875
[ Info: iteration 45, average log likelihood -1.418862
[ Info: iteration 46, average log likelihood -1.418849
[ Info: iteration 47, average log likelihood -1.418837
[ Info: iteration 48, average log likelihood -1.418825
[ Info: iteration 49, average log likelihood -1.418813
[ Info: iteration 50, average log likelihood -1.418802
┌ Info: EM with 100000 data points 50 iterations avll -1.418802
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4208080802324565
│     -1.4207517335782087
│      ⋮
└     -1.4188023995014913
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418800
[ Info: iteration 2, average log likelihood -1.418736
[ Info: iteration 3, average log likelihood -1.418675
[ Info: iteration 4, average log likelihood -1.418605
[ Info: iteration 5, average log likelihood -1.418520
[ Info: iteration 6, average log likelihood -1.418416
[ Info: iteration 7, average log likelihood -1.418293
[ Info: iteration 8, average log likelihood -1.418154
[ Info: iteration 9, average log likelihood -1.418005
[ Info: iteration 10, average log likelihood -1.417855
[ Info: iteration 11, average log likelihood -1.417711
[ Info: iteration 12, average log likelihood -1.417576
[ Info: iteration 13, average log likelihood -1.417455
[ Info: iteration 14, average log likelihood -1.417347
[ Info: iteration 15, average log likelihood -1.417251
[ Info: iteration 16, average log likelihood -1.417168
[ Info: iteration 17, average log likelihood -1.417094
[ Info: iteration 18, average log likelihood -1.417029
[ Info: iteration 19, average log likelihood -1.416971
[ Info: iteration 20, average log likelihood -1.416919
[ Info: iteration 21, average log likelihood -1.416873
[ Info: iteration 22, average log likelihood -1.416832
[ Info: iteration 23, average log likelihood -1.416794
[ Info: iteration 24, average log likelihood -1.416760
[ Info: iteration 25, average log likelihood -1.416730
[ Info: iteration 26, average log likelihood -1.416701
[ Info: iteration 27, average log likelihood -1.416675
[ Info: iteration 28, average log likelihood -1.416651
[ Info: iteration 29, average log likelihood -1.416628
[ Info: iteration 30, average log likelihood -1.416607
[ Info: iteration 31, average log likelihood -1.416587
[ Info: iteration 32, average log likelihood -1.416568
[ Info: iteration 33, average log likelihood -1.416550
[ Info: iteration 34, average log likelihood -1.416533
[ Info: iteration 35, average log likelihood -1.416517
[ Info: iteration 36, average log likelihood -1.416501
[ Info: iteration 37, average log likelihood -1.416485
[ Info: iteration 38, average log likelihood -1.416470
[ Info: iteration 39, average log likelihood -1.416456
[ Info: iteration 40, average log likelihood -1.416442
[ Info: iteration 41, average log likelihood -1.416428
[ Info: iteration 42, average log likelihood -1.416415
[ Info: iteration 43, average log likelihood -1.416401
[ Info: iteration 44, average log likelihood -1.416388
[ Info: iteration 45, average log likelihood -1.416375
[ Info: iteration 46, average log likelihood -1.416363
[ Info: iteration 47, average log likelihood -1.416350
[ Info: iteration 48, average log likelihood -1.416338
[ Info: iteration 49, average log likelihood -1.416326
[ Info: iteration 50, average log likelihood -1.416314
┌ Info: EM with 100000 data points 50 iterations avll -1.416314
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.418800259660531
│     -1.4187359329287805
│      ⋮
└     -1.4163139961825004
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4285093310305752
│     -1.4285284214707794
│     -1.4284617334349186
│     -1.428408123887053
│      ⋮
│     -1.4163381496037586
│     -1.4163260063677638
└     -1.4163139961825004
32×26 Array{Float64,2}:
 -0.292988    0.471895   -0.476495   -0.087495    -0.286818    -0.5704       0.0647337   -0.270736    -0.0392697    0.0956995   -0.57373     0.00827595  -0.760311      0.256997     0.0940904    0.161179    0.293284      0.107108    0.168272    -0.0833584   -0.421284   -0.949489    -0.109935    0.457738    0.718362     0.318246
 -0.179338    0.0847507  -0.310325   -0.74506      0.125287    -0.0240801    0.486405     0.0879259    0.353449     0.177192    -0.596628    0.110554     0.142287      0.399717    -0.216583     0.271325    0.249246      0.215994    0.102215     0.32731     -0.526963   -0.266365    -0.0445267  -0.10693    -0.169021     0.0320965
 -0.705364   -0.0716274   0.475109   -0.125031    -0.220131     0.218362     0.149247     0.847249     0.00360057   0.151214    -0.402031    0.163599    -0.017979      0.123315     0.198288    -0.39272    -0.260934     -0.230768   -0.0156042    0.325277    -0.546657    0.525834    -0.11494     0.13086     0.495152    -0.0221743
  0.420247    0.123965   -0.32943    -0.316482     0.149355    -0.0206036   -0.240104     0.276489     0.168204     0.0811575   -0.478087    0.176178    -0.16316      -0.0367171    0.00921494   0.336107    0.363564     -0.0463341  -0.294156     0.238973    -0.559227    0.93147      0.598444    0.318454    0.0754304   -0.24155
 -0.264988   -0.315951   -0.146596    0.0367875   -0.0988898   -0.100174    -0.627951     0.537906    -0.0252036    0.194444     0.0872716   0.244741     0.380696      0.407208     0.416498    -0.620246    0.0191012     0.398791    0.137194     0.285971    -0.504615    0.068687     0.0951277  -0.698383   -0.325196    -0.602702
 -0.390087    0.401504   -0.110429   -0.459588     0.503134     0.0994495   -0.738518     0.00329001  -0.676666     0.460837    -0.0339971   0.158076     0.272867      0.913758    -0.0862213    0.34026     0.178327     -0.224298    0.25163     -0.00598389  -0.145723   -0.0486835   -0.0108133  -0.259439   -0.146283     0.252166
  0.154015    0.143783    0.735505   -0.145422     0.286255     0.589021    -0.0490447    0.0132467   -0.543892     0.119935     0.668731   -0.0494371   -0.147287     -0.393469    -0.353889     0.330855   -0.37523      -0.0622643  -0.225224    -0.0966835   -0.208987    0.274516     0.147548    0.136504    0.058453     0.10503
 -0.177393    0.0965442  -0.525133   -0.205632     0.0786226   -0.0264401   -0.163391    -0.307754    -0.373163    -0.159855     0.52662    -0.39885      0.450869      0.0930352    0.480388     0.959188   -0.157418      0.233745   -0.428891    -0.133152     0.0804146   0.40917     -0.676128    0.0661724   0.0133595   -0.385114
 -0.150114   -0.311347   -0.219949    0.0637951   -0.174531    -0.00423506   0.371091     0.445776    -1.73731e-5  -0.16414     -0.152959   -0.734314    -0.0513877    -0.343605     0.260361    -0.0592396  -0.146666     -0.32371     0.360363     0.205052     0.053257   -0.163702    -0.553791    0.115084   -0.42454      0.563856
  0.0670017   0.0446294  -0.180178    0.0505912   -0.0259335   -0.098094     0.0243225   -0.213869     0.285828    -0.00730828   0.0242689   0.328334     0.065283      0.214202     0.0393484   -0.165742    0.0854967     0.0753728  -0.0955115   -0.129836    -0.0319257  -0.032279     0.172501   -0.101327   -0.0626149   -0.139227
  0.276985    0.0754737   0.212047    0.381697    -0.301978    -0.298013    -0.679358    -0.115109    -0.193541    -0.551793     0.766947   -0.263121    -0.111486     -0.0951565    0.255353    -0.665144   -0.231034      0.0341498   0.15124     -0.264601     0.493868   -0.121692    -0.128999    0.318571   -0.439948     0.432133
  0.228678   -0.0110665   0.170039    1.1177      -0.51187     -0.104058     0.663754     0.0276956    0.214494    -0.836645     0.213346    0.213946    -0.247344     -0.549599     0.182163    -0.231028   -0.568335     -0.303774   -0.545221    -0.06304      0.634893   -0.209545    -0.273086    0.335069    0.341665    -0.195062
  0.545849    0.0979201   0.449472    0.624629     0.0678166    0.401861     0.034899    -0.147565    -0.202802     0.249513    -0.300048    0.710662     0.297989     -0.891577    -0.0938934    0.243747    1.20359      -0.273229    0.561177    -0.201166    -0.162013   -0.958369     0.553442    0.101015   -0.370418     0.0979279
  0.270659   -0.0771324   0.127594    0.82166      0.184194     0.097895     0.0911489   -0.026656    -0.273465     0.315591     0.173194    0.152288     0.315055     -0.407686    -0.148338     0.140163    0.572291      0.0631577   0.211834    -0.00220834  -0.149803   -0.469212    -0.417441    0.0811125   0.831184     0.103957
  0.410141    0.0626067   0.782123    0.0280772    0.00733061  -0.545904    -0.0423826   -0.0331812    0.0582203    0.115169    -0.436085    0.274614    -0.634254      0.182156    -0.685031    -0.608089    0.151847     -0.144839    0.668697     0.0778249   -0.270252   -0.241845     0.529779    0.146607   -0.119712     0.00591102
  0.672669    0.320512    0.670802   -0.284045     0.0050928    0.542184     0.566216    -0.396813     0.641996    -0.595104    -0.351355    0.250122    -0.319605     -0.0114531   -0.596581    -0.207669    0.483812      0.179283    0.0485683   -0.103523     0.390535   -0.39837      0.146943    0.458158   -0.0739016   -0.167481
 -0.0965584  -0.291877   -0.404847    0.0295839    0.0639658   -0.142804    -0.174546     0.222037     0.199351    -0.0992831   -0.0530131  -0.630524    -0.13653      -0.250187     0.335469     0.029014    0.450943      0.198731    0.0394114    0.368157    -0.468198    0.114698    -0.672671    0.231946   -0.32011      0.434595
 -0.335317   -0.912745    0.149463    0.369929    -0.75801      0.0644303    0.0529752   -0.154884    -0.182565    -0.115978    -0.0569867  -0.271342    -0.000919799  -0.122066    -0.202549    -0.104278   -0.355756      0.0684173  -0.196556    -0.24683     -0.308787   -0.128995     0.0611164   0.06497    -0.328907     0.54493
  0.224771   -0.120232    0.5545     -0.0753655   -0.0682185   -0.0743364   -0.235945    -0.225873     0.0141156   -0.356749     0.362814    0.186842    -0.359552     -0.0514292   -0.0551945   -0.335897    0.149535      0.212194   -0.0787411   -0.0930217   -0.186326   -0.0644578   -0.129789    0.320764   -0.0577132    0.0345854
  0.0806834   0.242994    0.413529    0.258058    -0.260624     0.0518227    0.307573     0.0550072   -0.0422633    0.368351    -0.0777401   0.290746    -0.179692     -0.277048     0.104406    -0.500066    0.259817     -0.0996216   0.454237     0.0882926   -0.0526963  -0.0912537   -0.0558825  -0.0233413   0.0569662    0.0319342
 -0.318003    0.69084    -0.256259    0.116375     0.667617    -0.135506    -0.557874     0.37186     -0.104915     0.263617     0.0433159  -0.0924423   -0.416369     -0.0609632    0.156974     0.0386811   0.189996      0.176893    0.119997    -0.431659     0.40682    -0.336659    -0.0182668   0.414578   -0.0581127   -0.0779709
  0.342958    0.774257   -0.0672959  -0.471836     0.690122    -0.0331293   -0.0820573   -0.0289201    0.0889331    0.0607544    0.129708    0.262357    -0.0678218     0.133199     0.101228     0.466832    0.230746     -0.137961    0.0752251    0.411216     0.0110366   0.160968    -0.119181    0.17556     0.427257    -0.431782
 -0.113369    0.119486   -0.126742    0.0283577    0.0112907   -0.266877    -0.131813     0.0586813   -0.195488     0.0425077   -0.0209787   0.0150296    0.16174       0.24192     -0.0292521   -0.0419877   0.0199548     0.164388    0.0228378    0.168802    -0.0997699  -0.112194    -0.0138959  -0.113841   -0.0632045   -0.0459932
 -0.0250178  -0.0167245  -0.185465   -0.00257692   0.16443      0.289887     0.0570952    0.00100213   0.172744     0.0468453   -0.0591677  -0.0613536    0.00011069   -0.10104     -0.061065     0.235884   -0.0336322    -0.209083   -0.117058    -0.175238     0.0687993   0.103597     0.145614    0.0204165  -0.00485436  -0.0291339
 -0.306828    0.227967   -0.529144    0.622986    -0.203494     0.0024072    0.343556    -0.692425     0.316811     0.274266    -0.160931   -0.275821     0.0686893     0.00949925   0.210138    -0.104777   -0.0369618    -0.722533    0.526648    -0.361227     0.906625   -0.185655     0.0257875  -0.158373   -0.0787834   -0.0151687
  0.0718087  -0.193994   -0.582343    0.38328      0.211185     0.273829     0.00051603   0.413475     0.445446     0.235356    -0.211382    0.1433       0.0527713    -0.408654     0.0232468   -0.258986   -0.171623     -0.279831    4.25839e-5  -0.423593     0.606875    0.0611377    0.461401   -0.429976   -0.352041     0.101039
 -0.458124    0.101413    0.154284   -0.258052     0.51134     -0.0798785    0.17244     -0.563445     0.44386     -0.118288     0.175338    0.458759    -0.29958       0.0598641    0.113468    -0.29387    -0.263984     -0.0750444  -0.672538    -0.376426     0.0456502   0.00671922   0.299614   -0.563602    0.0207719   -0.611905
  0.557297   -0.145483   -0.529125    0.140207     0.1709      -0.187351     0.199305    -0.537006     0.252943     0.33983      0.550779    0.229761     0.0355971    -0.162897    -0.290673     0.376039   -0.000431951   0.771767   -0.221836    -0.284778    -0.0962366  -0.480218     0.429882   -0.63842    -0.248452    -0.694225
 -0.353682    0.343416   -0.157616   -0.496047     0.0223166   -0.378274     0.0333896    0.130869    -0.0397486   -0.209776     0.133225   -0.245412    -0.460114      0.406352     0.282579    -0.143582   -0.978197     -0.430799   -0.347631     0.0815084    0.184415    0.854778    -0.0335154  -0.0543909  -0.261747     0.208969
  0.258767   -0.233553    0.177237    0.00475467   0.0557499    0.274694    -0.120345     0.298221    -0.0018636   -0.53514      0.195839   -0.241623     0.571318      0.441381    -0.411262    -0.131354   -0.474772     -0.181005   -0.371418    -0.19419      0.471605    0.507701    -0.1725     -0.331633   -0.238218    -0.148752
  0.30965    -0.406543    0.387698    0.0421211   -0.630969    -0.0493294    0.675836    -0.598105    -0.215869    -0.0979375   -0.17756     0.0351612    0.964579      0.21224     -0.919831     0.0930162  -0.0137203    -0.289698    0.347337     0.573366    -0.259104   -0.350812    -0.180732   -0.475799   -0.0200367   -0.241058
  0.226491   -0.0921827  -0.194231   -0.00522516  -0.521512    -0.1951       0.330766    -0.0944725   -0.379486    -0.0138236    0.277366    0.16612      0.526011     -0.115821     0.574542     0.564554   -0.248649      0.0516643  -0.151579     0.209409     0.040044    0.0872913   -0.237972    0.0916302   0.242021     0.0884938[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416302
[ Info: iteration 2, average log likelihood -1.416290
[ Info: iteration 3, average log likelihood -1.416279
[ Info: iteration 4, average log likelihood -1.416267
[ Info: iteration 5, average log likelihood -1.416256
[ Info: iteration 6, average log likelihood -1.416244
[ Info: iteration 7, average log likelihood -1.416233
[ Info: iteration 8, average log likelihood -1.416222
[ Info: iteration 9, average log likelihood -1.416211
[ Info: iteration 10, average log likelihood -1.416200
┌ Info: EM with 100000 data points 10 iterations avll -1.416200
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.695789e+05
      1       7.194904e+05      -2.500885e+05 |       32
      2       7.014299e+05      -1.806044e+04 |       32
      3       6.946955e+05      -6.734465e+03 |       32
      4       6.916471e+05      -3.048413e+03 |       32
      5       6.898955e+05      -1.751561e+03 |       32
      6       6.886758e+05      -1.219661e+03 |       32
      7       6.877501e+05      -9.257822e+02 |       32
      8       6.870354e+05      -7.146963e+02 |       32
      9       6.864113e+05      -6.240403e+02 |       32
     10       6.859136e+05      -4.977343e+02 |       32
     11       6.854899e+05      -4.236748e+02 |       32
     12       6.850935e+05      -3.964453e+02 |       32
     13       6.847218e+05      -3.716456e+02 |       32
     14       6.844087e+05      -3.131561e+02 |       32
     15       6.841339e+05      -2.747871e+02 |       32
     16       6.838887e+05      -2.451371e+02 |       32
     17       6.836827e+05      -2.060472e+02 |       32
     18       6.835017e+05      -1.809609e+02 |       32
     19       6.833288e+05      -1.729000e+02 |       32
     20       6.831654e+05      -1.634852e+02 |       32
     21       6.830220e+05      -1.433102e+02 |       32
     22       6.828861e+05      -1.359513e+02 |       32
     23       6.827505e+05      -1.355569e+02 |       32
     24       6.826208e+05      -1.297179e+02 |       32
     25       6.825092e+05      -1.116438e+02 |       32
     26       6.824083e+05      -1.008780e+02 |       32
     27       6.823100e+05      -9.830824e+01 |       32
     28       6.822153e+05      -9.469370e+01 |       32
     29       6.821292e+05      -8.613892e+01 |       32
     30       6.820459e+05      -8.321858e+01 |       32
     31       6.819687e+05      -7.721768e+01 |       32
     32       6.819058e+05      -6.295994e+01 |       32
     33       6.818517e+05      -5.410714e+01 |       32
     34       6.817935e+05      -5.811076e+01 |       32
     35       6.817361e+05      -5.741395e+01 |       32
     36       6.816890e+05      -4.707957e+01 |       32
     37       6.816442e+05      -4.482198e+01 |       32
     38       6.816047e+05      -3.951174e+01 |       32
     39       6.815660e+05      -3.866894e+01 |       32
     40       6.815292e+05      -3.682858e+01 |       32
     41       6.814908e+05      -3.843518e+01 |       32
     42       6.814574e+05      -3.333531e+01 |       32
     43       6.814270e+05      -3.039773e+01 |       32
     44       6.813963e+05      -3.076564e+01 |       32
     45       6.813690e+05      -2.727824e+01 |       32
     46       6.813431e+05      -2.587968e+01 |       32
     47       6.813131e+05      -3.006074e+01 |       32
     48       6.812778e+05      -3.528991e+01 |       32
     49       6.812460e+05      -3.181769e+01 |       32
     50       6.812177e+05      -2.825477e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 681217.7003744522)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427810
[ Info: iteration 2, average log likelihood -1.422719
[ Info: iteration 3, average log likelihood -1.421311
[ Info: iteration 4, average log likelihood -1.420290
[ Info: iteration 5, average log likelihood -1.419264
[ Info: iteration 6, average log likelihood -1.418325
[ Info: iteration 7, average log likelihood -1.417651
[ Info: iteration 8, average log likelihood -1.417251
[ Info: iteration 9, average log likelihood -1.417018
[ Info: iteration 10, average log likelihood -1.416865
[ Info: iteration 11, average log likelihood -1.416751
[ Info: iteration 12, average log likelihood -1.416661
[ Info: iteration 13, average log likelihood -1.416585
[ Info: iteration 14, average log likelihood -1.416519
[ Info: iteration 15, average log likelihood -1.416462
[ Info: iteration 16, average log likelihood -1.416412
[ Info: iteration 17, average log likelihood -1.416366
[ Info: iteration 18, average log likelihood -1.416325
[ Info: iteration 19, average log likelihood -1.416288
[ Info: iteration 20, average log likelihood -1.416253
[ Info: iteration 21, average log likelihood -1.416221
[ Info: iteration 22, average log likelihood -1.416190
[ Info: iteration 23, average log likelihood -1.416162
[ Info: iteration 24, average log likelihood -1.416135
[ Info: iteration 25, average log likelihood -1.416109
[ Info: iteration 26, average log likelihood -1.416085
[ Info: iteration 27, average log likelihood -1.416061
[ Info: iteration 28, average log likelihood -1.416039
[ Info: iteration 29, average log likelihood -1.416017
[ Info: iteration 30, average log likelihood -1.415996
[ Info: iteration 31, average log likelihood -1.415976
[ Info: iteration 32, average log likelihood -1.415956
[ Info: iteration 33, average log likelihood -1.415937
[ Info: iteration 34, average log likelihood -1.415919
[ Info: iteration 35, average log likelihood -1.415901
[ Info: iteration 36, average log likelihood -1.415883
[ Info: iteration 37, average log likelihood -1.415867
[ Info: iteration 38, average log likelihood -1.415850
[ Info: iteration 39, average log likelihood -1.415834
[ Info: iteration 40, average log likelihood -1.415819
[ Info: iteration 41, average log likelihood -1.415804
[ Info: iteration 42, average log likelihood -1.415790
[ Info: iteration 43, average log likelihood -1.415776
[ Info: iteration 44, average log likelihood -1.415763
[ Info: iteration 45, average log likelihood -1.415750
[ Info: iteration 46, average log likelihood -1.415738
[ Info: iteration 47, average log likelihood -1.415726
[ Info: iteration 48, average log likelihood -1.415714
[ Info: iteration 49, average log likelihood -1.415703
[ Info: iteration 50, average log likelihood -1.415693
┌ Info: EM with 100000 data points 50 iterations avll -1.415693
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.281882     0.0158185    0.551588     0.654597   -0.088802    0.669933    -0.0968572  -0.223574    0.328635    -0.214901    -0.38644      0.862724     0.620372    0.0649693   -0.676841     0.0771301   0.928566    -0.274447    0.373148     0.118446   -0.0459811   -0.947775     0.349038   -0.273481   -0.234015     0.23439
  0.290867    -0.147133     0.196992     0.489604   -0.0646275   0.105953     0.332929   -0.61279    -0.0351784    0.504805     1.00182     -0.182265     0.147904   -0.338807    -0.363081     0.436631    0.0690628    0.745825    0.113854    -0.0218661  -0.52661     -0.233335    -0.114275   -0.122872    0.317761    -0.391795
  0.167525     0.0229906    0.122195    -0.125973   -0.519504   -0.0898479    0.922261   -0.154127   -0.00870131  -0.1669       0.00245834   0.0848674    0.623118    0.205218    -0.0408275   -0.0102086  -0.205944    -0.172134    0.309928     0.370174   -0.0575858    0.0725218   -0.495803   -0.2211     -0.00304457  -0.151119
  0.383975    -0.0818856    0.267066     0.0642548  -0.310669   -0.378574    -0.651238   -0.195985   -0.135084    -0.47346      0.831306    -0.234515    -0.119064    0.157508    -0.0729147   -0.589277   -0.226853     0.196619    0.0703226   -0.393431    0.290406    -0.0864835   -0.128265    0.175062   -0.558653     0.466088
  0.0218926   -0.123321     0.300227    -0.23919    -0.0491734   0.0686857   -0.478487    0.673984   -0.160413     0.110772    -0.0311552    0.13082      0.565535    0.475566    -0.0456279   -0.754705   -0.0925814    0.302795    0.410566     0.275132   -0.348707     0.353611     0.222738   -0.786211   -0.396141    -0.591024
 -0.180491     0.377795    -0.459637    -0.10799    -0.218805   -0.527391    -0.0630494  -0.205332   -0.0767625    0.225219    -0.598458     0.0016726   -0.589475    0.377828     0.0830041    0.116435    0.422878     0.239651    0.281545     0.0618598  -0.487927    -0.678385    -0.165224    0.188009    0.455992     0.158249
  0.377438     0.471579     0.644259    -0.30014     0.178721    1.13843      0.417374    0.160739    0.4708      -0.0591672    0.233458    -0.46665     -0.749516   -0.436726    -1.2062       0.337815    0.173693     0.0329405   0.206339    -0.392072    0.24059      0.31181     -0.164456   -0.358025   -0.13282      0.771309
 -0.436923    -0.0669183   -0.221046     0.652038   -0.176204   -0.0520499   -0.643731    0.683091   -0.715045     0.397937     0.274057     0.00507744   0.615099    0.202895     0.198327     0.237873   -0.229968    -0.127222   -0.125104     0.170735   -0.191127     0.0349067   -0.28626    -0.143471    0.169608     0.208991
 -0.00194632   0.0645585   -0.297992    -0.102422    0.146673    0.0309075    0.0124113   0.0353931   0.0715513    0.100868    -0.0406241   -0.0298629    0.0813318   0.0699554   -0.00398474   0.131854   -0.0582706   -0.0876739  -0.0207239    0.0219792   0.00862486   0.149528     0.159305   -0.0935423  -0.0702456   -0.114326
 -0.301491    -1.23606      0.00036699   0.291684   -1.15256    -0.02379      0.248477   -0.45332    -0.208692    -0.243325    -0.217694    -0.166787     0.212863   -0.0807874   -0.306739    -0.0118095  -0.510197     0.0173134  -0.371895    -0.0805509  -0.474712    -0.00257219   0.143122   -0.220204   -0.387357     0.577321
  0.593227     0.111396    -0.183861    -0.0592433   0.13841     0.096628     0.398699   -0.681531    0.570335    -0.361731    -0.0700314    0.0150413    0.0445349  -0.27598     -0.101508    -0.0582653   1.07115      0.334566   -0.0893663   -0.332001    0.541896    -0.425403     0.347545    0.644186    0.0277835   -0.460356
 -0.247788     0.569672    -0.390139    -0.0601418   0.467216   -0.0714607   -0.354536    0.0548231  -0.289636     0.0615782    0.034707    -0.272933     0.194113    0.215563    -0.0272139    0.315966    0.415642     0.0675281   0.0607236    0.0882704   0.314751    -0.36363     -0.360422    0.0210572  -0.120465     0.195639
  0.396117     0.0287432    0.36386      0.623951    0.128579    0.100802     0.197091    0.163323   -0.502269     0.525595    -0.193436     0.348127    -0.127789   -1.19548      0.236033     0.0162639   0.967743    -0.225612    0.541088    -0.0371765  -0.253345    -0.459453     0.230441    0.298168    0.0506814    0.0330703
  0.264886    -0.101848    -0.28549      0.0414239   0.136595   -0.0404987    0.0534238  -0.372939    0.264137     0.470875     0.233193     0.758993    -0.125075   -0.146271    -0.119607     0.0774984  -0.0921252    0.27401    -0.386943    -0.261784   -0.00792237  -0.2749       0.699262   -0.682906   -0.133872    -0.659184
  0.056488    -0.0468975    0.383288     0.185123   -0.166408    0.00128559  -0.0641552  -0.0319026  -0.0960674   -0.0648927    0.150523     0.112092    -0.141406   -0.134044     0.0410378   -0.204245    0.0964253    0.0762321   0.00662238  -0.0444215  -0.0986416   -0.0818387   -0.134459    0.178132    0.0554825    0.115354
 -0.230288     0.073013    -0.218148     0.71615    -0.0889675   0.0463528    0.218921   -0.228844    0.255789     0.609453    -0.234602    -0.0278329   -0.113945   -0.1137      -0.0469621   -0.47841    -0.0125309   -0.47497     0.544588    -0.424896    0.678827    -0.191888     0.132828   -0.316057   -0.178916     0.144258
  0.138771     0.15625     -0.923903     0.590443   -0.39104    -0.251131     0.24949    -0.283985    0.297059    -0.559241     0.288914    -0.196008     0.0712075  -0.46686      0.696871     0.312583   -0.408381    -0.124164   -0.0851608   -0.0192459   0.616127    -0.429925    -0.0549826   0.21358    -0.0306108    0.234363
  0.62854      0.127781     0.573743    -0.414005   -0.096894   -0.168919     0.184873   -0.112277    0.292572    -0.329743    -0.446306     0.162668    -0.634466    0.122124    -0.344497    -0.387024    0.318765    -0.106779    0.407506     0.387147   -0.278294    -0.0597307    0.309738    0.538217   -0.124215    -0.0404209
 -0.0736545    0.346989     0.436109    -0.412825    0.57578    -0.0940366    0.08605    -0.406366    0.195809    -0.528494     0.0523856    0.312252    -0.152042    0.435353    -0.31899     -0.0304206  -0.441417    -0.114725   -0.69341     -0.171209    0.311312     0.0904677   -0.0598301  -0.202039    0.00520103  -0.494587
 -0.271287    -0.448163    -0.360687    -0.027106    0.202573    0.593482    -0.146956    0.444346    0.483293    -0.362618    -0.0950607   -0.359163     0.235422    0.134464    -0.282145     0.119184   -0.399941    -0.293956   -0.400679    -0.514119    0.428781     0.392831     0.354817   -0.21212    -0.447581    -0.00997596
 -0.698516    -0.0528577    0.372282    -0.0236259   0.164335    0.110686    -0.381429    0.385282    0.060843     0.207823     0.227243     0.129664    -0.58626    -0.13944      0.289158    -0.594322   -0.141442     0.28879     0.254111    -0.433381   -0.500294    -0.0694111   -0.0858797   0.330157    0.0320131    0.0863917
  0.476594     1.09702     -0.0166317   -0.258447    1.05307     0.043251    -0.515596    0.326285    0.145079     0.217609     0.163406     0.431731    -0.13697     0.00259569   0.050061     0.303552    0.180988    -0.0464866  -0.0121749    0.0125754  -0.0692501    0.321595     0.138563    0.157032    0.477152    -0.565649
 -0.22131     -0.161631    -0.223195    -1.41611     0.638658   -0.129095    -0.187958   -0.28131     0.0752061    0.902713    -0.126225     0.019977     0.160118    0.50299     -0.27145      0.342915    0.367716     0.218263    0.305641     0.0913587  -0.86045      0.112273     0.247546   -0.374008   -0.447424     0.451415
  0.138339     0.0989221    0.507678    -0.499308    0.263466    0.0480461   -0.618085    0.298401   -0.549285    -0.404411     0.507397     0.331937    -0.105073    0.0538237   -0.266017     0.217166   -0.313659     0.039029   -0.948079     0.857972   -0.552625     0.686722     0.403005   -0.0289401  -0.616068     0.530551
 -0.0985125    0.0761255   -0.151472     0.0699448  -0.132751   -0.174063     0.123486    0.043297    0.126438    -0.00527882  -0.152753    -0.0063497   -0.130868    0.116352     0.0717158   -0.129656    0.00778868  -0.125977    0.140552     0.0107063   0.00278106  -0.197792    -0.0544066   0.0298494  -0.0791081    0.142978
  0.0451238   -0.606511    -0.588937     0.0488867   0.11695    -0.150397    -0.192097    0.290454    0.438151    -0.280761    -0.0830019   -0.354796    -0.0873478  -0.299842     0.498705    -0.0487657   0.380052     0.432467   -0.127561     0.503254   -0.640065     0.139279    -0.63765     0.0269371  -0.516909     0.149503
  0.27632     -0.15034      0.631609     1.1116     -0.238961    0.235504     0.198887    0.0519397  -0.168482    -0.759675     0.437136     0.0107033   -0.112197   -0.441444     0.111004    -0.418865   -0.629641    -0.445197   -0.308744    -0.133082    0.682597     0.151517    -0.280745    0.213814    0.0931298   -0.244373
 -0.378453    -0.00709469   0.0815829   -0.187274   -0.136492    0.179467     0.475548    0.505216    0.16912      0.129503    -0.866182     0.2241       0.0725762   0.189273     0.0491473    0.117048    0.105853    -0.131423   -0.195993     0.355334   -0.610049     0.172716     0.0866854   0.190225    0.475551    -0.217378
  0.0992141    0.0258854   -0.468574    -0.331037    0.104636   -0.0650138   -0.0549343  -0.371575   -0.391712    -0.0519064    0.346901    -0.165862     0.585623    0.289772     0.391513     0.850119   -0.0489269    0.247968   -0.328871    -0.119423   -0.109303     0.507569    -0.479331   -0.0738087  -0.0475763   -0.72599
  0.947005    -0.759301     0.441847    -0.138221    0.3485     -0.108593     0.263155    0.279066   -0.536342    -0.165051    -0.175371    -0.498041     0.682288   -0.590191    -0.511071     0.412041   -0.14249     -0.651156   -0.325817     0.121969    0.0624722    0.0135891   -0.42725     0.0539765   0.465417     0.620394
 -0.45963      0.596977     0.592737    -0.463771   -0.269868    0.757579     0.114456   -0.325304   -1.24724      0.276809     0.45852     -0.121043     0.100087    0.0224391   -0.0353479    0.426641   -0.364062    -0.311838    0.323164    -0.106279    0.240453     0.110933     0.482039    0.664706    0.700946     0.0297202
 -0.457127     0.300112    -0.269951    -0.442945    0.0543132  -0.290133     0.0808608   0.296002   -0.0222255    0.0594576    0.140486    -0.331958    -0.610436    0.020837     0.612644    -0.0103333  -0.760405    -0.381109   -0.208129    -0.0199164   0.137077     0.793818    -0.259969    0.153634   -0.0496274    0.317681[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415682
[ Info: iteration 2, average log likelihood -1.415673
[ Info: iteration 3, average log likelihood -1.415663
[ Info: iteration 4, average log likelihood -1.415654
[ Info: iteration 5, average log likelihood -1.415645
[ Info: iteration 6, average log likelihood -1.415637
[ Info: iteration 7, average log likelihood -1.415629
[ Info: iteration 8, average log likelihood -1.415622
[ Info: iteration 9, average log likelihood -1.415615
[ Info: iteration 10, average log likelihood -1.415608
┌ Info: EM with 100000 data points 10 iterations avll -1.415608
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
