Julia Version 1.5.0-DEV.84
Commit 833e6bf451 (2020-01-17 18:45 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed URIParser ────────── v0.4.0
 Installed Arpack ───────────── v0.4.0
 Installed NearestNeighbors ─── v0.4.4
 Installed StatsFuns ────────── v0.9.3
 Installed DataStructures ───── v0.17.9
 Installed BinaryProvider ───── v0.5.8
 Installed Clustering ───────── v0.13.3
 Installed DataAPI ──────────── v1.1.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Distances ────────── v0.8.2
 Installed Missings ─────────── v0.4.3
 Installed OrderedCollections ─ v1.1.0
 Installed CMake ────────────── v1.1.2
 Installed PDMats ───────────── v0.9.10
 Installed LegacyStrings ────── v0.4.1
 Installed StatsBase ────────── v0.32.0
 Installed Rmath ────────────── v0.6.0
 Installed FillArrays ───────── v0.8.4
 Installed SortingAlgorithms ── v0.3.1
 Installed JLD ──────────────── v0.9.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed Distributions ────── v0.22.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed SpecialFunctions ─── v0.9.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed ScikitLearnBase ──── v0.5.0
 Installed StaticArrays ─────── v0.12.1
 Installed HDF5 ─────────────── v0.12.5
 Installed Blosc ────────────── v0.5.1
 Installed FileIO ───────────── v1.2.1
 Installed QuadGK ───────────── v2.3.1
 Installed BinDeps ──────────── v1.0.0
 Installed Compat ───────────── v2.2.0
 Installed Parameters ───────── v0.12.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_4VDtop/Project.toml`
 [no changes]
  Updating `/tmp/jl_4VDtop/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_fbpRko/Project.toml`
 [no changes]
  Updating `/tmp/jl_fbpRko/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_yncIVT/Project.toml`
 [no changes]
  Updating `/tmp/jl_yncIVT/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_tMFRB7/Project.toml`
 [no changes]
  Updating `/tmp/jl_tMFRB7/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_6Elf4L/Project.toml`
 [no changes]
  Updating `/tmp/jl_6Elf4L/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_6Elf4L/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.5354618596752118e6, [97270.35418730647, 2729.6458126935286], [-6012.46064926615 -1078.5259120761373 860.3153589440349; 6033.381237680849 1370.3082114912863 -1025.7298860114593], [[86303.65610297685 -2323.7663578249303 2030.2173335730954; -2323.76635782493 97082.97717786342 1096.9749149588563; 2030.2173335730954 1096.9749149588565 96892.96416320179], [13859.894682157963 2492.9242623428345 -1886.1842733078518; 2492.9242623428345 3236.5728070273226 -540.388872645625; -1886.184273307852 -540.388872645625 3100.764605314691]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.686434e+03
      1       1.208919e+03      -4.775145e+02 |        6
      2       1.113213e+03      -9.570646e+01 |        2
      3       1.098086e+03      -1.512710e+01 |        0
      4       1.098086e+03       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 1098.0858772488145)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.063008
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.713018
[ Info: iteration 2, lowerbound -3.600430
[ Info: iteration 3, lowerbound -3.476260
[ Info: iteration 4, lowerbound -3.335979
[ Info: iteration 5, lowerbound -3.203518
[ Info: iteration 6, lowerbound -3.103825
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.040587
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.982068
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.915631
[ Info: iteration 10, lowerbound -2.837009
[ Info: iteration 11, lowerbound -2.747559
[ Info: iteration 12, lowerbound -2.652212
[ Info: iteration 13, lowerbound -2.557760
[ Info: iteration 14, lowerbound -2.469254
[ Info: iteration 15, lowerbound -2.395485
[ Info: iteration 16, lowerbound -2.345379
[ Info: iteration 17, lowerbound -2.322665
[ Info: dropping number of Gaussions to 3
[ Info: iteration 18, lowerbound -2.311179
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302931
[ Info: iteration 20, lowerbound -2.299262
[ Info: iteration 21, lowerbound -2.299257
[ Info: iteration 22, lowerbound -2.299255
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan 17 23:06:55 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan 17 23:07:02 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Fri Jan 17 23:07:05 2020: EM with 272 data points 0 iterations avll -2.063008
5.8 data points per parameter
, Fri Jan 17 23:07:07 2020: GMM converted to Variational GMM
, Fri Jan 17 23:07:15 2020: iteration 1, lowerbound -3.713018
, Fri Jan 17 23:07:15 2020: iteration 2, lowerbound -3.600430
, Fri Jan 17 23:07:15 2020: iteration 3, lowerbound -3.476260
, Fri Jan 17 23:07:15 2020: iteration 4, lowerbound -3.335979
, Fri Jan 17 23:07:15 2020: iteration 5, lowerbound -3.203518
, Fri Jan 17 23:07:15 2020: iteration 6, lowerbound -3.103825
, Fri Jan 17 23:07:16 2020: dropping number of Gaussions to 7
, Fri Jan 17 23:07:16 2020: iteration 7, lowerbound -3.040587
, Fri Jan 17 23:07:16 2020: dropping number of Gaussions to 5
, Fri Jan 17 23:07:16 2020: iteration 8, lowerbound -2.982068
, Fri Jan 17 23:07:16 2020: dropping number of Gaussions to 4
, Fri Jan 17 23:07:16 2020: iteration 9, lowerbound -2.915631
, Fri Jan 17 23:07:16 2020: iteration 10, lowerbound -2.837009
, Fri Jan 17 23:07:16 2020: iteration 11, lowerbound -2.747559
, Fri Jan 17 23:07:16 2020: iteration 12, lowerbound -2.652212
, Fri Jan 17 23:07:16 2020: iteration 13, lowerbound -2.557760
, Fri Jan 17 23:07:16 2020: iteration 14, lowerbound -2.469254
, Fri Jan 17 23:07:16 2020: iteration 15, lowerbound -2.395485
, Fri Jan 17 23:07:16 2020: iteration 16, lowerbound -2.345379
, Fri Jan 17 23:07:16 2020: iteration 17, lowerbound -2.322665
, Fri Jan 17 23:07:16 2020: dropping number of Gaussions to 3
, Fri Jan 17 23:07:16 2020: iteration 18, lowerbound -2.311179
, Fri Jan 17 23:07:16 2020: dropping number of Gaussions to 2
, Fri Jan 17 23:07:16 2020: iteration 19, lowerbound -2.302931
, Fri Jan 17 23:07:16 2020: iteration 20, lowerbound -2.299262
, Fri Jan 17 23:07:16 2020: iteration 21, lowerbound -2.299257
, Fri Jan 17 23:07:16 2020: iteration 22, lowerbound -2.299255
, Fri Jan 17 23:07:16 2020: iteration 23, lowerbound -2.299254
, Fri Jan 17 23:07:16 2020: iteration 24, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 25, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 26, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 27, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 28, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 29, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 30, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 31, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 32, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 33, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 34, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 35, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 36, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 37, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 38, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 39, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 40, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 41, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 42, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 43, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 44, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 45, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 46, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 47, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 48, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 49, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: iteration 50, lowerbound -2.299253
, Fri Jan 17 23:07:16 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398588, 178.0450922260141]
β = [95.95490777398588, 178.0450922260141]
m = [2.000229257775368 53.85198717246128; 4.250300733269908 79.28686694436182]
ν = [97.95490777398588, 180.0450922260141]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119484485 -0.008953123827346143; 0.0 0.012748664777409392], [0.1840415554748479 -0.007644049042327596; 0.0 0.008581705166333458]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000004
avll from stats: -0.9916634617336836
avll from llpg:  -0.9916634617336834
avll direct:     -0.9916634617336834
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9931991421790667
avll from llpg:  -0.9931991421790667
avll direct:     -0.9931991421790667
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0312224   0.0595777   -0.091299   -0.0226165     0.0775772    0.0596097    0.158872     0.00325179    0.220479     -0.185519     -0.0800805  -0.145934    0.0144574    0.132666   -0.206734     0.0803265    -0.0406775    0.212985     0.0800122   0.0413715    0.0190201   -0.0514638  -0.169169     0.0618816    0.0647469    0.0478077
  0.124763    0.0439284    0.0272803   0.0498847     0.0667949   -0.0518828   -0.0952361   -0.0338046     0.0522534    -0.128944      0.0409394  -0.028067   -0.0444427    0.0683638  -0.137462     0.0639574    -0.155474    -0.0717128   -0.0710517  -0.0549814    0.0986701   -0.0109338  -0.0088714   -0.00638912   0.0496042   -0.0760859
  0.021533    0.02217      0.0255639  -0.157917     -0.0424029   -0.0687343   -0.014609     0.0405011    -0.036666      0.0811047    -0.0851686   0.0383617   0.146722     0.187497   -0.09088      0.090463     -0.076576     0.115832    -0.09664    -0.025535     0.255751    -0.010444    0.0418185    0.116124    -0.154198    -0.0660009
  0.0171191  -0.0442793   -0.113464   -0.0599139    -0.156286     0.105913     0.0594066   -0.0797093     0.088745      0.116655      0.0982419  -0.0420714  -0.0947827   -0.182505   -0.0560324    0.0288971     0.0373277    0.0421208   -0.127956   -0.0812164    0.120572     0.0190696  -0.068729    -0.198107     0.122233     0.0146285
 -0.0930479  -0.0190315    0.0560024  -0.156294     -0.0559174   -0.0773907   -0.118297    -0.103314      0.065451      0.0873288    -0.0813057   0.0122402  -0.00726207  -0.167151    0.083964    -0.0839385    -0.024198    -0.0888894   -0.0798475   0.0206768   -0.0971844    0.100382   -0.0190637    0.0799991    0.291687    -0.0262474
  0.17137    -0.150495     0.0986798   0.0953197    -0.126131     0.160457    -0.212186     0.171031      0.0919156     0.0333957    -0.0788019  -0.0816166  -0.0396007   -0.0163836   0.11516      0.0465236     0.0535505    0.028736     0.0809773   0.136992     0.0330199    0.0822334  -0.095386    -0.144281    -0.0376081    0.0547103
  0.0350806   0.215821    -0.0721102  -0.0457097     0.143161    -0.0884506    0.155997    -0.0245061    -0.0471004    -0.0215206     0.151742    0.0169436   0.0497486    0.0711734   0.0605616    0.203397      0.0249406    0.299525    -0.116536   -0.116209    -0.00486296   0.0339104  -0.0379814   -0.0216217    0.00226288  -0.0393976
  0.113696   -0.231546     0.0454697   0.146882     -0.0183112   -0.0283393    0.219275    -0.0495758     0.00774774   -0.0686425    -0.0465227   0.166538    0.138368    -0.0307819  -0.0510342   -0.122529     -0.16994     -0.0575901   -0.0769719  -0.0895162   -0.0366255    0.0838176  -0.0510226    0.0443653   -0.0415377    0.0298669
 -0.0601133   0.0698717   -0.155859   -0.0273836     0.0769558   -0.114451     0.0908387    0.0746644     0.0700599     0.0329632     0.0683196  -0.0582667   0.0302558   -0.0648833   0.270229     0.0362083    -0.118842     0.207106    -0.0711334  -0.152385     0.0250625   -0.0859756  -0.0484585   -0.137396    -0.127913     0.158908
 -0.0939372   0.0317091    0.221152    0.00987656   -0.0637413   -0.0179853    0.0908326   -0.22997       0.0656398     0.0715799     0.0321693   0.0971505   0.0540617   -0.119372    0.119427    -0.10317      -0.0344582    0.0459251    0.129404   -0.0275778   -0.0870545   -0.0948538   0.107597    -0.0766447    0.13256      0.101724
  0.0704322  -0.00222059   0.14545     0.000806524   0.00360819  -0.060562    -0.198565    -0.127215      0.017804      0.0842238     0.0059196  -0.103062   -0.250056     0.0712235  -0.207679     0.103481      0.0381464   -0.0156536    0.0353693  -0.0969054    0.0194059    0.151058    0.0424334   -0.177224     0.0138198    0.0525655
 -0.131419    0.0539992   -0.147186    0.171697      0.247942    -0.119936     0.0731125   -0.0486618    -0.00484744    0.000821089  -0.0798396   0.0979073  -0.155171    -0.138741   -0.0570508    0.0886544     0.00932099   0.0501751   -0.0916794   0.116297     0.0339541    0.0249657  -0.0714178   -0.149416     0.0220274    0.0938612
  0.017614    0.0152742    0.0564278  -0.11991       0.00603215  -0.0216796   -0.0416665   -0.0799875     0.0668471    -0.0720448    -0.1586      0.076294    0.0241863   -0.0333953   0.202646    -0.0342495     0.0439583    0.054413     0.187764   -0.236044     0.101352     0.0642031   0.010841     0.194449    -0.20425      0.042289
  0.102478   -0.0265975   -0.101074    0.0840427     0.0429343    0.0266595    0.166906     0.0367044    -0.158398     -0.0903032     0.0226805   0.19312    -0.0299324    0.0292037  -0.0190535    0.0962901    -0.144632     0.036812    -0.0644373  -0.0591935   -0.0222112    0.0477546  -0.148295    -0.12655      0.0331879   -0.145555
 -0.102385   -0.00638953  -0.0595454   0.0143015     0.0728854    0.024679     0.086738     0.00379457   -0.143476      0.0568868    -0.0610117  -0.161323   -0.0960621   -0.107533   -0.0211764    0.0645192     0.0104274    0.129231    -0.0821074   0.0240457   -0.0555923    0.0280535  -0.0970651   -0.0665954    0.061303     0.0306546
 -0.0223431  -0.00560156   0.0717065   0.0398753     0.035731    -0.0149878    0.00225718   0.0966544    -0.00526652    0.0783716    -0.252578    0.0484639   0.073538    -0.0465591   0.183152     0.019024     -0.13687     -0.0293869   -0.0907915  -0.0504034    0.204582     0.077169   -0.153051     0.0397273    0.0976932   -0.0863204
  0.0473849  -0.0486067   -0.0429701   0.211054      0.00507255   0.050382     0.0688255   -0.0218403     0.163234     -0.0531955     0.14314     0.106756   -0.0322799   -0.114671   -0.0672269   -0.0384066    -0.0839429    0.0170705   -0.0408306   0.0807543   -0.0455215   -0.0476944   0.0433732   -0.0560502   -0.0879957   -0.0292555
  0.0119019  -0.00928914  -0.0414474  -0.110187     -0.0506559    0.0541077    0.0765716   -0.0273455     0.0880474    -0.0638779     0.0728464  -0.186341    0.120127    -0.0765423   0.00489249   0.153308      0.162706     0.00423977   0.114423    0.0583823    0.153189    -0.0107591   0.245852    -0.0358115    0.10619     -0.0151996
 -0.138742    0.0572508    0.0874176  -0.138213      0.0136647   -0.153538    -0.0123975   -0.253978     -0.0656542    -0.0761435    -0.0269169  -0.143638    0.0382927    0.0283453   0.152562    -0.0693357     0.0132105   -0.123732    -0.288171   -0.0597871   -0.0578531    0.0136175  -0.082885    -0.0282821    0.0787017   -0.146159
 -0.0141832   0.0443034    0.0822172   0.0505867    -0.090124    -0.0223165   -0.0334158   -0.180238     -0.0225943    -0.054155      0.158067    0.17063     0.100848     0.062166   -0.0459939    0.0546786    -0.0351691    0.0327398   -0.0791508  -0.0787113    0.0631601   -0.0528002   0.114892    -0.00341523  -0.0441041    0.0129066
  0.0358078  -0.255623    -0.0315641  -0.0154       -0.0090134    0.203669     0.0429376   -0.0239407    -0.145779      0.129422     -0.0853638  -0.0890312  -0.0866097   -0.0657     -0.0472896    0.159766     -0.0828737    0.0218894    0.0765874  -0.0846926   -0.0626634    0.0096062  -0.0449846   -0.16063      0.134501    -0.00840351
  0.123281    0.044221    -0.0223572   0.0565275    -0.00236783   0.0149856   -0.147144    -0.169354      0.231563      0.0599224     0.0203656   0.0353424   0.0687128    0.0568449   0.0416415   -0.11045      -0.00951126   0.185133    -0.0325829   0.156637    -0.0525779    0.0617093  -0.0891088    0.0052504    0.0590028   -0.106002
 -0.133404   -0.0448751   -0.0429815   0.103608     -0.102071    -0.103355    -0.0879941    0.000171137   0.0928962    -0.0448236     0.061188    0.153099   -0.109471    -0.0283522   0.180852     0.0255298     0.00113443   0.23839     -0.0267821  -0.139152    -0.0264787   -0.0342121   0.00860429   0.00680715  -0.0497083    0.0275334
 -0.181141    0.00512026  -0.204436   -0.191482      0.173951     0.24056     -0.11691      0.0378189    -0.159367      0.0954376    -0.0193417   0.193501   -0.0394934    0.139739   -0.262665     0.0298313    -0.0704405   -0.0853177    0.0244441   0.0814733    0.217044    -0.0327016  -0.0593332   -0.0969388   -0.106862     0.0230469
 -0.0118893  -0.0690796   -0.112668   -0.0460026    -0.0477162    0.102855     0.181349     0.101999     -0.105828      0.0425199     0.135975   -0.127951   -0.0172475    0.0517725  -0.076041    -0.000870885   0.0188248    0.13558      0.176574    0.023414     0.0775166    0.176824   -0.0823653   -0.0680427   -0.200067    -0.0820555
 -0.1169     -0.00631735   0.171699    0.16628      -0.11101     -0.0889853   -0.0364539   -0.00554819   -0.053742     -0.0411761     0.241766   -0.0211171   0.0159462    0.0231371   0.0586199   -0.181244     -0.0167487   -0.140766    -0.163451   -0.0565588    0.12349      0.041967   -0.0865667   -0.0695996    0.0872252   -0.0632546
 -0.118543   -0.0206246    0.0384185   0.0318445    -0.00557077   0.0218203    0.0875141    0.0382247    -0.139842      0.0258865     0.0894507  -0.0728474   0.00794912   0.152863   -0.13109     -0.188744      0.042873    -0.0351006   -0.275178   -0.058542    -0.128795     0.0196228  -0.0105909   -0.154839     0.049614    -0.144876
  0.107421    0.140448     0.118505   -0.220914     -0.0104719   -0.03664     -0.0604695   -0.00943503    0.000123723  -0.0655586    -0.161261   -0.0916429  -0.0145666   -0.0321788   0.11428      0.0611971     0.147677     0.0790635   -0.0838661  -0.0083415    0.0792597    0.119097   -0.0344807   -0.0490701   -0.0794355    0.0583583
 -0.0546208   0.0720977    0.0267687  -0.243939      0.122604    -0.118857     0.0566381   -0.0694027    -0.0518802     0.0584591    -0.0961119  -0.0443041  -0.00909805  -0.0851259  -0.0185373   -0.0320926    -0.0925171    0.121289    -0.185238    0.0195763    0.268826     0.0674403   0.0535485   -0.207218     0.0665393    0.0815834
  0.117853   -0.115098     0.0748244   0.0604948    -0.0912604   -0.00110759   0.0329876   -0.0297249    -0.124888     -0.0114664     0.210355   -0.140256   -0.168901     0.0108245   0.162039     0.106606     -0.0101586   -0.0467685   -0.176513   -0.00599011   0.0453148    0.0110198   0.00291943   0.143987    -0.048251    -0.0818835
  0.160066   -0.00544742   0.039288   -0.0585999    -0.0259494   -0.0121882    0.0746964    0.119181     -0.0994521     0.169833      0.122056    0.122912   -0.00627482   0.108566   -0.232672    -0.234477      0.150333    -0.101833    -0.124045    0.0076273    0.0239366   -0.0194759  -0.0386805   -0.102372    -0.00693771  -0.0206646
  0.128102    0.213731     0.0417492   0.0426156     0.0234795    0.16728      0.0108165   -0.0528781    -0.0173777     0.00400361    0.104556    0.145055    0.0782836    0.0269901   0.0924922    0.0787645    -0.0401337   -0.0768814   -0.125578    0.0672045    0.140016     0.0802672   0.0486212    0.089406    -0.121475     0.0183006kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4608793722971944
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.460970
[ Info: iteration 2, average log likelihood -1.460893
[ Info: iteration 3, average log likelihood -1.460313
[ Info: iteration 4, average log likelihood -1.452950
[ Info: iteration 5, average log likelihood -1.433454
[ Info: iteration 6, average log likelihood -1.425276
[ Info: iteration 7, average log likelihood -1.423319
[ Info: iteration 8, average log likelihood -1.421952
[ Info: iteration 9, average log likelihood -1.421078
[ Info: iteration 10, average log likelihood -1.420612
[ Info: iteration 11, average log likelihood -1.420374
[ Info: iteration 12, average log likelihood -1.420255
[ Info: iteration 13, average log likelihood -1.420194
[ Info: iteration 14, average log likelihood -1.420161
[ Info: iteration 15, average log likelihood -1.420143
[ Info: iteration 16, average log likelihood -1.420132
[ Info: iteration 17, average log likelihood -1.420126
[ Info: iteration 18, average log likelihood -1.420122
[ Info: iteration 19, average log likelihood -1.420119
[ Info: iteration 20, average log likelihood -1.420118
[ Info: iteration 21, average log likelihood -1.420116
[ Info: iteration 22, average log likelihood -1.420116
[ Info: iteration 23, average log likelihood -1.420115
[ Info: iteration 24, average log likelihood -1.420115
[ Info: iteration 25, average log likelihood -1.420115
[ Info: iteration 26, average log likelihood -1.420114
[ Info: iteration 27, average log likelihood -1.420114
[ Info: iteration 28, average log likelihood -1.420114
[ Info: iteration 29, average log likelihood -1.420114
[ Info: iteration 30, average log likelihood -1.420114
[ Info: iteration 31, average log likelihood -1.420114
[ Info: iteration 32, average log likelihood -1.420114
[ Info: iteration 33, average log likelihood -1.420114
[ Info: iteration 34, average log likelihood -1.420114
[ Info: iteration 35, average log likelihood -1.420114
[ Info: iteration 36, average log likelihood -1.420114
[ Info: iteration 37, average log likelihood -1.420114
[ Info: iteration 38, average log likelihood -1.420114
[ Info: iteration 39, average log likelihood -1.420114
[ Info: iteration 40, average log likelihood -1.420114
[ Info: iteration 41, average log likelihood -1.420114
[ Info: iteration 42, average log likelihood -1.420114
[ Info: iteration 43, average log likelihood -1.420114
[ Info: iteration 44, average log likelihood -1.420114
[ Info: iteration 45, average log likelihood -1.420114
[ Info: iteration 46, average log likelihood -1.420114
[ Info: iteration 47, average log likelihood -1.420114
[ Info: iteration 48, average log likelihood -1.420114
[ Info: iteration 49, average log likelihood -1.420114
[ Info: iteration 50, average log likelihood -1.420114
┌ Info: EM with 100000 data points 50 iterations avll -1.420114
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4609701838422104
│     -1.4608929046394525
│      ⋮
└     -1.4201137832246338
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420237
[ Info: iteration 2, average log likelihood -1.420128
[ Info: iteration 3, average log likelihood -1.419670
[ Info: iteration 4, average log likelihood -1.414974
[ Info: iteration 5, average log likelihood -1.401307
[ Info: iteration 6, average log likelihood -1.390238
[ Info: iteration 7, average log likelihood -1.385112
[ Info: iteration 8, average log likelihood -1.382214
[ Info: iteration 9, average log likelihood -1.380522
[ Info: iteration 10, average log likelihood -1.379477
[ Info: iteration 11, average log likelihood -1.378810
[ Info: iteration 12, average log likelihood -1.378389
[ Info: iteration 13, average log likelihood -1.378123
[ Info: iteration 14, average log likelihood -1.377945
[ Info: iteration 15, average log likelihood -1.377816
[ Info: iteration 16, average log likelihood -1.377714
[ Info: iteration 17, average log likelihood -1.377624
[ Info: iteration 18, average log likelihood -1.377537
[ Info: iteration 19, average log likelihood -1.377448
[ Info: iteration 20, average log likelihood -1.377351
[ Info: iteration 21, average log likelihood -1.377242
[ Info: iteration 22, average log likelihood -1.377119
[ Info: iteration 23, average log likelihood -1.376983
[ Info: iteration 24, average log likelihood -1.376843
[ Info: iteration 25, average log likelihood -1.376703
[ Info: iteration 26, average log likelihood -1.376567
[ Info: iteration 27, average log likelihood -1.376437
[ Info: iteration 28, average log likelihood -1.376314
[ Info: iteration 29, average log likelihood -1.376203
[ Info: iteration 30, average log likelihood -1.376104
[ Info: iteration 31, average log likelihood -1.376018
[ Info: iteration 32, average log likelihood -1.375945
[ Info: iteration 33, average log likelihood -1.375885
[ Info: iteration 34, average log likelihood -1.375837
[ Info: iteration 35, average log likelihood -1.375801
[ Info: iteration 36, average log likelihood -1.375775
[ Info: iteration 37, average log likelihood -1.375756
[ Info: iteration 38, average log likelihood -1.375743
[ Info: iteration 39, average log likelihood -1.375733
[ Info: iteration 40, average log likelihood -1.375726
[ Info: iteration 41, average log likelihood -1.375722
[ Info: iteration 42, average log likelihood -1.375718
[ Info: iteration 43, average log likelihood -1.375716
[ Info: iteration 44, average log likelihood -1.375714
[ Info: iteration 45, average log likelihood -1.375713
[ Info: iteration 46, average log likelihood -1.375712
[ Info: iteration 47, average log likelihood -1.375711
[ Info: iteration 48, average log likelihood -1.375710
[ Info: iteration 49, average log likelihood -1.375710
[ Info: iteration 50, average log likelihood -1.375710
┌ Info: EM with 100000 data points 50 iterations avll -1.375710
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.420237271079815
│     -1.4201276245374397
│      ⋮
└     -1.3757097140366232
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.375910
[ Info: iteration 2, average log likelihood -1.375733
[ Info: iteration 3, average log likelihood -1.375375
[ Info: iteration 4, average log likelihood -1.371413
[ Info: iteration 5, average log likelihood -1.354568
[ Info: iteration 6, average log likelihood -1.338980
[ Info: iteration 7, average log likelihood -1.330980
[ Info: iteration 8, average log likelihood -1.326158
[ Info: iteration 9, average log likelihood -1.323078
[ Info: iteration 10, average log likelihood -1.320703
[ Info: iteration 11, average log likelihood -1.318716
[ Info: iteration 12, average log likelihood -1.317384
[ Info: iteration 13, average log likelihood -1.316715
[ Info: iteration 14, average log likelihood -1.316409
[ Info: iteration 15, average log likelihood -1.316251
[ Info: iteration 16, average log likelihood -1.316144
[ Info: iteration 17, average log likelihood -1.316056
[ Info: iteration 18, average log likelihood -1.315977
[ Info: iteration 19, average log likelihood -1.315903
[ Info: iteration 20, average log likelihood -1.315834
[ Info: iteration 21, average log likelihood -1.315769
[ Info: iteration 22, average log likelihood -1.315710
[ Info: iteration 23, average log likelihood -1.315657
[ Info: iteration 24, average log likelihood -1.315612
[ Info: iteration 25, average log likelihood -1.315572
[ Info: iteration 26, average log likelihood -1.315537
[ Info: iteration 27, average log likelihood -1.315505
[ Info: iteration 28, average log likelihood -1.315476
[ Info: iteration 29, average log likelihood -1.315447
[ Info: iteration 30, average log likelihood -1.315417
[ Info: iteration 31, average log likelihood -1.315386
[ Info: iteration 32, average log likelihood -1.315353
[ Info: iteration 33, average log likelihood -1.315315
[ Info: iteration 34, average log likelihood -1.315273
[ Info: iteration 35, average log likelihood -1.315226
[ Info: iteration 36, average log likelihood -1.315177
[ Info: iteration 37, average log likelihood -1.315124
[ Info: iteration 38, average log likelihood -1.315069
[ Info: iteration 39, average log likelihood -1.315011
[ Info: iteration 40, average log likelihood -1.314952
[ Info: iteration 41, average log likelihood -1.314892
[ Info: iteration 42, average log likelihood -1.314832
[ Info: iteration 43, average log likelihood -1.314772
[ Info: iteration 44, average log likelihood -1.314715
[ Info: iteration 45, average log likelihood -1.314659
[ Info: iteration 46, average log likelihood -1.314607
[ Info: iteration 47, average log likelihood -1.314557
[ Info: iteration 48, average log likelihood -1.314510
[ Info: iteration 49, average log likelihood -1.314469
[ Info: iteration 50, average log likelihood -1.314433
┌ Info: EM with 100000 data points 50 iterations avll -1.314433
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.375909884412111
│     -1.3757328850149075
│      ⋮
└     -1.3144327549494943
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.314708
[ Info: iteration 2, average log likelihood -1.314375
[ Info: iteration 3, average log likelihood -1.313530
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.304316
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.278493
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.254234
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.241867
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.235443
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.230349
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.225863
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.238737
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.234758
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.231861
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.229428
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.226580
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.222678
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.234234
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.229583
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.226894
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.224576
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.222039
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.219140
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.232901
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.229248
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.226993
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.224856
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.222435
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.219644
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.232651
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.228990
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.226896
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.224904
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.222409
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.219462
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.231117
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.227253
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.225221
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.223474
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.221395
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.218951
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.230851
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.227116
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.225043
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.223229
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.221111
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.218628
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.230853
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.227113
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.225035
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.223217
┌ Info: EM with 100000 data points 50 iterations avll -1.223217
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3147084495950874
│     -1.3143745434059033
│      ⋮
└     -1.2232170542905907
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.221521
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.218617
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.220425
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.208427
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     17
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.166932
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     14
│     16
│     19
│     20
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.145415
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     17
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.148310
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.139186
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     16
│     17
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.126861
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.136824
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.134058
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     14
│     16
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.131336
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│     17
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.129228
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     23
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.134240
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     16
│     17
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.133248
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.139096
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     17
│     23
│     24
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.122187
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│      8
│     14
│     16
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.128534
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.138574
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.129910
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.125160
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│      8
│     14
│     16
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.118403
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     17
│     23
│     24
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.129504
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.135126
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.120839
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     14
│     16
│     19
│     20
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.130047
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.131796
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      8
│     14
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.124812
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     17
│     23
│     24
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.125957
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.132269
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      6
│     16
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.116391
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.136750
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.129254
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      8
│     14
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.124117
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     17
│     23
│     24
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.124089
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     14
│     16
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.130033
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.124671
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.133790
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.127980
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      8
│     14
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.122320
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     16
│     17
│     23
│     24
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.121469
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.137712
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.122150
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.133286
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.126137
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│      8
│     14
│     16
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.119938
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     17
│     23
│     24
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.129589
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.134743
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.121072
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     14
│     19
│     20
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.131533
┌ Info: EM with 100000 data points 50 iterations avll -1.131533
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2215214848692264
│     -1.2186168631601444
│      ⋮
└     -1.1315330604827674
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4608793722971944
│     -1.4609701838422104
│     -1.4608929046394525
│     -1.4603134320188835
│      ⋮
│     -1.1347427269992065
│     -1.121071586048413
└     -1.1315330604827674
32×26 Array{Float64,2}:
 -0.0502215    0.0379555     0.010125     0.0205359   -0.0381147   -0.0549474   0.0442631  -0.0402912    0.0229973    0.0138751    0.178603    -0.0167069  -0.00700473  -0.0206157    0.0153522   -0.00973106   0.0164671    0.0546785  -0.140161    -0.0769669    0.0954355    0.049095     -0.0590268   -0.105961     0.080296    -0.0303043
  0.00566244   0.0238527     0.071409    -0.0481383   -0.042758    -0.0345287  -0.037676   -0.0993677    0.0438464   -0.0618993   -0.00890971   0.134012    0.0565547    0.0016554    0.0872167   -0.0290885   -0.0044951   -0.012734    0.0490813   -0.165366     0.0753758    0.00988239    0.0496701    0.0924568   -0.126834     0.0307832
 -0.226494     0.000545236  -0.232886    -0.151946     0.192164     0.244924   -0.129282    0.0416437   -0.184415     0.0778625   -0.0162364    0.229358   -0.0465562    0.133524    -0.266608     0.024514    -0.0601322   -0.100381    0.0151682    0.0852789    0.208354    -0.0321414    -0.0508122   -0.114595    -0.113893     0.00521688
 -0.030622     0.0556041    -0.0615196   -0.00671849   0.100594     0.0454999   0.144594    0.00454251   0.197311    -0.184385    -0.0789814   -0.155442    0.0112663    0.149062    -0.219657     0.0755793   -0.0631679    0.204722    0.0894667    0.0385719    0.0290501   -0.0597729    -0.173725     0.0278194    0.0696357    0.0611936
  0.125936     0.0561469    -0.0265406    0.0576356   -0.0230906    0.0120866  -0.144415   -0.211462     0.229022     0.0448947    0.00923911   0.03738     0.0761146    0.0548709    0.0319183   -0.113537    -0.00623656   0.192495   -0.0445559    0.2112      -0.0884919    0.0621757    -0.0794033   -0.0231891    0.138388    -0.107548
 -0.0704065   -0.0216164     0.0698526   -0.140347    -0.0635297   -0.0462347  -0.123973   -0.0625997    0.0545107    0.086937    -0.0762812    0.0132283   0.0162111   -0.149988     0.0937058   -0.0653998   -0.0227027   -0.0778897  -0.0574279    0.0144403   -0.0600341    0.102178     -0.0451445    0.0845136    0.274132    -0.013552
  0.141413     0.17612       0.118721    -0.21995     -0.00690775  -0.034897   -0.0597965  -0.00179047  -0.0431157   -0.0637754   -0.1506      -0.0859886  -0.0240458   -0.0343646    0.118139     0.0672927    0.154344     0.0785207  -0.0877906   -0.0186335    0.0345755    0.0926827    -0.0151822   -0.0477724   -0.0354026    0.0577667
  0.0157042    0.0221695     0.0309658   -0.177815    -0.0649568   -0.0606072  -0.0144539   0.0304089   -0.0338135    0.0821133   -0.0943048    0.0375683   0.155496     0.148382    -0.0714432    0.0730168   -0.0757753    0.0885085  -0.0879158   -0.0383124    0.255338    -0.03843       0.0433153    0.138595    -0.211338    -0.055451
  0.0138813    0.0877212    -0.139853     0.0312855   -0.0223932   -0.12471     0.164628    0.0655414    0.0791967   -0.128622     0.104641    -0.13132     0.0297497   -0.196828     0.279969     0.0844332   -0.117667     0.195484   -0.137098    -0.14745      0.0285363   -0.158369     -0.0474438   -0.186214    -0.128739     0.146473
 -0.190251     0.0532956    -0.166024    -0.115471     0.108499    -0.115494    0.0329542   0.066924     0.0612122    0.211114     0.0027593    0.0593459   0.02939      0.0490839    0.317251    -0.00883829  -0.115778     0.25066     0.015271    -0.153885     0.0227471   -0.0329478    -0.0274428   -0.0921655   -0.134718     0.175729
  0.0371237   -0.171622     -0.0725417   -0.00894124  -0.00124057   0.0442689   0.0705108  -0.0251799   -0.164895     0.203675    -0.0070135   -0.0481244  -0.0746273   -0.0839565   -0.0380931    0.144669    -0.0650401   -0.0373415   0.113367    -0.0838052   -0.0795374   -0.586388     -0.0973326   -0.117596     0.131826    -0.00982611
  0.0301659   -0.297024     -0.00592825  -0.0251125   -0.00922483   0.269943    0.0280744  -0.021808    -0.139075     0.114574    -0.157373    -0.0717869  -0.0880135   -0.050954    -0.0470178    0.161936    -0.0960552    0.0940467   0.0544947   -0.0837384   -0.0571977    0.267042     -0.0413216   -0.182619     0.131256    -0.00714253
  0.153497     0.0151        0.0172469   -0.149034    -0.0261623   -0.0164078   0.0774014   0.133515    -0.128019     0.167152     0.121165     0.12211     0.0160801    0.0986437   -0.230804    -0.232133     0.150315    -0.099162   -0.102209     0.0161077    0.0226495   -0.0167573    -0.0421951   -0.11753     -0.00115529  -0.0188541
 -0.00875267  -0.0522133    -0.111005    -0.11821     -0.0399664    0.0976567   0.180932    0.0826815   -0.0869058    0.0386411    0.145099    -0.131439   -0.0580774    0.0504098   -0.0728935   -0.00181129   0.0132869    0.152088    0.190388     0.0253693    0.077226     0.192701     -0.0939307   -0.0890371   -0.208369    -0.0520633
  0.0694477   -0.125771      0.0136959    0.0815359   -0.0288212    0.0456064   0.0245441   0.0334182   -0.0247732    0.00427222  -0.0575962   -0.0197439  -3.6283e-5   -0.0454507    0.00977651  -0.0292067   -0.0462373    0.0552187  -0.00950743   0.018664     0.00129078   0.0652485    -0.0784745   -0.0435843   -0.00711597   0.0397833
  0.124864     0.208961      0.0418632    0.0488654    0.0279293    0.184253    0.0107719  -0.0263247   -0.0170179    0.00663339   0.107631     0.12971     0.0971971    0.0289242    0.0830246    0.0800745   -0.053489    -0.0832604  -0.112153     0.0754262    0.135976     0.103684      0.047413     0.0889172   -0.114592    -0.000531348
  0.108646    -0.111559      0.0728869    0.0521104   -0.0740103   -0.0250668   0.0566745  -0.0445189   -0.124556    -0.0117564    0.224036    -0.066751   -0.17284      0.0110494    0.152118     0.0986937   -0.00823368  -0.0185887  -0.176771    -0.0267977    0.0520788    0.0146132    -0.0333187    0.119449    -0.0478309   -0.0762434
 -0.0645124    0.0929512     0.0221852   -0.251358     0.134366    -0.13714     0.0332008  -0.0721354   -0.049497     0.0584129   -0.108481    -0.0275006  -0.00979994  -0.0797385   -0.0258167   -0.0402243   -0.0802285    0.134276   -0.187791     0.027452     0.256511     0.0523065     0.0863423   -0.197205     0.0758665    0.0902709
 -0.144245    -0.0589092    -0.112532     0.11172     -0.0916788   -0.0782121  -0.0879808   0.00428197   0.0976148   -0.0462216    0.195014     0.145243   -0.128344    -0.00522636   0.128412     0.0109854   -0.339365     0.243335   -0.0178144   -0.198134    -0.0276777   -0.0372344     0.03348      0.00654471  -0.268588     0.0267171
 -0.121973    -0.0085032     0.0669389    0.0865626   -0.087209    -0.161201   -0.0880478  -0.00206162   0.0696883   -0.044396    -0.248397     0.148581   -0.0867309   -0.0579816    0.21245      0.0900799    0.661053     0.238416   -0.0235161   -0.0264798   -0.029239    -0.0163273    -0.0470569    0.00640214   0.343943     0.0298165
 -0.126944     0.0187574     0.05882     -0.049462    -0.0271857   -0.0677398   0.0440742  -0.107947    -0.106315    -0.0231404    0.0332236   -0.105849    0.0244885    0.10471      0.00518229  -0.131927     0.0385545   -0.0789932  -0.258073    -0.0604853   -0.0928542    0.0147059    -0.0499728   -0.080274     0.0529436   -0.090265
 -0.13148      0.0627523    -0.150638     0.167889     0.262991    -0.121713    0.0756545  -0.0569862   -0.00521716   0.0140236   -0.0898221    0.0950922  -0.171906    -0.140985    -0.044208     0.0907306    0.0103253    0.0479625  -0.104832     0.101464     0.0489876    0.0415823    -0.0775946   -0.152698     0.00568508   0.0807893
 -0.0880318    0.0276235     0.192038    -0.0167158   -0.0171221   -0.0156485   0.102003   -0.214153     0.0454995    0.0309536    0.0417887    0.0630705   0.0486064   -0.116016     0.101652    -0.069077    -0.032599     0.0528293   0.122172    -0.00161681  -0.109988    -0.0677617     0.0194506   -0.0898949    0.108905     0.0893432
  0.0950017    0.0430339     0.0348418    0.043868     0.0576269   -0.05441    -0.100703   -0.0362598    0.0177361   -0.13086      0.0228621   -0.0433669  -0.0806216    0.0519853   -0.136622     0.0662199   -0.162495    -0.0636586  -0.0791832   -0.0529472    0.0951548   -0.011982     -0.00250087  -0.0471844    0.0438105   -0.0208122
  0.0766159   -0.0183634     0.186805     0.00563286  -0.0172257   -0.062735   -0.196182   -0.127108     0.0294981    0.0833178    0.0177692   -0.101957   -0.239927     0.0544771   -0.191048     0.0952234    0.00744577  -0.0239829   0.0478485   -0.103364     0.0210084    0.149964      0.0368191   -0.167915     0.0260932    0.0512628
  0.103138    -0.0437147    -0.133749     0.0558932    0.0626379    0.0419107   0.15693     0.0350705   -0.150914    -0.0872324    0.0615241    0.192824   -0.02709      0.038248    -0.00994421   0.0728869   -0.129072     0.0430555  -0.0286864   -0.0575228   -0.0164558    0.0420314    -0.142436    -0.130237     0.0451286   -0.14706
 -0.162078    -0.00488352    0.0563958    0.0425531    0.0463068    0.0590518   0.0283822   0.0954003    0.025718     0.20323     -0.342402     0.0178174   0.0281155   -0.115761     0.252867    -0.0190059   -0.148004    -0.0416712  -0.0980936   -0.0449379   -0.183802     0.0922496    -0.148668     0.0669551    0.00116259  -0.0867505
  0.149663    -0.00573502    0.0966161    0.0444784    0.0269829   -0.0252223  -0.06805     0.108906    -0.0130305    0.0171027   -0.190618     0.0660496   0.107135     0.0440039    0.159394     0.0401265   -0.153401    -0.0181976  -0.0935622   -0.0569951    0.554899     0.0405077    -0.159246     0.00404373   0.165828    -0.079688
 -0.474072    -0.00750846   -0.1316      -0.116283    -0.0498773    0.0546102  -0.467868   -0.0245554    0.080755     0.079181     0.419893    -0.193076    0.125686    -0.0545161    0.03652      0.17817      0.163593     0.030638    0.0706755   -0.0329742    0.234759    -0.0113274     0.138432    -0.0374144    0.106831    -0.0243014
  0.447823    -0.00741396   -0.0175965   -0.116039    -0.113301     0.0541975   0.558436   -0.0263328    0.0844988   -0.183789    -0.156724    -0.184385    0.117018    -0.0684453   -0.0180921    0.133134     0.173841     0.0839766   0.0725162    0.174814     0.0564428   -0.000460721   0.329811    -0.0356406    0.105936    -0.00507471
  0.0478586   -0.0722564    -0.0370127    0.20608      0.0419563    0.0482921   0.0509935  -0.0151106    0.0887007   -0.0478452    0.14128      0.0836738  -0.0364533   -0.0865317    0.0550016   -0.0152524   -0.0520507   -1.11771    -0.131294     0.0527697   -0.045799    -0.0462986     0.0263524   -0.0427798   -0.0419735   -0.00407101
  0.0413429   -0.00623316   -0.0579385    0.206735    -0.0465885    0.0526295   0.0800927  -0.0446658    0.259386    -0.0572882    0.146714     0.126751   -0.0229737   -0.150365    -0.0571689   -0.0370273   -0.0358143    1.1789      0.0330363    0.123042    -0.0433791   -0.049018      0.046859    -0.0868367   -0.108515    -0.0694524[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     16
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.123597
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      6
│      8
│     14
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.096485
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     16
│     17
│     23
│     24
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.114931
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      6
│      8
│     14
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.101441
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     16
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.117791
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      6
│      8
│     14
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.092851
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     16
│     17
│     23
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.123392
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      6
│      8
│     14
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.095756
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     16
│     17
│     23
│     24
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.114207
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      6
│      8
│     14
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.096604
┌ Info: EM with 100000 data points 10 iterations avll -1.096604
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.931733e+05
      1       7.554640e+05      -2.377093e+05 |       32
      2       7.285636e+05      -2.690038e+04 |       32
      3       7.122612e+05      -1.630240e+04 |       32
      4       7.004874e+05      -1.177378e+04 |       32
      5       6.909773e+05      -9.510144e+03 |       32
      6       6.845995e+05      -6.377804e+03 |       32
      7       6.813919e+05      -3.207563e+03 |       32
      8       6.795089e+05      -1.882987e+03 |       32
      9       6.774749e+05      -2.033996e+03 |       32
     10       6.751986e+05      -2.276337e+03 |       32
     11       6.740012e+05      -1.197348e+03 |       32
     12       6.736232e+05      -3.780473e+02 |       32
     13       6.733728e+05      -2.503649e+02 |       32
     14       6.730935e+05      -2.792966e+02 |       32
     15       6.727877e+05      -3.058733e+02 |       32
     16       6.725831e+05      -2.045216e+02 |       32
     17       6.724347e+05      -1.484762e+02 |       32
     18       6.722739e+05      -1.607968e+02 |       32
     19       6.720830e+05      -1.908868e+02 |       32
     20       6.718058e+05      -2.771343e+02 |       32
     21       6.714038e+05      -4.020631e+02 |       32
     22       6.708835e+05      -5.203195e+02 |       32
     23       6.702321e+05      -6.514063e+02 |       32
     24       6.696396e+05      -5.924258e+02 |       32
     25       6.691339e+05      -5.057796e+02 |       32
     26       6.687352e+05      -3.986462e+02 |       32
     27       6.683992e+05      -3.359850e+02 |       32
     28       6.681732e+05      -2.259998e+02 |       32
     29       6.680181e+05      -1.551602e+02 |       32
     30       6.679251e+05      -9.297082e+01 |       32
     31       6.678660e+05      -5.904194e+01 |       32
     32       6.678162e+05      -4.985973e+01 |       31
     33       6.677585e+05      -5.773716e+01 |       30
     34       6.676970e+05      -6.143845e+01 |       29
     35       6.676205e+05      -7.655965e+01 |       32
     36       6.675483e+05      -7.218438e+01 |       30
     37       6.674861e+05      -6.214399e+01 |       31
     38       6.674512e+05      -3.491385e+01 |       31
     39       6.674404e+05      -1.080987e+01 |       22
     40       6.674363e+05      -4.084175e+00 |       26
     41       6.674339e+05      -2.414057e+00 |       25
     42       6.674326e+05      -1.338649e+00 |       20
     43       6.674318e+05      -7.748936e-01 |       14
     44       6.674311e+05      -6.866714e-01 |        8
     45       6.674307e+05      -3.673751e-01 |        6
     46       6.674304e+05      -3.527348e-01 |        4
     47       6.674302e+05      -1.841155e-01 |        6
     48       6.674297e+05      -4.483889e-01 |       13
     49       6.674287e+05      -1.049715e+00 |        9
     50       6.674282e+05      -4.712294e-01 |        8
K-means terminated without convergence after 50 iterations (objv = 667428.2278860055)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.373897
[ Info: iteration 2, average log likelihood -1.345044
[ Info: iteration 3, average log likelihood -1.312855
[ Info: iteration 4, average log likelihood -1.274712
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.229899
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.203389
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.167487
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.149137
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      7
│     10
│     16
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.131925
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.180421
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.141702
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      7
│      8
│     16
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.102529
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.153662
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.142986
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     10
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.115284
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.126489
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│     18
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.129971
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.148080
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.136053
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.114961
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│     16
│     18
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.104617
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.149796
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.140722
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     16
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.100569
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     18
│     20
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.139005
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.149438
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.108753
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      8
│     10
│     18
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.117154
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.157741
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.136671
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.120941
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     18
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.117293
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.142253
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.145795
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.110071
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      8
│     16
│     18
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.117268
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.161084
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.143975
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.104938
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     18
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.119967
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.146795
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.143138
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.123244
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     18
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.114347
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     20
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.143234
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.146035
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.110232
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      8
│     16
│     18
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.117161
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.161184
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.144148
┌ Info: EM with 100000 data points 50 iterations avll -1.144148
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.106883    -0.00758312  -0.077711    0.00471977    0.0776044   -0.00155315   0.0806944   -0.0206761    -0.147213     0.0618369   -0.0476949   -0.160339    -0.0957222  -0.1104      -0.0213658    0.0378713    0.00537635   0.131936    -0.0799529     0.0752474   -0.0411348     0.0410335   -0.0981821   -0.0338975     0.0613386    0.0220503
  0.151128    -0.00589287   0.0840071   0.0382169     0.0243911   -0.0183628   -0.0636584    0.0890322     0.0116506    0.00383281  -0.196612     0.0611841    0.102703   -0.00265349   0.194212     0.0380299   -0.135923    -0.020352    -0.138558     -0.0223263    0.726247      0.0292233   -0.16558      0.0300045     0.164288    -0.0810231
 -0.152107    -0.00230647   0.0700542   0.0475862     0.0474513    0.0501061    0.0243243    0.106052      0.00266637   0.201119    -0.327887     0.0222927    0.031938   -0.0657191    0.212499    -0.0163251   -0.178615    -0.0375429   -0.0561265    -0.0789332   -0.343739      0.0993308   -0.142367     0.0382525     0.0152973   -0.0837538
 -0.0287031    0.057457    -0.0632547  -0.000693843   0.0932081    0.0190762    0.156909     0.00276759    0.208716    -0.185734    -0.0802206   -0.157539     0.0107183   0.148143    -0.216816     0.0721072   -0.0562048    0.213384     0.0952259     0.036427     0.0208793    -0.0597656   -0.166226     0.0402278     0.067717     0.0697077
  0.0150243   -0.0050136   -0.122491   -0.102982     -0.107062     0.0488771    0.0709868   -0.0419962     0.0945648   -0.0712535    0.132178    -0.16141      0.117419   -0.0701392    0.00466557   0.140741     0.154749     0.06027      0.0781477     0.0853921    0.139368     -0.00901534   0.296679    -0.039487      0.108021    -0.0266069
 -0.0160719    0.0244611    0.0768886   0.0345433    -0.0794484   -0.0430118   -0.0247478   -0.126698     -0.0197656   -0.0515508    0.154779     0.164886     0.0922094   0.0693169   -0.0280585    0.00574235  -0.0316969   -0.0488854   -0.0770752    -0.0875246    0.0399965    -0.0530221    0.11359      0.000525206  -0.0617302    0.0199915
 -0.0922117    0.00566284   0.0578722  -0.156096     -0.0568297   -0.0607398   -0.116375    -0.0782678     0.0534596    0.0881875   -0.0825607    0.0103319    0.0139078  -0.166041     0.0807761   -0.0504414   -0.0266157   -0.081027    -0.0782414     0.00976593  -0.0680216     0.0967534   -0.0445235    0.0928545     0.311659    -0.0192391
 -0.0842476    0.0289351    0.297836    0.00607573   -0.0120544    0.0072295    0.178093    -0.196573      0.0999827    0.0251945    0.0123447    0.0622784    0.117416   -0.127119     0.105905    -0.102639    -0.0283993    0.0129574    0.20957      -0.0302368   -0.123599     -0.0731654   -0.0586023   -0.0903977     0.126288     0.189875
 -0.129828     0.0640813   -0.0238636   0.00907897    0.129441    -0.134503     0.0329536   -0.158949     -0.0400313   -0.038007    -0.0505206   -0.0138724   -0.0702551  -0.0382489    0.0476348    0.0144241    0.00480039  -0.0420355   -0.18665       0.00581373  -0.00459851    0.0208125   -0.0762373   -0.0912442     0.0441116   -0.014729
  0.0267558    0.171031    -0.0391298  -0.0376267     0.113534    -0.119208     0.0728288   -0.0405669    -0.0224416   -0.0353189    0.149232     0.00974869   0.0489759   0.0666747    0.0458046    0.154626     0.0431209    0.252151    -0.102542     -0.099956    -0.0068375     0.0364134    0.0201086   -0.025527      0.0231699   -0.042508
  0.0777886    0.0065005   -0.0379889   0.129953     -0.0089478    0.0327224   -0.0322665   -0.114049      0.198279    -0.00644913   0.0782777    0.0622402    0.0170323  -0.0389952    0.0166079   -0.0661784   -0.0234863    0.135873    -0.0378767     0.14556     -0.0658137     0.00726564  -0.0194192   -0.050953      0.0371356   -0.0694169
  0.140712     0.178607     0.118732   -0.215506     -0.00683522  -0.0367823   -0.0608452   -0.00371279   -0.0370438   -0.063726    -0.152916    -0.0852978   -0.0250269  -0.0359908    0.121381     0.069287     0.155736     0.0815701   -0.0863033    -0.0178398    0.0323889     0.0929691   -0.00906761  -0.0481061    -0.0331146    0.0579002
  0.110474    -0.212318     0.0608777   0.12439      -0.0165376   -0.0290285    0.216084    -0.100494      0.00449938  -0.0834256   -0.0630853    0.157979     0.156146   -0.0341726   -0.0538512   -0.109644    -0.201966    -0.0654562   -0.0254215    -0.0848701   -0.0240252     0.0557939   -0.0405448    0.108378     -0.0383742    0.0290425
 -0.0878646    0.071229    -0.151913   -0.0437601     0.0431117   -0.118424     0.0983987    0.0692881     0.0697086    0.0430233    0.0520749   -0.0358344    0.0294302  -0.0774926    0.300143     0.0416805   -0.11833      0.221351    -0.0593813    -0.150699     0.0257152    -0.0963407   -0.0408356   -0.142408     -0.134032     0.160005
 -0.113515    -0.0187497    0.0380539   0.0490211    -0.0644607    0.0192709    0.0858622    0.0396254    -0.141607     0.0305522    0.091543    -0.0952394    0.0151672   0.152936    -0.146943    -0.199232     0.0411926   -0.035859    -0.26703      -0.0463757   -0.127264      0.0127437   -0.0100589   -0.152764      0.0225653   -0.0820405
  0.118776     0.211419     0.0370848   0.0307588     0.0237207    0.16687      0.00216298  -0.0205032    -0.0190326    0.0231933    0.0912994    0.122701     0.106085    0.0352948    0.0803449    0.0785863   -0.0497548   -0.0710684   -0.102688      0.0814805    0.14079       0.121855     0.0476399    0.0862062    -0.119872    -0.000558998
 -0.208837     0.00149305  -0.21041    -0.138644      0.18429      0.237624    -0.118232     0.0377507    -0.159507     0.0586307   -0.0186824    0.20169     -0.044848    0.129584    -0.257176     0.0308946   -0.0557471   -0.0784594    0.0174747     0.0818377    0.198098     -0.0333243   -0.0563722   -0.10636      -0.0942491    0.00862968
  0.0592543   -0.00345063   0.233807    0.0204989    -0.0208594   -0.0666311   -0.261155    -0.126964      0.0413846    0.0727588    0.0233494   -0.0794114   -0.26105     0.0561405   -0.178089     0.0927847    0.0246907   -0.0276914    0.0608474    -0.109784    -0.0325039     0.122457     0.0496522   -0.181611      0.0265656    0.0517364
  0.172918    -0.15161      0.108049    0.1029       -0.130704     0.159561    -0.205861     0.172438      0.0717568    0.0322236   -0.0753079   -0.0703442   -0.0426314  -0.0197851    0.116398    -0.0336236    0.0436024    0.0512048    0.0728995     0.0909156    0.0630202     0.0875269   -0.0941951   -0.165993     -0.0298778    0.0620162
 -0.141608    -0.0746115   -0.0700694   0.107526     -0.0847464   -0.131985    -0.080501    -0.000595876   0.0967773   -0.035902     0.0148463    0.155927    -0.128396   -0.0276765    0.265562     0.0206624   -0.042387     0.217728    -0.000655152  -0.166039    -0.0167418    -0.0299238   -0.0174196    0.00417193   -0.0948491    0.0420843
  0.0322115   -0.00746868   0.341896   -0.0898629    -0.208351     0.0685772    0.016422    -0.0344807     0.0566835    0.124584     0.219371    -0.0143115   -0.0839927   0.0855723   -0.181436    -0.127708     0.00574662  -0.866352    -0.154306     -0.145219     0.000771163   0.112094     0.0710077    0.104192      0.0812885    0.0694453
  0.0378655   -0.258269    -0.0275642  -0.0131134    -0.00552573   0.191379     0.0353924   -0.0227148    -0.150317     0.143077    -0.107078    -0.0674099   -0.0834991  -0.0593157   -0.0381687    0.154806    -0.0812148    0.0499471    0.0789169    -0.083503    -0.0641303    -0.0577996   -0.0627326   -0.160588      0.132551    -0.00826772
  0.0795051    0.0371069    0.0346735   0.0514993     0.0558487   -0.0837362   -0.119359    -0.0408258     0.0425766   -0.109325     0.00541015   0.00431788  -0.122649    0.0532918   -0.107789     0.051451    -0.18275     -0.0245137   -0.0544926    -0.0558254    0.104546     -0.0134853   -0.0237349   -0.0963797     0.0444095   -0.0344623
  0.059323    -0.0691925    0.0713837  -0.0110844    -0.0441563   -0.0251307   -0.00714021  -0.0489093    -0.00662049  -0.040312     0.0426069    0.0165499   -0.0922261  -0.0176377    0.179196     0.0259905    0.0120183    0.0131186   -0.00796009   -0.124577     0.0690719     0.0359402   -0.0245916    0.160701     -0.129967    -0.020565
 -0.0547492    0.0763298    0.024491   -0.239472      0.124754    -0.131665     0.0352047   -0.0742259    -0.0513045    0.0541922   -0.0914933   -0.029594    -0.012439   -0.0784427   -0.016483    -0.0334477   -0.0783389    0.127301    -0.18613       0.0185573    0.25017       0.0483952    0.0853344   -0.187369      0.0716674    0.0830833
 -0.0928527    0.180391    -0.16204     0.0273345    -0.0668786    0.013277    -0.0921637   -0.0216176     0.06936     -0.0505791    0.272897     0.0681766   -0.0928332   0.0303542   -0.183162     0.0867951   -0.134695     0.220557    -0.0597071    -0.116279    -0.0275784    -0.0256162    0.0326518    0.00329242   -0.0821932    0.0110996
  0.00117355  -0.0436296   -0.106555   -0.112042     -0.164576     0.0759388    0.0369675   -0.0804347     0.108098     0.128516     0.117094    -0.0220251   -0.082243   -0.156701    -0.0462791    0.00656181   0.0316317   -0.0231575   -0.107329     -0.0767703    0.159957      0.0598078   -0.0647866   -0.206223      0.126264     0.018204
 -0.00747896  -0.0727872   -0.10773    -0.136426     -0.0406916    0.0830211    0.174755     0.0800156    -0.0740195    0.0356321    0.136517    -0.116275    -0.0741392   0.0622337   -0.0760042    0.00367237   0.0103836    0.159197     0.178239      0.0201297    0.0748956     0.19971     -0.0928296   -0.097732     -0.193998    -0.0580151
  0.0213684    0.0121597    0.0322209  -0.162898     -0.0667777   -0.0605304   -0.032301     0.0200146    -0.07234      0.0791684   -0.0949208    0.0272311    0.120981    0.145527    -0.0831549    0.075985    -0.0835252    0.0854649   -0.0876235    -0.0496568    0.279131     -0.0516389    0.0431986    0.153264     -0.244573    -0.0537082
  0.150935     0.0204571    0.0170841  -0.14936      -0.0265116   -0.0167741    0.0761703    0.128913     -0.128062     0.16658      0.117926     0.121106     0.0150261   0.0954281   -0.2327      -0.230555     0.150187    -0.0976259   -0.103051      0.0134253    0.0236424    -0.0198192   -0.0429145   -0.11644      -0.00474496  -0.0192872
 -0.154711    -0.00415897   0.141965    0.171901     -0.0658502   -0.103167    -0.0286929   -0.011023     -0.0257701   -0.0591653    0.236688    -0.029815    -0.0144922   0.0158635    0.0544382   -0.173237    -0.0256712    0.00608333  -0.163398     -0.0432416    0.129053      0.0430504   -0.117952    -0.0767927     0.0969461   -0.0686381
  0.102383    -0.0439482   -0.13388     0.0562607     0.0648545    0.0412018    0.157058     0.0346941    -0.151679    -0.0865582    0.0593255    0.192753    -0.0245241   0.036409    -0.0130357    0.0703613   -0.129074     0.0432661   -0.0278781    -0.057359    -0.0144578     0.0411931   -0.141505    -0.134416      0.0457633   -0.146488[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.101696
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.069363
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      7
│     10
│     16
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.077486
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      5
│      6
│      7
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.065376
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│     10
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.091012
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.065893
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│      7
│     10
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.085739
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.070682
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      7
│     10
│     16
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.085838
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.072583
┌ Info: EM with 100000 data points 10 iterations avll -1.072583
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0382278   -0.0141586   -0.0167165    -0.0245201     0.0131201   -0.0658581    0.126282     0.156631    0.229243    -0.0159483    -0.0804785    0.00160314   0.0527034   -0.0637746     0.135424    -0.197957     0.00451861  -0.0136715    0.0277636    0.040457     0.112857     0.0329928     0.0169184    0.0212962    0.00463659   0.17902
  0.120941    -0.190103    -0.149252     -0.157685     -0.0441103    0.0573637   -0.0140329    0.0664953   0.287165     0.20541      -0.148902    -0.197602     0.0315737    0.0588012    -0.0492227    0.0439832   -0.0442692   -0.0931568   -0.0265047    0.139713    -0.110944    -0.0124994    -0.0897943   -0.0230825    0.0747305   -0.206838
 -0.029127    -0.161408     0.0323626     0.0370384     0.0998949    0.0525448   -0.14339     -0.0378165  -0.0482136   -0.233074      0.15819      0.00910615  -0.0633581   -0.062127      0.19696     -0.0742568    0.0656145    0.137914     0.0559399   -0.00938349  -0.0212195   -0.0612474     0.0503326    0.161674    -0.193808    -0.0763894
 -0.0306531    0.197497     0.0453894     0.0812224     0.0802555   -0.0640793    0.0138104    0.0584345  -0.0529706   -0.00342386   -0.073712    -0.0287393    0.157841    -0.0605964     0.00938384   0.10505      0.0499866   -0.0608582   -0.168515     0.0398264    0.0817413    0.162228      0.0726354    0.105795    -0.0410407    0.11497
 -0.112501     0.0741939    0.0633594    -0.0412717    -0.00257763   0.0475422   -0.0298689   -0.130642   -0.141611    -0.0360962     0.0582312    0.174811    -0.075834    -0.0302387    -0.135643    -0.0359703    0.0138893   -0.0396138    0.0150813   -0.0832519   -0.0489444    0.0242321     0.0304315    0.0916515   -0.0705368    0.245221
  0.127981     0.115618    -0.0252227    -0.0176803     0.0320944    0.0916367   -0.094634     0.162278    0.163016     0.174736      0.0123942    0.0950201   -0.0807805    0.00208789   -0.0723696   -0.0225684    0.0407012   -0.0732436   -0.109991     0.0151888   -0.166086     0.000192893  -0.214657     0.11564     -0.0836897   -0.021439
  0.0579141    0.0164715   -0.0415539     0.0351132    -0.122483    -0.120046     0.0602482   -0.204004    0.0159866    0.0718964    -0.155362    -0.0676858    0.197859     0.0541131    -0.0131402   -0.154392     0.275571     0.225403     0.00302573   0.0493106    0.0161679   -0.0136817     0.0687367    0.0491439   -0.101593     0.116097
  0.0811391    0.038199     0.0786367     0.00229892    0.100489    -0.0510774   -0.0149513   -0.177933    7.80511e-5  -0.0917005    -0.147211     0.0200807   -0.13338      0.0142773     0.00367801  -0.0395197    0.030836    -0.0583209   -0.165204    -0.113813     0.0668829    0.0578595     0.0579145   -0.113545     0.0224357   -0.0812194
 -0.086902     0.0846995    0.180391      0.0515618     0.0671099   -0.00963362   0.0125715   -0.262056    0.22551      0.0585944    -0.0802568    0.0387384    0.0471494   -0.0960761    -0.0695148   -0.184495     0.0817635   -0.0699096    0.0292445    0.198581     0.0802883   -0.137926     -0.00803714  -0.173671     0.159598     0.00615
  0.0185347   -0.0694034    0.160248     -0.0942453     0.133616    -0.0687832   -0.00614858   0.0367843  -0.0250771   -0.00441714   -0.0769109    0.0393723    0.0481776    0.133117      0.323327    -0.0585809    0.138677    -0.0902879    0.0406393    0.0848989   -0.0409039    0.0883998    -0.109171     0.13318     -0.183234     0.143103
  0.00435729   0.0821169    0.13517      -0.156604      0.0324068    0.298796    -0.0574704    0.13311     0.0436076    0.1035       -0.0917481   -0.142505     0.0224935   -0.190448      0.030398     0.0268917    0.0895226   -0.033379     0.039815    -0.1868      -0.0391253   -0.0157616     0.116963     0.115282     0.0210017   -0.0109068
 -0.156822    -0.123216    -0.121303      0.0595145    -0.106739    -0.104034     0.0826922    0.0459697  -0.00358059   0.0517469    -0.034454     0.00682412  -0.00986264  -0.0543601    -0.191817    -0.0908235   -0.0579399   -0.0152838    0.0263907    0.0702946   -0.0222717   -0.0546709     0.109374     0.0926873    0.0174784    0.00584
 -0.185606     0.0383264   -0.0820212     0.093701      0.108217    -0.0495799   -0.150771    -0.079353   -0.00819534   0.0291556    -0.029816    -0.0213214   -0.0215367   -0.126126     -0.122405    -0.029419    -0.131289     0.001066     0.210857     0.119799    -0.148598     0.211794     -0.0459213    0.18904      0.111522     0.137216
 -0.122505     0.101943    -0.105875      0.152044      0.0144976    0.0399216    0.165656    -0.0465721   0.0404558    0.0533525     0.235822     0.049658     0.118672     0.0728509    -0.0962458    0.0293312    0.105655     0.0450457   -0.0841091   -0.0653777   -0.13992      0.164535     -0.083623    -0.181153     0.0115891   -0.227393
  0.0190277   -0.0819071    0.0530662    -0.0262885    -0.149708    -0.069484    -0.0730001    0.0188411   0.0947437    0.172999      0.0329182    0.114699    -0.0824908   -0.0779255     0.0598441    0.0723253    0.038139    -0.190017     0.229061    -0.0166835   -0.00412549   0.00534433    0.0897536    0.046065     0.146749    -0.0333296
  0.0396469   -0.0259968   -0.204924      0.00177937    0.0769884    0.0550169   -0.160064     0.0943877  -0.00246375   0.0647859    -0.00252918   0.00785772  -0.00553235  -0.257726      0.0889263   -0.0748975    0.0697854   -0.0124992   -0.0442719    0.19921      0.0779379    0.0117387     0.0350935   -0.0646312    0.0336767   -0.0936269
 -0.0737215    0.100713    -0.130891      0.0715466    -0.111538    -0.0469402   -0.00709285   0.0223282  -0.0440089   -0.0611935     0.0260863   -0.00502203   0.084188    -0.000183015  -0.126982     0.07505      0.0241412    0.0337195    0.00707245  -0.00469664  -0.194874    -0.0983462    -0.00746906  -0.0638193   -0.131073    -0.0157612
  0.0632372   -0.00128873   0.154313      0.0686982    -0.0425858    0.0818021   -0.02612     -0.0149816   0.0352391    0.037013      0.0303622    0.0614358   -0.134179    -0.0105179     0.209278    -0.107339     0.0102487   -0.155887     0.178727     0.0661247   -0.141703    -0.0162117    -0.108995    -0.068278     0.165867     0.0591513
  0.0955971    0.0915403   -0.0157345    -0.000625817  -0.0502346   -0.0895367   -0.055522    -0.0869167   0.00782543   0.0635944     0.13212      0.0909921   -0.0309671   -0.0230997    -0.0681646    0.00769922   0.085334     0.106171    -0.078468     0.0468073   -0.102419    -0.0474058    -0.00268156   0.0558732    0.0462052   -0.252206
 -0.0588581   -0.0438934   -0.0907669     0.232982     -0.00903141   0.0783564    0.085016     0.129204   -0.101309    -0.133223     -0.0958084    0.0426809    0.137322     0.0751034    -0.0527082    0.021085    -0.0147126    0.114525     0.115562    -0.0492509   -0.186955     0.0239614     0.209026     0.0536225    0.0398803    0.0456978
  0.0172035    0.0519556   -0.0356332     0.0826778    -0.152924    -0.140335     0.0674888    0.0517204  -0.0607469   -0.0730816    -0.112606     0.0847988    0.0228075   -0.0187117    -0.0744102    0.178451    -0.053444    -0.0868477   -0.0329713   -0.010659    -0.00835074   0.0824234     0.0745789    0.110714     0.103896     0.126474
 -0.19062      0.1047      -0.0918989    -0.0635708     0.0758721   -0.0230385   -0.0189058    0.242167   -0.100085     0.0884574     0.0215438   -0.0617314   -0.09486     -0.00386368   -0.0524076   -0.0282193    0.0950601   -0.00709926  -0.119244     0.00971349  -0.0193245   -0.0815603     0.0239384    0.150031     0.0645106   -0.0992098
  0.0173022   -0.115288     0.0563171     0.0941126     0.125291     0.078744     0.0244596   -0.206618   -0.0267367    0.0660133    -0.0310506   -0.117935    -0.12319     -0.10969      -0.103539    -0.0156345    0.0173313   -0.049649     0.0274189   -0.233354     0.123717    -0.149271     -0.102983     0.0639596    0.0897577    0.0976528
 -0.0530446   -0.00703449  -0.000338021  -0.0153783     0.0997265   -0.0197847    0.0281152    0.199067   -0.0899447   -0.00315209   -0.0378185    0.0559999    0.115296    -0.0783403     0.118075    -0.106292    -0.0115243    0.0741061   -0.107537    -0.129849     0.218495     0.0399266    -0.141289    -0.0527917   -0.0379296    0.113345
  0.0746784    0.0468025   -0.0701496     0.136761     -0.05329      0.126216    -0.0430253    0.0831746   0.162043    -0.000568872  -0.0532765    0.102765    -0.123617     0.0103391    -0.16396      0.175806     0.0704805    0.137781     0.225086    -0.0506992   -0.152443    -0.283083     -0.121929     0.0582532    0.0640858    0.0897399
  0.00232917   0.115639     0.0584728     0.115417      0.0541871   -0.102028     0.0541299    0.110953   -0.0819477    0.024276     -0.0259011   -0.0434375    0.0670612   -0.100571      0.00410336   0.115088    -0.0730283   -0.0470525    0.0519431   -0.0826091   -0.286552    -0.125149     -0.056444    -0.0956732    0.0381736   -0.00876709
 -0.106778     0.0847611   -0.178277     -0.0840608     0.189065    -0.0437955   -0.0354472   -0.101737   -0.204888     0.0891654    -0.0901759    0.115393    -0.17424     -0.0100078    -0.145113    -0.0101009    0.113128     0.0270587    0.0386765    0.0963526    0.229481    -0.114251      0.00908085   0.175451     0.101167     0.089464
 -0.0659022    0.00147997  -0.0130291    -0.0550004     0.00688669  -0.0349864    0.105953     0.0736335  -0.0144797    0.029704     -0.0554278   -0.0618579    0.0389964    0.034167      0.0613657   -0.329282     0.0135457    0.0150696    0.00189593  -0.0102655    0.0270506   -0.138683      0.00991064   0.0973325    0.0564378    0.0234931
  0.13346      0.0529997   -0.0113313     0.106045     -0.110248     0.0172055    0.0137709    0.101136   -0.0181067    0.0721532     0.0552028    0.0828906    0.128787     0.00994539    0.0995525   -0.101549    -0.0499986   -0.171561     0.111698     0.0278479   -0.00754761   0.243005      0.140698     0.00208274   0.066989    -0.0408638
 -0.176138    -0.0256924   -0.180809      0.0791408     0.0186177   -0.150737    -0.153514    -0.125971   -0.0461425   -0.196714      0.134013    -0.0235204    0.207844     0.0328761     0.0540209   -0.0683286    0.0942743   -0.164166    -0.0198704    0.226108    -0.135646     0.0316868    -0.0780279    0.207788     0.0244595    0.107516
  0.298058     0.0421013   -0.0918119     0.0225401     0.0469498   -0.0400244    0.0928057    0.103159   -0.171248    -0.0272123     0.0476386    0.0268862    0.00962421   0.0940551     0.0898523   -0.0967324    0.057469     0.0840827    0.147704    -0.0760825   -0.167475    -0.0826926    -0.0345358   -0.118065     0.0314468    0.00456363
  0.11546      0.0919588   -0.0539578     0.0119115     0.183835     0.0247043   -0.00461054  -0.177855    0.128234    -0.0833765    -0.0900268   -0.108456     0.0139922   -0.0967139    -0.180015    -0.0697376   -0.166116     0.0225533   -0.17961      0.0238641   -0.0165675    0.0146414     0.0750651    0.110752     0.10275      0.00973937kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.409588791785883
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409606
[ Info: iteration 2, average log likelihood -1.409540
[ Info: iteration 3, average log likelihood -1.409481
[ Info: iteration 4, average log likelihood -1.409405
[ Info: iteration 5, average log likelihood -1.409302
[ Info: iteration 6, average log likelihood -1.409164
[ Info: iteration 7, average log likelihood -1.408981
[ Info: iteration 8, average log likelihood -1.408726
[ Info: iteration 9, average log likelihood -1.408346
[ Info: iteration 10, average log likelihood -1.407772
[ Info: iteration 11, average log likelihood -1.406985
[ Info: iteration 12, average log likelihood -1.406104
[ Info: iteration 13, average log likelihood -1.405353
[ Info: iteration 14, average log likelihood -1.404867
[ Info: iteration 15, average log likelihood -1.404612
[ Info: iteration 16, average log likelihood -1.404493
[ Info: iteration 17, average log likelihood -1.404439
[ Info: iteration 18, average log likelihood -1.404415
[ Info: iteration 19, average log likelihood -1.404405
[ Info: iteration 20, average log likelihood -1.404400
[ Info: iteration 21, average log likelihood -1.404398
[ Info: iteration 22, average log likelihood -1.404397
[ Info: iteration 23, average log likelihood -1.404396
[ Info: iteration 24, average log likelihood -1.404396
[ Info: iteration 25, average log likelihood -1.404396
[ Info: iteration 26, average log likelihood -1.404396
[ Info: iteration 27, average log likelihood -1.404396
[ Info: iteration 28, average log likelihood -1.404396
[ Info: iteration 29, average log likelihood -1.404395
[ Info: iteration 30, average log likelihood -1.404395
[ Info: iteration 31, average log likelihood -1.404395
[ Info: iteration 32, average log likelihood -1.404395
[ Info: iteration 33, average log likelihood -1.404395
[ Info: iteration 34, average log likelihood -1.404395
[ Info: iteration 35, average log likelihood -1.404395
[ Info: iteration 36, average log likelihood -1.404395
[ Info: iteration 37, average log likelihood -1.404395
[ Info: iteration 38, average log likelihood -1.404395
[ Info: iteration 39, average log likelihood -1.404395
[ Info: iteration 40, average log likelihood -1.404395
[ Info: iteration 41, average log likelihood -1.404395
[ Info: iteration 42, average log likelihood -1.404395
[ Info: iteration 43, average log likelihood -1.404395
[ Info: iteration 44, average log likelihood -1.404395
[ Info: iteration 45, average log likelihood -1.404395
[ Info: iteration 46, average log likelihood -1.404395
[ Info: iteration 47, average log likelihood -1.404395
[ Info: iteration 48, average log likelihood -1.404395
[ Info: iteration 49, average log likelihood -1.404395
[ Info: iteration 50, average log likelihood -1.404395
┌ Info: EM with 100000 data points 50 iterations avll -1.404395
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.40960589349936
│     -1.4095395364161836
│      ⋮
└     -1.404395061726447
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404409
[ Info: iteration 2, average log likelihood -1.404317
[ Info: iteration 3, average log likelihood -1.404226
[ Info: iteration 4, average log likelihood -1.404107
[ Info: iteration 5, average log likelihood -1.403957
[ Info: iteration 6, average log likelihood -1.403792
[ Info: iteration 7, average log likelihood -1.403636
[ Info: iteration 8, average log likelihood -1.403511
[ Info: iteration 9, average log likelihood -1.403418
[ Info: iteration 10, average log likelihood -1.403352
[ Info: iteration 11, average log likelihood -1.403303
[ Info: iteration 12, average log likelihood -1.403267
[ Info: iteration 13, average log likelihood -1.403241
[ Info: iteration 14, average log likelihood -1.403222
[ Info: iteration 15, average log likelihood -1.403208
[ Info: iteration 16, average log likelihood -1.403198
[ Info: iteration 17, average log likelihood -1.403191
[ Info: iteration 18, average log likelihood -1.403186
[ Info: iteration 19, average log likelihood -1.403182
[ Info: iteration 20, average log likelihood -1.403179
[ Info: iteration 21, average log likelihood -1.403177
[ Info: iteration 22, average log likelihood -1.403174
[ Info: iteration 23, average log likelihood -1.403172
[ Info: iteration 24, average log likelihood -1.403170
[ Info: iteration 25, average log likelihood -1.403168
[ Info: iteration 26, average log likelihood -1.403167
[ Info: iteration 27, average log likelihood -1.403165
[ Info: iteration 28, average log likelihood -1.403163
[ Info: iteration 29, average log likelihood -1.403162
[ Info: iteration 30, average log likelihood -1.403160
[ Info: iteration 31, average log likelihood -1.403159
[ Info: iteration 32, average log likelihood -1.403157
[ Info: iteration 33, average log likelihood -1.403155
[ Info: iteration 34, average log likelihood -1.403153
[ Info: iteration 35, average log likelihood -1.403152
[ Info: iteration 36, average log likelihood -1.403150
[ Info: iteration 37, average log likelihood -1.403148
[ Info: iteration 38, average log likelihood -1.403146
[ Info: iteration 39, average log likelihood -1.403144
[ Info: iteration 40, average log likelihood -1.403142
[ Info: iteration 41, average log likelihood -1.403140
[ Info: iteration 42, average log likelihood -1.403138
[ Info: iteration 43, average log likelihood -1.403136
[ Info: iteration 44, average log likelihood -1.403133
[ Info: iteration 45, average log likelihood -1.403131
[ Info: iteration 46, average log likelihood -1.403128
[ Info: iteration 47, average log likelihood -1.403126
[ Info: iteration 48, average log likelihood -1.403123
[ Info: iteration 49, average log likelihood -1.403121
[ Info: iteration 50, average log likelihood -1.403118
┌ Info: EM with 100000 data points 50 iterations avll -1.403118
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4044088463907565
│     -1.4043173795556005
│      ⋮
└     -1.4031178822853072
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403126
[ Info: iteration 2, average log likelihood -1.403053
[ Info: iteration 3, average log likelihood -1.402981
[ Info: iteration 4, average log likelihood -1.402889
[ Info: iteration 5, average log likelihood -1.402771
[ Info: iteration 6, average log likelihood -1.402625
[ Info: iteration 7, average log likelihood -1.402460
[ Info: iteration 8, average log likelihood -1.402291
[ Info: iteration 9, average log likelihood -1.402133
[ Info: iteration 10, average log likelihood -1.401994
[ Info: iteration 11, average log likelihood -1.401879
[ Info: iteration 12, average log likelihood -1.401789
[ Info: iteration 13, average log likelihood -1.401719
[ Info: iteration 14, average log likelihood -1.401666
[ Info: iteration 15, average log likelihood -1.401626
[ Info: iteration 16, average log likelihood -1.401594
[ Info: iteration 17, average log likelihood -1.401567
[ Info: iteration 18, average log likelihood -1.401544
[ Info: iteration 19, average log likelihood -1.401524
[ Info: iteration 20, average log likelihood -1.401505
[ Info: iteration 21, average log likelihood -1.401488
[ Info: iteration 22, average log likelihood -1.401471
[ Info: iteration 23, average log likelihood -1.401455
[ Info: iteration 24, average log likelihood -1.401439
[ Info: iteration 25, average log likelihood -1.401423
[ Info: iteration 26, average log likelihood -1.401408
[ Info: iteration 27, average log likelihood -1.401393
[ Info: iteration 28, average log likelihood -1.401378
[ Info: iteration 29, average log likelihood -1.401363
[ Info: iteration 30, average log likelihood -1.401349
[ Info: iteration 31, average log likelihood -1.401335
[ Info: iteration 32, average log likelihood -1.401321
[ Info: iteration 33, average log likelihood -1.401307
[ Info: iteration 34, average log likelihood -1.401294
[ Info: iteration 35, average log likelihood -1.401281
[ Info: iteration 36, average log likelihood -1.401268
[ Info: iteration 37, average log likelihood -1.401256
[ Info: iteration 38, average log likelihood -1.401244
[ Info: iteration 39, average log likelihood -1.401233
[ Info: iteration 40, average log likelihood -1.401222
[ Info: iteration 41, average log likelihood -1.401211
[ Info: iteration 42, average log likelihood -1.401201
[ Info: iteration 43, average log likelihood -1.401191
[ Info: iteration 44, average log likelihood -1.401181
[ Info: iteration 45, average log likelihood -1.401172
[ Info: iteration 46, average log likelihood -1.401163
[ Info: iteration 47, average log likelihood -1.401154
[ Info: iteration 48, average log likelihood -1.401146
[ Info: iteration 49, average log likelihood -1.401138
[ Info: iteration 50, average log likelihood -1.401129
┌ Info: EM with 100000 data points 50 iterations avll -1.401129
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4031257744196581
│     -1.4030532335605292
│      ⋮
└     -1.4011294508767236
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.401131
[ Info: iteration 2, average log likelihood -1.401063
[ Info: iteration 3, average log likelihood -1.400998
[ Info: iteration 4, average log likelihood -1.400921
[ Info: iteration 5, average log likelihood -1.400825
[ Info: iteration 6, average log likelihood -1.400710
[ Info: iteration 7, average log likelihood -1.400580
[ Info: iteration 8, average log likelihood -1.400441
[ Info: iteration 9, average log likelihood -1.400302
[ Info: iteration 10, average log likelihood -1.400167
[ Info: iteration 11, average log likelihood -1.400040
[ Info: iteration 12, average log likelihood -1.399923
[ Info: iteration 13, average log likelihood -1.399817
[ Info: iteration 14, average log likelihood -1.399724
[ Info: iteration 15, average log likelihood -1.399642
[ Info: iteration 16, average log likelihood -1.399571
[ Info: iteration 17, average log likelihood -1.399509
[ Info: iteration 18, average log likelihood -1.399454
[ Info: iteration 19, average log likelihood -1.399406
[ Info: iteration 20, average log likelihood -1.399363
[ Info: iteration 21, average log likelihood -1.399323
[ Info: iteration 22, average log likelihood -1.399287
[ Info: iteration 23, average log likelihood -1.399253
[ Info: iteration 24, average log likelihood -1.399221
[ Info: iteration 25, average log likelihood -1.399192
[ Info: iteration 26, average log likelihood -1.399164
[ Info: iteration 27, average log likelihood -1.399137
[ Info: iteration 28, average log likelihood -1.399112
[ Info: iteration 29, average log likelihood -1.399089
[ Info: iteration 30, average log likelihood -1.399066
[ Info: iteration 31, average log likelihood -1.399044
[ Info: iteration 32, average log likelihood -1.399023
[ Info: iteration 33, average log likelihood -1.399003
[ Info: iteration 34, average log likelihood -1.398984
[ Info: iteration 35, average log likelihood -1.398965
[ Info: iteration 36, average log likelihood -1.398946
[ Info: iteration 37, average log likelihood -1.398929
[ Info: iteration 38, average log likelihood -1.398911
[ Info: iteration 39, average log likelihood -1.398894
[ Info: iteration 40, average log likelihood -1.398878
[ Info: iteration 41, average log likelihood -1.398862
[ Info: iteration 42, average log likelihood -1.398847
[ Info: iteration 43, average log likelihood -1.398832
[ Info: iteration 44, average log likelihood -1.398817
[ Info: iteration 45, average log likelihood -1.398803
[ Info: iteration 46, average log likelihood -1.398789
[ Info: iteration 47, average log likelihood -1.398776
[ Info: iteration 48, average log likelihood -1.398763
[ Info: iteration 49, average log likelihood -1.398751
[ Info: iteration 50, average log likelihood -1.398739
┌ Info: EM with 100000 data points 50 iterations avll -1.398739
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.401131479420363
│     -1.4010625005697797
│      ⋮
└     -1.3987390767847998
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.398735
[ Info: iteration 2, average log likelihood -1.398666
[ Info: iteration 3, average log likelihood -1.398598
[ Info: iteration 4, average log likelihood -1.398518
[ Info: iteration 5, average log likelihood -1.398419
[ Info: iteration 6, average log likelihood -1.398295
[ Info: iteration 7, average log likelihood -1.398145
[ Info: iteration 8, average log likelihood -1.397974
[ Info: iteration 9, average log likelihood -1.397791
[ Info: iteration 10, average log likelihood -1.397609
[ Info: iteration 11, average log likelihood -1.397436
[ Info: iteration 12, average log likelihood -1.397280
[ Info: iteration 13, average log likelihood -1.397142
[ Info: iteration 14, average log likelihood -1.397022
[ Info: iteration 15, average log likelihood -1.396919
[ Info: iteration 16, average log likelihood -1.396830
[ Info: iteration 17, average log likelihood -1.396752
[ Info: iteration 18, average log likelihood -1.396685
[ Info: iteration 19, average log likelihood -1.396625
[ Info: iteration 20, average log likelihood -1.396571
[ Info: iteration 21, average log likelihood -1.396523
[ Info: iteration 22, average log likelihood -1.396479
[ Info: iteration 23, average log likelihood -1.396439
[ Info: iteration 24, average log likelihood -1.396402
[ Info: iteration 25, average log likelihood -1.396367
[ Info: iteration 26, average log likelihood -1.396335
[ Info: iteration 27, average log likelihood -1.396305
[ Info: iteration 28, average log likelihood -1.396277
[ Info: iteration 29, average log likelihood -1.396250
[ Info: iteration 30, average log likelihood -1.396225
[ Info: iteration 31, average log likelihood -1.396201
[ Info: iteration 32, average log likelihood -1.396178
[ Info: iteration 33, average log likelihood -1.396156
[ Info: iteration 34, average log likelihood -1.396135
[ Info: iteration 35, average log likelihood -1.396114
[ Info: iteration 36, average log likelihood -1.396095
[ Info: iteration 37, average log likelihood -1.396076
[ Info: iteration 38, average log likelihood -1.396059
[ Info: iteration 39, average log likelihood -1.396041
[ Info: iteration 40, average log likelihood -1.396025
[ Info: iteration 41, average log likelihood -1.396009
[ Info: iteration 42, average log likelihood -1.395994
[ Info: iteration 43, average log likelihood -1.395979
[ Info: iteration 44, average log likelihood -1.395966
[ Info: iteration 45, average log likelihood -1.395952
[ Info: iteration 46, average log likelihood -1.395939
[ Info: iteration 47, average log likelihood -1.395927
[ Info: iteration 48, average log likelihood -1.395915
[ Info: iteration 49, average log likelihood -1.395904
[ Info: iteration 50, average log likelihood -1.395893
┌ Info: EM with 100000 data points 50 iterations avll -1.395893
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3987354634948959
│     -1.3986661173765667
│      ⋮
└     -1.395892528323647
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.409588791785883
│     -1.40960589349936
│     -1.4095395364161836
│     -1.4094812950583848
│      ⋮
│     -1.3959150248976782
│     -1.3959035697935005
└     -1.395892528323647
32×26 Array{Float64,2}:
 -0.735314   -0.523055   -0.248892    -0.496968   -0.696101   -1.01062      1.1355     -0.274014    -0.0383698    0.232215   -0.0488015   0.530966    0.139765    -0.120012     0.287694     0.0440939     0.199423    -0.171723    0.0306978    0.573557    -0.660225   -0.179068    -0.575032    0.181994   -0.411092     0.422076
 -0.800514    0.238922    0.164162    -0.203754    0.340115   -0.359646     0.923166    0.0408689   -0.683537     0.475914   -0.143595    0.438298   -0.0301341    0.673725     0.119601    -0.388763     -0.0123452   -0.0458078   0.0757992    0.0115181   -0.364905    0.209644     0.0329215  -0.126903   -0.571918    -0.198932
 -0.321569   -0.239577   -0.74466     -0.042058   -0.0301114  -0.0871281    0.135415   -0.396625    -0.313204    -0.138425   -0.359283   -0.166412   -0.0684371    0.110583    -0.282384    -0.0773396     0.0441407   -0.953436   -0.639921    -0.138806    -0.276257    0.409934    -0.342935    0.044326    0.381107     0.108481
  0.056513    0.280839   -0.320978     0.131839   -0.106152   -0.284611     0.153346   -0.321766     0.130301     0.413563   -0.370665    0.426044    0.00226869   0.414436    -0.351499    -0.0612694    -0.0375876   -0.46331    -0.538896     1.0007       0.264447    0.276437    -0.338199    0.440993   -0.532661     0.192913
 -0.0320418  -0.359483   -0.0742601    0.0907518  -0.337347   -0.103632     0.12225    -0.00137255   0.0662318    0.313848   -0.116834    0.0940407  -0.0559575   -0.346041     0.0527343   -0.00725697   -0.0764766   -0.034979    0.0326044   -0.0608402    0.0999644   0.0991374   -0.170204    0.101054    0.304193     0.213691
 -0.0610657   0.664981    0.257076    -0.0287932   0.687756    0.112623    -0.377978    0.0347244    0.00415367  -0.320684    0.0516184  -0.226321    0.180894     0.218729    -0.0501414   -0.06318       0.114503     0.191987    0.00727474   0.0625089   -0.0592555  -0.218452     0.199753    0.0604712   0.0212553   -0.393383
 -0.438376    0.407483    0.649918    -0.466764    0.0481859  -0.0164603    0.32782    -0.0674651   -0.289077     0.277605   -0.594922    0.680784   -0.22075     -0.216177    -0.0391687    0.368295     -0.427368     0.441469    0.490948     0.072371     0.483951   -0.341927     0.471044   -0.0192445  -0.0638312   -0.0567572
 -0.39143     0.0872329   0.225866    -0.27492     0.119267    0.345009     0.217065    0.233383    -0.255627    -0.0987492  -0.697653    0.320072   -0.106053    -0.41788     -0.175464     0.919311      0.616513     0.534826   -0.50281     -0.0759087   -0.518486    0.0101604   -0.164424   -0.550879   -0.00138406   0.100576
  0.578333    0.53274     0.15629      0.568136   -0.414262   -0.0278838    0.416605   -0.815542    -0.218732     0.725218   -0.271541   -0.146823   -0.112767     0.0849687   -0.494591     0.185415     -0.0171548    0.284437    0.00691979   0.00609775  -0.0427383   0.389094     0.274119    0.0458426   0.24335     -0.152503
  0.301724   -0.103008    0.298664     0.553667   -0.428671    0.147734     0.35732     0.315267    -0.120449     0.651656    0.421388   -0.0157559  -0.272361    -0.0148033   -0.453962    -0.171979     -0.296793     0.63329     0.499885    -0.307218    -0.214742    0.128362    -0.431673   -0.113659    0.00511576  -0.152992
  1.25577    -0.443019   -0.0125074   -0.0326327  -0.466467    0.481893    -0.336473    0.117593     0.207626     0.260849    0.0765579  -0.390273    0.71189     -0.131971    -0.322781     0.111012     -0.0637466   -0.357497    0.14451     -0.121232    -0.666199    0.365562    -0.0384728  -0.144723   -0.0460935    0.0960624
  0.398444   -0.245656    0.517725    -0.122513    0.218495    0.880373     0.0229468   0.459697    -0.230199     0.0119038   0.204842    0.740752    0.421094     0.196097    -0.417897    -0.212451     -0.190578    -0.168375    0.157755    -0.0725771   -0.470163    0.249022     0.0741856  -0.516876   -0.272938     0.321082
 -0.114108    0.0646273  -0.620131     0.355935    0.0356879   0.175092    -0.0556654  -0.228094    -0.549702    -0.186625    0.529583   -0.251774   -0.469788     0.413117    -0.508765    -0.0679507    -0.221653    -0.368274    0.262443    -0.274914    -0.650708    0.172803     0.300769    0.0833661  -0.659528     0.44524
  0.240475    0.0728762  -0.393216     0.44149    -0.0587068  -0.408927    -0.0431352   0.333084     0.690934    -0.715156    0.182672   -0.579501    0.25771      0.357516    -0.316692    -0.253127     -0.112309    -0.339661    0.16527     -0.223928    -0.911175   -0.195998    -0.299711   -0.176006    0.0526997    0.0782778
 -0.0773075   0.650247   -0.696295     0.030107   -0.717173   -0.828891    -0.289272   -0.0370382    0.108093     0.29117    -0.235871   -0.351935    0.163345     0.148502     0.176232    -0.316157     -0.272305    -0.999153    0.332512     0.215663     0.440938   -0.417821     0.464825    0.393449   -0.113637     0.0709793
  0.53068     0.014406   -0.117096     0.418683    0.193209   -0.1399      -0.277924   -0.0461337    0.0494208    0.189314    0.67144    -0.112356    0.298994     0.475272     0.288513    -1.23929      -0.538206    -0.453575    0.376577     0.0623124    0.739695    0.28766      0.179366    0.635202   -0.0107434   -0.182134
  0.112203    0.192654    0.034418    -0.0322885   0.188264    0.0820507   -0.0615877  -0.091408    -0.0250466   -0.119081   -0.145466    0.0988586   0.0539213    0.0873979    0.170002     0.0560617     0.03961      0.0299635  -0.125238     0.0457291    0.0981337   0.120927     0.159636    0.0431748  -0.362125     0.113291
 -0.120136   -0.01663     0.151033    -0.0377473  -0.123308   -0.0820753    0.181103   -0.1953      -0.033        0.191713   -0.189034    0.101967   -0.176507    -0.144121     0.0789616   -0.0247894     0.0809627    0.131168   -0.0842383   -0.013613     0.0650415  -0.103878    -0.174686    0.0142717   0.398224    -0.126745
  0.115181   -0.0848713  -0.128655     0.123801    0.105045   -0.204793    -0.262051    0.270561     0.125443    -0.078101    0.0776447   0.192953    0.171833    -0.0137939   -0.394627     0.150627     -0.537225    -0.0522697   0.404717    -0.0159224   -0.255777   -0.0436294    0.114791    0.43907    -0.152003     0.122538
 -0.0279521  -0.127855   -0.223467     0.178371   -0.0329524   0.268313    -0.0571369   0.371842    -0.0302189    0.0390011   0.258333   -0.0860639   0.105587     0.0293533   -0.25216     -0.204741      0.196583    -0.151346    0.0946326   -0.0261602   -0.30698     0.00882448  -0.162749   -0.145928    0.0218134    0.0525408
 -0.138205   -0.510549    0.292448    -0.349524    0.0144088   0.391879    -0.0192761   0.345552     0.237526    -0.208834    0.209665   -0.326542   -0.0268942   -0.803435     0.185799     0.173558      0.234768     0.466828    0.415325    -0.630679    -0.24265    -0.492315     0.10032    -0.0428587   0.653123    -0.118665
  0.169532    0.0801229  -0.00779995  -0.0163299  -0.33876     0.0777796   -0.356008    0.261025     0.69741      0.0050609  -0.346213   -0.237036   -0.54479     -0.833731    -0.00830976   0.680724     -0.0764075   -0.078733   -0.350146    -0.123167     0.356357   -0.204476     0.214586    0.188761    0.82542     -0.244226
  0.461656   -0.244769    0.64046     -0.519627   -0.496956   -0.459217    -0.118389   -0.113794     0.345692     0.500036   -0.18562     0.215662    0.352369     0.00213508   0.183797    -0.134094     -0.177378    -0.113291    0.338946    -0.16294     -0.1635     -0.31489     -0.176686   -0.22794     0.363176    -0.15113
  0.377304   -0.689433   -0.152582    -0.146965   -0.532767   -0.00913443   0.308882   -0.131755    -0.0264654    0.579401    0.136028    0.182424   -0.405172    -0.8601       0.333478    -0.147972     -0.276194    -0.175408    0.162013     0.25153      0.889241    0.240716     0.234741    0.252342    0.329234     0.306104
  0.33701     0.34924     0.223915     0.657788    0.474355    0.52818     -0.163717    0.119107    -0.234833    -0.379064   -0.120621   -0.384655   -0.395876     0.0295623    0.329966    -0.177746      0.456531     0.382031   -0.379835    -0.376741     0.219399    0.778319     0.425381   -0.232279   -0.214386    -0.119137
 -0.357067   -0.135443   -0.239969    -0.0200064   0.653249    0.56773      0.578956   -0.00305822  -0.284597    -0.636964    0.0126335   0.399987   -0.0737093   -0.650753     0.0799499   -0.117109     -0.0727488    0.295115   -0.387697    -0.274449     0.187472    0.0228809    0.0487862   0.894616   -0.335209     0.0819108
 -0.916252    0.129817   -0.325172     0.392394    0.39018    -0.349382     0.0709905  -0.145009     0.112195    -0.152098   -0.0219983  -0.0410794  -0.870464     0.0385127    0.170757     0.0248518     0.378348     0.485142   -0.351345     0.165666     0.291422   -0.0539883   -0.291171    0.144575    0.391104    -0.0629128
  0.177026    0.175416   -0.363497     0.670968   -0.0425007   0.304692    -0.693149    0.146594     0.405056     0.219809    0.345617   -0.57495     0.309387     0.0514884   -0.0881652    0.231564      0.912554     0.177386   -0.315551     0.137591     0.054775    0.0470043   -0.387834    0.0168937   0.367845     0.177141
 -0.520392    0.554276    0.146914    -0.157363    0.329307   -0.574451    -0.102287   -0.0361508    0.120141    -0.778951   -0.538022   -0.479757    0.719872     0.250997     0.409228    -0.278739      0.330667    -0.244194   -0.321741    -0.247134    -0.50374    -0.569245     0.231393   -0.155471   -0.163175    -0.176506
  0.135989    0.54586    -0.0580933   -0.373366    0.322165   -0.155369    -0.437011   -0.266834    -0.280125    -0.255846    0.113265   -0.364073    0.0581561    0.376748     0.141017    -0.00917521    0.287506     0.0893236   0.484387     0.258104    -0.0579402  -0.488378     0.420775    0.172996   -0.400212    -0.362782
 -0.152592    0.0835839   0.261433    -0.505942    0.38523    -0.117095    -0.168618   -0.538645     0.198735    -0.294905   -0.200462    0.437126    0.539665     0.135554     0.590975     0.000592043   0.50655     -0.15217    -0.272023     0.518201     0.488763   -0.30048      0.0448695  -0.133232    0.573148     0.18574
 -0.534174   -0.430458   -0.0942893   -0.496281    0.387856   -0.339726    -0.346659    0.785611     0.229614    -0.535648    0.426208    0.198493    0.138038    -0.0102098    0.601574    -0.324121      0.00403742  -0.274001    0.014713     0.313909     0.237477   -0.297676    -0.0411583  -0.304952   -0.360249    -0.0497409[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.395882
[ Info: iteration 2, average log likelihood -1.395872
[ Info: iteration 3, average log likelihood -1.395862
[ Info: iteration 4, average log likelihood -1.395852
[ Info: iteration 5, average log likelihood -1.395843
[ Info: iteration 6, average log likelihood -1.395834
[ Info: iteration 7, average log likelihood -1.395825
[ Info: iteration 8, average log likelihood -1.395816
[ Info: iteration 9, average log likelihood -1.395808
[ Info: iteration 10, average log likelihood -1.395800
┌ Info: EM with 100000 data points 10 iterations avll -1.395800
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.658609e+05
      1       6.883365e+05      -1.775244e+05 |       32
      2       6.714847e+05      -1.685185e+04 |       32
      3       6.651710e+05      -6.313616e+03 |       32
      4       6.621411e+05      -3.029923e+03 |       32
      5       6.602612e+05      -1.879874e+03 |       32
      6       6.589021e+05      -1.359166e+03 |       32
      7       6.578316e+05      -1.070497e+03 |       32
      8       6.569562e+05      -8.754036e+02 |       32
      9       6.562492e+05      -7.070174e+02 |       32
     10       6.556589e+05      -5.902988e+02 |       32
     11       6.551800e+05      -4.788784e+02 |       32
     12       6.547865e+05      -3.934544e+02 |       32
     13       6.544767e+05      -3.098203e+02 |       32
     14       6.541967e+05      -2.800373e+02 |       32
     15       6.539499e+05      -2.467443e+02 |       32
     16       6.537414e+05      -2.085718e+02 |       32
     17       6.535522e+05      -1.891393e+02 |       32
     18       6.533823e+05      -1.699522e+02 |       32
     19       6.532312e+05      -1.510347e+02 |       32
     20       6.530867e+05      -1.445141e+02 |       32
     21       6.529557e+05      -1.310412e+02 |       32
     22       6.528468e+05      -1.088234e+02 |       32
     23       6.527482e+05      -9.863112e+01 |       32
     24       6.526461e+05      -1.020899e+02 |       32
     25       6.525461e+05      -9.999343e+01 |       32
     26       6.524463e+05      -9.986437e+01 |       32
     27       6.523513e+05      -9.501214e+01 |       32
     28       6.522683e+05      -8.293228e+01 |       32
     29       6.521903e+05      -7.805870e+01 |       32
     30       6.521226e+05      -6.767396e+01 |       32
     31       6.520554e+05      -6.723253e+01 |       32
     32       6.519967e+05      -5.867536e+01 |       32
     33       6.519471e+05      -4.956253e+01 |       32
     34       6.519056e+05      -4.153777e+01 |       32
     35       6.518689e+05      -3.671845e+01 |       32
     36       6.518317e+05      -3.717155e+01 |       32
     37       6.517979e+05      -3.377067e+01 |       32
     38       6.517699e+05      -2.802365e+01 |       32
     39       6.517437e+05      -2.621954e+01 |       32
     40       6.517168e+05      -2.683282e+01 |       32
     41       6.516897e+05      -2.712516e+01 |       32
     42       6.516663e+05      -2.347359e+01 |       32
     43       6.516396e+05      -2.668481e+01 |       32
     44       6.516127e+05      -2.691186e+01 |       32
     45       6.515858e+05      -2.688772e+01 |       32
     46       6.515600e+05      -2.573247e+01 |       32
     47       6.515357e+05      -2.431843e+01 |       32
     48       6.515099e+05      -2.584986e+01 |       32
     49       6.514860e+05      -2.388724e+01 |       32
     50       6.514630e+05      -2.296537e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 651463.0126100413)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407113
[ Info: iteration 2, average log likelihood -1.402318
[ Info: iteration 3, average log likelihood -1.401121
[ Info: iteration 4, average log likelihood -1.400311
[ Info: iteration 5, average log likelihood -1.399462
[ Info: iteration 6, average log likelihood -1.398580
[ Info: iteration 7, average log likelihood -1.397842
[ Info: iteration 8, average log likelihood -1.397353
[ Info: iteration 9, average log likelihood -1.397062
[ Info: iteration 10, average log likelihood -1.396881
[ Info: iteration 11, average log likelihood -1.396756
[ Info: iteration 12, average log likelihood -1.396662
[ Info: iteration 13, average log likelihood -1.396585
[ Info: iteration 14, average log likelihood -1.396522
[ Info: iteration 15, average log likelihood -1.396467
[ Info: iteration 16, average log likelihood -1.396418
[ Info: iteration 17, average log likelihood -1.396375
[ Info: iteration 18, average log likelihood -1.396336
[ Info: iteration 19, average log likelihood -1.396301
[ Info: iteration 20, average log likelihood -1.396268
[ Info: iteration 21, average log likelihood -1.396237
[ Info: iteration 22, average log likelihood -1.396208
[ Info: iteration 23, average log likelihood -1.396181
[ Info: iteration 24, average log likelihood -1.396155
[ Info: iteration 25, average log likelihood -1.396130
[ Info: iteration 26, average log likelihood -1.396107
[ Info: iteration 27, average log likelihood -1.396085
[ Info: iteration 28, average log likelihood -1.396064
[ Info: iteration 29, average log likelihood -1.396044
[ Info: iteration 30, average log likelihood -1.396024
[ Info: iteration 31, average log likelihood -1.396006
[ Info: iteration 32, average log likelihood -1.395988
[ Info: iteration 33, average log likelihood -1.395971
[ Info: iteration 34, average log likelihood -1.395954
[ Info: iteration 35, average log likelihood -1.395939
[ Info: iteration 36, average log likelihood -1.395923
[ Info: iteration 37, average log likelihood -1.395909
[ Info: iteration 38, average log likelihood -1.395895
[ Info: iteration 39, average log likelihood -1.395881
[ Info: iteration 40, average log likelihood -1.395868
[ Info: iteration 41, average log likelihood -1.395855
[ Info: iteration 42, average log likelihood -1.395842
[ Info: iteration 43, average log likelihood -1.395830
[ Info: iteration 44, average log likelihood -1.395818
[ Info: iteration 45, average log likelihood -1.395807
[ Info: iteration 46, average log likelihood -1.395796
[ Info: iteration 47, average log likelihood -1.395785
[ Info: iteration 48, average log likelihood -1.395775
[ Info: iteration 49, average log likelihood -1.395764
[ Info: iteration 50, average log likelihood -1.395755
┌ Info: EM with 100000 data points 50 iterations avll -1.395755
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0320211   0.468823    -0.419258    0.085511   -0.182775    -0.239407     0.184656    -0.639624    -0.138094     0.510145   -0.425939     0.287108    0.0336765    0.470429    -0.460763    -0.108126     0.024565    -0.624772   -0.42741      0.686412    0.166214    0.35447     -0.122807     0.217387   -0.19082     -0.0143959
  0.65531     0.106763     0.418023   -0.297836   -0.714802    -0.69278     -0.429721    -0.269088     0.640864     0.619454   -0.395103    -0.128626    0.129204     0.136505     0.356879    -0.0202415   -0.0583381   -0.40217     0.288935    -0.137566   -0.0531588  -0.234939     0.120674    -0.288872    0.419335    -0.192897
 -0.655997    0.311851    -0.280248   -0.515279    0.3547      -0.751447    -0.299014     0.0743983   -0.119893    -0.512285    0.23985     -0.109372   -0.0262276    0.240014     0.707507    -0.294317    -0.0633279   -0.385518    0.00252033   0.478447    0.528106   -0.361191     0.540037     0.209995   -0.315183    -0.271451
  0.378176    0.242283    -0.125463    0.379857   -0.327051     0.225549    -0.78912      0.520752     0.551632     0.10826     0.314301    -0.785096    0.742446    -0.0513156   -0.209028     0.239133     0.682886     0.275604    0.251116     0.462253   -0.243257   -0.295748    -0.133838    -0.22983     0.206749     0.389331
 -0.0645288  -0.0881692   -0.51927     0.693332   -0.52133     -0.789894    -0.178933     0.00304334   0.214221    -0.451021    0.220629    -0.759358   -0.0265217    0.213232    -0.359119    -0.180504    -0.379651    -0.371736    0.241188    -0.271195   -0.704421   -0.00765606  -0.155882    -0.126387    0.434407    -0.207268
 -0.569957   -0.45886     -0.182492   -0.324999   -0.294881    -0.943967     0.710392    -0.557375     0.168056    -0.0334107  -0.256567     0.373561    0.139081    -0.00873934   0.309131     0.0661947    0.215224     0.0725628  -0.230662     0.775937   -0.303112    0.0987137   -0.668649     0.439885   -0.154855     0.598157
  0.775824    0.248277     0.319893    0.249754    0.405993     0.162993    -0.466118    -0.201938     0.239476    -0.0362276   0.407461    -0.142437    0.508887     0.463253     0.353618    -0.764701    -0.248327    -0.0772643   0.195653     0.0428076   0.604783    0.132667     0.182231     0.453063   -0.00160953  -0.270918
  0.0441136   0.00699209   0.0783431  -0.079692    0.0122651   -0.018365     0.00109217  -0.0939588   -0.0304346    0.02336    -0.0783158    0.128528    0.00898219  -0.0531254    0.108955     0.00504508  -0.00643201   0.0645101   0.0188585    0.0308299   0.032272   -0.0124487    0.0309343    0.0937744  -0.0147285    0.053799
 -0.20422     0.0526708   -0.304279    0.598466    0.616929     0.506277     0.496343     0.208294    -0.638616    -0.44272     0.659395    -0.122752    0.213538     0.416965    -0.0076848   -0.486535     0.49048      0.219194   -0.0159055   -0.213365   -0.552867    0.38006      0.172705    -0.404011   -0.730258     0.422307
 -0.244198   -0.285425    -0.744092    0.213839   -0.0128028   -0.0232005   -0.264096    -0.381811    -0.00700416  -0.182078    0.117655    -0.454024    0.181598     0.128452     0.13871      0.0256014    0.607545    -0.776251   -0.739179     0.0263945  -0.217123    0.12562     -0.533694     0.262736    0.478526     0.437604
 -0.507175   -0.156264    -0.171768   -0.201531    0.806861     0.751648     0.608531     0.0158996   -0.359087    -0.649425   -0.00836371   0.683619   -0.0815627   -0.578798    -0.0267954   -0.0689316   -0.103704     0.264591   -0.428263    -0.196554    0.191874    0.0687469   -0.042021     0.894319   -0.357951     0.0713371
  0.220997    0.492859     0.229192    0.54446     0.113132     0.779866    -0.235048     0.111811    -0.30501      0.0546081  -0.680556    -0.135307   -0.38691     -0.0264641    0.202344     0.139793     0.356324     0.381861   -0.573048    -0.139914    0.337181    0.728972     0.203681    -0.0219657  -0.185321     0.0899572
  0.336459    0.145468    -0.179934    0.0668343   0.011379     0.273808    -0.647871    -0.321122    -0.395515     0.0652562   0.470411    -0.214222   -0.757502     0.764285    -0.369232    -0.14658     -0.0782609   -0.298767    0.545656    -0.223306   -0.60475     0.10136      0.30012     -0.280523   -0.548609     0.074149
  0.0648616   0.253333     0.0202518   0.0966817   0.400939    -0.13415     -0.493845     0.448309     0.172115    -0.170809   -0.0796647    0.34317     0.32773      0.209185    -0.643381     0.403902    -0.394852    -0.0051651   0.59119      0.141872   -0.433715   -0.139606     0.213887     0.366949   -0.321858    -0.0192872
  0.176094    0.071343    -0.650187    0.369808    9.76888e-5  -0.10317      0.107266    -0.06426     -0.148903    -0.290482    0.0840642   -0.192871   -0.194087    -0.172558    -0.149627    -0.221314    -0.747401    -0.426214   -0.00379375  -0.262489    0.0940964   0.189144     0.338682     0.790016   -0.492643     0.35036
 -0.329357    0.183923     0.697896   -0.270572    0.345575     0.177403     0.0604618    0.114806    -0.0697175   -0.0674186  -0.21423      0.0854862  -0.0282759   -0.245481    -0.0459726    0.186922     0.161781     0.621623    0.0503872   -0.102723   -0.159718   -0.104172     0.107446    -0.317192    0.319381    -0.225599
 -0.323251   -0.32174     -0.47103    -0.0855393  -0.3333      -0.00715185  -0.0158532    0.901736    -0.62083     -0.176283   -0.176482    -0.14325     0.0389984   -0.722895    -0.147124     0.783404     0.282887     0.0974084  -0.317741    -0.111147   -0.816472   -0.0365746   -0.178951    -0.567126   -0.67412     -0.0684627
 -0.141311    0.324404    -0.403006    0.154968    0.241226     0.00342045  -0.113293    -0.4339      -0.0345373   -0.139214   -0.152843    -0.450802   -0.692561    -0.478197     0.339348     0.453493     0.451549     0.660187    0.0823591   -0.416978    0.355694   -0.607818     0.147342     0.439933    0.473382    -0.21354
  0.460428    0.24997      0.538389    0.355717   -0.326847    -0.0676665    0.512258    -0.254529    -0.227759     0.650062    0.122161     0.0301415  -0.136198     0.0927043   -0.457231     0.0385098   -0.19216      0.760091    0.426861    -0.014515   -0.0302104   0.107062     0.0418894   -0.0919913   0.0536765   -0.237815
 -0.12758    -0.778397     0.218236   -0.284576   -0.0893234    0.108052     0.0499859    0.45454      0.250234    -0.0959975   0.366689     0.127759    0.077624    -0.342991     0.275001    -0.211086    -0.0615466    0.219608    0.521888    -0.371099   -0.237869   -0.303402    -0.14889     -0.114487    0.289882     0.15384
 -0.840819    0.19678     -0.326849    0.523502    0.188961    -0.152773     0.0187785    0.179443     0.0606381    0.116428    0.211727     0.069875   -0.565933     0.234394     0.00401704  -0.244223     0.255609     0.324497   -0.155147     0.38545     0.315129   -0.0679271   -0.413556     0.0871204   0.106014    -0.022562
  0.501105   -0.383092     0.373436   -0.795961    0.0110965    0.304978    -0.0746202    0.240536    -0.173319     0.0590841   0.250734     0.476264    0.811959     0.278981    -0.043161    -0.257663    -0.37958     -0.657622    0.206331     0.100232   -0.328644   -0.243614    -0.0437283   -0.331409   -0.385683     0.0558206
  0.401212   -0.656333    -0.224426   -0.0411513  -0.584197    -0.154601     0.207931    -0.0448866    0.074821     0.659631    0.194977     0.160216   -0.396717    -0.792472     0.367654    -0.269057    -0.328209    -0.265933    0.26865      0.29781     1.09239     0.218317     0.220344     0.347696    0.344673     0.245378
 -0.345035    0.172495     0.434655   -0.613033    0.202633     0.0910695    0.0843979   -0.164206    -0.0993886    0.0607039  -0.577888     0.582429    0.124844    -0.220339     0.457336     0.392103     0.340023     0.204557   -0.226252     0.293055    0.393974   -0.347213     0.0977968   -0.213886    0.279466     0.0380116
  0.291746   -0.060484    -0.277813    0.257957   -0.0674634    0.380456    -0.140597     0.314342     0.02793      0.222202    0.273071    -0.147819    0.0957325    0.0801668   -0.435248    -0.161732     0.100503    -0.27624     0.0215334   -0.0912007  -0.230236    0.162301    -0.177353    -0.122457    0.0685169   -0.0134137
 -0.646351   -0.011667     0.117776   -0.258147   -0.266833    -0.282105     0.962098     0.0093964   -0.516888     0.533473   -0.327924     0.350748   -0.376118    -0.0719113   -0.243045    -0.219842    -0.351412    -0.252764    0.13523     -0.0606831  -0.293069   -0.110973    -0.114014    -0.0572543  -0.0880232   -0.0673688
 -0.476369    0.0701415   -0.440373   -0.0676599   0.332229    -0.341146     0.137763     0.0781677    0.25283      0.409131   -0.642713     0.33248    -0.664795     0.169986    -0.0429184    0.607492     0.335195    -0.431895   -0.561937    -0.175903    0.218505    0.702278     0.448606    -0.865135    0.597137     0.335431
  0.88131    -0.356531     0.0658035   0.270206   -0.342111     0.648071     0.180894    -0.180669     0.0389731    0.389502   -0.171912     0.0914982   0.346331    -0.470396    -0.616679     0.0797988   -0.0386793    0.0272571   0.0177158   -0.466513   -0.503066    0.769752    -0.174299    -0.124144    0.331712     0.212547
 -0.301245    0.420562     0.103405   -0.209254    0.366277    -0.310902    -0.108534    -0.00561964   0.122594    -0.6448     -0.301253    -0.269791    0.517723     0.31295      0.339064    -0.22122      0.383549    -0.151859   -0.119716    -0.0632933  -0.364971   -0.414775     0.146962    -0.180716   -0.139093    -0.132191
  0.0609822   0.055219    -0.5093      0.317187   -0.164397    -0.217611    -0.0556814    0.093928     0.262731    -0.0235434   0.0397538   -0.10297     0.215748     0.229476    -0.20177     -0.236435    -0.12005     -0.556382   -0.0367628    0.0507982  -0.118568   -0.16748     -0.321056     0.306831   -0.0444101    0.177472
 -0.183653   -0.140468     0.174185    0.543467    0.693616     0.0586352   -0.0174463    0.058761     0.278728    -0.564807    0.115584    -0.0191426  -0.567467    -0.285471    -0.175643     0.335054     0.547739     0.525547   -0.798326    -0.204001   -0.0876691   0.534482    -0.0524521   -0.0894017   0.175977    -0.468718
 -0.0078429  -0.0971483    0.241409   -0.148584   -0.437404     0.219939    -0.171899     0.464743     0.705437    -0.0697898  -0.253114    -0.228686   -0.331794    -1.14515     -0.133925     0.457729     0.0221883   -0.0473285  -0.304739    -0.162407    0.0774211  -0.44655      0.00183868   0.181939    0.889108    -0.286194[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.395745
[ Info: iteration 2, average log likelihood -1.395736
[ Info: iteration 3, average log likelihood -1.395728
[ Info: iteration 4, average log likelihood -1.395720
[ Info: iteration 5, average log likelihood -1.395712
[ Info: iteration 6, average log likelihood -1.395704
[ Info: iteration 7, average log likelihood -1.395697
[ Info: iteration 8, average log likelihood -1.395690
[ Info: iteration 9, average log likelihood -1.395684
[ Info: iteration 10, average log likelihood -1.395677
┌ Info: EM with 100000 data points 10 iterations avll -1.395677
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
