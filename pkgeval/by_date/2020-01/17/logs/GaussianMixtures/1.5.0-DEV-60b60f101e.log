Julia Version 1.5.0-DEV.77
Commit 60b60f101e (2020-01-16 15:44 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed LegacyStrings ────── v0.4.1
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Rmath ────────────── v0.6.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed Arpack ───────────── v0.4.0
 Installed QuadGK ───────────── v2.3.1
 Installed SpecialFunctions ─── v0.9.0
 Installed BinDeps ──────────── v1.0.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Distances ────────── v0.8.2
 Installed CMake ────────────── v1.1.2
 Installed JLD ──────────────── v0.9.1
 Installed BinaryProvider ───── v0.5.8
 Installed StaticArrays ─────── v0.12.1
 Installed URIParser ────────── v0.4.0
 Installed Parameters ───────── v0.12.0
 Installed OrderedCollections ─ v1.1.0
 Installed DataAPI ──────────── v1.1.0
 Installed DataStructures ───── v0.17.9
 Installed HDF5 ─────────────── v0.12.5
 Installed StatsFuns ────────── v0.9.3
 Installed FileIO ───────────── v1.2.1
 Installed StatsBase ────────── v0.32.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed FillArrays ───────── v0.8.4
 Installed NearestNeighbors ─── v0.4.4
 Installed Blosc ────────────── v0.5.1
 Installed Missings ─────────── v0.4.3
 Installed SortingAlgorithms ── v0.3.1
 Installed PDMats ───────────── v0.9.10
 Installed Clustering ───────── v0.13.3
 Installed Distributions ────── v0.22.3
 Installed Compat ───────────── v2.2.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_qA9nqq/Project.toml`
 [no changes]
  Updating `/tmp/jl_qA9nqq/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_h21vIS/Project.toml`
 [no changes]
  Updating `/tmp/jl_h21vIS/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_qcZulN/Project.toml`
 [no changes]
  Updating `/tmp/jl_qcZulN/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_dibW4m/Project.toml`
 [no changes]
  Updating `/tmp/jl_dibW4m/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_kO80ql/Project.toml`
 [no changes]
  Updating `/tmp/jl_kO80ql/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_kO80ql/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.4442034349916994e6, [74088.57057774339, 25911.429422256595], [-16380.53071030909 12520.505106006256 4626.836544831202; 15785.425185549668 -12381.228222556821 -4621.265304215225], [[86304.80183763143 1824.0330483953032 201.14800895482801; 1824.0330483953032 72501.96826083898 1076.6115053800982; 201.14800895482801 1076.611505380098 72274.13806540502], [13695.176696008148 -2311.4837394039005 -230.9574029537729; -2311.4837394039005 27269.87152389385 -1005.8947668938166; -230.9574029537729 -1005.8947668938168 28058.891850792566]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.034430e+03
      1       1.007595e+03      -1.026835e+03 |        7
      2       9.435499e+02      -6.404529e+01 |        2
      3       9.410064e+02      -2.543578e+00 |        2
      4       9.394892e+02      -1.517132e+00 |        0
      5       9.394892e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 939.4892360720523)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.064726
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.721801
[ Info: iteration 2, lowerbound -3.560951
[ Info: iteration 3, lowerbound -3.406141
[ Info: iteration 4, lowerbound -3.255468
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.112279
[ Info: iteration 6, lowerbound -2.984360
[ Info: iteration 7, lowerbound -2.887668
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.804213
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.712879
[ Info: iteration 10, lowerbound -2.632073
[ Info: iteration 11, lowerbound -2.561678
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.489157
[ Info: iteration 13, lowerbound -2.425439
[ Info: iteration 14, lowerbound -2.378555
[ Info: iteration 15, lowerbound -2.343699
[ Info: iteration 16, lowerbound -2.319532
[ Info: iteration 17, lowerbound -2.308069
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.303068
[ Info: iteration 19, lowerbound -2.299263
[ Info: iteration 20, lowerbound -2.299258
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan 17 20:12:32 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan 17 20:12:40 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Fri Jan 17 20:12:42 2020: EM with 272 data points 0 iterations avll -2.064726
5.8 data points per parameter
, Fri Jan 17 20:12:43 2020: GMM converted to Variational GMM
, Fri Jan 17 20:12:51 2020: iteration 1, lowerbound -3.721801
, Fri Jan 17 20:12:51 2020: iteration 2, lowerbound -3.560951
, Fri Jan 17 20:12:51 2020: iteration 3, lowerbound -3.406141
, Fri Jan 17 20:12:51 2020: iteration 4, lowerbound -3.255468
, Fri Jan 17 20:12:52 2020: dropping number of Gaussions to 7
, Fri Jan 17 20:12:52 2020: iteration 5, lowerbound -3.112279
, Fri Jan 17 20:12:52 2020: iteration 6, lowerbound -2.984360
, Fri Jan 17 20:12:52 2020: iteration 7, lowerbound -2.887668
, Fri Jan 17 20:12:52 2020: dropping number of Gaussions to 5
, Fri Jan 17 20:12:52 2020: iteration 8, lowerbound -2.804213
, Fri Jan 17 20:12:52 2020: dropping number of Gaussions to 4
, Fri Jan 17 20:12:52 2020: iteration 9, lowerbound -2.712879
, Fri Jan 17 20:12:52 2020: iteration 10, lowerbound -2.632073
, Fri Jan 17 20:12:52 2020: iteration 11, lowerbound -2.561678
, Fri Jan 17 20:12:52 2020: dropping number of Gaussions to 3
, Fri Jan 17 20:12:52 2020: iteration 12, lowerbound -2.489157
, Fri Jan 17 20:12:52 2020: iteration 13, lowerbound -2.425439
, Fri Jan 17 20:12:52 2020: iteration 14, lowerbound -2.378555
, Fri Jan 17 20:12:52 2020: iteration 15, lowerbound -2.343699
, Fri Jan 17 20:12:52 2020: iteration 16, lowerbound -2.319532
, Fri Jan 17 20:12:52 2020: iteration 17, lowerbound -2.308069
, Fri Jan 17 20:12:52 2020: dropping number of Gaussions to 2
, Fri Jan 17 20:12:52 2020: iteration 18, lowerbound -2.303068
, Fri Jan 17 20:12:52 2020: iteration 19, lowerbound -2.299263
, Fri Jan 17 20:12:52 2020: iteration 20, lowerbound -2.299258
, Fri Jan 17 20:12:52 2020: iteration 21, lowerbound -2.299255
, Fri Jan 17 20:12:52 2020: iteration 22, lowerbound -2.299254
, Fri Jan 17 20:12:52 2020: iteration 23, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 24, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 25, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 26, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 27, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 28, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 29, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 30, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 31, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 32, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 33, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 34, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 35, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 36, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 37, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 38, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 39, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 40, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 41, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 42, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 43, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 44, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 45, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 46, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 47, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 48, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 49, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: iteration 50, lowerbound -2.299253
, Fri Jan 17 20:12:52 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.9549077739861, 178.0450922260139]
β = [95.9549077739861, 178.0450922260139]
m = [2.0002292577753695 53.851987172461286; 4.250300733269909 79.28686694436185]
ν = [97.9549077739861, 180.0450922260139]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948411 -0.008953123827346218; 0.0 0.012748664777409387], [0.1840415554748471 -0.00764404904232761; 0.0 0.00858170516633356]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.9879957033133763
avll from llpg:  -0.9879957033133742
avll direct:     -0.9879957033133743
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9934073691161294
avll from llpg:  -0.9934073691161293
avll direct:     -0.9934073691161291
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.178125    -0.018589     0.00506077   0.0956094    -0.13259      0.103234     -0.19306     -0.137699    -0.0113443    0.0303997    0.174756    -0.0220675   0.156604    -0.0159375    0.0629158     0.0843789   -0.109543     0.0461506    0.150352    -0.0786531    0.135087     -0.00326213   0.0407502    0.209895     0.0241178    0.0265457
  0.0451298    0.106129     0.0145249   -0.0871442    -0.110108     0.134454     -0.0960628    0.0850469   -0.183724     0.0664797   -0.0215017   -0.0643093   0.0440157    0.0575725   -0.119612      0.00875596  -0.12115      0.0792551    0.17347      0.00137818  -0.0217737    -0.0565783    0.184397    -0.132711    -0.0979446   -0.0791414
  0.0867312   -0.0793442   -0.200339    -0.0788079    -0.0466562    0.0801118     0.0705387    0.0297455    0.130145     0.0183717    0.0335699    0.126982    0.0452232   -0.00431526  -0.184285     -0.138068     0.1161       0.0528147    0.0714127    0.0180524    0.0909851    -0.0889877    0.0355527    0.115653    -0.115378     0.0852759
 -0.0501366    0.0823334    0.0520743    0.185649     -0.0356586   -0.113143     -0.0631592    0.027655    -0.00159729   0.104902     0.129686     0.0337851  -0.142671     0.0855785   -0.0758526    -0.102371     0.0795943   -0.0922189    0.028891     0.0510868   -0.0710782    -0.0376428    0.0771124    0.117453     0.0620881    0.155922
  0.16847      0.0487122   -0.101746     0.014286     -0.0842777    0.0775385     0.0151209    0.0728174    0.0629438   -0.0719588   -0.0852872   -0.078236   -0.0426467    0.103531    -0.177337      0.0675713   -0.0326474    0.0509932   -0.0419092    0.0534969   -0.0268192     0.170263     0.134648    -0.218054     0.0170643   -0.015995
 -0.198863     0.0824902    0.211711    -0.0173716     0.0198836    0.251429     -0.0267992   -0.0161184   -0.00314378  -0.0383072   -0.0012583    0.119897    0.0598002   -0.174672    -0.110005     -0.0415965   -0.0342673   -0.0203315   -0.298696     0.0574148    0.0476298     0.0723569   -0.025215    -0.053381    -0.0102074    0.160809
 -0.00529788  -0.136039    -0.0353323    0.194633     -0.0539093   -0.00109293   -0.038164    -0.0488447    0.0112333   -0.0707584    0.0459335   -0.0492269  -0.134551     0.0151089    0.0998517     0.0524428   -0.140255     0.0503119   -0.0532802    0.0946049   -0.0657551    -0.141742     0.0025569    0.00199082  -0.00652809  -0.118246
 -0.0245319    0.0978226    0.109408     0.0671173    -0.00629097  -0.0896058     0.0455808   -0.0898632   -0.0468668   -0.0118822    0.101231     0.12554     0.16071     -0.0160683    0.00518472    0.00234401  -0.0652635   -0.0750886   -0.245034    -0.0494796   -0.000621746   0.0832139    0.0963586   -0.0267752   -0.0316409    0.00325634
 -0.0388148   -0.0227207    0.0106032   -0.0571493     0.00334913   0.112719      0.0981392    0.120777     0.0127879   -0.119046    -0.0385971    0.0283559  -0.0576592    0.00713915  -0.0169148     0.0656381   -0.0307559    0.0579278   -0.0175949   -0.0926815   -0.0972836    -0.100265     0.0531715    0.0618443    0.0677475    0.181352
 -0.0026549   -0.0836717    0.133074     0.0624898     0.0884473    0.0384461     0.0587468   -0.160544     0.0895471    0.00867508  -0.0263056    0.0861346   0.12987      0.0721868   -0.0193539     0.045927    -0.113585     0.00306835  -0.19658      0.0180058   -0.19715       0.0872826   -0.0462151    0.130186    -0.166884     0.011409
 -0.0293468    0.0854706    0.133008     0.0131581    -0.0888823   -0.0715184    -0.0103866    0.128504    -0.0593528   -0.0644886    0.0683504   -0.137455   -0.0137075   -0.0152882   -0.0640092     0.0434235   -0.112902     0.0275203    0.11372     -0.115925    -0.0265729    -0.154269    -0.155294    -0.0547848   -0.00352355  -0.0411111
 -0.0131654    0.0419442   -0.00579618   0.0349709    -0.0799249    0.255815      0.0125868    0.00763631   0.102156     0.0378886   -0.0419819   -0.0272652  -0.0789236   -0.192887    -0.0435213     0.00482166  -0.213721    -0.230026    -0.0247794    0.0289088   -0.0359559     0.0448946   -0.0377636    0.0471501    0.0125306    0.0668099
  0.253938     0.110818     0.132641     0.139258      0.0759962    0.01086      -0.0110413   -0.0830561   -0.00955193  -0.117536    -0.075257     0.203916   -0.0470385    0.192633    -0.0984225     0.152177     0.0305447    0.195019    -0.0152437    0.0643027   -0.0251318     0.0635785   -0.0639833    0.0300603    0.0520527   -0.0687569
  0.116997     0.0659714   -0.0455991   -0.156919      0.016484    -0.0688186    -0.00271133   0.0179261   -0.158928     0.112964     0.110418    -0.0282882  -0.0473388    0.116951     0.113895      0.0841037   -0.092292    -0.0301216    0.0369401   -0.0742428   -0.159071      0.168788    -0.103837     0.0547582    0.0437661   -0.0395629
  0.169795     0.109898    -0.0388336    0.258867     -0.0241539   -0.0831485    -0.199424    -0.105017     0.0735121   -0.150655    -0.17918      0.0748462  -0.0548747   -0.112816     0.0910095     0.0533587   -0.0259341    0.033676     0.104416     0.0961164   -0.0954929    -0.214134    -0.158605     0.0283015    0.115585     0.0565859
 -0.10871      0.146755     0.182651    -0.000577497  -0.241563    -0.100045     -0.0255018    0.0677834    0.0201895    0.0232731    0.183318     0.0261338   0.0154816   -0.137379    -0.0646626     0.00225067   0.0694878    0.116429    -0.0837654    0.0441567   -0.017889     -0.0744207   -0.157831     0.0326757    0.00649567  -0.0283712
 -0.121839     0.0514656   -0.0102143   -0.0653478     0.012049    -0.192343      0.0410423    0.0556528    0.0776596   -0.00453318  -0.0155169   -0.0600855  -0.0370669    0.0743698    0.211603     -0.0347443   -0.0419111    0.017689     0.0375096    0.0392871    0.0191666     0.0444766    0.00157501  -0.00897467  -0.0560256   -0.139745
  0.112311    -0.049129     0.00244057   0.241521     -0.108354     0.0790495     0.0486349    0.111796     0.0887404    0.243992    -0.0174707    0.223919    0.197722     0.133888    -0.0546228    -0.118161    -0.0506232   -0.0351748   -0.0146894    0.0525532    0.0495926    -0.0238138   -0.0819102    0.0343142   -0.0715871    0.140766
  0.159398    -0.0102204    0.0199336   -0.0219747    -0.00187713  -0.00753738   -0.0575735    0.0134445    0.0975502    0.0766091   -0.165256     0.0489815  -0.068606     0.12381     -0.0272352    -0.0161969    0.0648885    0.0101022    0.112387    -0.086455     0.114768      0.0823955    0.0750569   -0.0273536   -0.0228621    0.0474234
 -0.131661    -0.191116     0.0390591    0.111564     -0.220317     0.0285155     0.0681095   -0.107599     0.0889506    0.0324869   -0.150152     0.15354     0.118019     0.0133273    0.0502867     0.0284339   -0.00900834  -0.172076    -0.067492    -0.0939941   -0.00419865    0.0432036    0.11225     -0.170429    -0.0356455   -0.019282
 -0.00791152  -0.0667437    0.0167826   -0.107881     -0.119308    -0.0535319     0.112755     0.203191     0.19074     -0.0150524   -0.0119579    0.0381592   0.136003    -0.149468     0.060683      0.00090242   0.0356642   -0.0106819   -0.00794717  -0.0865449    0.101843      0.0484753    0.161158     0.178477     0.103151    -0.114008
 -0.0869998   -0.101415     0.156926     0.15452      -0.0850033   -0.0147485     0.0772847   -0.0980407    0.0697932   -0.0109182   -0.0725117    0.0180469   0.0406131    0.120881     0.024714      0.135974     0.0948684   -0.0983412    0.0782217    0.0383403    0.0675467    -0.143303    -0.0871725   -0.125793     0.0766819    0.131713
  0.11746      0.0328287   -0.0325057    0.104427     -0.0139234   -0.0631401    -0.261024    -0.136334     0.118328    -0.17519     -0.0589356    0.0120209   0.0902328   -0.0117358   -0.000564717   0.124443     0.0322356    0.0541632   -0.0114714   -0.238397    -0.0470423     0.148313     0.152509    -0.115603    -0.0621254    0.075672
  0.0323156    0.0781328    0.0259443    0.156712     -0.0396393   -0.141882     -0.0208825   -0.109734    -0.0467516    0.0939828    0.0586901    0.0725475   0.144099     0.056294     0.0979603     0.108669     0.0883458   -0.0353384   -0.00604435   0.0127251   -0.126963      0.18314     -0.115595    -0.156675    -0.0974059    0.155861
 -0.0258799   -0.0886718   -0.0350527    0.100846     -0.117895    -0.000756692   0.0270666   -0.102281    -0.0178666    0.127918     0.0387865    0.0491621   0.104185    -0.0922608    0.0262435    -0.0715772   -0.0922172   -0.0706615   -0.0602349    0.152303    -0.138539      0.223261     0.00297442  -0.0679479    0.110798     0.0630332
 -0.0114769   -0.0100252   -0.0557812    0.0377498    -0.0622579   -0.0231412     0.105296    -0.0225198   -0.135836    -0.0649666   -0.0304049    0.102248   -0.0031346   -0.0863805   -0.049456      0.10393     -0.0323588    0.0175158   -0.219008    -0.00735369  -0.103444      0.0265902   -0.073749    -0.118266    -0.216586     0.0430628
 -0.154145    -0.0914867    0.0769669    0.118811      0.025454     0.155314      0.0630552   -0.021028     0.11205     -0.11843      0.119891    -0.0668018   0.129412     0.100769     0.023138      0.0993995   -0.0874049   -0.0366095   -0.102873     0.0665398    0.000168246   0.206116    -0.0967       0.206293     0.111612     0.0593858
 -0.168301     0.104561     0.0931895    0.0268274    -0.0600985   -0.0398969     0.0493549   -0.0818831    0.028934     0.0514298   -0.0206933   -0.0611765  -0.00376469  -0.0403283   -0.18933      -0.240925     0.303211    -0.130559    -0.0496589   -0.0116378    0.0964218    -0.0493722   -0.0505118   -0.0454077    0.123319    -0.0164511
 -0.264805     0.00357733  -0.0113029   -0.104653      0.00181032  -0.188371      0.0261315    0.0529951    0.0747767    0.00201815   0.00507668   0.106003    0.119358     0.0554693   -0.0712821    -0.00477301   0.194658     0.00682866  -0.115072    -0.00179084   0.0450187    -0.139188    -0.0342746   -0.254025     0.0189278   -0.0469945
 -0.0723386    0.0362707    0.0328998    0.0581628    -0.125803     0.105655      0.0222342   -0.0311608   -0.202128     0.0126003   -0.178908    -0.0596803  -0.00297915   0.112755    -0.0264575    -0.015628     0.0384138    0.077161     0.186686    -0.0132529    0.0881225    -0.033163     0.0134214    0.0316103   -0.048843     0.00715275
  0.0083652   -0.100419    -0.0342531   -0.0855709    -0.202681     0.0947878     0.00836697   0.00580792  -0.124153    -0.0339208    0.0594496   -0.0742163  -0.198144    -0.0300272   -0.00406315   -0.227899    -0.0437984   -0.151038     0.0156959    0.0149064    0.062173     -0.057622    -0.113115     0.046209     0.0429676   -0.102344
 -0.00180014   0.00525306  -0.0116192   -0.0324118    -0.0936664   -0.0582493     0.0635445   -0.0890219   -0.00444444   0.0430873   -0.1536      -0.0649513  -0.133112     0.0254459    0.00357065    0.0816275    0.138186    -0.0118756    0.176187     0.030634    -0.0621032     0.015259    -0.0452645   -0.0212709   -0.00120556   0.106318kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3858190982579235
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.385862
[ Info: iteration 2, average log likelihood -1.385772
[ Info: iteration 3, average log likelihood -1.384121
[ Info: iteration 4, average log likelihood -1.372112
[ Info: iteration 5, average log likelihood -1.353451
[ Info: iteration 6, average log likelihood -1.346514
[ Info: iteration 7, average log likelihood -1.344168
[ Info: iteration 8, average log likelihood -1.343126
[ Info: iteration 9, average log likelihood -1.342583
[ Info: iteration 10, average log likelihood -1.342318
[ Info: iteration 11, average log likelihood -1.342201
[ Info: iteration 12, average log likelihood -1.342142
[ Info: iteration 13, average log likelihood -1.342101
[ Info: iteration 14, average log likelihood -1.342061
[ Info: iteration 15, average log likelihood -1.342013
[ Info: iteration 16, average log likelihood -1.341966
[ Info: iteration 17, average log likelihood -1.341927
[ Info: iteration 18, average log likelihood -1.341901
[ Info: iteration 19, average log likelihood -1.341885
[ Info: iteration 20, average log likelihood -1.341876
[ Info: iteration 21, average log likelihood -1.341870
[ Info: iteration 22, average log likelihood -1.341868
[ Info: iteration 23, average log likelihood -1.341866
[ Info: iteration 24, average log likelihood -1.341865
[ Info: iteration 25, average log likelihood -1.341865
[ Info: iteration 26, average log likelihood -1.341865
[ Info: iteration 27, average log likelihood -1.341865
[ Info: iteration 28, average log likelihood -1.341865
[ Info: iteration 29, average log likelihood -1.341864
[ Info: iteration 30, average log likelihood -1.341864
[ Info: iteration 31, average log likelihood -1.341864
[ Info: iteration 32, average log likelihood -1.341864
[ Info: iteration 33, average log likelihood -1.341864
[ Info: iteration 34, average log likelihood -1.341864
[ Info: iteration 35, average log likelihood -1.341864
[ Info: iteration 36, average log likelihood -1.341864
[ Info: iteration 37, average log likelihood -1.341864
[ Info: iteration 38, average log likelihood -1.341864
[ Info: iteration 39, average log likelihood -1.341864
[ Info: iteration 40, average log likelihood -1.341864
[ Info: iteration 41, average log likelihood -1.341864
[ Info: iteration 42, average log likelihood -1.341864
[ Info: iteration 43, average log likelihood -1.341864
[ Info: iteration 44, average log likelihood -1.341864
[ Info: iteration 45, average log likelihood -1.341864
[ Info: iteration 46, average log likelihood -1.341864
[ Info: iteration 47, average log likelihood -1.341864
[ Info: iteration 48, average log likelihood -1.341864
[ Info: iteration 49, average log likelihood -1.341864
[ Info: iteration 50, average log likelihood -1.341864
┌ Info: EM with 100000 data points 50 iterations avll -1.341864
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3858624803355013
│     -1.3857717828868656
│      ⋮
└     -1.3418643760789741
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.341991
[ Info: iteration 2, average log likelihood -1.341848
[ Info: iteration 3, average log likelihood -1.340961
[ Info: iteration 4, average log likelihood -1.334833
[ Info: iteration 5, average log likelihood -1.323963
[ Info: iteration 6, average log likelihood -1.315557
[ Info: iteration 7, average log likelihood -1.310242
[ Info: iteration 8, average log likelihood -1.307470
[ Info: iteration 9, average log likelihood -1.305335
[ Info: iteration 10, average log likelihood -1.303624
[ Info: iteration 11, average log likelihood -1.302475
[ Info: iteration 12, average log likelihood -1.301761
[ Info: iteration 13, average log likelihood -1.301293
[ Info: iteration 14, average log likelihood -1.300961
[ Info: iteration 15, average log likelihood -1.300713
[ Info: iteration 16, average log likelihood -1.300517
[ Info: iteration 17, average log likelihood -1.300349
[ Info: iteration 18, average log likelihood -1.300197
[ Info: iteration 19, average log likelihood -1.300057
[ Info: iteration 20, average log likelihood -1.299929
[ Info: iteration 21, average log likelihood -1.299810
[ Info: iteration 22, average log likelihood -1.299698
[ Info: iteration 23, average log likelihood -1.299585
[ Info: iteration 24, average log likelihood -1.299467
[ Info: iteration 25, average log likelihood -1.299340
[ Info: iteration 26, average log likelihood -1.299203
[ Info: iteration 27, average log likelihood -1.299059
[ Info: iteration 28, average log likelihood -1.298917
[ Info: iteration 29, average log likelihood -1.298786
[ Info: iteration 30, average log likelihood -1.298668
[ Info: iteration 31, average log likelihood -1.298558
[ Info: iteration 32, average log likelihood -1.298452
[ Info: iteration 33, average log likelihood -1.298346
[ Info: iteration 34, average log likelihood -1.298237
[ Info: iteration 35, average log likelihood -1.298121
[ Info: iteration 36, average log likelihood -1.297998
[ Info: iteration 37, average log likelihood -1.297867
[ Info: iteration 38, average log likelihood -1.297728
[ Info: iteration 39, average log likelihood -1.297583
[ Info: iteration 40, average log likelihood -1.297435
[ Info: iteration 41, average log likelihood -1.297289
[ Info: iteration 42, average log likelihood -1.297148
[ Info: iteration 43, average log likelihood -1.297018
[ Info: iteration 44, average log likelihood -1.296904
[ Info: iteration 45, average log likelihood -1.296809
[ Info: iteration 46, average log likelihood -1.296736
[ Info: iteration 47, average log likelihood -1.296679
[ Info: iteration 48, average log likelihood -1.296636
[ Info: iteration 49, average log likelihood -1.296600
[ Info: iteration 50, average log likelihood -1.296569
┌ Info: EM with 100000 data points 50 iterations avll -1.296569
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3419914521445502
│     -1.3418483197513784
│      ⋮
└     -1.296569467528098
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.296709
[ Info: iteration 2, average log likelihood -1.296508
[ Info: iteration 3, average log likelihood -1.295822
[ Info: iteration 4, average log likelihood -1.290428
[ Info: iteration 5, average log likelihood -1.275846
[ Info: iteration 6, average log likelihood -1.262851
[ Info: iteration 7, average log likelihood -1.254763
[ Info: iteration 8, average log likelihood -1.251073
[ Info: iteration 9, average log likelihood -1.249452
[ Info: iteration 10, average log likelihood -1.248596
[ Info: iteration 11, average log likelihood -1.248078
[ Info: iteration 12, average log likelihood -1.247733
[ Info: iteration 13, average log likelihood -1.247478
[ Info: iteration 14, average log likelihood -1.247265
[ Info: iteration 15, average log likelihood -1.247061
[ Info: iteration 16, average log likelihood -1.246839
[ Info: iteration 17, average log likelihood -1.246571
[ Info: iteration 18, average log likelihood -1.246222
[ Info: iteration 19, average log likelihood -1.245754
[ Info: iteration 20, average log likelihood -1.245109
[ Info: iteration 21, average log likelihood -1.243980
[ Info: iteration 22, average log likelihood -1.241478
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.236947
[ Info: iteration 24, average log likelihood -1.256267
[ Info: iteration 25, average log likelihood -1.251660
[ Info: iteration 26, average log likelihood -1.248199
[ Info: iteration 27, average log likelihood -1.246753
[ Info: iteration 28, average log likelihood -1.245567
[ Info: iteration 29, average log likelihood -1.244050
[ Info: iteration 30, average log likelihood -1.241894
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.238535
[ Info: iteration 32, average log likelihood -1.255685
[ Info: iteration 33, average log likelihood -1.251014
[ Info: iteration 34, average log likelihood -1.247722
[ Info: iteration 35, average log likelihood -1.246458
[ Info: iteration 36, average log likelihood -1.245373
[ Info: iteration 37, average log likelihood -1.243838
[ Info: iteration 38, average log likelihood -1.241855
[ Info: iteration 39, average log likelihood -1.239200
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.235191
[ Info: iteration 41, average log likelihood -1.254460
[ Info: iteration 42, average log likelihood -1.249749
[ Info: iteration 43, average log likelihood -1.246320
[ Info: iteration 44, average log likelihood -1.244947
[ Info: iteration 45, average log likelihood -1.243691
[ Info: iteration 46, average log likelihood -1.241925
[ Info: iteration 47, average log likelihood -1.239823
[ Info: iteration 48, average log likelihood -1.237060
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.232942
[ Info: iteration 50, average log likelihood -1.252872
┌ Info: EM with 100000 data points 50 iterations avll -1.252872
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2967090837863726
│     -1.2965078563968118
│      ⋮
└     -1.2528719405717637
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.248487
[ Info: iteration 2, average log likelihood -1.245070
[ Info: iteration 3, average log likelihood -1.242477
[ Info: iteration 4, average log likelihood -1.227775
[ Info: iteration 5, average log likelihood -1.191234
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.159862
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.158058
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.164046
[ Info: iteration 9, average log likelihood -1.156962
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.137616
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.158625
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.154589
[ Info: iteration 13, average log likelihood -1.151985
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.133467
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.158023
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.154082
[ Info: iteration 17, average log likelihood -1.152097
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.133508
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.157949
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.154080
[ Info: iteration 21, average log likelihood -1.152230
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.133648
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.157919
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.154108
[ Info: iteration 25, average log likelihood -1.152351
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.133819
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.157791
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.153977
[ Info: iteration 29, average log likelihood -1.152231
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.133669
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.138505
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.158707
[ Info: iteration 33, average log likelihood -1.153783
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.135516
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.141453
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.158344
[ Info: iteration 37, average log likelihood -1.153617
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.135463
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.141628
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.158020
[ Info: iteration 41, average log likelihood -1.153497
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.135721
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.142343
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.140776
[ Info: iteration 45, average log likelihood -1.159912
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.138994
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.145549
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.145127
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.142649
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.145524
┌ Info: EM with 100000 data points 50 iterations avll -1.145524
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2484870244411777
│     -1.2450698995598908
│      ⋮
└     -1.145524421265985
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.149073
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.138001
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.130304
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     13
│     15
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.094660
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.112389
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.070580
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.084772
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.073691
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     15
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.091622
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.066110
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.086975
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.083326
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.083867
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.038173
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.099536
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.076173
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.076826
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.055843
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.085728
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.078008
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.090213
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.052873
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.092863
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.079734
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.080536
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.053071
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     13
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.088854
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.072885
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     13
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.087629
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.062525
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.090740
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.069506
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     16
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.086634
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.058344
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.094277
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.064482
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     13
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.078995
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.062329
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     11
│     12
│     15
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.077742
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.082311
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.090913
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.050990
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│      ⋮
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.080065
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     13
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.077181
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     13
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.076438
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.056258
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.097000
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.071047
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.084418
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.060012
┌ Info: EM with 100000 data points 50 iterations avll -1.060012
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1490727555640816
│     -1.1380013505288884
│      ⋮
└     -1.0600119990125823
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3858190982579235
│     -1.3858624803355013
│     -1.3857717828868656
│     -1.3841214627289014
│      ⋮
│     -1.0710468110413018
│     -1.084418350222753
└     -1.0600119990125823
32×26 Array{Float64,2}:
 -0.0496928   -0.0211388    -0.0584115   -0.00985     -0.0579891    -0.0427816    0.0969428   -0.0163576   -0.134353   -0.0950369    -0.0299762    0.100478    -0.00473499  -0.094441     -0.0789788    0.0923319   -0.00308012   0.0149405   -0.198785    -0.00865359  -0.113935    0.0263883  -0.0748902    -0.126662    -0.203358     0.0323676
  0.0342885    0.0778708     0.0370742    0.154416    -0.0384842    -0.132026    -0.0243554   -0.115467    -0.0547269   0.093607      0.0262772    0.0900661    0.143986     0.0814339     0.114969     0.0637439    0.0901558   -0.0371766    0.0115038    0.00804519  -0.160515    0.181402   -0.116268     -0.144148    -0.0883044    0.172528
  0.288516     0.0712842     0.183398    -0.0200671   -0.198421      0.213617    -0.0337473    0.04194     -0.0450718  -0.0379177     0.214689     0.0425307    0.0556083   -0.1618       -0.271779     0.136039    -0.284881    -0.0249847   -0.292402    -0.0891919   -1.19942     0.290778   -0.00687203    0.083112     0.0159292    0.143182
 -0.401096     0.0867211     0.207348    -0.0164814    0.0728567     0.257643    -0.0332119   -0.0653747   -0.0155597  -0.0379556    -0.0445753    0.158777     0.0536393   -0.199447     -0.00459011  -0.0826593    0.0689437   -0.0106219   -0.293913     0.137138     0.453106    0.0460567  -0.0288854    -0.104781    -0.0284122    0.173883
 -0.271264     0.000304381  -0.00032583  -0.131058     0.00074665   -0.188813     0.0317209    0.0657369    0.0791414   0.0123278    -0.00612951   0.0684505    0.126711     0.061292     -0.0632152   -0.00647048   0.232015     0.0037351   -0.0887635    0.0230172    0.0459029  -0.136076   -0.0531568    -0.284814     0.00712671  -0.0555762
  0.00365869  -0.0234585    -0.00885073   0.0513332   -0.0406363     0.128277     0.0358305    0.0529521    0.0621605  -0.0899845     0.015428    -0.0691884    0.0483125    0.121216     -0.0814025    0.084624    -0.0544424    2.37117e-5  -0.0858926    0.0535958   -0.012391    0.196702    0.0127877     0.00597715   0.065692     0.0150143
 -0.0131973    0.101223      0.10578      0.0332875   -0.0140396    -0.0895704    0.012155    -0.122115    -0.0455128   0.0105468     0.150918     0.156599     0.185613    -0.01014       0.00627047   0.00134329  -0.0456263   -0.0768041   -0.223756    -0.0514566   -0.0294516   0.0658725   0.0672339    -0.0469619   -0.0321309    0.000979176
  0.169362     0.14736      -0.0407449    0.240115    -0.0272293    -0.0866352   -0.191982    -0.123161     0.0672157  -0.149245     -0.1845       0.0765967   -0.0543004   -0.12988       0.094035     0.05306     -0.0215957    0.0205108    0.117421     0.099342    -0.0807811  -0.197265   -0.152267      0.0711167    0.115221     0.0475565
  0.00651979  -0.124192     -0.0227358   -0.0990887   -0.0929501    -0.0758688    0.131503     0.199645     0.156883   -0.0471663     0.0177774   -0.0494242    0.143947    -0.140729      0.0437843   -0.0171003   -0.0882498   -0.028515     0.0115658   -0.10285      0.0889621   0.0709922   0.0641361     0.169271     0.103115    -1.00734
 -0.0107929    0.0206226     0.0440106   -0.108484    -0.0507382    -0.042591     0.0911192    0.223203     0.232377    0.0201249    -0.0248005    0.101047     0.0987495   -0.156143      0.0616051   -0.0055328    0.096843     0.0136562   -0.0198265   -0.0492376    0.113492    0.0108595   0.227066      0.174859     0.10191      0.670101
  0.436485     0.065839     -0.10039     -0.257302    -0.418758     -0.0600701   -0.00255556   0.108678    -0.121468    0.112967      0.107013    -0.0217018    0.0105437    0.160044      0.115031     0.0974947   -0.0936627   -0.0220586    0.135846    -0.0767386   -0.14472     0.266764    0.0330148     0.0886062    0.0418878    0.060518
 -0.121314     0.0658043     0.0656469   -0.0351317    0.589384     -0.107921     0.00272696  -0.0818903   -0.174358    0.112649      0.114212    -0.024759    -0.0927368    0.0596764     0.113048     0.10014     -0.0788348   -0.0244181   -0.0414355   -0.068511    -0.185531    0.0988054  -0.238318      0.00885536   0.0166464   -0.0901343
 -0.120222     0.0579633    -0.013472    -0.0739674    0.000267319  -0.185777     0.0414001    0.0552184    0.074781   -0.00520574   -0.0140404   -0.117738    -0.0825702    0.0605449     0.227498    -0.0188871   -0.0389988   -0.00435603   0.04188      0.0616938    0.0110933   0.0397361   0.000585049  -0.103836    -0.0646533   -0.168659
  0.0996233   -0.0855815    -0.196952    -0.101979    -0.0445263     0.0838937    0.07284      0.0080414    0.133398    0.0378237     0.044051     0.117519     0.0424878   -0.00358156   -0.196185    -0.150559     0.139071     0.0420085    0.0513379    0.0169213    0.0953452  -0.10784     0.0322476     0.124717    -0.177008     0.0835799
  0.184105    -0.0117163     0.0345809   -0.0200854   -0.0286228    -0.00242123  -0.06037      0.0104074    0.0930783   0.0699151    -0.244993     0.0507068   -0.093851     0.187955     -0.0261308   -0.0435969    0.162032     0.0119834    0.119478    -0.0697448    0.110372    0.0986301   0.108438     -0.0104896   -0.0221716    0.102134
 -0.0513009   -0.0104616    -0.0399569   -0.0267031   -0.0566154    -0.0937592    0.0123027    0.0314245    0.0964498   0.0394172     0.0324765    0.0268533   -0.0734532    0.0255742     0.0976935   -0.00796763  -0.0629452    0.0173533    0.0284558   -0.0434929    0.0609269   0.0631152  -0.0210633     0.00359876  -0.0172174   -0.0404712
  0.00177167   0.0545285     0.0722406   -0.00950064  -0.0996239    -0.0542629    0.0411507    0.0163798   -0.0344719   0.00198044   -0.0416847   -0.101462    -0.0765905    0.00594075   -0.0208518    0.0538355   -0.0316848    0.0123236    0.136215    -0.0310868   -0.0423932  -0.0713573  -0.0698909    -0.0789012    0.0108063    0.0279056
  0.00711123   0.0352396     0.0348687    0.111892    -0.103231      0.0241424   -0.110581    -0.0481905   -0.0864969   0.0358936     0.0183649   -0.034137    -0.00944078   0.0476462    -0.00709437  -0.019491     0.0158102   -0.00657174   0.0950756    0.00365205   0.0414068  -0.0507064   0.0337541     0.097504     0.0166385    0.0747991
 -0.031435     0.0733211     0.0405931    0.0480952   -0.0455997    -0.0535331   -0.091753    -0.106008     0.0670489  -0.0120123    -0.0302784   -0.0344226    0.0622779   -0.0119902    -0.088135    -0.071004     0.177089    -0.0431249   -0.0287852   -0.0949569    0.0330188   0.0400988   0.0499016    -0.0857845    0.06827      0.0285111
 -0.0166092   -0.105976     -0.0320154    0.133297    -0.098647     -0.00570514  -0.0238694   -0.075466    -0.0200633   0.0186518     0.0512406    0.00221857  -0.00240299  -0.0418081     0.0626561   -0.0104565   -0.124141    -0.0180278   -0.0325383    0.104208    -0.0809146   0.0619787   0.0116761    -0.0272245    0.0384391   -0.0166334
 -0.0491688    0.153596      0.131845     0.00138871  -0.202674     -0.0679349   -0.0575858    0.128601     0.0192141   0.0148409     0.174977     0.0216465   -0.0488738   -0.10885      -0.087378    -0.0418728   -0.0186917    0.256399    -0.0773388    0.0885669    0.0039276  -0.617244   -0.152826      0.0461927    0.0161347   -0.0275336
 -0.124285     0.139156      0.2235       0.00110952  -0.212579     -0.14184     -0.0255855   -0.0468067    0.0360664   0.0302479     0.191087     0.0785402    0.0736182   -0.135507     -0.063439     0.0557041    0.178407    -0.0749002   -0.0902319   -0.0144486   -0.0448614   0.328436   -0.200299      0.0324262   -0.0109722   -0.023199
 -0.0892184   -0.0607214     0.155269     0.155253    -0.0840451    -0.0149476    0.0694776   -0.101142     0.0355513  -0.000689715  -0.0756518    0.0154737    0.0020722    0.0958409     0.0295257    0.139495     0.11951     -0.0905719    0.0655339    0.0339943    0.065472   -0.11155    -0.0832122    -0.121254     0.0619142    0.159309
  0.101556    -0.0529432    -0.0227442    0.24066     -0.11054       0.0826469    0.0510372    0.108554     0.08794     0.195076     -0.0229541    0.230634     0.191731     0.127619     -0.0530444   -0.0940037   -0.0396858    0.0112503   -0.0303068    0.0526093    0.0500132   0.0064016  -0.0753908     0.0327418   -0.0860325    0.139058
 -0.127427    -0.199489      0.0273692    0.110685    -0.197986      0.0268627    0.0668779   -0.0973377    0.0427485   0.0251184    -0.161055     0.151662     0.136272     0.0232995     0.0540892    0.0227336   -0.00671632  -0.166407    -0.0945234   -0.0731944    0.0161465   0.059659    0.112533     -0.165991    -0.0107025   -0.0180234
 -0.00380595  -0.0836225     0.135481     0.0621972    0.090932      0.0356529    0.0700813   -0.202264     0.0861448  -0.0249924    -0.0271041    0.0663207    0.12701      0.0438618    -0.00694546   0.017161    -0.113045     0.0424143   -0.194092     0.0297458   -0.193865    0.0859481  -0.0439957     0.128728    -0.152195     0.0109737
 -0.0843293   -0.197987      0.0102844    0.0282474   -0.0947938     0.218623     0.0441042   -0.0264458   -0.0943195   0.0355444     0.0176996   -0.0123489   -0.147673    -0.134369     -0.045314     0.0258966   -0.176994    -0.203191     0.00400121   0.0364154   -0.0453201   0.0377329  -0.0656591     0.0445444   -0.00913942  -0.0784356
 -0.00469602   0.180568     -0.004806     0.0360305   -0.0805378     0.263815    -0.0197434    0.00065141   0.164782    0.0367426    -0.0823364   -0.0292869   -0.0657751   -0.207045     -0.0480475    0.0100436   -0.226733    -0.236947    -0.0472519    0.0262078   -0.0316512   0.0451565  -0.0226206     0.0484661    0.0196198    0.149794
  0.238968     0.0842904     0.129716     0.135154     0.0764315    -0.00012759  -0.00206502  -0.0689888   -0.0375621  -0.0895471    -0.0703453    0.19359     -0.0526032    0.205106     -0.0758826    0.161904     0.0299738    0.187433    -0.011392     0.0371872   -0.032236    0.0592219  -0.0608325     0.031406     0.0562365   -0.0832594
  0.0262395   -0.005575     -0.013715    -0.091232    -0.15939       0.11378     -0.0277255    0.0551073   -0.149789    0.0313457     0.0247923   -0.0681256   -0.0741521    0.000520033  -0.064174    -0.12835     -0.0824108   -0.0349996    0.0723782    0.0123223    0.0294552  -0.0617904   0.0240923    -0.0412062   -0.0119678   -0.0721018
 -0.0588895   -0.0905992     0.0301855    0.0342633   -0.0813778     0.0962706   -0.0221283    0.0284595    0.115512   -0.0506849    -0.0866947    0.0970573    0.0282531   -0.0565864    -0.00684689  -0.0485717   -0.0163696   -0.0507089   -0.033648    -0.106949    -0.061944    0.0141471   0.0633826    -0.0475227   -0.00951335   0.0699108
 -0.0368286   -0.00217062    0.00793972  -0.0702138    0.0155817     0.116585     0.0933529    0.124661    -0.0107671  -0.125523     -0.0318259    0.0180191   -0.0647362    0.0352518    -0.0367941    0.0732793   -0.0303633    0.0745713   -0.0186633   -0.0814445   -0.141615   -0.0968756   0.0375911     0.0740681    0.128566     0.20189[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.082285
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.046079
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     16
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.072215
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.051281
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.076070
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.038545
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.079437
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.045997
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.072804
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.046292
┌ Info: EM with 100000 data points 10 iterations avll -1.046292
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.719756e+05
      1       6.388770e+05      -2.330986e+05 |       32
      2       6.118382e+05      -2.703882e+04 |       32
      3       5.959255e+05      -1.591265e+04 |       32
      4       5.877120e+05      -8.213488e+03 |       32
      5       5.836884e+05      -4.023663e+03 |       32
      6       5.812859e+05      -2.402459e+03 |       32
      7       5.793753e+05      -1.910667e+03 |       32
      8       5.779688e+05      -1.406477e+03 |       32
      9       5.771096e+05      -8.592224e+02 |       32
     10       5.765843e+05      -5.252872e+02 |       32
     11       5.761992e+05      -3.851102e+02 |       32
     12       5.758912e+05      -3.079721e+02 |       32
     13       5.756196e+05      -2.716066e+02 |       32
     14       5.753329e+05      -2.866898e+02 |       32
     15       5.750917e+05      -2.411835e+02 |       32
     16       5.748866e+05      -2.050836e+02 |       32
     17       5.747288e+05      -1.578430e+02 |       32
     18       5.745850e+05      -1.438194e+02 |       32
     19       5.744494e+05      -1.355191e+02 |       32
     20       5.742993e+05      -1.501007e+02 |       32
     21       5.741477e+05      -1.516631e+02 |       32
     22       5.740046e+05      -1.430889e+02 |       32
     23       5.738397e+05      -1.648468e+02 |       32
     24       5.735991e+05      -2.406824e+02 |       32
     25       5.733080e+05      -2.910825e+02 |       32
     26       5.730351e+05      -2.728750e+02 |       32
     27       5.728162e+05      -2.189062e+02 |       32
     28       5.726315e+05      -1.847023e+02 |       32
     29       5.725142e+05      -1.173086e+02 |       32
     30       5.724510e+05      -6.313137e+01 |       32
     31       5.724199e+05      -3.115301e+01 |       32
     32       5.724014e+05      -1.847660e+01 |       32
     33       5.723914e+05      -1.003449e+01 |       29
     34       5.723858e+05      -5.564723e+00 |       27
     35       5.723819e+05      -3.883393e+00 |       25
     36       5.723785e+05      -3.431416e+00 |       23
     37       5.723771e+05      -1.401041e+00 |       20
     38       5.723756e+05      -1.528957e+00 |       17
     39       5.723746e+05      -9.430503e-01 |       12
     40       5.723742e+05      -4.523436e-01 |       11
     41       5.723737e+05      -5.111341e-01 |       11
     42       5.723733e+05      -3.459896e-01 |        9
     43       5.723730e+05      -2.839358e-01 |        8
     44       5.723729e+05      -1.891847e-01 |        7
     45       5.723726e+05      -2.238984e-01 |        6
     46       5.723724e+05      -2.017888e-01 |        4
     47       5.723724e+05      -4.318443e-02 |        0
     48       5.723724e+05       0.000000e+00 |        0
K-means converged with 48 iterations (objv = 572372.3812328889)
┌ Info: K-means with 32000 data points using 48 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.291830
[ Info: iteration 2, average log likelihood -1.262451
[ Info: iteration 3, average log likelihood -1.232681
[ Info: iteration 4, average log likelihood -1.193530
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.143355
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      8
│      9
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.089548
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.070360
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     16
│     18
│     19
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.088428
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.112820
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.056279
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      9
│     13
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.055502
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     16
│     18
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.081712
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.075434
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.041834
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│      9
│     13
│     20
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.040887
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      7
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.081626
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.070971
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      8
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.019228
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│      9
│     13
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.044605
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     16
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.083839
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.067179
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      6
│      7
│      8
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.001793
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.116789
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.069165
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     24
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.041997
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│      8
│     13
│     19
│     20
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.038292
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.103149
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      7
│     16
│     18
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.040431
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.080233
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│      8
│     13
│     19
│     20
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.018723
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      9
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.091471
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│     16
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.067760
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.060401
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      6
│      7
│      8
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.006726
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.117827
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     16
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.055301
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.051190
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      8
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.004096
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.119027
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      7
│     16
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.052707
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.065256
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      6
│      8
│     13
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.009820
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.101817
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     16
│     18
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.060014
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.062124
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      6
│      7
│      8
│      ⋮
│     20
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.007645
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.093794
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     16
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.058174
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      7
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.057378
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│      8
│     13
│     19
│     20
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.026245
┌ Info: EM with 100000 data points 50 iterations avll -1.026245
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0315517    -0.142014    -0.0359242     0.172439    -0.0568438   -0.00983869   -0.0508137   -0.056221     -9.2636e-5   -0.0891946    0.0380377   -0.0544157   -0.142156     0.0177827    0.0944877    0.0521828   -0.148465     0.0530235   -0.0518852    0.097561    -0.0667336   -0.107191   -0.00977368   0.017936   -0.0183147   -0.108436
  0.154344      0.0658499   -0.0163699    -0.14557      0.0881433   -0.0837458     0.00030357   0.0137988    -0.148501     0.112745     0.110642    -0.0235242   -0.0428794    0.110315     0.114347     0.0978431   -0.0865926   -0.0229245    0.0460591   -0.0721759   -0.164344     0.180875   -0.104805     0.0485322   0.029142    -0.0152641
  0.107888      0.0334051   -0.0223182     0.0907874   -0.014883    -0.0633233    -0.249734    -0.142571      0.112373    -0.162135    -0.0528659   -0.00325458   0.139269     0.0148054    0.00127419   0.121055     0.02654      0.0554916   -0.0101211   -0.232545    -0.0211644    0.120452    0.126083    -0.113656   -0.0824463    0.0929656
 -0.121812     -0.212305     0.0200197     0.112134    -0.203814     0.0281995     0.0659856   -0.0970311     0.0420216    0.0282148   -0.163659     0.149903     0.132606     0.0151873    0.0531631    0.0164652   -6.25154e-5  -0.16078     -0.100725    -0.0729826    0.0312446    0.0594184   0.139451    -0.169024   -0.012976    -0.013026
  0.546119      0.0631187    0.133488      0.0244888   -0.0319829    0.0411826    -0.0259103   -0.114165     -0.0513573    0.0183049    0.0110154    0.0435146    0.104354     0.00445768   0.105383     0.0871621    0.0551117   -0.0415017   -0.170814    -0.0352015   -0.278817     0.178069   -0.0541797   -0.139514   -0.0597913    0.150448
 -0.0388803     0.0837634    0.0525496     0.184672    -0.0464935   -0.0969131    -0.0654771    0.0244399    -0.0103693    0.104209     0.108177     0.0106618   -0.145024     0.0935757   -0.0770399   -0.10019      0.0834048   -0.115875     0.0122375    0.0590801   -0.0750149   -0.113596    0.0849282    0.114818    0.0835161    0.154255
 -0.472023      0.0785476    0.191183     -0.0194422    0.00556459   0.268333     -0.0349441   -0.0260983    -0.0244698   -0.0261322    0.0234699    0.127929     0.0330162   -0.244549    -0.0879444   -0.0970131   -0.0318279   -0.0189236   -0.276197     0.108504     0.189529     0.0720551  -0.0324209   -0.051496   -0.0121754    0.160381
 -0.0305544    -0.0922742   -0.0285331     0.0942184   -0.123926    -0.000489399   0.0415414   -0.0916364    -0.0381365    0.139831     0.0382162    0.0580332    0.121314    -0.103674     0.0336435   -0.0716463   -0.0904421   -0.0990278   -0.049554     0.143094    -0.131236     0.232261    0.00739188  -0.0973312   0.102175     0.0627487
 -0.0649878     0.0275451    0.0401032     0.0573485   -0.118091     0.0888292    -0.0290986   -0.00845766   -0.20513      0.00340224  -0.180693    -0.0805125   -0.010024     0.0529021   -0.00770331  -0.038943     0.0362135    0.0423399    0.160421     0.0034896    0.0899062   -0.0224202  -0.0179007    0.0263496  -0.0397159    0.00195957
 -0.0122318    -0.0440768    0.0196193    -0.103467    -0.0754089   -0.0596904     0.112383     0.211233      0.198824    -0.0123096   -0.00243358   0.0298896    0.115036    -0.150455     0.0530974   -0.0103156    0.0122248   -0.00777826  -0.00879363  -0.0651915    0.101355     0.0422126   0.152244     0.171776    0.102063    -0.124552
  0.0340747     0.0692893    0.104508      0.0378367   -0.194075    -0.0105828    -0.133254    -0.0611299     0.0019003    0.00646286   0.184409     0.0204396    0.083121    -0.0868317   -0.00589067   0.0520349   -0.0103123    0.0721325    0.0231031   -0.0140468    0.0563293   -0.0687026  -0.0820631    0.103219    0.021783     0.00543692
 -0.0385707    -0.016153     0.0133402    -0.0512757    0.00552939   0.101914      0.0723308    0.0987383     0.00783499  -0.110106    -0.0381228    0.0332039   -0.0466838    0.0222327   -0.0239524    0.0576027   -0.023073     0.0548322   -0.0235061   -0.0836394   -0.129932    -0.0730387   0.0344734    0.056525    0.110987     0.184555
 -0.120293      0.0420402   -0.012837     -0.0715609   -0.00274472  -0.192173      0.0409044    0.0499808     0.0800935   -0.0042892   -0.0196419   -0.087464    -0.0821978    0.0571495    0.21984     -0.0155594   -0.0434851    0.00218682   0.0390668    0.0376168    0.0201403    0.04383    -0.00179918  -0.0966059  -0.0648271   -0.143409
  0.0519629     0.0848492    0.0114832    -0.0828481   -0.112903     0.129821     -0.0622914    0.0816052    -0.181009     0.0511445   -0.0188822   -0.0658418    0.0313721    0.0281803   -0.120278    -0.0121207   -0.121866     0.0758226    0.152689     0.0147222   -0.0189129   -0.0647382   0.17749     -0.128784   -0.0675731   -0.0744244
  0.166413      0.0647311   -0.0937153     0.0163972   -0.116043     0.0833734     0.0015894    0.0711214     0.0465347   -0.0529509   -0.074753    -0.0622263   -0.0401631    0.158077    -0.167806     0.0775888   -0.0192267    0.0270106   -0.0429683    0.0332773   -0.0285716    0.179383    0.123198    -0.218916    0.0123918   -0.0111337
  0.00577437   -0.0864803    0.107867      0.0473178    0.0365704    0.0396419     0.0822051   -0.172305      0.0538882   -0.0578694    0.00244385   0.0500915    0.0835733    0.0313274   -0.0188574   -0.0274796   -0.0966392    0.00692339  -0.191624     0.0105339   -0.182252     0.0577223  -0.0822059    0.115819   -0.107925     0.00092002
 -0.273563      0.00128836  -0.00218335   -0.132697     0.00106166  -0.189032      0.0347438    0.063394      0.0783933    0.0148438   -0.00775328   0.0699784    0.126999     0.061727    -0.062057    -0.00732434   0.230989     0.0033852   -0.0908602    0.0263079    0.0469453   -0.135808   -0.05485     -0.288358    0.00982259  -0.055838
  0.285659      0.0943396    0.12155       0.126376     0.0605284   -0.00136963    0.00662346  -0.0753961    -0.0318127   -0.107958    -0.0712354    0.192215    -0.0562344    0.206224    -0.0876668    0.144048     0.0307272    0.185669    -0.0112843    0.0607741   -0.0227611    0.0626484  -0.0769424    0.0623121   0.0674206   -0.127578
  0.000267916   0.0105635   -0.0249516    -0.0350917   -0.113749    -0.0485845     0.0768865   -0.0862893    -0.00540048   0.0555864   -0.153836    -0.0534554   -0.178726     0.0318971    0.0210015    0.058375     0.0969871   -0.00193507   0.152736     0.0364935   -0.0605935    0.0221544   0.0234694   -0.0260488  -0.00248164   0.123123
  0.169064      0.144261    -0.0402453     0.240853    -0.0290431   -0.0868156    -0.190182    -0.126027      0.0662746   -0.148807    -0.18236      0.0770667   -0.0544053   -0.12957      0.0944999    0.0506501   -0.0220517    0.0192094    0.117642     0.0990608   -0.0782815   -0.195011   -0.154246     0.0706529   0.114657     0.0460243
  2.22678e-5    0.0979105    0.163557      0.0169783   -0.0837308   -0.0633429    -0.00363072   0.114859     -0.0604152   -0.0609851    0.0852404   -0.136579     0.00948623  -0.0215045   -0.0632415    0.0393857   -0.149145     0.0283699    0.112303    -0.0887796   -0.036781    -0.153161   -0.150223    -0.122817    0.0236896   -0.0639508
  0.0978496    -0.0862301   -0.19285      -0.102295    -0.0476092    0.0788222     0.0713047    0.011551      0.13231      0.0422126    0.0428741    0.114408     0.0338492    0.00106465  -0.181012    -0.146117     0.142645     0.0396229    0.0498955    0.0192331    0.0946707   -0.104185    0.0334572    0.120162   -0.176124     0.0837338
 -0.159869     -0.088411     0.0667681     0.0929935    0.0369208    0.167325      0.0639971    0.054329      0.0753152   -0.120636     0.0987567   -0.0724458    0.135304     0.10174      0.00634748   0.0904899   -0.0724901   -0.0358836   -0.130401     0.0745492   -0.00168233   0.203685   -0.0960659    0.206933    0.110269     0.049862
  0.0363249     0.0856094    0.0315838     0.169362    -0.0379443   -0.148022     -0.0212153   -0.121695     -0.0843727    0.0908783    0.0292671    0.113611     0.134292     0.13585      0.115647     0.0984428    0.0830354   -0.0398764    0.0149492    0.00409258  -0.196279     0.173117   -0.119298    -0.14698    -0.094958     0.198067
 -9.96335e-5   -0.0617802    0.0679813     0.195922    -0.0982476    0.0299059     0.0614517    0.000647875   0.0581899    0.0904875   -0.0513901    0.121092     0.0992559    0.118328    -0.00915169   0.0271541    0.0425789   -0.0407626    0.0190923    0.0428074    0.0599657   -0.0553602  -0.0798754   -0.0498399  -0.00811041   0.145888
 -0.04953      -0.0200029   -0.0572959    -0.0103327   -0.058387    -0.0440947     0.0950408   -0.0158665    -0.128542    -0.0883015   -0.0297226    0.0983742   -0.00479725  -0.0932952   -0.0742579    0.0801376   -0.00286692   0.0107635   -0.196773    -0.00680463  -0.114834     0.0262565  -0.075863    -0.125139   -0.19955      0.0282339
  0.0100526    -0.0846473   -0.0276104    -0.0938309   -0.204852     0.126565     -0.0174447    0.0621446    -0.111074     0.0174288    0.0828507   -0.0921509   -0.169647    -0.0152372    0.00544889  -0.23768     -0.0371556   -0.124153     0.0330734   -0.0206733    0.136526    -0.0487004  -0.144611     0.0817732   0.035505    -0.0961403
  0.157487     -0.004578     0.0399614    -0.0188015   -0.0298254   -0.00373959   -0.0530285    0.0187457     0.0973673    0.0755263   -0.191347     0.053702    -0.0888308    0.150756     0.00302498  -0.0370327    0.109677     0.00650987   0.0988181   -0.0499242    0.113728     0.095118    0.0571203   -0.0264998  -0.0209684    0.0643565
  0.057322     -0.0798347    0.0752964     0.0738626   -0.00805521   0.0300452    -0.0453577   -0.120405     -0.00500232   0.102253    -0.0330403    0.0915776   -0.0209874    0.116372     0.00485952  -0.0120751   -0.0446656    0.0275716   -0.0674125    0.0632671   -0.0188385    0.0528449  -0.0690353    0.0870135  -0.0862257   -0.0214039
 -0.0280204     0.0688059   -0.000931447   0.0331897   -0.0849107    0.249097     -0.00165487  -0.00830443    0.0899813    0.0401939   -0.0504528   -0.0233044   -0.0892963   -0.187656    -0.0467226    0.0114624   -0.209939    -0.227851    -0.0292633    0.0285927   -0.0369304    0.0424586  -0.0376329    0.0471522   0.012307     0.0882453
 -0.0141158     0.0996119    0.104165      0.0312412   -0.018041    -0.0898846     0.0169673   -0.11996      -0.0471544    0.0132828    0.148579     0.155342     0.179086    -0.0060084    0.0057486    0.00119985  -0.048661    -0.0780284   -0.21908     -0.0516665   -0.0276388    0.0648066   0.066178    -0.0463688  -0.0318162    0.00236861
 -0.168032      0.106145     0.0950672     0.00490538  -0.0606799   -0.0414843     0.0468249   -0.0815446     0.0246386    0.133672    -0.0205196   -0.0620388   -0.00164875  -0.038959    -0.182545    -0.241226     0.32641     -0.129459    -0.0497935    0.0142412    0.0783734   -0.0289141  -0.0224058   -0.0522898   0.199299    -0.0116935[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.089831
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│      9
│     16
│     18
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.018908
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│      9
│     18
│     19
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.993149
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│      7
│      8
│      9
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.993563
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.048681
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      7
│      9
│     16
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.992430
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      8
│      9
│     13
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.033934
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      7
│      9
│     16
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.988779
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      9
│     19
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.022088
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│      9
│     16
│     18
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.026311
┌ Info: EM with 100000 data points 10 iterations avll -1.026311
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0102687    0.104942      0.00620563  -0.0515183   -0.114093    -0.0572845    -0.147609     0.0741479    0.0251819   -0.0261724   -0.0417139    0.0373371   -0.0451078   0.0350451    0.0418624   -0.175489    -0.0827605    0.149997     0.0385682    0.139228     -0.189964    0.192203    -0.0675241    -0.141791    -0.0182775   -0.0622082
 -0.147257    -0.0863825    -0.0499705    0.170788     0.101946    -0.0259236    -0.0307768   -0.0154804   -0.00351394  -0.0186384    0.27486     -0.0189967   -0.125665    0.13765     -0.102794     0.182222     0.0220154    0.00628373  -0.12665      0.194469      0.0205768  -0.0273384    0.241147      0.131308    -0.114762    -0.175254
  0.106794     0.0405086    -0.00484136  -0.0384386   -0.106745    -0.0710816    -0.0801096    0.0110317    0.016333    -0.121154     0.150985    -0.0473161    0.0748921  -0.0542074   -0.0142866    0.0290237    0.193194    -0.134285     0.0562335    0.031385     -0.0700732  -0.0852875   -0.0554572    -0.167878     0.107449     0.111854
  0.0874731   -0.0761294    -0.019024    -0.0546275    0.00779452   0.0986035     0.0861031   -0.00203827   0.0135576    0.197075     0.0266384    0.0174665    0.0481363   0.0179863   -0.0305055   -0.136553    -0.0761321    0.0558314   -0.229426    -0.107165      0.288098   -0.141644    -0.0730591    -0.041481    -0.249404    -0.0446437
 -0.0555949    0.094171      0.0641095    0.11391      0.16215      0.0982047    -0.00539785   0.0189177    0.0498868    0.00167891  -0.0520813   -0.00630877  -0.0972482  -0.072011     0.0507147   -0.120751     0.0718799   -0.00352191   0.118165    -0.0494511    -0.0367305  -0.0803525   -0.00913965   -0.0338776    0.26643     -0.02733
  0.0965624    0.0203879     0.168744     0.0491011   -0.0230086   -0.0794061     0.028916     0.0418259   -0.0193127    0.06631     -0.0555351    0.189281     0.0204173  -0.0941324    0.195166    -0.0682471    0.112306     0.0216952   -0.0489357    0.134605     -0.0502249   0.06418      0.184874     -0.236768     0.0460556   -0.102074
 -0.126204     0.14852       0.00916311  -0.0799196   -0.0436494    0.169787      0.0437717    0.0999966   -0.0612325    0.0976555   -0.0426154   -0.0938539   -0.0417312  -0.0899133    0.130118    -0.0174777    0.102185    -0.00411691  -0.0959468   -0.0911894     0.090014    0.0221956   -0.193552      0.0319806   -0.163717     0.0831468
  0.074187    -0.0459012     0.0139414    0.134347    -0.0202815    0.0876405     0.154522    -0.185127     0.0632678    0.0292806    0.0401284   -0.0526442    0.185591   -0.043204     0.126434    -0.0224192    0.112561     0.00245159   0.160388    -0.0581145     0.0764085  -0.0131414   -0.047401      0.087799    -0.0516329   -0.0817892
 -0.0583541    0.112073      0.0116006   -0.0892205   -0.116933     0.0950435    -0.0664631   -0.030652     0.096556    -0.126593    -0.106103     0.0566987    0.0201789  -0.175427     0.202673    -0.132184     0.0870223    0.0152725    0.120954    -0.00600188   -0.0538091  -0.0292484    0.0412198    -0.123504     0.05646     -0.0971493
  0.0177047   -0.134751     -0.126242     0.0110723   -0.0239093   -0.142095     -0.13636     -0.0947258    0.00396233   0.032221    -0.113901     0.0416307   -0.0623207  -0.0629435   -0.100474    -0.180045     0.0634362   -0.0598427   -0.0994043    0.117395      0.0478404   0.104213     0.15861      -0.0560242   -0.0346592    0.154862
  0.119593     0.000417906   0.00208422   0.031613    -0.0151955    0.0824787     0.146908     0.00308851   0.11997     -0.0641089    0.056221     0.0420021   -0.217212   -0.0779585    0.0734613   -0.00311319   0.0351786    0.226245     0.0852084   -0.15365       0.0462066  -0.179335    -0.0264305     0.0525372    0.0561096   -0.0392912
  0.0385956   -0.063389     -0.13265      0.157625     0.0517669   -0.0403149     0.040881     0.147584    -0.0618935    0.0102192   -0.00319545   0.15437     -0.0519236   0.0219616    0.0813313    0.0564082    0.0736425    0.133137    -0.0114996   -0.173994     -0.0161917  -0.0675587    0.0505616    -0.105789     0.0515304    0.00652786
 -0.00519132   0.0572348    -0.104356     0.085931    -0.0788921    0.141881      0.0810596    0.0765444   -0.00490486  -0.0973893   -0.0125361    0.181237    -0.0316018   0.198274     0.030988    -0.0487622   -0.057056     0.165573     0.0757246    0.0049934     0.0215732   0.0833808    0.0203221     0.117228     0.0221235   -0.0460557
 -0.0324344    0.0249101    -0.179877    -0.0301981   -0.134421    -0.075585     -0.0867969    0.0116675    0.041598    -0.0806555    0.208424    -0.176978     0.0265634   0.0286993    0.15085     -0.189152    -0.00179564  -0.256071    -0.0984336   -0.114425     -0.0364418   0.122553    -0.209497      0.0192857   -0.0217471   -0.0210902
 -0.0238151   -0.0605539    -0.00505814  -0.218987    -0.0201398   -0.1103        0.206073    -0.107959    -0.193833     0.0203482   -0.00411675  -0.197449     0.0575376  -0.031065     0.0395824    0.0834717   -0.0637375   -0.0119757    0.0697883    0.102144      0.214364   -0.0608959    0.10832      -0.0125651   -0.166557     0.0823717
 -0.0041115    0.0559295    -0.0546196    0.0120021    0.013111     0.129578      0.0536216    0.236097    -0.136522    -0.0810371    0.13367      0.0317698    0.135109    0.07593     -0.0912454   -0.10279     -0.156382    -0.0130753    0.142073     0.0228993     0.0150944  -0.0921093    0.000302457  -0.0498571   -0.1375       0.056513
  0.162468    -0.0648875     0.0715223   -0.139827     0.0638413    0.0824138    -0.088896    -0.0850407    0.00659152   0.0344881    0.112247     0.0104963   -0.0851575   0.237008     0.0057444    0.0982302   -0.220021     0.00915382   0.0540864   -0.0322762    -0.149104   -0.0279506    0.0340337     0.0454074    0.0617156   -0.0231871
 -0.127995    -0.0354579    -0.0356143    0.1731      -0.0538905    0.0990048     0.0329916    0.031689     0.0724875   -0.0910142    0.206295     0.0669571   -0.103672    0.0532483    0.0208551    0.0365866   -0.0535471   -0.0444229   -0.070983    -0.0847844     0.14807    -0.187511     0.0918589    -0.0723321   -0.213674     0.0331542
  0.0395403   -0.0851839    -0.00154589  -0.0351311   -0.116068     0.0351331     0.00279143  -0.00962131   0.186271     0.155169    -0.0501346    0.0274046   -0.105521    0.0251831   -0.0592195    0.162236     0.00468601  -0.0203511    0.0302845   -0.0668833    -0.103023    0.0742226    0.15023       0.209122     0.0330736   -0.0794846
 -0.0845955   -0.10137       0.0116748   -0.1121       0.038914    -0.00550281    0.0119789   -0.0311511   -0.110335     0.0891073   -0.0423786   -0.0161192    0.350105   -0.068337    -0.0695523    0.199077    -0.240986    -0.0668115    0.0280206    0.126732     -0.0240061   0.203017    -0.132095     -0.0184144    0.0563029   -0.0851779
  0.07847     -0.144225      0.0087662   -0.102905     0.0441934    0.0121878    -0.0281971    0.0219187   -0.183348    -0.142312     0.049234     0.0581854   -0.0515785  -0.00585419   0.0795116    0.164818     0.0263631    0.118328    -0.0326351    0.0846725     0.0890015   0.0899072   -0.0351029    -0.172117     0.00710727  -0.0249601
  0.163461     0.0871861    -0.0492959   -0.0811939   -0.121308     0.0887757    -0.0150377    0.153321     0.0987325   -0.13268      0.161514     0.0133964   -0.0761653  -0.0616889    0.0134428    0.092313    -0.153911    -0.162942    -0.00250469  -0.0721234     0.0678272  -0.0924595   -0.177804      0.0358673    0.051292    -0.101537
  0.247577     0.263119      0.0628275   -0.135692    -0.00202387  -0.19196       0.136041     0.00129373   0.0187038   -0.0844749   -0.0507848    0.109902    -0.0905777  -0.168317    -0.0185789   -0.0487059    0.0446137   -0.0351229    0.110608    -0.00553696    0.0757991   0.0939344    0.0260064     0.00697332   0.0862743    0.0975693
 -0.132418     0.00751733   -0.230365     0.0945952   -0.134292    -0.064984     -0.160856    -0.0256174   -0.219549    -0.053584    -0.051292    -0.101026     0.0389192  -0.0894139    0.154802     0.0513617    0.135972     0.0945962    0.152982     0.157005     -0.0556723   0.00142793  -0.0325312     0.045243     0.0199609    0.0532468
 -0.234688     0.00651782   -0.0811797   -0.0394399   -0.0699996    0.0971599    -0.148428    -0.046597     0.0602387    0.0729258    0.145321     0.0510474   -0.0512013  -0.00427831   0.0468889    0.10157     -0.116732     0.041872     0.133639     0.10639      -0.0786806  -0.0387189   -0.157442     -0.0841939   -0.0624309    0.00387402
 -0.0930213    0.134318      0.0153433   -0.00900467   0.18938      0.0676683     0.0165289   -0.018783     0.0994595   -0.0269855    0.159181     0.0190177   -0.154269    0.0372926    0.0315992   -0.122894     0.0932042    0.00154595   0.123213    -0.0300244     0.148501    0.0171855    0.119531     -0.0132215    0.00721186  -0.0606379
  0.185182     0.0239737    -0.00127069   0.0623918   -0.016868    -0.0480876    -0.039609     0.0692653   -0.091526     0.0495959   -0.102891     0.101837    -0.0161486   0.0740659   -0.130244     0.113865    -0.0401604   -0.0249166   -0.0462889    0.0347219     0.0245256  -0.106476     0.053673     -0.0895423    0.0243204    0.128608
  0.0239328    0.0410434    -0.0172348    0.0631687   -0.0778588   -0.190621      0.0244355   -0.0217601    0.240743     0.153401    -0.171249     0.0642276   -0.2651      0.118407     0.174528     0.0552302    0.0335887   -0.168299     0.0593228   -0.0687819     0.109198   -0.0394373    0.107359      0.0835843    0.0737693    0.181941
 -0.0392587    0.0020306     0.0437771   -0.0335296    0.175564    -0.000978534  -0.0545335   -0.166933     0.110053    -0.0333203   -0.0296522    0.0526671    0.0444097   0.0147981    0.0881192    0.0534436    0.123952    -0.0464037   -0.00964991  -0.0113696     0.0737375   0.173366     0.0893306    -0.00460409   0.0868156    0.0688047
 -0.14606      0.0192452    -0.0501809    0.055935    -0.0674338    0.0480848     0.0786072   -0.13398      0.119758    -0.130019     0.0443108    0.0534797    0.03092    -0.0758394    0.0525922    0.113439    -0.18611      0.161667     0.11342      0.000740243   0.0659139   0.0433178   -0.115799     -0.0895477    0.177403    -0.102631
 -0.13474     -0.222284     -0.0980276    0.245404    -0.148006     0.0906639    -0.0391615    0.0591591   -0.0221481    0.0413405    0.197397     0.25224      0.0329211   0.0344801   -0.00542523   0.144657     0.120278    -0.050713    -0.0739567    0.00708996    0.212762   -0.120357    -0.0400069     0.00405095   0.120402    -0.0653634
  0.204905     0.0364408     0.0221029   -0.148585    -0.0486691   -0.0269904     0.15135      0.0808885    0.0518522    0.174272    -0.0739628   -0.0662768    0.0373075   0.103812     0.177236     0.10932      0.024607     0.02939     -0.124571     0.0121265    -0.013018   -0.0529472   -0.0954887     0.0103992   -0.092376    -0.0877895kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4288611550016925
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428882
[ Info: iteration 2, average log likelihood -1.428824
[ Info: iteration 3, average log likelihood -1.428784
[ Info: iteration 4, average log likelihood -1.428738
[ Info: iteration 5, average log likelihood -1.428682
[ Info: iteration 6, average log likelihood -1.428612
[ Info: iteration 7, average log likelihood -1.428513
[ Info: iteration 8, average log likelihood -1.428350
[ Info: iteration 9, average log likelihood -1.428037
[ Info: iteration 10, average log likelihood -1.427423
[ Info: iteration 11, average log likelihood -1.426401
[ Info: iteration 12, average log likelihood -1.425179
[ Info: iteration 13, average log likelihood -1.424230
[ Info: iteration 14, average log likelihood -1.423735
[ Info: iteration 15, average log likelihood -1.423530
[ Info: iteration 16, average log likelihood -1.423451
[ Info: iteration 17, average log likelihood -1.423421
[ Info: iteration 18, average log likelihood -1.423409
[ Info: iteration 19, average log likelihood -1.423403
[ Info: iteration 20, average log likelihood -1.423401
[ Info: iteration 21, average log likelihood -1.423400
[ Info: iteration 22, average log likelihood -1.423399
[ Info: iteration 23, average log likelihood -1.423399
[ Info: iteration 24, average log likelihood -1.423399
[ Info: iteration 25, average log likelihood -1.423398
[ Info: iteration 26, average log likelihood -1.423398
[ Info: iteration 27, average log likelihood -1.423398
[ Info: iteration 28, average log likelihood -1.423398
[ Info: iteration 29, average log likelihood -1.423398
[ Info: iteration 30, average log likelihood -1.423398
[ Info: iteration 31, average log likelihood -1.423398
[ Info: iteration 32, average log likelihood -1.423397
[ Info: iteration 33, average log likelihood -1.423397
[ Info: iteration 34, average log likelihood -1.423397
[ Info: iteration 35, average log likelihood -1.423397
[ Info: iteration 36, average log likelihood -1.423397
[ Info: iteration 37, average log likelihood -1.423397
[ Info: iteration 38, average log likelihood -1.423397
[ Info: iteration 39, average log likelihood -1.423397
[ Info: iteration 40, average log likelihood -1.423397
[ Info: iteration 41, average log likelihood -1.423397
[ Info: iteration 42, average log likelihood -1.423397
[ Info: iteration 43, average log likelihood -1.423397
[ Info: iteration 44, average log likelihood -1.423397
[ Info: iteration 45, average log likelihood -1.423397
[ Info: iteration 46, average log likelihood -1.423397
[ Info: iteration 47, average log likelihood -1.423397
[ Info: iteration 48, average log likelihood -1.423397
[ Info: iteration 49, average log likelihood -1.423397
[ Info: iteration 50, average log likelihood -1.423397
┌ Info: EM with 100000 data points 50 iterations avll -1.423397
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4288824282663941
│     -1.4288240090894886
│      ⋮
└     -1.4233966091079873
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423418
[ Info: iteration 2, average log likelihood -1.423357
[ Info: iteration 3, average log likelihood -1.423315
[ Info: iteration 4, average log likelihood -1.423267
[ Info: iteration 5, average log likelihood -1.423212
[ Info: iteration 6, average log likelihood -1.423149
[ Info: iteration 7, average log likelihood -1.423083
[ Info: iteration 8, average log likelihood -1.423016
[ Info: iteration 9, average log likelihood -1.422954
[ Info: iteration 10, average log likelihood -1.422898
[ Info: iteration 11, average log likelihood -1.422849
[ Info: iteration 12, average log likelihood -1.422804
[ Info: iteration 13, average log likelihood -1.422763
[ Info: iteration 14, average log likelihood -1.422724
[ Info: iteration 15, average log likelihood -1.422686
[ Info: iteration 16, average log likelihood -1.422650
[ Info: iteration 17, average log likelihood -1.422614
[ Info: iteration 18, average log likelihood -1.422578
[ Info: iteration 19, average log likelihood -1.422544
[ Info: iteration 20, average log likelihood -1.422511
[ Info: iteration 21, average log likelihood -1.422479
[ Info: iteration 22, average log likelihood -1.422449
[ Info: iteration 23, average log likelihood -1.422422
[ Info: iteration 24, average log likelihood -1.422397
[ Info: iteration 25, average log likelihood -1.422375
[ Info: iteration 26, average log likelihood -1.422355
[ Info: iteration 27, average log likelihood -1.422339
[ Info: iteration 28, average log likelihood -1.422325
[ Info: iteration 29, average log likelihood -1.422314
[ Info: iteration 30, average log likelihood -1.422304
[ Info: iteration 31, average log likelihood -1.422296
[ Info: iteration 32, average log likelihood -1.422290
[ Info: iteration 33, average log likelihood -1.422284
[ Info: iteration 34, average log likelihood -1.422280
[ Info: iteration 35, average log likelihood -1.422276
[ Info: iteration 36, average log likelihood -1.422273
[ Info: iteration 37, average log likelihood -1.422270
[ Info: iteration 38, average log likelihood -1.422267
[ Info: iteration 39, average log likelihood -1.422265
[ Info: iteration 40, average log likelihood -1.422263
[ Info: iteration 41, average log likelihood -1.422261
[ Info: iteration 42, average log likelihood -1.422259
[ Info: iteration 43, average log likelihood -1.422257
[ Info: iteration 44, average log likelihood -1.422255
[ Info: iteration 45, average log likelihood -1.422254
[ Info: iteration 46, average log likelihood -1.422252
[ Info: iteration 47, average log likelihood -1.422251
[ Info: iteration 48, average log likelihood -1.422249
[ Info: iteration 49, average log likelihood -1.422248
[ Info: iteration 50, average log likelihood -1.422246
┌ Info: EM with 100000 data points 50 iterations avll -1.422246
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4234176332319208
│     -1.423356763856569
│      ⋮
└     -1.4222461853378334
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422264
[ Info: iteration 2, average log likelihood -1.422207
[ Info: iteration 3, average log likelihood -1.422168
[ Info: iteration 4, average log likelihood -1.422123
[ Info: iteration 5, average log likelihood -1.422070
[ Info: iteration 6, average log likelihood -1.422009
[ Info: iteration 7, average log likelihood -1.421942
[ Info: iteration 8, average log likelihood -1.421873
[ Info: iteration 9, average log likelihood -1.421806
[ Info: iteration 10, average log likelihood -1.421745
[ Info: iteration 11, average log likelihood -1.421691
[ Info: iteration 12, average log likelihood -1.421643
[ Info: iteration 13, average log likelihood -1.421598
[ Info: iteration 14, average log likelihood -1.421557
[ Info: iteration 15, average log likelihood -1.421516
[ Info: iteration 16, average log likelihood -1.421475
[ Info: iteration 17, average log likelihood -1.421432
[ Info: iteration 18, average log likelihood -1.421388
[ Info: iteration 19, average log likelihood -1.421343
[ Info: iteration 20, average log likelihood -1.421295
[ Info: iteration 21, average log likelihood -1.421246
[ Info: iteration 22, average log likelihood -1.421197
[ Info: iteration 23, average log likelihood -1.421147
[ Info: iteration 24, average log likelihood -1.421099
[ Info: iteration 25, average log likelihood -1.421053
[ Info: iteration 26, average log likelihood -1.421010
[ Info: iteration 27, average log likelihood -1.420971
[ Info: iteration 28, average log likelihood -1.420935
[ Info: iteration 29, average log likelihood -1.420904
[ Info: iteration 30, average log likelihood -1.420876
[ Info: iteration 31, average log likelihood -1.420851
[ Info: iteration 32, average log likelihood -1.420830
[ Info: iteration 33, average log likelihood -1.420810
[ Info: iteration 34, average log likelihood -1.420793
[ Info: iteration 35, average log likelihood -1.420778
[ Info: iteration 36, average log likelihood -1.420763
[ Info: iteration 37, average log likelihood -1.420750
[ Info: iteration 38, average log likelihood -1.420738
[ Info: iteration 39, average log likelihood -1.420727
[ Info: iteration 40, average log likelihood -1.420717
[ Info: iteration 41, average log likelihood -1.420707
[ Info: iteration 42, average log likelihood -1.420698
[ Info: iteration 43, average log likelihood -1.420689
[ Info: iteration 44, average log likelihood -1.420680
[ Info: iteration 45, average log likelihood -1.420672
[ Info: iteration 46, average log likelihood -1.420665
[ Info: iteration 47, average log likelihood -1.420657
[ Info: iteration 48, average log likelihood -1.420650
[ Info: iteration 49, average log likelihood -1.420643
[ Info: iteration 50, average log likelihood -1.420637
┌ Info: EM with 100000 data points 50 iterations avll -1.420637
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.422264469488796
│     -1.4222070801242286
│      ⋮
└     -1.4206368129221667
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420641
[ Info: iteration 2, average log likelihood -1.420583
[ Info: iteration 3, average log likelihood -1.420530
[ Info: iteration 4, average log likelihood -1.420470
[ Info: iteration 5, average log likelihood -1.420397
[ Info: iteration 6, average log likelihood -1.420308
[ Info: iteration 7, average log likelihood -1.420203
[ Info: iteration 8, average log likelihood -1.420087
[ Info: iteration 9, average log likelihood -1.419964
[ Info: iteration 10, average log likelihood -1.419841
[ Info: iteration 11, average log likelihood -1.419723
[ Info: iteration 12, average log likelihood -1.419614
[ Info: iteration 13, average log likelihood -1.419516
[ Info: iteration 14, average log likelihood -1.419431
[ Info: iteration 15, average log likelihood -1.419358
[ Info: iteration 16, average log likelihood -1.419296
[ Info: iteration 17, average log likelihood -1.419244
[ Info: iteration 18, average log likelihood -1.419200
[ Info: iteration 19, average log likelihood -1.419161
[ Info: iteration 20, average log likelihood -1.419128
[ Info: iteration 21, average log likelihood -1.419098
[ Info: iteration 22, average log likelihood -1.419071
[ Info: iteration 23, average log likelihood -1.419046
[ Info: iteration 24, average log likelihood -1.419023
[ Info: iteration 25, average log likelihood -1.419001
[ Info: iteration 26, average log likelihood -1.418980
[ Info: iteration 27, average log likelihood -1.418959
[ Info: iteration 28, average log likelihood -1.418939
[ Info: iteration 29, average log likelihood -1.418919
[ Info: iteration 30, average log likelihood -1.418900
[ Info: iteration 31, average log likelihood -1.418881
[ Info: iteration 32, average log likelihood -1.418862
[ Info: iteration 33, average log likelihood -1.418843
[ Info: iteration 34, average log likelihood -1.418824
[ Info: iteration 35, average log likelihood -1.418805
[ Info: iteration 36, average log likelihood -1.418787
[ Info: iteration 37, average log likelihood -1.418769
[ Info: iteration 38, average log likelihood -1.418751
[ Info: iteration 39, average log likelihood -1.418734
[ Info: iteration 40, average log likelihood -1.418717
[ Info: iteration 41, average log likelihood -1.418701
[ Info: iteration 42, average log likelihood -1.418685
[ Info: iteration 43, average log likelihood -1.418669
[ Info: iteration 44, average log likelihood -1.418655
[ Info: iteration 45, average log likelihood -1.418640
[ Info: iteration 46, average log likelihood -1.418626
[ Info: iteration 47, average log likelihood -1.418613
[ Info: iteration 48, average log likelihood -1.418600
[ Info: iteration 49, average log likelihood -1.418587
[ Info: iteration 50, average log likelihood -1.418575
┌ Info: EM with 100000 data points 50 iterations avll -1.418575
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4206409449207025
│     -1.420582755230329
│      ⋮
└     -1.4185749628262712
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418572
[ Info: iteration 2, average log likelihood -1.418502
[ Info: iteration 3, average log likelihood -1.418432
[ Info: iteration 4, average log likelihood -1.418351
[ Info: iteration 5, average log likelihood -1.418249
[ Info: iteration 6, average log likelihood -1.418123
[ Info: iteration 7, average log likelihood -1.417972
[ Info: iteration 8, average log likelihood -1.417802
[ Info: iteration 9, average log likelihood -1.417623
[ Info: iteration 10, average log likelihood -1.417445
[ Info: iteration 11, average log likelihood -1.417278
[ Info: iteration 12, average log likelihood -1.417127
[ Info: iteration 13, average log likelihood -1.416994
[ Info: iteration 14, average log likelihood -1.416879
[ Info: iteration 15, average log likelihood -1.416779
[ Info: iteration 16, average log likelihood -1.416692
[ Info: iteration 17, average log likelihood -1.416617
[ Info: iteration 18, average log likelihood -1.416549
[ Info: iteration 19, average log likelihood -1.416489
[ Info: iteration 20, average log likelihood -1.416435
[ Info: iteration 21, average log likelihood -1.416386
[ Info: iteration 22, average log likelihood -1.416341
[ Info: iteration 23, average log likelihood -1.416300
[ Info: iteration 24, average log likelihood -1.416263
[ Info: iteration 25, average log likelihood -1.416229
[ Info: iteration 26, average log likelihood -1.416197
[ Info: iteration 27, average log likelihood -1.416167
[ Info: iteration 28, average log likelihood -1.416140
[ Info: iteration 29, average log likelihood -1.416114
[ Info: iteration 30, average log likelihood -1.416090
[ Info: iteration 31, average log likelihood -1.416067
[ Info: iteration 32, average log likelihood -1.416045
[ Info: iteration 33, average log likelihood -1.416024
[ Info: iteration 34, average log likelihood -1.416004
[ Info: iteration 35, average log likelihood -1.415985
[ Info: iteration 36, average log likelihood -1.415966
[ Info: iteration 37, average log likelihood -1.415948
[ Info: iteration 38, average log likelihood -1.415931
[ Info: iteration 39, average log likelihood -1.415914
[ Info: iteration 40, average log likelihood -1.415898
[ Info: iteration 41, average log likelihood -1.415883
[ Info: iteration 42, average log likelihood -1.415868
[ Info: iteration 43, average log likelihood -1.415854
[ Info: iteration 44, average log likelihood -1.415840
[ Info: iteration 45, average log likelihood -1.415827
[ Info: iteration 46, average log likelihood -1.415814
[ Info: iteration 47, average log likelihood -1.415802
[ Info: iteration 48, average log likelihood -1.415790
[ Info: iteration 49, average log likelihood -1.415779
[ Info: iteration 50, average log likelihood -1.415768
┌ Info: EM with 100000 data points 50 iterations avll -1.415768
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4185720490671976
│     -1.418501668246951
│      ⋮
└     -1.41576823769968
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4288611550016925
│     -1.4288824282663941
│     -1.4288240090894886
│     -1.428784108475719
│      ⋮
│     -1.415790462504857
│     -1.4157791516956642
└     -1.41576823769968
32×26 Array{Float64,2}:
 -0.0938403   -0.0967828  -0.0678335    0.304801    -0.153743     0.529151    -0.340428    -0.763965     0.870857    0.434323   -0.137812     0.148084    -0.382127     0.0458111  -0.0337944    -0.322036    0.0480666   -0.818324    -0.278824    -0.273727   -0.61468    -0.423552    -0.438132    0.0641113    0.0779872   0.26919
  0.230904     0.0196457  -0.283452    -0.219257     0.229638     0.477413     0.0520352    0.115853     0.640829    0.0467851  -0.165653    -0.16446      0.00706204  -0.247318   -0.0520696    -0.739986   -0.282512    -0.777427    -0.422435    -0.0932957   0.112169    0.68883     -0.133061    0.564515     0.0589985   0.157671
  0.228094     0.539777   -0.17414      0.00857886  -0.0749619    0.488131     0.181741     0.0408677   -0.350741    0.429924   -0.523385     0.404331     0.0371018    0.535318    0.151055      0.0944558   1.16838     -0.27024      0.311466    -0.0474255  -0.214464   -0.065271    -0.232919   -0.335341    -0.140449   -0.162161
 -0.455083    -0.124199   -0.263238    -0.498874    -0.833001     0.249588    -0.0145593    0.0330291   -0.245453    0.522917   -0.186557     0.463919    -0.149434     0.0535303  -0.244876      0.0991597   0.618478     0.508908     0.216621     0.544787    0.104514   -0.900548     0.125783    0.794382    -0.515506   -0.0188173
 -0.504107    -0.053654   -0.265233    -0.616603     0.0580245    0.410873    -0.541725    -0.217425     0.142542   -0.694106   -0.286704    -0.621097    -0.115918     0.254239   -0.629837      0.113434   -0.540355    -0.361667     0.575418    -0.237217    0.107099   -0.0776733   -0.0624695   0.195072    -0.558539    0.00242248
 -0.0428991    0.367754   -0.649257    -0.848807    -0.333347     0.334594     0.977624     0.648928    -0.368008   -0.137307   -0.149538    -0.406394    -0.278617    -0.153585   -0.610992      0.043195   -0.179615    -0.166046    -0.193       -0.15342    -0.563938    0.1085       0.892677    0.0226231   -0.516065   -0.371664
  0.307394     0.253893    0.203315     0.31089      0.383683    -0.0524427    0.0238469   -0.700457     0.337687   -0.110071   -0.0160245   -0.528542    -0.0452004   -0.031796    0.266967      0.715936   -0.733269    -0.973246     0.0297499   -0.241355    0.396421    0.608839     0.633497   -0.762561     0.167108   -0.189999
 -0.00624486  -0.115406    0.505892    -0.222951     0.124435     0.405055     0.0668654   -0.331854    -0.656255   -0.0485062  -0.293654     0.13343     -0.130471     0.0730549   0.24488       0.793544   -0.50127     -0.0455474   -0.225273    -0.51355     0.268892    0.127356     0.137002    0.44163      0.381037   -0.530412
  0.562716     0.672486    0.4417      -0.820014    -0.0613707   -0.444668     0.639155    -0.298321    -0.438968   -0.0639023  -0.289609    -0.61745      0.0729321    0.682611    0.462503      0.0152498   0.0342872   -0.120998    -0.0945108    0.637995    0.246963   -0.214291    -0.277819   -0.415629     0.0824877   0.353723
  0.367433     0.343277    0.38103      0.171585    -0.0229723   -1.14588      0.194596     0.563203    -0.241782    0.214397    0.405604    -0.169613     0.0419051    0.146504    0.555165     -0.161592   -0.136956    -0.0585413    0.22764     -0.10274    -0.257406    0.203418    -0.193348   -0.171658     0.112004   -0.256384
  0.523169    -0.0367011  -0.251757     0.394279    -0.64417     -0.257851     0.300297     0.163641     0.226825   -0.136299    0.0181758   -0.229491    -0.520399    -0.141882    0.0211987    -0.131277    0.702884     0.361815     0.338832     0.0734336  -0.613129   -0.377752     0.184826   -0.418329     0.148529   -0.130844
 -0.10436      0.118349   -0.309569     0.276774    -0.762968    -0.00506401   0.280598    -0.0268983    0.0265189   0.199285    0.331297    -0.545096     0.575098    -0.122541    0.0156603     0.155155    0.343429    -0.174779     0.459635     0.0867983  -0.338889   -0.279223    -0.445637   -0.00985567   0.282302   -0.057261
 -0.663355     0.15394     0.163128     0.836145     0.422559     0.0243357    0.0279627   -0.193013    -0.424833   -0.0402063   0.24015      0.152993    -0.544888    -0.067699   -0.111227     -0.341969   -0.318129    -0.159536     0.214524    -0.26172     0.398394   -0.757921    -0.862924    0.0209577    0.224027    0.552162
 -0.0734637    0.0233579   0.286011     0.630136     0.166827    -0.244017    -0.633505    -0.516222     0.195239    0.0737261   0.129099     0.348401     0.337233     0.21838     0.799361      0.0495736   0.563151     0.425411     0.27289      0.448764    0.405564   -0.270682    -0.618859   -0.29049      0.306562    0.34825
  0.0340091   -0.0186823  -0.116481     0.154699    -0.0448807   -0.0487364   -0.0250748   -0.0183615    0.118981    0.112667    0.0551504    0.0337618    0.0552995   -0.0725594   0.152475      0.0612358   0.286798     0.0649464    0.0971762    0.0458694  -0.0455529  -0.0351025   -0.104      -0.164724    -0.030479    0.0410076
 -0.245495    -0.230567    0.0907817   -0.0430589   -0.390724    -0.526253    -0.0502819    0.21452     -0.0842954  -0.388171    0.678376    -0.0960061   -0.494291    -0.30549     0.225072     -0.0893674  -0.978236     0.398942    -0.460303     0.189358    0.308173   -0.433579     0.519403   -0.0345356   -0.136613    0.306518
 -0.555582    -0.502684   -0.162603     0.229395     0.250465     0.0659149   -0.699385     0.414203     0.412905   -0.225642    0.164203     0.403151     0.309364    -0.40746    -0.351285     -0.172609   -0.0930568    0.227322    -0.0344324   -0.163554   -0.269956    0.156185     0.0833259  -0.10872     -0.313366    0.335523
  0.790378    -0.24505     0.261947     0.209894     0.441903    -0.301172    -0.00353032  -0.0339616    0.309523   -0.39302     0.276571    -0.505288     0.247985    -0.27566    -0.118633     -0.0941775  -0.378944     0.0528143   -0.201435    -0.514984   -0.202903    0.547823    -0.0346904  -0.205325     0.614276   -0.0759601
 -0.0341562   -0.669601    0.164363    -0.149115     0.436041    -0.0893637   -0.888705     0.0847857   -0.0306774   0.165817    0.00978919   0.542023    -0.170069     0.331831   -0.0721888    -0.0717287  -0.482108    -0.147989    -0.744477    -0.329961    0.794674    0.0814651    0.21318    -0.00156117  -0.196584    0.606874
  0.202982    -0.181683   -0.201369     0.147014     0.203773    -0.0448972   -0.23243      0.0353908    0.0914798   0.827159    0.135721     0.762723     1.11403      0.216619   -0.385529     -0.418346    0.239776    -0.0910328   -0.340514     0.462137    0.640709   -0.0388257   -0.463902    0.263413     0.0210629  -0.0859463
 -0.211363     0.0550951  -0.109749    -0.152006    -0.252125     0.601385     0.489937    -0.343978     0.119443   -0.329241    0.132094     0.0612653   -0.183976    -0.282748   -0.176974     -0.393486   -0.00245624  -0.00570083  -0.268406     0.431318    0.44553    -0.0772098   -0.0337586   0.17369      0.0172739   0.268182
  0.495912     0.168729   -0.00997618  -0.401337    -0.342755     0.212209     0.284565    -0.0819625    0.169993    0.792402    0.0941555    0.212367    -0.325914     0.070357    0.31444      -0.0482749  -0.140251    -0.0569931   -0.356984    -0.0668082   0.371566   -0.126469     0.409871    0.381657    -0.0333747   0.303334
 -0.0344133    0.275847    0.115807    -0.0775341    0.641906     0.482967     0.217798    -0.224532     0.138144   -0.227689    0.191624     1.22397     -0.129142     0.0146412   0.0840205    -0.0842008   0.200171     0.235945    -0.581862     0.0681331   0.111512    0.386415     0.257104   -0.0452707   -0.168094   -0.256269
  0.313936     0.38003     0.171476     0.700944     0.311376    -0.249471     0.582507    -0.685177     0.0101977   0.0479372   0.606955     0.582968    -0.474253    -0.211908   -0.137576     -0.363393   -0.132833     0.779211    -0.698229    -0.0339867   0.728465   -0.509758     0.455471    0.212689     0.665782   -0.394272
  0.102018    -0.183667   -0.33026     -0.126061     0.00121288   0.0952989   -0.206178     0.0816342   -0.0279815   0.264843   -0.29188     -0.0306166   -0.101642     0.060502   -0.000858761  -0.25338     0.052981    -0.235161     0.050222    -0.0679499  -0.262206   -0.354227    -0.123854    0.203283     0.0492804  -0.0486401
  0.133855    -0.125253   -0.026721    -0.360967     0.221313     0.339308    -0.305285     0.0551508    0.187561   -0.0755304  -0.621801     0.00856764   0.013047     0.143508    0.00625516    0.112204    0.255901    -0.225737     0.242097    -0.133819   -0.15208     0.558014     0.011278    0.0341897   -0.106679   -0.100173
  0.114888     0.0921209   0.19462      0.346941     0.0143318   -0.0839681    0.219083    -0.00802684   0.0693664   0.0256416   0.334781     0.0125923   -0.0271807   -0.0309639   0.279279     -0.0506212   0.117287    -0.17262     -0.00375888  -0.110608    0.0262961   0.0803914   -0.175776   -0.163135     0.191224    0.229655
 -0.0885835    0.0601236  -0.0647245   -0.0852203   -0.121987    -0.110336     0.0219363    0.0760729   -0.0858079  -0.115104    0.113611    -0.0156352    0.0351972    0.0379558  -0.092696      0.120613   -0.16293      0.271483     0.0495695    0.198673    0.0717386  -0.0647884    0.129658   -0.0218283   -0.101308   -0.147437
 -0.481637    -0.0364154   0.2237      -0.194073     0.0393695    0.207494     0.204483    -0.0194493   -0.178805   -0.876641   -0.213551    -0.633293    -1.03453     -0.224176    0.273974      0.309833   -0.493607     0.401273     0.417725    -0.041267   -0.131605    0.245227     0.20287    -0.219809    -0.451505    0.0996199
 -0.272461    -0.26603     0.0234983    0.412066    -0.150319    -0.243988    -0.172226     0.293648    -0.273967    0.0410978  -0.040836     0.166928    -0.414814     0.176592   -0.123674      0.845515   -0.209225     0.196161     0.0228385   -0.549034   -0.0703616  -0.00567829   0.454095   -0.187766    -0.224498   -0.478698
 -0.104542    -0.294534   -0.150195    -0.748583     0.033317    -0.502592    -0.157624     0.560304    -0.066794   -0.0868787  -0.0641884   -0.353228     0.551593     0.118685    0.089987      0.237518   -0.610417     0.400406     0.375229     0.603602    0.184332    0.419886     0.0538945  -0.00525429  -0.298381   -0.505071
 -0.37187      0.362086    0.178486     0.0827993    0.263263    -0.280377     0.139718     0.2442      -0.693586   -0.4427      0.0114965    0.0830087    0.475499    -0.307658    0.250637      0.320093    0.465769     0.569555     0.581545     0.418361    0.339732    0.28642      0.257602   -0.309227     0.161372   -0.517612[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415758
[ Info: iteration 2, average log likelihood -1.415747
[ Info: iteration 3, average log likelihood -1.415738
[ Info: iteration 4, average log likelihood -1.415728
[ Info: iteration 5, average log likelihood -1.415719
[ Info: iteration 6, average log likelihood -1.415710
[ Info: iteration 7, average log likelihood -1.415701
[ Info: iteration 8, average log likelihood -1.415692
[ Info: iteration 9, average log likelihood -1.415684
[ Info: iteration 10, average log likelihood -1.415675
┌ Info: EM with 100000 data points 10 iterations avll -1.415675
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.487326e+05
      1       7.166933e+05      -2.320392e+05 |       31
      2       7.012169e+05      -1.547638e+04 |       31
      3       6.960459e+05      -5.171035e+03 |       31
      4       6.935346e+05      -2.511284e+03 |       31
      5       6.919721e+05      -1.562478e+03 |       31
      6       6.908575e+05      -1.114651e+03 |       31
      7       6.900090e+05      -8.484617e+02 |       31
      8       6.893646e+05      -6.443909e+02 |       31
      9       6.888462e+05      -5.184649e+02 |       31
     10       6.884431e+05      -4.031297e+02 |       31
     11       6.881217e+05      -3.213290e+02 |       31
     12       6.878383e+05      -2.834598e+02 |       31
     13       6.875788e+05      -2.594455e+02 |       31
     14       6.873442e+05      -2.346081e+02 |       31
     15       6.871375e+05      -2.066867e+02 |       31
     16       6.869509e+05      -1.866317e+02 |       31
     17       6.867700e+05      -1.808446e+02 |       31
     18       6.865878e+05      -1.822403e+02 |       31
     19       6.864162e+05      -1.716444e+02 |       31
     20       6.862591e+05      -1.570585e+02 |       31
     21       6.861063e+05      -1.527525e+02 |       31
     22       6.859759e+05      -1.304246e+02 |       31
     23       6.858523e+05      -1.236433e+02 |       31
     24       6.857414e+05      -1.108470e+02 |       31
     25       6.856369e+05      -1.045132e+02 |       31
     26       6.855417e+05      -9.520041e+01 |       31
     27       6.854449e+05      -9.683877e+01 |       31
     28       6.853569e+05      -8.799978e+01 |       31
     29       6.852739e+05      -8.297376e+01 |       31
     30       6.851930e+05      -8.086482e+01 |       31
     31       6.851156e+05      -7.743467e+01 |       31
     32       6.850376e+05      -7.801345e+01 |       31
     33       6.849586e+05      -7.903300e+01 |       31
     34       6.848872e+05      -7.140502e+01 |       31
     35       6.848074e+05      -7.980703e+01 |       31
     36       6.847259e+05      -8.147161e+01 |       31
     37       6.846481e+05      -7.777002e+01 |       31
     38       6.845704e+05      -7.774026e+01 |       31
     39       6.844973e+05      -7.309104e+01 |       31
     40       6.844314e+05      -6.586560e+01 |       31
     41       6.843674e+05      -6.398641e+01 |       31
     42       6.843041e+05      -6.329711e+01 |       31
     43       6.842442e+05      -5.990313e+01 |       31
     44       6.841923e+05      -5.190420e+01 |       31
     45       6.841388e+05      -5.352395e+01 |       31
     46       6.840838e+05      -5.504589e+01 |       31
     47       6.840347e+05      -4.901539e+01 |       31
     48       6.839842e+05      -5.056427e+01 |       31
     49       6.839290e+05      -5.515049e+01 |       31
     50       6.838772e+05      -5.183643e+01 |       31
K-means terminated without convergence after 50 iterations (objv = 683877.1849099017)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
ERROR: LoadError: LoadError: UndefVarError: ind2sub not defined
Stacktrace:
 [1] sanitycheck!(::GMM{Float64,Array{Float64,2}}) at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:54
 [2] GMMk(::Int64, ::Array{Float64,2}; kind::Symbol, nInit::Int64, nIter::Int64, sparse::Int64) at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:140
 [3] #GMM#7 at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:36 [inlined]
 [4] top-level scope at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:29
 [5] include(::String) at ./client.jl:439
 [6] top-level scope at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/test/runtests.jl:7
 [7] include(::String) at ./client.jl:439
 [8] top-level scope at none:6
in expression starting at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:22
in expression starting at /home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/test/runtests.jl:7
err = ProcessFailedException(Base.Process[Process(`/opt/julia/bin/julia -Cnative -J/opt/julia/lib/julia/sys.so -g1 --code-coverage=none --color=no --compiled-modules=yes --check-bounds=yes --inline=yes --startup-file=no --track-allocation=none --eval 'append!(empty!(Base.DEPOT_PATH), ["/home/pkgeval/.julia", "/opt/julia/local/share/julia", "/opt/julia/share/julia", "/usr/local/share/julia"])
append!(empty!(Base.DL_LOAD_PATH), String[])

cd("/home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/test")
append!(empty!(ARGS), String[])
include("/home/pkgeval/.julia/packages/GaussianMixtures/RGtTJ/test/runtests.jl")
'`, ProcessExited(1))])
ERROR: Package GaussianMixtures errored during testing
Stacktrace:
 [1] pkgerror(::String, ::Vararg{String,N} where N) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Types.jl:54
 [2] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Operations.jl:1471
 [3] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:313
 [4] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:300
 [5] #test#66 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:294 [inlined]
 [6] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:294 [inlined]
 [7] #test#65 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:293 [inlined]
 [8] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:293 [inlined]
 [9] test(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:292
 [10] test(::String) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:292
 [11] top-level scope at none:13
