Julia Version 1.5.0-DEV.49
Commit c330f8d0d5 (2020-01-10 15:42 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed Missings ─────────── v0.4.3
 Installed SortingAlgorithms ── v0.3.1
 Installed JLD ──────────────── v0.9.1
 Installed FileIO ───────────── v1.2.1
 Installed Parameters ───────── v0.12.0
 Installed StatsFuns ────────── v0.9.3
 Installed Distributions ────── v0.22.1
 Installed StatsBase ────────── v0.32.0
 Installed OrderedCollections ─ v1.1.0
 Installed BinDeps ──────────── v1.0.0
 Installed SpecialFunctions ─── v0.9.0
 Installed BinaryProvider ───── v0.5.8
 Installed NearestNeighbors ─── v0.4.4
 Installed Rmath ────────────── v0.6.0
 Installed Clustering ───────── v0.13.3
 Installed FillArrays ───────── v0.8.4
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed DataAPI ──────────── v1.1.0
 Installed Blosc ────────────── v0.5.1
 Installed Distances ────────── v0.8.2
 Installed CMakeWrapper ─────── v0.2.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Compat ───────────── v2.2.0
 Installed Arpack ───────────── v0.4.0
 Installed PDMats ───────────── v0.9.10
 Installed QuadGK ───────────── v2.3.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed StaticArrays ─────── v0.12.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed CMake ────────────── v1.1.2
 Installed URIParser ────────── v0.4.0
 Installed DataStructures ───── v0.17.7
 Installed LegacyStrings ────── v0.4.1
 Installed HDF5 ─────────────── v0.12.5
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.1
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_xTYT63/Project.toml`
 [no changes]
  Updating `/tmp/jl_xTYT63/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_seYrNc/Project.toml`
 [no changes]
  Updating `/tmp/jl_seYrNc/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_jhpaOU/Project.toml`
 [no changes]
  Updating `/tmp/jl_jhpaOU/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_u27zgo/Project.toml`
 [no changes]
  Updating `/tmp/jl_u27zgo/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_x2Cv6k/Project.toml`
 [no changes]
  Updating `/tmp/jl_x2Cv6k/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_x2Cv6k/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.1
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.7825492322170506e6, [3.9740914764937996, 99996.0259085235], [-12.843052766018225 1.036287070772853 11.752193402040724; -97.71429173910454 5.5233335773428225 -73.69886047601376], [[41.93597630618199 -3.7054322670609725 -37.54297665524571; -3.7054322670609725 0.7410293197197081 2.637990617843595; -37.54297665524571 2.637990617843595 35.244100183632625], [99722.1656607809 191.75224010757896 -297.5182658598253; 191.75224010757896 99861.52855895847 136.48295331229647; -297.5182658598253 136.48295331229647 100043.81044958044]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.317844e+03
      1       1.148501e+03      -1.693435e+02 |        4
      2       1.138445e+03      -1.005553e+01 |        2
      3       1.133744e+03      -4.700786e+00 |        0
      4       1.133744e+03       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 1133.7442435752373)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.092133
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.790874
[ Info: iteration 2, lowerbound -3.654721
[ Info: iteration 3, lowerbound -3.499953
[ Info: iteration 4, lowerbound -3.318174
[ Info: iteration 5, lowerbound -3.133255
[ Info: iteration 6, lowerbound -2.977419
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.864291
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.806958
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.785574
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.763689
[ Info: iteration 11, lowerbound -2.746079
[ Info: iteration 12, lowerbound -2.727052
[ Info: iteration 13, lowerbound -2.701951
[ Info: iteration 14, lowerbound -2.670267
[ Info: iteration 15, lowerbound -2.632330
[ Info: iteration 16, lowerbound -2.589518
[ Info: iteration 17, lowerbound -2.544197
[ Info: iteration 18, lowerbound -2.499242
[ Info: iteration 19, lowerbound -2.457121
[ Info: iteration 20, lowerbound -2.419004
[ Info: iteration 21, lowerbound -2.384650
[ Info: iteration 22, lowerbound -2.353609
[ Info: iteration 23, lowerbound -2.327471
[ Info: iteration 24, lowerbound -2.310916
[ Info: iteration 25, lowerbound -2.307957
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.302916
[ Info: iteration 27, lowerbound -2.299259
[ Info: iteration 28, lowerbound -2.299256
[ Info: iteration 29, lowerbound -2.299254
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Jan 14 02:40:30 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Jan 14 02:40:38 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Tue Jan 14 02:40:41 2020: EM with 272 data points 0 iterations avll -2.092133
5.8 data points per parameter
, Tue Jan 14 02:40:43 2020: GMM converted to Variational GMM
, Tue Jan 14 02:40:51 2020: iteration 1, lowerbound -3.790874
, Tue Jan 14 02:40:51 2020: iteration 2, lowerbound -3.654721
, Tue Jan 14 02:40:51 2020: iteration 3, lowerbound -3.499953
, Tue Jan 14 02:40:51 2020: iteration 4, lowerbound -3.318174
, Tue Jan 14 02:40:51 2020: iteration 5, lowerbound -3.133255
, Tue Jan 14 02:40:51 2020: iteration 6, lowerbound -2.977419
, Tue Jan 14 02:40:51 2020: dropping number of Gaussions to 7
, Tue Jan 14 02:40:51 2020: iteration 7, lowerbound -2.864291
, Tue Jan 14 02:40:51 2020: dropping number of Gaussions to 6
, Tue Jan 14 02:40:51 2020: iteration 8, lowerbound -2.806958
, Tue Jan 14 02:40:51 2020: dropping number of Gaussions to 4
, Tue Jan 14 02:40:51 2020: iteration 9, lowerbound -2.785574
, Tue Jan 14 02:40:51 2020: dropping number of Gaussions to 3
, Tue Jan 14 02:40:51 2020: iteration 10, lowerbound -2.763689
, Tue Jan 14 02:40:51 2020: iteration 11, lowerbound -2.746079
, Tue Jan 14 02:40:51 2020: iteration 12, lowerbound -2.727052
, Tue Jan 14 02:40:51 2020: iteration 13, lowerbound -2.701951
, Tue Jan 14 02:40:51 2020: iteration 14, lowerbound -2.670267
, Tue Jan 14 02:40:51 2020: iteration 15, lowerbound -2.632330
, Tue Jan 14 02:40:51 2020: iteration 16, lowerbound -2.589518
, Tue Jan 14 02:40:51 2020: iteration 17, lowerbound -2.544197
, Tue Jan 14 02:40:51 2020: iteration 18, lowerbound -2.499242
, Tue Jan 14 02:40:51 2020: iteration 19, lowerbound -2.457121
, Tue Jan 14 02:40:51 2020: iteration 20, lowerbound -2.419004
, Tue Jan 14 02:40:51 2020: iteration 21, lowerbound -2.384650
, Tue Jan 14 02:40:51 2020: iteration 22, lowerbound -2.353609
, Tue Jan 14 02:40:51 2020: iteration 23, lowerbound -2.327471
, Tue Jan 14 02:40:51 2020: iteration 24, lowerbound -2.310916
, Tue Jan 14 02:40:51 2020: iteration 25, lowerbound -2.307957
, Tue Jan 14 02:40:51 2020: dropping number of Gaussions to 2
, Tue Jan 14 02:40:51 2020: iteration 26, lowerbound -2.302916
, Tue Jan 14 02:40:51 2020: iteration 27, lowerbound -2.299259
, Tue Jan 14 02:40:51 2020: iteration 28, lowerbound -2.299256
, Tue Jan 14 02:40:52 2020: iteration 29, lowerbound -2.299254
, Tue Jan 14 02:40:52 2020: iteration 30, lowerbound -2.299254
, Tue Jan 14 02:40:52 2020: iteration 31, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 32, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 33, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 34, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 35, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 36, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 37, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 38, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 39, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 40, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 41, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 42, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 43, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 44, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 45, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 46, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 47, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 48, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 49, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: iteration 50, lowerbound -2.299253
, Tue Jan 14 02:40:52 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222607388, 95.9549077739263]
β = [178.04509222607388, 95.9549077739263]
m = [4.250300733269422 79.28686694435463; 2.000229257774866 53.85198717245863]
ν = [180.04509222607388, 97.9549077739263]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554747828 -0.007644049042333709; 0.0 0.008581705166324194], [0.3758763611956779 -0.008953123827356187; 0.0 0.012748664777411588]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000006
avll from stats: -0.9780095447760631
avll from llpg:  -0.9780095447760633
avll direct:     -0.9780095447760633
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9881591650504408
avll from llpg:  -0.9881591650504405
avll direct:     -0.9881591650504405
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0943599   -0.181124     0.0815967   -0.0904566    0.0583276    0.146456     0.0611138    0.0220978   -0.0695539    0.0814406    0.0389755    -0.0864841   -0.0574992    0.125364     0.0528026   -0.142759      0.144479    -0.14709      0.0631063   -0.0509793   -0.00359793    0.00596437  -0.129294    -0.011523      0.123861      0.0199158
  0.21186      0.152267    -0.20684     -0.0589144    0.0540681   -0.0790813   -0.116366    -0.0751274   -0.081571    -0.0582377    0.058057      0.168207    -0.229156    -0.0409714    0.0651263   -0.00837044   -0.0693877   -0.0138049   -0.00602622  -0.0251838   -0.0209349    -0.0614984    0.178951     0.0456984    -0.144532     -0.215889
  0.0736604    0.121352     0.102613    -0.0328367    0.0172096    0.0352334   -0.0864276   -0.00689545  -0.034019    -0.0875652   -0.0815307    -0.0595148   -0.0451634    0.0582062    0.16314     -0.0241727    -0.00788361   0.0324457   -0.159697     0.0202284    0.11564      -0.0923471    0.184766    -0.0277531    -0.229421      0.0975471
 -0.0738144   -0.0313653    0.281518     0.09603      0.0447946   -0.062033    -0.031836     0.0503302   -0.183096    -0.118918    -0.0322396    -0.149524     0.0825132    0.0267284    0.125135     0.0183583     0.0396237    0.07595     -0.0349615    0.0745184    0.0956949    -0.0601432   -0.0957332    0.0771843    -0.0265265     0.0976856
 -0.20709     -0.119719     0.287145     0.0172382   -0.0650459   -0.0369052   -0.192394     0.0519224   -0.0979734   -0.112492     0.0637992    -0.0629994    0.0504056   -0.206704    -0.107815     0.0221023     0.0240824   -0.090473     0.134045    -0.276035    -0.0768437     0.131874    -0.12427      0.146607     -0.0697362    -0.0750738
  0.078516     0.00896074   0.0337408   -0.104297     0.111913    -0.0268365    0.125968     0.0237017   -0.101495    -0.160252     0.0209388     0.0186582   -0.00206091   0.0383535    0.0132387    0.0022217    -0.0808405   -0.00691918   0.0945497    0.112211    -0.171425      0.0738014   -0.00844944   0.0498855    -0.28821       0.0534095
  0.0533893    0.122902    -0.096057    -0.0764611    0.0788694   -0.09397      0.0219234   -0.13087     -0.0403471    0.0671937   -0.0266949     0.218548    -0.0218843   -0.0488139    0.0202783   -0.0119988     0.0359908    0.102782     0.0761466    0.178941     0.000789055   0.0573119    0.103906     0.186386      0.000602852   0.0739042
 -0.010551     0.0248229    0.222481    -0.012614     0.105757    -0.0526792    0.157582     0.049931    -0.00418624   0.137648    -0.116909     -0.0930833    0.0882939    0.0188583    0.0707292    0.129823     -0.0250936   -0.0758478    0.111251    -0.211414     0.0190309    -0.0488071   -0.0626931    0.109256     -0.0225966     0.160817
  0.0966301    0.0602997    0.173064    -0.011287     0.270374     0.0486566   -0.016667     0.0313839    0.175821    -0.0678161   -0.0847649     0.0436978   -0.0861273    0.0211331    0.0581035   -0.0986196     0.0662593    0.0634093   -0.145195    -0.00152155   0.0773285    -0.166731     0.185773     0.0714189    -0.0233356    -0.0997405
 -0.0631185    0.0697269   -0.0284892   -0.0165222    0.0885915    0.0580795    0.01393     -0.0559184   -0.0434521    0.0777101    0.0436907     0.104075     0.0399825    0.0317019    0.0872612   -0.00830628    0.0336841   -0.0586569   -0.057092     0.10563      0.0145471    -0.0634563    0.0716423   -0.184853      0.166021      0.0392359
 -0.131824     0.118152     0.0535754   -0.0116789    0.0202959   -0.0356005   -0.110438    -0.102173    -0.0571138    0.0868731   -0.136162      0.22442      0.149726    -0.139613     0.0363353   -0.0809257    -0.0175803   -0.0156972   -0.0149705    0.112566     0.115219     -0.051413    -0.0503879   -0.091671     -0.0280003    -0.177836
 -0.0664671   -0.222039    -0.139758     0.0314744    0.0602012   -0.103163     0.0898988   -0.0504754    0.0943613   -0.0602039    0.113108     -0.0344904    0.163617     0.0382722    0.162094     0.000976663   0.00807181  -0.0679394   -0.0335606   -0.0383814    0.00813597   -0.0378738   -0.0225101    0.105034     -0.0294467    -0.271257
 -0.0780455   -0.0237876   -0.07032      0.0668834    0.168091     0.0536812   -0.0966039   -0.0266055    0.0712047   -0.00460551   0.0398587     0.146091    -0.0636558   -0.111211    -0.0374753   -0.261216      0.074653     0.022838    -0.184016    -0.155406    -0.119932      0.129454    -0.0660769    0.101087     -0.172559      0.00398592
  0.123666    -0.0731992   -0.0306926    0.133225     0.0789322    0.0892765    0.0615222   -0.10335      0.0773901    0.204498    -0.0505477    -0.0537012    0.0325119    0.00623967   0.0455533    0.0267893     0.137366    -0.0614774   -0.179046    -0.0770376    0.0457949    -0.0335938   -0.100407     0.128422      0.0472481     0.0432557
  0.0612609   -0.048862    -0.0881115    0.112938    -0.0763569    0.082456     0.184714    -0.0124464    0.0392067    0.104762    -0.0894369     0.0712791    0.0692228   -0.109649    -0.00232796   0.129621      0.0750502    0.0791811   -0.0643247    0.0419667    0.151011     -0.0307412    0.038688    -0.0875016     0.0402663    -0.130348
 -0.0690142    0.0873532    0.0240576    0.0724096    0.111304    -0.0206848   -0.0546719    0.0112149    0.110734     0.0239619    0.118508     -0.0435153    0.0229865   -0.0486675   -0.0563698   -0.00761667    0.0466754    0.00103962  -0.122202    -0.200431    -0.0398842    -0.059574    -0.0577997    0.0746365    -0.025812     -0.0404542
  0.0291675    0.0248954   -0.0568205   -0.145151     0.0121305   -0.0904893   -0.0411988    0.0601438    0.0291469   -0.0926527    0.0422607    -0.0684068    0.00694383  -0.0206956    0.00355623   0.0761164     0.119607     0.075088    -0.0519571   -0.210058    -0.0143846     0.0118164    0.0246261   -0.0646295     0.135489      0.00854656
 -0.0376991   -0.0898155   -0.0263125   -0.0899885   -0.0811114   -0.0382583   -0.0127845    0.0202339   -0.075945     0.0509506    0.165096      0.06296      0.0935796   -0.089438    -0.0231879    0.0586736     0.0699812    0.0128997    0.347008    -0.125619    -0.0637866    -0.013211    -0.129389    -0.0625397    -0.042706      0.095198
  0.186746    -0.0469953   -0.0117212    0.0412612    0.240616    -0.0279172    0.00395398  -0.128886     0.0511115   -0.0746833   -0.243184     -0.233889     0.110684     0.00712901   0.168899    -0.00683132    0.13665     -0.035894    -0.0478605    0.102687     0.107195      0.168523    -0.0525029    0.119069      0.0209466    -0.0474152
 -0.08291     -0.241244     0.0106261    0.14666      0.0470813   -0.0723479    0.0634125    0.222253    -0.132287    -0.0795414   -0.134765     -0.0443456    0.112109    -0.0652784    0.065228     0.0913727     0.0986267   -0.136034    -0.0114782    0.0279981   -0.158665     -0.120524    -0.1889      -0.202962     -0.131785      0.0242302
 -0.146319     0.0145613    0.121417    -0.132045     0.140625     0.0799788    0.0475213   -0.0238751    0.0452765   -0.0394615    0.0400699     0.151828     0.0764442    0.0984939    0.179291    -0.14051       0.0890168   -0.0572477    0.0170156    0.0849739   -0.199027      0.182845     0.0829398    0.000529638   0.0121342    -0.0337201
  0.190401     0.0644266   -0.150637     0.0994346    0.0283437   -0.0720136   -0.0697067   -0.0792928   -0.144369     0.106357    -0.065574     -0.0537548    0.0106581    0.0510235   -0.0628493   -0.113578      0.0327181    0.0884914   -0.0855687   -0.0602103   -0.000111904  -0.0220549    0.106099    -0.265049     -0.294199     -0.0321777
  0.0140115   -0.0673003    0.11183      0.0568864   -0.0163575    0.0416522   -0.203241    -0.212474    -0.0851539   -0.0962777   -0.0412191     0.114864     0.0936475    0.0129315    0.0443834   -0.06422       0.175366    -0.173418     0.120612    -0.0196039   -0.0519449     0.119812    -0.00568556   0.0331965    -0.0556985     0.161917
 -0.00764009  -0.153168     0.0165374   -0.022875    -0.00169632   0.157676     0.0156427    0.0834678    0.0267062    0.0496051    0.000533453   0.00157489  -0.127324     0.200723    -0.00620179   0.00245935   -0.0467316    0.153787    -0.0704928    0.0196139    0.116924      0.0462011    0.0809207    0.107928     -0.0593439     0.161039
 -0.106967    -0.0794356    0.0740133   -0.173886     0.0350696   -0.202053    -0.0411902   -0.0419783   -0.0532335    0.103211     0.197971     -0.00163307  -0.103275     0.0149434   -0.181211    -0.170604      0.024106    -0.131781     0.0132511    0.14704     -0.0390721     0.10679      0.0681622   -0.266625      0.0332267     0.10183
 -0.105469     0.0571563   -0.00737658  -0.014857    -0.0410555    0.00939629  -0.0596254    0.0183599   -0.0306788    0.0346884    0.0278834    -0.070542     0.00334971  -0.143805     0.0710888   -0.111709     -0.17482     -0.0604433    0.0483971    0.0338394    0.0169928    -0.0799406   -0.024115     0.217096     -0.0437422    -0.0887898
  0.00370005  -0.0944198    0.0079574    0.00604692   0.0464721   -0.00820801  -0.177138    -0.0654005    0.070147    -0.206151    -0.111093     -0.222789    -0.0832102    0.0104624   -0.0625783    0.109536      0.0316223   -0.0250855    0.0805538    0.204279     0.0761327    -0.0785527   -0.019712    -0.151951      0.155639     -0.0549208
  0.177993     0.0973993    0.0153384   -0.0486471   -0.0851134   -0.0115643   -0.0415925    0.0613685    0.119413    -0.0316451    0.0405332     0.096925     0.00193423   0.0719091    0.0883141   -0.105396     -0.0953908    0.0676882    0.0640211   -0.059007    -0.141209     -0.135565     0.0414103   -0.047363      0.0763546    -0.152094
 -0.0715011    0.0755834   -0.102011     0.0320472    0.0953775   -0.119374    -0.0088189    0.0761876   -0.139749     0.0332888   -0.0484301    -0.0686786    0.135427     0.0383605   -0.00415739   0.0643573     0.111511    -0.0773822    0.230017     0.0946764   -0.0164359     0.00956302  -0.241277    -0.019436      0.10663      -0.104
 -0.178108     0.0077545   -0.148448     0.0343937    0.0471462   -0.0931241    0.00599789  -0.0633467    0.050518    -0.106094     0.0117353     0.145283    -0.0490795    0.0910712   -0.0349212    0.0225581    -0.0900788   -0.0931667    0.126793    -0.133324     0.0865451    -0.025431     0.170108     0.050294     -0.0945579     0.0157481
 -0.0391877    0.0648813    0.0294072    0.105102     0.0392812   -0.203807    -0.101125     0.169124     0.0756488   -0.126015     0.00706461   -0.13101      0.0502026   -0.0532088   -0.00885891   0.082782     -0.0403244   -0.15019     -0.0315388   -0.0185656    0.142957     -0.0383033   -0.189556    -0.00121902    0.120032     -0.0614364
 -0.0640573    0.0946412    0.148797     0.0424369   -0.127313     0.13006     -0.139307     0.0738227   -0.0822869   -0.153458     0.0446299    -0.0553089    0.0679128   -0.172922    -0.107871     0.0424232     0.0676968   -0.0350566    0.0703322    0.111035    -0.163851     -0.116968     0.103332     0.0317103    -0.250843      0.1995kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3947727446406906
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.394847
[ Info: iteration 2, average log likelihood -1.394773
[ Info: iteration 3, average log likelihood -1.394236
[ Info: iteration 4, average log likelihood -1.387203
[ Info: iteration 5, average log likelihood -1.367486
[ Info: iteration 6, average log likelihood -1.360997
[ Info: iteration 7, average log likelihood -1.360197
[ Info: iteration 8, average log likelihood -1.359880
[ Info: iteration 9, average log likelihood -1.359695
[ Info: iteration 10, average log likelihood -1.359573
[ Info: iteration 11, average log likelihood -1.359483
[ Info: iteration 12, average log likelihood -1.359413
[ Info: iteration 13, average log likelihood -1.359355
[ Info: iteration 14, average log likelihood -1.359301
[ Info: iteration 15, average log likelihood -1.359241
[ Info: iteration 16, average log likelihood -1.359163
[ Info: iteration 17, average log likelihood -1.359050
[ Info: iteration 18, average log likelihood -1.358906
[ Info: iteration 19, average log likelihood -1.358775
[ Info: iteration 20, average log likelihood -1.358680
[ Info: iteration 21, average log likelihood -1.358614
[ Info: iteration 22, average log likelihood -1.358567
[ Info: iteration 23, average log likelihood -1.358534
[ Info: iteration 24, average log likelihood -1.358510
[ Info: iteration 25, average log likelihood -1.358492
[ Info: iteration 26, average log likelihood -1.358478
[ Info: iteration 27, average log likelihood -1.358468
[ Info: iteration 28, average log likelihood -1.358460
[ Info: iteration 29, average log likelihood -1.358453
[ Info: iteration 30, average log likelihood -1.358449
[ Info: iteration 31, average log likelihood -1.358445
[ Info: iteration 32, average log likelihood -1.358442
[ Info: iteration 33, average log likelihood -1.358440
[ Info: iteration 34, average log likelihood -1.358438
[ Info: iteration 35, average log likelihood -1.358437
[ Info: iteration 36, average log likelihood -1.358436
[ Info: iteration 37, average log likelihood -1.358435
[ Info: iteration 38, average log likelihood -1.358435
[ Info: iteration 39, average log likelihood -1.358434
[ Info: iteration 40, average log likelihood -1.358434
[ Info: iteration 41, average log likelihood -1.358433
[ Info: iteration 42, average log likelihood -1.358433
[ Info: iteration 43, average log likelihood -1.358433
[ Info: iteration 44, average log likelihood -1.358433
[ Info: iteration 45, average log likelihood -1.358433
[ Info: iteration 46, average log likelihood -1.358432
[ Info: iteration 47, average log likelihood -1.358432
[ Info: iteration 48, average log likelihood -1.358432
[ Info: iteration 49, average log likelihood -1.358432
[ Info: iteration 50, average log likelihood -1.358432
┌ Info: EM with 100000 data points 50 iterations avll -1.358432
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.394846666800681
│     -1.3947729133732527
│      ⋮
└     -1.358432123477545
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.358541
[ Info: iteration 2, average log likelihood -1.358445
[ Info: iteration 3, average log likelihood -1.358127
[ Info: iteration 4, average log likelihood -1.355067
[ Info: iteration 5, average log likelihood -1.344190
[ Info: iteration 6, average log likelihood -1.333613
[ Info: iteration 7, average log likelihood -1.329981
[ Info: iteration 8, average log likelihood -1.328820
[ Info: iteration 9, average log likelihood -1.328198
[ Info: iteration 10, average log likelihood -1.327754
[ Info: iteration 11, average log likelihood -1.327373
[ Info: iteration 12, average log likelihood -1.327006
[ Info: iteration 13, average log likelihood -1.326624
[ Info: iteration 14, average log likelihood -1.326176
[ Info: iteration 15, average log likelihood -1.325595
[ Info: iteration 16, average log likelihood -1.324848
[ Info: iteration 17, average log likelihood -1.323969
[ Info: iteration 18, average log likelihood -1.322976
[ Info: iteration 19, average log likelihood -1.321881
[ Info: iteration 20, average log likelihood -1.320769
[ Info: iteration 21, average log likelihood -1.319786
[ Info: iteration 22, average log likelihood -1.319023
[ Info: iteration 23, average log likelihood -1.318464
[ Info: iteration 24, average log likelihood -1.318050
[ Info: iteration 25, average log likelihood -1.317741
[ Info: iteration 26, average log likelihood -1.317512
[ Info: iteration 27, average log likelihood -1.317338
[ Info: iteration 28, average log likelihood -1.317198
[ Info: iteration 29, average log likelihood -1.317079
[ Info: iteration 30, average log likelihood -1.316969
[ Info: iteration 31, average log likelihood -1.316857
[ Info: iteration 32, average log likelihood -1.316722
[ Info: iteration 33, average log likelihood -1.316530
[ Info: iteration 34, average log likelihood -1.316244
[ Info: iteration 35, average log likelihood -1.315818
[ Info: iteration 36, average log likelihood -1.315203
[ Info: iteration 37, average log likelihood -1.314465
[ Info: iteration 38, average log likelihood -1.313905
[ Info: iteration 39, average log likelihood -1.313600
[ Info: iteration 40, average log likelihood -1.313452
[ Info: iteration 41, average log likelihood -1.313376
[ Info: iteration 42, average log likelihood -1.313327
[ Info: iteration 43, average log likelihood -1.313285
[ Info: iteration 44, average log likelihood -1.313239
[ Info: iteration 45, average log likelihood -1.313182
[ Info: iteration 46, average log likelihood -1.313107
[ Info: iteration 47, average log likelihood -1.313010
[ Info: iteration 48, average log likelihood -1.312905
[ Info: iteration 49, average log likelihood -1.312802
[ Info: iteration 50, average log likelihood -1.312714
┌ Info: EM with 100000 data points 50 iterations avll -1.312714
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3585413691988153
│     -1.358445471870547
│      ⋮
└     -1.31271442654286
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.312777
[ Info: iteration 2, average log likelihood -1.312584
[ Info: iteration 3, average log likelihood -1.312076
[ Info: iteration 4, average log likelihood -1.307967
[ Info: iteration 5, average log likelihood -1.294457
[ Info: iteration 6, average log likelihood -1.282462
[ Info: iteration 7, average log likelihood -1.277948
[ Info: iteration 8, average log likelihood -1.275566
[ Info: iteration 9, average log likelihood -1.273310
[ Info: iteration 10, average log likelihood -1.271003
[ Info: iteration 11, average log likelihood -1.268933
[ Info: iteration 12, average log likelihood -1.267114
[ Info: iteration 13, average log likelihood -1.265351
[ Info: iteration 14, average log likelihood -1.263435
[ Info: iteration 15, average log likelihood -1.261180
[ Info: iteration 16, average log likelihood -1.258735
[ Info: iteration 17, average log likelihood -1.256187
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.253795
[ Info: iteration 19, average log likelihood -1.269276
[ Info: iteration 20, average log likelihood -1.263363
[ Info: iteration 21, average log likelihood -1.260844
[ Info: iteration 22, average log likelihood -1.258983
[ Info: iteration 23, average log likelihood -1.257229
[ Info: iteration 24, average log likelihood -1.255676
[ Info: iteration 25, average log likelihood -1.254094
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.252391
[ Info: iteration 27, average log likelihood -1.268413
[ Info: iteration 28, average log likelihood -1.263041
[ Info: iteration 29, average log likelihood -1.260732
[ Info: iteration 30, average log likelihood -1.258941
[ Info: iteration 31, average log likelihood -1.257081
[ Info: iteration 32, average log likelihood -1.255243
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.253411
[ Info: iteration 34, average log likelihood -1.268268
[ Info: iteration 35, average log likelihood -1.263056
[ Info: iteration 36, average log likelihood -1.260824
[ Info: iteration 37, average log likelihood -1.259095
[ Info: iteration 38, average log likelihood -1.257258
[ Info: iteration 39, average log likelihood -1.255368
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.253498
[ Info: iteration 41, average log likelihood -1.268243
[ Info: iteration 42, average log likelihood -1.263052
[ Info: iteration 43, average log likelihood -1.260848
[ Info: iteration 44, average log likelihood -1.259146
[ Info: iteration 45, average log likelihood -1.257322
[ Info: iteration 46, average log likelihood -1.255413
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.253524
[ Info: iteration 48, average log likelihood -1.268235
[ Info: iteration 49, average log likelihood -1.263051
[ Info: iteration 50, average log likelihood -1.260860
┌ Info: EM with 100000 data points 50 iterations avll -1.260860
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3127769727671488
│     -1.3125836580860941
│      ⋮
└     -1.2608596491623343
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.259373
[ Info: iteration 2, average log likelihood -1.257271
[ Info: iteration 3, average log likelihood -1.253576
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.239647
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.215051
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.200046
[ Info: iteration 7, average log likelihood -1.188982
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.167688
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.179645
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.172937
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.163661
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.171066
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.170665
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      9
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.171240
[ Info: iteration 15, average log likelihood -1.186942
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.162814
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.165090
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.175052
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.164651
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.156519
[ Info: iteration 21, average log likelihood -1.168211
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.152748
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.166232
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.174829
[ Info: iteration 25, average log likelihood -1.183921
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.167988
[ Info: iteration 27, average log likelihood -1.169306
[ Info: iteration 28, average log likelihood -1.150311
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.135681
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.181041
[ Info: iteration 31, average log likelihood -1.188046
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.167695
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.164804
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      9
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.164988
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.176683
[ Info: iteration 36, average log likelihood -1.170677
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.153202
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.171285
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.163346
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.161550
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.156944
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.177059
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.165815
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.159288
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.153476
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.172640
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.175999
[ Info: iteration 48, average log likelihood -1.173388
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.152828
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.178567
┌ Info: EM with 100000 data points 50 iterations avll -1.178567
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2593729596885377
│     -1.2572706204219162
│      ⋮
└     -1.1785669805049641
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.171114
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.151906
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     23
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.144652
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     12
│     15
│     18
│     19
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.125183
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     12
│     17
│     23
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.105858
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.065781
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      4
│      7
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.075752
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.105361
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      5
│      8
│     10
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.051050
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      9
│     16
│     18
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.062654
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│     12
│     15
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.078818
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      8
│      9
│     11
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.071646
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      7
│     10
│     12
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.044446
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.092243
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      4
│      5
│      8
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.048978
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      9
│     15
│     16
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.063556
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     12
│     17
│     23
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.087400
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      8
│      9
│     11
│     12
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.061105
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      4
│      7
│     10
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.043368
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.105376
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      8
│     12
│     23
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.061540
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      9
│     10
│     12
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.045780
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│     17
│     23
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.088366
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      8
│     11
│     12
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.070151
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      7
│      9
│     15
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.045584
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     12
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.092292
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      4
│      5
│      8
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.051259
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     15
│     16
│     18
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.069469
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      9
│     12
│     17
│     23
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.082575
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      8
│     11
│     12
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.066338
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      4
│      7
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.041707
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     12
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.102622
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      8
│      9
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.055376
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     15
│     16
│     18
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.059707
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│     10
│     12
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.076634
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      8
│      9
│     11
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.069844
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      7
│     12
│     15
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.047503
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     11
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.089463
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      4
│      5
│      8
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.053874
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│     11
│     12
│     15
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.063063
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     17
│     23
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.088368
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      8
│     10
│     12
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.061616
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      4
│      7
│     11
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.039287
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.104793
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      8
│      9
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.054701
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│     11
│     12
│     15
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.052133
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│      9
│     10
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.082869
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     12
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.076727
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      4
│      7
│      9
│     10
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.038569
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.100383
┌ Info: EM with 100000 data points 50 iterations avll -1.100383
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1711140236408855
│     -1.1519061744543326
│      ⋮
└     -1.1003825599649688
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3947727446406906
│     -1.394846666800681
│     -1.3947729133732527
│     -1.3942363796732966
│      ⋮
│     -1.0767273125210455
│     -1.0385693415013955
└     -1.1003825599649688
32×26 Array{Float64,2}:
 -0.00899098   0.0241185   0.222414    -0.0362862     0.112732    -0.0394379    0.203275      0.0530147    0.0183803    0.151126    -0.11906      -0.0784497    0.0861175    0.0339832    0.0525741    0.125928    -0.0567308    -0.0740455    0.107015   -0.210778     0.0301864    0.000986032  -0.0569746    0.118162    -0.0215545   0.136995
 -0.0908457    0.0512921   0.0207441   -0.0286718    -0.0296741    0.0227915   -0.0238917    -0.0087907   -0.0229893    0.151933     0.00847492   -0.0586362    0.0122867   -0.153038     0.0511285   -0.111417    -0.218417     -0.0603704    0.0307989   0.0498582   -0.0212059   -0.0722739     0.0202605    0.194941    -0.0355564  -0.0928381
 -0.147532     0.120987    0.0450582   -0.0458804     0.0431411   -0.00782333  -0.109311     -0.0925264   -0.0840607    0.130065    -0.13943       0.227907     0.120507    -0.148387     0.035105    -0.133409    -0.0221027    -0.0924674   -0.0417304   0.130004     0.128075    -0.0514149    -0.0645502   -0.0828874   -0.0320995  -0.185267
  0.0510387   -0.013979   -0.0807798    0.110264     -0.067656     0.112739     0.173806     -0.0406157    0.00536796   0.0934378   -0.0923059     0.0697678    0.0861732   -0.108444     0.00739474   0.12043      0.0725916     0.0744385   -0.0593926   0.0345111    0.111173    -0.0307975     0.0301133   -0.131029     0.0371725  -0.113703
 -0.0359311    0.0714914  -0.0181749   -0.020046      0.0808412    0.0589355   -0.0025884    -0.0309916   -0.0438124    0.129515     0.0423136     0.103156     0.0407643    0.0382035    0.109851    -0.0108182    0.0343986    -0.0417008   -0.085024    0.0606574    0.0263571   -0.0623795     0.0793936   -0.183448     0.138729    0.0383613
  0.0979972    0.0601352   0.174468    -0.0392742     0.266672     0.0653068   -0.0474789     0.0337452    0.178931    -0.078633    -0.0863926     0.0237055   -0.0927254    0.0241886    0.06017     -0.0785239    0.0718169     0.0798625   -0.151258   -0.0107786    0.0772057   -0.164929      0.153904     0.0722387   -0.0474879  -0.095296
 -0.00841219   0.0284268  -0.0173131   -0.136468      0.0124155   -0.0834288   -0.0419032     0.0548779    0.0237468   -0.0725812    0.0448314    -0.0639833   -0.018207    -0.0195911    0.00169848   0.0658699    0.105383      0.0738678   -0.0395706  -0.204405    -0.0108541   -0.0289342     0.0490748   -0.0617184    0.151898    0.000824077
 -0.00290032  -0.0881613   0.00827497   0.00639533    0.0462769   -0.00825024  -0.188137     -0.0677763    0.0711167   -0.187386    -0.112041     -0.230563    -0.0831237    0.0386031   -0.0682674    0.103181    -0.00509329    0.0945524    0.0502714   0.229271     0.0904986   -0.0802152    -0.0543259   -0.133883     0.155149   -0.0545617
  0.0803258    0.681148    0.106408     0.0369756    -1.75792e-5   0.0552897   -0.0633019     0.262295    -0.303794    -0.0915279   -0.0583085    -0.0500928   -0.0526195   -1.01282      0.0482932   -0.0127718   -0.00844031    0.0314984    0.014021    0.025379     0.118996     0.0325651     0.15997     -0.0333485   -0.446148    0.128518
  0.0159816   -0.136385    0.105513    -0.0435913     0.0260245    0.0515105   -0.0834022    -0.12403      0.0397016   -0.0874561   -0.0683024    -0.0609649   -0.029127     0.585847     0.175733    -0.0145731   -0.000396801   0.0250691   -0.321038    0.0199065    0.113062    -0.167246      0.183101    -0.0125198   -0.156556    0.142031
 -0.0660504    0.103954    0.138012     0.0507305    -0.144472     0.129136    -0.142868      0.070854    -0.0920574   -0.14155      0.0569211    -0.0523322    0.0819912   -0.16678     -0.107291     0.0434703    0.0665944    -0.0385536    0.0922846   0.0979619   -0.193819    -0.131737      0.0898408    0.03011     -0.258931    0.193621
  0.183314     0.0955628   0.0191126   -0.0477731    -0.0973376   -0.00736298  -0.0442968     0.0462846    0.118884    -0.0279513    0.0512454     0.115319    -0.022736     0.0710102    0.0854212   -0.102387    -0.0950804     0.0672369    0.113615   -0.0415313   -0.148169    -0.125033      0.0557099   -0.0478683    0.0606739  -0.171034
 -0.0217591   -0.0281781   0.060859    -0.000257887   0.0290118   -0.0350217   -0.0570824    -0.0597224   -0.0934312   -0.0214276    0.0267814     0.0641821    0.0631886   -0.0214225    0.0400069   -0.0127921    0.0983008     0.00797709   0.115722    0.0176563   -0.00383511   0.0143739    -0.0374671    0.0660547   -0.0259462   0.11389
 -0.0171115    0.0577346  -0.0943736    0.0587723     0.0551621   -0.0850202   -0.0368631    -0.030037    -0.00788945   0.00838451   0.0123969     0.0130752   -0.0127142    0.0541175   -0.0621334   -0.0261508   -0.00475102    0.0112119   -0.0247653  -0.133259     0.0325798   -0.0170517     0.0683869   -0.0523442   -0.134502   -0.0214245
  0.0121779   -0.141348    0.0282113   -0.00578157    0.022231     0.153386     0.0128977     0.0764795    0.00546422   0.0466868   -0.0319945     0.00355709  -0.124795     0.190839     0.059452     0.00340697  -0.0252576     0.130158    -0.124848   -0.00767953   0.111255     0.0432937     0.0608803    0.0966327   -0.066977    0.16657
  0.105243    -0.178607    0.0790172   -0.087772      0.0404177    0.133674     0.0834118     0.0649136   -0.137489     0.0815398    0.0451743    -0.0797755   -0.0615442    0.103037     0.0452282   -0.144615     0.136005     -0.168137     0.115445   -0.0618178   -0.0174531    0.0163797    -0.105523    -0.0321975    0.122242    0.0206433
 -0.145741    -0.0683377   0.0804261   -0.179141      0.0391603   -0.192953    -0.03295      -0.0413958   -0.0948412    0.0998377    0.186939      0.00398296  -0.103306     0.0149173   -0.179897    -0.157413     0.00457396   -0.130206     0.0203412   0.164602    -0.040773     0.103873      0.071614    -0.290203     0.0686803   0.155279
 -0.182019    -0.0723234  -0.064605     0.0794772     0.200885     0.0675937   -0.0860522    -0.0141199    0.0917457   -0.0141387    0.0471648     0.143725     0.0465044   -0.153923    -0.0590442   -0.306998     0.0370467     0.0281682   -0.140388   -0.232083    -0.113507     0.149891     -0.0801807    0.0852684   -0.154532    0.101494
  0.168229     0.125853   -0.188578     0.0193873     0.071187    -0.0630989   -0.114751     -0.0805955   -0.242806     0.273868     0.0499315     0.357875    -0.0542198   -0.0405868   -0.345031     0.0583035    0.0697961    -0.00890253  -0.0262319  -0.0489712    0.0126665   -0.0265706     0.259405    -0.302807    -0.101829   -0.187042
  0.171042     0.132082   -0.183618    -0.086478      0.0653806   -0.0599252   -0.106506     -0.0792985    0.127862    -0.28653      0.0459008     0.0637207   -0.361167    -0.0410641    0.412951    -0.121057    -0.154226     -0.0121847   -0.0497941  -0.0379426   -0.0739767   -0.0442032     0.0127192    0.27449     -0.155908   -0.176997
 -0.036276     0.0923274   0.0503454    0.105791      0.0530301   -0.203224    -0.0996511     0.171422     0.0763727   -0.1072      -0.00577538   -0.13412      0.107788    -0.0325744   -0.00777204   0.10184     -0.0468203    -0.14658     -0.0290745  -0.0274484    0.161775    -0.0265661    -0.192367    -0.00403332   0.118328   -0.0755796
 -0.0765496   -0.209639   -0.0562035    0.0673058     0.0550752   -0.0737521    0.0606305     0.0701804   -0.0151383   -0.0701181   -0.000221845  -0.0205126    0.0900709   -0.0281578    0.147275     0.0285357    0.0339       -0.0900632   -0.040322   -0.0334806   -0.0914505   -0.0404594    -0.0901214   -0.0242845   -0.0770245  -0.138963
 -0.199314     0.0429231  -0.0792827    0.0326334     0.0772336   -0.114732    -0.0358333     0.0553345   -0.135712     0.0697768   -0.0331911    -0.264135     0.136973     0.0348143    0.0222502    0.0818206    0.101894     -0.137184     0.212269    0.688137    -0.020768    -0.79611      -0.23235     -0.0189343    0.0815838  -0.096614
  0.0272795    0.05801    -0.117443     0.0317111     0.0300651   -0.111478     0.0239095     0.105131    -0.146435    -0.065843    -0.0337548     0.227703     0.135467     0.0342332   -0.0379879    0.0422354    0.116442      0.00794789   0.208253   -0.670468    -0.0152246    1.11548      -0.215159    -0.0123502    0.163633   -0.0981888
  0.13023     -0.408944   -0.0162555    0.146502     -0.0540124    0.0614258    0.0471965     0.0206173    0.0784728    0.311265     0.0840625    -0.837487     0.0315723    0.00524283   0.0303917    0.0414695    0.279409     -0.0504628   -0.216193   -0.0749718    0.032003    -0.00084706   -0.100485     0.127014     0.0449481   0.0978233
  0.120153     0.18916    -0.109263     0.111167      0.162221     0.0961149    0.0701182    -0.120813     0.0799754    0.11463     -0.0984637     0.692735     0.0306582    0.00581908   0.0368595    0.0191443   -0.0075032    -0.0535808   -0.213444   -0.0803811    0.0635103   -0.0505831    -0.100383     0.121437     0.0484525  -0.00278769
  0.0323615   -0.0693883   0.035486    -0.092523      0.072898    -0.116464     0.144103     -0.00348566  -0.100967    -0.671013     0.0142364     0.0228797    0.00937655  -0.0542705   -0.0617889    0.00943572  -0.0741524    -0.00737154   0.0932295   0.108671    -0.161975     0.0599077    -0.00704133   0.0550277   -0.243836    0.0530738
  0.134209     0.0313605   0.00879467  -0.0861714     0.11107      0.109966     0.105282      0.0578157   -0.101281     0.636705     0.0229506     0.0249872    0.00134313   0.134054     0.0950374    0.00937064  -0.068728     -0.00436224   0.0789938   0.0924261   -0.199039     0.0794349    -0.00648501   0.0415551   -0.277042    0.0514535
 -0.163137    -0.150444    0.201046     0.0047443    -0.0616192   -0.0130454   -0.205236      0.0214965   -0.10729      0.133937     0.121469     -0.0741211    0.0531904   -0.196855     0.00763523   0.0222058    0.0273443    -0.0209234    0.147964   -0.254762     0.00167449  -0.70828      -0.121915     0.152593    -0.0735619  -0.0467239
 -0.232833    -0.122026    0.344464     0.0228364    -0.0716259   -0.0676527   -0.195239      0.0808605   -0.0342399   -0.364624     0.0103393    -0.059802     0.0492932   -0.212364    -0.140397     0.0264348    0.0236107    -0.0734758    0.126867   -0.245884    -0.148968     0.827603     -0.176291     0.134535    -0.0630579  -0.0576408
 -0.149868     0.0472516   0.123189    -0.142793      0.138627     0.0689047    0.0403225    -0.00315223   0.0143934   -0.00463374   0.0402027     0.141921     0.0632839    0.114675     0.167174    -0.132929     0.0779821    -0.0762499    0.0146446   0.101292    -0.199499     0.181325      0.0890023    0.00249455   0.0116291  -0.0403342
  0.17736     -0.0194798  -0.0109827    0.0350348     0.23134     -0.0127481   -0.000390624  -0.114507     0.0566812   -0.079807    -0.253963     -0.236374     0.112584     0.0386667    0.166142     0.00147978   0.146568     -0.0409202   -0.0454635   0.0893129    0.117455     0.213021     -0.0540063    0.109956     0.0206447  -0.0351559[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      4
│      5
│      8
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.050568
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      4
│      5
│      7
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.009605
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      4
│      5
│      8
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.041701
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      4
│      5
│      7
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.014004
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      4
│      5
│      8
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.044534
┌ Warning: Variances had to be floored 
│   ind =
│    21-element Array{Int64,1}:
│      1
│      4
│      5
│      7
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.006090
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      4
│      5
│      8
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.049431
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      4
│      5
│      7
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.009379
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      4
│      5
│      8
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.041599
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      4
│      5
│      7
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.014056
┌ Info: EM with 100000 data points 10 iterations avll -1.014056
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.882654e+05
      1       6.599308e+05      -2.283346e+05 |       32
      2       6.333388e+05      -2.659204e+04 |       32
      3       6.184535e+05      -1.488530e+04 |       32
      4       6.075638e+05      -1.088972e+04 |       32
      5       6.006976e+05      -6.866161e+03 |       32
      6       5.970434e+05      -3.654226e+03 |       32
      7       5.948621e+05      -2.181286e+03 |       32
      8       5.932058e+05      -1.656307e+03 |       32
      9       5.912829e+05      -1.922883e+03 |       32
     10       5.897136e+05      -1.569242e+03 |       32
     11       5.889955e+05      -7.181633e+02 |       32
     12       5.887070e+05      -2.885018e+02 |       32
     13       5.885699e+05      -1.370722e+02 |       32
     14       5.884937e+05      -7.623502e+01 |       32
     15       5.884333e+05      -6.039555e+01 |       32
     16       5.883656e+05      -6.763897e+01 |       32
     17       5.882846e+05      -8.103126e+01 |       32
     18       5.881898e+05      -9.482403e+01 |       32
     19       5.880342e+05      -1.556294e+02 |       32
     20       5.878881e+05      -1.460245e+02 |       32
     21       5.877894e+05      -9.877427e+01 |       32
     22       5.877447e+05      -4.466546e+01 |       31
     23       5.877211e+05      -2.360104e+01 |       31
     24       5.877097e+05      -1.136355e+01 |       29
     25       5.877037e+05      -6.031926e+00 |       27
     26       5.876994e+05      -4.279633e+00 |       21
     27       5.876963e+05      -3.148843e+00 |       26
     28       5.876938e+05      -2.437119e+00 |       22
     29       5.876922e+05      -1.607165e+00 |       21
     30       5.876905e+05      -1.699191e+00 |       24
     31       5.876887e+05      -1.787372e+00 |       23
     32       5.876872e+05      -1.546681e+00 |       20
     33       5.876857e+05      -1.473098e+00 |       21
     34       5.876844e+05      -1.351518e+00 |       16
     35       5.876837e+05      -6.944115e-01 |       12
     36       5.876829e+05      -7.506252e-01 |       15
     37       5.876812e+05      -1.725481e+00 |       17
     38       5.876788e+05      -2.378591e+00 |       21
     39       5.876767e+05      -2.066031e+00 |       20
     40       5.876747e+05      -2.095947e+00 |       17
     41       5.876731e+05      -1.558508e+00 |       19
     42       5.876707e+05      -2.393616e+00 |       23
     43       5.876677e+05      -3.009743e+00 |       21
     44       5.876652e+05      -2.518062e+00 |       24
     45       5.876626e+05      -2.525830e+00 |       20
     46       5.876602e+05      -2.417723e+00 |       21
     47       5.876565e+05      -3.709133e+00 |       22
     48       5.876514e+05      -5.146254e+00 |       26
     49       5.876466e+05      -4.820512e+00 |       24
     50       5.876433e+05      -3.278180e+00 |       21
K-means terminated without convergence after 50 iterations (objv = 587643.274835211)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.313361
[ Info: iteration 2, average log likelihood -1.281877
[ Info: iteration 3, average log likelihood -1.250328
[ Info: iteration 4, average log likelihood -1.212209
[ Info: iteration 5, average log likelihood -1.168395
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      4
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.112925
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     13
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.079570
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     11
│     20
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.094469
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.108861
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      4
│      7
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.084899
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.093681
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     15
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.050242
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      9
│     13
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.067400
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.090832
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.079810
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     15
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.077714
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     12
│     18
│     21
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.062896
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│     11
│     13
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.076826
[ Info: iteration 19, average log likelihood -1.104020
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     14
│     15
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.031566
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      9
│     11
│     21
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.068427
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     17
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.102848
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.086817
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     14
│     15
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.029259
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     11
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.072365
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     17
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.087146
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     13
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.080911
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     14
│     15
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.058381
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     18
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.078308
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.080512
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     12
│     13
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.043858
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     11
│     14
│     15
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.064430
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.109683
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.064776
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     12
│     13
│     14
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.043010
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     15
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.079775
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.090206
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     11
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.069266
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.054269
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     15
│     17
│     20
│     21
│     24
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.041486
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.094100
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.064546
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     12
│     13
│     14
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.025768
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     11
│     20
│     21
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.062025
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.075819
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.054851
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     12
│     13
│     14
│     15
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.045865
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     20
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.073258
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.062465
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      6
│     11
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.054516
┌ Info: EM with 100000 data points 50 iterations avll -1.054516
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0980431    0.0604258   0.175042   -0.0383168    0.260624     0.0659669   -0.045648     0.033055     0.181726   -0.0805915   -0.0829859    0.0199942   -0.0897009    0.0251324     0.0591116    -0.0759763     0.0680756    0.0725219   -0.147099   -0.0132522    0.0765206    -0.164022     0.157859     0.0677447   -0.0466804  -0.0968658
 -0.0941987   -0.0303736   0.275036    0.0854359    0.0602866   -0.0633518   -0.0287997    0.0780613   -0.180659   -0.119076    -0.0164868   -0.147828     0.10462      0.0295927     0.106971      0.00133129    0.0518211    0.0709833   -0.0323247   0.0727655    0.102644     -0.0690587   -0.0804292    0.0714114   -0.0343146   0.11407
 -0.198897    -0.137018    0.270032    0.0143642   -0.065802    -0.0379307   -0.202409     0.0509112   -0.0700851  -0.116362     0.06065     -0.0663204    0.0514402   -0.207772     -0.0681839     0.0237677     0.0225746   -0.0460713    0.139415   -0.253165    -0.0731953     0.0750197   -0.151635     0.144321    -0.0672276  -0.0561733
 -0.144955    -0.0661486   0.0795874  -0.177921     0.040278    -0.193488    -0.0316668   -0.0415951   -0.0931355   0.0981497    0.186579     0.00301132  -0.102072     0.017605     -0.179061     -0.158066      0.00574939  -0.1297       0.0185958   0.161492    -0.0407768     0.104039     0.0705527   -0.289646     0.0692083   0.154546
 -0.0840698   -0.243855    0.0212298   0.14742      0.00448912  -0.0838749    0.058989     0.222217    -0.145023   -0.089604    -0.149719    -0.0409889    0.108675    -0.0772532     0.103264      0.0876766     0.0621698   -0.138157    -0.013108   -0.00850482  -0.18055      -0.116044    -0.173648    -0.200649    -0.138016    0.0281136
 -0.104673     0.0591872  -0.0999832   0.0321362    0.067246    -0.115531    -0.00921164   0.0759443   -0.14457     0.0162198   -0.0386055   -0.07547      0.137057     0.0380562    -0.000287727   0.0729637     0.106447    -0.0799767    0.222838    0.162005    -0.0186198    -0.0240763   -0.231872    -0.0171371    0.120695   -0.102927
  0.206291     0.126139   -0.186095   -0.0262752    0.0485299   -0.0525158   -0.125612    -0.108245    -0.0722168  -0.105675     0.0616038    0.292402    -0.322826    -0.0781276     0.126944     -0.0116968    -0.044681    -0.0525362    0.0282137  -0.0257999   -0.059101     -0.0318135    0.188955    -0.0800628   -0.188539   -0.0986588
  0.0638883    0.103285    0.0764973  -0.00396678  -0.112446     0.0587516   -0.091618     0.0560332    0.0155497  -0.0833989    0.0475534    0.0284993    0.0281033   -0.0432843    -0.00147406   -0.0263829    -0.0196868    0.020079     0.0990169   0.0207332   -0.150744     -0.12952      0.0748786   -0.0134375   -0.095218    0.00569496
 -0.0111491    0.0598673  -0.142522   -0.0291056    0.0566815    0.023401    -0.0711085   -0.0248107   -0.0773947  -0.0288941    0.0279062   -0.0406592    0.0244012    0.0370114     0.0492941    -0.00110086    0.0634881    1.70019e-5   0.0364984  -0.0328922    0.000714775  -0.068292     0.0394073   -0.167729     0.10272     0.0192415
 -0.040897    -0.0918259  -0.0333818  -0.0818302   -0.0494454   -0.0430482   -0.019947     0.0154564   -0.0952924   0.0662784    0.160479     0.0700189    0.0796714   -0.0662003    -0.0225831     0.0501557     0.0741033   -0.00994991   0.360683   -0.125696    -0.0719622    -0.0124182   -0.127549    -0.0497842   -0.0407516   0.0786295
  0.111748    -0.179974    0.08806    -0.0884212    0.0572493    0.146026     0.0800311    0.0510913   -0.129955    0.0844424    0.0387813   -0.0834406   -0.0608268    0.106062      0.0620074    -0.146315      0.139868    -0.129052     0.073701   -0.0606073   -0.00518724    0.0199917   -0.124414    -0.00912196   0.0896189   0.0199622
 -0.0884955   -0.0345083  -0.0757441   0.0661241    0.164502     0.0455144   -0.0969861   -0.0309893    0.0588216  -0.00414793   0.0394199    0.158084    -0.0570811   -0.0978347    -0.0241844    -0.246404      0.0292245    0.0192779   -0.176669   -0.179734    -0.118722      0.12036     -0.0821243    0.0926434   -0.157712    0.0300685
  0.0300846    0.121474   -0.107632   -0.0606272    0.0916247   -0.100281     0.0206341   -0.128348    -0.0279709   0.0662767   -0.0171475    0.306057    -0.00842105  -0.0786992     0.0106813     0.0268674     0.0699573    0.168313     0.0623194   0.164638     0.00246721    0.0548427    0.102686     0.309746     0.0355104   0.0767175
  0.187041    -0.0144704  -0.0138634   0.0302985    0.23372     -0.0191966   -0.00110827  -0.114492     0.0445435  -0.0834954   -0.242848    -0.229219     0.110622     0.0371832     0.164966     -0.000992627   0.13159     -0.0406917   -0.0481395   0.0973172    0.111438      0.197736    -0.0514799    0.112967     0.0295455  -0.0468812
  0.013965    -0.144458    0.0224296  -0.0107454    0.0106627    0.147689     0.0127379    0.0725654    0.0139964   0.0483909   -0.0233484    0.0016297   -0.126612     0.197667      0.0597102     0.00274667   -0.0318067    0.122768    -0.110017   -0.00806632   0.112936      0.0465194    0.0797997    0.083098    -0.0705833   0.16328
 -0.0646389    0.0828908   0.0205135   0.0864544    0.110127    -0.0201607   -0.0509591    0.0237994    0.122455    0.0130994    0.136189    -0.0425409    0.0134045   -0.0428972    -0.0811405    -0.0310903     0.0364114    0.0144387   -0.120815   -0.213197    -0.0422136    -0.0499851   -0.0544121    0.0848441   -0.0246347  -0.0572076
 -0.0198317   -0.0736729   0.146474    0.0523309   -0.0200802    0.0512115   -0.249185    -0.194298    -0.11361    -0.113726    -0.031751     0.115274     0.152354     0.0103179     0.0582884    -0.0701625     0.159268    -0.170742     0.128554   -0.0209972   -0.0451807     0.118275     0.00543755  -0.0162974   -0.0742875   0.137971
 -0.0171888    0.0284676  -0.0162757  -0.141632     0.0118775   -0.0969182   -0.0409382    0.0589783    0.0214506  -0.0805874    0.0455205   -0.0730207   -0.0122708   -0.0179607     0.00619298    0.0705882     0.110436     0.0564065   -0.0382543  -0.199349    -0.011727     -0.0311417    0.0428848   -0.0645374    0.143823   -0.000597539
 -0.0779225    0.0557583   0.0133484  -0.0335205   -0.0194105    0.0191187   -0.0286484   -0.0110815   -0.0222963   0.135175     0.00760378  -0.0520222    0.0155675   -0.140872      0.0769391    -0.111317     -0.218547    -0.0584289    0.0281069   0.0407202   -0.0298296    -0.0728333    0.0368484    0.190437    -0.0461497  -0.0971889
 -8.83609e-5  -0.0832626   0.0223088   0.00912542   0.0453949   -0.00573784  -0.196993    -0.0847772    0.064434   -0.193624    -0.118356    -0.226617    -0.0791233    0.0213636    -0.0656547     0.099922      0.0083143    0.0820757    0.0553605   0.220169     0.0884179    -0.077186    -0.0373715   -0.135646     0.140534   -0.0400482
 -0.0371975    0.0733079  -0.0256675  -0.0155867    0.0810479    0.0561284   -0.00591171  -0.0381531   -0.0547813   0.172636     0.0421282    0.152218     0.0406328    0.0374723     0.115764     -0.00544876    0.0319303   -0.0543121   -0.0914623   0.0624431    0.0310571    -0.0626421    0.0928466   -0.181994     0.135792    0.0387559
  0.0555322    0.131269    0.102549   -0.0272137    0.0315577    0.0424481   -0.0727113   -0.00524875  -0.0729414  -0.0857244   -0.0752384   -0.0612674   -0.0432413    0.100332      0.150682     -0.0186195    -0.0117847    0.030051    -0.243145    0.0195296    0.126865     -0.102629     0.199701    -0.029455    -0.235514    0.123379
 -0.147266     0.0515012   0.122009   -0.142393     0.138827     0.0690536    0.0387369   -0.00796802   0.0194864  -0.00973408   0.0397874    0.145856     0.0646638    0.115044      0.16791      -0.130538      0.0773492   -0.0773498    0.0143642   0.0993914   -0.199848      0.179125     0.0878213    0.00348881   0.0128162  -0.0401536
 -0.00334229   0.0238294   0.229595   -0.0407299    0.109945    -0.0448825    0.198526     0.0480523    0.0195227   0.150912    -0.113137    -0.0864788    0.090201     0.0462798     0.052434      0.124571     -0.0559116   -0.0780779    0.109864   -0.200705     0.0308948     0.0130377   -0.0668729    0.110884    -0.0185673   0.134251
 -0.0362913    0.0932707   0.0499934   0.106303     0.0553598   -0.203972    -0.0998724    0.171661     0.0765082  -0.106103    -0.00492733  -0.134602     0.107118    -0.0320652    -0.00789974    0.103981     -0.0470099   -0.147219    -0.0288267  -0.0273232    0.161194     -0.0245764   -0.192765    -0.00351348   0.118131   -0.0744229
 -0.145018     0.0310018  -0.150885    0.0544634    0.0371357   -0.144123     0.00561803  -0.0602629    0.0223608  -0.110106    -0.0215679    0.154618    -0.0645329    0.116739     -0.0202866     0.0247685    -0.10062     -0.101774     0.11956    -0.139255     0.124301     -0.0136073    0.166065     0.0474894   -0.0947005   0.0119819
  0.0695504   -0.0242941  -0.0380275   0.0116191    0.00989534   0.0496815    0.160478     0.00287487  -0.0500831  -0.0115159   -0.0372653    0.0491668    0.0322161   -0.0434142    -0.000616899   0.068956      0.00251345   0.0374211    0.0118408   0.0712262   -0.0402198     0.017955     0.0158827   -0.0302292   -0.104979   -0.0236549
  0.165755     0.0658857  -0.151745    0.044705     0.0334415   -0.0714125   -0.0693823   -0.0596232   -0.141882    0.106739    -0.0549697   -0.0639565   -0.00561855   0.0641827    -0.0702664    -0.0835837     0.0341206    0.103974    -0.0749967  -0.0560022    0.00674809   -0.00652952   0.0890334   -0.25098     -0.273524   -0.0402542
 -0.130591     0.119286    0.0457769  -0.0324836    0.0319396    0.00732335  -0.090866    -0.103748    -0.077596    0.119926    -0.135962     0.214185     0.11744     -0.145153      0.0344603    -0.116966     -0.0139815   -0.0774907   -0.0483664   0.117456     0.136662     -0.0501355   -0.0546925   -0.0907443   -0.03056    -0.188239
  0.133022    -0.0421272  -0.082752    0.114198     0.0579427    0.0567181    0.0379844   -0.0571576    0.0920919   0.199345    -0.00764163   0.0478212    0.0312754    0.000410711   0.0250667     0.03098       0.129191    -0.0472262   -0.218986   -0.0672821    0.0441881    -0.0283104   -0.108655     0.131881     0.0425821   0.0265812
  0.0563787    0.0537331  -0.0373593  -0.0656306    0.0389539    0.0352692   -0.0215762   -0.132594    -0.0512898   0.062205    -0.0010116    0.0430548   -0.0390194    0.0964654     0.0215868    -0.0540089     0.136839    -0.0477276    0.0836573   0.0938204   -0.011839      0.0548603   -0.0216936    0.0174977    0.024468    0.04797
 -0.0455214   -0.211543   -0.118666    0.0058453    0.0604193   -0.0865683    0.0843186   -0.0509541    0.0716428  -0.0509794    0.112179    -0.0410467    0.0908345    0.0285525     0.185581     -0.00432538    0.00342539  -0.0655867   -0.0349657  -0.037554    -0.000170274  -0.0192472   -0.0155722    0.112012    -0.0283042  -0.260049[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     13
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.061361
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     12
│     13
│     14
│     15
│      ⋮
│     24
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.002115
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      7
│      9
│     12
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.981461
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     21
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.016502
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     12
│     13
│     14
│      ⋮
│     18
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.011431
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│     12
│     13
│     14
│      ⋮
│     22
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.007526
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│      7
│      9
│     12
│      ⋮
│     20
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.007514
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     21
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.015752
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      7
│     12
│     13
│      ⋮
│     20
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.991807
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     12
│     13
│     14
│     15
│     21
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.026139
┌ Info: EM with 100000 data points 10 iterations avll -1.026139
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.205413     -0.086921     0.0144465    0.0788108   -0.074849     0.0219337    0.200982     0.00162436   0.0133367   -0.000452356   0.0285596   -0.0732368    0.0202128    -0.0965781    0.0632473    -0.0554443   -0.139938    -0.16872      0.10224     -0.0573391    -0.0575065    0.0725537    0.00940144   -0.0627185   -0.0636391    0.0310738
  0.0154654     0.0984092   -0.0144001    0.0517706   -0.142263    -0.112114     0.105624    -0.111371     0.182086     0.124519      0.0120992    0.0452667   -0.146641     -0.0764983    0.0279728    -0.22617     -0.146527     0.099732     0.00535934  -0.080679     -0.0313026   -0.0577511   -0.1827        0.00177261   0.04961      0.143371
 -0.000546953  -0.0373502   -0.0311323   -0.121479     0.194128     0.0513847    0.10802      0.0395694    0.0685455   -0.0286433     0.104374     0.0434942   -0.00490202   -0.0171317   -0.0154766    -0.0045564   -0.0410413    0.030566     0.0165972    0.0886466    -0.0357964   -0.027337    -0.160448     -0.0161066   -0.0322757   -0.0766441
  0.000710163   0.00263628   0.219927     0.0540637    0.0381727    0.128224    -0.088958    -0.10457      0.0075323    0.22412       0.0439633   -0.0266567   -0.117517      0.00863313  -0.114258     -0.054614     0.0189454   -0.0816384    0.0475941    0.00441659   -0.0746457    0.0222067   -0.000572303  -0.0702245   -0.0730507    0.138534
 -0.0416819    -0.197766     0.0131432    0.063034     0.0389566    0.0134598   -0.00195625  -0.0514499    0.106511     0.0258175     0.0252343    0.164188     0.0727448    -0.158746    -0.0524112     0.0073843   -0.00277616   0.0395639   -0.105329    -0.00653927    0.170084     0.103509     0.0963367     0.0275779   -0.0356579   -0.0904577
 -0.109403      0.157205    -0.0582981   -0.167158    -0.187502    -0.180333     0.0942928   -0.111044     0.0252919   -0.0146619     0.0739897    0.126184     0.0876879    -0.0560899   -0.143411      0.104976     0.028074     0.25378     -0.00379092   0.0195504     0.0264382    0.131487    -0.0670545    -0.019877     0.0283953    0.00821888
  0.0139098     0.0904028   -0.278568     0.064323     0.0962025   -0.00268468   0.121347     0.0559794    0.0348856   -0.0703994     0.0516621   -0.0249992    0.201269     -0.056127    -0.0589817    -0.0571426    0.00592472  -0.0371123    0.0380328   -0.0528788    -0.0093418   -0.0440595   -0.0666954     0.0337731   -0.00804349  -0.00553985
 -0.0237124     0.0837756   -0.0378642    0.0499089   -0.0352054   -0.1206       0.0644861   -0.25245      0.0618692   -0.187724     -0.00261878  -0.114784     0.0477972    -0.0407851   -0.0550329     0.0328699   -0.0181177   -0.0643354   -0.0506257   -0.0102145     0.141592    -0.0590261   -0.00530606   -0.132472     0.0296422    0.0857454
  0.0518908    -0.150887     0.00695179  -0.204771    -0.0143765    0.137172     0.0281016   -0.0905808   -0.101047    -0.232        -0.0306154   -0.112275    -0.170494     -0.0845381    0.0703909    -0.049424    -0.0496834    0.146908     0.0546713    0.298891      0.0312084   -0.0456569    0.0853838     0.0147142   -0.0015017    0.0476174
  0.0514007     0.0154656    0.129388    -0.0861601   -0.0838246    0.029736    -0.0422497   -0.0344444    0.234982    -0.152764     -0.00114869   0.0940358    0.022004     -0.0287711   -0.000231821   0.0733066    0.00511527   0.0910175   -0.0631887    0.000664806  -0.063787     0.0961897    0.092714      0.0517131   -0.0296976   -0.107693
  0.170007      0.0377637    0.10738      0.074121    -0.158186     0.0428586    0.216527    -0.0103648    0.0357966    0.00821153   -0.0166083    0.194497    -0.00805776    0.0395835    0.0283567    -0.0196151    0.156489    -0.137634     0.0634871   -0.10251      -0.0575944   -0.0370767    0.020288     -0.0712424    0.0330645   -0.0909663
 -0.0132917    -0.143069     0.113535    -0.038169     0.0433428    0.113965     0.0335904    0.0438319    0.117117     0.0661478    -0.00476227   0.0840392   -0.0138175     0.0992018   -0.00135882    0.116211     0.0178915    0.00680947   0.0291217   -0.0737985    -0.116008     0.0120028   -0.151168      0.0179752    0.0504586    0.0101771
  0.0973758    -0.148451     0.0974365    0.104548     0.107023    -0.0408807    0.142437    -0.0318315   -0.150975     0.00986276   -0.109165    -0.0193775    0.00244625    0.0129339    0.114624     -0.13045     -0.0277364   -0.11687      0.134952    -0.115533      0.0855352    0.0317276    0.0546721    -0.111193    -0.0799535    0.0770994
 -0.102259      0.127695    -0.00687657   0.121617     0.00855497   0.117989    -0.156593     0.0146606   -0.113581     0.00898875   -0.0364386   -0.161379    -0.000399265  -0.0383418   -0.0381756    -0.080693     0.103107    -0.0180784    0.0861416   -0.02592      -0.0950122   -0.0898987    0.0410556     0.101133    -0.162133    -0.0422799
 -0.000465387  -0.05933      0.0440376    0.138858    -0.0121561    0.107663    -0.0750341    0.0253979    0.0679269    0.0376135    -0.0124697   -0.0790551   -0.133445     -0.0556921   -0.207815     -0.145561     0.0154942    0.10791      0.0438433    0.31062      -0.0159332    0.13715      0.00867505   -0.0390875   -0.068557     0.0839202
 -0.0961582     0.0516271    0.161218    -0.112343    -0.108999    -0.0633481   -0.0525455   -0.155715     0.0860201   -0.117844      0.0991084   -0.160232    -0.0655157    -0.00854989  -0.113634     -0.0375969    0.137159     0.0474817   -0.186275    -0.0198146     0.0748513    0.0488317    0.0355986    -0.0332046    0.12632      0.116465
 -0.0933325     0.168676    -0.0752967   -0.106256     0.192956    -0.0766192    0.0171648    0.159038     0.263293     0.230317      0.0664962   -0.00240239  -0.038027     -0.0544523    0.143894     -0.035275     0.150833     0.0245776   -0.00516924   0.0299472    -0.0393222    0.121619     0.0665519     0.0553275    0.0141227   -0.0324739
  0.0551586    -0.00423052   0.0464525   -0.0971834    0.11106      0.146703     0.0133305   -0.0144159   -0.0379558   -0.0170523     0.224819    -0.0709997    0.0826087     0.106435    -0.0818177    -0.0361091    0.1064      -0.129369     0.0666193    0.077012      0.0482376   -0.167224     0.0192273    -0.0525806   -0.00724605  -0.0980263
  0.0813585     0.0401215    0.012579     0.128965     0.0018156    0.0218578   -0.0018001    0.0570596    0.117959     0.0409407    -0.0212893    0.0309216    0.077533      0.0834596    0.18455       0.10328      0.0255352   -0.00462499  -0.163632     0.0314839     0.144609    -0.0718305    0.00693681    0.0854028    0.0559996   -0.141588
  0.159903     -0.0218631    0.0470012    0.298242    -0.0842378    0.0101666   -0.0226908    0.0972331   -0.078707     0.160982      0.0151514    0.0932075   -0.0878399     0.0775614    0.00227495   -0.0606272    0.0227943    0.162074     0.147186     0.0098583    -0.0923487   -0.0511164    0.0387826    -0.0747915   -0.0957572   -0.0540056
  0.010594      0.0299276    0.100958     0.190339    -0.0793549    0.248225    -0.0156186   -0.130079     0.0119198    0.131185     -0.0459458    0.0767367    0.0587203    -0.0636348   -0.0782725    -0.147049     0.0652484    0.144877     0.0310706   -0.0833351     0.0120303   -0.130521    -0.183941     -0.23871     -0.127571     0.0398376
 -0.158593      0.0168054    0.111316     0.182932    -0.330075     0.044518    -0.0972334   -0.0128946    0.172299    -0.0830658    -0.0336618   -0.104704     0.131453      0.0244763    0.0482962    -0.0712806    0.0334008   -0.0947853   -0.0234522    0.0377405     0.146947     0.0422201    0.0588303     0.0517418    0.0827282   -0.119255
 -0.0346616    -0.0503964   -0.160235     0.00058582   0.0294692    0.00719436  -0.12162      0.0878693    0.019243     0.0433189    -0.030233    -0.218512    -0.00312932   -0.0667736   -0.000857607   0.079243    -0.116761     0.00264766   0.0601866    0.0827224     0.167956    -0.040216    -0.105606     -0.0348874   -0.103726     0.151611
  0.0862074    -0.0161865    0.00280615  -0.130072    -0.133326     0.125465     0.0351211    0.0112787   -0.0339375   -0.144662      0.07458     -0.00842783   0.082602     -0.109511    -0.0197439     0.0652678    0.00902132  -0.0781946    0.0161334   -0.13815      -0.125177     0.0294041   -0.0195537     0.15518      0.00175713  -0.0406573
  0.221567     -0.0643513   -0.0105992    0.0936058   -0.0238739   -0.222987    -0.115731    -0.0610654   -0.0753856   -0.0653193    -0.0342722   -0.0943709    0.111738      0.108056     0.0210006     0.141974     0.00640132   0.139498    -0.19874      0.0888693     0.0872491   -0.0361845   -0.147946      0.148839    -0.085949     0.0847489
 -0.00206903    0.0533774   -0.232717     0.104887    -0.0773029    0.112102    -0.122662     0.174731    -0.103907    -0.0644885     0.156533     0.0587463    0.0934491    -0.0202038   -0.0298384    -0.0577077    0.0553585   -0.00978655  -0.00125301   0.0564877     0.0177792   -0.242961     0.00585963    0.00150571  -0.0537888    0.0443736
  0.0351225     0.0212989    0.103274     0.0194969    0.12951     -0.0242897    0.0216381   -0.00289669   0.125024    -0.0478029    -0.0808214    0.0398152    0.0681093     0.0335259   -0.117734      0.0728093    0.0250208   -0.0468401    0.209194     0.0754006    -0.0296086    0.137686    -0.135069      0.07376      0.0494628    0.00290962
 -0.166511     -0.00111325   0.0723375    0.00523105   0.0950723    0.0569286    0.00512658   0.0712904    0.0341333    0.0620729    -0.0713307   -0.237724     0.160569     -0.0639231   -0.109166      0.116422    -0.00327848   0.0671143   -0.131951     0.104981      0.0578568    0.0707067    0.0464589    -0.0550604   -0.028996     0.0712829
 -0.0520015    -0.143409    -0.0405681    0.00527757  -0.0698032    0.0835084    0.00846258  -0.0979684   -0.0411441    0.0941873     0.122172    -0.142889     0.20776       0.0909344    0.00181797   -0.0573455    0.0925158   -0.0728626   -0.157123    -0.00990401    0.00986189   0.221383     0.0317106    -0.12139      0.0752438   -0.0403957
 -0.0564783    -0.0436765    0.03825      0.0984096    0.0484568   -0.0752063   -0.0378273    0.0692709   -0.0638941    0.159879      0.0947695   -0.0272391    0.0896796     0.23258      0.054586     -0.00575183   0.0605741    0.0601399   -0.0892258   -0.180388     -0.0064985   -0.179108    -0.0299568     0.106547     0.256173    -0.110925
  0.0292499    -0.0071452   -0.20098     -0.133736    -0.176442    -0.0303561    0.0376459   -0.0736873    0.00530099   0.00162164   -0.0180961    0.108208    -0.0162688     0.0178203   -0.0291932    -0.0165241    0.0519681    0.133644    -0.0770951   -0.090939     -0.0277759   -0.00173714   0.0240465     0.0832306    0.0237342    0.107299
 -0.0517815    -0.0401787    0.0193008    0.0916571   -0.0357119    0.0926404    0.268117     0.0199673   -0.0344791    0.153635      0.0586189    0.111755     0.121771      0.0707753   -0.0792861    -0.0173264    0.0970745   -0.10588      0.149877    -0.0326238    -0.0680162   -0.0180707    0.0857272     0.0942217   -0.0672514   -0.0197053kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4181749037171525
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418194
[ Info: iteration 2, average log likelihood -1.418137
[ Info: iteration 3, average log likelihood -1.418097
[ Info: iteration 4, average log likelihood -1.418052
[ Info: iteration 5, average log likelihood -1.418001
[ Info: iteration 6, average log likelihood -1.417941
[ Info: iteration 7, average log likelihood -1.417876
[ Info: iteration 8, average log likelihood -1.417809
[ Info: iteration 9, average log likelihood -1.417744
[ Info: iteration 10, average log likelihood -1.417683
[ Info: iteration 11, average log likelihood -1.417625
[ Info: iteration 12, average log likelihood -1.417557
[ Info: iteration 13, average log likelihood -1.417455
[ Info: iteration 14, average log likelihood -1.417271
[ Info: iteration 15, average log likelihood -1.416918
[ Info: iteration 16, average log likelihood -1.416286
[ Info: iteration 17, average log likelihood -1.415342
[ Info: iteration 18, average log likelihood -1.414299
[ Info: iteration 19, average log likelihood -1.413496
[ Info: iteration 20, average log likelihood -1.413048
[ Info: iteration 21, average log likelihood -1.412844
[ Info: iteration 22, average log likelihood -1.412758
[ Info: iteration 23, average log likelihood -1.412722
[ Info: iteration 24, average log likelihood -1.412707
[ Info: iteration 25, average log likelihood -1.412701
[ Info: iteration 26, average log likelihood -1.412698
[ Info: iteration 27, average log likelihood -1.412696
[ Info: iteration 28, average log likelihood -1.412696
[ Info: iteration 29, average log likelihood -1.412695
[ Info: iteration 30, average log likelihood -1.412695
[ Info: iteration 31, average log likelihood -1.412694
[ Info: iteration 32, average log likelihood -1.412694
[ Info: iteration 33, average log likelihood -1.412694
[ Info: iteration 34, average log likelihood -1.412693
[ Info: iteration 35, average log likelihood -1.412693
[ Info: iteration 36, average log likelihood -1.412693
[ Info: iteration 37, average log likelihood -1.412693
[ Info: iteration 38, average log likelihood -1.412693
[ Info: iteration 39, average log likelihood -1.412693
[ Info: iteration 40, average log likelihood -1.412693
[ Info: iteration 41, average log likelihood -1.412692
[ Info: iteration 42, average log likelihood -1.412692
[ Info: iteration 43, average log likelihood -1.412692
[ Info: iteration 44, average log likelihood -1.412692
[ Info: iteration 45, average log likelihood -1.412692
[ Info: iteration 46, average log likelihood -1.412692
[ Info: iteration 47, average log likelihood -1.412692
[ Info: iteration 48, average log likelihood -1.412692
[ Info: iteration 49, average log likelihood -1.412692
[ Info: iteration 50, average log likelihood -1.412692
┌ Info: EM with 100000 data points 50 iterations avll -1.412692
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4181943693549062
│     -1.418136716868516
│      ⋮
└     -1.4126918824408108
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412711
[ Info: iteration 2, average log likelihood -1.412651
[ Info: iteration 3, average log likelihood -1.412608
[ Info: iteration 4, average log likelihood -1.412559
[ Info: iteration 5, average log likelihood -1.412501
[ Info: iteration 6, average log likelihood -1.412433
[ Info: iteration 7, average log likelihood -1.412359
[ Info: iteration 8, average log likelihood -1.412283
[ Info: iteration 9, average log likelihood -1.412210
[ Info: iteration 10, average log likelihood -1.412146
[ Info: iteration 11, average log likelihood -1.412089
[ Info: iteration 12, average log likelihood -1.412038
[ Info: iteration 13, average log likelihood -1.411991
[ Info: iteration 14, average log likelihood -1.411946
[ Info: iteration 15, average log likelihood -1.411901
[ Info: iteration 16, average log likelihood -1.411858
[ Info: iteration 17, average log likelihood -1.411817
[ Info: iteration 18, average log likelihood -1.411779
[ Info: iteration 19, average log likelihood -1.411746
[ Info: iteration 20, average log likelihood -1.411718
[ Info: iteration 21, average log likelihood -1.411696
[ Info: iteration 22, average log likelihood -1.411679
[ Info: iteration 23, average log likelihood -1.411666
[ Info: iteration 24, average log likelihood -1.411657
[ Info: iteration 25, average log likelihood -1.411650
[ Info: iteration 26, average log likelihood -1.411645
[ Info: iteration 27, average log likelihood -1.411641
[ Info: iteration 28, average log likelihood -1.411638
[ Info: iteration 29, average log likelihood -1.411636
[ Info: iteration 30, average log likelihood -1.411634
[ Info: iteration 31, average log likelihood -1.411633
[ Info: iteration 32, average log likelihood -1.411631
[ Info: iteration 33, average log likelihood -1.411630
[ Info: iteration 34, average log likelihood -1.411629
[ Info: iteration 35, average log likelihood -1.411628
[ Info: iteration 36, average log likelihood -1.411627
[ Info: iteration 37, average log likelihood -1.411626
[ Info: iteration 38, average log likelihood -1.411625
[ Info: iteration 39, average log likelihood -1.411624
[ Info: iteration 40, average log likelihood -1.411623
[ Info: iteration 41, average log likelihood -1.411622
[ Info: iteration 42, average log likelihood -1.411621
[ Info: iteration 43, average log likelihood -1.411620
[ Info: iteration 44, average log likelihood -1.411619
[ Info: iteration 45, average log likelihood -1.411618
[ Info: iteration 46, average log likelihood -1.411617
[ Info: iteration 47, average log likelihood -1.411616
[ Info: iteration 48, average log likelihood -1.411615
[ Info: iteration 49, average log likelihood -1.411614
[ Info: iteration 50, average log likelihood -1.411613
┌ Info: EM with 100000 data points 50 iterations avll -1.411613
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412711157497748
│     -1.4126507620172024
│      ⋮
└     -1.4116130660985282
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411622
[ Info: iteration 2, average log likelihood -1.411572
[ Info: iteration 3, average log likelihood -1.411528
[ Info: iteration 4, average log likelihood -1.411478
[ Info: iteration 5, average log likelihood -1.411417
[ Info: iteration 6, average log likelihood -1.411346
[ Info: iteration 7, average log likelihood -1.411264
[ Info: iteration 8, average log likelihood -1.411176
[ Info: iteration 9, average log likelihood -1.411088
[ Info: iteration 10, average log likelihood -1.411002
[ Info: iteration 11, average log likelihood -1.410921
[ Info: iteration 12, average log likelihood -1.410847
[ Info: iteration 13, average log likelihood -1.410781
[ Info: iteration 14, average log likelihood -1.410723
[ Info: iteration 15, average log likelihood -1.410675
[ Info: iteration 16, average log likelihood -1.410634
[ Info: iteration 17, average log likelihood -1.410601
[ Info: iteration 18, average log likelihood -1.410575
[ Info: iteration 19, average log likelihood -1.410553
[ Info: iteration 20, average log likelihood -1.410535
[ Info: iteration 21, average log likelihood -1.410520
[ Info: iteration 22, average log likelihood -1.410508
[ Info: iteration 23, average log likelihood -1.410497
[ Info: iteration 24, average log likelihood -1.410488
[ Info: iteration 25, average log likelihood -1.410479
[ Info: iteration 26, average log likelihood -1.410471
[ Info: iteration 27, average log likelihood -1.410464
[ Info: iteration 28, average log likelihood -1.410457
[ Info: iteration 29, average log likelihood -1.410451
[ Info: iteration 30, average log likelihood -1.410445
[ Info: iteration 31, average log likelihood -1.410439
[ Info: iteration 32, average log likelihood -1.410434
[ Info: iteration 33, average log likelihood -1.410429
[ Info: iteration 34, average log likelihood -1.410424
[ Info: iteration 35, average log likelihood -1.410419
[ Info: iteration 36, average log likelihood -1.410415
[ Info: iteration 37, average log likelihood -1.410410
[ Info: iteration 38, average log likelihood -1.410406
[ Info: iteration 39, average log likelihood -1.410402
[ Info: iteration 40, average log likelihood -1.410398
[ Info: iteration 41, average log likelihood -1.410394
[ Info: iteration 42, average log likelihood -1.410390
[ Info: iteration 43, average log likelihood -1.410386
[ Info: iteration 44, average log likelihood -1.410382
[ Info: iteration 45, average log likelihood -1.410379
[ Info: iteration 46, average log likelihood -1.410375
[ Info: iteration 47, average log likelihood -1.410371
[ Info: iteration 48, average log likelihood -1.410367
[ Info: iteration 49, average log likelihood -1.410364
[ Info: iteration 50, average log likelihood -1.410360
┌ Info: EM with 100000 data points 50 iterations avll -1.410360
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.411622318111166
│     -1.4115718467541334
│      ⋮
└     -1.410359677800259
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410366
[ Info: iteration 2, average log likelihood -1.410312
[ Info: iteration 3, average log likelihood -1.410267
[ Info: iteration 4, average log likelihood -1.410215
[ Info: iteration 5, average log likelihood -1.410154
[ Info: iteration 6, average log likelihood -1.410079
[ Info: iteration 7, average log likelihood -1.409989
[ Info: iteration 8, average log likelihood -1.409887
[ Info: iteration 9, average log likelihood -1.409776
[ Info: iteration 10, average log likelihood -1.409661
[ Info: iteration 11, average log likelihood -1.409546
[ Info: iteration 12, average log likelihood -1.409434
[ Info: iteration 13, average log likelihood -1.409328
[ Info: iteration 14, average log likelihood -1.409229
[ Info: iteration 15, average log likelihood -1.409138
[ Info: iteration 16, average log likelihood -1.409056
[ Info: iteration 17, average log likelihood -1.408983
[ Info: iteration 18, average log likelihood -1.408918
[ Info: iteration 19, average log likelihood -1.408862
[ Info: iteration 20, average log likelihood -1.408811
[ Info: iteration 21, average log likelihood -1.408767
[ Info: iteration 22, average log likelihood -1.408727
[ Info: iteration 23, average log likelihood -1.408692
[ Info: iteration 24, average log likelihood -1.408660
[ Info: iteration 25, average log likelihood -1.408631
[ Info: iteration 26, average log likelihood -1.408604
[ Info: iteration 27, average log likelihood -1.408579
[ Info: iteration 28, average log likelihood -1.408556
[ Info: iteration 29, average log likelihood -1.408535
[ Info: iteration 30, average log likelihood -1.408514
[ Info: iteration 31, average log likelihood -1.408495
[ Info: iteration 32, average log likelihood -1.408477
[ Info: iteration 33, average log likelihood -1.408460
[ Info: iteration 34, average log likelihood -1.408443
[ Info: iteration 35, average log likelihood -1.408427
[ Info: iteration 36, average log likelihood -1.408412
[ Info: iteration 37, average log likelihood -1.408398
[ Info: iteration 38, average log likelihood -1.408384
[ Info: iteration 39, average log likelihood -1.408370
[ Info: iteration 40, average log likelihood -1.408357
[ Info: iteration 41, average log likelihood -1.408345
[ Info: iteration 42, average log likelihood -1.408333
[ Info: iteration 43, average log likelihood -1.408321
[ Info: iteration 44, average log likelihood -1.408310
[ Info: iteration 45, average log likelihood -1.408299
[ Info: iteration 46, average log likelihood -1.408289
[ Info: iteration 47, average log likelihood -1.408280
[ Info: iteration 48, average log likelihood -1.408270
[ Info: iteration 49, average log likelihood -1.408261
[ Info: iteration 50, average log likelihood -1.408253
┌ Info: EM with 100000 data points 50 iterations avll -1.408253
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4103656946851153
│     -1.4103123395528108
│      ⋮
└     -1.4082525929995815
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408253
[ Info: iteration 2, average log likelihood -1.408183
[ Info: iteration 3, average log likelihood -1.408114
[ Info: iteration 4, average log likelihood -1.408030
[ Info: iteration 5, average log likelihood -1.407925
[ Info: iteration 6, average log likelihood -1.407796
[ Info: iteration 7, average log likelihood -1.407645
[ Info: iteration 8, average log likelihood -1.407479
[ Info: iteration 9, average log likelihood -1.407307
[ Info: iteration 10, average log likelihood -1.407138
[ Info: iteration 11, average log likelihood -1.406980
[ Info: iteration 12, average log likelihood -1.406836
[ Info: iteration 13, average log likelihood -1.406710
[ Info: iteration 14, average log likelihood -1.406601
[ Info: iteration 15, average log likelihood -1.406507
[ Info: iteration 16, average log likelihood -1.406427
[ Info: iteration 17, average log likelihood -1.406358
[ Info: iteration 18, average log likelihood -1.406298
[ Info: iteration 19, average log likelihood -1.406246
[ Info: iteration 20, average log likelihood -1.406199
[ Info: iteration 21, average log likelihood -1.406157
[ Info: iteration 22, average log likelihood -1.406119
[ Info: iteration 23, average log likelihood -1.406083
[ Info: iteration 24, average log likelihood -1.406050
[ Info: iteration 25, average log likelihood -1.406019
[ Info: iteration 26, average log likelihood -1.405989
[ Info: iteration 27, average log likelihood -1.405960
[ Info: iteration 28, average log likelihood -1.405933
[ Info: iteration 29, average log likelihood -1.405906
[ Info: iteration 30, average log likelihood -1.405880
[ Info: iteration 31, average log likelihood -1.405855
[ Info: iteration 32, average log likelihood -1.405830
[ Info: iteration 33, average log likelihood -1.405806
[ Info: iteration 34, average log likelihood -1.405782
[ Info: iteration 35, average log likelihood -1.405758
[ Info: iteration 36, average log likelihood -1.405735
[ Info: iteration 37, average log likelihood -1.405713
[ Info: iteration 38, average log likelihood -1.405691
[ Info: iteration 39, average log likelihood -1.405669
[ Info: iteration 40, average log likelihood -1.405648
[ Info: iteration 41, average log likelihood -1.405628
[ Info: iteration 42, average log likelihood -1.405609
[ Info: iteration 43, average log likelihood -1.405590
[ Info: iteration 44, average log likelihood -1.405572
[ Info: iteration 45, average log likelihood -1.405555
[ Info: iteration 46, average log likelihood -1.405538
[ Info: iteration 47, average log likelihood -1.405523
[ Info: iteration 48, average log likelihood -1.405508
[ Info: iteration 49, average log likelihood -1.405493
[ Info: iteration 50, average log likelihood -1.405479
┌ Info: EM with 100000 data points 50 iterations avll -1.405479
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4082528956625093
│     -1.408183269241367
│      ⋮
└     -1.4054794852349135
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4181749037171525
│     -1.4181943693549062
│     -1.418136716868516
│     -1.4180969726348447
│      ⋮
│     -1.405507669363714
│     -1.4054932728856744
└     -1.4054794852349135
32×26 Array{Float64,2}:
  0.330071    0.494246    -0.155531    -0.0454269    0.589496    -0.761239     0.396972     0.144419     0.199532   -0.168361     -0.200694   -0.570392    -0.329843    -0.0794197   -0.191392    -0.600936    -0.696927     -0.633077   -0.422473     0.187996    0.276056    0.116768      0.0111597   -0.184569     0.448362   -0.041583
  0.191484    0.127275    -0.23363      0.134561    -0.142317     0.960793    -0.395521     0.12532      0.245965   -0.435776     -0.382842   -0.252309    -0.364197     0.352092     0.467463    -0.619432    -0.820364     -0.377262   -0.32672      0.406116   -0.0645115  -0.120816     -0.0154667    0.375497    -0.0287458  -0.448164
 -0.147823   -0.138253    -1.18054     -0.989802     0.459501    -0.0514621    0.127125    -0.14614     -0.317081    0.259698      0.170552    0.385688    -0.0666943   -0.217638    -0.0242385   -0.0171451    0.161157     -0.308779    0.293808     0.171734   -0.627817   -0.122306      0.0561985    0.00758133   0.0250156   0.0121798
 -0.0550218  -0.0166153    0.144596    -0.963217     0.107978     0.50903     -0.36364      0.203438    -0.381438    0.264995      0.0671106   0.170119     0.143937    -0.640301    -0.17817      0.199293     0.21149      -0.120299   -0.0320334   -0.0742496   0.406837    0.166        -0.477015     0.40524      0.332754   -0.0900548
 -0.135134   -0.397525    -0.271651     0.644015    -0.195873     0.0657761   -0.842818    -0.0832181    0.172611    0.204772     -0.0129034   0.216181    -0.253705     0.528443     0.988104     0.0417181    0.13252       0.0753086   0.271845     0.471955   -0.0958739   0.674372     -0.22185      0.695738     0.0251836  -0.130567
 -0.0186269  -0.0356248    0.185818     0.178108    -0.143728     0.00730018  -0.0159313   -0.211604     0.119228    0.0290189     0.0757976   0.00685723  -0.0247543    0.0393568    0.00021021   0.0521908    0.172709      0.246102    0.06216     -0.131629   -0.136787   -0.000223387  -0.101982    -0.0066294   -0.14788     0.0461016
  0.802899   -0.23887      0.206291     0.32261      0.0833448    0.0489053   -0.173075     0.0828326   -0.188714    0.14206      -0.106419   -0.275249     0.400657     0.440305     0.0695722    0.306389    -0.0682327     0.0718773  -0.957181     0.989757    0.53823    -0.103771      0.245062     0.152395     0.374158    0.348771
  0.735005    0.279963     0.461545    -0.15452      1.05933      0.223219    -0.361272     0.521467     0.110787   -0.164513      0.184327   -0.658417     0.0945577    1.08164      0.491795     0.247588    -0.264522      0.0723807   0.549436     0.824629    0.446258   -0.353806     -0.187124    -0.259634    -0.560536   -0.153865
 -0.878114    0.610903    -0.739908     0.0750433   -0.266677     0.381306     0.46767     -0.257302     0.13607    -0.0138132    -0.57542     0.196556     0.42764     -0.309039    -0.207494    -0.496861     0.267724     -0.123648    0.188438     0.0254555   0.147309   -0.985356      0.0134528    0.0410032    0.0932753   0.106839
 -0.830617    0.265322     0.0795725    0.00733816  -0.100218     0.241607     0.0736164    0.364195     0.14228     0.243018     -0.167702    0.459049     0.418818    -0.343472    -0.359998     0.0870274   -0.214586     -0.0512466  -0.11395     -0.402154    0.0454589  -0.0308282     0.357842     0.0141471    0.161817   -0.372305
 -0.573425    0.249458     0.00890865  -0.227637     0.246161    -0.25902      0.253785     0.278918     0.177969   -0.143419      0.225061   -0.0158115   -0.228653    -0.548091    -0.184245     0.0698131    0.138281     -0.0395946   0.578692    -0.928292   -0.271864    0.0973908    -0.0291631   -0.200274     0.0140582  -0.0568924
  0.387434    0.135513     0.259428    -0.205924     0.269688     0.532704     0.198357     0.0129804    0.0824754   0.284269     -0.0730029  -0.151256    -0.245523    -0.649543    -0.670503    -0.0625848    0.461354      0.37382     0.186975    -0.568604    0.379639   -0.212571      0.410961    -0.50832     -0.413459   -0.0704463
 -0.183873   -0.221093    -0.0674159    0.804859    -0.36144     -0.314944     0.123575    -0.414965    -0.683757    0.474782      0.438811    0.557155     0.72078      0.0474652   -0.124939     0.483629     0.384494      0.508521   -0.223792     0.123055   -0.267729   -0.119534     -0.485006    -0.592895     0.259588    0.505358
 -0.0889897  -0.630642    -0.160142     0.143074    -0.198806    -0.450953     0.565247     0.0833487    0.184455    0.115805     -0.0481344   0.149176    -0.123338    -0.107104    -0.239933     0.448257     0.000649599  -0.560723   -0.459435    -0.0838056   0.0457542   0.0608266     0.674506    -0.406453     0.48414     0.424243
 -0.271005   -0.0177836    0.886562     0.402917    -0.154233    -0.383949     0.995805    -0.0710392   -0.148412    0.0474662    -0.323892   -0.327295     0.249213    -0.199491    -0.1383      -0.474953     0.381003      0.409565    0.019303    -0.234933    0.472413    0.62705       0.0701494    0.0681529   -0.0721424   0.106463
 -0.149113   -0.173799     0.861219     0.670443    -0.407299     0.494361    -0.0435372    0.65271      0.0924857   0.312659      0.722958    0.0308477    0.0397627    0.177913     0.331057     0.304076     0.274191      0.252856    0.00793693  -0.659693    0.224466   -0.186243      0.232239     0.0237449    0.0901629   0.307634
  0.157328    0.551318    -0.377181     0.0341404   -0.696515    -0.468267     0.280185    -0.214651    -0.333936   -0.0937011     0.664439   -0.13029      0.713431     0.121323    -0.0954575   -0.28952     -0.309036     -0.0633609  -0.155258     0.297039   -0.100391   -0.506081      0.725728    -0.394083    -0.494183   -0.494863
  0.375739    0.197042    -0.25746      0.406881    -0.147817    -0.0278189   -0.61201     -0.0950569    1.10526    -0.105491      0.644214    0.0631556    0.496636    -0.2244      -0.245421     0.453318    -0.205762      0.242254    0.0889188   -0.102459    0.178651   -0.344037      0.125556    -0.315401    -0.23868    -0.348589
 -0.0609331   0.0717567   -0.040669     0.766572     0.103451    -0.105714    -0.245731    -0.191399     0.184464   -0.000203368  -0.0215879  -0.692501     0.316034    -0.124039     0.245648    -0.262734    -0.0926158     0.264761    0.0456653   -0.331887    0.0690364   0.0680477    -0.0185981   -0.920023     0.0243672   0.00399294
 -0.162579   -0.0916766   -0.219331     1.0369      -0.431538    -0.29626      0.127723    -0.349254     0.431351   -0.481438     -0.338239   -0.501909     0.132444     0.926053     0.0500603   -0.312595     0.232727      0.37832     0.167477     0.143725    0.102597   -0.139104      0.497737    -0.240544    -0.402013    0.349029
  0.200066   -0.387369    -0.227454     0.081811     0.227599    -0.0189918   -0.273084    -0.128534    -0.021206    0.138774     -0.109121    0.126984     0.209221    -0.0676038    0.406556    -0.290062    -0.68444      -0.349501   -0.0587517    0.105132    0.160417    0.328927     -0.252988    -0.093931    -0.0859804  -0.604707
  0.154827   -0.0493076   -0.884209    -0.145536     0.11099     -0.141471    -0.41774     -0.147436     0.156589    0.115976      0.0540694   0.100414    -0.00292787   0.252916    -0.0587882    0.0879824   -0.191848     -0.200837   -0.099566     0.301579   -0.151192   -0.0982858    -0.168139    -0.1807       0.0114057   0.121284
 -0.093683   -0.437943     0.731348     0.372597     0.466885     0.0935539    0.144449    -0.0615656    0.288653    0.53093      -0.0033898   0.276653    -0.111331     0.465981    -0.0338579    0.175756    -0.495257      0.0899768  -0.168575    -0.126329   -0.231517   -0.375302     -0.414189    -0.0945851   -0.18236     0.112751
  0.876033   -0.523393     0.924121     0.00243777  -0.069565    -0.254126    -0.33146      0.0341066    0.0954951  -0.166613      0.407955    0.00343107  -0.60102      0.141585    -0.043466     0.415257    -0.0397725    -0.120826   -0.124477    -0.262012   -0.507393    0.961701     -0.00257489  -0.124149    -0.303295   -0.00756796
 -0.0560373  -0.246891     0.0420602   -0.426671    -0.00334449  -0.0680218    0.636316     0.140375    -0.891822    0.0349458    -0.138501    0.341729    -0.185325     0.35095      0.2304      -0.183317     0.0914194    -0.18266     0.00510651   0.423698    0.0160144   0.129851     -0.218938     0.533778     0.233404   -0.00853598
 -0.193628    0.0640234    0.159627    -0.243153    -0.285568    -0.178467    -0.111389    -0.239338     0.372546   -0.0610897    -0.0811609   0.628454     0.0669051    0.190865    -0.0780299    0.404414     0.474276      0.066886    0.103548     0.058036   -0.318085   -0.00155765   -0.353599     0.930536     0.135829    0.19779
 -0.0469554   0.484811     0.135508    -0.430245    -0.112248     0.220893     0.0888536   -0.402235     0.0876733  -0.342675     -0.147223   -0.172882    -0.857665    -0.00821158  -0.460752    -0.735887     0.00520089    0.407293    0.0991133    0.0127899  -0.291653   -0.18342      -0.227948     0.222984    -0.199012   -0.13869
  0.278162    0.133644     0.536346    -0.0134186   -0.11844      0.760789    -0.247464    -0.0907228   -0.0697098  -0.525473     -0.0568479  -0.153688     0.395147    -0.0837522    0.105086    -0.0890635   -0.00972645    0.27865     0.294209     0.130729   -0.0739365  -0.0630067    -0.473894     0.561083    -0.539662   -0.299085
  0.370224   -0.233024     0.123622    -0.0586915    0.088811    -0.171434     0.181061    -0.014568    -0.174027   -0.165729      0.296805   -0.732593    -0.205571     0.345076     0.149437     0.066711     0.376303     -0.0240325   0.0640197    0.212127    0.225754    0.0330628    -0.388048     0.115364     0.0652091   0.807641
  0.33503     0.102429    -0.589531    -0.240869    -0.294079     0.00460075  -0.0104805    0.00283242  -0.409708   -0.497785     -0.0954183  -0.366363     0.237718    -0.541351    -0.255141     0.045443     0.408794      0.186259   -0.0942108    0.50627     0.200285    0.17169       0.639981    -0.245336     0.441219    0.18973
 -0.0484516   0.00657597   0.00413906  -0.0130103    0.0697784    0.0770387    0.095806     0.0432147    0.0459649  -0.172315     -0.0291034  -0.124168     0.0888204   -0.0210248   -0.121885    -0.113637    -0.229538     -0.102806   -0.0629844    0.114196    0.0382637  -0.0814906     0.0499102   -0.0562138   -0.115855   -0.13507
  0.0133726   0.0670688    0.0841892    0.0953831   -0.223926     0.0407122   -0.00506624  -0.0412018    0.0252443   0.239086      0.0926743   0.0855407    0.0305911   -0.0934092    0.0777968    0.00762668   0.412384      0.0774635   0.0998509   -0.195546    0.0141283   0.103343      0.0254864    0.109555     0.0567      0.110483[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405466
[ Info: iteration 2, average log likelihood -1.405454
[ Info: iteration 3, average log likelihood -1.405441
[ Info: iteration 4, average log likelihood -1.405430
[ Info: iteration 5, average log likelihood -1.405419
[ Info: iteration 6, average log likelihood -1.405408
[ Info: iteration 7, average log likelihood -1.405397
[ Info: iteration 8, average log likelihood -1.405387
[ Info: iteration 9, average log likelihood -1.405378
[ Info: iteration 10, average log likelihood -1.405369
┌ Info: EM with 100000 data points 10 iterations avll -1.405369
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.143349e+05
      1       7.061133e+05      -2.082216e+05 |       32
      2       6.878723e+05      -1.824101e+04 |       32
      3       6.821525e+05      -5.719762e+03 |       32
      4       6.793798e+05      -2.772708e+03 |       32
      5       6.776453e+05      -1.734531e+03 |       32
      6       6.763981e+05      -1.247224e+03 |       32
      7       6.754120e+05      -9.860365e+02 |       32
      8       6.745789e+05      -8.330824e+02 |       32
      9       6.738624e+05      -7.165434e+02 |       32
     10       6.732830e+05      -5.794412e+02 |       32
     11       6.727840e+05      -4.989471e+02 |       32
     12       6.723429e+05      -4.411430e+02 |       32
     13       6.719749e+05      -3.679658e+02 |       32
     14       6.716377e+05      -3.371513e+02 |       32
     15       6.713284e+05      -3.093212e+02 |       32
     16       6.710613e+05      -2.671104e+02 |       32
     17       6.708368e+05      -2.245374e+02 |       32
     18       6.706470e+05      -1.897357e+02 |       32
     19       6.704819e+05      -1.651386e+02 |       32
     20       6.703321e+05      -1.497550e+02 |       32
     21       6.701932e+05      -1.389182e+02 |       32
     22       6.700514e+05      -1.417853e+02 |       32
     23       6.699121e+05      -1.393586e+02 |       32
     24       6.697720e+05      -1.400484e+02 |       32
     25       6.696294e+05      -1.426723e+02 |       32
     26       6.695048e+05      -1.245334e+02 |       32
     27       6.693898e+05      -1.150770e+02 |       32
     28       6.692849e+05      -1.048255e+02 |       32
     29       6.692030e+05      -8.188527e+01 |       32
     30       6.691380e+05      -6.502380e+01 |       32
     31       6.690806e+05      -5.742169e+01 |       32
     32       6.690251e+05      -5.551293e+01 |       32
     33       6.689693e+05      -5.581009e+01 |       32
     34       6.689159e+05      -5.339763e+01 |       32
     35       6.688603e+05      -5.558440e+01 |       32
     36       6.688133e+05      -4.695472e+01 |       32
     37       6.687755e+05      -3.782919e+01 |       32
     38       6.687374e+05      -3.807489e+01 |       32
     39       6.686929e+05      -4.455246e+01 |       32
     40       6.686500e+05      -4.286336e+01 |       32
     41       6.686025e+05      -4.756600e+01 |       32
     42       6.685504e+05      -5.205203e+01 |       32
     43       6.685014e+05      -4.900321e+01 |       32
     44       6.684583e+05      -4.305828e+01 |       32
     45       6.684173e+05      -4.099960e+01 |       32
     46       6.683808e+05      -3.654446e+01 |       32
     47       6.683468e+05      -3.396722e+01 |       32
     48       6.683155e+05      -3.133591e+01 |       32
     49       6.682910e+05      -2.452982e+01 |       32
     50       6.682683e+05      -2.270438e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 668268.2577298398)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417825
[ Info: iteration 2, average log likelihood -1.412659
[ Info: iteration 3, average log likelihood -1.411190
[ Info: iteration 4, average log likelihood -1.410063
[ Info: iteration 5, average log likelihood -1.408921
[ Info: iteration 6, average log likelihood -1.407936
[ Info: iteration 7, average log likelihood -1.407288
[ Info: iteration 8, average log likelihood -1.406927
[ Info: iteration 9, average log likelihood -1.406723
[ Info: iteration 10, average log likelihood -1.406591
[ Info: iteration 11, average log likelihood -1.406496
[ Info: iteration 12, average log likelihood -1.406421
[ Info: iteration 13, average log likelihood -1.406358
[ Info: iteration 14, average log likelihood -1.406304
[ Info: iteration 15, average log likelihood -1.406257
[ Info: iteration 16, average log likelihood -1.406214
[ Info: iteration 17, average log likelihood -1.406175
[ Info: iteration 18, average log likelihood -1.406139
[ Info: iteration 19, average log likelihood -1.406106
[ Info: iteration 20, average log likelihood -1.406075
[ Info: iteration 21, average log likelihood -1.406046
[ Info: iteration 22, average log likelihood -1.406018
[ Info: iteration 23, average log likelihood -1.405992
[ Info: iteration 24, average log likelihood -1.405967
[ Info: iteration 25, average log likelihood -1.405943
[ Info: iteration 26, average log likelihood -1.405921
[ Info: iteration 27, average log likelihood -1.405899
[ Info: iteration 28, average log likelihood -1.405879
[ Info: iteration 29, average log likelihood -1.405860
[ Info: iteration 30, average log likelihood -1.405842
[ Info: iteration 31, average log likelihood -1.405824
[ Info: iteration 32, average log likelihood -1.405807
[ Info: iteration 33, average log likelihood -1.405792
[ Info: iteration 34, average log likelihood -1.405776
[ Info: iteration 35, average log likelihood -1.405762
[ Info: iteration 36, average log likelihood -1.405747
[ Info: iteration 37, average log likelihood -1.405734
[ Info: iteration 38, average log likelihood -1.405721
[ Info: iteration 39, average log likelihood -1.405708
[ Info: iteration 40, average log likelihood -1.405696
[ Info: iteration 41, average log likelihood -1.405684
[ Info: iteration 42, average log likelihood -1.405672
[ Info: iteration 43, average log likelihood -1.405661
[ Info: iteration 44, average log likelihood -1.405650
[ Info: iteration 45, average log likelihood -1.405639
[ Info: iteration 46, average log likelihood -1.405628
[ Info: iteration 47, average log likelihood -1.405618
[ Info: iteration 48, average log likelihood -1.405608
[ Info: iteration 49, average log likelihood -1.405598
[ Info: iteration 50, average log likelihood -1.405589
┌ Info: EM with 100000 data points 50 iterations avll -1.405589
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.866418     0.489626   -0.643034   -0.114497   -0.268001     0.375879      0.486476    -0.104288     0.0386185  -0.0656562   -0.528335    0.357491     0.508065    -0.20576    -0.000795201  -0.353965     0.286162   -0.256154     0.259031    0.0954527   0.100297    -0.943846    0.0185147    0.320843    0.196489    0.0944096
  0.856383    -0.516653    1.02677     0.0794567  -0.177159    -0.248464     -0.455907     0.0867488    0.130877   -0.124852     0.509866    0.0301655   -0.57218      0.148563   -0.115523      0.419931    -0.0113137   0.0587435   -0.109953   -0.34258    -0.577053     1.12418     0.0664426   -0.113766   -0.279291   -0.0190215
 -0.382348    -0.187568    0.057642    0.104907    0.159989     0.209208     -0.0656528    0.163527     0.0051973   0.404535    -0.486951    0.4911       0.42895     -0.0531129   0.0371613    -0.00670507  -0.494682   -0.148626    -0.151901   -0.0995632   0.198435     0.219352    0.0330096   -0.0935561   0.132685   -0.703024
 -0.0239741    0.196435   -0.931517    0.0463152  -0.28164     -0.300328     -0.262485    -0.515843    -0.194476    0.185415    -0.10302     0.235724    -0.0579548    0.292954    0.329985     -0.607615    -0.209598   -0.309769    -0.225997    0.295047   -0.333178     0.203202   -0.228632     0.0246035   0.10841    -0.0871343
 -0.00106353  -0.332228   -0.148029   -0.0995215   0.211533    -0.482455      0.583717     0.433738    -0.167535    0.129155    -0.205973    0.0622841   -0.238388    -0.280517    0.00171648   -0.110044    -0.21935    -0.57171     -0.241171    0.208888    0.0234729    0.44063     0.512147    -0.176145    0.598849    0.0817794
 -0.785086     0.217521    0.0202413  -0.173188   -0.0333846   -0.167291      0.337892     0.102909     0.256103   -0.140817     0.163529    0.226363    -0.235234    -0.518578   -0.151713      0.0271418    0.231609   -0.113124     0.604564   -1.09339    -0.400183     0.110387    0.0614634   -0.0666712  -0.0693769  -0.134571
  0.533067    -0.0450292   0.143377    0.275608    0.0322771    0.13504      -0.188445     0.143967    -0.142806    0.358714     0.0344238   0.0117776    0.539374     0.559932   -0.0387703     0.306377    -0.140079    0.205885    -0.878754    1.10697     0.388625    -0.362484    0.152937     0.403278    0.402065    0.341227
  0.357134    -0.445029   -1.25762    -0.447296    0.206815     0.148866     -0.637106     0.0952116    0.232659   -0.0723942    0.539815   -0.0273992    0.119471    -0.21514    -0.191447      0.43279     -0.40964     0.093582     0.394825    0.188121   -0.0457095   -0.343798    0.00229461  -0.404798    0.07741    -0.101423
 -0.127671     0.36425    -0.431697    0.0270218  -0.150615    -0.263174      0.437335    -0.24777      0.0615658  -0.00598851   0.0607199  -0.0229234    0.241167    -0.439721   -0.923198     -0.143953    -0.110632    0.0208441   -0.198535   -0.126005    0.0148998   -0.409087    0.545705    -0.702255   -0.0967493   0.133713
 -0.0956012   -0.154495    0.41461    -0.077866    0.12911     -0.267263      0.246905    -0.0194764   -0.124394   -0.133372    -0.0110605  -0.201149    -0.191692     0.268646   -0.0645415     0.18202      0.44419     0.168828    -0.0500589  -0.0222841  -0.17728      0.022283   -0.740712     0.408776    0.296154    0.886573
 -0.277053    -0.293524   -0.0152926   0.677272   -0.350105    -0.304745      0.100275    -0.183021    -0.4917      0.493019     0.391402    0.396091     0.749332     0.0806974   0.10428       0.738518     0.52784     0.37084     -0.192417    0.0412213  -0.262496     0.0396501  -0.0427396   -0.522704    0.217939    0.441476
  0.52453      0.0416332   0.280538   -0.258845    0.457404     0.188416      0.193415    -0.232713    -0.124832    0.647131     0.355857   -0.269594    -0.36715     -0.360957   -0.235177     -0.0222979    0.820534    0.52179      0.480555   -0.591138    0.447182    -0.294885   -0.117183    -0.501073   -0.547918   -0.0281983
  0.185597    -0.46536     0.155176    0.121484   -0.114823     0.000835884   0.26456     -0.240388     0.239138    0.0962777    0.12826     0.0857874   -0.185357     0.278881   -0.0661216     0.719012     0.0569647  -0.619263    -0.413861   -0.298945   -0.0104059   -0.397607    0.123482    -0.0830191  -0.0236505   0.579205
  0.295628     0.211185   -0.0628315   0.740674   -0.484356     0.0120726    -0.278551    -0.164171     0.777818   -0.039725     0.507375    0.0687813    0.495196    -0.0816087   0.303483      0.108731    -0.382443   -0.0205616   -0.123732   -0.0667109   0.325814    -0.246493    0.3637      -0.133114   -0.50862    -0.509853
 -0.00776508   0.140062   -0.0119914  -0.128789   -0.263222    -0.0118318     0.0765174   -0.0568318   -0.0724195   0.0913875    0.0782976   0.151342    -0.00924035  -0.0435862   0.00775396   -0.025009     0.367924    0.00335454   0.124363   -0.0454806  -0.00277543   0.0324757   0.022622     0.249085    0.0468879   0.0382338
 -0.217719    -0.0831995  -0.133769    0.903712   -0.354187    -0.256856      0.057396    -0.524459     0.386071   -0.469235    -0.206953   -0.627512     0.143763     0.597379    0.0123571    -0.554129     0.0978468   0.569595     0.243343    0.137436   -0.0335872   -0.07488     0.218396    -0.354576   -0.425322    0.293138
 -0.42478      0.0917803   0.516233    0.301517   -0.136835     0.0984278     0.311667     1.02358      0.159554   -0.0408691    0.330925   -0.192041     0.409377     0.121003   -0.287851      0.265234     0.313148    0.161362    -0.0329008  -0.470546    0.511658    -0.217599    0.54777     -0.107568    0.0623686   0.066195
  0.248154     0.454916    0.302818   -0.0889484  -0.180125     0.609277     -0.342689    -0.0219002   -0.0569143  -0.668451     0.17343    -0.0593121    0.40924      0.0130782   0.0304121    -0.0317658    0.0142285   0.212721     0.34608     0.149494   -0.188559    -0.271225   -0.37195      0.500738   -0.635678   -0.517034
  0.657405     0.293402    0.490704   -0.0140548   1.09407      0.210862     -0.439523     0.547427     0.184811   -0.0335611    0.144487   -0.72841      0.0622909    1.12355     0.638225      0.0844649   -0.377198    0.0510012    0.492225    0.783399    0.492614    -0.337538   -0.188641    -0.282073   -0.565546   -0.0897933
 -0.031616     0.103403    0.14642     0.0547687   0.593581     0.0449122    -0.165742     0.242639     0.350315    0.0134974    0.215698   -0.309491    -0.118115    -0.271008    0.0129456    -0.103137    -0.369915   -0.0811913    0.117272   -0.461404    0.00576959   0.118824   -0.117658    -0.357102   -0.0691356  -0.20064
 -0.22017     -0.407997   -0.0732694   0.36749    -0.372359     0.0722872    -0.88023     -0.173566     0.468203    0.177747    -0.0473727   0.465083    -0.240923     0.273753    0.518171      0.364072     0.360618    0.223074     0.490618    0.253683   -0.0734608    0.633976   -0.358099     0.959301    0.12928     0.0528068
 -0.039078    -0.126361   -0.0930854   0.166285    0.00257227   0.0131607     0.00936868  -0.0305294    0.0290403  -0.0602783    0.0112996  -0.137237     0.22386      0.0805454  -0.0412358    -0.106625    -0.277175   -0.0756685   -0.0957629   0.151309   -0.0174722   -0.0629257   0.0334357   -0.164819   -0.146847   -0.0683087
  0.395738     0.0510169  -0.492177   -0.449544    0.579872    -0.551034      0.0376384   -0.944317     0.32675    -0.245274    -0.430283    0.00920454   0.245049     0.148965   -0.463668      0.457855     0.0464055  -0.41683      0.175528    0.719115   -0.22195      0.291116   -0.278339    -0.325379   -0.543813   -0.238167
 -0.33913     -0.124711    0.74036     0.530898    0.0414691    0.346694     -0.0791479    0.132815     0.299607    0.850899     0.175995    0.617082    -0.176783     0.449654    0.0943936    -0.212111    -0.421669    0.274456     0.0995956  -0.666701   -0.551936    -0.446335   -0.373611     0.151096   -0.137143    0.09062
 -0.10797      0.178086    0.0231728  -0.95512     0.0131183    0.43152      -0.302889     0.113462    -0.249624    0.230746     0.0836658   0.285601     0.114635    -0.89172    -0.430022      0.181361     0.178059   -0.107651    -0.044278   -0.156069    0.216462     0.107431   -0.206981     0.392978    0.297384   -0.131656
  0.607459    -0.108533   -0.199262    0.0573831  -0.174837    -0.1766        0.0173136   -0.0811862   -0.3865     -0.410291     0.0597059  -0.896385     0.178694     0.0964174   0.191329     -0.00219277   0.340908   -0.0426088   -0.190041    0.427322    0.737181     0.212517    0.363167    -0.322809    0.301829    0.390302
 -0.024991    -0.100842   -0.190015   -0.317281    0.212544     0.211098     -0.0207679    0.054716    -0.213714   -0.0522691   -0.152713   -0.0361058   -0.327575     0.360338    0.407958     -0.314421    -0.102626   -0.154002     0.0366671   0.281724   -0.121343     0.0311732  -0.204797     0.508577    0.0131263  -0.111285
 -0.00329777  -0.104168    0.678882    0.21111    -0.291361     0.0890316     0.562185    -0.222751    -0.195761    0.0561881   -0.586265   -0.0325821    0.179551    -0.359664   -0.106157     -0.576813     0.353296    0.494343     0.117393   -0.172376    0.441167     0.748496   -0.0930288    0.321945   -0.174673   -0.073889
  0.319273    -0.447736    0.170255   -0.189852    0.240158     0.159174      0.0713276    0.0117849   -0.381715   -0.0923836    0.119027    0.0589462   -0.291488     0.459289    0.371471     -0.120085    -0.301017   -0.068599     0.0231614   0.543855    0.0357034    0.141941   -0.442671     0.423036   -0.153791   -0.120628
 -0.0288341    0.557412    0.242336   -0.464676   -0.0497294    0.269949      0.401338    -0.172387     0.0488677  -0.488121    -0.279941   -0.250574    -0.640719    -0.0127151  -0.710744     -0.706757    -0.174779    0.139419    -0.160384    0.14005    -0.198808    -0.418906   -0.0986824    0.165058   -0.0648987  -0.0856111
  0.371438    -0.283958    0.370306    0.575415   -0.202666     0.12314      -0.236145    -0.0769801    0.358322   -0.0888674    0.0916776  -0.265756     0.0736943    0.0124992   0.333718      0.204544    -0.176985    0.0176189   -0.279006    0.0544918   0.125567     0.022753   -0.0985034   -0.27943     0.108029    0.00192576
 -0.12066      0.472715   -0.242045    0.118715   -0.0470356    0.174038     -0.121171    -0.00749651   0.210727   -0.0106879   -0.123114   -0.105676     0.0906973   -0.608141   -0.457128     -0.0701152    0.363552    0.563613    -0.065659   -0.151376   -0.227767    -0.203959    0.371327    -0.411918    0.226706    0.0700813[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405580
[ Info: iteration 2, average log likelihood -1.405571
[ Info: iteration 3, average log likelihood -1.405562
[ Info: iteration 4, average log likelihood -1.405553
[ Info: iteration 5, average log likelihood -1.405545
[ Info: iteration 6, average log likelihood -1.405536
[ Info: iteration 7, average log likelihood -1.405528
[ Info: iteration 8, average log likelihood -1.405520
[ Info: iteration 9, average log likelihood -1.405512
[ Info: iteration 10, average log likelihood -1.405505
┌ Info: EM with 100000 data points 10 iterations avll -1.405505
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
