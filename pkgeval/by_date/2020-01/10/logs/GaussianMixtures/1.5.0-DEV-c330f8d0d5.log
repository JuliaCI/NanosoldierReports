Julia Version 1.5.0-DEV.49
Commit c330f8d0d5 (2020-01-10 15:42 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed Missings ─────────── v0.4.3
 Installed SortingAlgorithms ── v0.3.1
 Installed JLD ──────────────── v0.9.1
 Installed FileIO ───────────── v1.2.1
 Installed Parameters ───────── v0.12.0
 Installed StatsFuns ────────── v0.9.3
 Installed Distributions ────── v0.22.0
 Installed StatsBase ────────── v0.32.0
 Installed SpecialFunctions ─── v0.9.0
 Installed BinaryProvider ───── v0.5.8
 Installed NearestNeighbors ─── v0.4.4
 Installed OrderedCollections ─ v1.1.0
 Installed BinDeps ──────────── v1.0.0
 Installed Rmath ────────────── v0.6.0
 Installed Blosc ────────────── v0.5.1
 Installed Clustering ───────── v0.13.3
 Installed DataAPI ──────────── v1.1.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed CMakeWrapper ─────── v0.2.3
 Installed FillArrays ───────── v0.8.2
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Distances ────────── v0.8.2
 Installed PDMats ───────────── v0.9.10
 Installed Arpack ───────────── v0.4.0
 Installed StaticArrays ─────── v0.12.1
 Installed QuadGK ───────────── v2.3.1
 Installed Compat ───────────── v2.2.0
 Installed CMake ────────────── v1.1.2
 Installed Arpack_jll ───────── v3.5.0+2
 Installed LegacyStrings ────── v0.4.1
 Installed HDF5 ─────────────── v0.12.5
 Installed URIParser ────────── v0.4.0
 Installed DataStructures ───── v0.17.7
 Installed ScikitLearnBase ──── v0.5.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.0
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_3DC7Xr/Project.toml`
 [no changes]
  Updating `/tmp/jl_3DC7Xr/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_2LvTpt/Project.toml`
 [no changes]
  Updating `/tmp/jl_2LvTpt/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_BEK9S0/Project.toml`
 [no changes]
  Updating `/tmp/jl_BEK9S0/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_4mlw4g/Project.toml`
 [no changes]
  Updating `/tmp/jl_4mlw4g/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_Nsmgr0/Project.toml`
 [no changes]
  Updating `/tmp/jl_Nsmgr0/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_Nsmgr0/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.0
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.0207238439830104e6, [8801.426522533424, 91198.57347746659], [-8868.012740211174 6.61710405983053 -8017.045324204852; 8956.636913445322 -317.67229312268574 7855.335978250758], [[15270.79605667196 1011.4359489118682 3008.9246977261; 1011.4359489118682 7865.751609777597 1480.386422893324; 3008.9246977261 1480.3864228933242 12672.15831164717], [84476.02869855796 -828.5058600615511 -3240.240777456778; -828.5058600615511 92052.63892690619 -1394.9605543378425; -3240.2407774567773 -1394.9605543378423 88204.87860896473]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.683010e+03
      1       1.190546e+03      -4.924643e+02 |        5
      2       1.093444e+03      -9.710230e+01 |        4
      3       1.072034e+03      -2.140962e+01 |        0
      4       1.072034e+03       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 1072.033891187651)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.068665
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.686538
[ Info: iteration 2, lowerbound -3.538940
[ Info: iteration 3, lowerbound -3.411482
[ Info: iteration 4, lowerbound -3.297230
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.196922
[ Info: iteration 6, lowerbound -3.120643
[ Info: iteration 7, lowerbound -3.086524
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -3.071774
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -3.046576
[ Info: iteration 10, lowerbound -3.024214
[ Info: iteration 11, lowerbound -2.998164
[ Info: iteration 12, lowerbound -2.963019
[ Info: iteration 13, lowerbound -2.917194
[ Info: iteration 14, lowerbound -2.859454
[ Info: iteration 15, lowerbound -2.789046
[ Info: iteration 16, lowerbound -2.706270
[ Info: iteration 17, lowerbound -2.614533
[ Info: iteration 18, lowerbound -2.523135
[ Info: iteration 19, lowerbound -2.444252
[ Info: iteration 20, lowerbound -2.383850
[ Info: iteration 21, lowerbound -2.343339
[ Info: dropping number of Gaussions to 3
[ Info: iteration 22, lowerbound -2.318703
[ Info: iteration 23, lowerbound -2.307427
[ Info: dropping number of Gaussions to 2
[ Info: iteration 24, lowerbound -2.302949
[ Info: iteration 25, lowerbound -2.299262
[ Info: iteration 26, lowerbound -2.299257
[ Info: iteration 27, lowerbound -2.299255
[ Info: iteration 28, lowerbound -2.299254
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan 10 22:05:54 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan 10 22:06:03 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Fri Jan 10 22:06:05 2020: EM with 272 data points 0 iterations avll -2.068665
5.8 data points per parameter
, Fri Jan 10 22:06:07 2020: GMM converted to Variational GMM
, Fri Jan 10 22:06:16 2020: iteration 1, lowerbound -3.686538
, Fri Jan 10 22:06:16 2020: iteration 2, lowerbound -3.538940
, Fri Jan 10 22:06:16 2020: iteration 3, lowerbound -3.411482
, Fri Jan 10 22:06:16 2020: iteration 4, lowerbound -3.297230
, Fri Jan 10 22:06:17 2020: dropping number of Gaussions to 7
, Fri Jan 10 22:06:17 2020: iteration 5, lowerbound -3.196922
, Fri Jan 10 22:06:17 2020: iteration 6, lowerbound -3.120643
, Fri Jan 10 22:06:17 2020: iteration 7, lowerbound -3.086524
, Fri Jan 10 22:06:17 2020: dropping number of Gaussions to 5
, Fri Jan 10 22:06:17 2020: iteration 8, lowerbound -3.071774
, Fri Jan 10 22:06:17 2020: dropping number of Gaussions to 4
, Fri Jan 10 22:06:17 2020: iteration 9, lowerbound -3.046576
, Fri Jan 10 22:06:17 2020: iteration 10, lowerbound -3.024214
, Fri Jan 10 22:06:17 2020: iteration 11, lowerbound -2.998164
, Fri Jan 10 22:06:17 2020: iteration 12, lowerbound -2.963019
, Fri Jan 10 22:06:17 2020: iteration 13, lowerbound -2.917194
, Fri Jan 10 22:06:17 2020: iteration 14, lowerbound -2.859454
, Fri Jan 10 22:06:17 2020: iteration 15, lowerbound -2.789046
, Fri Jan 10 22:06:17 2020: iteration 16, lowerbound -2.706270
, Fri Jan 10 22:06:17 2020: iteration 17, lowerbound -2.614533
, Fri Jan 10 22:06:17 2020: iteration 18, lowerbound -2.523135
, Fri Jan 10 22:06:17 2020: iteration 19, lowerbound -2.444252
, Fri Jan 10 22:06:17 2020: iteration 20, lowerbound -2.383850
, Fri Jan 10 22:06:17 2020: iteration 21, lowerbound -2.343339
, Fri Jan 10 22:06:17 2020: dropping number of Gaussions to 3
, Fri Jan 10 22:06:17 2020: iteration 22, lowerbound -2.318703
, Fri Jan 10 22:06:17 2020: iteration 23, lowerbound -2.307427
, Fri Jan 10 22:06:17 2020: dropping number of Gaussions to 2
, Fri Jan 10 22:06:17 2020: iteration 24, lowerbound -2.302949
, Fri Jan 10 22:06:17 2020: iteration 25, lowerbound -2.299262
, Fri Jan 10 22:06:17 2020: iteration 26, lowerbound -2.299257
, Fri Jan 10 22:06:17 2020: iteration 27, lowerbound -2.299255
, Fri Jan 10 22:06:17 2020: iteration 28, lowerbound -2.299254
, Fri Jan 10 22:06:17 2020: iteration 29, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 30, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 31, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 32, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 33, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 34, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 35, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 36, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 37, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 38, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 39, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 40, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 41, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 42, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 43, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 44, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 45, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 46, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 47, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 48, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 49, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: iteration 50, lowerbound -2.299253
, Fri Jan 10 22:06:17 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777396786, 178.04509222603215]
β = [95.95490777396786, 178.04509222603215]
m = [2.000229257775217 53.85198717246049; 4.2503007332697615 79.28686694435964]
ν = [97.95490777396786, 180.04509222603215]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611950935 -0.00895312382734883; 0.0 0.012748664777410112], [0.18404155547482426 -0.007644049042329026; 0.0 0.008581705166330587]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.992351390264766
avll from llpg:  -0.9923513902647648
avll direct:     -0.9923513902647646
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9908061644340556
avll from llpg:  -0.9908061644340553
avll direct:     -0.9908061644340553
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.00990799  -0.0857744   0.132701    -0.0221375    0.0169299   -0.0240423     0.0669078  -0.143272     0.100849     0.0413411   -0.0304644    -0.247793     -0.0178792    0.0541928    0.348622    -0.114169      0.000262162   0.113916    0.107919     -0.0645244    0.223525    -0.184828      0.206544    -0.155756     0.0132567    -0.0588402
  0.0688332    0.0248861  -0.131301     0.185571    -0.0694945    0.0508218     0.163622    0.0328621    0.0931547   -0.13108     -0.0342821    -0.0534783     0.0963205    0.00555934  -0.0650466    0.0610176    -0.134421      0.0371997  -0.0851623     0.262219    -0.0638052    0.0123022    -0.118444    -0.0704217   -0.000577405  -0.0660014
 -0.0841152    0.0193296  -0.00244614   0.00115332   0.0383752   -0.16144      -0.0357582   0.0798272    0.0688848   -0.067969    -0.0143941     0.0375537     0.00236316   0.0942836   -0.0296115   -0.0373401    -0.0360669     0.0726038  -0.0284266     0.133766     0.0177387   -0.114112     -0.0848045    0.0477253    0.159366     -0.0304654
  0.0755087    0.0884729  -0.0232817    0.100833    -0.252943    -0.142729     -0.0665621  -0.124576    -0.100606    -0.0173921    0.0539729    -0.0648767     0.0191278    0.101849     0.10956     -0.0522504    -0.00571694   -0.121807   -0.0640887     0.105637    -0.0479964   -0.0911444    -0.0414254    0.0927499    0.00957905   -0.029324
  0.0345217    0.0559923  -0.134731    -0.0801617   -0.151205    -0.000602482   0.0299216  -0.0792507   -0.19211     -0.0562694    0.0296042     0.0163554     0.00131819   0.029956     0.147299     0.120169      0.0708993     0.242027   -0.118531      0.00543703   0.0146405   -0.000247811  -0.0283631    0.0575696    0.109884      0.124499
  0.0552858    0.120704    0.0435768   -0.153883     0.00845378   0.0644621     0.0268987   0.0959805    0.0302733    0.0379329    0.0517182    -0.0351274    -0.0511792    0.0955001   -0.0576562   -0.0654907     0.13297      -0.0433358  -0.00459431    0.0449131   -0.194765    -0.0722862     0.0783809   -0.020266    -0.035981      0.0805636
  0.138255    -0.0827871   0.260413    -0.0606081    0.00533536   0.0941267    -0.0450463  -0.205815     0.164687    -0.0158494    0.0707486    -0.0777467    -0.0366727    0.114283     0.0354541   -0.0280598    -0.169791     -0.0740499  -0.0849376    -0.3813       0.0048507    0.0650229     0.0420127    0.0114112    0.0672499    -0.000725144
  0.0249009   -0.0971136   0.0901135    0.199487     0.0550658   -0.0113807    -0.105972    0.11898     -0.0930396   -0.00294621   0.0778718     0.147926      0.0349299   -0.0510883   -0.102058    -0.0632835     0.0744286    -0.0079068   0.0321438     0.123647    -0.0903843   -0.18501      -0.0851386    0.00686559   0.130734      0.0928349
 -0.0558934    0.0660882  -0.0771614    0.120826    -0.0303819    0.148242      0.0402698   0.0655903    0.0241039    0.129985     0.140216      0.144596      0.134501     0.0856311   -0.0255317   -0.0386666     0.0314985     0.190176    0.0787877    -0.0720785    0.0761601   -0.0777603     0.125458     0.0927804    0.147114      0.0199714
  0.131907    -0.0405411   0.0936595    0.0240232   -0.189098    -0.0695294     0.0601821  -0.0387088    0.0322534   -0.167781     0.108625     -0.0572973    -0.0599103    0.00859028  -0.00533328   0.000451466  -0.134761      0.0255205   0.0255034     0.00120765  -0.0771985   -0.0994801     0.0162502    0.199851     0.00999173    0.223874
 -0.00129586  -0.274499    0.107836    -0.0402325    0.0860967    0.177454     -0.141434    0.0503781    0.223693     0.0827167   -0.169005      0.0594825     0.103402     0.150178     0.0420555    0.124538     -0.0444294    -0.0320365   0.0197693     0.0571268    0.0357116   -0.0115011     0.0242454    0.0148653   -0.202717      0.00662828
  0.0204687    0.251359    0.00812429   0.0697382    0.116717    -0.00149009   -0.0809462   0.187822    -0.0246784   -0.0513119   -0.217484     -0.000664128   0.0747747   -0.136416     0.208772    -0.0121252    -0.069039     -0.0246027   0.0112233     0.0118247    0.102507     0.000752445  -0.110031     0.147997     0.106296      0.0671016
  0.0117181   -0.138848    0.13559     -0.0238209    0.0921904    0.0405233     0.0358932   0.0176302   -0.0409472    0.038159     0.159415     -0.101662      0.082091     0.0213965   -0.154942    -0.00605513   -0.13179       0.108208   -0.0556664    -0.147303    -0.171483     0.00419239    0.0926427   -0.0151069    0.151734      0.060705
  0.0102541    0.02377     0.0689091   -0.00590664   0.0531742   -0.110361     -0.0786774   0.0103756   -0.0368426    0.00245803  -0.158198     -0.0131818    -0.0993695   -0.0389213   -0.213328    -0.0692388     0.0738529    -0.218477    0.261429      0.130125     0.109933     0.0193836     0.0131353   -0.0384762    0.0693708    -0.019978
 -0.0650998    0.108226   -0.193888    -0.113795    -0.0174552   -0.00361317    0.0370212  -0.0335434   -0.0221461   -0.0472332   -0.0653544    -0.137443     -0.0444379   -0.171288     0.0434089    0.0583395    -0.0729222     0.115278   -0.0455468     0.172593     0.021442    -0.00294104   -0.0216672   -0.136615     0.0409691    -0.0736594
  0.0858431   -0.123741   -0.0479444   -0.174504    -0.127524    -0.0836027     0.308223    0.136124     0.174172     0.0556735   -0.0774965    -0.0488999    -0.123084    -0.0295454   -0.0349773    0.0626296    -0.0308264    -0.159714   -0.0443634    -0.0947258   -0.0768266   -0.116506      0.114965     0.0687706    0.0864035    -0.0211697
  0.0125182   -0.0505946   0.179471    -0.0995893    0.0327726    0.0251957    -0.0502302   0.102045    -0.0468995   -0.0993964   -0.184229      0.0918236     0.0366921    0.230711     0.0263371    0.276407      0.0197842     0.0177656   0.086511     -0.00408047  -0.159513    -0.153399     -0.0668375   -0.10239     -0.116454      0.0695337
 -0.131118     0.121172   -0.164851     0.0432368   -0.0698913   -0.0671351     0.0180313   0.00170229  -0.00143336  -0.0130524   -0.0891122     0.155866      0.0381333    0.136952    -0.0259935   -0.00880136    0.0191112     0.0330226   0.0260759     0.00957533   0.0345193   -0.088658     -0.00320746  -0.210681    -0.0564626     0.0325329
 -0.135891     0.0667657   0.0456834   -0.0361423   -0.129178    -0.259023     -0.0213549   0.072478     0.00291814  -0.128162     0.000899031  -0.0628875    -0.0467477   -0.0421095   -0.00497852  -0.0990961    -0.0815926     0.06792    -0.0733534     0.0262919   -0.119935     0.0871406    -0.0224893    0.0921386   -0.0274731     0.0395385
 -0.0345114    0.0670058  -0.0566318    0.00924176   0.00733775   0.130246     -0.0756813   0.0769661   -0.0873548    0.0464757   -0.0758292     0.0227723     0.00300549   0.14457     -0.130573    -0.0518575    -0.0988228     0.0228203  -0.223227      0.0285744   -0.0627411   -0.169919     -0.13777     -0.0122915    0.210045      0.0472157
  0.026543     0.0593485  -0.161       -0.101754    -0.0233892    0.00508795   -0.073589    0.00978314  -0.00289513  -0.0528657   -0.101462      0.0354009    -0.100816    -0.240536    -0.023072    -0.0621312     0.0612735    -0.130723   -0.008109      0.10642      0.0589889   -0.053738      0.095717    -0.121429    -0.0809661     0.0113671
 -0.119534    -0.0252632  -0.00873622   0.0105264   -0.0395414   -0.0178923    -0.0748315  -0.116905    -0.0302814    0.0713249    0.0376698     0.00286632    0.066169    -0.0767742    0.135503     0.0253258    -0.197893      0.0130327  -0.0149018    -0.121        0.0407312   -0.0904172    -0.0811759    0.0324559    0.00156131    0.0245162
  0.0033402   -0.0989592  -0.00780972   0.085794     0.0356868   -0.0698063     0.0440219   0.059277     0.175583    -0.183053    -0.0731269    -0.0239981    -0.121903     0.0335185    0.0586084   -0.0607302     0.0343202     0.173393   -0.046313     -0.104641    -0.00920189  -0.0174503     0.0168085   -0.098173     0.0238003    -0.073074
  0.147361     0.0491008  -0.0739651   -0.0293014    0.0686174    0.0990748    -0.0333603   0.0445331    0.114796     0.0268078   -0.0547446    -0.146964      0.0375706   -0.0427299   -0.0631955   -0.149273     -0.0448583     0.174397   -0.0155038    -0.0164345   -0.043846    -0.098885      0.0632407    0.146095     0.0637488    -0.0403442
  0.087889    -0.0926526   0.0791912    0.0162333   -0.0634638    0.0635103     0.175156   -0.06965      0.0352401    0.134427     0.028271      0.0237094     0.0283961   -0.123454    -0.0402236    0.0622473    -0.132519     -0.0215358   0.107338      0.114838    -0.0861667    0.0771681     0.0655919    0.0467786    0.0360544    -0.0629673
 -0.147878    -0.0287285  -0.0214111    0.153545    -0.130398     0.126476      0.0641419   0.0386234   -0.153748    -0.086437     0.0368973    -0.0884422     0.00627967  -0.100319     0.0833824    0.0822392     0.0143442     0.0049116   0.0119456     0.0173602   -0.0182158   -0.0282432    -0.0691294    0.14615     -0.0267922    -0.0410963
  0.0346045    0.167092   -0.264021     0.234501     0.0313628    0.0634599    -0.0635926  -0.0815054   -0.0222392    0.00449055   0.0388523     0.0839709     0.083538     0.029775     0.0512456   -0.0364332    -0.150169      0.057922   -0.0543479     0.031671    -0.00558745   0.0170488    -0.087437     0.142692    -0.0397999    -0.0414053
  0.127053    -0.0582451   0.094664    -0.067288    -0.0380348   -0.0363239    -0.0813964  -0.0920865    0.0424192   -0.14545     -0.036595      0.115072      0.0572201    0.0784021   -0.0312206   -0.145429      0.227109     -0.0386733   0.000292166  -0.180148    -0.120476     0.139827      0.119938     0.287951    -0.0514735     0.0733038
 -0.105358    -0.0692579  -0.130231    -0.106846     0.0656107    0.0689491     0.102016   -0.0240434    0.081554     0.0142843   -0.0232521     0.155882     -0.0918241    0.0626211   -0.0429787    0.0239507    -0.150061      0.118335   -0.0415494    -0.148106    -0.023947     0.105309      0.00726104  -0.0571746   -0.224876      0.0950036
  0.0667326   -0.10261    -0.0991336   -0.141182    -0.00912896  -0.0463096     0.140571   -0.0168477   -0.123897    -0.046514    -0.0315824    -0.00456097   -0.0536742   -0.0689252    0.155152     0.046899      0.11768       0.143231    0.0551964     0.0784193   -0.081689     0.013872     -0.017931    -0.0910007    0.00150732    0.0131974
 -0.132025    -0.0497542  -0.0257666    0.013101    -0.0459318    0.00951429   -0.124726    0.14872     -0.124027     0.17691     -0.0299233    -0.0951642     0.0155665   -0.154372    -0.0228819   -0.0554082    -0.121848      0.055736    0.10654      -0.0159422    0.0368529    0.0857401     0.0392178   -0.00386454   0.090458     -0.0996348
  0.0318329   -0.0427764  -0.080952     0.0581102    0.117562     0.0755579    -0.0435292  -0.173973    -0.0856865    0.0455856   -0.186267      0.0503558    -0.00843756   0.0255391    0.0225705   -0.286723      0.0447211     0.259735   -0.188954     -0.0413629   -0.132336     0.124232      0.0748036   -0.00244163  -0.0243977    -0.147138kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3839373444067649
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.384009
[ Info: iteration 2, average log likelihood -1.383924
[ Info: iteration 3, average log likelihood -1.383161
[ Info: iteration 4, average log likelihood -1.375355
[ Info: iteration 5, average log likelihood -1.357417
[ Info: iteration 6, average log likelihood -1.351791
[ Info: iteration 7, average log likelihood -1.350894
[ Info: iteration 8, average log likelihood -1.350452
[ Info: iteration 9, average log likelihood -1.350142
[ Info: iteration 10, average log likelihood -1.349882
[ Info: iteration 11, average log likelihood -1.349618
[ Info: iteration 12, average log likelihood -1.349276
[ Info: iteration 13, average log likelihood -1.348742
[ Info: iteration 14, average log likelihood -1.348162
[ Info: iteration 15, average log likelihood -1.347676
[ Info: iteration 16, average log likelihood -1.347279
[ Info: iteration 17, average log likelihood -1.346942
[ Info: iteration 18, average log likelihood -1.346655
[ Info: iteration 19, average log likelihood -1.346406
[ Info: iteration 20, average log likelihood -1.346194
[ Info: iteration 21, average log likelihood -1.346029
[ Info: iteration 22, average log likelihood -1.345901
[ Info: iteration 23, average log likelihood -1.345797
[ Info: iteration 24, average log likelihood -1.345709
[ Info: iteration 25, average log likelihood -1.345637
[ Info: iteration 26, average log likelihood -1.345580
[ Info: iteration 27, average log likelihood -1.345536
[ Info: iteration 28, average log likelihood -1.345501
[ Info: iteration 29, average log likelihood -1.345470
[ Info: iteration 30, average log likelihood -1.345441
[ Info: iteration 31, average log likelihood -1.345408
[ Info: iteration 32, average log likelihood -1.345360
[ Info: iteration 33, average log likelihood -1.345269
[ Info: iteration 34, average log likelihood -1.345013
[ Info: iteration 35, average log likelihood -1.344141
[ Info: iteration 36, average log likelihood -1.342464
[ Info: iteration 37, average log likelihood -1.341166
[ Info: iteration 38, average log likelihood -1.340677
[ Info: iteration 39, average log likelihood -1.340536
[ Info: iteration 40, average log likelihood -1.340495
[ Info: iteration 41, average log likelihood -1.340480
[ Info: iteration 42, average log likelihood -1.340474
[ Info: iteration 43, average log likelihood -1.340471
[ Info: iteration 44, average log likelihood -1.340470
[ Info: iteration 45, average log likelihood -1.340469
[ Info: iteration 46, average log likelihood -1.340468
[ Info: iteration 47, average log likelihood -1.340468
[ Info: iteration 48, average log likelihood -1.340468
[ Info: iteration 49, average log likelihood -1.340468
[ Info: iteration 50, average log likelihood -1.340468
┌ Info: EM with 100000 data points 50 iterations avll -1.340468
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3840088404126025
│     -1.3839236958420813
│      ⋮
└     -1.3404678154927523
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.340599
[ Info: iteration 2, average log likelihood -1.340469
[ Info: iteration 3, average log likelihood -1.339850
[ Info: iteration 4, average log likelihood -1.334037
[ Info: iteration 5, average log likelihood -1.319624
[ Info: iteration 6, average log likelihood -1.311230
[ Info: iteration 7, average log likelihood -1.308396
[ Info: iteration 8, average log likelihood -1.307010
[ Info: iteration 9, average log likelihood -1.306119
[ Info: iteration 10, average log likelihood -1.305557
[ Info: iteration 11, average log likelihood -1.305201
[ Info: iteration 12, average log likelihood -1.304970
[ Info: iteration 13, average log likelihood -1.304812
[ Info: iteration 14, average log likelihood -1.304695
[ Info: iteration 15, average log likelihood -1.304601
[ Info: iteration 16, average log likelihood -1.304524
[ Info: iteration 17, average log likelihood -1.304458
[ Info: iteration 18, average log likelihood -1.304400
[ Info: iteration 19, average log likelihood -1.304349
[ Info: iteration 20, average log likelihood -1.304303
[ Info: iteration 21, average log likelihood -1.304262
[ Info: iteration 22, average log likelihood -1.304224
[ Info: iteration 23, average log likelihood -1.304190
[ Info: iteration 24, average log likelihood -1.304158
[ Info: iteration 25, average log likelihood -1.304129
[ Info: iteration 26, average log likelihood -1.304102
[ Info: iteration 27, average log likelihood -1.304079
[ Info: iteration 28, average log likelihood -1.304057
[ Info: iteration 29, average log likelihood -1.304038
[ Info: iteration 30, average log likelihood -1.304021
[ Info: iteration 31, average log likelihood -1.304006
[ Info: iteration 32, average log likelihood -1.303993
[ Info: iteration 33, average log likelihood -1.303981
[ Info: iteration 34, average log likelihood -1.303971
[ Info: iteration 35, average log likelihood -1.303963
[ Info: iteration 36, average log likelihood -1.303956
[ Info: iteration 37, average log likelihood -1.303949
[ Info: iteration 38, average log likelihood -1.303944
[ Info: iteration 39, average log likelihood -1.303939
[ Info: iteration 40, average log likelihood -1.303936
[ Info: iteration 41, average log likelihood -1.303933
[ Info: iteration 42, average log likelihood -1.303930
[ Info: iteration 43, average log likelihood -1.303928
[ Info: iteration 44, average log likelihood -1.303926
[ Info: iteration 45, average log likelihood -1.303924
[ Info: iteration 46, average log likelihood -1.303923
[ Info: iteration 47, average log likelihood -1.303922
[ Info: iteration 48, average log likelihood -1.303921
[ Info: iteration 49, average log likelihood -1.303920
[ Info: iteration 50, average log likelihood -1.303919
┌ Info: EM with 100000 data points 50 iterations avll -1.303919
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3405987859875022
│     -1.3404686761020685
│      ⋮
└     -1.3039190395626163
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.304114
[ Info: iteration 2, average log likelihood -1.303897
[ Info: iteration 3, average log likelihood -1.302704
[ Info: iteration 4, average log likelihood -1.293611
[ Info: iteration 5, average log likelihood -1.273522
[ Info: iteration 6, average log likelihood -1.258693
[ Info: iteration 7, average log likelihood -1.252932
[ Info: iteration 8, average log likelihood -1.250532
[ Info: iteration 9, average log likelihood -1.249307
[ Info: iteration 10, average log likelihood -1.248540
[ Info: iteration 11, average log likelihood -1.247954
[ Info: iteration 12, average log likelihood -1.247411
[ Info: iteration 13, average log likelihood -1.246785
[ Info: iteration 14, average log likelihood -1.246043
[ Info: iteration 15, average log likelihood -1.245329
[ Info: iteration 16, average log likelihood -1.244959
[ Info: iteration 17, average log likelihood -1.244816
[ Info: iteration 18, average log likelihood -1.244734
[ Info: iteration 19, average log likelihood -1.244653
[ Info: iteration 20, average log likelihood -1.244555
[ Info: iteration 21, average log likelihood -1.244439
[ Info: iteration 22, average log likelihood -1.244314
[ Info: iteration 23, average log likelihood -1.244204
[ Info: iteration 24, average log likelihood -1.244116
[ Info: iteration 25, average log likelihood -1.244048
[ Info: iteration 26, average log likelihood -1.243996
[ Info: iteration 27, average log likelihood -1.243956
[ Info: iteration 28, average log likelihood -1.243925
[ Info: iteration 29, average log likelihood -1.243898
[ Info: iteration 30, average log likelihood -1.243872
[ Info: iteration 31, average log likelihood -1.243844
[ Info: iteration 32, average log likelihood -1.243813
[ Info: iteration 33, average log likelihood -1.243778
[ Info: iteration 34, average log likelihood -1.243737
[ Info: iteration 35, average log likelihood -1.243692
[ Info: iteration 36, average log likelihood -1.243648
[ Info: iteration 37, average log likelihood -1.243609
[ Info: iteration 38, average log likelihood -1.243579
[ Info: iteration 39, average log likelihood -1.243555
[ Info: iteration 40, average log likelihood -1.243536
[ Info: iteration 41, average log likelihood -1.243521
[ Info: iteration 42, average log likelihood -1.243509
[ Info: iteration 43, average log likelihood -1.243498
[ Info: iteration 44, average log likelihood -1.243489
[ Info: iteration 45, average log likelihood -1.243480
[ Info: iteration 46, average log likelihood -1.243472
[ Info: iteration 47, average log likelihood -1.243463
[ Info: iteration 48, average log likelihood -1.243454
[ Info: iteration 49, average log likelihood -1.243444
[ Info: iteration 50, average log likelihood -1.243434
┌ Info: EM with 100000 data points 50 iterations avll -1.243434
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3041136302271192
│     -1.3038971694071568
│      ⋮
└     -1.2434339580080864
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.243713
[ Info: iteration 2, average log likelihood -1.243378
[ Info: iteration 3, average log likelihood -1.242192
[ Info: iteration 4, average log likelihood -1.230261
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.195533
[ Info: iteration 6, average log likelihood -1.178446
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.166628
[ Info: iteration 8, average log likelihood -1.166135
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.158832
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.166252
[ Info: iteration 11, average log likelihood -1.165180
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.157871
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.161183
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.161016
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.165023
[ Info: iteration 16, average log likelihood -1.163741
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.157824
[ Info: iteration 18, average log likelihood -1.160726
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.155816
[ Info: iteration 20, average log likelihood -1.158778
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.154424
[ Info: iteration 22, average log likelihood -1.158012
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.153867
[ Info: iteration 24, average log likelihood -1.157335
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.152848
[ Info: iteration 26, average log likelihood -1.155582
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.149908
[ Info: iteration 28, average log likelihood -1.151845
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.146855
[ Info: iteration 30, average log likelihood -1.150353
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.145976
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.148483
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.155669
[ Info: iteration 34, average log likelihood -1.152579
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.147080
[ Info: iteration 36, average log likelihood -1.150676
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.146739
[ Info: iteration 38, average log likelihood -1.150606
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.146717
[ Info: iteration 40, average log likelihood -1.150591
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.146712
[ Info: iteration 42, average log likelihood -1.150584
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.146710
[ Info: iteration 44, average log likelihood -1.150579
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.146709
[ Info: iteration 46, average log likelihood -1.150574
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.146708
[ Info: iteration 48, average log likelihood -1.150569
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.146707
[ Info: iteration 50, average log likelihood -1.150564
┌ Info: EM with 100000 data points 50 iterations avll -1.150564
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2437127161361445
│     -1.2433778702555636
│      ⋮
└     -1.1505636161028459
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.147064
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.146510
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.141190
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.108490
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      7
│      9
│     10
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.059050
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.049889
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│      9
│     10
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.048615
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│      8
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.044650
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.040286
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│      9
│     10
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.045269
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      7
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.042315
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.041922
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.033609
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.055406
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.038017
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      8
│      9
│     10
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.041828
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      7
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.048647
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.037542
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.032134
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.055400
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      7
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.037983
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│      9
│     10
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.048752
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      7
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.043597
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.041934
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.033609
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.055397
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.038007
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      8
│      9
│     10
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.041819
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      7
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.048637
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.037532
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.032124
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.055391
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      7
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.037973
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│      9
│     10
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.048744
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      7
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.043589
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.041927
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.033602
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.055391
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.038000
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      8
│      9
│     10
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.041814
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      7
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.048632
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.037528
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.032119
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.055388
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      7
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.037969
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│      9
│     10
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.048742
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      7
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.043586
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.041925
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.033600
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.055389
┌ Info: EM with 100000 data points 50 iterations avll -1.055389
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1470639202679611
│     -1.1465100465263312
│      ⋮
└     -1.055389276362629
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3839373444067649
│     -1.3840088404126025
│     -1.3839236958420813
│     -1.383161066432765
│      ⋮
│     -1.0419251780083958
│     -1.0335995971527596
└     -1.055389276362629
32×26 Array{Float64,2}:
  0.0208582  -0.076618     0.137424     0.0224863    0.0184687   -0.0216079    0.0649029   -0.140999      0.128829     0.0212445    -0.0215384   -0.24091      -0.0480214     0.0196524    0.341773    -0.113645    -0.0122619    0.100665     0.105727    -0.0618023    0.219938    -0.279901     0.21048     -0.280857      0.00967447  -0.0605729
  0.0203198   0.250838     0.0166669    0.0589842    0.11531     -0.0251646   -0.059673     0.183201      0.0104001   -0.0524405    -0.18428     -0.00196385    0.0735671    -0.116167     0.186571    -0.0179256   -0.0852557   -0.0284757    0.0159704    0.0243491    0.0894369   -0.0267197   -0.102015     0.143334      0.1027       0.0575576
  0.119117   -0.0311604    0.0881856    0.0712747   -0.209762    -0.0882743    0.0695451   -0.0402067     0.0366561   -0.179525      0.119304    -0.0530162    -0.0706301    -0.0157229    0.00169049  -0.00697402  -0.12796      0.0197676    0.0200125    0.0354771   -0.1146      -0.0909581    0.0308652    0.119477      0.00113723   0.241655
 -1.2928e-5   0.063967    -0.045741     0.0159759    0.0163026    0.161322    -0.0674705    0.0209265    -0.0830559    0.0371651    -0.0539478    0.0159048    -0.0112389     0.143184    -0.0880418   -0.0430853   -0.100266     0.0289262   -0.201406     0.038228    -0.0537513   -0.178462    -0.138689    -0.0200796     0.200693     0.057669
  0.0805599  -0.134248    -0.0554283   -0.165179    -0.12783     -0.0901947    0.29741      0.121025      0.165485     0.0353692    -0.0722732   -0.0576264    -0.114599     -0.0249376   -0.0262583    0.0545979   -0.021933    -0.152738    -0.0242915   -0.0507389   -0.0798143   -0.133209     0.128973     0.0956259     0.0783413    0.0180881
  0.145618    0.0337155   -0.0823473   -0.0341455    0.0697574    0.0898816   -0.0355203    0.0674715     0.0969409    0.0179933    -0.0585396   -0.14959       0.0539101    -0.0293908   -0.058309    -0.137067    -0.0455972    0.188385    -0.00423622  -0.040755    -0.0527302   -0.153394     0.070988     0.134493      0.0672946   -0.0466026
  0.0610055   0.057282    -0.127085    -0.0816702   -0.146197     0.0209197    0.0204598   -0.0837776    -0.201121    -0.0542713     0.0285922    0.000303877  -0.000207117   0.0632304    0.159807     0.116457     0.0726524    0.231494    -0.117316     0.00376895   0.0156146   -0.0115528   -0.0276866    0.055387      0.074073     0.129856
  0.0348974  -0.0436695   -0.0922102    0.0591014    0.118291     0.0547414   -0.056851    -0.172036     -0.0227995    0.0489668    -0.201493     0.0627644     0.000329881   0.0550589    0.0323828   -0.268343     0.0428447    0.25414     -0.186604    -0.0279073   -0.131765     0.0511677    0.0766794    0.00294434   -0.0239096   -0.165403
  0.0117207  -0.133164     0.0496426   -0.0170309    0.105401    -0.0457439   -0.00705505  -0.293711     -0.0393209   -0.0431384     0.159098     0.253179      0.0206128    -0.120394    -0.182464     0.0610905   -0.390198     0.164209    -0.0518717   -0.136656    -0.152961     0.024058     0.0578247   -0.0281701     0.244188     0.139415
  0.0108849  -0.140335     0.259593    -0.0314162    0.0834129    0.246638     0.00521075   0.318244     -0.0421838    0.133501      0.159019    -0.495637      0.0940589     0.0121597   -0.146627    -0.0631913    0.0627936    0.039741    -0.0624907   -0.143799    -0.191968     0.044062     0.160581    -0.0132337     0.116657    -0.0176979
 -0.128281    0.0310533   -0.00777342  -0.0669681    0.0469913   -0.120856    -0.0834529    0.105908      0.0876083   -0.104558      0.152188     0.0234725     0.0212356     0.103756    -0.101379    -0.200043     0.050771     0.0494064   -0.0289506    0.128362    -0.0538654   -0.122673    -0.0603046    0.0376341     0.118128    -0.0359158
 -0.0349901   0.0224608    0.00111976   0.0845859    0.0351297   -0.224229    -0.0676398    0.0759588     0.0597388   -0.053928     -0.168353     0.0233214    -0.0563545     0.0881201    0.0654113    0.276967    -0.0642612    0.0772425   -0.0315162    0.166393     0.0971718   -0.0938125   -0.113993     0.0527396     0.124908    -0.0331489
  0.0414625   0.037341    -0.155051     0.0515367   -0.0100386    0.0443118    0.0572771    0.00686154    0.0527528   -0.097703     -0.0647773   -0.0141951    -0.00820264   -0.120021    -0.040303    -0.00226822  -0.0288272   -0.0604774   -0.0460421    0.16149      0.00211621  -0.00576561  -0.0220117   -0.0958499    -0.0443737   -0.0286129
  0.0762137  -0.087973     0.145301    -0.0805773    0.0529641    0.113033    -0.0518093   -0.0203308     0.141479     0.0354502    -0.00556551  -0.0317405     0.0147715     0.128994     0.0127966    0.00994687  -0.0377131   -0.0536403   -0.04662     -0.141222    -0.0443359   -0.00339075   0.0577335    0.000400208  -0.0474862    0.0418934
 -0.117618   -0.00404684   0.0422971    0.00884766  -0.03756     -0.0182897   -0.0391823   -0.12634      -0.0483545    0.0845388     0.0403098   -0.0214836     0.076578     -0.0622995    0.142296     0.0221732   -0.210847     0.0139153   -0.0156034   -0.105807     0.0328866   -0.092039    -0.0902015    0.0304141    -0.00369945  -0.00311786
 -0.148624   -0.0155445   -0.0137409    0.15151     -0.1281       0.116343     0.0717816    0.0299968    -0.157808    -0.0957137     0.0274986   -0.0901638    -0.0222929    -0.100188     0.0748748    0.0512218    0.0246049    0.0645439    0.0213421    0.0250326   -0.0502959   -0.027374    -0.0805702    0.169522     -0.0389736   -0.0176364
 -0.113371   -0.0668565   -0.157303    -0.101142     0.0780803    0.0713609    0.111451    -0.0233045     0.0998251    0.0146652    -0.0181053    0.146512     -0.0914578     0.0975625   -0.043462     0.0228703   -0.143233     0.124106    -0.0657935   -0.14495     -0.0645066    0.0694415   -0.0111766   -0.0581436    -0.293981     0.0994894
 -0.130352    0.0978657   -0.181098     0.0631736   -0.0733949   -0.0666759    0.0239824   -0.000574471  -0.015444    -0.0150371    -0.0912711    0.150291      0.0393123     0.130552    -0.021616    -0.0102723    0.028162     0.0410181    0.031439     0.00759751   0.0378336   -0.113975     0.00605283  -0.199116     -0.077754     0.0334122
  0.0737766   0.123296    -0.158283     0.159104    -0.103988    -0.0316894   -0.081483    -0.0988161    -0.0540647   -0.00604062    0.0362251    0.0153297     0.0338774     0.0638353    0.0749599   -0.037886    -0.067661    -0.0308052   -0.0619579    0.0623859   -0.0357627   -0.0274264   -0.0666878    0.125262     -0.0409791   -0.0353674
 -0.0371439   0.0813438   -0.0764438    0.131746    -0.0306269    0.155698     0.0814561    0.0599359     0.0218951    0.106751      0.139589     0.135301      0.14921       0.0802012   -0.00561962  -0.0356821    0.00287474   0.185951     0.105959    -0.0937599    0.0362279   -0.0873276    0.115609     0.0895982     0.231592     0.0171007
 -0.138228    0.0725457    0.0918086   -0.0597932   -0.127197    -0.285802    -0.01034      0.0756851     0.00241673  -0.122476     -0.0429774   -0.0661192    -0.0462568    -0.0374948    0.00709366  -0.112046    -0.116776     0.0659953   -0.0644942    0.0186972   -0.0847703    0.0850918   -0.0215779    0.0799833    -0.0236206    0.040143
 -0.0590201   0.134138    -0.183073    -0.110574    -0.0309347   -0.0208442    0.048898    -0.0160669    -0.0191145   -0.0487457    -0.0648072   -0.149143     -0.0435968    -0.11022      0.0657752    0.0641805   -0.0563014    0.113515    -0.0330766    0.149634     0.00719927  -0.00394849  -0.0165317   -0.132242      0.0410377   -0.0734789
 -0.0245526  -0.0888182   -0.0133689    0.139646     0.0287683   -0.0610926    0.0594584    0.042714      0.180834    -0.193955     -0.0857208   -0.052547     -0.135968      0.0516459    0.0528161   -0.0733103   -0.00307006   0.18875     -0.0683507   -0.11394     -0.0148343   -0.0317852    0.0586313   -0.097737      0.0175178   -0.0756822
  0.0260701  -0.0508459    0.177931    -0.0851764   -0.00945857   0.0267866   -0.10045      0.0993718    -0.037678    -0.146407     -0.205429     0.0830595     0.0321078     0.220151     0.0416151    0.249905     0.0615383    0.0213067    0.0781699    0.00788763  -0.1399      -0.146395    -0.0314482   -0.0961354    -0.103442     0.055104
  0.125594   -0.0518213    0.0946054   -0.0548265   -0.0420898   -0.0374254   -0.0656171   -0.0853564     0.0726503   -0.14513      -0.0371501    0.125471      0.0596876     0.0775054   -0.0272578   -0.179625     0.19724     -0.0545854   -0.00579341  -0.192865    -0.11672      0.160622     0.100894     0.276313     -0.0835783    0.0646197
  0.0948378  -0.0856195    0.0791182    0.00854709  -0.0632833    0.0566259    0.163164    -0.0735452     0.00926302   0.131331      0.0333725    0.0259989     0.0247643    -0.129449    -0.0366812    0.0792604   -0.133622    -0.00896951   0.0910598    0.135966    -0.0942209    0.0441776    0.0659464    0.0465428     0.0292836   -0.06452
  0.021344    0.0202852    0.0838317   -0.00383011   0.0547983   -0.106806    -0.0700876   -0.0135415    -0.0586956    0.00966954   -0.134185    -0.012568     -0.0998298    -0.0365203   -0.212356    -0.0715545    0.0781385   -0.219796     0.250041     0.146517     0.121789     0.0201546    0.0140473   -0.0571922     0.0744354   -0.0205566
 -0.145071   -0.0095336   -0.0176341    0.00916248  -0.0473584    0.00911209  -0.124093     0.0884804    -0.106358     0.231495     -0.0266849   -0.0791907     0.0408992    -0.145453    -0.0394025   -0.0348643   -0.137763     0.0546774    0.111748    -0.016371     0.0412367    0.0773129    0.037908    -0.0158383     0.0905996   -0.0967133
  0.0403822  -0.106202    -0.102336    -0.122471    -0.0101413   -0.0294633    0.159994    -0.0282572    -0.151215    -0.0656757    -0.198322     0.0393072    -0.0509186    -0.0738432    0.161027     0.0927742    0.13571      0.148417     0.0610276    0.0779851   -0.764603     0.0805582    0.06445     -0.131359     -0.0163921    0.00537129
  0.078477   -0.100925    -0.118839    -0.16846     -0.00966879  -0.0333408    0.00454984  -0.0184794    -0.0912107   -0.0109463     0.0755903   -0.0563385    -0.0419948    -0.0426638    0.153588     0.00858833   0.0989609    0.14491      0.0525989    0.0708048    0.593093    -0.0768942   -0.103401    -0.0416041     0.00161515   0.0290994
  0.0645092  -0.105259    -0.106192     0.324787     0.0553695    0.0312396    0.00383406   0.0767667    -0.147039     0.0136774    -0.401551     0.191071     -0.0694898    -0.0709835   -0.098668    -0.177538     0.0418196   -0.0624052   -0.0327703    0.217432    -0.105317    -0.16455      0.106879     0.0926245     0.0948801    0.0565498
 -0.0170846  -0.0762378    0.153258     0.0214606    0.0521828   -0.0729792   -0.177012     0.112957     -0.0116286   -0.000284452   0.579485     0.0431206     0.131835     -0.00119068  -0.0897246    0.0578998    0.0911536    0.0185595    0.080295     0.00318583  -0.0260075   -0.211571    -0.155843    -0.104566      0.17342      0.10072[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.037998
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     24
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.020910
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      7
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.037938
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     24
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.022522
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.037936
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     24
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.020852
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      7
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.037938
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     24
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.022518
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│      9
│     10
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.037936
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     24
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.020851
┌ Info: EM with 100000 data points 10 iterations avll -1.020851
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.392753e+05
      1       6.497863e+05      -1.894890e+05 |       32
      2       6.228001e+05      -2.698622e+04 |       32
      3       6.074431e+05      -1.535698e+04 |       32
      4       5.967619e+05      -1.068119e+04 |       32
      5       5.900757e+05      -6.686192e+03 |       32
      6       5.856028e+05      -4.472948e+03 |       32
      7       5.829698e+05      -2.632951e+03 |       32
      8       5.813410e+05      -1.628820e+03 |       32
      9       5.801529e+05      -1.188070e+03 |       32
     10       5.791976e+05      -9.552830e+02 |       32
     11       5.784548e+05      -7.428314e+02 |       32
     12       5.778329e+05      -6.219202e+02 |       32
     13       5.772870e+05      -5.458617e+02 |       32
     14       5.768591e+05      -4.278948e+02 |       32
     15       5.765369e+05      -3.222469e+02 |       32
     16       5.762656e+05      -2.713099e+02 |       32
     17       5.760733e+05      -1.922735e+02 |       32
     18       5.759064e+05      -1.668860e+02 |       32
     19       5.757236e+05      -1.828427e+02 |       31
     20       5.755362e+05      -1.873711e+02 |       32
     21       5.753000e+05      -2.361908e+02 |       32
     22       5.750727e+05      -2.273303e+02 |       32
     23       5.749049e+05      -1.677529e+02 |       32
     24       5.747950e+05      -1.098896e+02 |       32
     25       5.747117e+05      -8.329508e+01 |       31
     26       5.746525e+05      -5.929117e+01 |       31
     27       5.746110e+05      -4.143910e+01 |       30
     28       5.745683e+05      -4.269467e+01 |       32
     29       5.745165e+05      -5.179285e+01 |       30
     30       5.744581e+05      -5.847378e+01 |       31
     31       5.743685e+05      -8.950866e+01 |       31
     32       5.742635e+05      -1.050565e+02 |       32
     33       5.741489e+05      -1.145632e+02 |       32
     34       5.740227e+05      -1.262503e+02 |       31
     35       5.739138e+05      -1.089169e+02 |       32
     36       5.738199e+05      -9.382441e+01 |       31
     37       5.737071e+05      -1.128068e+02 |       31
     38       5.736052e+05      -1.019021e+02 |       32
     39       5.735241e+05      -8.113493e+01 |       32
     40       5.734581e+05      -6.602692e+01 |       32
     41       5.734206e+05      -3.751306e+01 |       31
     42       5.733849e+05      -3.562663e+01 |       31
     43       5.733573e+05      -2.765083e+01 |       31
     44       5.733448e+05      -1.249783e+01 |       29
     45       5.733372e+05      -7.548559e+00 |       27
     46       5.733330e+05      -4.243229e+00 |       24
     47       5.733297e+05      -3.240222e+00 |       23
     48       5.733267e+05      -3.065072e+00 |       28
     49       5.733231e+05      -3.600689e+00 |       24
     50       5.733213e+05      -1.730619e+00 |       17
K-means terminated without convergence after 50 iterations (objv = 573321.3478689499)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.288883
[ Info: iteration 2, average log likelihood -1.252673
[ Info: iteration 3, average log likelihood -1.215610
[ Info: iteration 4, average log likelihood -1.176236
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.131430
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.111647
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.086261
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     15
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.052954
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.074043
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.044885
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     12
│     14
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.035658
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     11
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.057094
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.077344
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.063506
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.039960
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     15
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.056889
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.072172
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      8
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.054185
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.050378
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.055856
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      8
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.062537
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.056920
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     12
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.043309
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.054447
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.057469
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.044729
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     12
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.054751
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.054590
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.044286
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     19
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.043267
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.067841
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     12
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.032078
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      8
│     11
│     19
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.038004
[ Info: iteration 34, average log likelihood -1.103231
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.051684
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.026734
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      8
│     15
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.065044
[ Info: iteration 38, average log likelihood -1.073684
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.034619
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.045483
[ Info: iteration 41, average log likelihood -1.078761
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      8
│     15
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.027791
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.064336
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.074444
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.065233
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│     11
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.041704
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.059040
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.057050
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.051307
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.057803
┌ Info: EM with 100000 data points 50 iterations avll -1.057803
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.142771   -0.00859581  -0.0169957   0.00831633  -0.0462285    0.00840646  -0.124972    0.0838492   -0.107381     0.231168    -0.028532   -0.0773582     0.0394027   -0.145244    -0.0385118   -0.035804    -0.134925     0.0529366     0.113975    -0.016181      0.0428645    0.0767192    0.0379574   -0.0159862    0.0912705   -0.0960448
  0.0196249  -0.0728799    0.137317    0.0247506    0.0182775   -0.0222632    0.0645606  -0.14269      0.129476     0.0188839   -0.0210099  -0.241711     -0.0480432    0.0154148    0.344681    -0.113928    -0.0124517    0.100034      0.105945    -0.0613906     0.220195    -0.284426     0.210598    -0.282089     0.0103197   -0.0600354
  0.115789   -0.0802331    0.0933379  -0.0527134   -0.050312    -0.0373886   -0.0262841  -0.118813     0.15402     -0.151458    -0.0391097   0.100254      0.0509964    0.0682718   -0.0184777   -0.335837     0.326085    -0.0773186    -0.0366891   -0.184664     -0.125239     0.19599      0.139952     0.336031    -0.106954     0.0821238
 -0.0152465  -0.0845585   -0.0106261   0.126269     0.0261033   -0.0548972    0.0454924   0.0522137    0.152916    -0.191051    -0.108605   -0.0406198    -0.125434     0.0756606    0.0521789   -0.0485189    0.002954     0.176482     -0.0650122   -0.111043     -0.0202405   -0.0299128    0.0504136   -0.0974025    0.0227123   -0.0740163
  0.0580963   0.0575378   -0.127532   -0.0810458   -0.145742     0.0229576    0.0206624  -0.0875444   -0.204792    -0.0547639    0.0299445  -0.000633831  -0.00289428   0.0640991    0.160811     0.120926     0.0746182    0.237033     -0.11843      0.00546575    0.0159897   -0.0122673   -0.0276362    0.057459     0.0775036    0.132116
  0.0961318  -0.0860356    0.0798573   0.00511058  -0.06304      0.0516084    0.155553   -0.0743992    0.00905985   0.120593     0.0334764   0.0298584     0.0251555   -0.123808    -0.0375554    0.0667724   -0.130496    -0.0118347     0.0853974    0.120264     -0.0989971    0.04621      0.0672262    0.0466914    0.0276146   -0.0625105
 -0.127064    0.0663952    0.0790231  -0.0504565   -0.0893684   -0.253649    -0.0295958   0.0710182   -0.00277206  -0.114142    -0.0512326  -0.0555287    -0.0541752   -0.0380132   -0.032868    -0.103833    -0.0810138    0.0294999    -0.00657217   0.0473501    -0.0220604    0.0716469   -0.0171598    0.0575947   -0.00835184   0.0278618
  0.0326352  -0.0438792   -0.0910546   0.0591399    0.116893     0.0613259   -0.0545415  -0.178696    -0.0223899    0.0472879   -0.197691    0.0567815     0.00187833   0.0505595    0.0347207   -0.267193     0.0403694    0.249638     -0.184936    -0.0281313    -0.129244     0.0508989    0.0762394    0.00426414  -0.0245754   -0.159171
  0.140084    0.0190589   -0.0698701  -0.0386253    0.0590201    0.0823168   -0.0289916   0.063477     0.0954509   -0.00301677  -0.0509382  -0.10958       0.0504267   -0.023756    -0.0592941   -0.139602    -0.0272347    0.154536      0.00121211  -0.0709198    -0.0563678   -0.0923195    0.0804032    0.155789     0.0523327   -0.0324856
  0.0333424   0.157742    -0.258074    0.236737     0.0218006    0.0607819   -0.0709292  -0.0832515   -0.0255506   -0.0214809    0.0331335   0.0887674     0.0612059    0.0229382    0.050156    -0.0503817   -0.142056     0.066967     -0.0685885    0.0436059    -0.0102958    0.037954    -0.0841345    0.142844    -0.0682091   -0.0303063
  0.0729726   0.0245108    0.101291   -0.00681758   0.0233219   -0.110106    -0.0803337  -0.0578943   -0.0696431   -0.0137186   -0.198213    0.00301132   -0.0761118   -0.00990242  -0.16489     -0.076518     0.116198    -0.210099      0.276857     0.165592      0.140437     0.0261374    0.0142776   -0.0100651    0.0651273   -0.0108316
 -0.0602951   0.13689     -0.189953   -0.111545    -0.0300072   -0.0144912    0.0505576  -0.0163577   -0.0195206   -0.0472843   -0.0651192  -0.156238     -0.0443535   -0.11635      0.0660363    0.0669272   -0.0568591    0.115134     -0.0348244    0.151072      0.013207    -0.00298204  -0.0162957   -0.135736     0.0419323   -0.0776895
  0.0403679  -0.0952936   -0.151746   -0.141997    -0.00869542  -0.0371182    0.100986   -0.0277355   -0.125035    -0.0627914   -0.0687444  -0.000743235  -0.0408997   -0.139235     0.171948     0.0360008    0.117468     0.143761      0.0577741    0.0881405    -0.216347    -0.0446761   -0.00139502  -0.124703     0.00540639   0.00940166
  0.0272836  -0.0321179    0.19101    -0.0957371   -0.0106552    0.0241903   -0.100692    0.0989622   -0.0439274   -0.126522    -0.19262     0.0891934     0.0348317    0.216991     0.0310653    0.256942     0.05913      0.0148991     0.086744     0.00942245   -0.145058    -0.13878     -0.031728    -0.0874891   -0.0987924    0.0600237
  0.117687   -0.0782674    0.0865855  -0.084669    -0.0550271   -0.0371938   -0.104203   -0.0825922    0.0776709   -0.136668    -0.0259616   0.127391      0.0345789    0.0878179   -0.0226539   -0.166471     0.207648     0.0286541    -0.0279808   -0.154209     -0.0422774    0.1194       0.0332872    0.130595    -0.127875     0.0369361
  0.0210293  -0.283773     0.112479   -0.0439453    0.0908665    0.18063     -0.141885    0.0531868    0.234177     0.0852949   -0.17756     0.0401346     0.122223     0.15144      0.0536301    0.121792    -0.0347078   -0.037775     -0.00102925   0.000902868   0.0368027   -0.0113939    0.0313378    0.0123542   -0.201407     0.00943541
 -0.113265   -0.00894744   0.0483428   0.00848485  -0.0366683   -0.0218315   -0.0351485  -0.13695     -0.0481032    0.083454     0.0431103  -0.0237276     0.071003    -0.06473      0.131751     0.0199614   -0.204186     0.00521581   -0.0105705   -0.107466      0.0319648   -0.0760444   -0.0827462    0.0370162   -0.00235483  -0.00364947
  0.0439366   0.126951     0.0364976  -0.148278     0.00729197   0.0331489    0.0170534   0.102956     0.0147296    0.0411948    0.081911   -0.0378333    -0.0693856    0.0852291   -0.0637786   -0.0711922    0.146194    -0.0529118    -0.0121458    0.0144248    -0.21204     -0.0633757    0.0809749   -0.0279131   -0.0313081    0.0931861
  0.135547   -0.0371842    0.0918014   0.0740463   -0.169711    -0.0622258    0.0644917  -0.0419829    0.0336775   -0.178963     0.122331   -0.052389     -0.0524766    0.00947348   0.00345616  -0.0130542   -0.141253     0.038166      0.00983153   0.0396685    -0.124354    -0.125527     0.00666948   0.121381    -0.00632633   0.254962
 -0.0430203   0.043442    -0.0265075   0.0130606    0.0262627   -0.0133249   -0.0707209   0.0448546   -0.00744001  -0.0241184   -0.0320878   0.0269894    -0.0201226    0.118573    -0.0575288   -0.0149041   -0.0466204    0.0353214    -0.12015      0.0802953    -0.0233431   -0.127424    -0.100464     0.0217798    0.164436     0.00748833
 -0.127587    0.093891    -0.178067    0.0614655   -0.0709961   -0.0665331    0.0232583  -0.00256281  -0.0197134   -0.0108407   -0.0856863   0.14885       0.0381873    0.125912    -0.0244832   -0.0132648    0.0300813    0.0372675     0.0323648    0.00824057    0.0372593   -0.108585     0.00939436  -0.186592    -0.0769348    0.0325497
  0.0701771   0.0216299   -0.129874    0.195712    -0.0653675    0.0524232    0.188241    0.0252331    0.099691    -0.131838    -0.0639601  -0.053453      0.0995085    0.00631826  -0.0641941    0.0590267   -0.104168     0.0340765    -0.0739192    0.231731     -0.0605535    0.0170223   -0.114315    -0.0576141   -0.00981052  -0.0683322
  0.025662   -0.0910133    0.015942    0.169763     0.0537447   -0.0276224   -0.0815353   0.0883297   -0.0824516    0.00437604   0.0451512   0.118192      0.0154213   -0.0405795   -0.102813    -0.0666063    0.0655287   -0.0383182     0.0239399    0.115687     -0.0568676   -0.179899    -0.0168909   -0.0202536    0.131417     0.0722064
  0.140716   -0.0785942    0.276469   -0.0523851    0.0428768    0.0863951   -0.0427401  -0.197866     0.163024    -0.0237203    0.0822574  -0.100277     -0.0234276    0.122317     0.0441048   -0.0287302   -0.19039     -0.0747639    -0.0848291   -0.387483      0.00433015   0.0608767    0.0506049    0.0176745    0.0707482    0.0160974
  0.101832   -0.12416      0.0101529  -0.149441    -0.0112178   -0.0290199    0.0351955  -0.0118502   -0.105358     0.0227506   -0.0504901  -0.0282301    -0.0623537    0.156546     0.119446     0.0988574    0.119221     0.150442      0.0528562    0.0419167     0.152931     0.132359    -0.0574817    0.0142275   -0.0335381    0.0379741
  0.0185732   0.251865     0.0192453   0.0637376    0.118426    -0.0288996   -0.0628649   0.181423     0.00327851  -0.0561226   -0.18339     0.00349043    0.0720959   -0.123938     0.198535    -0.0166519   -0.088743    -0.0293537     0.014445     0.0110556     0.101339    -0.030411    -0.102034     0.148508     0.112398     0.0599449
  0.0196154   0.052832    -0.186347   -0.0894206    0.0341198    0.0337014   -0.0839444   0.00136232  -0.018708    -0.0601877   -0.0717031   0.0231031    -0.0992943   -0.233376    -0.0185379   -0.0520986    0.0584872   -0.150333     -0.0130328    0.109844      0.0526277   -0.0357437    0.0845871   -0.120085    -0.0726984    0.00839368
 -0.147895   -0.0167026   -0.0200186   0.152079    -0.124999     0.110423     0.0718918   0.026652    -0.156598    -0.0955125    0.0296642  -0.0983635    -0.0168969   -0.0993856    0.071184     0.0526063    0.0193025    0.0637686     0.0239074    0.0200078    -0.0437056   -0.0246874   -0.0795108    0.168864    -0.0377769   -0.020312
  0.111428   -0.127665    -0.0565712  -0.164413    -0.126029    -0.104293     0.304222    0.125436     0.162852     0.0349959   -0.0696695  -0.0624163    -0.11259     -0.0205462   -0.0316779    0.0537219   -0.0253234   -0.159428     -0.0319617   -0.0641254    -0.0753945   -0.136318     0.120337     0.0972876    0.0899586    0.00987912
 -0.0192039   0.00937744  -0.114619   -0.00225923  -0.0779559   -0.0230232    0.0212798  -0.0701182    0.01581      0.00450441   0.0146383   0.044348     -0.0464753    0.0965285    0.0221028   -0.00888607  -0.0778398   -0.000725737  -0.0574151   -0.0355542    -0.0595717   -0.00712089  -0.0252344    0.0270895   -0.15786      0.0352951
  0.0196174  -0.119155     0.180732   -0.0234164    0.0772294    0.0859489   -0.0073538   0.025784    -0.0439653    0.0522305    0.153908   -0.101475      0.069345    -0.0662986   -0.17329     -0.00432689  -0.147047     0.0773261    -0.059674    -0.157638     -0.179742     0.0381616    0.100264    -0.00444756   0.186988     0.0607265
 -0.0388213   0.0820677   -0.0750336   0.130745    -0.0312579    0.155099     0.0784086   0.0606981    0.0231467    0.104416     0.1406      0.138725      0.147497     0.0803788   -0.00649258  -0.0394008    0.00943657   0.186827      0.106852    -0.0919342     0.0372204   -0.0864673    0.114357     0.0894349    0.238176     0.0179753[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.059038
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     14
│     15
│     19
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.026756
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     14
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.020528
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      8
│     11
│     14
│     15
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.015595
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     14
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.042452
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     14
│     15
│     19
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.015829
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.030824
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     11
│     14
│     15
│     19
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.003084
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     14
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.032764
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     14
│     15
│     19
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.032754
┌ Info: EM with 100000 data points 10 iterations avll -1.032754
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0138395   -0.00130081  -0.0169709   0.0617092   -0.0295586    0.049067     0.0271697     0.132363    -0.0582003   -0.101247     0.081071    -0.016183    0.0713918   -0.0709935   -0.046299     0.0940726     0.0966293    0.193605     0.0763204    0.0328877   -0.050422     -0.160751     0.134628    0.0506341   -0.0920571   -0.0512282
 -0.0980148   -0.0617085   -0.0376337   0.193878     0.0522866   -0.110485     0.0370383     0.0387842    0.100514     0.00849739   0.16748     -0.105154   -0.0436998   -0.187661     0.0816502   -0.128918      0.14774     -0.120572    -0.096952    -0.032159     0.0352401     0.0786318   -0.152545    0.0792151   -0.0113834    0.109881
 -0.161265     0.1708      -0.201992   -0.0470491   -0.0215424   -0.0889139    0.0467813    -0.00327006   0.0476011    0.14476     -0.0261062    0.193151    0.0237958    0.125696    -0.0694396   -0.0277723    -0.124148    -0.0257859    0.00456332  -0.0312092   -0.120534      0.0361722   -0.077463    0.00485185  -0.0762341    0.177637
 -0.00826305   0.0508063    0.0129244  -0.0359902   -0.163461     0.097204     0.1836        0.0322842    0.122595    -0.103366    -0.0480593   -0.0422023   0.0179515    0.0465392   -0.00360835   0.0811306    -0.00183948   0.19319      0.00235047   0.190427     0.0313994    -0.0943607   -0.0596466  -0.04627     -0.177235    -0.0715224
 -0.0856322    0.145541     0.18109     0.0340729    0.036895     0.0626847   -0.0526034     0.0458783   -0.148184     0.157681    -0.0832688   -0.290146   -0.10502      0.054323    -0.0560022    0.0265723     0.123847    -0.101137    -0.0541185    0.0432124    0.0571314    -0.0750835   -0.133482   -0.0138663   -0.0211061    0.0212634
 -0.0582052    0.0712757   -0.040442    0.0629264    0.0202175    0.101394    -0.115468     -0.0299234   -0.0339079    0.136593    -0.122803     0.0600877  -0.102278    -0.0751429   -0.187363    -0.000831083  -0.0320917   -0.0267096    0.0883287   -0.00983177  -0.00881923   -0.0320851    0.05106    -0.0752399   -0.129357     0.179593
  0.109166     0.0459427   -0.0623432   0.213759    -0.115537    -0.0514094   -0.000540471   0.101642    -0.0253419   -0.0885723    0.0298854    0.0519009   0.024039     0.0336457    0.162518    -0.203523      0.0833625    0.0680156    0.0499841    0.0891717    0.0567941     0.0291549   -0.0584772   0.00860347   0.026713    -0.131836
  0.0598704   -0.357083    -0.126375   -0.13275      0.0578508   -0.249267     0.0281181     0.194713     0.0107737   -0.0087333   -0.0542872    0.183461   -0.118385    -0.160102    -0.112588    -0.0449208    -0.0528338    0.118925    -0.0134772    0.0350284    0.000314503  -0.00164774  -0.039531   -0.0920781   -0.039403    -0.168083
  0.0636525    0.0134612    0.149326    0.073059    -0.0495576   -0.0591004   -0.0846966    -0.139392     0.0624394   -0.236266     0.00909538  -0.0697416   0.0378883   -0.027324     0.164871    -0.0815553    -0.0299227    0.0100359    0.0019103    0.0663488   -0.176461     -0.0845676    0.0358283   0.163672    -0.0719883    0.122666
 -0.0798344   -0.184134    -0.118208   -0.0314628   -0.0896092    0.258501     0.131867     -0.157675    -0.117597     0.0367306    0.0465592    0.0677553  -0.175559     0.138345    -0.14387      0.0406569     0.0928074    0.0976543   -0.0932526    0.00324455   0.0346514    -0.00625575   0.0607495  -0.0124046   -0.0202042   -0.104398
 -0.128001     0.0629049   -0.0051094   0.0891424    0.017279    -0.011258     0.0764356     0.0699034    0.121369     0.0108815   -0.0907606   -0.0115655   0.0666104    0.0635621   -0.0866866    0.0386102     0.015898     0.0345312    0.0189761    0.0213012    0.00389282   -0.178038    -0.0220143  -0.25506      0.0229214   -0.169946
 -0.22047      0.0624141    0.0741251   0.00622124  -0.0379932    0.0744675   -0.0480308     0.0272552    0.0262042   -0.0961746   -0.0125365   -0.111108    0.129253     0.0616196    0.148379     0.0580381    -0.0428458    0.0264339    0.0988396   -0.0935128    0.0216932    -0.0647662   -0.0457817  -0.0885078   -0.0759669   -0.0855969
  0.0377054   -0.162409     0.0228171  -0.162949    -0.00851751  -0.0699633   -0.198225     -0.0900742   -0.169163    -0.0499215   -0.189829     0.0529187  -0.00661067   0.025801    -0.107877    -0.00188479   -0.0275677    0.0664793    0.11812      0.202829    -0.0716639    -0.0169909   -0.0501796  -0.110452     0.0474696   -0.0357616
 -0.0741973    0.0354043    0.0675455   0.0785909    0.0302861   -0.0587749    0.0206209     0.267112    -0.0268852    0.0634828   -0.0264723   -0.172734   -0.113162     0.142184     0.0862738   -0.0452258     0.136772     0.175166    -0.00252477   0.108162    -0.00792303    0.132111     0.0968741  -0.0187736   -0.119311     0.12431
  0.0891041   -0.118036    -0.165143   -0.0201842   -0.066515    -0.0287307    0.0822062     0.170473    -0.0296987    0.115637     0.0847213    0.0348811   0.0413002    0.0762702    0.0128658    0.0672972     0.0036681   -0.0349985   -0.0132721   -0.0313646   -0.0436084    -0.019607    -0.124525   -0.0672048   -0.0194249   -0.126198
 -0.0109167    0.00342661   0.109958    0.0342126    0.0481558   -0.0953104    0.137213      0.0086157   -0.0321829   -0.0887484   -0.0463005    0.0344478   0.0215703    0.225225    -0.0456724    0.0411189     0.0759367    0.162926     0.0297339    0.0413749    0.0137004    -0.0740108   -0.0203905   0.0288176   -0.197981     0.0190607
  0.0834803    0.114508     0.0590446   0.0287728    0.0297035   -0.00706111  -0.153392     -0.0952515   -0.160773    -0.183954     0.046667    -0.031671   -0.0349779   -0.0430926    0.0147801    0.0676768    -0.0745588   -0.0961478   -0.0594632    0.115531    -0.2202       -0.00724581  -0.10765     0.0138895    0.101687     0.0367863
  0.0563943   -0.0409641    0.0264985  -0.0110702    0.388638    -0.23259     -0.0981859     0.0287776    0.0798889    0.0551635   -0.00857717   0.134491   -0.0289084    0.0419178   -0.0556221   -0.0224314     0.0645068    0.0513533    0.0225787    0.209019     0.0316657     0.0494895   -0.174983   -0.212777     0.265106    -0.0417678
  0.0511464   -0.0970529    0.0972866  -0.0521347    0.105917     0.0430052   -0.0924057     0.147864     0.0556937    0.146248    -0.00769317  -0.265591   -0.0725286    0.0448821    0.0557761    0.133482     -0.207132     0.0418169   -0.0581097   -0.147035     0.00845222    0.103979     0.0266159  -0.0731629   -0.00280883   0.207037
  0.148482     0.00680014  -0.0417536   0.0495125    0.326897     0.106484     0.0096064    -0.0774475   -0.0277095    0.101115     0.0968805    0.0324164  -0.0435172    0.123625     0.0485172    0.0099067     0.00807606   0.00154056   0.0635581   -0.0479872   -0.00773597    0.0625124    0.0313566  -0.0717193    0.117268    -0.219164
  0.140205    -0.0442682    0.0434157  -0.113304    -0.121708     0.102712     0.161741     -0.173317     0.124698     0.0807268    0.0617073   -0.0319281   0.0199795   -0.0343252    0.147531    -0.0378354     0.0406035    0.233904    -0.117249     0.179084    -0.0211778    -0.119156    -0.0312815  -0.0859354   -0.00860037  -0.0365817
 -0.0845478    0.162632    -0.0644115   0.0551776    0.178361    -0.0142131   -0.13144      -0.0199959   -0.0499154    0.00835641   0.125728    -0.0796008  -0.0801808    0.0280725   -0.158084     0.0407413    -0.00350745   0.0148885   -0.0018791    0.128094    -0.0252279    -0.0827395   -0.133542    0.00695334   0.00363769   0.0495061
 -0.207099     0.0166612   -0.157859    0.123164    -0.135357    -0.0749185   -0.0495298    -0.0115205   -0.00158646   0.0313477   -0.0630586    0.0755039   0.0660887    0.1741      -0.0584485   -0.107044      0.198283     0.0827459    0.0539529    0.0305041    0.0928004    -0.149264    -0.0701126  -0.0630341    0.00962164   0.104996
 -0.190622    -0.0378247   -0.16035    -0.0101231   -0.0508013   -0.0113665    0.0747302     0.0141914   -0.209585    -0.0960874    0.13043     -0.0401128  -0.0971165   -0.048445    -0.0551971    0.187472     -4.47168e-5   0.113494     0.0867522   -0.114408     0.0171396     0.0785929   -0.128273   -0.0231673    0.131671     0.198798
  0.093648     0.0291849   -0.0276887  -0.0282085    0.0568781    0.116737     0.0694267    -0.133007     0.00497774   0.0146432    0.107924    -0.0167386  -0.137062     0.022963     0.191006    -0.0273343     0.0825763   -0.0755519   -0.0876686    0.175786     0.0200921     0.0789093    0.084925    0.190496    -0.348521     0.0673497
  0.0301899    0.134651    -0.0404507  -0.0223673   -0.00872073   0.0637484    0.0613081    -0.0150707    0.00506561  -0.0270994    0.171811    -0.0371437   0.0701955    0.0435233   -0.0112471    0.12311      -0.0200492    0.043569     0.0820179    0.0471991   -0.04877      -0.0983805   -0.19151     0.254032    -0.233259    -0.0872374
  0.0748506    0.0357159    0.0155927  -0.0836632    0.16777     -0.103329    -0.0470258     0.0100487   -0.129116     0.0578674    0.0333415   -0.0447861  -0.0833647   -0.0890307   -0.0326987    0.0958109     0.0063982   -0.0759635   -0.046675     0.105404    -0.0339739    -0.00786344   0.0569448   0.06463      0.0629477    0.0708175
  0.0335377    0.222242    -0.0221434   0.135187     0.0767136   -0.0552859    0.255928     -0.210766    -0.263365    -0.0950725   -0.00965569   0.041876    0.00588769   0.13042      0.168843     0.0856749     0.171797    -0.232101    -0.185444    -0.0890377   -0.0444901     0.154261    -0.0762399  -0.0176839   -0.0810517   -0.180203
  0.0147945   -0.173079    -0.0449643  -0.111086    -0.0324942    0.0628154   -0.0194134     0.0491141    0.0169811    0.130873     0.013198     0.257204    0.0174732    0.00912369  -0.0461539   -0.0412932    -0.157712     0.0385825    0.0343599    0.00719836  -0.0656892    -0.0822223   -0.115894    0.0464617   -0.121283     0.258797
  0.113609    -0.102943     0.175006   -0.0876923   -0.090874     0.054642    -0.00882983    0.018832    -0.0859273    0.161819     0.00659132  -0.115013   -0.0812343   -0.0281696   -0.161768     0.139875     -0.0910158   -0.137099    -0.124479     0.0503986    0.075884      0.0173982   -0.0395532  -0.0317184   -0.0090816   -0.0637911
 -0.021266    -0.0119965   -0.0478837   0.196733    -0.017024     0.0283483   -0.0232367     0.0644941   -0.0790962    0.0124312   -0.0160232    0.232119   -0.0582954    0.180036     0.0180019    0.197691     -0.0163299    0.159167    -0.0404484    0.0339913   -0.108921     -0.144744    -0.143312    0.0733601   -0.192207     0.104046
 -0.144174    -0.059045     0.0685292   0.0856983   -0.193949     0.0885519    0.0123305     0.147055     0.0154697   -0.0589069    0.0732479    0.0470252  -0.0903521   -0.041981     0.0514066    0.050356     -0.0340616    0.0241642   -0.0633906    0.00813137   0.0805421    -0.0946609   -0.0205258  -0.0187821    0.0591249    0.0434541kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.41879107532604
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418809
[ Info: iteration 2, average log likelihood -1.418748
[ Info: iteration 3, average log likelihood -1.418707
[ Info: iteration 4, average log likelihood -1.418662
[ Info: iteration 5, average log likelihood -1.418610
[ Info: iteration 6, average log likelihood -1.418547
[ Info: iteration 7, average log likelihood -1.418466
[ Info: iteration 8, average log likelihood -1.418346
[ Info: iteration 9, average log likelihood -1.418125
[ Info: iteration 10, average log likelihood -1.417670
[ Info: iteration 11, average log likelihood -1.416799
[ Info: iteration 12, average log likelihood -1.415517
[ Info: iteration 13, average log likelihood -1.414283
[ Info: iteration 14, average log likelihood -1.413534
[ Info: iteration 15, average log likelihood -1.413212
[ Info: iteration 16, average log likelihood -1.413092
[ Info: iteration 17, average log likelihood -1.413049
[ Info: iteration 18, average log likelihood -1.413033
[ Info: iteration 19, average log likelihood -1.413027
[ Info: iteration 20, average log likelihood -1.413024
[ Info: iteration 21, average log likelihood -1.413022
[ Info: iteration 22, average log likelihood -1.413022
[ Info: iteration 23, average log likelihood -1.413021
[ Info: iteration 24, average log likelihood -1.413021
[ Info: iteration 25, average log likelihood -1.413020
[ Info: iteration 26, average log likelihood -1.413020
[ Info: iteration 27, average log likelihood -1.413020
[ Info: iteration 28, average log likelihood -1.413019
[ Info: iteration 29, average log likelihood -1.413019
[ Info: iteration 30, average log likelihood -1.413019
[ Info: iteration 31, average log likelihood -1.413019
[ Info: iteration 32, average log likelihood -1.413018
[ Info: iteration 33, average log likelihood -1.413018
[ Info: iteration 34, average log likelihood -1.413018
[ Info: iteration 35, average log likelihood -1.413018
[ Info: iteration 36, average log likelihood -1.413018
[ Info: iteration 37, average log likelihood -1.413018
[ Info: iteration 38, average log likelihood -1.413018
[ Info: iteration 39, average log likelihood -1.413018
[ Info: iteration 40, average log likelihood -1.413018
[ Info: iteration 41, average log likelihood -1.413018
[ Info: iteration 42, average log likelihood -1.413018
[ Info: iteration 43, average log likelihood -1.413017
[ Info: iteration 44, average log likelihood -1.413017
[ Info: iteration 45, average log likelihood -1.413017
[ Info: iteration 46, average log likelihood -1.413017
[ Info: iteration 47, average log likelihood -1.413017
[ Info: iteration 48, average log likelihood -1.413017
[ Info: iteration 49, average log likelihood -1.413017
[ Info: iteration 50, average log likelihood -1.413017
┌ Info: EM with 100000 data points 50 iterations avll -1.413017
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4188094420702473
│     -1.418748368811072
│      ⋮
└     -1.4130172443231814
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413035
[ Info: iteration 2, average log likelihood -1.412972
[ Info: iteration 3, average log likelihood -1.412928
[ Info: iteration 4, average log likelihood -1.412879
[ Info: iteration 5, average log likelihood -1.412823
[ Info: iteration 6, average log likelihood -1.412759
[ Info: iteration 7, average log likelihood -1.412691
[ Info: iteration 8, average log likelihood -1.412624
[ Info: iteration 9, average log likelihood -1.412562
[ Info: iteration 10, average log likelihood -1.412510
[ Info: iteration 11, average log likelihood -1.412467
[ Info: iteration 12, average log likelihood -1.412431
[ Info: iteration 13, average log likelihood -1.412401
[ Info: iteration 14, average log likelihood -1.412375
[ Info: iteration 15, average log likelihood -1.412352
[ Info: iteration 16, average log likelihood -1.412331
[ Info: iteration 17, average log likelihood -1.412312
[ Info: iteration 18, average log likelihood -1.412294
[ Info: iteration 19, average log likelihood -1.412276
[ Info: iteration 20, average log likelihood -1.412259
[ Info: iteration 21, average log likelihood -1.412242
[ Info: iteration 22, average log likelihood -1.412226
[ Info: iteration 23, average log likelihood -1.412210
[ Info: iteration 24, average log likelihood -1.412195
[ Info: iteration 25, average log likelihood -1.412180
[ Info: iteration 26, average log likelihood -1.412166
[ Info: iteration 27, average log likelihood -1.412153
[ Info: iteration 28, average log likelihood -1.412141
[ Info: iteration 29, average log likelihood -1.412130
[ Info: iteration 30, average log likelihood -1.412120
[ Info: iteration 31, average log likelihood -1.412111
[ Info: iteration 32, average log likelihood -1.412103
[ Info: iteration 33, average log likelihood -1.412095
[ Info: iteration 34, average log likelihood -1.412088
[ Info: iteration 35, average log likelihood -1.412082
[ Info: iteration 36, average log likelihood -1.412077
[ Info: iteration 37, average log likelihood -1.412071
[ Info: iteration 38, average log likelihood -1.412067
[ Info: iteration 39, average log likelihood -1.412062
[ Info: iteration 40, average log likelihood -1.412058
[ Info: iteration 41, average log likelihood -1.412055
[ Info: iteration 42, average log likelihood -1.412051
[ Info: iteration 43, average log likelihood -1.412048
[ Info: iteration 44, average log likelihood -1.412045
[ Info: iteration 45, average log likelihood -1.412042
[ Info: iteration 46, average log likelihood -1.412039
[ Info: iteration 47, average log likelihood -1.412036
[ Info: iteration 48, average log likelihood -1.412034
[ Info: iteration 49, average log likelihood -1.412031
[ Info: iteration 50, average log likelihood -1.412029
┌ Info: EM with 100000 data points 50 iterations avll -1.412029
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.413035390949653
│     -1.41297175748255
│      ⋮
└     -1.4120287300112062
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412037
[ Info: iteration 2, average log likelihood -1.411982
[ Info: iteration 3, average log likelihood -1.411939
[ Info: iteration 4, average log likelihood -1.411891
[ Info: iteration 5, average log likelihood -1.411836
[ Info: iteration 6, average log likelihood -1.411771
[ Info: iteration 7, average log likelihood -1.411695
[ Info: iteration 8, average log likelihood -1.411611
[ Info: iteration 9, average log likelihood -1.411524
[ Info: iteration 10, average log likelihood -1.411438
[ Info: iteration 11, average log likelihood -1.411356
[ Info: iteration 12, average log likelihood -1.411281
[ Info: iteration 13, average log likelihood -1.411214
[ Info: iteration 14, average log likelihood -1.411156
[ Info: iteration 15, average log likelihood -1.411108
[ Info: iteration 16, average log likelihood -1.411068
[ Info: iteration 17, average log likelihood -1.411035
[ Info: iteration 18, average log likelihood -1.411008
[ Info: iteration 19, average log likelihood -1.410985
[ Info: iteration 20, average log likelihood -1.410967
[ Info: iteration 21, average log likelihood -1.410950
[ Info: iteration 22, average log likelihood -1.410935
[ Info: iteration 23, average log likelihood -1.410922
[ Info: iteration 24, average log likelihood -1.410910
[ Info: iteration 25, average log likelihood -1.410898
[ Info: iteration 26, average log likelihood -1.410888
[ Info: iteration 27, average log likelihood -1.410878
[ Info: iteration 28, average log likelihood -1.410868
[ Info: iteration 29, average log likelihood -1.410859
[ Info: iteration 30, average log likelihood -1.410851
[ Info: iteration 31, average log likelihood -1.410844
[ Info: iteration 32, average log likelihood -1.410836
[ Info: iteration 33, average log likelihood -1.410830
[ Info: iteration 34, average log likelihood -1.410824
[ Info: iteration 35, average log likelihood -1.410818
[ Info: iteration 36, average log likelihood -1.410813
[ Info: iteration 37, average log likelihood -1.410808
[ Info: iteration 38, average log likelihood -1.410804
[ Info: iteration 39, average log likelihood -1.410800
[ Info: iteration 40, average log likelihood -1.410796
[ Info: iteration 41, average log likelihood -1.410792
[ Info: iteration 42, average log likelihood -1.410789
[ Info: iteration 43, average log likelihood -1.410786
[ Info: iteration 44, average log likelihood -1.410783
[ Info: iteration 45, average log likelihood -1.410780
[ Info: iteration 46, average log likelihood -1.410777
[ Info: iteration 47, average log likelihood -1.410774
[ Info: iteration 48, average log likelihood -1.410772
[ Info: iteration 49, average log likelihood -1.410769
[ Info: iteration 50, average log likelihood -1.410767
┌ Info: EM with 100000 data points 50 iterations avll -1.410767
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412036933335657
│     -1.411982099588537
│      ⋮
└     -1.4107669077222975
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410773
[ Info: iteration 2, average log likelihood -1.410728
[ Info: iteration 3, average log likelihood -1.410690
[ Info: iteration 4, average log likelihood -1.410647
[ Info: iteration 5, average log likelihood -1.410597
[ Info: iteration 6, average log likelihood -1.410537
[ Info: iteration 7, average log likelihood -1.410466
[ Info: iteration 8, average log likelihood -1.410385
[ Info: iteration 9, average log likelihood -1.410297
[ Info: iteration 10, average log likelihood -1.410204
[ Info: iteration 11, average log likelihood -1.410112
[ Info: iteration 12, average log likelihood -1.410022
[ Info: iteration 13, average log likelihood -1.409939
[ Info: iteration 14, average log likelihood -1.409862
[ Info: iteration 15, average log likelihood -1.409793
[ Info: iteration 16, average log likelihood -1.409731
[ Info: iteration 17, average log likelihood -1.409675
[ Info: iteration 18, average log likelihood -1.409625
[ Info: iteration 19, average log likelihood -1.409581
[ Info: iteration 20, average log likelihood -1.409541
[ Info: iteration 21, average log likelihood -1.409504
[ Info: iteration 22, average log likelihood -1.409472
[ Info: iteration 23, average log likelihood -1.409442
[ Info: iteration 24, average log likelihood -1.409414
[ Info: iteration 25, average log likelihood -1.409389
[ Info: iteration 26, average log likelihood -1.409365
[ Info: iteration 27, average log likelihood -1.409343
[ Info: iteration 28, average log likelihood -1.409322
[ Info: iteration 29, average log likelihood -1.409302
[ Info: iteration 30, average log likelihood -1.409284
[ Info: iteration 31, average log likelihood -1.409267
[ Info: iteration 32, average log likelihood -1.409250
[ Info: iteration 33, average log likelihood -1.409234
[ Info: iteration 34, average log likelihood -1.409219
[ Info: iteration 35, average log likelihood -1.409205
[ Info: iteration 36, average log likelihood -1.409191
[ Info: iteration 37, average log likelihood -1.409178
[ Info: iteration 38, average log likelihood -1.409166
[ Info: iteration 39, average log likelihood -1.409153
[ Info: iteration 40, average log likelihood -1.409141
[ Info: iteration 41, average log likelihood -1.409130
[ Info: iteration 42, average log likelihood -1.409119
[ Info: iteration 43, average log likelihood -1.409108
[ Info: iteration 44, average log likelihood -1.409097
[ Info: iteration 45, average log likelihood -1.409087
[ Info: iteration 46, average log likelihood -1.409077
[ Info: iteration 47, average log likelihood -1.409067
[ Info: iteration 48, average log likelihood -1.409057
[ Info: iteration 49, average log likelihood -1.409047
[ Info: iteration 50, average log likelihood -1.409037
┌ Info: EM with 100000 data points 50 iterations avll -1.409037
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4107731284781222
│     -1.4107282369335405
│      ⋮
└     -1.4090371891014504
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409036
[ Info: iteration 2, average log likelihood -1.408970
[ Info: iteration 3, average log likelihood -1.408907
[ Info: iteration 4, average log likelihood -1.408834
[ Info: iteration 5, average log likelihood -1.408743
[ Info: iteration 6, average log likelihood -1.408631
[ Info: iteration 7, average log likelihood -1.408497
[ Info: iteration 8, average log likelihood -1.408347
[ Info: iteration 9, average log likelihood -1.408185
[ Info: iteration 10, average log likelihood -1.408021
[ Info: iteration 11, average log likelihood -1.407861
[ Info: iteration 12, average log likelihood -1.407710
[ Info: iteration 13, average log likelihood -1.407571
[ Info: iteration 14, average log likelihood -1.407444
[ Info: iteration 15, average log likelihood -1.407331
[ Info: iteration 16, average log likelihood -1.407231
[ Info: iteration 17, average log likelihood -1.407143
[ Info: iteration 18, average log likelihood -1.407066
[ Info: iteration 19, average log likelihood -1.406998
[ Info: iteration 20, average log likelihood -1.406938
[ Info: iteration 21, average log likelihood -1.406885
[ Info: iteration 22, average log likelihood -1.406838
[ Info: iteration 23, average log likelihood -1.406794
[ Info: iteration 24, average log likelihood -1.406755
[ Info: iteration 25, average log likelihood -1.406718
[ Info: iteration 26, average log likelihood -1.406683
[ Info: iteration 27, average log likelihood -1.406651
[ Info: iteration 28, average log likelihood -1.406620
[ Info: iteration 29, average log likelihood -1.406591
[ Info: iteration 30, average log likelihood -1.406563
[ Info: iteration 31, average log likelihood -1.406536
[ Info: iteration 32, average log likelihood -1.406511
[ Info: iteration 33, average log likelihood -1.406486
[ Info: iteration 34, average log likelihood -1.406463
[ Info: iteration 35, average log likelihood -1.406440
[ Info: iteration 36, average log likelihood -1.406418
[ Info: iteration 37, average log likelihood -1.406396
[ Info: iteration 38, average log likelihood -1.406376
[ Info: iteration 39, average log likelihood -1.406356
[ Info: iteration 40, average log likelihood -1.406336
[ Info: iteration 41, average log likelihood -1.406317
[ Info: iteration 42, average log likelihood -1.406299
[ Info: iteration 43, average log likelihood -1.406281
[ Info: iteration 44, average log likelihood -1.406263
[ Info: iteration 45, average log likelihood -1.406246
[ Info: iteration 46, average log likelihood -1.406229
[ Info: iteration 47, average log likelihood -1.406213
[ Info: iteration 48, average log likelihood -1.406197
[ Info: iteration 49, average log likelihood -1.406181
[ Info: iteration 50, average log likelihood -1.406166
┌ Info: EM with 100000 data points 50 iterations avll -1.406166
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4090355287707055
│     -1.4089703376468559
│      ⋮
└     -1.4061659311645756
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.41879107532604
│     -1.4188094420702473
│     -1.418748368811072
│     -1.4187071518016305
│      ⋮
│     -1.4061967531934347
│     -1.4061811390090888
└     -1.4061659311645756
32×26 Array{Float64,2}:
  1.0776      0.24224    -0.763998     0.0756356   -0.127727   -0.0340012    0.427014    -0.127398     0.185534   -0.280329    0.279369    -0.0416039  -0.0635712    -0.0642752   -0.280563    -0.0638989    -0.191382    0.290846      0.155749   -0.310461    0.0773544  -0.580247   -0.330245    -0.484624      0.371063    0.364874
  0.656552   -0.18767    -0.0511959   -0.0869054   -0.0556874   0.943951    -0.143065     0.280204    -0.386726   -0.117711   -0.288539    -0.199456    0.769515      0.260917    -0.418959    -0.044471      0.271005    0.0132119    -0.0105927  -0.473348    0.339105   -0.989031   -0.351135     0.103059     -0.373444   -0.000602672
 -0.486575   -0.129424   -0.257373     0.263054     0.72862    -0.450006    -0.168189     0.446269    -0.474441   -1.07312    -0.933768     0.53455    -0.0997767     0.0972426    0.440671    -1.14583      -0.490059    0.222349      0.290245    0.110073    0.576444   -0.283377    0.073051     0.726243      0.0431992  -0.414214
 -0.0823739   0.0270927   0.167106     0.0144813    0.121956   -0.280523    -0.4776      -0.382851    -0.273395    0.309956   -0.492929     0.118515    0.16765       0.189699     0.157328     0.31252       0.182925    0.351285      0.82526    -0.149392    0.0322705   0.230404   -0.130009    -0.970097      0.616163   -0.200277
 -0.775167   -0.688647    0.364222     0.0701547    0.664462    0.492858    -0.555681    -0.753217    -0.105202    0.387985   -0.0801024    0.190094   -0.728315     -0.272879    -0.275858     0.00826702    0.317806    0.192865     -0.323226   -0.0664046   0.957273    0.53751    -0.184401     0.170483     -0.697274    0.309984
  0.0299435  -0.211949   -0.131101     0.55296      0.373493    0.118742     0.767581    -0.143831     0.244857    0.141006    0.195545    -0.0258084  -0.54806       0.298521     0.35121      0.366039      0.424124   -0.0426539     0.365509    0.0434995   0.122878    0.31756    -0.085633    -0.614409     -0.252645    0.834813
  0.667793    0.0718188   0.22821     -0.273332    -0.36159     0.285764     0.462255     0.048656     0.166076   -0.175281    0.271438     0.0151342   0.15024      -0.92383     -0.12978     -0.0962598    -0.0619829  -0.175546      0.425668   -0.103567    0.954534    0.391802    0.299645     0.235238     -0.0456128   0.637177
  0.589443    0.030158   -0.00177167   0.171991    -0.745652    0.06263      0.145646    -0.0692762   -0.0956927   0.680431    0.833942    -0.266534   -0.0193654    -0.88428     -0.387776     1.74474      -0.133872    0.000233306  -0.158003   -0.671577   -0.102736    0.546972   -0.115148    -0.818318      0.0827493   0.930984
 -0.352027   -0.132577    0.192651    -0.120984    -0.17775    -0.0543241   -0.295612     0.125069    -0.249367    0.111277    0.261778    -0.0285305   0.00574128   -0.0953183   -0.357094    -0.320945     -0.0320208   0.0479374    -0.135584    0.183213   -0.134533   -0.393349    0.0296212    0.203103      0.236145   -0.109731
 -0.219543    0.139213   -0.441459    -0.226686     0.0935843  -0.0110674    0.183706    -0.378636     0.457045    0.0746947  -0.397504    -0.133513    0.0401464    -0.0777515    0.69591      0.225892     -0.283441    0.186924     -0.256112   -0.0596551  -0.337245    0.458135   -0.00160394   0.257834     -0.296774   -0.0607342
 -0.0941298  -0.114539   -0.272391    -0.231774    -0.309143   -0.00454221   0.0322722    0.207068     0.151278   -0.182062   -0.0927463   -0.154367    0.0308746    -0.344722    -0.0476419   -0.135093     -0.443721    0.119587     -0.865736    0.255431   -0.071389   -0.468964   -0.205462     0.480711     -0.286557    0.0541829
  0.594417   -0.123129    0.178625    -0.1813       0.174722    0.0282946   -0.140338     0.506828    -0.0812799  -0.664688   -0.145213    -0.119887    0.461323     -0.14002      0.590879     0.0836377     0.0150189  -0.0993674    -0.362915    0.116796    0.306118    0.713471   -0.429991     0.363194     -0.168908   -0.248949
 -0.0129266   0.453127    0.00540382   0.439726     0.205893    0.146837     0.602384     0.522        0.372394   -0.470807    0.00794823   0.0227893   0.000255415   0.41192     -0.403575     0.0889556    -0.0645427   0.0480355    -0.281204    0.719657   -0.161103   -0.241343   -0.0214865    0.254405     -0.074831   -0.663735
 -0.251242    0.378998    0.353769     0.16492     -0.205409    0.604181     0.62978      0.0410675    0.0389345  -0.401604    0.905895    -0.446794   -0.098362      0.156966    -0.267687    -0.302726      0.0852235   0.0784862    -0.252682    0.388218   -0.364609   -0.0306545  -0.561092     0.0547384    -0.699834    0.756848
  0.0405625   0.695924    0.558043     0.177469     0.0903821  -0.192956     0.292906     0.975811    -0.175078    0.200979   -0.0970053   -0.163217   -0.194928      0.349477    -0.584148     0.25036      -0.225787   -0.0937475     0.0711287  -0.203793    0.443483   -0.179376    0.425601    -0.790067     -0.389136   -0.371647
  0.0145397   0.41991     0.620323    -0.139833    -0.314637    0.171026    -0.0843337    0.10842     -0.264731    0.124729   -0.316277     0.48662    -0.339898      0.51429      0.110492     0.451722      0.594619   -0.118698      0.253461    0.577387    0.0256533   0.115548    0.757623     0.38485      -0.649636   -0.095895
  0.0272699  -0.505709    0.100482    -0.163834    -0.136595    0.0302331   -0.44215      0.123786    -0.768574    0.47924    -0.0607815   -0.265325   -0.37363      -0.211964    -0.0610349   -0.047384      0.143186    0.347123      0.342007   -0.369512    0.569942   -0.417284   -0.194686    -0.484306      0.046465    0.126289
 -0.399345   -0.0346257  -0.263631     0.378876     0.1473     -0.127161    -0.19428     -0.42558      0.212533    0.316772    0.174457     0.0114264  -0.735641      0.171935    -0.407408     0.0435646     0.155165   -0.146314      0.351383    0.0995418  -0.174853   -0.208722    0.271755    -0.300021      0.143634    0.27591
  0.0285829  -0.54681    -0.0259012    0.550149    -0.276305   -0.496679    -0.0644411    0.287043    -0.523222   -0.417696    0.38479      0.726125    0.0874789     0.628441    -0.454315    -0.239786      0.559286   -0.481544      0.172732    0.406221    0.286406   -0.30014    -0.0776425   -0.000847577   0.111565    0.270637
  0.184421   -0.818116   -0.630285     0.511008     0.555156   -0.370484    -0.138198    -0.276371    -0.150614   -0.0984567   0.313442     0.187527    0.0635102     0.503324    -0.0581911   -0.217362      0.162874   -0.0402309    -0.278521   -0.190703   -0.488936    0.38881    -0.654704     0.363431     -0.2285     -0.178537
 -0.184899   -0.435527   -0.0517811   -0.184478    -0.503331    0.156012    -0.188815    -0.784848     0.127604   -0.0445273  -0.0098856   -0.0897353   0.149597     -0.60872      0.0512507    0.271368      0.13103    -0.0184227    -0.0145219   0.156689   -0.598784    0.0611387  -0.00137438   0.470691      0.657997   -0.0034709
  0.29976     0.246987   -0.0924104    0.405584    -0.664234   -0.449703     0.0514871    0.396175     0.466918   -0.0295126   0.158903    -0.298931    0.0183849    -0.331507     0.609445     0.0502466     0.166031   -0.583659      0.183428   -0.107457   -0.440929   -0.0280528  -0.111141     0.288588      0.679994    0.139116
 -0.210935    0.224857    0.0939186   -0.158497     0.485032   -0.264011    -0.379371    -0.268303     0.0889224  -0.244087   -0.316831    -0.0652985   0.283765      0.115655     0.0359157   -0.42643      -0.234602   -0.169086     -0.0541594   0.0811578  -0.511244   -0.549138   -0.259141     0.259385      0.750139   -0.899529
 -0.0527774   0.219837    0.0422309   -0.429869     0.307806    0.0196062    0.0106305   -0.500516     0.152796   -0.10096     0.136485    -0.111165   -0.110826     -0.25293      0.00321357  -0.116843     -0.11518     0.0581371     0.134188   -0.369079    0.239734    0.422414    0.192797    -0.434728      0.518814   -0.306083
  0.0770547   0.425674    0.120101    -0.125574    -0.0646982  -0.00755658   0.0227135    0.20456     -0.015504    0.088283   -0.480552    -0.303246    0.118365      0.0923901   -0.105296     0.14778      -0.03576     0.231594      0.108642    0.113479    0.0735506  -0.236505    0.0237653   -0.0155307    -0.188414   -0.358627
 -0.110844    0.126643    0.0443072   -0.181914    -0.220204   -0.0921935    0.00922618  -0.0727786    0.171277    0.563456   -0.146802     0.468632    0.228277     -0.00242829   0.110562    -0.234517     -0.349588    0.312964      0.582836   -0.183225   -0.313744   -0.692466    0.192041    -0.167378      0.114389    0.349248
 -0.450886    0.105241   -0.147103    -0.642525     0.404739    0.38463      0.0764542   -0.199825    -0.224631    0.317528    0.0692927   -0.0874049   0.250338      0.256107     0.156122     0.000317785  -0.0541736   0.581645     -0.310038    0.0478987   0.150962    0.189204   -0.0834675   -0.0777753    -0.574677    0.0361523
 -0.56415     0.0172706   0.322007    -0.0728687    0.0696939  -0.136042    -0.160158     0.703985    -0.151488    0.467194    0.179497     0.45722     0.0738368     0.444713     0.411561     0.23825       0.0588492   0.254952     -0.150008    0.598865   -0.358611    0.237498   -0.197691     0.16949       0.0283289  -0.24264
 -0.177177   -0.425928    0.156281    -0.0288802    0.150852    0.150812    -0.381326    -0.0161451   -0.109967   -0.172192    0.061284     0.151635   -0.168102      0.0374702    0.101748    -0.0860684     0.0102613  -0.407267     -0.183603    0.22224    -0.0507681   0.0617019  -0.124102     0.114201     -0.0845401   0.0504547
  0.0775133  -0.0165848  -0.0508226    0.00766377   0.0484351  -0.0819158    0.163007    -0.00117657   0.0532558  -0.0425557   0.24858     -0.0250951   0.0876492    -0.0800271   -0.0268533   -0.0874656     0.0159783   0.0785952    -0.0319476   0.0574307  -0.049122   -0.0104542  -0.10031      0.00148383    0.136035    0.0415983
  0.398139    0.0362978  -0.214225     0.324547    -0.0240327  -0.200043     0.0950692   -0.578049    -0.204384   -0.534162   -0.259117    -0.119857   -0.242849     -0.184527    -0.0922923    0.274953     -0.0628922  -0.264476      0.13521    -0.445763   -0.0532673   0.0998072   0.249115    -0.202286     -0.316904    0.197458
  0.26047     0.119668   -0.0966342    0.401427     0.029574   -0.0247582    0.439997     0.397116    -0.0536887   0.347887    0.207867    -0.0432353  -0.192605      0.211526     0.0267104    0.379155      0.267001    0.126679      0.0939184  -0.164745    0.147929    0.494403    0.0739548   -0.171268     -0.470642    0.315504[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406151
[ Info: iteration 2, average log likelihood -1.406137
[ Info: iteration 3, average log likelihood -1.406123
[ Info: iteration 4, average log likelihood -1.406110
[ Info: iteration 5, average log likelihood -1.406097
[ Info: iteration 6, average log likelihood -1.406084
[ Info: iteration 7, average log likelihood -1.406073
[ Info: iteration 8, average log likelihood -1.406061
[ Info: iteration 9, average log likelihood -1.406050
[ Info: iteration 10, average log likelihood -1.406040
┌ Info: EM with 100000 data points 10 iterations avll -1.406040
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.583028e+05
      1       6.971831e+05      -2.611197e+05 |       32
      2       6.872796e+05      -9.903520e+03 |       32
      3       6.829597e+05      -4.319927e+03 |       32
      4       6.804447e+05      -2.514939e+03 |       32
      5       6.787435e+05      -1.701202e+03 |       32
      6       6.774908e+05      -1.252684e+03 |       32
      7       6.765917e+05      -8.991315e+02 |       32
      8       6.758633e+05      -7.283819e+02 |       32
      9       6.752317e+05      -6.315955e+02 |       32
     10       6.747043e+05      -5.274256e+02 |       32
     11       6.742556e+05      -4.487272e+02 |       32
     12       6.737944e+05      -4.611640e+02 |       32
     13       6.733894e+05      -4.050059e+02 |       32
     14       6.730711e+05      -3.182782e+02 |       32
     15       6.728005e+05      -2.706441e+02 |       32
     16       6.725601e+05      -2.404034e+02 |       32
     17       6.723500e+05      -2.100543e+02 |       32
     18       6.721641e+05      -1.859277e+02 |       32
     19       6.719942e+05      -1.698493e+02 |       32
     20       6.718389e+05      -1.553364e+02 |       32
     21       6.716825e+05      -1.564460e+02 |       32
     22       6.715425e+05      -1.399746e+02 |       32
     23       6.714176e+05      -1.248334e+02 |       32
     24       6.713006e+05      -1.170176e+02 |       32
     25       6.711967e+05      -1.039259e+02 |       32
     26       6.711002e+05      -9.655190e+01 |       32
     27       6.710080e+05      -9.212763e+01 |       32
     28       6.709354e+05      -7.267241e+01 |       32
     29       6.708718e+05      -6.357971e+01 |       32
     30       6.708146e+05      -5.713928e+01 |       32
     31       6.707638e+05      -5.086629e+01 |       32
     32       6.707224e+05      -4.141178e+01 |       32
     33       6.706788e+05      -4.355434e+01 |       32
     34       6.706365e+05      -4.229851e+01 |       32
     35       6.705926e+05      -4.390060e+01 |       32
     36       6.705519e+05      -4.069407e+01 |       32
     37       6.705140e+05      -3.787110e+01 |       32
     38       6.704807e+05      -3.332685e+01 |       32
     39       6.704490e+05      -3.175644e+01 |       32
     40       6.704202e+05      -2.874895e+01 |       32
     41       6.703940e+05      -2.620916e+01 |       32
     42       6.703707e+05      -2.333676e+01 |       32
     43       6.703489e+05      -2.176996e+01 |       32
     44       6.703287e+05      -2.022753e+01 |       32
     45       6.703098e+05      -1.888015e+01 |       32
     46       6.702943e+05      -1.546104e+01 |       32
     47       6.702815e+05      -1.283199e+01 |       32
     48       6.702682e+05      -1.329894e+01 |       32
     49       6.702547e+05      -1.344995e+01 |       32
     50       6.702406e+05      -1.416541e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 670240.5712343601)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418528
[ Info: iteration 2, average log likelihood -1.413391
[ Info: iteration 3, average log likelihood -1.411916
[ Info: iteration 4, average log likelihood -1.410753
[ Info: iteration 5, average log likelihood -1.409562
[ Info: iteration 6, average log likelihood -1.408556
[ Info: iteration 7, average log likelihood -1.407916
[ Info: iteration 8, average log likelihood -1.407559
[ Info: iteration 9, average log likelihood -1.407347
[ Info: iteration 10, average log likelihood -1.407205
[ Info: iteration 11, average log likelihood -1.407099
[ Info: iteration 12, average log likelihood -1.407015
[ Info: iteration 13, average log likelihood -1.406945
[ Info: iteration 14, average log likelihood -1.406886
[ Info: iteration 15, average log likelihood -1.406834
[ Info: iteration 16, average log likelihood -1.406787
[ Info: iteration 17, average log likelihood -1.406745
[ Info: iteration 18, average log likelihood -1.406707
[ Info: iteration 19, average log likelihood -1.406671
[ Info: iteration 20, average log likelihood -1.406637
[ Info: iteration 21, average log likelihood -1.406605
[ Info: iteration 22, average log likelihood -1.406574
[ Info: iteration 23, average log likelihood -1.406545
[ Info: iteration 24, average log likelihood -1.406517
[ Info: iteration 25, average log likelihood -1.406489
[ Info: iteration 26, average log likelihood -1.406462
[ Info: iteration 27, average log likelihood -1.406436
[ Info: iteration 28, average log likelihood -1.406411
[ Info: iteration 29, average log likelihood -1.406386
[ Info: iteration 30, average log likelihood -1.406362
[ Info: iteration 31, average log likelihood -1.406339
[ Info: iteration 32, average log likelihood -1.406317
[ Info: iteration 33, average log likelihood -1.406296
[ Info: iteration 34, average log likelihood -1.406276
[ Info: iteration 35, average log likelihood -1.406257
[ Info: iteration 36, average log likelihood -1.406238
[ Info: iteration 37, average log likelihood -1.406221
[ Info: iteration 38, average log likelihood -1.406204
[ Info: iteration 39, average log likelihood -1.406188
[ Info: iteration 40, average log likelihood -1.406172
[ Info: iteration 41, average log likelihood -1.406157
[ Info: iteration 42, average log likelihood -1.406142
[ Info: iteration 43, average log likelihood -1.406128
[ Info: iteration 44, average log likelihood -1.406114
[ Info: iteration 45, average log likelihood -1.406100
[ Info: iteration 46, average log likelihood -1.406086
[ Info: iteration 47, average log likelihood -1.406073
[ Info: iteration 48, average log likelihood -1.406059
[ Info: iteration 49, average log likelihood -1.406046
[ Info: iteration 50, average log likelihood -1.406034
┌ Info: EM with 100000 data points 50 iterations avll -1.406034
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.445326    0.167518    -0.374192     0.444544   -0.0238219   0.102446    0.413252    0.00336157   0.647385    0.354592    -0.899623    0.507193    -0.252528      0.43184      0.700356    0.293207    0.545024     0.204594    0.383451    0.367203     0.0947913   -0.173016    -0.0892126   -0.185089   -0.430776     0.528239
  0.839933   -0.112243     0.159379    -0.250887   -0.039123    0.191187    0.125559    0.319381     0.108499   -0.535361     0.267366   -0.00609027   0.227638     -0.741756     0.280136   -0.290744   -0.0519688   -0.191152    0.0554432   0.0413325    0.605167     0.688791    -0.0271646    0.262572    0.0508019    0.162764
  0.148808    0.0309284   -0.077108     0.0510545  -0.0528909   0.0189642   0.0344769   0.113128     0.0327521  -0.0362874   -0.144663    0.0374226    0.0613459     0.0536851    0.169629    0.264161    0.0823447   -0.055927   -0.167917    0.0193134   -0.0545174    0.146319    -0.031887     0.119534   -0.241801    -0.121815
 -0.284139    0.0187269    0.248478    -0.397216    0.157619    0.22984    -0.0505208   0.399131    -0.316833    0.318011     0.0396113   0.21166      0.1573        0.418782     0.285037   -0.0915971   0.0713259    0.303977   -0.184505    0.382153     0.0935806   -0.0777234   -0.213469     0.0612805  -0.395496     0.0194513
 -0.401468    0.202705    -0.303557    -0.224702    1.09184     0.199294    0.308841   -0.220659     0.0979295  -0.453629    -0.334407    0.269854    -0.0381313     0.65173      0.302183   -0.577602   -0.35674      0.0349022   0.0830977   0.282754    -0.227947    -0.148335     0.257251     0.20772    -0.0490123   -0.879244
  0.280509    0.0265437   -0.14685      0.237913   -0.0518843  -0.253904    0.0205719  -0.637246    -0.14567    -0.559737    -0.296486   -0.0196978   -0.51192      -0.303804    -0.303348    0.115202   -0.0894501   -0.33151     0.215139   -0.333779     0.0291766   -0.0776753    0.497116    -0.184442   -0.121977     0.225328
  0.113141   -0.856339    -0.459465     0.581705   -0.0604658  -0.431594   -0.165535    0.144915    -0.487293   -0.451386     0.276093    0.466939    -0.04938       0.381092    -0.16575    -0.23607     0.221225    -0.468661   -0.152745    0.292418     0.0407104   -0.196475    -0.385416     0.152891   -0.0615131    0.224511
  0.035855   -0.185101     0.0885545   -0.332928    0.18976    -0.117196   -0.374873   -0.329026    -0.344473    0.397355    -0.273084    0.114023    -0.0558278    -0.187208     0.263627    0.239869    0.00219724   0.318157    0.786389   -0.430549     0.475325     0.180673     0.0290771   -0.904319    0.689319    -0.0948444
 -0.149057   -0.063931     0.052567    -0.0393785   0.0615588   0.0478545   0.0855053  -0.0445074   -0.0205387  -0.146546     0.3138     -0.116544     0.000338954  -0.23422     -0.196779   -0.0688097  -0.126295     0.0142456  -0.239705    0.205111    -0.122969     0.0031717   -0.100801     0.0189547   0.0582377    0.0601415
 -0.175365    0.00616327   0.48348     -0.471293   -0.273205    0.0344917  -0.368208   -0.174939     0.118212   -0.26811     -0.473571   -0.0774231    0.235312     -0.367811     0.508191    0.0921348  -0.310605    -0.153433   -0.149474    0.219624    -0.191537    -0.130399    -0.00851375   0.480233    0.366582    -0.402424
  0.0732553  -0.168495    -0.016847     0.0144192   0.123774   -0.168451   -0.186859   -0.147829     0.0339575   0.186941     0.163265    0.135856    -0.170312      0.0907995    0.130294   -0.243334    0.235047    -0.0630205   0.466806   -0.150295     0.171461     0.00803774  -0.00571265  -0.299319    0.37493      0.103088
 -0.319341   -0.0597389    0.348155     0.433251    0.229008   -0.0603056  -0.221454    0.755802     0.0814473   0.603634     0.298883    0.229137    -0.491029      0.66376      0.517747    0.825854    0.365566    -0.0408299   0.252841    0.0576593   -0.344809     0.795718     0.0943987    0.249798   -0.428344     0.148436
 -0.459619   -0.0779789   -0.154667    -0.0406507  -0.271288   -0.134064   -0.0835501  -0.633557    -0.0120441   0.791493    -0.0140815   0.465954    -0.0485816     0.135616    -0.175391    0.0522597   0.0614661    0.137584    0.385598    0.227719    -0.909255    -0.370634     0.205641    -0.101509    0.154138     0.38509
  0.247988    0.738211     0.223157    -0.0465146  -0.166909    0.114597    0.5475      0.0884898    0.0515603   0.278389    -0.116471   -0.122185     0.099118     -0.166326     0.0922385   0.385507    0.0720342    0.488955    0.495294   -0.274766     0.176171     0.0583694    0.438114    -0.188593   -0.414435     0.364755
 -0.0260919  -0.0376817    0.799704     0.181658   -0.144792    0.0482383  -0.0393819   0.319097    -0.477256   -0.375954     0.0733643   0.467804     0.0190882     0.87926     -0.489962    0.0450913   0.734909    -0.503217    0.655048    0.268431     0.311834    -0.234345     0.458856    -0.180573    0.00364194  -0.181316
 -0.052912    0.26541     -0.0637356    0.277807   -0.290341    0.204696    0.519934    0.340664     0.428718   -0.528461     0.305195   -0.232027     0.0224425     0.0529628   -0.261947   -0.120418    0.0463266   -0.137546   -0.656082    0.727475    -0.338615    -0.185832    -0.180261     0.670586   -0.300992     0.0689581
 -0.633089   -0.711357     0.316649     0.195876    0.475437    0.399188   -0.299309   -0.828357    -0.0176651   0.320077    -0.183004    0.465356    -0.7854       -0.24445     -0.283724   -0.0379507   0.325252     0.180153   -0.403867   -0.0231204    0.999188     0.487372    -0.134942     0.107526   -0.731717     0.423727
 -0.0585755   0.304642    -0.0554694    0.391552   -0.35253    -0.358209    0.121212   -0.164848     0.556873    0.149581     0.218213   -0.337829    -0.0409944    -0.269939     0.625486    0.174504    0.0831106   -0.261986    0.30887    -0.0766543   -0.579187     0.547018    -0.213248     0.160469    0.473932    -0.144529
  0.0619485   0.486774     0.698092     0.685177    0.297518    0.47616     0.218586    1.02938      0.377656   -0.352334    -0.220206    0.183219     0.0982801     0.318366    -0.323472    0.751992   -0.649799     0.310833    0.0305126   0.111507    -0.0602772   -0.543363    -0.086041    -0.447401    0.0623703   -0.839537
 -0.789618    0.349116    -0.137151    -0.317789    0.421656   -0.612885    0.383104    0.0108411    0.37186     0.194458     0.230353    0.246158    -0.0944419     0.203769    -0.161306   -0.597537   -0.682532     0.306084   -0.242277   -0.106194     0.300246     0.355367     0.0901296   -0.37838    -0.228669     0.287662
  0.249099    0.403797     0.223352     0.43562     0.127114   -0.278522    0.571797    0.9105      -0.41021    -0.00150564   0.282801   -0.29964     -0.403828      0.369416    -0.495175    0.0916066   0.0594594   -0.136903   -0.0881722   0.0832515    0.549171    -0.0511669    0.0555479   -0.714855   -0.381651     0.0928231
 -0.741994    0.171507     0.0713454   -0.517379   -0.237017   -0.0716725   0.0590014   0.148109    -0.11582     0.402555     0.0221896  -0.0230364   -0.200605      0.00931968   0.1002      0.219424   -0.0366545    0.415144   -0.451574    0.437227    -0.0919852    0.159916     0.35705      0.108976   -0.085999    -0.215687
 -0.760058   -0.0911317    0.68056     -0.427359    0.617497    0.716062   -0.958768   -0.140424    -0.92915     0.684507    -0.20579    -0.672611    -0.216681     -0.241341    -0.740932    0.100004   -0.0172344   -0.0110026   0.0973845  -0.0193744    0.316552     0.0923125   -0.0654897    0.0871747  -0.834381    -0.502601
 -0.278635   -0.498319    -0.43861      0.282632    0.531598    0.49313    -0.286275   -0.564079     0.447346   -0.227097     0.653515   -0.342596    -0.770141     -0.230266     0.22205    -0.0871955  -0.0246191    0.0270016  -0.137806   -0.028408    -0.206802    -0.0383973   -0.359616     0.197052    0.286436     0.890643
 -0.217532   -0.140328     0.166895     0.265087    0.154634   -0.847989   -0.738864   -0.0676031   -0.34842     0.0541369   -0.709248    0.33083      0.217023      0.109867     0.0185983  -0.28542    -0.0898874    0.30151    -0.394549   -0.0180401   -0.646045     0.0196063   -0.370674    -0.0842335   0.320931    -0.871826
 -0.317417   -0.471595    -0.139847     0.106459    0.331111   -0.289032   -0.462396    0.150209    -0.121688   -0.48035     -0.0560527   0.295957     0.465588      0.164324     0.299567   -0.587175    0.00755399  -0.0407177  -0.386904    0.128725    -0.23476      0.120168    -0.616182     0.861425    0.219745    -0.324488
  0.455178    0.129142    -0.159486     0.17459    -0.0618414   0.100369    0.15013    -0.216787     0.0676294  -0.130766     0.0446844  -0.16187      0.0345459    -0.131382    -0.125723   -0.0264875   0.0546422   -0.0462884   0.341104   -0.254507     0.0112926   -0.172343    -0.149543    -0.268832    0.0502994    0.224424
  0.30634    -0.342184    -0.687388     0.419271    0.473918   -0.0354227   0.363934   -0.554255    -0.113935    0.063619     0.625734    0.00206411  -0.0267339     0.786655    -0.327513    0.317935    0.438215     0.16531    -0.0738805  -0.160906    -0.232956     0.587389    -0.228526    -0.227379   -0.5531      -0.0416673
  0.45336    -0.137085    -0.513224    -0.462467    0.0357903   0.378495    0.123686   -0.0399638   -0.12613    -0.209697    -0.375412   -0.463627     0.401932     -0.0610235    0.264855    0.277644   -0.218223     0.310705   -0.60552    -0.393823     0.0585818   -0.126198    -0.443039     0.116631   -0.465471    -0.0295826
 -0.0777045   0.306244    -0.104732     0.221637    0.0507902  -0.0958996  -0.103387    0.00895324   0.140569    0.126677    -0.42303    -0.407059    -0.0300809     0.347614    -0.481787    0.0344371   0.0381952    0.0025672   0.381357    0.00719727  -0.0637303   -0.517572    -0.0674908   -0.0721435   0.193621    -0.426002
  0.463978   -0.0783833   -0.00909736   0.198362   -0.646726    0.0611673   0.166807   -0.0691065   -0.142233    0.453324     0.686964   -0.271975    -0.0834007    -0.771792    -0.279104    1.19784    -0.0411191   -0.0917898  -0.14331    -0.485342    -0.00169233   0.435356    -0.106049    -0.576863    0.031488     0.837724
  0.165926   -0.0625936   -0.205206    -0.142135   -0.412031   -0.0318125  -0.179926    0.276489    -0.106802    0.268691     0.105195   -0.00898385   0.203374     -0.34973     -0.387651   -0.482023   -0.205608     0.274051    0.03935    -0.17504      0.109313    -1.04091     -0.038277     0.0812428   0.327488     0.113892[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406021
[ Info: iteration 2, average log likelihood -1.406009
[ Info: iteration 3, average log likelihood -1.405997
[ Info: iteration 4, average log likelihood -1.405986
[ Info: iteration 5, average log likelihood -1.405974
[ Info: iteration 6, average log likelihood -1.405963
[ Info: iteration 7, average log likelihood -1.405952
[ Info: iteration 8, average log likelihood -1.405941
[ Info: iteration 9, average log likelihood -1.405930
[ Info: iteration 10, average log likelihood -1.405919
┌ Info: EM with 100000 data points 10 iterations avll -1.405919
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
