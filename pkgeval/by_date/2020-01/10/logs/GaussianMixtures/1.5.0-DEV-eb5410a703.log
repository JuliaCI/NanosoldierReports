Julia Version 1.5.0-DEV.45
Commit eb5410a703 (2020-01-10 02:37 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed Missings ─────────── v0.4.3
 Installed Compat ───────────── v2.2.0
 Installed Blosc ────────────── v0.5.1
 Installed OrderedCollections ─ v1.1.0
 Installed StatsFuns ────────── v0.9.3
 Installed StaticArrays ─────── v0.12.1
 Installed Distributions ────── v0.22.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed HDF5 ─────────────── v0.12.5
 Installed Parameters ───────── v0.12.0
 Installed StatsBase ────────── v0.32.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed DataAPI ──────────── v1.1.0
 Installed Distances ────────── v0.8.2
 Installed URIParser ────────── v0.4.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed FillArrays ───────── v0.8.2
 Installed JLD ──────────────── v0.9.1
 Installed BinaryProvider ───── v0.5.8
 Installed NearestNeighbors ─── v0.4.4
 Installed DataStructures ───── v0.17.7
 Installed QuadGK ───────────── v2.3.1
 Installed Clustering ───────── v0.13.3
 Installed PDMats ───────────── v0.9.10
 Installed SortingAlgorithms ── v0.3.1
 Installed BinDeps ──────────── v1.0.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Arpack ───────────── v0.4.0
 Installed Rmath ────────────── v0.6.0
 Installed CMake ────────────── v1.1.2
 Installed SpecialFunctions ─── v0.9.0
 Installed LegacyStrings ────── v0.4.1
 Installed FileIO ───────────── v1.2.1
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.0
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_nYl2gw/Project.toml`
 [no changes]
  Updating `/tmp/jl_nYl2gw/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_ii99lI/Project.toml`
 [no changes]
  Updating `/tmp/jl_ii99lI/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_BmFDqX/Project.toml`
 [no changes]
  Updating `/tmp/jl_BmFDqX/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_a28Aaz/Project.toml`
 [no changes]
  Updating `/tmp/jl_a28Aaz/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_tnMCdx/Project.toml`
 [no changes]
  Updating `/tmp/jl_tnMCdx/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_tnMCdx/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.0
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -5.253084895691654e6, [55774.504754471294, 44225.495245528706], [-36793.213526547486 -5325.426331178275 -13939.38172694396; 36505.45219867698 4698.094030022862 13815.522051624224], [[51413.77134317747 -312.16120894784086 -2238.5282895015885; -312.1612089478408 53767.26067267093 824.3040868905827; -2238.5282895015885 824.3040868905827 56387.939609581015], [48890.71570647709 678.202123106358 2433.4204232194265; 678.202123106358 46186.661911410854 -1284.4029850461325; 2433.4204232194265 -1284.4029850461327 43462.421020096815]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.726069e+03
      1       1.010262e+03      -7.158065e+02 |        8
      2       9.261889e+02      -8.407349e+01 |        4
      3       8.996476e+02      -2.654128e+01 |        3
      4       8.822277e+02      -1.741983e+01 |        2
      5       8.438435e+02      -3.838427e+01 |        2
      6       8.172084e+02      -2.663511e+01 |        2
      7       8.008054e+02      -1.640299e+01 |        0
      8       8.008054e+02       0.000000e+00 |        0
K-means converged with 8 iterations (objv = 800.805372103328)
┌ Info: K-means with 272 data points using 8 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.055018
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.794397
[ Info: iteration 2, lowerbound -3.655912
[ Info: iteration 3, lowerbound -3.499275
[ Info: iteration 4, lowerbound -3.320231
[ Info: iteration 5, lowerbound -3.144450
[ Info: iteration 6, lowerbound -2.996120
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.881360
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.783376
[ Info: iteration 9, lowerbound -2.709539
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.645592
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.574483
[ Info: iteration 12, lowerbound -2.501981
[ Info: iteration 13, lowerbound -2.439042
[ Info: iteration 14, lowerbound -2.388826
[ Info: iteration 15, lowerbound -2.351231
[ Info: iteration 16, lowerbound -2.324376
[ Info: iteration 17, lowerbound -2.309555
[ Info: iteration 18, lowerbound -2.308553
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302915
[ Info: iteration 20, lowerbound -2.299259
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan 10 13:01:09 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan 10 13:01:17 2020: K-means with 272 data points using 8 iterations
11.3 data points per parameter
, Fri Jan 10 13:01:20 2020: EM with 272 data points 0 iterations avll -2.055018
5.8 data points per parameter
, Fri Jan 10 13:01:22 2020: GMM converted to Variational GMM
, Fri Jan 10 13:01:30 2020: iteration 1, lowerbound -3.794397
, Fri Jan 10 13:01:30 2020: iteration 2, lowerbound -3.655912
, Fri Jan 10 13:01:30 2020: iteration 3, lowerbound -3.499275
, Fri Jan 10 13:01:30 2020: iteration 4, lowerbound -3.320231
, Fri Jan 10 13:01:30 2020: iteration 5, lowerbound -3.144450
, Fri Jan 10 13:01:30 2020: iteration 6, lowerbound -2.996120
, Fri Jan 10 13:01:31 2020: dropping number of Gaussions to 7
, Fri Jan 10 13:01:31 2020: iteration 7, lowerbound -2.881360
, Fri Jan 10 13:01:31 2020: dropping number of Gaussions to 5
, Fri Jan 10 13:01:31 2020: iteration 8, lowerbound -2.783376
, Fri Jan 10 13:01:31 2020: iteration 9, lowerbound -2.709539
, Fri Jan 10 13:01:31 2020: dropping number of Gaussions to 4
, Fri Jan 10 13:01:31 2020: iteration 10, lowerbound -2.645592
, Fri Jan 10 13:01:31 2020: dropping number of Gaussions to 3
, Fri Jan 10 13:01:31 2020: iteration 11, lowerbound -2.574483
, Fri Jan 10 13:01:31 2020: iteration 12, lowerbound -2.501981
, Fri Jan 10 13:01:31 2020: iteration 13, lowerbound -2.439042
, Fri Jan 10 13:01:31 2020: iteration 14, lowerbound -2.388826
, Fri Jan 10 13:01:31 2020: iteration 15, lowerbound -2.351231
, Fri Jan 10 13:01:31 2020: iteration 16, lowerbound -2.324376
, Fri Jan 10 13:01:31 2020: iteration 17, lowerbound -2.309555
, Fri Jan 10 13:01:31 2020: iteration 18, lowerbound -2.308553
, Fri Jan 10 13:01:31 2020: dropping number of Gaussions to 2
, Fri Jan 10 13:01:31 2020: iteration 19, lowerbound -2.302915
, Fri Jan 10 13:01:31 2020: iteration 20, lowerbound -2.299259
, Fri Jan 10 13:01:31 2020: iteration 21, lowerbound -2.299256
, Fri Jan 10 13:01:31 2020: iteration 22, lowerbound -2.299254
, Fri Jan 10 13:01:31 2020: iteration 23, lowerbound -2.299254
, Fri Jan 10 13:01:31 2020: iteration 24, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 25, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 26, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 27, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 28, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 29, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 30, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 31, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 32, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 33, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 34, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 35, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 36, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 37, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 38, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 39, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 40, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 41, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 42, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 43, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 44, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 45, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 46, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 47, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 48, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 49, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: iteration 50, lowerbound -2.299253
, Fri Jan 10 13:01:31 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601396, 95.95490777398605]
β = [178.04509222601396, 95.95490777398605]
m = [4.250300733269909 79.28686694436183; 2.0002292577753695 53.851987172461286]
ν = [180.04509222601396, 97.95490777398605]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484816 -0.007644049042327562; 0.0 0.00858170516633351], [0.3758763611948405 -0.008953123827345956; 0.0 0.012748664777409387]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.9797652879065505
avll from llpg:  -0.9797652879065508
avll direct:     -0.9797652879065508
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.01248630718332
avll from llpg:  -1.01248630718332
avll direct:     -1.01248630718332
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0526022   -0.144218   -0.0458563    0.0965907    -0.100435    -0.0885702     0.116368     0.158523     0.0948759   -0.0871264    0.153561     -0.0428388   -0.0103168   -0.0377038    0.0382326    0.0653386    0.0245735    0.0428606   -0.190759    -0.0729511   -0.043201     0.0292292    -0.0694697    -0.0727933    0.0601725   0.141194
  0.0404907    0.0673942  -0.08842      0.194072      0.0507333   -0.159443      0.229048     0.126801    -0.15293     -0.00854309   0.0144024     0.0316527    0.0887039   -0.0591222   -0.0243109   -0.0919335    0.187393    -0.0188063    0.00196966   0.119403    -0.00978258   0.15247      -0.0907492    -0.00505396  -0.0809125   0.0593418
 -0.104661     0.0613714  -0.0427211   -0.0301361     0.186082    -0.379776      0.172022     0.0566728    0.190298    -0.0916802    0.0535159     0.155607    -0.152947    -0.131271    -0.120777    -0.0230919   -0.0672865    0.285958     0.0447978   -0.0689498    0.0692976    0.0160279    -0.0536186     0.0356615    0.0390749  -0.072597
  0.0113602   -0.0154592   0.0727289   -0.0734703    -0.00178241  -0.0878853    -0.0232534    0.00205073   0.0319927   -0.109718    -0.10993       0.0216118   -0.080546     0.150207     0.073643    -0.135757     0.209931    -0.0234678    0.17863     -0.105263    -0.166945     0.0335966    -0.149317      0.0137424    0.0607004  -0.122881
  0.024411    -0.119652   -0.0527219    0.0682116    -0.0116994    0.0645894    -0.194676     0.0103609   -0.139856     0.0532778    0.0235241    -0.18961     -0.0595057    0.114075    -0.00889548  -0.304505     0.133154     0.00536834  -0.224024     0.21943     -0.0214187    0.0325975    -0.173197     -0.0127762    0.0875101  -0.0206182
  0.133474     0.13747     0.0130405   -0.095909      0.0898812    0.151848      0.00857141  -0.121833     0.128858    -0.105569     0.154134     -0.0357222    0.0696746    0.0752597   -0.199963    -0.0969142   -0.192943     0.00912034   0.0498458    0.144399    -0.00142355   0.150241     -0.0652003     0.0984909   -0.0953347   0.0332159
  0.0754553   -0.035606   -0.0364701    0.0707777    -0.205252     0.0227565     0.104036    -0.0786165    0.223257    -0.225756    -0.0961689     0.0772745   -0.0374606    0.108306    -0.0348128    0.102458    -0.0167113   -0.133994     0.347316     0.00606467  -0.298793    -0.061829     -0.0199248     0.0982267   -0.2442     -0.120422
 -0.0851524    0.0305253   0.0873389    0.0369667    -0.268847     0.236023     -0.0588969    0.0818334    0.00634247   0.014583    -0.0438905     0.0344908   -0.0342691   -0.0442453    0.168928    -0.0402995   -0.0613151   -0.0138015   -0.0727416   -0.211929     0.00224885  -0.0711807    -0.115903     -0.0716996    0.100792   -0.0381397
  0.0422079    0.0974106   0.164739    -0.137827      0.108638    -0.118526      0.0654907   -0.0373096    0.17512     -0.0368132    0.183579      0.0190001    0.142793    -0.020288     0.00143098  -0.0614622    0.227179    -0.140269     0.19919      0.0083565    0.132141    -0.111531     -0.0251963    -0.0763922    0.0884667  -0.157421
 -0.141617     0.0529737  -0.112917     0.0930421     0.15706     -0.0329785    -0.152644    -0.0105508    0.0686156   -0.00672934  -0.0508536    -0.0569024    0.0427577    0.0609159   -0.084692    -0.186052     0.094871     0.0931186   -0.0294086    0.014165    -0.0695614   -0.0472967     0.0689404    -0.140819     0.0129693   0.133434
  0.0712765   -0.130212    0.0110662    0.0209359    -0.0575879   -0.0982186    -0.00479537  -0.0286497    0.108439     0.0555174    0.126314      0.107247     0.17252     -0.146457     0.0323566   -0.00165914  -0.205453    -0.0489705   -0.147755    -0.0512987   -0.0541755    0.00832136   -0.0940535     0.0547705   -0.0631099   0.108051
 -0.0796373    0.114761    0.0562728   -0.100283     -0.0679293   -0.0587467    -0.191212     0.112582     0.0800211    0.119138    -0.113091      0.13182      0.127616     0.0136644   -0.130151    -0.0770097   -0.0600312   -0.189225    -0.167215     0.111155    -0.00525251  -0.220154     -0.0241625     0.168952    -0.0336314   0.0609697
 -0.152932     0.127625    0.261283    -0.0486784     0.072004     0.0495233    -0.0262765    0.0915151   -0.0428624   -0.16114     -0.00793405   -0.0689904   -0.0309939    0.140463     0.0936063   -0.0930895   -0.0587013   -0.0768203    0.0960895   -0.0832954   -0.018099    -0.0433146     0.0639021    -0.0721213    0.142056   -0.0683675
 -0.0256913   -0.0582185   0.103239    -0.253439      0.00279532   0.141036      0.0484459   -0.0230128   -0.0195263    0.0204289   -0.115628     -0.0502942   -0.0174226   -0.133788     0.172877    -0.273054     0.0279807    0.0468149    0.161488     0.145383     0.0113899   -0.127294     -0.149178     -0.077919    -0.0273605   0.0353807
  0.0545788    0.0526715   0.104082    -0.000903077   0.0750515   -0.059148      0.0565711    0.0433203   -0.00775336   0.0300324   -0.0400773     0.0265172   -0.0335224   -0.0460499    0.0482969    0.0950927    0.0568335    0.0556346   -0.124848     0.229099    -0.0704474   -0.00466963    0.0230565    -0.0169228   -0.122438   -0.0667338
  0.162807    -0.0734506  -0.100917     0.0243643     0.010665     0.0957413     0.0192001    0.114409    -0.00301933  -0.0513624   -0.0888263     0.141998    -0.0354196    0.0460185   -0.131579    -0.0911968    0.0198307   -0.0554247   -0.106233    -0.157302     0.0115653    0.0208339    -0.0874741     0.0488198   -0.0537998   0.0594855
  0.0642299    0.0433213   0.155003    -0.0474267     0.162735    -0.0585323     0.0836025    0.0444098   -0.00467415   0.0485778    0.0863716    -0.0690576   -0.115121     0.0869217   -0.0851267    0.0892476    0.0228495    0.0694142   -0.0140085    0.0640701    0.0681976   -0.0351495    -0.161069     -0.0841462    0.0208559   0.0556498
 -0.0989018    0.0175531  -0.00171113   0.270097      0.0273766    0.0873982    -0.0677216   -0.110778     0.197954    -0.118012    -0.0490142    -0.092028     0.019601    -0.236931    -0.0740166   -0.00800268  -0.110571    -0.0654494   -0.063227    -0.111914     0.0743527    0.114151      0.0375195    -0.0591185   -0.0909378   0.005811
  0.00633862   0.168291    0.0215091    0.0566702    -0.0470618   -0.142219     -0.239142     0.185343     0.156185     0.0769205   -0.110144      0.0861796   -0.1276      -0.0548926    0.111754     0.00908952   0.0591278    0.0928746   -0.0752734    0.0995427    0.0690252   -0.0384736     0.118519      0.0354371   -0.0298653  -0.14011
  0.190085    -0.0173234   0.118492     0.0382562     0.0826426    0.0282839    -0.111828     0.122504     0.0488176    0.148747     0.134099     -0.00439898  -0.0229646    0.111324     0.119149    -0.18768     -0.154997     0.188144    -0.0710304    0.0982977   -0.0238868   -0.0065362     0.074491      0.210193     0.147217   -0.110603
 -0.064052     0.11679     0.0416534   -0.0185962    -0.141434    -0.0649797     0.0807847   -0.11099     -0.0204897    0.0640309   -0.103251      0.0166036   -0.16165     -0.076486     0.00207957   0.0910028    0.172001     0.0638092   -0.0420431   -0.040945    -0.0226942   -0.0824028     0.0988815    -0.0861195    0.214743    0.18946
 -0.107552     0.0463003   0.0207345    0.0607723    -0.0066057   -0.111525      0.113781     0.225978     0.0179448    0.0139556   -0.0434356     0.0122708   -0.145424    -0.0282282    0.0867661    0.0171235   -0.0670061   -0.0496656   -0.111909     0.107225    -0.170168     0.0632181    -0.0652105     0.128447    -0.0934033   0.0613633
 -0.0142234   -0.106547    0.0970331    0.0129852     0.143316     0.0208363    -0.258077    -0.0905963    0.0559634   -0.00989233  -0.00591521    0.186052     0.0864917   -0.0205813    0.0873187    0.05862      0.0341932   -0.0565828   -0.0557894    0.142118    -0.114583     0.0157284    -0.0457194     0.0652092    0.0816078  -0.029964
  0.0458363    0.138828   -0.158737     0.182284      0.0467938   -0.232653     -0.150856     0.111846    -0.133101     0.00787174   0.00892699    0.0717851    0.0793309   -0.150487    -0.283025    -0.0241585    0.0741319    0.0140133   -0.148827    -0.121615    -0.246547     0.0291393     0.187522      0.0553229    0.0503198  -0.0343343
 -0.054987    -0.164534    0.0773471    0.0453315    -0.079421     0.0437687     0.128178     0.0708659    0.0262878   -0.0411965   -0.189084      0.0397615   -0.137266     0.00170712  -0.10686     -0.00492863   0.142417    -0.0251797    0.0176033    0.0609987    0.0607191    0.0158463    -0.102088      0.11121     -0.0828465   0.0632421
 -0.0158559   -0.107222   -0.0546161    0.128618     -0.0750417    0.239394     -0.0355072    0.209103     0.0227133   -0.0286575   -0.0420738     0.0519206    9.02984e-5   0.0710835   -0.209484     0.0567615    0.0901011   -0.1197      -0.11947     -0.0416372    0.023586    -0.0630849     0.000458219   0.0982308    0.244896    0.0164219
 -0.116126     0.0789896   0.1005      -0.217677     -0.0961365    0.184877     -0.0645773    0.0909256    0.052644     0.00937393  -0.111367      0.106962     0.140538     0.00112687  -7.84728e-5   0.0228283    0.045665    -0.295167    -0.0841218   -0.139351    -0.0904489   -0.122162      0.0721218     0.0598948    0.0241265  -0.0613174
 -0.126759     0.0816924   0.0230952   -0.10705      -0.0586935   -0.00862877    0.0950854   -0.0213017    0.00603004   0.0989174   -0.0586094     0.16243     -0.0663614    0.0442132   -0.0100002    0.0631684   -0.0925406   -0.166403    -0.132314     0.118701    -0.0841315   -0.000372989  -0.00208714   -0.27002      0.0291194  -0.173006
  0.0501439   -0.160642    0.0179797    0.0114457     0.0884943   -0.0782397    -0.130938     0.151229     0.114997    -0.0796153    0.0281789    -0.03476      0.0882462   -0.0148107   -0.0620802    0.0945515    0.00261518   0.00170647  -0.0257912   -0.034362     0.0470491    0.00350313    0.0876278    -0.320313     0.0452583   0.041794
  0.0711821    0.065946    0.0273318   -0.12275      -0.138728     0.079439     -0.12828      0.0892183    0.0902304   -0.0929272   -0.120895      0.0765173    0.00348377  -7.21155e-5  -0.0465188   -0.00891766  -0.0784169    0.0470121    0.179771    -0.0658243    0.037019    -0.0935357     0.142165      0.0231867    0.0736152  -0.166741
  0.0765585   -0.0235151  -0.014124     0.0894233     0.0424512    0.0594035     0.129827     0.0698667    0.0127375   -0.0240513    0.000364385   0.00304951   0.104713     0.131956     0.169673     0.320579     0.147511    -0.0599187   -0.161083    -0.107581    -0.038335    -0.0566716    -0.0135773    -0.0693852    0.0831822  -0.0182263
  0.120651    -0.0969104  -0.0464711    0.0902854     0.185887    -0.000974316   0.102239    -0.182582     0.050182    -0.11519     -0.023312     -0.0530599    0.153074    -0.0808875    0.131405    -0.0442139   -0.0554787    0.0436593    0.0319023   -0.0920552   -0.0341245    0.0773229    -0.064164     -0.0658756    0.0415583  -0.108554kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3807310867993363
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.380817
[ Info: iteration 2, average log likelihood -1.380703
[ Info: iteration 3, average log likelihood -1.379463
[ Info: iteration 4, average log likelihood -1.368265
[ Info: iteration 5, average log likelihood -1.350074
[ Info: iteration 6, average log likelihood -1.346249
[ Info: iteration 7, average log likelihood -1.345435
[ Info: iteration 8, average log likelihood -1.344976
[ Info: iteration 9, average log likelihood -1.344668
[ Info: iteration 10, average log likelihood -1.344449
[ Info: iteration 11, average log likelihood -1.344284
[ Info: iteration 12, average log likelihood -1.344155
[ Info: iteration 13, average log likelihood -1.344043
[ Info: iteration 14, average log likelihood -1.343935
[ Info: iteration 15, average log likelihood -1.343811
[ Info: iteration 16, average log likelihood -1.343646
[ Info: iteration 17, average log likelihood -1.343411
[ Info: iteration 18, average log likelihood -1.343177
[ Info: iteration 19, average log likelihood -1.343016
[ Info: iteration 20, average log likelihood -1.342897
[ Info: iteration 21, average log likelihood -1.342802
[ Info: iteration 22, average log likelihood -1.342722
[ Info: iteration 23, average log likelihood -1.342656
[ Info: iteration 24, average log likelihood -1.342603
[ Info: iteration 25, average log likelihood -1.342559
[ Info: iteration 26, average log likelihood -1.342522
[ Info: iteration 27, average log likelihood -1.342492
[ Info: iteration 28, average log likelihood -1.342465
[ Info: iteration 29, average log likelihood -1.342441
[ Info: iteration 30, average log likelihood -1.342419
[ Info: iteration 31, average log likelihood -1.342399
[ Info: iteration 32, average log likelihood -1.342381
[ Info: iteration 33, average log likelihood -1.342364
[ Info: iteration 34, average log likelihood -1.342349
[ Info: iteration 35, average log likelihood -1.342335
[ Info: iteration 36, average log likelihood -1.342322
[ Info: iteration 37, average log likelihood -1.342310
[ Info: iteration 38, average log likelihood -1.342298
[ Info: iteration 39, average log likelihood -1.342288
[ Info: iteration 40, average log likelihood -1.342278
[ Info: iteration 41, average log likelihood -1.342270
[ Info: iteration 42, average log likelihood -1.342262
[ Info: iteration 43, average log likelihood -1.342255
[ Info: iteration 44, average log likelihood -1.342248
[ Info: iteration 45, average log likelihood -1.342242
[ Info: iteration 46, average log likelihood -1.342236
[ Info: iteration 47, average log likelihood -1.342230
[ Info: iteration 48, average log likelihood -1.342224
[ Info: iteration 49, average log likelihood -1.342219
[ Info: iteration 50, average log likelihood -1.342212
┌ Info: EM with 100000 data points 50 iterations avll -1.342212
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3808168463781858
│     -1.380703022435299
│      ⋮
└     -1.3422124688088621
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.342297
[ Info: iteration 2, average log likelihood -1.342204
[ Info: iteration 3, average log likelihood -1.341795
[ Info: iteration 4, average log likelihood -1.337711
[ Info: iteration 5, average log likelihood -1.323109
[ Info: iteration 6, average log likelihood -1.310996
[ Info: iteration 7, average log likelihood -1.306320
[ Info: iteration 8, average log likelihood -1.304038
[ Info: iteration 9, average log likelihood -1.302784
[ Info: iteration 10, average log likelihood -1.301898
[ Info: iteration 11, average log likelihood -1.301220
[ Info: iteration 12, average log likelihood -1.300713
[ Info: iteration 13, average log likelihood -1.300347
[ Info: iteration 14, average log likelihood -1.300086
[ Info: iteration 15, average log likelihood -1.299896
[ Info: iteration 16, average log likelihood -1.299755
[ Info: iteration 17, average log likelihood -1.299647
[ Info: iteration 18, average log likelihood -1.299562
[ Info: iteration 19, average log likelihood -1.299493
[ Info: iteration 20, average log likelihood -1.299437
[ Info: iteration 21, average log likelihood -1.299391
[ Info: iteration 22, average log likelihood -1.299352
[ Info: iteration 23, average log likelihood -1.299319
[ Info: iteration 24, average log likelihood -1.299290
[ Info: iteration 25, average log likelihood -1.299265
[ Info: iteration 26, average log likelihood -1.299241
[ Info: iteration 27, average log likelihood -1.299218
[ Info: iteration 28, average log likelihood -1.299195
[ Info: iteration 29, average log likelihood -1.299172
[ Info: iteration 30, average log likelihood -1.299147
[ Info: iteration 31, average log likelihood -1.299122
[ Info: iteration 32, average log likelihood -1.299097
[ Info: iteration 33, average log likelihood -1.299073
[ Info: iteration 34, average log likelihood -1.299051
[ Info: iteration 35, average log likelihood -1.299032
[ Info: iteration 36, average log likelihood -1.299016
[ Info: iteration 37, average log likelihood -1.299006
[ Info: iteration 38, average log likelihood -1.298998
[ Info: iteration 39, average log likelihood -1.298994
[ Info: iteration 40, average log likelihood -1.298990
[ Info: iteration 41, average log likelihood -1.298988
[ Info: iteration 42, average log likelihood -1.298986
[ Info: iteration 43, average log likelihood -1.298985
[ Info: iteration 44, average log likelihood -1.298984
[ Info: iteration 45, average log likelihood -1.298983
[ Info: iteration 46, average log likelihood -1.298983
[ Info: iteration 47, average log likelihood -1.298982
[ Info: iteration 48, average log likelihood -1.298982
[ Info: iteration 49, average log likelihood -1.298982
[ Info: iteration 50, average log likelihood -1.298982
┌ Info: EM with 100000 data points 50 iterations avll -1.298982
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.342296911783189
│     -1.3422035409775306
│      ⋮
└     -1.2989815943342953
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.299106
[ Info: iteration 2, average log likelihood -1.298959
[ Info: iteration 3, average log likelihood -1.298128
[ Info: iteration 4, average log likelihood -1.291003
[ Info: iteration 5, average log likelihood -1.271410
[ Info: iteration 6, average log likelihood -1.255761
[ Info: iteration 7, average log likelihood -1.248105
[ Info: iteration 8, average log likelihood -1.244351
[ Info: iteration 9, average log likelihood -1.241462
[ Info: iteration 10, average log likelihood -1.238313
[ Info: iteration 11, average log likelihood -1.236061
[ Info: iteration 12, average log likelihood -1.234926
[ Info: iteration 13, average log likelihood -1.234004
[ Info: iteration 14, average log likelihood -1.233284
[ Info: iteration 15, average log likelihood -1.232878
[ Info: iteration 16, average log likelihood -1.232652
[ Info: iteration 17, average log likelihood -1.232490
[ Info: iteration 18, average log likelihood -1.232337
[ Info: iteration 19, average log likelihood -1.232167
[ Info: iteration 20, average log likelihood -1.231967
[ Info: iteration 21, average log likelihood -1.231729
[ Info: iteration 22, average log likelihood -1.231452
[ Info: iteration 23, average log likelihood -1.231124
[ Info: iteration 24, average log likelihood -1.230749
[ Info: iteration 25, average log likelihood -1.230366
[ Info: iteration 26, average log likelihood -1.230021
[ Info: iteration 27, average log likelihood -1.229759
[ Info: iteration 28, average log likelihood -1.229585
[ Info: iteration 29, average log likelihood -1.229457
[ Info: iteration 30, average log likelihood -1.229341
[ Info: iteration 31, average log likelihood -1.229224
[ Info: iteration 32, average log likelihood -1.229108
[ Info: iteration 33, average log likelihood -1.228997
[ Info: iteration 34, average log likelihood -1.228914
[ Info: iteration 35, average log likelihood -1.228862
[ Info: iteration 36, average log likelihood -1.228832
[ Info: iteration 37, average log likelihood -1.228815
[ Info: iteration 38, average log likelihood -1.228804
[ Info: iteration 39, average log likelihood -1.228795
[ Info: iteration 40, average log likelihood -1.228788
[ Info: iteration 41, average log likelihood -1.228782
[ Info: iteration 42, average log likelihood -1.228777
[ Info: iteration 43, average log likelihood -1.228771
[ Info: iteration 44, average log likelihood -1.228767
[ Info: iteration 45, average log likelihood -1.228762
[ Info: iteration 46, average log likelihood -1.228758
[ Info: iteration 47, average log likelihood -1.228754
[ Info: iteration 48, average log likelihood -1.228750
[ Info: iteration 49, average log likelihood -1.228747
[ Info: iteration 50, average log likelihood -1.228743
┌ Info: EM with 100000 data points 50 iterations avll -1.228743
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2991055841821189
│     -1.2989593756832827
│      ⋮
└     -1.2287427465310958
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.228955
[ Info: iteration 2, average log likelihood -1.228687
[ Info: iteration 3, average log likelihood -1.226945
[ Info: iteration 4, average log likelihood -1.210710
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.176951
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.159108
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.153708
[ Info: iteration 8, average log likelihood -1.149235
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.136616
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.152018
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.150562
[ Info: iteration 12, average log likelihood -1.148083
[ Info: iteration 13, average log likelihood -1.135720
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.126641
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.159154
[ Info: iteration 16, average log likelihood -1.151712
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.138319
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.143454
[ Info: iteration 19, average log likelihood -1.145426
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.134340
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.138368
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.152917
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.149086
[ Info: iteration 24, average log likelihood -1.149165
[ Info: iteration 25, average log likelihood -1.137049
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.130188
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.149115
[ Info: iteration 28, average log likelihood -1.147228
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.133779
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.152677
[ Info: iteration 31, average log likelihood -1.148650
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.136172
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.141005
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.143504
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.145427
[ Info: iteration 36, average log likelihood -1.146348
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.132328
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.139813
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.152702
[ Info: iteration 40, average log likelihood -1.149545
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.137488
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.143030
[ Info: iteration 43, average log likelihood -1.144767
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.132814
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.150241
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.146660
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.147099
[ Info: iteration 48, average log likelihood -1.148526
[ Info: iteration 49, average log likelihood -1.136825
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.129906
┌ Info: EM with 100000 data points 50 iterations avll -1.129906
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2289551618486456
│     -1.2286870882592194
│      ⋮
└     -1.129905718012753
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.148573
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.133670
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     16
│     23
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.127998
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     17
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.124162
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     23
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.097526
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.059922
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.073773
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.070865
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.044416
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.067207
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.059231
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.039269
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.066758
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.059276
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.039372
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.066730
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.059255
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.039370
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.066671
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.059156
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.039163
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.066351
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.058640
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.038361
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.065403
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.057810
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.037875
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.065121
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.057731
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.038023
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.065130
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.057738
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.038118
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.065143
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.057747
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.038174
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.065151
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.057754
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.038212
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.065156
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.057759
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.038240
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.065160
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.057763
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.038262
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.065163
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.057767
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.038281
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.065165
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     22
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.057770
┌ Info: EM with 100000 data points 50 iterations avll -1.057770
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.148573285578872
│     -1.1336700044826813
│      ⋮
└     -1.0577700315096004
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3807310867993363
│     -1.3808168463781858
│     -1.380703022435299
│     -1.379462523553149
│      ⋮
│     -1.0382813905212087
│     -1.0651650499061618
└     -1.0577700315096004
32×26 Array{Float64,2}:
 -0.109646    0.0890267    0.0907801   -0.220295   -0.0943871     0.178717    -0.0668413    0.0835305    0.0311217   -0.00183384   -0.106628     0.111021     0.13914       0.00317958   -0.00398286   0.0227606    0.0469963  -0.306124     -0.0785133   -0.132694    -0.0453903    -0.135651      0.0675511    0.0451551    0.00428115  -0.0439937
  0.0462887   0.127007    -0.153855     0.181675    0.0217591    -0.240467    -0.151819     0.111495    -0.151133     0.00268505    0.0172042    0.0694321    0.0670367    -0.147558     -0.276769    -0.054264     0.0712573   0.0133827    -0.139433    -0.123595    -0.254741     -0.000455503   0.184323     0.0702253    0.056831    -0.0404948
  0.0993813   0.0765393    0.0867649   -0.0573636   0.136947      0.0332627    0.0539334   -0.00565941   0.0687203   -0.00291673    0.113052    -0.0623994   -0.0186467     0.0777815    -0.131171     0.041552    -0.0697496   0.0474004     0.00946207   0.0821448    0.039628      0.0493482    -0.135018    -0.0175321   -0.0217111    0.0478891
 -0.0758321  -0.0222735    0.100901     0.069694   -0.262957      0.179191    -0.0530833    0.111144     0.00995303  -0.000573332  -0.0409505    0.0300657   -0.0175609    -0.0899843     0.163277    -0.0190117   -0.0315181  -0.000478295  -0.0809069   -0.201171    -0.0186201    -0.0619992    -0.108305    -0.079729     0.0819608   -0.0220537
 -0.137913    0.0447953    0.0321834    0.0281393  -0.0285095    -0.179109     0.0484844    0.291514     0.00927052   0.0175674    -0.0877376   -0.0229096   -0.19241       0.00543324    0.104434     0.0167168   -0.103131   -0.0613026    -0.177005     0.10061     -0.143914      0.088974     -0.0721871    0.157692    -0.326962     0.00360409
 -0.0590229   0.0462157    0.0149977    0.0719179   0.0254008     0.0109481    0.228712     0.10859      0.020531     0.00234178    0.0456963    0.032436    -0.102611     -0.0632367     0.0543622    0.0223532   -0.0365227  -0.0350827    -0.0584603    0.11238     -0.185719      0.0452644    -0.0589881    0.106865     0.0851167    0.113749
 -0.0888633   0.00811785  -0.0157644    0.257025    0.0575782     0.123142    -0.198003    -0.15191      0.202507    -0.0950959     0.00485414  -0.0914207    0.0186106    -0.607214     -0.0697953   -0.0124881   -0.0198448  -0.0593002     0.00032764  -0.120606     0.0996058     0.193581      0.012937    -0.0556219   -0.0864576    0.00541695
 -0.106619    0.0265712    0.00773789   0.267746   -0.0320836    -0.0546633    0.0714588   -0.0654584    0.198242    -0.168563     -0.0762388   -0.0916813    0.0320657     0.101559     -0.0790678    6.92722e-5  -0.209661   -0.073026     -0.145418    -0.0675856    0.0195059     0.0435606     0.0453338   -0.0630417   -0.0714011    0.011055
  0.0192976   0.0137945   -0.044857     0.0426027   0.0638721     0.0144922   -0.0498801   -0.0140876    0.0678638   -0.0661259    -0.0886932   -0.00327751   0.0626518     0.000751984  -0.0184063   -0.0751924   -0.0191791   0.0559039     0.0592507   -0.0645316   -0.0194381    -0.0126482     0.0613617   -0.0458458    0.0370946   -0.0640291
 -0.0200041   0.0103907    0.00527804   0.0325982  -0.0995402    -0.0753541    0.0948442    0.00719467   0.0294713    0.00687933    0.0255332   -0.0175131   -0.0865795    -0.0418202     0.00819397   0.0961979    0.0845859   0.0706787    -0.100949     0.0132442   -0.0162411    -0.0296294     0.0292566   -0.0714151    0.153604     0.154273
  0.0508747  -0.0807355   -0.00509522   0.0380798   0.0662673    -0.0162361    0.00483931   0.113414     0.0757474   -0.0511682     0.0303517   -0.00928986   0.0903703     0.0592316     0.0590909    0.198041     0.0862046  -0.0282962    -0.0742072   -0.0393174    0.0010258    -0.0213124     0.0307968   -0.167806     0.0602944   -0.0206842
  0.0973372  -0.0556412    0.117564     0.0231402   0.135078      0.0215991   -0.183059     0.0292131    0.0444264    0.0731758     0.0748276    0.113714     0.037511      0.0560218     0.0759083   -0.0791728   -0.0630907   0.0697002    -0.039655     0.117293    -0.098944      0.00771226    0.00290105   0.121242     0.122671    -0.0766126
 -0.0639231   0.0870252   -0.130168     0.0455951   0.278447     -0.447426     0.174232     0.0253452    0.14783     -0.103823      0.0571878    0.188209    -0.23208      -0.0909412    -0.257415    -0.0184168   -0.034944    0.278845      0.0916379    0.00985119   0.10983       0.0219294    -0.433459    -0.0680279    0.0400302   -0.0958697
 -0.143984    0.0390094    0.0236155   -0.10106     0.0812145    -0.338497     0.174487     0.0933969    0.29618     -0.139912      0.043111     0.144316    -0.105899     -0.130895      0.0156739   -0.0262105   -0.10644     0.309667     -0.0225444   -0.0505825   -0.00222267    0.0139474     0.372172     0.054295     0.0339513   -0.0356244
  0.0686331  -0.0162357   -0.0512989    0.0725554  -0.20091       0.0210626    0.102311    -0.0797073    0.194105    -0.2286       -0.0828099    0.0715128   -0.0255433     0.0890778    -0.067339     0.0811936   -0.0126357  -0.131616      0.341352     0.0033664   -0.274541     -0.0578214    -0.0197387    0.0830197   -0.2141      -0.0944352
  0.0594084  -0.0152157   -0.0316381    0.0778805  -0.0216306    -0.103425     0.0821199    0.0213881   -0.0142691    0.0261737     0.0808832    0.101496     0.136696     -0.117099      0.0116682   -0.0646014   -0.0507701  -0.0367972    -0.0746435    0.022251    -0.0371302     0.0618932    -0.0866868    0.0343798   -0.0903165    0.0970226
 -0.047135    0.135582     0.0895534    0.0628753  -0.508035      0.101005     0.129077     0.0965694   -0.0179315   -0.0303065    -0.184306    -0.166972    -0.0449692    -0.620384     -0.106176    -0.00742938   0.141846   -0.0328624     0.0183762   -0.0471917    0.0887896     0.0747641    -0.1012       0.238038    -0.072295     0.0427642
 -0.0472414  -0.566293     0.0643996    0.0830499   0.424473      0.0417419    0.125621     0.0800583    0.127929    -0.0333777    -0.184971     0.257621    -0.312783      0.728322     -0.134875    -0.00640041   0.139487   -0.0512201     0.0167241    0.185174     0.0591823    -0.0439801    -0.101653    -0.0178954   -0.091426     0.062979
 -0.0169465   0.100209     0.108754    -0.104808    0.0373562    -0.106903    -0.0548815    0.0408352    0.121823     0.00567418    0.0443034    0.0777142    0.138732     -0.00545344   -0.047796    -0.081285     0.0616494  -0.157117      0.044293     0.0805262    0.0520219    -0.136929     -0.0269455    0.0474306    0.00386558  -0.0567238
 -0.118052    0.0798272    0.0188231   -0.106446   -0.0622092    -0.00918781   0.0872546   -0.0199704    0.00738346   0.0693422    -0.0575915    0.188547    -0.0649517     0.0546404    -0.0505801    0.0623013   -0.0846166  -0.175869     -0.115989     0.108041    -0.0832889     0.0228101    -0.0035514   -0.255147     0.017568    -0.172539
  0.0210666  -0.116994    -0.0639696    0.12067    -0.0152061     0.0657272   -0.192593     0.00652209  -0.130293     0.0557402    -0.0965348   -0.202432    -0.0690711     0.123336     -0.0340884   -0.317993     0.141979    0.00684839   -0.226341     0.221174    -0.0217635     0.0367977    -0.183156    -0.012575     0.151912    -0.0227422
 -0.0159715  -0.0522269    0.101232    -0.239546   -0.000269224   0.135276     0.0606253   -0.0306584   -0.0378321    0.00766582   -0.091372    -0.0483269    0.000342639  -0.129027      0.246125    -0.266084     0.0071898   0.0283171     0.152782     0.139104     0.014637     -0.111753     -0.14399     -0.0782496   -0.0215553    0.02945
  0.0680746   0.0725287    0.106369    -0.0367714   0.0641942    -0.0611285    0.0455257    0.0408548    0.00213915   0.0332419    -0.0611565    0.0178196   -0.0398904    -0.0395215     0.0475327    0.0832291    0.0675283   0.0602519    -0.116247     0.22798     -0.0902249    -0.0158738     0.0112211   -0.0182657   -0.121381    -0.0419193
  0.0150622  -0.0201955    0.0724415   -0.050536   -0.0115428    -0.12161     -0.0212075    0.0143674    0.0274052   -0.108864     -0.102618     0.0165309   -0.0991703     0.132858      0.0777677   -0.131418     0.201487   -0.0229242     0.187881    -0.0939912   -0.168964      0.0332573    -0.136684     0.0129688    0.0582605   -0.0829264
 -0.169331    0.280743     0.477237    -0.211163    0.0395656     0.0710503   -0.026741    -0.196198     0.0668049   -1.22642       0.285956    -0.0604146   -0.0118097     0.125305      0.119619    -0.0917318   -0.0568994  -0.212938      0.0964754   -0.0692679   -0.263296     -0.059537      0.107975     0.00226536   0.14571     -0.158987
 -0.146134   -0.140168     0.183637    -0.165227    0.049511      0.0122227   -0.00952974   0.236853     0.263673     0.0216676    -0.114076    -0.0722048   -0.0412442     0.194186      0.281726    -0.0798393   -0.0674126  -0.41069       0.100972    -0.102886     0.0552136    -0.0352429     0.0637924   -0.0327654    0.139856    -0.123364
  0.0573735   0.274873     0.0781157    0.144853    0.0832917     0.0526136    0.00786342   0.126245    -0.486732    -0.444525     -0.140888    -0.0756546   -0.0413312     0.107135     -0.121012    -0.0598145   -0.0563961   0.460925      0.095916    -0.0817457   -0.000372661  -0.0359702     0.100602    -0.221775     0.128619    -0.0958417
 -0.329257    0.101413     0.355555    -0.0508447   0.113089      0.0556891   -0.0711537   -0.0541741   -0.101406     0.991382      0.0279437   -0.0642183   -0.0357903     0.0982161    -0.00796582  -0.156912    -0.0582352  -0.147307      0.0913281   -0.0695696    0.174877     -0.040889     -0.0239019   -0.117499     0.148669     0.0211529
 -0.0344734  -0.114629    -0.0526654    0.118484   -0.0863474     0.218219    -0.0717998    0.214798     0.0352335   -0.0325706    -0.0326637    0.0572399    0.00443555    0.0719885    -0.193883     0.0615018    0.0904932  -0.112406     -0.120091    -0.0338923    0.0289677    -0.0648516     0.00996531   0.0896834    0.273177     0.012609
 -0.0324605   0.154698     0.0315445    0.04834    -0.0477588    -0.141242    -0.227141     0.196736     0.138129     0.0758651    -0.0955652    0.0879847   -0.147817     -0.0491936     0.111356     0.00700254   0.0537496   0.099241     -0.0679947    0.124395     0.0771516    -0.0562574     0.13707      0.0552012   -0.0285295   -0.139662
  0.326302   -0.0336431   -0.252672    -0.0356072   0.0181799    -0.0722514   -0.0966035    0.176217    -0.00201533  -0.0356845     0.0854244    0.134104    -0.0208637     0.0461367    -0.50067     -0.0918633   -0.128955   -0.0819909    -0.108943    -0.163496     0.0390099    -0.000811458  -0.088975     0.0745201   -0.0690595    0.0535893
  0.0123664  -0.127136     0.0334618    0.086148    0.00916918    0.212464     0.107601     0.0467121   -0.00227061  -0.0416331    -0.285507     0.15005     -0.050666      0.0471471     0.221354    -0.0902335    0.139538   -0.0456321    -0.135103    -0.15362     -0.0159248     0.0327608    -0.0878039    0.0921368   -0.0478273    0.0549369[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.038298
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     17
│     18
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.034923
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.038258
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     17
│     18
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.034878
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.038256
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     17
│     18
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.034873
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.038254
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     17
│     18
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.034869
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     20
│     21
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.038253
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     17
│     18
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.034866
┌ Info: EM with 100000 data points 10 iterations avll -1.034866
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.372010e+05
      1       6.490099e+05      -1.881911e+05 |       32
      2       6.237450e+05      -2.526493e+04 |       32
      3       6.059818e+05      -1.776317e+04 |       32
      4       5.913459e+05      -1.463595e+04 |       32
      5       5.800971e+05      -1.124871e+04 |       32
      6       5.744420e+05      -5.655169e+03 |       32
      7       5.716373e+05      -2.804690e+03 |       32
      8       5.700588e+05      -1.578460e+03 |       32
      9       5.690971e+05      -9.617589e+02 |       32
     10       5.683533e+05      -7.437621e+02 |       32
     11       5.678117e+05      -5.415809e+02 |       32
     12       5.673560e+05      -4.557637e+02 |       32
     13       5.668966e+05      -4.593134e+02 |       32
     14       5.664116e+05      -4.850295e+02 |       32
     15       5.658697e+05      -5.419045e+02 |       32
     16       5.653877e+05      -4.820501e+02 |       32
     17       5.650393e+05      -3.483975e+02 |       32
     18       5.648429e+05      -1.963226e+02 |       32
     19       5.647366e+05      -1.063091e+02 |       32
     20       5.646797e+05      -5.694120e+01 |       31
     21       5.646371e+05      -4.263012e+01 |       32
     22       5.645966e+05      -4.042297e+01 |       32
     23       5.645388e+05      -5.782096e+01 |       32
     24       5.644601e+05      -7.874224e+01 |       32
     25       5.643472e+05      -1.128631e+02 |       32
     26       5.641999e+05      -1.473409e+02 |       32
     27       5.640227e+05      -1.771425e+02 |       32
     28       5.638786e+05      -1.441070e+02 |       32
     29       5.637865e+05      -9.212571e+01 |       32
     30       5.637343e+05      -5.219770e+01 |       31
     31       5.637049e+05      -2.941663e+01 |       30
     32       5.636913e+05      -1.354691e+01 |       27
     33       5.636862e+05      -5.137726e+00 |       28
     34       5.636836e+05      -2.571737e+00 |       23
     35       5.636824e+05      -1.267730e+00 |       18
     36       5.636817e+05      -6.980769e-01 |       10
     37       5.636812e+05      -4.937029e-01 |        9
     38       5.636807e+05      -4.341381e-01 |       10
     39       5.636805e+05      -2.395443e-01 |        5
     40       5.636803e+05      -1.665598e-01 |        7
     41       5.636801e+05      -2.106138e-01 |        5
     42       5.636799e+05      -2.318913e-01 |        5
     43       5.636797e+05      -1.999408e-01 |        8
     44       5.636795e+05      -2.104128e-01 |        4
     45       5.636793e+05      -1.482512e-01 |        2
     46       5.636793e+05      -2.576482e-02 |        2
     47       5.636793e+05      -3.735313e-02 |        3
     48       5.636792e+05      -9.228831e-02 |        3
     49       5.636791e+05      -9.008143e-02 |        4
     50       5.636790e+05      -6.133420e-02 |        2
K-means terminated without convergence after 50 iterations (objv = 563679.0201680865)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.288501
[ Info: iteration 2, average log likelihood -1.254193
[ Info: iteration 3, average log likelihood -1.215493
[ Info: iteration 4, average log likelihood -1.171013
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.115408
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.094769
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     15
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.061998
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      5
│      9
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.024839
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.059621
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     14
│     15
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.019951
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      5
│      9
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.040944
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.069082
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.028363
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│      9
│     14
│     15
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -0.999236
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.067938
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.016972
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      5
│      8
│      9
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -0.998092
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.079963
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.048595
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      9
│     15
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -0.985961
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     10
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.048137
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.041686
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│      9
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.020736
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.059177
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     14
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.018824
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      5
│      9
│     15
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.984464
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.059367
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     14
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.032684
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.014989
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│     10
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.002784
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     14
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.038183
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      9
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.010699
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     10
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.016178
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      8
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.032371
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      9
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.014748
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.019596
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      8
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.007528
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      9
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.026128
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.047054
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.016360
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      5
│      8
│      ⋮
│     14
│     15
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -0.962929
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.077548
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.044111
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│     15
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.000136
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.045837
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.016661
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.008708
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.056203
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      8
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.005449
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      9
│     10
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.013897
┌ Info: EM with 100000 data points 50 iterations avll -1.013897
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0977093   0.0174467   -0.00413248   0.2628       0.0130189    0.0338799    -0.0627575  -0.108596     0.200365    -0.131629     -0.0364445   -0.0915751    0.0253526   -0.251773    -0.0744012   -0.00611181  -0.11558      -0.0662425    -0.0728458   -0.0943233    0.0595555     0.118488      0.0292211   -0.0593647   -0.0790395    0.00854745
 -0.0476858  -0.20942      0.0761406    0.0756119   -0.0616407    0.0790486     0.126053    0.0950999    0.0489084   -0.0350232    -0.187057     0.039015    -0.189684     0.0259729   -0.131104    -0.0076686    0.139402     -0.0430314     0.0182916    0.0650516    0.0734543     0.0200081    -0.101526     0.120215    -0.082217     0.0563245
  0.0919235  -0.00375014   0.00835253  -0.0305498   -0.0136579    0.0362682    -0.0116801  -0.0717948    0.0917766   -0.008751      0.133726     0.0572391    0.117275    -0.0319083   -0.0763252   -0.0767188   -0.203294     -0.014738     -0.0491562    0.0504083   -0.0286084     0.0730435    -0.0880091    0.0824245   -0.0770423    0.0674222
 -0.0107378  -0.108025    -0.0761812    0.131163    -0.00176973   0.0612437    -0.176902    0.00799616  -0.108725     0.0284356    -0.126816    -0.246874    -0.0614129    0.105115    -0.0121931   -0.322932     0.174838     -0.00181391   -0.229664     0.197442    -0.0185988     0.0342181    -0.168016    -0.0170959    0.170731    -0.033204
 -0.0289729   0.154781     0.0291844    0.050029    -0.0471243   -0.142409     -0.232679    0.197577     0.141832     0.0759729    -0.0938979    0.088835    -0.150979    -0.0501103    0.112142     0.00581058   0.0530849     0.098385     -0.0680739    0.126494     0.0792056    -0.055125      0.132821     0.0553778   -0.0291213   -0.139412
  0.0246899  -0.153248     0.0230746   -0.027033     0.0796147   -0.0700138    -0.11676     0.135025     0.134678    -0.0715011     0.0408463   -0.0167938    0.087292    -0.011372    -0.0798284    0.0614343   -0.000984211   0.0154571    -0.0102907   -0.00666983   0.0394019    -0.00579092    0.0584827   -0.312303     0.0484223    0.0664396
  0.0576458   0.0669471    0.0212124   -0.0921186   -0.115854     0.0793375    -0.132773    0.101259     0.0955297   -0.0800873    -0.170348     0.074091     0.0042758   -0.00164754  -0.0691742    0.00820133  -0.077093      0.0463818     0.181074    -0.10365      0.0349723    -0.076695      0.140107     0.0455542    0.0694262   -0.166511
  0.256818   -0.083159    -0.147422     0.0175249    0.0147188    0.0679566     0.033975    0.148753    -0.00829927  -0.0279611    -0.135122     0.229216    -0.0417031    0.047962    -0.314063    -0.069126    -0.0519608    -0.0470369    -0.117144    -0.160925    -0.000593029   0.0275103    -0.0874015    0.11059     -0.0923871    0.0561615
  0.0714387  -0.0228515   -0.0554758    0.0706468   -0.20504      0.0313565     0.105455   -0.0811106    0.208244    -0.238312     -0.0850921    0.0765435   -0.0373653    0.0915978   -0.0595926    0.092212    -0.0168161    -0.137549      0.360776    -0.00280231  -0.295421     -0.0604027    -0.0131518    0.0892113   -0.2229      -0.0994774
 -0.121471    0.0842878    0.0208766   -0.107454    -0.0694957   -0.00881067    0.0937232  -0.0212193    0.00665763   0.0704588    -0.0577016    0.195607    -0.0692882    0.0594156   -0.0513919    0.062402    -0.0862202    -0.182355     -0.118326     0.10663     -0.0863746     0.0234424    -0.00155391  -0.261425     0.0197071   -0.172286
 -0.0946817   0.0641932   -0.0457785   -0.0204729    0.201038    -0.431387      0.174267    0.0535926    0.230753    -0.1101        0.0546249    0.176037    -0.215639    -0.11199     -0.185782    -0.021795    -0.0678889     0.303564      0.0273157    0.031901     0.081888      0.0165278    -0.0975529    0.0240874    0.0380917   -0.0624368
 -0.13774     0.0509322   -0.0989762    0.0958292    0.130814    -0.034826     -0.135415   -0.011785     0.0688028   -0.00482941   -0.0784219   -0.0509091    0.0268036    0.0565437   -0.0925627   -0.181399     0.0917141     0.0869505    -0.0627349    0.00873241  -0.072541     -0.0531344     0.104673    -0.139967     0.0209919    0.155318
 -0.0352028  -0.114387    -0.0528375    0.118878    -0.0839589    0.219976     -0.0746994   0.221063     0.0307517   -0.0328012    -0.0336947    0.0582491    0.00287563   0.0720526   -0.189872     0.0622604    0.0954977    -0.113102     -0.120143    -0.034716     0.0302643    -0.0656444     0.00625328   0.0894922    0.26875      0.0144165
 -0.0898801   0.11493      0.0554812   -0.0984475   -0.0675559   -0.0518003    -0.189553    0.117493     0.0797269    0.0911386    -0.10044      0.133071     0.12452      0.0123533   -0.119074    -0.0952907   -0.0816925    -0.195079     -0.134374     0.162167    -0.00593063   -0.171391     -0.0289739    0.167418    -0.0577919    0.0538808
 -0.0114338  -0.087488     0.0934896   -0.00598745   0.167807     0.0209949    -0.263439   -0.0906238    0.0554905   -0.00730024   -0.00526088   0.22329      0.0916086   -0.0516526    0.0675709    0.0482856    0.0328442    -0.0521419    -0.0587713    0.140456    -0.137421      0.0184109    -0.0467707    0.033087     0.079721    -0.0342916
 -0.135328    0.113179     0.256411    -0.0675084    0.0699602    0.0447606    -0.0214391   0.0528953   -0.0570885   -0.16989      -0.00423459  -0.0690445   -0.033767     0.135768     0.0773525   -0.093354    -0.0604238    -0.0782794     0.0966469   -0.0828791   -0.00394877   -0.0417806     0.0648473   -0.0938867    0.139922    -0.0936392
 -0.206675    0.0645873   -0.127592    -0.0892532   -0.0363631    0.0511037     0.174443    0.115031     0.0996143   -0.247378     -0.00600646   0.0773795    0.371964    -0.0780775    0.577038    -0.0340971   -0.0974538     0.168545      0.170162    -0.671037    -0.260419      0.0356877     0.632133    -0.373554     0.0299165   -0.125394
 -0.100909    0.045606     0.0254554    0.0529296   -0.00228993  -0.0868702     0.135501    0.207786     0.0134996    0.00919404   -0.0182956    0.0050327   -0.150902    -0.027044     0.0851916    0.0186916   -0.0702023    -0.048886     -0.121491     0.106259    -0.163843      0.066489     -0.0652467    0.139494    -0.124793     0.0595689
 -0.024689   -0.0572601    0.0855976   -0.281246     0.00211769   0.139648      0.0411765  -0.0369203   -0.0257899    0.0108383    -0.116109    -0.0537013    0.025331    -0.115437     0.454288    -0.365861    -0.0360888     0.0210287     0.153135     0.126417     0.010356     -0.116935     -0.149741    -0.077758    -0.0270902    0.0794232
  0.0380891   0.0923678    0.159001    -0.124538     0.118394    -0.151315      0.0690809  -0.0367186    0.170135    -0.0444239     0.181712     0.0317181    0.146016    -0.0236653   -0.008125    -0.0728037    0.216119     -0.136729      0.211607     0.0036619    0.11816      -0.111341     -0.0274288   -0.0755165    0.068793    -0.189393
  0.0747358   0.0536747    0.118272    -0.0470489    0.0671723   -0.0291972     0.0560307   0.0391887   -0.0110984    0.0290242    -0.0601808    0.0273384   -0.040478    -0.0495292    0.0497481    0.123214     0.0522871     0.0661418    -0.0838364    0.215778    -0.0798674    -0.0191287     0.0203162   -0.0296585   -0.124267    -0.103042
  0.0463149   0.12722     -0.153689     0.181718     0.0218915   -0.240288     -0.151667    0.111524    -0.151251     0.00287517    0.0169339    0.069551     0.066725    -0.147623    -0.276648    -0.0540291    0.0710258     0.0124908    -0.139276    -0.123605    -0.254768     -0.000483115   0.184321     0.0691776    0.0562771   -0.0401448
  0.0379164   0.0797702   -0.0753266    0.182067     0.0638754   -0.143943      0.216811    0.109775    -0.155996    -0.00350734    0.00732551   0.0399607    0.0925229   -0.0717781    0.0279632   -0.103859     0.189129     -0.0281068     0.0123194    0.118737    -0.00978284    0.145649     -0.0676882    0.00121613  -0.0826681    0.0818157
  0.0787949   0.0459073    0.144022    -0.0439952    0.157487    -0.058238      0.0857275   0.0679179    0.0146422    0.0544988     0.0827745   -0.0712874   -0.0884517    0.0815055   -0.0863813    0.140807     0.0161075     0.0775001    -0.0144065    0.0390265    0.0712662    -0.0228711    -0.16112     -0.114213     0.0151845    0.0627132
  0.0139319  -0.0202485    0.0745662   -0.0475566   -0.0107816   -0.121639     -0.0210087   0.0147552    0.0274906   -0.107816     -0.103313     0.0185877   -0.101048     0.129986     0.0781296   -0.1341       0.200483     -0.0215574     0.184673    -0.0910985   -0.167314      0.0299801    -0.135094     0.0123722    0.0582435   -0.0854193
  0.0758107  -0.00722995  -0.0133368    0.0717129    0.042216     0.0507749     0.12378     0.0762846    0.0149964   -0.0261713     0.0206304   -0.00197933   0.0720197    0.128585     0.168061     0.322223     0.14988      -0.0692997    -0.127465    -0.0800101   -0.0206913    -0.0660904    -0.0149602   -0.0472375    0.0674105   -0.0770059
  0.198021   -0.0252697    0.141641     0.0503138    0.0981647    0.0262333    -0.110957    0.136948     0.0449947    0.144625      0.154422     0.0183915   -0.0123513    0.15851      0.0892939   -0.185188    -0.152759      0.187306     -0.00465919   0.0980463   -0.0650643    -0.00155072    0.0382367    0.209062     0.153877    -0.112362
 -0.082457   -0.00738303   0.109221     0.0558515   -0.285952     0.210929     -0.0576171   0.115398     0.00724079   0.0111357    -0.0478889    0.0319341   -0.0163595   -0.0917668    0.171171    -0.0238649   -0.0457687     0.000242454  -0.0813089   -0.217142    -0.0199762    -0.0736486    -0.112529    -0.0714279    0.0853539   -0.0237317
  0.135839   -0.0928071   -0.0465614    0.121367     0.197015    -0.000850628   0.0917339  -0.185934     0.0562338   -0.127089     -0.0231319   -0.0486398    0.147459    -0.0518923    0.126891    -0.0414669   -0.0556952     0.0396773     0.042109    -0.0920451   -0.0360702     0.0620131    -0.0689265   -0.0615294    0.0149021   -0.159831
 -0.109725    0.0896041    0.0910648   -0.221806    -0.0949459    0.179193     -0.0671049   0.0847886    0.0318175   -0.000279749  -0.106437     0.111379     0.139489     0.00294412  -0.00426357   0.0226231    0.0466947    -0.305364     -0.0791179   -0.132687    -0.0460659    -0.136745      0.0677565    0.0477191    0.00467716  -0.0456148
  0.0475331  -0.141926    -0.0535071    0.0839152   -0.0928739   -0.094309      0.115721    0.165178     0.0949354   -0.0609772     0.150639    -0.0661419   -0.0149897   -0.0334765    0.0287437    0.0871511    0.00702921    0.0332578    -0.181467    -0.0600028   -0.0385664     0.0265511    -0.0965642   -0.0451455    0.0787351    0.138257
 -0.0768755   0.122182     0.0647223   -0.0243047   -0.13548     -0.0588994     0.0793625  -0.10937     -0.031297     0.0624841    -0.0810712    0.0191577   -0.155413    -0.0749604   -0.00167869   0.0941832    0.156863      0.0828571    -0.0681485    0.037342    -0.00224453   -0.0977944     0.0882664   -0.0686257    0.220457     0.173916[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.046031
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     19
│     20
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.981008
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      5
│      8
│      ⋮
│     15
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.947626
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     14
│     19
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.020655
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.996418
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      5
│      8
│      ⋮
│     20
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.937322
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     14
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.032467
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     19
│     20
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.986319
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      5
│      8
│      ⋮
│     15
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.948895
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     14
│     19
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.020563
┌ Info: EM with 100000 data points 10 iterations avll -1.020563
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.159319    -0.035674     0.0723227    0.0847669   -0.278917    -0.0490766   -0.0304855    0.0459285   -0.0356512   -0.160068     0.00919794  -0.0107935    0.0548449  -0.169226     0.0435056    0.0829527    -0.0922761    -0.192342     0.0970922   -0.033151     0.043185     0.0329182    0.104475      0.0944501  -0.0186946   -0.0151041
 -0.120246    -0.0699029   -0.094368    -0.0150911    0.0695017   -0.200896     0.202377    -0.108563     0.171876    -0.00654812   0.0134676    0.0750247    0.0903034  -0.0715344   -0.0774331   -0.02974      -0.0475413    -0.144001     0.0249191    0.0754495    0.011444     0.0371871   -0.107002     -0.223626    0.107201    -0.189398
 -0.00924239   0.0241464   -0.00248338  -0.101928    -0.11197     -0.0346157    0.0951674    0.0495218   -0.0526655   -0.0904251   -0.102417     0.030579     0.14604     0.0696328   -0.152241    -0.140571     -0.142826      0.00413068  -0.00184586   0.10325      0.0113698   -0.0666619   -0.172773      0.10701    -0.0475267    0.0206001
  0.175484    -0.130638     0.00773234  -0.0721988   -0.0333117   -0.0175383    0.162685     0.201999    -0.0778892    0.127635    -0.160902    -0.0604244   -0.0502825   0.234694    -0.0907953   -0.114342     -0.0694235    -0.0333604   -0.127175    -0.0721627    0.162849    -0.0431281   -0.000114211   0.038902    0.0112434   -0.0349425
 -0.0690327   -0.0372122   -0.0488982    0.0629504    0.0700401    0.0390404   -0.023227    -0.00727874   0.0365891    0.00711728   0.0434275   -0.0414823   -0.156759   -0.0344396   -0.00407253   0.13631       0.0859075     0.0685253    0.0190155    0.0434631   -0.128205     0.0290048    0.0106994    -0.0176275  -0.115422    -0.0971998
  0.229859     0.077556     0.0553201   -0.0152047    0.119027     0.107404    -0.0175687    0.126812    -0.0390632    0.00628921   0.0408794    0.0673978   -0.18486     0.00384272   0.200785    -0.193173     -0.0312411    -1.53303e-5   0.0245753   -0.0480793    0.100657     0.0143872    0.0559652    -0.224489    0.0913961    0.0511657
  0.0417644   -0.0891014    0.0488051    0.186254    -0.143654    -0.0171945    0.05719     -0.0538117    0.154041    -0.181851     0.00084034  -0.0231256    0.131483    0.087077    -0.0442235   -0.0340895    -0.000334096   0.112078    -0.0760883    0.111517    -3.1127e-5   -0.0731675    0.0521677    -0.179044   -0.0989332    0.0140213
 -0.00779393   0.122487     0.0118387    0.0146501    0.00392708   0.0406609   -0.0744167    0.0350023    0.0803762   -0.032746     0.0282789    0.0626328    0.207328   -0.0386047   -0.0790121    0.136527     -0.169121      0.0373069    0.0455822    0.196447    -0.130389    -0.14584     -0.0395966     0.0281081  -0.0247924   -0.01292
 -0.0436341    0.0733965   -0.0733967   -0.207574    -0.0374952    0.00417407   0.168691    -0.136878    -0.046083    -0.0223175    0.0291115    0.0409398   -0.0583958   0.0427426   -0.0776319    0.0247099    -0.11171      -0.0427506   -0.0213166   -0.205081    -0.00253248   0.0508772   -0.116534      0.110892    0.0119977   -0.00222228
  0.0410587    0.0421083   -0.0221132   -0.0263724    0.0755306   -0.187393     0.100423     0.109814    -0.0102307   -0.117751     0.0143418    0.123466     0.230163   -0.0302071   -0.071611    -0.129066     -0.141177      0.0137019    0.0584485    0.125105    -0.253856     0.027557    -0.142636     -0.0443158   0.00177419   0.0328013
  0.0304942   -0.0314698   -0.00185325   0.0584043    0.0650011   -0.0898683    0.0718875    0.0608325   -0.0387519   -0.0756544   -0.136153    -0.072233    -0.0642088   0.104662     0.0236574   -0.000350277   0.0420362     0.0194433    0.0645913    0.0708947   -0.0566904    0.00614223   0.0356228    -0.112375   -0.0325515   -0.0757394
 -0.0481913    0.147196    -0.118854    -0.102657    -0.00365746   0.0273469    0.0343825   -0.0899375    0.0721885   -0.0655479   -0.0658707   -0.0504275    0.0871343  -0.0559537   -0.134511    -0.0803266     0.0941018     0.0466687    0.0462628    0.00549606  -0.0304388    0.06537     -0.0829888    -0.278412   -0.0382372    0.0754895
  0.0913949   -0.111457    -0.131181     0.0117629   -0.0177255    0.303816     0.121508     0.0220118    0.0694125   -0.171263    -0.0333119    0.0184191    0.0740354  -0.121388     0.0711195    0.0211397     0.0782388    -0.168921    -0.152346    -0.232601     0.135725    -0.0934483    0.0659779    -0.037988    0.0366459    0.0717216
  0.117969    -0.12376     -0.111351     0.123597    -0.0260838   -0.0751428   -0.00377672  -0.0921492    0.0305019    0.0488499   -0.0833165   -0.0880067    0.163281   -0.0945383    0.0411289   -0.125136     -0.0907835     0.103731     0.0400145   -0.0653344   -0.0877042    0.0318653    0.0230389    -0.087991   -0.175272    -0.0565786
 -0.060537     0.0155094    0.192047     0.0116316   -0.13849      0.0188822    0.0507165    0.0986795   -0.204617     0.0576751   -0.065402     0.149804    -0.168808   -0.118147    -0.293246     0.0415765    -0.072758     -0.0207432    0.0930872   -0.0444087   -0.19614      0.266617    -0.080215      0.108556   -0.277657    -0.151087
 -0.13632     -0.161254     0.0900521   -0.122611     0.15217     -0.0635414    0.0293291    0.0550493    0.0748064    0.0513976    0.0886066    0.185097    -0.118859    0.0490604   -0.0809539    0.1003       -0.0426239    -0.0782369    0.0132497    0.0230474    0.0798875    0.00949012  -0.231171     -0.0406511   0.0189325   -0.0646473
 -0.17395      0.0519615   -0.0201055    0.141227     0.0896442   -0.134565     0.0232815   -0.107861     0.0913066    0.0418322   -0.0873319   -0.0657624    0.0476523  -0.068331    -0.00206468   0.117742      0.0366003    -0.101668    -0.0784027   -0.0748415   -0.00111119  -0.00911499   0.242184     -0.0366066  -0.0241583   -0.0146826
 -0.0546801    0.0193216   -0.157873    -0.0538769   -0.15282     -0.00252466   0.0226978   -0.0326843   -0.271739     0.0122257   -0.124586     0.144902    -0.10727    -0.023655     0.0374784   -0.0576832    -0.0486514    -0.0951806   -0.101716     0.00570381   0.0992325   -0.0544588    0.125579      0.012842   -0.18021      0.0454918
  0.0842107    0.178977     0.131106     0.0976977   -0.0678003    0.0358127    0.0556998    0.0241144   -0.0623483   -0.0979727    0.0206146   -0.00210684   0.184376   -0.0351351   -0.0332742   -0.131459      0.0484009    -0.151583     0.0851674    0.168153    -0.0531318   -0.236835    -0.0112377     0.0734428   0.0948249   -0.126634
  0.115814    -0.181134     0.182903     0.137293     0.225314     0.0570697   -0.00542344  -0.061801    -0.0606941    0.0572128   -0.0382905   -0.19124     -0.0252543  -0.0500604   -0.0888229    0.0343072    -0.221045      0.155978     0.0503149   -0.131974    -0.0214892    0.152739     0.0956584     0.0417024   0.0266121   -0.142482
  0.0518718   -0.113046     0.0775319   -0.103113    -0.0313749    0.0511509    0.151824     0.0651261   -0.213944    -0.00767594   0.106172    -0.186401    -0.0871048  -0.153661    -0.132346    -0.0751191    -0.0764201     0.0150175    0.15769      0.0633842    0.0506649    0.11448      0.0452809     0.173293   -0.146422     0.0957979
  0.0376336    0.0234541    0.0894905    0.0957094   -0.108993     0.070122    -0.147151    -0.0703952    0.0520659    0.115979     0.132705    -0.142677    -0.0427558   0.0117159   -0.0501336    0.0508518    -0.039729     -0.182896    -0.101479     0.121149     0.083194    -0.0831994    0.0154277    -0.0601216   0.161703     0.191819
  0.0974396   -0.0217929    0.139301    -0.0170531   -0.237499    -0.0430505    0.178476    -0.0630124    0.0235722   -0.303157     0.136272     0.060612     0.10616     0.168466     0.0145531   -0.0496032     0.152824     -0.185161    -0.157904     0.122958    -0.11429      0.00406142  -0.050378     -0.0856505   0.108645     0.0382659
  0.106738     0.148773    -0.103768    -0.110846    -0.00490801  -0.0257554    0.0235169    0.114788     0.0407372    0.0228198   -0.016267     0.0565119    0.074901    0.121849     0.0628662   -0.10113      -0.0251057     0.00298139  -0.0443235    0.181758     0.0307855   -0.20513      0.0743888    -0.0187076  -0.0541471    0.0546074
 -0.0179626   -0.0402123    0.157657    -0.220703    -0.0788833    0.00420717  -0.0711742   -0.101417     0.0960045    0.0572801    0.152734    -0.0135148    0.117913    0.0791496    0.0786895    0.0912705    -0.0240875    -0.185307     0.0877407   -0.0428957    0.0697077    0.0241021    0.0288324     0.0840968  -0.161298    -0.00967344
 -0.0324665   -0.0147399    0.0963347   -0.0950012   -0.22555     -0.0360129    0.00197471   0.00490085  -0.211102     0.294586     0.162086    -0.15473     -0.0227644   0.0775839   -0.0772156   -0.00107227   -0.185333      0.0468722   -0.0625508    0.078973    -0.01749      0.1514      -0.15667      -0.0471028  -0.0304537    0.0811645
 -0.135641    -0.0806194   -0.097584    -0.0299536   -0.095175    -0.0443324    0.112517     0.0998277   -0.00659636  -0.0715891    0.0199202   -0.046965    -0.130357    0.175631     0.0396159   -0.00199565   -0.0852214    -0.103839     0.0391655    0.0550293    0.0358035    0.141831    -0.0318181     0.0200777   0.20295     -0.0490998
 -0.166294    -0.0492672   -0.0708297   -0.0204947    0.0156348   -0.00255635  -0.088844    -0.00989712   0.147369    -0.0593266   -0.0314763    0.0402348   -0.0620004  -0.031522     0.0274191   -0.0268504    -0.0596929     0.0692849    0.00167392   0.0115878    0.00303219  -0.0182265   -0.24171       0.141197    0.0496819   -0.143121
  0.185098     0.11644     -0.0158211    0.158552     0.103907     0.136076    -0.0205865   -0.114239    -0.219133    -0.0171099    0.0800462    0.047317     0.0576846  -0.0592948    0.162891    -0.168654      0.0164248     0.115626     0.0919711    0.0325571   -0.0420004   -0.0677457   -0.0161746    -0.0580218   0.136926    -0.0124383
 -0.00904951   0.174717    -0.00599439  -0.00616471  -0.0977789    0.129509    -0.0886138    0.14943     -0.110048    -0.106498    -0.114838    -0.00597398   0.125915   -0.00271375  -0.0022838   -0.0462888     0.0402022     0.0279357    0.219791     0.0497363    0.153198     0.175402    -0.0214372     0.0509791  -0.0800495    0.0515551
 -0.105484     0.0536357    0.135434    -0.123125     0.00778214   0.109635    -0.0157392   -0.037918     0.00275576   0.0186882    0.240124     0.0803732   -0.0197261  -0.0479533   -0.0767847    0.0289188    -0.0105866    -0.156419    -0.0595455    0.0182889   -0.027509     0.320805     0.0576777    -0.048948   -0.0492346   -0.0695907
 -0.0261996   -0.00505577  -0.0399716   -0.0443158    0.170885    -0.129493     0.050793     0.0493972   -0.164304    -0.0424009    0.174428     0.102481     0.231067   -0.0414987    0.0896093    0.0479278     0.0654053    -0.00884131   0.0468463   -0.0658341    0.183356    -0.0156877    0.00369699    0.0262779  -0.0784063   -0.0385505kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4195414705500016
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419561
[ Info: iteration 2, average log likelihood -1.419471
[ Info: iteration 3, average log likelihood -1.419394
[ Info: iteration 4, average log likelihood -1.419299
[ Info: iteration 5, average log likelihood -1.419181
[ Info: iteration 6, average log likelihood -1.419036
[ Info: iteration 7, average log likelihood -1.418851
[ Info: iteration 8, average log likelihood -1.418588
[ Info: iteration 9, average log likelihood -1.418168
[ Info: iteration 10, average log likelihood -1.417496
[ Info: iteration 11, average log likelihood -1.416567
[ Info: iteration 12, average log likelihood -1.415590
[ Info: iteration 13, average log likelihood -1.414862
[ Info: iteration 14, average log likelihood -1.414459
[ Info: iteration 15, average log likelihood -1.414273
[ Info: iteration 16, average log likelihood -1.414193
[ Info: iteration 17, average log likelihood -1.414160
[ Info: iteration 18, average log likelihood -1.414145
[ Info: iteration 19, average log likelihood -1.414139
[ Info: iteration 20, average log likelihood -1.414136
[ Info: iteration 21, average log likelihood -1.414134
[ Info: iteration 22, average log likelihood -1.414134
[ Info: iteration 23, average log likelihood -1.414133
[ Info: iteration 24, average log likelihood -1.414133
[ Info: iteration 25, average log likelihood -1.414133
[ Info: iteration 26, average log likelihood -1.414133
[ Info: iteration 27, average log likelihood -1.414133
[ Info: iteration 28, average log likelihood -1.414133
[ Info: iteration 29, average log likelihood -1.414132
[ Info: iteration 30, average log likelihood -1.414132
[ Info: iteration 31, average log likelihood -1.414132
[ Info: iteration 32, average log likelihood -1.414132
[ Info: iteration 33, average log likelihood -1.414132
[ Info: iteration 34, average log likelihood -1.414132
[ Info: iteration 35, average log likelihood -1.414132
[ Info: iteration 36, average log likelihood -1.414132
[ Info: iteration 37, average log likelihood -1.414132
[ Info: iteration 38, average log likelihood -1.414132
[ Info: iteration 39, average log likelihood -1.414132
[ Info: iteration 40, average log likelihood -1.414132
[ Info: iteration 41, average log likelihood -1.414132
[ Info: iteration 42, average log likelihood -1.414132
[ Info: iteration 43, average log likelihood -1.414132
[ Info: iteration 44, average log likelihood -1.414132
[ Info: iteration 45, average log likelihood -1.414132
[ Info: iteration 46, average log likelihood -1.414132
[ Info: iteration 47, average log likelihood -1.414132
[ Info: iteration 48, average log likelihood -1.414132
[ Info: iteration 49, average log likelihood -1.414132
[ Info: iteration 50, average log likelihood -1.414132
┌ Info: EM with 100000 data points 50 iterations avll -1.414132
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4195608125664974
│     -1.4194713346153303
│      ⋮
└     -1.4141316887461786
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414151
[ Info: iteration 2, average log likelihood -1.414059
[ Info: iteration 3, average log likelihood -1.413978
[ Info: iteration 4, average log likelihood -1.413882
[ Info: iteration 5, average log likelihood -1.413768
[ Info: iteration 6, average log likelihood -1.413648
[ Info: iteration 7, average log likelihood -1.413535
[ Info: iteration 8, average log likelihood -1.413440
[ Info: iteration 9, average log likelihood -1.413366
[ Info: iteration 10, average log likelihood -1.413308
[ Info: iteration 11, average log likelihood -1.413260
[ Info: iteration 12, average log likelihood -1.413214
[ Info: iteration 13, average log likelihood -1.413167
[ Info: iteration 14, average log likelihood -1.413113
[ Info: iteration 15, average log likelihood -1.413051
[ Info: iteration 16, average log likelihood -1.412977
[ Info: iteration 17, average log likelihood -1.412893
[ Info: iteration 18, average log likelihood -1.412804
[ Info: iteration 19, average log likelihood -1.412717
[ Info: iteration 20, average log likelihood -1.412640
[ Info: iteration 21, average log likelihood -1.412577
[ Info: iteration 22, average log likelihood -1.412530
[ Info: iteration 23, average log likelihood -1.412497
[ Info: iteration 24, average log likelihood -1.412475
[ Info: iteration 25, average log likelihood -1.412460
[ Info: iteration 26, average log likelihood -1.412450
[ Info: iteration 27, average log likelihood -1.412444
[ Info: iteration 28, average log likelihood -1.412439
[ Info: iteration 29, average log likelihood -1.412435
[ Info: iteration 30, average log likelihood -1.412432
[ Info: iteration 31, average log likelihood -1.412429
[ Info: iteration 32, average log likelihood -1.412427
[ Info: iteration 33, average log likelihood -1.412425
[ Info: iteration 34, average log likelihood -1.412423
[ Info: iteration 35, average log likelihood -1.412421
[ Info: iteration 36, average log likelihood -1.412419
[ Info: iteration 37, average log likelihood -1.412418
[ Info: iteration 38, average log likelihood -1.412416
[ Info: iteration 39, average log likelihood -1.412414
[ Info: iteration 40, average log likelihood -1.412413
[ Info: iteration 41, average log likelihood -1.412411
[ Info: iteration 42, average log likelihood -1.412410
[ Info: iteration 43, average log likelihood -1.412408
[ Info: iteration 44, average log likelihood -1.412406
[ Info: iteration 45, average log likelihood -1.412405
[ Info: iteration 46, average log likelihood -1.412403
[ Info: iteration 47, average log likelihood -1.412402
[ Info: iteration 48, average log likelihood -1.412400
[ Info: iteration 49, average log likelihood -1.412399
[ Info: iteration 50, average log likelihood -1.412397
┌ Info: EM with 100000 data points 50 iterations avll -1.412397
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4141507774866868
│     -1.4140587182143363
│      ⋮
└     -1.4123969382393058
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412406
[ Info: iteration 2, average log likelihood -1.412336
[ Info: iteration 3, average log likelihood -1.412271
[ Info: iteration 4, average log likelihood -1.412195
[ Info: iteration 5, average log likelihood -1.412099
[ Info: iteration 6, average log likelihood -1.411982
[ Info: iteration 7, average log likelihood -1.411846
[ Info: iteration 8, average log likelihood -1.411700
[ Info: iteration 9, average log likelihood -1.411555
[ Info: iteration 10, average log likelihood -1.411424
[ Info: iteration 11, average log likelihood -1.411315
[ Info: iteration 12, average log likelihood -1.411228
[ Info: iteration 13, average log likelihood -1.411163
[ Info: iteration 14, average log likelihood -1.411116
[ Info: iteration 15, average log likelihood -1.411082
[ Info: iteration 16, average log likelihood -1.411057
[ Info: iteration 17, average log likelihood -1.411038
[ Info: iteration 18, average log likelihood -1.411023
[ Info: iteration 19, average log likelihood -1.411011
[ Info: iteration 20, average log likelihood -1.411001
[ Info: iteration 21, average log likelihood -1.410992
[ Info: iteration 22, average log likelihood -1.410984
[ Info: iteration 23, average log likelihood -1.410976
[ Info: iteration 24, average log likelihood -1.410969
[ Info: iteration 25, average log likelihood -1.410962
[ Info: iteration 26, average log likelihood -1.410955
[ Info: iteration 27, average log likelihood -1.410948
[ Info: iteration 28, average log likelihood -1.410941
[ Info: iteration 29, average log likelihood -1.410934
[ Info: iteration 30, average log likelihood -1.410927
[ Info: iteration 31, average log likelihood -1.410920
[ Info: iteration 32, average log likelihood -1.410913
[ Info: iteration 33, average log likelihood -1.410906
[ Info: iteration 34, average log likelihood -1.410898
[ Info: iteration 35, average log likelihood -1.410891
[ Info: iteration 36, average log likelihood -1.410883
[ Info: iteration 37, average log likelihood -1.410875
[ Info: iteration 38, average log likelihood -1.410867
[ Info: iteration 39, average log likelihood -1.410859
[ Info: iteration 40, average log likelihood -1.410851
[ Info: iteration 41, average log likelihood -1.410843
[ Info: iteration 42, average log likelihood -1.410835
[ Info: iteration 43, average log likelihood -1.410827
[ Info: iteration 44, average log likelihood -1.410819
[ Info: iteration 45, average log likelihood -1.410811
[ Info: iteration 46, average log likelihood -1.410803
[ Info: iteration 47, average log likelihood -1.410796
[ Info: iteration 48, average log likelihood -1.410788
[ Info: iteration 49, average log likelihood -1.410781
[ Info: iteration 50, average log likelihood -1.410774
┌ Info: EM with 100000 data points 50 iterations avll -1.410774
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4124061266787091
│     -1.412335925241652
│      ⋮
└     -1.4107742642254473
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410777
[ Info: iteration 2, average log likelihood -1.410713
[ Info: iteration 3, average log likelihood -1.410656
[ Info: iteration 4, average log likelihood -1.410590
[ Info: iteration 5, average log likelihood -1.410510
[ Info: iteration 6, average log likelihood -1.410411
[ Info: iteration 7, average log likelihood -1.410296
[ Info: iteration 8, average log likelihood -1.410168
[ Info: iteration 9, average log likelihood -1.410038
[ Info: iteration 10, average log likelihood -1.409911
[ Info: iteration 11, average log likelihood -1.409794
[ Info: iteration 12, average log likelihood -1.409686
[ Info: iteration 13, average log likelihood -1.409590
[ Info: iteration 14, average log likelihood -1.409505
[ Info: iteration 15, average log likelihood -1.409430
[ Info: iteration 16, average log likelihood -1.409367
[ Info: iteration 17, average log likelihood -1.409313
[ Info: iteration 18, average log likelihood -1.409268
[ Info: iteration 19, average log likelihood -1.409231
[ Info: iteration 20, average log likelihood -1.409199
[ Info: iteration 21, average log likelihood -1.409171
[ Info: iteration 22, average log likelihood -1.409147
[ Info: iteration 23, average log likelihood -1.409126
[ Info: iteration 24, average log likelihood -1.409107
[ Info: iteration 25, average log likelihood -1.409090
[ Info: iteration 26, average log likelihood -1.409073
[ Info: iteration 27, average log likelihood -1.409058
[ Info: iteration 28, average log likelihood -1.409044
[ Info: iteration 29, average log likelihood -1.409030
[ Info: iteration 30, average log likelihood -1.409017
[ Info: iteration 31, average log likelihood -1.409005
[ Info: iteration 32, average log likelihood -1.408993
[ Info: iteration 33, average log likelihood -1.408981
[ Info: iteration 34, average log likelihood -1.408970
[ Info: iteration 35, average log likelihood -1.408959
[ Info: iteration 36, average log likelihood -1.408949
[ Info: iteration 37, average log likelihood -1.408939
[ Info: iteration 38, average log likelihood -1.408929
[ Info: iteration 39, average log likelihood -1.408919
[ Info: iteration 40, average log likelihood -1.408909
[ Info: iteration 41, average log likelihood -1.408899
[ Info: iteration 42, average log likelihood -1.408890
[ Info: iteration 43, average log likelihood -1.408881
[ Info: iteration 44, average log likelihood -1.408871
[ Info: iteration 45, average log likelihood -1.408862
[ Info: iteration 46, average log likelihood -1.408854
[ Info: iteration 47, average log likelihood -1.408845
[ Info: iteration 48, average log likelihood -1.408836
[ Info: iteration 49, average log likelihood -1.408828
[ Info: iteration 50, average log likelihood -1.408819
┌ Info: EM with 100000 data points 50 iterations avll -1.408819
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4107765461450188
│     -1.410713240744142
│      ⋮
└     -1.4088193168138239
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408819
[ Info: iteration 2, average log likelihood -1.408750
[ Info: iteration 3, average log likelihood -1.408684
[ Info: iteration 4, average log likelihood -1.408608
[ Info: iteration 5, average log likelihood -1.408513
[ Info: iteration 6, average log likelihood -1.408394
[ Info: iteration 7, average log likelihood -1.408254
[ Info: iteration 8, average log likelihood -1.408097
[ Info: iteration 9, average log likelihood -1.407933
[ Info: iteration 10, average log likelihood -1.407771
[ Info: iteration 11, average log likelihood -1.407619
[ Info: iteration 12, average log likelihood -1.407480
[ Info: iteration 13, average log likelihood -1.407355
[ Info: iteration 14, average log likelihood -1.407244
[ Info: iteration 15, average log likelihood -1.407146
[ Info: iteration 16, average log likelihood -1.407061
[ Info: iteration 17, average log likelihood -1.406986
[ Info: iteration 18, average log likelihood -1.406920
[ Info: iteration 19, average log likelihood -1.406862
[ Info: iteration 20, average log likelihood -1.406811
[ Info: iteration 21, average log likelihood -1.406766
[ Info: iteration 22, average log likelihood -1.406725
[ Info: iteration 23, average log likelihood -1.406689
[ Info: iteration 24, average log likelihood -1.406656
[ Info: iteration 25, average log likelihood -1.406625
[ Info: iteration 26, average log likelihood -1.406597
[ Info: iteration 27, average log likelihood -1.406571
[ Info: iteration 28, average log likelihood -1.406547
[ Info: iteration 29, average log likelihood -1.406524
[ Info: iteration 30, average log likelihood -1.406502
[ Info: iteration 31, average log likelihood -1.406482
[ Info: iteration 32, average log likelihood -1.406462
[ Info: iteration 33, average log likelihood -1.406443
[ Info: iteration 34, average log likelihood -1.406425
[ Info: iteration 35, average log likelihood -1.406407
[ Info: iteration 36, average log likelihood -1.406390
[ Info: iteration 37, average log likelihood -1.406374
[ Info: iteration 38, average log likelihood -1.406358
[ Info: iteration 39, average log likelihood -1.406343
[ Info: iteration 40, average log likelihood -1.406328
[ Info: iteration 41, average log likelihood -1.406314
[ Info: iteration 42, average log likelihood -1.406299
[ Info: iteration 43, average log likelihood -1.406286
[ Info: iteration 44, average log likelihood -1.406272
[ Info: iteration 45, average log likelihood -1.406259
[ Info: iteration 46, average log likelihood -1.406246
[ Info: iteration 47, average log likelihood -1.406233
[ Info: iteration 48, average log likelihood -1.406221
[ Info: iteration 49, average log likelihood -1.406209
[ Info: iteration 50, average log likelihood -1.406197
┌ Info: EM with 100000 data points 50 iterations avll -1.406197
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4088191701970103
│     -1.4087497293434077
│      ⋮
└     -1.406196747540752
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4195414705500016
│     -1.4195608125664974
│     -1.4194713346153303
│     -1.4193935005950524
│      ⋮
│     -1.4062210403668833
│     -1.4062088036677471
└     -1.406196747540752
32×26 Array{Float64,2}:
 -0.177074   -0.167985    0.106138    -0.43022    -0.45465     -0.408121    0.0146221   -0.272098    -0.416887   -0.0749036   1.02103     0.426401    0.464202    0.321529    0.113132     0.0775176   -0.320579    0.283031    -0.241117   -0.692458   -0.254403    -0.00636569   0.743266   -0.00876222   0.0497376    0.202162
  0.620796   -0.235558    0.118185    -0.395895   -0.269593    -0.229087    0.0286133   -0.0998948    0.0197384   0.605708    0.622443   -0.183791   -0.114023   -0.436577    0.25676      0.204621     0.453625   -0.0131909    0.123806   -0.781701    0.640875    -0.370236     0.82987    -0.394403     0.513855     0.423402
 -0.20843    -0.540921   -0.704707    -0.0293083   0.300117    -0.166855   -0.334413     0.100904     0.0810303  -0.272757    0.127105   -0.161662   -0.532733   -0.042809   -0.206889    -0.350164     0.205928   -0.281703     0.0471862  -1.13339     0.192418     0.214405    -0.10192    -0.610844     0.520087    -0.115265
  0.118835    0.444655   -0.0147777    0.217805    0.21844      0.122149    0.0403564   -0.304259     0.0153282  -0.0314833   0.0586304   0.162544    0.110182   -0.163769   -0.142584    -0.0384532    0.0222637   0.0340767    0.314093   -0.0736884   0.134038     0.0551037    0.260017   -0.279823    -0.115411     0.402326
 -0.0889849   0.0336561  -0.39119     -0.355261    0.0176758    0.110279    0.0893194   -0.174644    -0.257264    0.848502   -0.0545185   0.0432622  -0.863413    0.26872    -0.333021    -0.0207435    0.319417   -0.150416     0.227557   -0.64795    -0.0203209    0.111724    -0.607934    0.0810973   -0.793986     0.174467
 -0.064187    0.0575772  -0.34341      0.167457   -0.0682675    0.338032   -0.381501    -0.521699    -0.0439226   0.110018   -0.838928    0.0904411  -0.875685   -0.0756404  -0.294689    -0.312914     0.0832469   0.0568528    0.263591    0.642665    0.317809    -0.155757    -0.0842765  -0.143201    -0.346187     0.0536536
  0.628099   -0.441524    0.191056    -0.189988   -0.0940274    0.154903    0.320898    -0.0569124   -0.856396    1.02553    -0.436443    0.134153   -0.234474   -0.269482    0.352085     0.0833157   -0.0739552   0.260117     0.595629    0.358673    0.4349      -0.359245    -0.0380153   0.306401     0.172148    -0.133707
  0.309938    0.997411    0.586764    -0.142608   -0.311204     0.0949314   0.033776    -0.0530247   -0.600971    0.126866   -0.323974    0.281639   -0.549219    0.138723   -0.288898     0.629014     0.386352    0.617838     0.58672     0.291549    0.197419     0.0402806   -0.146715    0.32678     -0.532815    -0.0406432
 -0.718466    0.0129247  -0.253913    -0.0694781  -1.05788     -0.0634303  -0.362013    -0.22522      0.246326   -0.263046    0.540935    0.0655452   0.576607    0.317638   -0.0487977   -0.361536     0.146782    0.128399    -0.552061    0.245647    0.00749863   0.184934     0.12744    -0.0873164   -0.329531     0.447748
 -0.890855   -0.235192   -0.243843    -0.194261    0.604711     0.0676059   0.0688093   -0.125002     0.130876   -1.08385    -0.096296    0.445878    0.610902    0.177821    0.158312    -0.521044    -0.318633   -0.29476     -0.274037    0.113085    0.202435    -0.751965     0.564786   -0.139472     0.248159    -0.066386
 -0.121009    0.247167    0.622004     0.409724   -0.48366      0.385926    0.152273    -0.516319     0.353681   -0.233922   -0.305077   -0.24817     0.92662    -0.502329    0.241527     0.228016    -0.409092    0.163192    -0.434615    0.934956   -0.276018     0.0189064    0.41989     0.16071      0.130772    -0.198423
  0.384742   -0.300357    0.0786982    0.118589   -0.244387    -0.035568    0.158882     0.885881     0.236271   -0.111668    0.251896    0.0848806   0.592439    0.145537    0.103096    -0.29281     -0.2249     -0.220444    -0.424352    0.645388   -0.411545     0.394802     0.21377     0.0453145    0.514238    -0.0483135
 -0.410721   -0.249267    0.350754     0.132629   -0.608975    -0.104141    0.0214636   -0.0292107   -0.0735999  -0.118702   -0.202424   -0.480251   -0.28615     0.0674221  -0.161977     0.125561     0.942931   -0.56487      0.423404   -0.0210493  -0.052334     0.274493    -0.0400901   0.813527     0.357552     0.0898615
  0.28041     0.614983    0.339792     0.323803    0.654187     0.198655    0.0953178    0.318226     0.472929   -0.522819   -0.347501   -0.207229   -0.258908    0.298498   -0.563811    -0.228711     0.413035   -0.575189     0.164558    0.291016    0.0929817    0.0806978   -0.0434587   0.0200365   -0.149794    -0.334827
  0.0786151  -0.247149   -0.0306518   -0.200299   -0.123798    -0.595974    0.232238     0.174739    -0.108103   -0.192449    0.0258317  -0.211865    0.140056   -0.0338096   0.319128     0.14861     -0.635008   -0.115387    -0.280878   -0.225484   -0.0443709   -0.244426    -0.729301   -0.401104    -0.538645    -0.680592
 -0.47654    -0.743634    0.193885    -0.467199   -0.00719593   0.0192429  -0.18956      0.19945      0.480393   -0.289958   -0.0595401  -0.420023   -0.0904629   0.105371    0.32988      0.304693    -0.542452   -0.157838    -0.200208    0.0251702  -0.507079    -0.0649864   -0.446179    0.965724     0.319337    -0.584264
 -0.472248   -0.158941   -0.227864     0.391546    0.144423    -0.130191    0.00107753   0.210169     0.273211   -0.750126    0.201733   -0.148854    0.128251    0.378443   -0.0378559   -0.441124     0.144576   -0.282862    -0.219407   -0.114304   -0.501048     0.532329    -0.443506   -0.221559    -0.147351    -0.0632371
 -0.113456   -0.561227   -0.205293    -0.0267293  -0.502516     0.0497979  -0.230522    -0.104594    -0.19079     0.672004    0.243524   -0.295225   -0.273942    0.0259183   0.133705     0.0613164   -0.302436   -0.00497239  -0.505743    0.0795218  -0.554823     0.446864    -0.426598    0.0585016   -0.192477    -0.0671431
 -0.311916    0.0862058   0.160241    -0.670499    0.457693     0.0429733   0.254222    -0.498769    -0.121083    0.0756634   0.12898    -0.082648    0.0406571   0.0979862   0.0367764    0.785784    -0.121818   -0.0650148   -0.283448   -0.519465    0.539539    -0.111119    -0.16788    -0.324208    -0.300491    -0.21055
 -0.488443   -0.400534   -0.0133986   -0.102047    0.526803     0.159353    0.28035      0.626129    -0.340145   -0.105807    0.410102    0.189439    0.210969   -0.201337    0.19591      0.573007     0.0957223  -0.420434    -0.0867043  -0.312563   -0.0356614    0.113005    -0.109843   -0.100141     0.391389    -0.318376
  0.421723   -0.0377761  -0.0286855    0.227824    0.469476    -0.107956    0.496754     0.0409237   -0.0896471   0.160839   -0.306607   -0.256556   -0.0821255  -0.499544    0.0769295    0.299088    -0.301422   -0.049441     0.622234   -0.452906   -0.0833756    0.0601309   -0.507207    0.138021     0.248764    -0.305502
  0.208667   -0.0182418  -0.029698     0.06024     0.130474     0.172413    0.342715     0.247393    -0.226091    0.277317    0.0036647  -0.140935   -0.12144    -0.0941264  -0.041494    -0.199721     0.132351   -0.0587609    0.381664    0.300501   -0.448102    -0.345099    -0.599615    0.54917     -0.545295    -0.177999
 -0.160647   -0.198933   -0.0151768   -0.160907   -0.141374    -0.140693    0.0958697    0.0858046   -0.0382667  -0.210806    0.135394    0.131481    0.350556    0.0460954   0.132435     0.0183579   -0.213559   -0.0426551   -0.197074    0.100915   -0.0527595   -0.0739255   -0.0156353  -0.0674237    0.0182147   -0.11248
  0.50845    -0.08472     0.23156     -0.325849   -0.064596    -0.0996487   0.412343     0.387312     0.053657    0.0185215  -0.378706   -0.0894828   0.078491    0.312914   -0.397108     0.0183601   -0.371335    0.239348    -0.258419    0.116935   -0.0318125   -0.0652647   -0.239329    0.0741327   -0.099434    -0.265316
  0.272756    0.468748   -0.345975    -0.0197186  -0.00238505  -0.0262573   0.132374     0.0200498   -0.0146431   0.0410999   0.102165    0.646445    0.389204   -0.121709    0.137976    -0.101385    -0.785154    0.275551    -0.544383    0.258817    0.0281142   -0.361359     0.240321   -0.761404    -0.103504     0.0328969
  0.166651    0.189187   -0.409001     0.12524    -0.00400158  -0.421008    0.137017    -0.131758    -0.439011   -0.282914   -0.398883    0.258631    0.129451   -0.160778   -0.00103612  -0.298624    -0.0856162   0.259905     1.19006    -0.25382     0.460125    -0.800506    -0.150036   -0.45745      0.00152843   0.122437
  0.0993823   0.635284   -0.0480194    0.252661    0.0749807   -0.504098   -0.0168508   -0.160935    -0.346507    0.035296    0.285055    0.638019    0.291234   -0.122948   -0.0309054   -0.220782     0.362797   -0.220708     0.243831   -0.192736    0.343709     0.503762     0.400582   -0.629683     0.00568263   0.568555
  0.299989    0.440501   -0.159259     0.188868    0.487298     1.04044     0.0179197   -0.00316834   0.0300887   0.0173243   0.182472    0.326131    0.253697   -0.217242   -0.389086     0.00854614   0.210234    0.228074     0.338214    0.340867   -0.0422218    0.11715      0.560034   -0.219789     0.005284     0.575598
  0.0117299   0.197534    0.00192669  -0.090526    0.0331376    0.0735284  -0.0546619   -0.109104    -0.137147    0.239234   -0.0195668   0.057544   -0.285135   -0.0112483  -0.0761153    0.00586341   0.213483   -0.13668      0.156453   -0.0438073   0.111938     0.0470548   -0.0185752   0.0103998   -0.151716     0.139393
 -0.152422   -0.019221    0.197707     0.488927   -0.136652    -0.0172625  -0.425921    -0.538228     0.0305731  -0.255923    0.123717   -0.323621   -0.159263   -0.104001   -0.029872    -0.111356     0.0596963   0.19252      0.239205    0.169682    0.110051     0.0925547    0.178885    0.0860795   -0.0556915    0.084742
  0.376265    0.14847     0.0925105   -0.105514   -0.434008     0.0659127  -0.371466     0.358714     0.579434   -0.102644   -0.349334    0.190477    0.0230644   0.148767   -0.38903     -0.582436    -0.162779    0.180527     0.0824086   0.473562   -0.242551     0.0794249    0.386282    0.532496     0.393949     0.390442
 -0.0499274  -0.14503     0.176794     0.118599    0.0272292   -0.0916124  -0.013657     0.376581     0.580797   -0.137199    0.423851   -0.328649    0.472337    0.102345    0.207735    -0.378372    -0.23219    -0.211813    -0.658727    0.264927   -0.00890198   0.191386     0.504025    0.118045     0.554153    -0.071861[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406185
[ Info: iteration 2, average log likelihood -1.406173
[ Info: iteration 3, average log likelihood -1.406161
[ Info: iteration 4, average log likelihood -1.406150
[ Info: iteration 5, average log likelihood -1.406139
[ Info: iteration 6, average log likelihood -1.406127
[ Info: iteration 7, average log likelihood -1.406116
[ Info: iteration 8, average log likelihood -1.406105
[ Info: iteration 9, average log likelihood -1.406094
[ Info: iteration 10, average log likelihood -1.406084
┌ Info: EM with 100000 data points 10 iterations avll -1.406084
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.404090e+05
      1       6.936956e+05      -2.467134e+05 |       32
      2       6.819958e+05      -1.169985e+04 |       32
      3       6.775354e+05      -4.460371e+03 |       32
      4       6.752445e+05      -2.290919e+03 |       32
      5       6.737444e+05      -1.500091e+03 |       32
      6       6.726277e+05      -1.116693e+03 |       32
      7       6.717757e+05      -8.520093e+02 |       32
      8       6.711208e+05      -6.548999e+02 |       32
      9       6.705513e+05      -5.694747e+02 |       32
     10       6.700073e+05      -5.440336e+02 |       32
     11       6.695221e+05      -4.851728e+02 |       32
     12       6.691331e+05      -3.889854e+02 |       32
     13       6.687964e+05      -3.367417e+02 |       32
     14       6.685191e+05      -2.772618e+02 |       32
     15       6.682969e+05      -2.222439e+02 |       32
     16       6.681192e+05      -1.777081e+02 |       32
     17       6.679586e+05      -1.605937e+02 |       32
     18       6.678162e+05      -1.424079e+02 |       32
     19       6.676935e+05      -1.226715e+02 |       32
     20       6.675822e+05      -1.112752e+02 |       32
     21       6.674900e+05      -9.222937e+01 |       32
     22       6.674103e+05      -7.968589e+01 |       32
     23       6.673418e+05      -6.854914e+01 |       32
     24       6.672819e+05      -5.981278e+01 |       32
     25       6.672199e+05      -6.204901e+01 |       32
     26       6.671571e+05      -6.279059e+01 |       32
     27       6.670869e+05      -7.024721e+01 |       32
     28       6.670285e+05      -5.836760e+01 |       32
     29       6.669759e+05      -5.260261e+01 |       32
     30       6.669283e+05      -4.760755e+01 |       32
     31       6.668793e+05      -4.901414e+01 |       32
     32       6.668315e+05      -4.776239e+01 |       32
     33       6.667877e+05      -4.379521e+01 |       32
     34       6.667478e+05      -3.990844e+01 |       32
     35       6.667123e+05      -3.551467e+01 |       32
     36       6.666830e+05      -2.924986e+01 |       32
     37       6.666563e+05      -2.675852e+01 |       32
     38       6.666293e+05      -2.700498e+01 |       32
     39       6.666073e+05      -2.196366e+01 |       32
     40       6.665891e+05      -1.815809e+01 |       32
     41       6.665728e+05      -1.639751e+01 |       32
     42       6.665561e+05      -1.662451e+01 |       32
     43       6.665383e+05      -1.782487e+01 |       32
     44       6.665218e+05      -1.649575e+01 |       32
     45       6.665060e+05      -1.582893e+01 |       32
     46       6.664927e+05      -1.325400e+01 |       32
     47       6.664814e+05      -1.133850e+01 |       32
     48       6.664726e+05      -8.738746e+00 |       32
     49       6.664643e+05      -8.354266e+00 |       32
     50       6.664568e+05      -7.513271e+00 |       32
K-means terminated without convergence after 50 iterations (objv = 666456.7777957905)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417571
[ Info: iteration 2, average log likelihood -1.412699
[ Info: iteration 3, average log likelihood -1.411406
[ Info: iteration 4, average log likelihood -1.410492
[ Info: iteration 5, average log likelihood -1.409569
[ Info: iteration 6, average log likelihood -1.408707
[ Info: iteration 7, average log likelihood -1.408057
[ Info: iteration 8, average log likelihood -1.407642
[ Info: iteration 9, average log likelihood -1.407381
[ Info: iteration 10, average log likelihood -1.407203
[ Info: iteration 11, average log likelihood -1.407069
[ Info: iteration 12, average log likelihood -1.406962
[ Info: iteration 13, average log likelihood -1.406871
[ Info: iteration 14, average log likelihood -1.406793
[ Info: iteration 15, average log likelihood -1.406725
[ Info: iteration 16, average log likelihood -1.406664
[ Info: iteration 17, average log likelihood -1.406610
[ Info: iteration 18, average log likelihood -1.406561
[ Info: iteration 19, average log likelihood -1.406516
[ Info: iteration 20, average log likelihood -1.406474
[ Info: iteration 21, average log likelihood -1.406435
[ Info: iteration 22, average log likelihood -1.406399
[ Info: iteration 23, average log likelihood -1.406365
[ Info: iteration 24, average log likelihood -1.406332
[ Info: iteration 25, average log likelihood -1.406302
[ Info: iteration 26, average log likelihood -1.406272
[ Info: iteration 27, average log likelihood -1.406245
[ Info: iteration 28, average log likelihood -1.406218
[ Info: iteration 29, average log likelihood -1.406193
[ Info: iteration 30, average log likelihood -1.406168
[ Info: iteration 31, average log likelihood -1.406145
[ Info: iteration 32, average log likelihood -1.406123
[ Info: iteration 33, average log likelihood -1.406102
[ Info: iteration 34, average log likelihood -1.406082
[ Info: iteration 35, average log likelihood -1.406063
[ Info: iteration 36, average log likelihood -1.406045
[ Info: iteration 37, average log likelihood -1.406028
[ Info: iteration 38, average log likelihood -1.406011
[ Info: iteration 39, average log likelihood -1.405995
[ Info: iteration 40, average log likelihood -1.405980
[ Info: iteration 41, average log likelihood -1.405965
[ Info: iteration 42, average log likelihood -1.405951
[ Info: iteration 43, average log likelihood -1.405938
[ Info: iteration 44, average log likelihood -1.405925
[ Info: iteration 45, average log likelihood -1.405912
[ Info: iteration 46, average log likelihood -1.405900
[ Info: iteration 47, average log likelihood -1.405888
[ Info: iteration 48, average log likelihood -1.405877
[ Info: iteration 49, average log likelihood -1.405865
[ Info: iteration 50, average log likelihood -1.405855
┌ Info: EM with 100000 data points 50 iterations avll -1.405855
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.611593    0.859442    -0.258369    0.369468    -0.0687783  -0.105579    -0.0258298   -0.0925165     0.05132      0.133472    0.0632662    0.394884     0.173639   -0.188175    -0.0281847  -0.521887   -0.0921316  -0.140009    -0.113553    0.364775    0.161656     0.0920048    0.49844     -0.635081    -0.0832031   0.400035
  0.300842    0.0149687   -0.05044     0.00146542   0.174102   -0.035997     0.177144     0.195795     -0.223276     0.236323   -0.12127     -0.0036219   -0.240641   -0.00935509  -0.0942467  -0.092787    0.0149     -0.0927057    0.389772   -0.0790009  -0.198782    -0.153401    -0.415691     0.14936     -0.207581   -0.135378
  0.135203    0.0885017   -0.112497    0.103943    -0.0055563  -0.00645483  -0.0977471   -0.101699     -0.144351     0.133096   -0.0439624    0.163827    -0.175806   -0.00482655  -0.146585   -0.136755    0.0836007   0.0896883    0.336722   -0.0277348   0.159131    -0.00477419   0.0479765   -0.151598    -0.0525516   0.158192
 -0.193162    0.06775      0.416771    0.198343    -0.382102    0.270853     0.0331598   -0.276811      0.374592    -0.241426    0.0856371   -0.111333     0.92502    -0.26117      0.268062   -0.11387    -0.313354   -0.0118588   -0.597479    0.750006   -0.240848     0.0392711    0.575219     0.064763     0.20006    -0.0572012
  0.230877    0.0361296   -0.0748331  -0.752706    -0.399216   -0.557972     0.240296    -0.0330233    -0.0273473    0.138006    0.693033     0.131305     0.274113    0.0594936    0.19266     0.206702   -0.0348982   0.0155107   -0.385738   -0.889714    0.431169    -0.0386001    0.701394    -0.48763      0.196685    0.287817
 -0.354869    0.361692     0.0205561   0.399283     0.319671    0.128935    -0.0787755    0.270256      0.348757    -0.432602   -0.690719    -0.0170561   -0.062811    0.0725334    0.0141885  -0.0970953  -0.134061   -0.445179    -0.0281394   0.88927    -0.148405    -0.148209    -0.576037     0.105112    -0.514623   -0.511252
  0.294021   -0.319871    -0.0733904  -0.313027     0.300575    0.00161022  -0.135919     0.140458     -0.536799     0.794788    0.542625     0.0543402   -0.663524   -0.0775497   -0.0294798   0.241204    0.531725   -0.135707     0.190468   -0.989582    0.723023    -0.310945     0.143946    -0.0214557    0.156845    0.0932582
 -0.0205407   0.438671     0.337241    0.0843586    0.146623    0.423845    -0.0946052   -0.000721877   0.107663     0.059732   -0.0527371    0.342361     0.0528305   0.0541818   -0.240255   -0.10195     0.363258    0.0667914    0.438417    0.29357     0.301951     0.193156     0.579409     0.433132     0.366394    0.46472
 -0.253552   -0.422032    -0.0713076   0.722676    -0.5001      0.121837    -0.124058    -0.0369376    -0.130946     0.0745896   0.0651039   -0.733259    -0.198972   -0.385119     0.145342    0.179844    0.51818     0.199301     0.297758    0.0519192  -0.215853     0.60284     -0.380968     0.40577      0.0595084  -0.0796451
 -0.38164    -0.360905     0.206142   -0.537003    -0.0315089  -0.180781     0.332739    -0.179927     -0.278865     0.0212498   0.150674    -0.0356289    0.181539    0.147533     0.121245    0.317474   -0.104099   -0.203383    -0.218584   -0.159189    0.140325    -0.189523    -0.216934     0.0133983   -0.104848   -0.239791
 -0.535443   -0.0880685   -0.593362   -0.437885    -0.132671    0.275689     0.0932253   -0.542905     -0.033719     0.592775   -0.549948    -0.211907    -1.02501     0.183609    -0.381824   -0.113707    0.280119   -0.249005     0.154156   -0.30387    -0.156108     0.109146    -0.659051     0.319875    -0.612105    0.240003
 -0.424205   -0.344816    -0.35833     0.469465    -0.0978952  -0.320972    -1.04231     -0.565263     -0.110945    -0.196047    0.0816377    0.114371    -0.3482     -0.0387122   -0.180393   -0.685867    0.0146185   0.0495713    0.172473   -0.230794   -0.0153652    0.206206     0.292238    -0.406005    -0.0303684   0.0805623
 -0.918975   -0.648052     0.166663   -0.532978    -0.0869401  -0.494335    -0.403673     0.165622      0.49489     -0.115064    0.440981    -0.00285571   0.0670996   0.319423     0.516344    0.432163   -0.558986   -0.200568    -0.353624   -0.259633   -0.624925     0.131353    -0.483318     0.528493    -0.109059   -0.620538
 -0.211655    0.700798    -0.181953    0.342609     0.139383    0.173275    -0.230415     0.225824      0.785213    -0.877153    0.11579     -0.0595445    0.134615    0.559542    -0.644007   -0.298334    0.190069   -0.0814421   -0.38186    -0.125057   -0.19208      0.52643      0.00998572  -0.345524    -0.25744     0.21747
  0.207481   -0.485978    -0.0277055  -0.259508     0.475656    0.0941305    0.502727     0.0560662    -0.133595    -0.0606715  -0.52745     -0.287605    -0.0341672  -0.707344     0.369625    0.591991   -0.540458   -0.257888     0.345486   -0.30266     0.140759    -0.0626442   -0.510103     0.385953     0.516625   -0.42441
 -0.0595941   0.0249561   -0.0361585   0.0815473   -0.0934972  -0.0321366   -0.00382589   0.00884477    0.0796161   -0.12261     0.0975111   -0.015754     0.125881    0.00963025  -0.0162185  -0.0309805  -0.0561927  -0.00066694  -0.105688    0.036611    0.00215463   0.115668     0.104749    -0.0864949    0.0325066   0.0670356
 -0.12645    -0.0944486    0.0412938  -0.316783    -0.102638    0.637076    -0.417128     0.0455511    -0.0347872    0.246724    0.347864     0.244422    -0.108378    0.288136    -0.338303   -0.213151    0.238872   -0.13375     -0.704744    0.332303   -0.490011     0.441415     0.0726166    0.0814196   -0.410542    0.301656
  0.287595   -0.0708834    0.436095    0.0619345    0.112553   -0.174329     0.347456     0.470941     -0.198937    -0.26998     0.376873     0.534829     0.761441   -0.21914      0.18064     0.0196185  -0.349681    0.00504155  -0.450027    0.457552   -0.108564    -0.217497     0.361394    -0.49109      0.258792   -0.574203
 -0.349724   -0.00376981  -0.546546   -0.111807     0.201173   -0.580649     0.395313    -0.0840195     0.190657    -1.05201    -0.158364     0.118239     0.30049     0.0714437    0.125053   -0.592715   -0.0841578  -0.0942817    0.744716   -0.511822    0.391164    -0.758743     0.190935    -0.387091     0.259868    0.213502
 -0.0144963   0.0193259    0.406884    0.041987     0.024364   -0.287207     0.106084     0.155427     -0.00989616  -0.406042   -0.208332    -0.447303    -0.511685    0.233605    -0.496386   -0.17904     0.888316   -1.01017      0.462754   -0.0597773   0.123824     0.052234    -0.141374     0.352151     0.281274   -0.284581
  0.797499   -0.421324     0.164879   -0.249015    -0.767954   -0.362957     0.108755     0.381873     -0.413813     0.398908   -0.152897    -0.208471    -0.0695116   0.288827    -0.237599   -0.107024   -0.661017    0.282182    -0.233299   -0.117918   -0.438496     0.25757     -0.63715     -0.11665     -0.416726   -0.20749
 -0.692233    0.202592    -0.558862   -0.118192    -0.352063    0.0648222   -0.16331     -0.254508     -0.157957    -0.253404    0.203046     0.549055     0.611573    0.0527804    0.288831   -0.0721465  -0.748047    0.449047    -0.658852    0.223066    0.100015    -0.225276     0.10499     -0.267638    -0.274681    0.287325
 -0.300858   -0.82753     -0.344927    0.368645     0.417101    0.102856     0.334423     0.669949      0.0124953   -0.283914    0.403817    -0.218015     0.255401    0.397485     0.241825   -0.551708   -0.156527   -0.431756    -0.49599    -0.112189   -0.545238     0.234159    -0.317528    -0.00341381   0.475399   -0.452485
  0.188181    0.0187869   -0.251991   -0.499858     0.559188    0.213093     0.16924     -0.0855732     0.2916       0.0197032  -0.250082    -0.229993    -0.101333    0.174489    -0.145775    0.384286   -0.618755    0.39633     -0.388471   -0.303976    0.345424    -0.377874    -0.168142    -0.418233    -0.156032   -0.559429
  0.34675     0.626343    -0.382188    0.180772     0.230705    0.152213     0.177148    -0.0794758    -0.842646     0.0188739  -0.202676     0.684061     0.256468   -0.191511    -0.377587    0.0552754   0.14423     0.427729     1.12603    -0.28255     0.211125    -0.0886449   -0.0280571   -0.891619    -0.258703    0.591338
  0.0681825   0.553244     0.466863   -0.0816017   -0.276963    0.0765116   -0.289344    -0.794089     -0.235325     0.0362815  -0.345012    -0.0296429   -0.550691   -0.0788773   -0.268757    0.348036    0.258634    0.437073     0.364061    0.223884    0.336138    -0.0430787   -0.00999397   0.22946     -0.536298    0.105416
  0.847608    0.127256     0.428705    0.451951     0.647277    0.591611     0.0911429   -0.0719787     0.588843     0.329898    0.0220758   -0.473593    -0.248142   -0.607764    -0.245228    0.267245    0.0243863   0.117748     0.53752    -0.200754   -0.421417    -0.239058     0.534756    -0.173868     0.250636    0.122375
 -0.443537   -0.782614    -0.119035   -0.213441    -0.510789   -0.0421396   -0.136536     0.116558      0.194766    -0.395001    0.373726     0.204634     0.38038    -0.106224     0.422706   -0.0376865   0.290372   -0.513673     0.0254926   0.082285   -0.18173      0.357322     0.205315     0.0802493    0.770419    0.567123
  0.180342   -0.222014     0.238413   -0.0611888   -0.396637   -0.0771447   -0.130508     0.2669        0.618566    -0.24817    -0.148556    -0.288943     0.224327    0.14596     -0.179913   -0.349286   -0.387448    0.1521      -0.32826     0.511027   -0.273599     0.0507385    0.149287     0.537816     0.415423    0.00172755
  0.586057   -0.187417    -0.0426075  -0.0815005   -0.1876      0.113155     0.0988877   -0.188612     -0.682898     0.633535   -0.601959     0.219558    -0.25532    -0.34228      0.196454   -0.121101   -0.0901656   0.277196     0.668463    0.64231     0.505657    -0.642191    -0.00764118   0.0201408   -0.0592174  -0.141354
  0.302661    0.605518     0.472474   -0.203262    -0.0089108   0.134492     1.00793      0.585098     -0.244829     0.267064   -0.00863014   0.0753537    0.0517549   0.263885    -0.0830095   0.472443    0.166224    0.260985     0.289454    0.455909   -0.148862    -0.200957    -0.346259     0.69552     -0.547423   -0.0764881
 -0.518033    0.257842    -0.0577394   0.213384     0.549666   -0.158524     0.240249    -0.116052     -0.429311    -0.0137937   0.629581     0.0276173    0.204154   -0.224254     0.273595    0.602767    0.126872   -0.400421     0.0583845  -0.635767    0.158239     0.362797    -0.258952    -0.562333    -0.368458   -0.0671534[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405844
[ Info: iteration 2, average log likelihood -1.405834
[ Info: iteration 3, average log likelihood -1.405824
[ Info: iteration 4, average log likelihood -1.405814
[ Info: iteration 5, average log likelihood -1.405805
[ Info: iteration 6, average log likelihood -1.405796
[ Info: iteration 7, average log likelihood -1.405787
[ Info: iteration 8, average log likelihood -1.405778
[ Info: iteration 9, average log likelihood -1.405770
[ Info: iteration 10, average log likelihood -1.405762
┌ Info: EM with 100000 data points 10 iterations avll -1.405762
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
