Julia Version 1.5.0-DEV.199
Commit cc47f87314 (2020-01-29 16:52 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenBLAS_jll ─────── v0.3.7+5
 Installed CMake ────────────── v1.1.2
 Installed HDF5 ─────────────── v0.12.5
 Installed BinDeps ──────────── v1.0.0
 Installed Parameters ───────── v0.12.0
 Installed StaticArrays ─────── v0.12.1
 Installed StatsBase ────────── v0.32.0
 Installed OrderedCollections ─ v1.1.0
 Installed LegacyStrings ────── v0.4.1
 Installed PDMats ───────────── v0.9.11
 Installed QuadGK ───────────── v2.3.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed JLD ──────────────── v0.9.2
 Installed Blosc ────────────── v0.5.1
 Installed BinaryProvider ───── v0.5.8
 Installed DataAPI ──────────── v1.1.0
 Installed URIParser ────────── v0.4.0
 Installed Distances ────────── v0.8.2
 Installed Missings ─────────── v0.4.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed SortingAlgorithms ── v0.3.1
 Installed NearestNeighbors ─── v0.4.4
 Installed CMakeWrapper ─────── v0.2.3
 Installed StatsFuns ────────── v0.9.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Rmath ────────────── v0.6.0
 Installed Compat ───────────── v2.2.0
 Installed Clustering ───────── v0.13.3
 Installed SpecialFunctions ─── v0.9.0
 Installed Arpack ───────────── v0.4.0
 Installed Distributions ────── v0.22.4
 Installed FileIO ───────────── v1.2.1
 Installed FillArrays ───────── v0.8.4
 Installed DataStructures ───── v0.17.9
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_XrBQM4/Project.toml`
 [no changes]
  Updating `/tmp/jl_XrBQM4/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_UMDFfN/Project.toml`
 [no changes]
  Updating `/tmp/jl_UMDFfN/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_FN3HOy/Project.toml`
 [no changes]
  Updating `/tmp/jl_FN3HOy/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_aU6HIG/Project.toml`
 [no changes]
  Updating `/tmp/jl_aU6HIG/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_Nvn8t9/Project.toml`
 [no changes]
  Updating `/tmp/jl_Nvn8t9/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_Nvn8t9/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.2
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.7361322303267457e7, [30483.03936221527, 69516.96063778472], [-19546.96405464468 -13051.484139460092 -8112.489656301474; 19398.31985000526 13017.75609822171 8490.731186081506], [[53686.48958539632 15987.187589213705 4598.857323428152; 15987.187589213705 41678.916129115714 2803.2003350043415; 4598.857323428152 2803.200335004342 31883.830705495253], [46231.75307999468 -15448.845406997589 -4531.406301116252; -15448.845406997589 58973.97697620859 -2429.8809390404585; -4531.406301116252 -2429.8809390404585 68563.90744528006]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.636532e+03
      1       1.048294e+03      -5.882377e+02 |        5
      2       1.027362e+03      -2.093215e+01 |        0
      3       1.027362e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 1027.361766129659)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.071552
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.690847
[ Info: iteration 2, lowerbound -3.537060
[ Info: iteration 3, lowerbound -3.384741
[ Info: iteration 4, lowerbound -3.227588
[ Info: iteration 5, lowerbound -3.081272
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.960614
[ Info: iteration 7, lowerbound -2.872690
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.801018
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.735953
[ Info: iteration 10, lowerbound -2.685945
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.629965
[ Info: iteration 12, lowerbound -2.561713
[ Info: iteration 13, lowerbound -2.493118
[ Info: iteration 14, lowerbound -2.431577
[ Info: iteration 15, lowerbound -2.383074
[ Info: iteration 16, lowerbound -2.346944
[ Info: iteration 17, lowerbound -2.321561
[ Info: iteration 18, lowerbound -2.308613
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.303146
[ Info: iteration 20, lowerbound -2.299264
[ Info: iteration 21, lowerbound -2.299258
[ Info: iteration 22, lowerbound -2.299255
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan 31 05:13:52 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan 31 05:14:00 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Fri Jan 31 05:14:02 2020: EM with 272 data points 0 iterations avll -2.071552
5.8 data points per parameter
, Fri Jan 31 05:14:04 2020: GMM converted to Variational GMM
, Fri Jan 31 05:14:12 2020: iteration 1, lowerbound -3.690847
, Fri Jan 31 05:14:12 2020: iteration 2, lowerbound -3.537060
, Fri Jan 31 05:14:12 2020: iteration 3, lowerbound -3.384741
, Fri Jan 31 05:14:12 2020: iteration 4, lowerbound -3.227588
, Fri Jan 31 05:14:12 2020: iteration 5, lowerbound -3.081272
, Fri Jan 31 05:14:13 2020: dropping number of Gaussions to 7
, Fri Jan 31 05:14:13 2020: iteration 6, lowerbound -2.960614
, Fri Jan 31 05:14:13 2020: iteration 7, lowerbound -2.872690
, Fri Jan 31 05:14:13 2020: dropping number of Gaussions to 5
, Fri Jan 31 05:14:13 2020: iteration 8, lowerbound -2.801018
, Fri Jan 31 05:14:13 2020: dropping number of Gaussions to 4
, Fri Jan 31 05:14:13 2020: iteration 9, lowerbound -2.735953
, Fri Jan 31 05:14:13 2020: iteration 10, lowerbound -2.685945
, Fri Jan 31 05:14:13 2020: dropping number of Gaussions to 3
, Fri Jan 31 05:14:13 2020: iteration 11, lowerbound -2.629965
, Fri Jan 31 05:14:13 2020: iteration 12, lowerbound -2.561713
, Fri Jan 31 05:14:13 2020: iteration 13, lowerbound -2.493118
, Fri Jan 31 05:14:13 2020: iteration 14, lowerbound -2.431577
, Fri Jan 31 05:14:13 2020: iteration 15, lowerbound -2.383074
, Fri Jan 31 05:14:13 2020: iteration 16, lowerbound -2.346944
, Fri Jan 31 05:14:13 2020: iteration 17, lowerbound -2.321561
, Fri Jan 31 05:14:13 2020: iteration 18, lowerbound -2.308613
, Fri Jan 31 05:14:13 2020: dropping number of Gaussions to 2
, Fri Jan 31 05:14:13 2020: iteration 19, lowerbound -2.303146
, Fri Jan 31 05:14:13 2020: iteration 20, lowerbound -2.299264
, Fri Jan 31 05:14:13 2020: iteration 21, lowerbound -2.299258
, Fri Jan 31 05:14:13 2020: iteration 22, lowerbound -2.299255
, Fri Jan 31 05:14:13 2020: iteration 23, lowerbound -2.299254
, Fri Jan 31 05:14:13 2020: iteration 24, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 25, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 26, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 27, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 28, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 29, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 30, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 31, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 32, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 33, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 34, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 35, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 36, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 37, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 38, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 39, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 40, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 41, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 42, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 43, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 44, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 45, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 46, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 47, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 48, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 49, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: iteration 50, lowerbound -2.299253
, Fri Jan 31 05:14:13 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398581, 178.04509222601416]
β = [95.95490777398581, 178.04509222601416]
m = [2.0002292577753678 53.851987172461264; 4.250300733269907 79.28686694436182]
ν = [97.95490777398581, 180.04509222601416]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948468 -0.00895312382734594; 0.0 0.012748664777409218], [0.18404155547484874 -0.007644049042327724; 0.0 0.008581705166333508]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000004
avll from stats: -1.0023874895444889
avll from llpg:  -1.0023874895444882
avll direct:     -1.0023874895444882
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.9805121027194762
avll from llpg:  -0.9805121027194762
avll direct:     -0.9805121027194763
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.00841874   0.0501703    -0.149326    -0.0258248     0.0288389    0.0967902   -0.0827507    0.084761     0.116218     0.10979     -0.0579484   -0.0668675   -0.00254606  -0.144031      0.144432    -0.144872    -0.0340567   -0.0647541    0.0476636   0.20955      0.120441     0.131368     0.161098     -0.0625002     0.0112709   0.0334917
 -0.0511322   -0.088605      0.0153876   -0.0294404    -0.0509005   -0.0453644    0.0162745    0.242712     0.0147233   -0.0368948   -0.0461299    0.130633     0.124861     0.0239922     0.115229     0.136158    -0.108011     0.040276     0.129699    0.241948     0.0901431   -0.0426093    0.0224734     0.033358     -0.0500971   0.0812531
 -0.165629     0.166966     -0.18543      0.147332     -0.00338561  -0.0412627   -0.0739363    0.0101094   -0.0559495    0.0905329    0.212143    -0.0185143   -0.0577796   -0.0865531     0.133834     0.0609757   -0.0223834    0.00176974  -0.0102188   0.0858031   -0.0257551   -0.0611793   -0.256156      0.0160607    -0.12584    -0.129337
  0.164529     0.149664     -0.0496462   -0.0242732    -0.0792135    0.194851     0.0447806    0.0742553    0.00895382  -0.0756525    0.00543497  -0.14136      0.0690815   -0.0122748     0.00757272  -0.0827726    0.048044    -0.00372308   0.0813003   0.124692     0.00529956   0.0844763   -0.098785     -0.0738629    -0.0224001   0.0381167
 -0.0119578   -0.0379747     0.00378607   0.043012      0.102443    -0.00175611   0.0543288   -0.0610333   -0.218811     0.0636596   -0.0373875    0.0954724   -0.0839694    0.0762915    -0.0856005    0.0552049    0.0202076    0.0899667   -0.0170825  -0.108761    -0.0784005   -0.0850933    0.056329     -0.114711     -0.0277029   0.0523435
 -0.0186011   -0.0217577     0.20234     -0.042594     -0.147278    -0.118578    -0.0372683    0.0850435   -0.0363359    0.14169     -0.162072     0.103601    -0.0571673   -0.0991555    -0.0212949   -0.0705675    0.122304    -0.099486    -0.0116823  -0.020677    -0.0492251    0.0562476    0.040444     -0.0165132    -0.0217945  -0.0335744
  0.0571633   -0.0498519    -0.101783     0.000524382   0.0841633   -0.0362543    0.0522663   -0.124441     0.100099    -0.0889956   -0.138865    -0.00547648  -0.00154425   0.118913      0.0874454   -0.139965     0.12817      0.139001     0.221994   -0.0612398   -0.0460387   -0.0267614    0.0167619     0.0206212     0.0543003  -0.179982
  0.00152571   0.0658618     0.0410764   -0.119706     -0.18241      0.105169    -0.0340231    0.14738      0.21175      0.0654935   -0.00999596  -0.143219    -0.0575396   -0.0807324     0.0457261   -0.0146707   -0.190987     0.0742803    0.0336104  -0.0528065    0.0324982    0.112548     0.0548784     0.00490256    0.0111154   0.0794037
  0.0589671   -0.0974136    -0.0160597    0.0229592     0.0973143    0.0397864   -0.0663013   -0.1541       0.00602584  -0.132558     0.103184    -0.0516172   -0.0598225   -0.0573308    -0.113622    -0.238937     0.0238581   -0.00334752   0.0359593  -0.00818378  -0.133389    -0.0732226    0.0828894    -0.192617     -0.125434    0.121242
  0.0407696   -0.0180186     0.0661912    0.0980137    -0.109426    -0.0915673   -0.027828    -0.0424757    0.0260141    0.167476     0.202691    -0.0431909   -0.0351468    0.0283567    -0.105492     0.0986681   -0.0145444    0.0852853   -0.132056    0.0503469   -0.0190093   -0.218009    -0.169259      0.00970946   -0.0411133  -0.0362321
 -0.0343618   -0.00204681    0.0102574    0.0201112    -0.0303578   -0.0274662   -0.0414755   -0.0598895   -0.113787     0.106802     0.00751083  -0.0198872    0.171476    -0.0645707    -0.0203848   -0.119525     0.0983587    0.0369815    0.101677   -0.177866    -0.0892616    0.0641213    0.0742711    -0.100832      0.0711054  -0.0292374
  0.0405057   -0.0419493    -0.100134    -0.0178935     0.132673    -0.0276153    0.0410589    0.0820759    0.0163258   -0.0374611    0.168802     0.12065     -0.01743      0.0929377    -0.00031639   0.00988965  -0.10364     -0.11272      0.0814421  -0.102378    -0.0333382    0.00730025   0.074934     -0.0193827     0.118408    0.0959326
  0.00745338  -0.0104864    -0.0471958    0.20091       0.108852    -0.122232     0.0286954    0.00334195   0.00989879   0.0719303   -0.105997     0.0135489   -0.0486852    0.112147      0.154131     0.0523474    0.0128506   -0.0843401    0.0927654  -0.0130818   -0.0193353    0.164013    -0.083108      0.000345676   0.196299   -0.0864332
 -0.0354321    0.0827346    -0.151532     0.126783     -0.0835787    0.137343    -0.0161452    0.101219    -0.0168255   -0.0589012    0.106707    -0.182946     0.0435637   -0.0262439    -0.0780385    0.128007     0.143897     0.0733535    0.0635539   0.0497313    0.15638     -0.0718263   -0.014531     -0.0802115     0.0844883   0.0912536
  0.0780526   -0.0732307     0.0487767   -0.0059581    -0.0740779   -0.0762833   -0.0408427    0.00663683   0.0537189    0.00936439   0.0036374    0.0552707   -0.0657591   -0.147991      0.238779     0.0478797    0.0510434    0.0946372    0.0796702  -0.0529406    0.0355829    0.0185196   -0.0918273    -0.0773116     0.167214    0.0454747
  0.0752114    0.0668212     0.191146    -0.126816      0.00667819   0.0951903   -0.0429159    0.100164    -0.15888     -0.050429     0.0462468   -0.0159788   -0.185521    -0.0824375    -0.0964679   -0.0653709   -0.0636536   -0.109127    -0.0808005  -0.0352438   -0.197227     0.0702294   -0.022819     -0.00760688    0.123302    0.0289339
  0.142387     0.176165     -0.061946     0.0449063     0.00843939  -0.068558    -0.00477161   0.144193     0.153897    -0.0110025   -0.0585544   -0.142521    -0.0864326   -0.222357     -0.00745694  -0.177433    -0.110515     0.135741    -0.108674    0.0689382   -0.147915    -0.0845551    0.0320482    -0.0188954     0.0649632  -0.0341724
 -0.0139543   -0.0169767     0.0095394    0.176758      0.0366051    0.209354     0.174906     0.0604863    0.0967275    0.0850129   -0.153015     0.00220474   0.0959524    0.0334961    -0.149573    -0.00306775   0.059133     0.0269502    0.0781983   0.0894653    0.0491383    0.045096    -0.00593187   -0.0396905    -0.0177125   0.00242909
 -0.0655159   -0.0155935     0.119457     0.0809163    -0.112536     0.0817087   -0.148975    -0.0368386   -0.0132878    0.111837     0.0160483    0.0204456   -0.010308     0.00101628   -0.0634421    0.140184     0.0940362   -0.01801     -0.0302633   0.167601    -0.347896     0.201153     0.115032      0.0878785    -0.120018   -0.1305
  0.0106523   -0.0366472     0.0702832    0.0808469    -0.136455     0.0245034   -0.0352353   -0.158125     0.159762     0.104063    -0.0707652   -0.102891    -0.0355075   -0.0715672     0.0794242   -0.0325105   -0.0193725    0.087749     0.0772298  -0.169306    -0.1144       0.0762201    0.0279735     0.0292696    -0.067115    0.123347
  0.125256    -0.130861     -0.123186    -0.0437059    -0.0608786    0.0302365    0.0495314    0.185459    -0.0432352   -0.192376    -0.0179195    0.171888    -0.104466     0.0231784     0.012549    -0.217275     0.160583     0.157257     0.136743    0.077826     0.0169319    0.102362    -0.0329615     0.131511      0.0451376   0.139632
  0.299815    -0.06589      -0.00017734  -0.0289611     0.138511     0.230722    -0.00747801   0.110249     0.0472434   -0.0754093    0.0831782   -0.0720799    0.0016661   -0.210322      0.226215     0.101859    -0.16762      0.0331047   -0.0933227  -0.0775423   -0.0282562   -0.189571     0.0509166    -0.120265      0.155499    0.246218
  0.111588     0.00322329   -0.0105538    0.0215836    -0.0533739   -0.0265729    0.0285844    0.130999     0.10574     -0.00665353  -0.00252922   0.106215     0.0983485    0.00914697    0.0555502   -0.17961      0.0397243   -0.150765    -0.200089    0.0793285    0.0395091    0.0747363    0.028048      0.0407429    -0.0187949  -0.232735
 -0.151683     0.000171656   0.0162306   -0.0555718    -0.134792     0.106464    -0.0351294   -0.0931425   -0.21265     -0.0179564    0.027224     0.109606    -0.0351923    0.00190971   -0.151386    -0.0986325    0.0129233   -0.0446679    0.0629115  -0.235077    -0.0320792   -0.0227397    0.028635     -0.0980122     0.0683541  -0.0179696
 -0.0329513   -0.0149659     0.0149493    0.0359147     0.026975     0.051401    -0.0576989    0.064532    -0.065902    -0.0664153    0.0183873   -0.0140003    0.163079     0.122008      0.0774114   -0.00478846   0.0970259   -0.113763     0.0542176  -0.201017     0.149        0.0515279   -0.108323      0.213918     -0.0150311   0.00773397
  0.00984671   0.144111      0.0348341   -0.134767     -0.0306792    0.00453496   0.167307     0.0912775    0.00619902   0.112655     0.11921      0.00466197   0.0625439    0.105173     -0.0958368   -0.0834359   -0.0500996   -0.0618873    0.111548   -0.210609    -0.0582166   -0.137908     0.100199      0.0314599     0.0581785   0.0090162
 -0.00789747  -0.0691813     0.0362446   -0.210241      0.0221978   -0.0214627   -0.0221861   -0.0509909   -0.00632594  -0.0660917    0.081655    -0.0599936   -0.0429118    0.000514638   0.0891809   -0.0896396   -0.190386     0.175341     0.0521469   0.108335    -0.0670434    0.00526513   0.0912972     0.219902     -0.0159475   0.252641
  0.00568216   0.158484     -0.165536    -0.194179      0.0768886   -0.130709    -0.0416169   -0.120491    -0.127717     0.0579288   -0.0171425   -0.127403     0.143485    -0.164409     -0.0638876    0.104662     0.0862498    0.192596    -0.0105521  -0.0494834    0.124548    -0.0199388   -0.014115     -0.139653     -0.107681   -0.0117079
  0.0511441   -0.0123339     0.122564     0.117525      0.087402     0.0602355    0.0707961    0.052686    -0.0433825    0.150757     0.0037673    0.0793841    0.0229329    0.160468      0.0384816   -0.112146    -0.0487405    0.00380023  -0.0228253   0.135872     0.0859878   -0.0424845   -0.0712078    -0.0222052    -0.0804356   0.088165
 -0.277533    -0.108175     -0.0949934   -0.0168599     0.00783949  -0.0168653   -0.0785876   -0.0993826    0.0938992   -0.0618627    0.0964111    0.114248     0.0193074   -0.0249245    -0.0993956    0.13011      0.108217    -0.0691696   -0.0463989   0.174945     0.108755     0.183187    -0.155461      0.0944663     0.0285594   0.0107375
  0.0720803   -0.0376697     0.0349873   -0.189895      0.0182706    0.0511324    0.0473381    0.142235    -0.0406031   -0.180089     0.226237     0.354949     0.00583569  -0.056785      0.119224    -0.0243381   -0.00545129   0.085295    -0.13525    -0.0474791   -0.0782817   -0.0047102   -0.0627271    -0.00855478   -0.216795   -0.104225
 -0.090414     0.0605538    -0.121682     0.0165302    -0.0242864   -0.109341    -0.0320657    0.142259     0.0051868    0.185215    -0.0778011   -0.116091     0.0547409    0.173767      0.0138573    0.0111966   -0.167945    -0.0203136   -0.0363979  -0.088175     0.0252774   -0.100336     0.000599576  -0.0246863     0.192171   -0.00530622kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4260680118362474
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426133
[ Info: iteration 2, average log likelihood -1.426063
[ Info: iteration 3, average log likelihood -1.425360
[ Info: iteration 4, average log likelihood -1.418377
[ Info: iteration 5, average log likelihood -1.401755
[ Info: iteration 6, average log likelihood -1.393868
[ Info: iteration 7, average log likelihood -1.392346
[ Info: iteration 8, average log likelihood -1.391713
[ Info: iteration 9, average log likelihood -1.391340
[ Info: iteration 10, average log likelihood -1.391114
[ Info: iteration 11, average log likelihood -1.390977
[ Info: iteration 12, average log likelihood -1.390890
[ Info: iteration 13, average log likelihood -1.390832
[ Info: iteration 14, average log likelihood -1.390793
[ Info: iteration 15, average log likelihood -1.390766
[ Info: iteration 16, average log likelihood -1.390746
[ Info: iteration 17, average log likelihood -1.390732
[ Info: iteration 18, average log likelihood -1.390721
[ Info: iteration 19, average log likelihood -1.390713
[ Info: iteration 20, average log likelihood -1.390707
[ Info: iteration 21, average log likelihood -1.390703
[ Info: iteration 22, average log likelihood -1.390699
[ Info: iteration 23, average log likelihood -1.390696
[ Info: iteration 24, average log likelihood -1.390694
[ Info: iteration 25, average log likelihood -1.390692
[ Info: iteration 26, average log likelihood -1.390691
[ Info: iteration 27, average log likelihood -1.390689
[ Info: iteration 28, average log likelihood -1.390688
[ Info: iteration 29, average log likelihood -1.390687
[ Info: iteration 30, average log likelihood -1.390686
[ Info: iteration 31, average log likelihood -1.390685
[ Info: iteration 32, average log likelihood -1.390684
[ Info: iteration 33, average log likelihood -1.390684
[ Info: iteration 34, average log likelihood -1.390683
[ Info: iteration 35, average log likelihood -1.390682
[ Info: iteration 36, average log likelihood -1.390682
[ Info: iteration 37, average log likelihood -1.390681
[ Info: iteration 38, average log likelihood -1.390681
[ Info: iteration 39, average log likelihood -1.390680
[ Info: iteration 40, average log likelihood -1.390680
[ Info: iteration 41, average log likelihood -1.390680
[ Info: iteration 42, average log likelihood -1.390679
[ Info: iteration 43, average log likelihood -1.390679
[ Info: iteration 44, average log likelihood -1.390679
[ Info: iteration 45, average log likelihood -1.390678
[ Info: iteration 46, average log likelihood -1.390678
[ Info: iteration 47, average log likelihood -1.390678
[ Info: iteration 48, average log likelihood -1.390678
[ Info: iteration 49, average log likelihood -1.390678
[ Info: iteration 50, average log likelihood -1.390678
┌ Info: EM with 100000 data points 50 iterations avll -1.390678
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4261326163140469
│     -1.426063311171732
│      ⋮
└     -1.3906776716689444
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.390768
[ Info: iteration 2, average log likelihood -1.390660
[ Info: iteration 3, average log likelihood -1.390082
[ Info: iteration 4, average log likelihood -1.385306
[ Info: iteration 5, average log likelihood -1.372054
[ Info: iteration 6, average log likelihood -1.362265
[ Info: iteration 7, average log likelihood -1.357577
[ Info: iteration 8, average log likelihood -1.354560
[ Info: iteration 9, average log likelihood -1.352422
[ Info: iteration 10, average log likelihood -1.350892
[ Info: iteration 11, average log likelihood -1.349679
[ Info: iteration 12, average log likelihood -1.348642
[ Info: iteration 13, average log likelihood -1.347678
[ Info: iteration 14, average log likelihood -1.346744
[ Info: iteration 15, average log likelihood -1.345886
[ Info: iteration 16, average log likelihood -1.345125
[ Info: iteration 17, average log likelihood -1.344411
[ Info: iteration 18, average log likelihood -1.343719
[ Info: iteration 19, average log likelihood -1.343072
[ Info: iteration 20, average log likelihood -1.342503
[ Info: iteration 21, average log likelihood -1.342035
[ Info: iteration 22, average log likelihood -1.341657
[ Info: iteration 23, average log likelihood -1.341350
[ Info: iteration 24, average log likelihood -1.341094
[ Info: iteration 25, average log likelihood -1.340881
[ Info: iteration 26, average log likelihood -1.340703
[ Info: iteration 27, average log likelihood -1.340550
[ Info: iteration 28, average log likelihood -1.340419
[ Info: iteration 29, average log likelihood -1.340307
[ Info: iteration 30, average log likelihood -1.340207
[ Info: iteration 31, average log likelihood -1.340111
[ Info: iteration 32, average log likelihood -1.340013
[ Info: iteration 33, average log likelihood -1.339906
[ Info: iteration 34, average log likelihood -1.339787
[ Info: iteration 35, average log likelihood -1.339655
[ Info: iteration 36, average log likelihood -1.339505
[ Info: iteration 37, average log likelihood -1.339319
[ Info: iteration 38, average log likelihood -1.339061
[ Info: iteration 39, average log likelihood -1.338705
[ Info: iteration 40, average log likelihood -1.338171
[ Info: iteration 41, average log likelihood -1.337494
[ Info: iteration 42, average log likelihood -1.337006
[ Info: iteration 43, average log likelihood -1.336791
[ Info: iteration 44, average log likelihood -1.336723
[ Info: iteration 45, average log likelihood -1.336695
[ Info: iteration 46, average log likelihood -1.336677
[ Info: iteration 47, average log likelihood -1.336665
[ Info: iteration 48, average log likelihood -1.336656
[ Info: iteration 49, average log likelihood -1.336650
[ Info: iteration 50, average log likelihood -1.336646
┌ Info: EM with 100000 data points 50 iterations avll -1.336646
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3907675185445374
│     -1.3906604379116707
│      ⋮
└     -1.3366463171388885
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.336793
[ Info: iteration 2, average log likelihood -1.336586
[ Info: iteration 3, average log likelihood -1.334803
[ Info: iteration 4, average log likelihood -1.320817
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.300223
[ Info: iteration 6, average log likelihood -1.300599
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.287880
[ Info: iteration 8, average log likelihood -1.293524
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.283638
[ Info: iteration 10, average log likelihood -1.290745
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.281533
[ Info: iteration 12, average log likelihood -1.289037
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.280049
[ Info: iteration 14, average log likelihood -1.287872
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.279109
[ Info: iteration 16, average log likelihood -1.287099
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.278161
[ Info: iteration 18, average log likelihood -1.285874
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.276436
[ Info: iteration 20, average log likelihood -1.283798
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.273985
[ Info: iteration 22, average log likelihood -1.281249
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.271608
[ Info: iteration 24, average log likelihood -1.279559
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.270585
[ Info: iteration 26, average log likelihood -1.279121
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.270347
[ Info: iteration 28, average log likelihood -1.278964
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.270214
[ Info: iteration 30, average log likelihood -1.278851
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.270110
[ Info: iteration 32, average log likelihood -1.278759
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.270027
[ Info: iteration 34, average log likelihood -1.278680
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.269953
[ Info: iteration 36, average log likelihood -1.278604
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.269882
[ Info: iteration 38, average log likelihood -1.278534
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.269818
[ Info: iteration 40, average log likelihood -1.278473
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.269759
[ Info: iteration 42, average log likelihood -1.278414
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.269691
[ Info: iteration 44, average log likelihood -1.278332
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.269578
[ Info: iteration 46, average log likelihood -1.278177
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.269366
[ Info: iteration 48, average log likelihood -1.277902
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.269024
[ Info: iteration 50, average log likelihood -1.277487
┌ Info: EM with 100000 data points 50 iterations avll -1.277487
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3367930651663653
│     -1.336585664055053
│      ⋮
└     -1.277487496438329
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.268713
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.268163
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.265376
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.244928
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.216156
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.211227
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.200942
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.203563
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.195988
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.199833
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.193847
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.198857
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.193421
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.198596
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.193286
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.198495
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.193235
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.198452
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.193213
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.198432
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.193202
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.198421
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.193196
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.198415
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.193193
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.198412
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.193191
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.198410
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.193190
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.198408
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.193189
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.198407
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.193188
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.198406
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.193187
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.198406
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.193186
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.198405
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.193186
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.198405
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.193185
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.198405
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.193185
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.198405
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.193184
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.198405
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.193184
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.198404
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.193183
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.198404
┌ Info: EM with 100000 data points 50 iterations avll -1.198404
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.268712889729401
│     -1.2681627398021929
│      ⋮
└     -1.1984043590097135
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     13
│     14
│     15
│     16
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.193400
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     13
│     14
│     15
│     16
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.193047
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     13
│     14
│     15
│     16
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.190489
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     11
│     13
│     14
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.166509
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      9
│     10
│     13
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.123966
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.100895
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     13
│     14
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.094770
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.081715
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.093033
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.095014
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.083547
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.092846
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.095092
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.083756
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.085581
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.098298
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.085466
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.087554
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.090879
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.088675
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.089362
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.092842
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.081165
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.092563
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.094449
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.082952
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.084893
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.097621
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.084822
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.087020
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.090336
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.088123
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.088830
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.092504
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.080932
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.092105
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.094257
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.083022
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.084779
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.097524
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.084829
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.086365
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.086892
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.080535
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.080239
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.083929
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.079654
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.080317
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.084197
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     21
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.072618
┌ Info: EM with 100000 data points 50 iterations avll -1.072618
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.193400129617384
│     -1.1930465918123159
│      ⋮
└     -1.0726180671311583
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4260680118362474
│     -1.4261326163140469
│     -1.426063311171732
│     -1.42535972693465
│      ⋮
│     -1.080316537735983
│     -1.084197116620402
└     -1.0726180671311583
32×26 Array{Float64,2}:
  0.0367481    -0.0698492    0.0399209    0.0421433   -0.00572173   0.0334731   -0.0609206   -0.157074     0.0941042   -0.0158141    0.0337744   -0.101431    -0.0622523    -0.0582529  -0.0171951   -0.131179     0.00688413   0.0491843    0.0729603   -0.0518517   -0.114419    -0.0117763    0.0559045    -0.0641625   -0.108359     0.137509
  0.00167767   -0.0170007    0.00658809   0.184603     0.0805784   -0.121233     0.00829591   0.00605163   0.0157887    0.0641643   -0.128213     0.0156087   -0.0465766     0.115238    0.163298     0.0519345    0.00794851  -0.0946685    0.0906876    0.0735052   -0.0383449    0.167216    -0.0665372    -0.0585283    0.169616    -0.0671361
 -0.0906318     0.0511752   -0.0216411    0.0949749   -0.0508813    0.0218377   -0.107479    -0.0274899   -0.0100659    0.0903648    0.105408     0.00605245  -0.0344243    -0.011122    0.0324085    0.0891128    0.0327062    0.00576514   0.0129371    0.120247    -0.182566     0.0777919   -0.0567445     0.0389297   -0.120962    -0.0907936
 -0.129859     -0.0585504   -0.0368628    0.022787     0.0209023    0.0162771   -0.0559023   -0.0114576    0.0138849   -0.0676259    0.0392574    0.0511082    0.100456      0.0455728  -0.0100807    0.0393264    0.106845    -0.099098    -0.0538863   -0.0129748    0.114042     0.11111     -0.135385      0.133435    -0.00247364  -0.00401884
 -5.50338e-5    0.0578717    0.0379545   -0.128965    -0.205157     0.0989749   -0.0257541    0.126141     0.178284     0.0454772    0.0265039   -0.122454    -0.0705527    -0.0672741   0.0528204   -0.0364308   -0.197845     0.069514     0.0258473   -0.0526302    0.0142812    0.0986585    0.0659219     0.0144932    0.00224788   0.0800098
  0.346957     -0.0646122    0.00171986  -0.0425707    0.141024     0.222856    -0.0250543    0.144277     0.0573926   -0.0994503    0.0595227   -0.079682     0.000257162  -0.209681    0.201469     0.112693    -0.161712     0.0571179   -0.0841782   -0.0708572   -0.0272957   -0.186909     0.0547932    -0.11541      0.192213     0.249957
 -0.010022     -0.0380703    0.0703186   -0.0293022    0.0800301   -0.0127829    0.0123562   -0.0848063   -0.193101     0.00790036  -0.0137684    0.0788487   -0.0709107     0.0646715  -0.0528927   -0.0631455   -0.0244684    0.125129    -0.00510835  -0.0686131   -0.0428967   -0.055747     0.0646968    -0.0378908   -0.0144013    0.0952353
  0.0431119    -0.0162481    0.108998     0.12156      0.083455     0.0534867    0.0687341    0.0282466   -0.049828     0.1398       0.0123669    0.11564      0.0159029     0.153095    0.0486162   -0.103339    -0.0537021    0.00454267  -0.0224378    0.136072     0.0860917    0.00160003  -0.0347327    -0.0331199   -0.0766765    0.0627005
 -0.103548      0.277727    -0.190471    -0.177208     0.0516103   -0.198962    -0.177163    -0.138262    -0.199495     0.108303    -1.6451      -0.127002     0.109689     -0.265513   -0.0790247    0.0845683    0.171445     0.275922    -0.0553787   -0.0485499   -0.0311069    0.10578     -0.063911     -0.148639    -0.149589     0.0532732
  0.107254      0.135706    -0.225863    -0.194407     0.106017    -0.186784    -0.111       -0.0834163    0.039377     0.13601      0.0950501   -0.179018     0.17368      -0.0762993  -0.0479318    0.0835992   -0.163834     0.248537     0.0185239   -0.0506215   -0.0408072    0.0123949    0.0151873    -0.133331    -0.291245     0.201681
 -0.0789531     0.00646296  -0.208343    -0.185183     0.0105082   -0.0886044    0.0917919   -0.110488    -0.123831     0.025746    -0.134658    -0.0931567    0.134537     -0.196333   -0.0935947    0.127385     0.188241     0.0991788    0.0567179   -0.0446724    0.38562     -0.1041       0.0182844    -0.136494     0.0736391   -0.211011
 -0.0588446     0.211877    -0.0933739   -0.208208     0.0883575   -0.0425837   -0.0300115   -0.166109    -0.30273     -0.0277509    1.67589     -0.0859429    0.152788     -0.0965806  -0.014016     0.116064     0.197665     0.216357    -0.0787921   -0.0537767    0.0814303   -0.0563751   -0.0306556    -0.144554     0.0759051    0.0202151
  0.00975904    0.113584     0.351795    -0.146286     0.0266652    0.263991     0.0781109    0.141762    -0.287549    -0.18161      0.281162    -0.294932     0.00566096   -0.0596878   0.119064    -0.107474     0.471021     0.00263381  -0.278891    -0.080638    -0.408656     0.0374082   -0.031145     -0.0106116   -0.216539    -0.0758406
  0.153395     -0.161721    -0.369229    -0.224049     0.0484384    0.0687279    0.0312424    0.142763    -0.280515    -0.186333     0.29626      0.635514     0.00577653   -0.0559741   0.119871    -0.0550546   -0.536039     0.231122    -0.52725     -0.0546701   -0.421262     0.00751262  -0.0327487    -0.0147606   -0.21475     -0.0905712
  0.0639451     0.0417121    0.0293756   -0.207288    -0.0377784    0.122905     0.0523925    0.143267     0.121503    -0.181263     0.12022      0.27551      0.00597647   -0.050462    0.120212     0.0308848    0.0550898    0.198373     0.0373278   -0.00469461   0.168235    -0.0472466   -0.0760926    -0.00610438  -0.213251    -0.0973393
  0.0653222    -0.104992     0.107357    -0.174261     0.0384117   -0.140114     0.0346839    0.142904     0.184338    -0.179666     0.186312     0.994576     0.00607052   -0.0510125   0.119592     0.0209053    0.0931441   -0.0446016    0.122528    -0.0731565    0.128679    -0.0160523   -0.10125      -0.00363685  -0.213054    -0.171846
  0.0578439    -0.0355026   -0.0981518   -0.00578849   0.0840425   -0.0269802    0.0642777   -0.245758     0.0994613   -0.10594     -0.113659    -0.00373964  -0.000719405   0.133063    0.0708631   -0.147622     0.125839     0.133007     0.220254    -0.0623811   -0.073925    -0.041447     0.000542443   0.0223086    0.04425     -0.16932
  0.167429      0.158882    -0.014407    -0.0253292   -0.0793303    0.19699      0.0349879    0.035549     0.0120877   -0.0750579   -0.0158651   -0.139377     0.058493      0.0274114  -0.0149149   -0.0567594    0.0454171    0.00198883   0.0803821    0.100325    -0.00853438   0.0844704   -0.0958672    -0.104698    -0.0194349    0.0370246
  0.000547476  -0.0104094    0.0311817    0.0545307   -0.0372721   -0.0695057   -0.0366073   -0.0475888   -0.0487495    0.145607     0.0926982   -0.028767     0.0701607    -0.0247012  -0.0625753   -0.0116744    0.050123     0.0579644   -0.0357208   -0.0653735   -0.0524493   -0.0993758   -0.0360566    -0.0382448    0.0254693   -0.0186391
 -0.0181744    -0.0230701    0.175845    -0.0451941   -0.150471    -0.0987165   -0.0331484    0.0700471    0.00848396   0.148612    -0.154337     0.110557    -0.0657805    -0.0981829  -0.0307326   -0.0711117    0.145055    -0.100801    -0.0097095   -0.0279185   -0.0572688   -0.00538361   0.0335183    -0.0181198   -0.0242877   -0.0331737
 -0.123349     -0.0779272    0.0535498   -0.045982     0.0197774   -0.648346    -0.0585693   -0.916436    -0.245351    -0.0176528    0.00485419   0.0936311   -0.0227328     0.197522    0.00233894  -0.102872     0.0111197   -0.0849431    0.0256729   -0.23581     -0.0317247   -0.0326532    0.115369     -0.0980016   -0.0133177   -0.0543118
 -0.1633        0.0536541   -0.00360563  -0.0529696   -0.214924     0.848419    -0.00120221   0.820243    -0.174733    -0.0176563   -0.0112411    0.120508    -0.0551253    -0.0848446  -0.280812    -0.0899375    0.0111216    0.0261265    0.0938909   -0.234753    -0.0291574   -0.0433368   -0.0646145    -0.10765      0.101847     0.0317827
  0.00163297    0.0235038   -0.115718    -0.0440576    0.0326872    0.0969646   -0.0254871    0.0776757    0.109503     0.109964    -0.0338475   -0.0840667   -0.00867006   -0.122627    0.143708    -0.134412    -0.0674987   -0.0226203    0.097182     0.194502     0.092789     0.110282     0.12335      -0.0344782   -0.0279284    0.054831
  0.0695589    -0.0784279    0.0550246    0.00162055  -0.10138     -0.0762801   -0.0359626    0.00900502   0.0665694    0.0112828    0.00113427   0.0739437   -0.0625643    -0.147137    0.195612     0.0440255    0.0641661    0.0868098    0.0755079   -0.0482522    0.0196341    0.0354995   -0.0897455    -0.0829188    0.161673     0.0275555
  0.0173566     0.169005     0.0341909   -0.135834    -0.0273028    0.00245262   0.163281     0.0884051    0.0208293    0.120676     0.121085     0.0177784    0.0538191     0.116526   -0.0780818   -0.0865006   -0.0637045   -0.0611141    0.0918243   -0.199859    -0.0663806   -0.204171     0.0840016     0.0416643    0.0567763    0.0087768
  0.0978784     0.191125    -0.0506563    0.0382709   -0.00847067  -0.078708     0.00447822   0.15057      0.15004     -0.0109792   -0.0570375   -0.142091    -0.0736146    -0.209255   -0.00258484  -0.184506    -0.111185     0.141885    -0.100389     0.0725019   -0.147969    -0.0847999    0.010109     -0.0243838    0.0681407   -0.033033
  0.0440112    -0.0278344   -0.0560592   -0.00599645   0.0291133    0.0325363    0.0409823    0.103183     0.0679929   -0.0292599    0.0849934    0.117492     0.0134368     0.064305    0.0230816   -0.0811281   -0.0374888   -0.126525    -0.0323682   -0.0135039   -0.00233326   0.0504591    0.0588514    -0.013262     0.0432292   -0.0454124
 -0.0306058     0.0669214   -0.0714008    0.155298    -0.00601945   0.179234     0.0686432    0.0801346    0.0268419    0.024329    -0.0147648   -0.0977862    0.0682625    -0.0174546  -0.108512     0.0726137    0.113779     0.0496314    0.0781174    0.0433907    0.114017    -0.0417591   -0.0175009    -0.0467282    0.0379242    0.0447973
 -0.0490376    -0.0816618    0.0167357   -0.0147041   -0.0435305   -0.0449245    0.0184986    0.23243      0.042041    -0.0368429   -0.0411669    0.13423      0.13658       0.0136347   0.100481     0.139711    -0.115831     0.0382993    0.127522     0.241093     0.0865867   -0.0715003    0.0227505     0.0359319   -0.0500061    0.0695643
 -0.092029      0.0499486   -0.114846     0.0538748   -0.0249835   -0.111968    -0.0292753    0.162955     0.0124098    0.173083    -0.0915809   -0.104291     0.0344086     0.176498    0.0078298   -0.00279956  -0.16979     -0.0205856    0.0252245   -0.173952     0.0209646   -0.0700892    0.0105252    -0.0134012    0.187191    -0.00415129
  0.0778005     0.0704905    0.194218    -0.121655     0.0070154    0.0952399   -0.0364182    0.0667747   -0.166003    -0.0346309    0.0482336   -0.0250173   -0.185334     -0.0657141  -0.0958205   -0.0547068   -0.0463256   -0.0996751   -0.0893433   -0.0259      -0.196125     0.10004     -0.0176838    -0.010038     0.149702     0.0301746
  0.131489     -0.124361    -0.108466    -0.0306748   -0.0587766    0.0296331    0.066351     0.147343    -0.0258427   -0.204082    -0.0107838    0.147749    -0.110805      0.0145279  -0.00528354  -0.29112      0.158631     0.165372     0.114919     0.150084     0.0162425    0.172885    -0.000786208   0.132211     0.0443906    0.142987[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.075640
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.072194
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.070209
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.075559
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.072263
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.070369
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.068184
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.075536
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.072043
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.069988
┌ Info: EM with 100000 data points 10 iterations avll -1.069988
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.555009e+05
      1       7.000127e+05      -2.554882e+05 |       32
      2       6.736060e+05      -2.640675e+04 |       32
      3       6.553849e+05      -1.822107e+04 |       32
      4       6.447569e+05      -1.062805e+04 |       32
      5       6.393346e+05      -5.422232e+03 |       32
      6       6.364808e+05      -2.853799e+03 |       32
      7       6.346935e+05      -1.787335e+03 |       32
      8       6.333998e+05      -1.293660e+03 |       32
      9       6.322524e+05      -1.147474e+03 |       32
     10       6.311703e+05      -1.082098e+03 |       32
     11       6.301031e+05      -1.067186e+03 |       32
     12       6.291798e+05      -9.232346e+02 |       32
     13       6.284703e+05      -7.094998e+02 |       32
     14       6.278697e+05      -6.006545e+02 |       32
     15       6.272579e+05      -6.117930e+02 |       32
     16       6.264917e+05      -7.662150e+02 |       32
     17       6.259221e+05      -5.695336e+02 |       32
     18       6.255788e+05      -3.433571e+02 |       32
     19       6.252752e+05      -3.035662e+02 |       32
     20       6.249928e+05      -2.824441e+02 |       32
     21       6.247193e+05      -2.735024e+02 |       32
     22       6.244663e+05      -2.529474e+02 |       32
     23       6.242366e+05      -2.297144e+02 |       32
     24       6.240761e+05      -1.604679e+02 |       32
     25       6.239523e+05      -1.238712e+02 |       32
     26       6.238651e+05      -8.713965e+01 |       32
     27       6.238239e+05      -4.122531e+01 |       32
     28       6.237988e+05      -2.511635e+01 |       32
     29       6.237809e+05      -1.788414e+01 |       31
     30       6.237706e+05      -1.026345e+01 |       32
     31       6.237620e+05      -8.656373e+00 |       32
     32       6.237513e+05      -1.068044e+01 |       31
     33       6.237444e+05      -6.901260e+00 |       28
     34       6.237386e+05      -5.766626e+00 |       29
     35       6.237307e+05      -7.899020e+00 |       26
     36       6.237239e+05      -6.824940e+00 |       27
     37       6.237186e+05      -5.277382e+00 |       25
     38       6.237125e+05      -6.138972e+00 |       28
     39       6.237060e+05      -6.524441e+00 |       30
     40       6.236954e+05      -1.061125e+01 |       29
     41       6.236827e+05      -1.266821e+01 |       29
     42       6.236716e+05      -1.107582e+01 |       28
     43       6.236610e+05      -1.057325e+01 |       26
     44       6.236526e+05      -8.419768e+00 |       31
     45       6.236447e+05      -7.912235e+00 |       29
     46       6.236367e+05      -8.021070e+00 |       28
     47       6.236302e+05      -6.458170e+00 |       28
     48       6.236196e+05      -1.060753e+01 |       25
     49       6.236093e+05      -1.032154e+01 |       28
     50       6.235970e+05      -1.229650e+01 |       29
K-means terminated without convergence after 50 iterations (objv = 623597.0060882573)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.336443
[ Info: iteration 2, average log likelihood -1.306411
[ Info: iteration 3, average log likelihood -1.274146
[ Info: iteration 4, average log likelihood -1.229760
[ Info: iteration 5, average log likelihood -1.179724
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.120304
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.094313
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     13
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.057338
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.067547
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.040224
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│     10
│     13
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.037752
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.061164
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     20
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.032689
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.056024
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.058021
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.036399
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│     10
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.039673
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.071185
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.037132
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     10
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.040444
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.051625
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.033703
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.042188
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│     13
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.039762
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.042268
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.053416
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.048524
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     19
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.026071
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.051531
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     13
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.051048
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.034450
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      6
│     10
│     19
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.025764
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.085416
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.029490
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     10
│     13
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.032055
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.074512
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.043358
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     10
│     20
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.034333
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.071140
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     13
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.031122
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│     10
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.045676
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.076336
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.046730
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      7
│     10
│     13
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.030351
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.062874
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.052813
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.044437
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│      7
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.045234
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     19
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.030713
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.066766
┌ Info: EM with 100000 data points 50 iterations avll -1.066766
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.091918      0.0477005    -0.115885     0.050688    -0.0254931   -0.110937    -0.0300955    0.164196     0.0114065    0.172984   -0.0969458   -0.102561     0.0308726     0.176288     0.00853171   -0.0017347  -0.172165    -0.0217782    0.0272031   -0.179953    0.0240855   -0.0707633    0.0104522   -0.010168     0.187529    -0.00499894
  0.140402      0.00322673    0.0230192   -0.00239223   0.00596644   0.0625702   -0.0295663    0.0854325   -0.178296    -0.052545   -0.00125068  -0.042922     0.345012      0.0671593    0.0660735    -0.0390499   0.059007    -0.200944    -0.109812    -0.0162257   0.126343     0.0697174   -0.0846234    0.38631      0.00731265  -0.0827034
  0.0513706    -0.0214088    -0.106403    -0.0193496    0.0942592    0.0746221    0.0413331    0.0819906    0.011204    -0.0399246   0.170469     0.119543    -0.068646      0.101012     0.000307147   0.0177489  -0.102801    -0.103387     0.141917    -0.107654   -0.0398624    0.0184138    0.074794    -0.0189904    0.116464     0.104482
 -0.0339852    -0.000446604   0.00892127   0.161492     0.0466549    0.194091     0.15819      0.0634392    0.092129     0.0833179  -0.132252     0.00987703   0.0947296     0.0312767   -0.134011     -0.0212397   0.0789911    0.0322004    0.0631808    0.052638    0.0674965    0.0333356   -0.00808392  -0.0390122   -0.0250578   -0.00743485
  0.00169212   -0.010945      0.0325282    0.0546361   -0.0354894   -0.0684437   -0.0370519   -0.0446129   -0.0462261    0.144476    0.10016     -0.0286165    0.0695091    -0.0217202   -0.0651863    -0.0126844   0.0492851    0.0587213   -0.0424686   -0.0619378  -0.0516398   -0.102281    -0.0346748   -0.0384637    0.0231382   -0.0183625
 -0.0847805    -0.0265575     0.143652     0.0822642   -0.109889     0.0956051   -0.176724    -0.0430696   -0.00812054   0.1025      0.0155212    0.0390052   -0.0101342     0.0501272   -0.07888       0.157766    0.109359    -0.0137838   -0.0306009    0.159937   -0.354316     0.194167     0.0759911    0.0606234   -0.117608    -0.127277
 -0.312695     -0.100252     -0.0761561    0.0035069    0.0577595   -0.0251858   -0.0553681   -0.0713449    0.0799222   -0.0547006   0.0848197    0.109463     0.00360723   -0.00788674  -0.083945      0.114154    0.0961408   -0.0435378   -0.0656373    0.132562    0.108204     0.166784    -0.150326     0.115162     0.0299144    0.00661752
 -0.00678977   -0.0697205     0.0382907   -0.22383      0.0281142   -0.0249465   -0.0331644   -0.0422356   -0.0116734   -0.0464064   0.0808795   -0.0443655   -0.0470897     0.00166133   0.0900425    -0.0916687  -0.187307     0.149711     0.0679241    0.11569    -0.056456     0.0108726    0.0948241    0.219517    -0.012897     0.25213
  0.0470951    -0.014961      0.116727     0.139348     0.0848534    0.057438     0.0709577    0.0324717   -0.0546498    0.153351    0.00892034   0.123955     0.0191245     0.159322     0.0485157    -0.103212   -0.0486078    0.00325351  -0.0238186    0.13606     0.0942949    0.0003551   -0.0435731   -0.0481131   -0.079471     0.0516027
  0.000693754   0.0660378     0.0395236   -0.118322    -0.228301     0.104644    -0.0339671    0.142213     0.191857     0.0635862   0.0224354   -0.125286    -0.0690466    -0.0752942    0.0490676    -0.0279482  -0.19596      0.0693677    0.0237474   -0.0730578   0.0211346    0.10421      0.0607873    0.00524452   0.0034477    0.0624156
 -0.143344      0.165617     -0.190287     0.142879    -0.00446978  -0.0391562   -0.0396251    9.75037e-5  -0.0496823    0.0754224   0.211755    -0.0169304   -0.0539989    -0.0632768    0.132758      0.0590977   0.00863477  -0.00426869   0.0577689    0.0697214  -0.0409762   -0.0494013   -0.253754    -0.0543369   -0.127517    -0.131186
  0.0110189    -0.0282662     0.097254     0.0772013   -0.100892     0.0317311   -0.0443971   -0.150637     0.183024     0.102954   -0.0670056   -0.113641    -0.0534868    -0.0716244    0.0872627    -0.0326065  -0.00617219   0.085718     0.0577687   -0.15788    -0.114857     0.0662486    0.0171976    0.0568327   -0.080229     0.134741
  0.0615215    -0.0589807    -0.0229749    0.0306844   -0.0372827    0.0562208   -0.026407     0.0688469   -0.0501758   -0.122478   -0.0146566   -0.0437648    0.217444      0.166316     0.0518607     0.0131098   0.139621    -0.0509179   -0.0546882   -0.150518    0.120521     0.00156517  -0.0957368    0.210127     0.00999267   0.0670497
  0.0698889    -0.0803298     0.0533965   -0.00155577  -0.100142    -0.0741692   -0.0339214    0.0126846    0.0641991    0.0105123   0.00456799   0.0870869   -0.0605698    -0.145638     0.195382      0.0416759   0.0656733    0.0829563    0.0748202   -0.0493475   0.0246697    0.0343414   -0.0883174   -0.082956     0.15194      0.0233627
 -0.0233529     0.108532     -0.138484     0.125128    -0.0515901    0.149323    -0.0209425    0.101866    -0.0355809   -0.04764     0.104333    -0.1975       0.0437347    -0.039773    -0.0687648     0.138142    0.14618      0.0738709    0.0484757    0.0458201   0.159955    -0.0904569   -0.024152    -0.0582029    0.0823243    0.0806103
  0.171118      0.160075     -0.016362    -0.0236608   -0.0843067    0.20146      0.0323949    0.0363311    0.00867037  -0.0745841  -0.0218321   -0.140301     0.0591877     0.0326448   -0.0231032    -0.0641395   0.0465555   -0.00370809   0.0805234    0.0951188  -0.00751609   0.0854138   -0.0975028   -0.0969271   -0.0187454    0.0363696
  0.0981216     0.191579     -0.0506306    0.0388131   -0.00697201  -0.0787555    0.0046182    0.150449     0.150651    -0.0115044  -0.0570842   -0.142119    -0.0737282    -0.209352    -0.00218307   -0.184438   -0.111151     0.141624    -0.100473     0.072076   -0.148031    -0.0847426    0.00978445  -0.02434      0.0683007   -0.0337748
 -0.018253     -0.0230282     0.176048    -0.0456179   -0.150122    -0.0988005   -0.0331866    0.0704376    0.00754707   0.148417   -0.154194     0.110775    -0.0656319    -0.0982492   -0.0306242    -0.0710604   0.147952    -0.100558    -0.0110759   -0.0280677  -0.0599743   -0.00556953   0.033425    -0.0184579   -0.0242171   -0.0330501
  0.0125206    -0.00720287   -0.0099042    0.18501      0.0797408   -0.104234    -0.00129354   0.00709317   0.00862412   0.0391635  -0.174325    -0.0141186   -0.0762994     0.12019      0.178273      0.0562089   0.0136573   -0.11581      0.130754     0.0512059  -0.0262427    0.148211    -0.0716513   -0.0919552    0.175544    -0.0532366
  0.0834193    -0.00779372   -0.00119625   0.0405843   -0.0520622   -0.0218815    0.0289285    0.129916     0.140253    -0.0143825  -0.0045961    0.122548     0.133582      0.0170383    0.0570874    -0.163369    0.0506583   -0.176563    -0.195779     0.0627135   0.044564     0.0900608    0.0254056   -0.0135965   -0.0398897   -0.222346
 -0.0232117     0.136504     -0.184146    -0.190687     0.0622985   -0.129475    -0.0438298   -0.110614    -0.127276     0.0576743  -0.0462725   -0.120888     0.139477     -0.15462     -0.056267      0.101697    0.0798845    0.202671    -0.00324841  -0.0491707   0.105846    -0.0148105   -0.0114661   -0.13738     -0.0846139    0.00542612
 -0.0499572    -0.0838828     0.0177884   -0.0125988   -0.0445042   -0.0450402    0.0188448    0.235844     0.0376989   -0.0378511  -0.0425289    0.133775     0.13577       0.0126183    0.0971683     0.137973   -0.114924     0.0378608    0.125978     0.241577    0.0869772   -0.0663565    0.022392     0.0400727   -0.050072     0.0701149
  0.00593829    0.0359844    -0.146926    -0.0276043    0.0321153    0.11721     -0.0342772    0.0938277    0.109684     0.10796    -0.0529377   -0.0948395   -0.006936     -0.130937     0.15548      -0.12877    -0.0565537   -0.0452494    0.0865178    0.191865    0.109275     0.123812     0.128563    -0.0585451   -0.042556     0.0342728
  0.35346      -0.0645096     0.00142322  -0.0364936    0.141858     0.227952    -0.0247938    0.146996     0.0611789   -0.102682    0.0592395   -0.0771392    0.00111448   -0.213259     0.202783      0.118873   -0.161257     0.0555807   -0.0865931   -0.0770549  -0.026417    -0.188052     0.0528652   -0.121463     0.197541     0.249639
  0.158669     -0.117965     -0.145866    -0.052818    -0.0740969    0.0282123    0.0850893    0.179681    -0.0206075   -0.189896   -0.00843943   0.257511    -0.228902     -0.12512     -0.0348723    -0.503412    0.175934     0.187586     0.216195     0.265117    0.0192066    0.315249     0.0356425    0.142096     0.0342047    0.128386
  0.0780379     0.0700886     0.194129    -0.124237     0.00686098   0.09493     -0.036775     0.0659483   -0.165516    -0.0341981   0.0482848   -0.0237874   -0.186259     -0.0658042   -0.0957913    -0.056496   -0.0446328   -0.0992543   -0.088893    -0.024366   -0.19556      0.100869    -0.0159849   -0.0095687    0.14879      0.0285836
  0.0751919    -0.0150089     0.045725    -0.158538     0.0119294    0.0553       0.0360096    0.133441    -0.0483049   -0.153746    0.22465      0.435364     0.0171995    -0.0301642    0.126357     -0.0194343   0.0276866    0.067251    -0.167487    -0.0562758  -0.10238      0.00593377  -0.0617363    0.00286573  -0.183167    -0.107648
  0.0578042    -0.0362287    -0.0966454   -0.00516361   0.0839506   -0.0252372    0.0667762   -0.247985     0.100188    -0.108723   -0.116189    -0.00394263  -0.000843939   0.133831     0.072405     -0.146316    0.127398     0.133627     0.2217      -0.0644252  -0.0761505   -0.0415825    0.00112386   0.0202066    0.0439358   -0.171651
 -0.0141954    -0.0293191     0.0620803    0.0596554    0.100717    -0.00930602   0.0380867   -0.102528    -0.216735     0.0519236  -0.0436219    0.114512    -0.078521      0.0821024   -0.0985582    -0.0607413   0.0205632    0.090057    -0.0208358   -0.124572   -0.0350768   -0.0753389    0.057289    -0.120084    -0.0181021    0.0459244
  0.00937378    0.172735      0.0352959   -0.134183    -0.0296091    0.00358495   0.163817     0.0907065    0.0200374    0.118656    0.122543     0.0184599    0.0616276     0.121557    -0.0820969    -0.0868884  -0.0615525   -0.0583766    0.0975807   -0.20319    -0.068236    -0.212149     0.0842825    0.0390619    0.0524908    0.00236314
 -0.141777     -0.00775736    0.0267001   -0.049846    -0.093736     0.0921712   -0.0301602   -0.0592185   -0.213257    -0.0178729  -0.0042556    0.105509    -0.0361441     0.0578377   -0.134786     -0.0954723   0.0113113   -0.0256991    0.0561295   -0.235426   -0.0303072   -0.0393736    0.0269972   -0.102905     0.0449354   -0.0141266
  0.0623754    -0.125963     -0.0100069    0.0223284    0.0833079    0.0371782   -0.0716512   -0.162012     0.0110747   -0.13034     0.114963    -0.079728    -0.0742125    -0.0561712   -0.122661     -0.231635    0.042219     0.00410274   0.0894613    0.0373307  -0.117823    -0.071628     0.0759956   -0.191753    -0.1326       0.125855[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.070263
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│     20
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.004841
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│      7
│     10
│     19
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.994995
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     13
│     20
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.037075
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.027892
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      7
│     10
│     13
│      ⋮
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.987952
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│      7
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.049917
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│     20
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.016905
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      6
│      7
│     10
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.001626
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     13
│     19
│     20
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.031715
┌ Info: EM with 100000 data points 10 iterations avll -1.031715
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0766388    0.0333206   -0.00640044   0.120605     0.0606269   0.0749864    0.142705     0.0985526    0.124589    -0.331466     0.028458      0.0326095   -0.107703    -0.0392424   0.074089    -0.0203596    -0.129032     0.107659      0.0114135     0.141765    -0.143389     0.0683256   -0.119823    -0.115507     0.208093     0.058775
  0.0127636   -0.118592     0.0407387   -0.0614819   -0.0579074  -0.0233876    0.232403    -0.0708862   -0.0374641    0.0540073   -0.0547059    -0.153725     0.0827951    0.102321   -0.0927389    0.12635       0.0723971    0.021589      0.117273     -0.054919     0.010843    -0.0518475   -0.11659      0.0825034   -0.180457    -0.0327844
  0.0429985    0.118131     0.0966237   -6.80029e-5   0.170377   -0.177684    -0.158305     0.0264305    0.135282    -0.0457337   -0.0466393    -0.00321158   0.0430868   -0.0245025   0.104241    -0.00888741   -0.181626    -0.0683596    -0.0485241     0.00966762  -0.0376885    0.00934113  -0.118208    -0.118667    -0.0727966   -0.0739107
 -0.0605037   -0.24324     -0.0459951   -0.218641     0.0673777   0.0346701    0.0357547   -0.0413408   -0.0841298    0.0564492   -0.23395      -0.138613    -0.114551    -0.0708381   0.103339     0.126002     -0.0782367   -0.0276318    -0.0639571    -0.133653     0.00682403   0.109557     0.158089     0.0562642    0.151963     0.0887504
  0.111999    -0.0464738    0.133364    -0.0832109   -0.204361   -0.0586047   -0.19864      0.096556     0.0426001   -0.00670717  -0.0608546     0.138281     0.0101676    0.0573288   0.112315     0.072058     -0.0795721    0.0902099    -0.0068986     0.146459     0.00171601   0.0350052    0.0208249    0.172391     0.0680066    0.185293
 -0.0138977   -0.124788     0.146962    -0.0761162    0.0845336  -2.92421e-5   0.143247    -0.0808661   -0.0714257   -0.378358    -0.0399333     0.11589     -0.170254     0.139745   -0.088616     0.174256     -0.0190024   -0.0211746     0.0315523    -0.151536    -0.0454345    0.171193    -0.0871624    0.073427    -0.0438332   -0.0641857
  0.00965005  -0.0659871    0.111271    -0.0450804    0.149799   -0.112305     0.0400261   -0.0247677    0.150403     0.0462219    0.199868      0.144381    -0.143619    -0.0700156   0.113183    -0.0896268    -0.0347245   -0.0630182    -0.0922397    -0.0697316   -0.0656794    0.00744476   0.0398053   -0.0272744    0.178622     0.190916
  0.032573     0.125925     0.0484913    0.104326     0.1541     -0.119091    -0.0763296   -0.0170236    0.15693      0.0128387    0.227717     -0.0559291    0.18513      0.0258071  -0.0454757   -0.0728525     0.0464087    0.087362     -0.0845961    -0.107995    -0.104262    -0.0422996   -0.0546713    0.06366      0.167414    -0.137543
  0.0353714    0.0683988    0.0488325    0.17893      0.111907    0.207637     0.0513111    0.0853325    0.0274497   -0.0798787   -0.158793     -0.0309835    0.0111862   -0.0407005   0.209454     0.00128179   -0.0125087   -0.053862      0.0350823     0.0603544   -0.0884684    0.0597482    0.0958354    0.0861759    0.0953494   -0.043829
  0.0213511    0.0172978   -0.051248    -0.00876356  -0.149662   -0.0526369   -0.120061    -0.0492152    0.0906889   -0.147846    -0.0455507     0.0991295    0.0106282    0.0471144  -0.11095      0.0834224    -0.0124067   -0.0356666    -0.091392      0.0837268   -0.00484189   0.0310736   -0.0706674    0.0682335    0.0289739   -0.0916216
  0.0361701    0.0587273    0.0549438    0.0260949   -0.107589    0.0337725    0.0242727   -0.0419474   -0.11837     -0.100041    -0.00899567    0.0508268    0.0548262    0.271143   -0.0411386    0.250237      0.0803677   -0.165328     -0.0694405     0.153425     0.0907507   -0.158108     0.196829     0.0472726   -0.135071    -0.0510835
  0.109479     0.0290913   -0.0660211   -0.0557304    0.136844    0.12216     -0.0833247    0.055248     0.107459    -0.0953493    0.0757613     0.0439205    0.00669885   0.0769018   0.145659    -0.000193701  -0.120084    -0.000966229   0.00372247   -0.176499    -0.146575    -0.250541    -0.0743439    0.231535    -0.055741     0.029167
 -0.0170648   -0.0755237    0.0483933    0.0162974    0.0451426   0.167552    -0.200016    -0.030343    -0.0961141    0.114585     0.0218411     0.0280905    0.0554756   -0.143327   -0.0439219    0.159904     -0.0265777    0.137531     -0.118504      0.00586295  -0.0601348    0.304866    -0.00347866   0.0611675    0.0515066    0.065611
 -0.194173    -0.0604435   -0.0789041    0.0390011   -0.141962    0.136967     0.167399     0.0102967    0.0416538    0.0838491    0.0324326    -0.0452034    0.0480859    0.0350633  -0.135873    -0.0143848     0.00370309  -0.116703      0.0190704     0.0730103    0.0752186    0.0162456   -0.203861    -0.0722279   -0.171841    -0.0423141
  0.15483      0.129994    -0.202966     0.172745    -0.102004   -0.00761092  -0.00662492   0.0273734    0.0361771    0.0499266   -0.096644     -0.157185    -0.154269     0.0991817   0.0750424    0.123402     -0.0917024   -0.0159283    -0.148217      0.026221    -0.159261     0.0621945    0.125722     0.117519    -0.0878823   -0.0683549
 -0.0140187   -0.00309825  -0.190867    -0.113163    -0.0521289  -0.0930483    0.0171184    0.136588     0.0496456   -0.0357727   -0.0359815     0.111202    -0.0597965   -0.0435181   0.0794787   -0.123922      0.0715784    0.214919     -0.103282      0.00433005  -0.179424    -0.0517567   -0.181638     0.0221288   -0.144629    -0.0518963
 -0.0726998    0.0899119   -0.0640751    0.074684    -0.097864    0.0527595   -0.0402342   -0.0855505    0.0984868   -0.0499968   -0.119104      0.00444102   0.0158475   -0.222957   -0.023128     0.138904      0.0179922   -0.104915      0.0202777     0.0949933    0.163614    -0.0188706    0.0331952   -0.080223    -0.00675531  -0.044326
  0.0495442   -0.0628195    0.153012     0.0689819    0.162222   -0.179719     0.0666809    0.0842856    0.0306731    0.0246832    0.0665661     0.0138642   -0.147149    -0.0945395  -0.105563    -0.00096036   -0.00197555   0.0296736    -0.0979321     0.0392244    0.102041     0.133691     0.266119    -0.106888     0.145688    -0.129623
  0.0375744    0.0876701   -0.0589113    0.085865     0.139809   -0.0371546   -0.135669     0.0729632   -0.265221    -0.136154     0.0793626    -0.166582    -0.14763      0.0370718  -0.0387888   -0.0647326    -0.129394     0.0432        0.140514      0.0129514    0.175927     0.103309    -0.0335309    0.0771671    0.253345    -0.00414489
  0.0148832    0.126562    -0.0533083   -0.010293     0.101095    0.0609134    0.143915     0.0480012    0.107364     0.339595    -0.000653656   0.0505138    0.0956125   -0.151555    0.101579     0.220646      0.00685635  -0.185877      0.00709468   -0.0408321   -0.0862381    0.0536402    0.110992    -0.0505884   -0.137144     0.0407943
 -0.0538425   -0.122395     0.00545013   0.0144988   -0.0224274  -0.173861    -0.0839562    0.0432345   -0.0445432   -0.0645365   -0.0622168     0.0659142   -0.00548877   0.0901554   0.0475581   -0.153238      0.0625995    0.0947169     0.0144096    -0.0433642    0.102623    -0.138345    -0.123765    -0.0743598    0.016749    -0.0716814
 -0.0632772   -0.0539181    0.179977    -0.0642447   -0.0387964  -0.0151448    0.0671342   -0.00732225   0.0110403   -0.0726724    0.0263751    -0.0740541    0.0286246    0.0417868  -0.203675     0.0511373     0.0924899   -0.179116     -0.0312193    -0.114883     0.104735     0.0785808    0.0176474   -0.0582343   -0.102515     0.0667404
  0.00154267   0.0226339    0.0497576    0.11362     -0.242345   -0.230435    -0.0271454    0.142412    -0.0687538   -0.130525     0.138789      0.0922291    0.120259    -0.110418    0.00340596   0.141578      0.147893     0.0105901     0.0859109    -0.0153793    0.207756     0.0420203   -0.172272    -0.0362307    0.0129159    0.109651
 -0.0257771    0.132548     0.129132    -0.0605844   -0.111051    0.0308812   -0.0298861   -0.0461165   -0.255216    -0.237826    -0.112312     -0.173253    -0.0394817    0.165279   -0.0690093   -0.171518      0.104351    -0.0653104    -0.0573657    -0.0885225    0.0147719    0.0302679   -0.0627475   -0.0411604   -0.157797     0.0537552
  0.0672483    0.107267    -0.11873      0.0118143   -0.180695    0.0117453   -0.0291766   -0.114029    -0.0516088   -0.00920297   0.116958      0.09011     -0.110036     0.142364    0.105122    -0.0500946    -0.045397     0.195379     -0.0479546     0.0283431    0.0975091    0.123879    -0.0933268   -0.0273666    0.225789    -0.0329069
 -0.0411692    0.0345567   -0.0323259   -0.09714     -0.0383533  -0.137408    -0.0326083    0.212541    -0.0746521    0.0382264    0.0873915     0.0349244    0.0661933    0.164543   -0.0129076    0.141075     -0.0481816    0.0177489    -0.136893     -0.0425197    0.0163674    0.0334842   -0.0888638   -0.00313758  -0.00746162  -0.022483
 -0.0801443   -0.0451669   -0.165201    -0.0656162   -0.0511693   0.0923818   -0.0111851    0.0674437    0.0757796   -0.00145428  -0.107906     -0.158858    -0.188896     0.264297    0.0883887    0.256024      0.101412     0.216854     -0.0325123     0.209273    -0.190365    -0.0591988   -0.00743667   0.0258529    0.0721704   -0.0112519
 -0.00416219  -0.0896562    0.0689192    0.0240478   -0.124813    0.0209349    0.0287588    0.122759     0.056402    -0.012606     0.119659     -0.142798     0.0154919   -0.100979    0.174116    -0.0140059     0.103028    -0.0760468     0.0690917     0.0432587   -0.185143     0.087745     0.040445    -0.118564    -0.0414394   -0.0337947
 -0.0505128    0.102282     0.0620546   -0.0406534   -0.0255844  -0.122043    -0.0811488    0.153441    -0.00574632   0.0699135    0.163715     -0.10714      0.186723     0.0372861  -0.0726183   -0.0545299     0.018337     0.110763     -0.0484378     0.0143417   -0.0448608    0.0354476   -0.0331945    0.0868691   -0.131088    -0.0414562
  0.205467    -0.0284055   -0.061669     0.0645001   -0.0160582  -0.10234      0.014641    -0.109905     0.00847494   0.0223829    0.0661445     0.0859995    0.108795     0.11294    -0.0840123   -0.230657      0.0584944    0.210121     -0.101451      0.0667609    0.100843    -0.108718    -0.0155002   -0.09207      0.0519629   -0.0264777
  0.00321322   0.281476     0.100604    -0.182178    -0.140957    0.0276777    0.0353858   -0.275289    -0.123997     0.181616    -0.0440699    -0.167851    -0.0962054   -0.17863    -0.106295     0.00825123   -0.238907     0.177222      0.0156509     0.196838     0.0363122    0.0938183   -0.0489559   -0.134316    -0.0190161    0.101101
  0.114098     0.143416    -0.105237    -0.0448128   -0.245999    0.0329658   -0.0319263   -0.101685    -0.0681886   -0.227961     0.176554      0.158       -0.00744071   0.0252222  -0.145186     0.137085      0.029977     0.107122      0.000709264   0.0916856    0.157564     0.0932634   -0.157847    -0.061848    -0.0039606    0.0193472kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4142724502407589
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414290
[ Info: iteration 2, average log likelihood -1.414241
[ Info: iteration 3, average log likelihood -1.414206
[ Info: iteration 4, average log likelihood -1.414165
[ Info: iteration 5, average log likelihood -1.414115
[ Info: iteration 6, average log likelihood -1.414052
[ Info: iteration 7, average log likelihood -1.413971
[ Info: iteration 8, average log likelihood -1.413852
[ Info: iteration 9, average log likelihood -1.413647
[ Info: iteration 10, average log likelihood -1.413254
[ Info: iteration 11, average log likelihood -1.412540
[ Info: iteration 12, average log likelihood -1.411507
[ Info: iteration 13, average log likelihood -1.410453
[ Info: iteration 14, average log likelihood -1.409728
[ Info: iteration 15, average log likelihood -1.409369
[ Info: iteration 16, average log likelihood -1.409218
[ Info: iteration 17, average log likelihood -1.409158
[ Info: iteration 18, average log likelihood -1.409133
[ Info: iteration 19, average log likelihood -1.409123
[ Info: iteration 20, average log likelihood -1.409118
[ Info: iteration 21, average log likelihood -1.409116
[ Info: iteration 22, average log likelihood -1.409115
[ Info: iteration 23, average log likelihood -1.409115
[ Info: iteration 24, average log likelihood -1.409114
[ Info: iteration 25, average log likelihood -1.409114
[ Info: iteration 26, average log likelihood -1.409114
[ Info: iteration 27, average log likelihood -1.409114
[ Info: iteration 28, average log likelihood -1.409113
[ Info: iteration 29, average log likelihood -1.409113
[ Info: iteration 30, average log likelihood -1.409113
[ Info: iteration 31, average log likelihood -1.409113
[ Info: iteration 32, average log likelihood -1.409113
[ Info: iteration 33, average log likelihood -1.409113
[ Info: iteration 34, average log likelihood -1.409113
[ Info: iteration 35, average log likelihood -1.409113
[ Info: iteration 36, average log likelihood -1.409113
[ Info: iteration 37, average log likelihood -1.409113
[ Info: iteration 38, average log likelihood -1.409113
[ Info: iteration 39, average log likelihood -1.409112
[ Info: iteration 40, average log likelihood -1.409112
[ Info: iteration 41, average log likelihood -1.409112
[ Info: iteration 42, average log likelihood -1.409112
[ Info: iteration 43, average log likelihood -1.409112
[ Info: iteration 44, average log likelihood -1.409112
[ Info: iteration 45, average log likelihood -1.409112
[ Info: iteration 46, average log likelihood -1.409112
[ Info: iteration 47, average log likelihood -1.409112
[ Info: iteration 48, average log likelihood -1.409112
[ Info: iteration 49, average log likelihood -1.409112
[ Info: iteration 50, average log likelihood -1.409112
┌ Info: EM with 100000 data points 50 iterations avll -1.409112
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4142900412798751
│     -1.414240586869886
│      ⋮
└     -1.4091121326075013
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409130
[ Info: iteration 2, average log likelihood -1.409078
[ Info: iteration 3, average log likelihood -1.409041
[ Info: iteration 4, average log likelihood -1.408999
[ Info: iteration 5, average log likelihood -1.408948
[ Info: iteration 6, average log likelihood -1.408888
[ Info: iteration 7, average log likelihood -1.408823
[ Info: iteration 8, average log likelihood -1.408757
[ Info: iteration 9, average log likelihood -1.408695
[ Info: iteration 10, average log likelihood -1.408640
[ Info: iteration 11, average log likelihood -1.408593
[ Info: iteration 12, average log likelihood -1.408553
[ Info: iteration 13, average log likelihood -1.408519
[ Info: iteration 14, average log likelihood -1.408488
[ Info: iteration 15, average log likelihood -1.408461
[ Info: iteration 16, average log likelihood -1.408434
[ Info: iteration 17, average log likelihood -1.408409
[ Info: iteration 18, average log likelihood -1.408385
[ Info: iteration 19, average log likelihood -1.408362
[ Info: iteration 20, average log likelihood -1.408340
[ Info: iteration 21, average log likelihood -1.408318
[ Info: iteration 22, average log likelihood -1.408298
[ Info: iteration 23, average log likelihood -1.408278
[ Info: iteration 24, average log likelihood -1.408260
[ Info: iteration 25, average log likelihood -1.408243
[ Info: iteration 26, average log likelihood -1.408227
[ Info: iteration 27, average log likelihood -1.408213
[ Info: iteration 28, average log likelihood -1.408200
[ Info: iteration 29, average log likelihood -1.408188
[ Info: iteration 30, average log likelihood -1.408177
[ Info: iteration 31, average log likelihood -1.408166
[ Info: iteration 32, average log likelihood -1.408157
[ Info: iteration 33, average log likelihood -1.408148
[ Info: iteration 34, average log likelihood -1.408140
[ Info: iteration 35, average log likelihood -1.408133
[ Info: iteration 36, average log likelihood -1.408125
[ Info: iteration 37, average log likelihood -1.408118
[ Info: iteration 38, average log likelihood -1.408112
[ Info: iteration 39, average log likelihood -1.408106
[ Info: iteration 40, average log likelihood -1.408100
[ Info: iteration 41, average log likelihood -1.408094
[ Info: iteration 42, average log likelihood -1.408089
[ Info: iteration 43, average log likelihood -1.408084
[ Info: iteration 44, average log likelihood -1.408080
[ Info: iteration 45, average log likelihood -1.408075
[ Info: iteration 46, average log likelihood -1.408072
[ Info: iteration 47, average log likelihood -1.408068
[ Info: iteration 48, average log likelihood -1.408065
[ Info: iteration 49, average log likelihood -1.408061
[ Info: iteration 50, average log likelihood -1.408059
┌ Info: EM with 100000 data points 50 iterations avll -1.408059
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4091295139850826
│     -1.4090779451866056
│      ⋮
└     -1.4080586053185071
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408068
[ Info: iteration 2, average log likelihood -1.408019
[ Info: iteration 3, average log likelihood -1.407979
[ Info: iteration 4, average log likelihood -1.407934
[ Info: iteration 5, average log likelihood -1.407881
[ Info: iteration 6, average log likelihood -1.407818
[ Info: iteration 7, average log likelihood -1.407745
[ Info: iteration 8, average log likelihood -1.407666
[ Info: iteration 9, average log likelihood -1.407586
[ Info: iteration 10, average log likelihood -1.407511
[ Info: iteration 11, average log likelihood -1.407443
[ Info: iteration 12, average log likelihood -1.407384
[ Info: iteration 13, average log likelihood -1.407335
[ Info: iteration 14, average log likelihood -1.407294
[ Info: iteration 15, average log likelihood -1.407260
[ Info: iteration 16, average log likelihood -1.407231
[ Info: iteration 17, average log likelihood -1.407206
[ Info: iteration 18, average log likelihood -1.407184
[ Info: iteration 19, average log likelihood -1.407164
[ Info: iteration 20, average log likelihood -1.407146
[ Info: iteration 21, average log likelihood -1.407130
[ Info: iteration 22, average log likelihood -1.407115
[ Info: iteration 23, average log likelihood -1.407100
[ Info: iteration 24, average log likelihood -1.407086
[ Info: iteration 25, average log likelihood -1.407073
[ Info: iteration 26, average log likelihood -1.407061
[ Info: iteration 27, average log likelihood -1.407049
[ Info: iteration 28, average log likelihood -1.407038
[ Info: iteration 29, average log likelihood -1.407028
[ Info: iteration 30, average log likelihood -1.407018
[ Info: iteration 31, average log likelihood -1.407009
[ Info: iteration 32, average log likelihood -1.407000
[ Info: iteration 33, average log likelihood -1.406992
[ Info: iteration 34, average log likelihood -1.406984
[ Info: iteration 35, average log likelihood -1.406976
[ Info: iteration 36, average log likelihood -1.406969
[ Info: iteration 37, average log likelihood -1.406963
[ Info: iteration 38, average log likelihood -1.406956
[ Info: iteration 39, average log likelihood -1.406950
[ Info: iteration 40, average log likelihood -1.406944
[ Info: iteration 41, average log likelihood -1.406938
[ Info: iteration 42, average log likelihood -1.406932
[ Info: iteration 43, average log likelihood -1.406926
[ Info: iteration 44, average log likelihood -1.406920
[ Info: iteration 45, average log likelihood -1.406914
[ Info: iteration 46, average log likelihood -1.406909
[ Info: iteration 47, average log likelihood -1.406903
[ Info: iteration 48, average log likelihood -1.406898
[ Info: iteration 49, average log likelihood -1.406892
[ Info: iteration 50, average log likelihood -1.406886
┌ Info: EM with 100000 data points 50 iterations avll -1.406886
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4080675308547137
│     -1.4080186178257241
│      ⋮
└     -1.4068863478158071
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406889
[ Info: iteration 2, average log likelihood -1.406835
[ Info: iteration 3, average log likelihood -1.406785
[ Info: iteration 4, average log likelihood -1.406729
[ Info: iteration 5, average log likelihood -1.406663
[ Info: iteration 6, average log likelihood -1.406586
[ Info: iteration 7, average log likelihood -1.406495
[ Info: iteration 8, average log likelihood -1.406396
[ Info: iteration 9, average log likelihood -1.406291
[ Info: iteration 10, average log likelihood -1.406186
[ Info: iteration 11, average log likelihood -1.406085
[ Info: iteration 12, average log likelihood -1.405992
[ Info: iteration 13, average log likelihood -1.405907
[ Info: iteration 14, average log likelihood -1.405831
[ Info: iteration 15, average log likelihood -1.405764
[ Info: iteration 16, average log likelihood -1.405704
[ Info: iteration 17, average log likelihood -1.405652
[ Info: iteration 18, average log likelihood -1.405605
[ Info: iteration 19, average log likelihood -1.405565
[ Info: iteration 20, average log likelihood -1.405529
[ Info: iteration 21, average log likelihood -1.405497
[ Info: iteration 22, average log likelihood -1.405469
[ Info: iteration 23, average log likelihood -1.405444
[ Info: iteration 24, average log likelihood -1.405421
[ Info: iteration 25, average log likelihood -1.405401
[ Info: iteration 26, average log likelihood -1.405383
[ Info: iteration 27, average log likelihood -1.405366
[ Info: iteration 28, average log likelihood -1.405351
[ Info: iteration 29, average log likelihood -1.405337
[ Info: iteration 30, average log likelihood -1.405323
[ Info: iteration 31, average log likelihood -1.405311
[ Info: iteration 32, average log likelihood -1.405299
[ Info: iteration 33, average log likelihood -1.405288
[ Info: iteration 34, average log likelihood -1.405277
[ Info: iteration 35, average log likelihood -1.405267
[ Info: iteration 36, average log likelihood -1.405257
[ Info: iteration 37, average log likelihood -1.405247
[ Info: iteration 38, average log likelihood -1.405238
[ Info: iteration 39, average log likelihood -1.405228
[ Info: iteration 40, average log likelihood -1.405219
[ Info: iteration 41, average log likelihood -1.405211
[ Info: iteration 42, average log likelihood -1.405202
[ Info: iteration 43, average log likelihood -1.405194
[ Info: iteration 44, average log likelihood -1.405186
[ Info: iteration 45, average log likelihood -1.405178
[ Info: iteration 46, average log likelihood -1.405170
[ Info: iteration 47, average log likelihood -1.405162
[ Info: iteration 48, average log likelihood -1.405154
[ Info: iteration 49, average log likelihood -1.405147
[ Info: iteration 50, average log likelihood -1.405140
┌ Info: EM with 100000 data points 50 iterations avll -1.405140
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4068886254289779
│     -1.4068346114986165
│      ⋮
└     -1.4051397091936744
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405140
[ Info: iteration 2, average log likelihood -1.405081
[ Info: iteration 3, average log likelihood -1.405026
[ Info: iteration 4, average log likelihood -1.404962
[ Info: iteration 5, average log likelihood -1.404884
[ Info: iteration 6, average log likelihood -1.404788
[ Info: iteration 7, average log likelihood -1.404673
[ Info: iteration 8, average log likelihood -1.404540
[ Info: iteration 9, average log likelihood -1.404394
[ Info: iteration 10, average log likelihood -1.404244
[ Info: iteration 11, average log likelihood -1.404096
[ Info: iteration 12, average log likelihood -1.403955
[ Info: iteration 13, average log likelihood -1.403825
[ Info: iteration 14, average log likelihood -1.403708
[ Info: iteration 15, average log likelihood -1.403605
[ Info: iteration 16, average log likelihood -1.403514
[ Info: iteration 17, average log likelihood -1.403435
[ Info: iteration 18, average log likelihood -1.403366
[ Info: iteration 19, average log likelihood -1.403306
[ Info: iteration 20, average log likelihood -1.403253
[ Info: iteration 21, average log likelihood -1.403207
[ Info: iteration 22, average log likelihood -1.403165
[ Info: iteration 23, average log likelihood -1.403127
[ Info: iteration 24, average log likelihood -1.403093
[ Info: iteration 25, average log likelihood -1.403062
[ Info: iteration 26, average log likelihood -1.403033
[ Info: iteration 27, average log likelihood -1.403006
[ Info: iteration 28, average log likelihood -1.402980
[ Info: iteration 29, average log likelihood -1.402956
[ Info: iteration 30, average log likelihood -1.402933
[ Info: iteration 31, average log likelihood -1.402911
[ Info: iteration 32, average log likelihood -1.402890
[ Info: iteration 33, average log likelihood -1.402870
[ Info: iteration 34, average log likelihood -1.402850
[ Info: iteration 35, average log likelihood -1.402831
[ Info: iteration 36, average log likelihood -1.402813
[ Info: iteration 37, average log likelihood -1.402795
[ Info: iteration 38, average log likelihood -1.402777
[ Info: iteration 39, average log likelihood -1.402760
[ Info: iteration 40, average log likelihood -1.402744
[ Info: iteration 41, average log likelihood -1.402727
[ Info: iteration 42, average log likelihood -1.402711
[ Info: iteration 43, average log likelihood -1.402696
[ Info: iteration 44, average log likelihood -1.402681
[ Info: iteration 45, average log likelihood -1.402666
[ Info: iteration 46, average log likelihood -1.402651
[ Info: iteration 47, average log likelihood -1.402637
[ Info: iteration 48, average log likelihood -1.402623
[ Info: iteration 49, average log likelihood -1.402609
[ Info: iteration 50, average log likelihood -1.402595
┌ Info: EM with 100000 data points 50 iterations avll -1.402595
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4051397602601958
│     -1.4050814504230669
│      ⋮
└     -1.4025954897297537
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4142724502407589
│     -1.4142900412798751
│     -1.414240586869886
│     -1.4142056726596317
│      ⋮
│     -1.4026227720607956
│     -1.402609004169385
└     -1.4025954897297537
32×26 Array{Float64,2}:
 -0.107704     0.229988    0.0356031   -0.455908    -0.149189    -0.11707     -0.198075    -0.393115   -0.841054   -0.368339     0.294534   -0.101271   -1.05703     0.399091    0.545366    0.213793   -0.293032    -0.277024    0.152271     0.457743   -0.373825     0.616458    -0.128846     0.37081    -0.284567    0.60789
 -0.337616    -0.482427   -0.155317    -0.295825     0.565011    -0.195873     0.381041    -0.289778   -0.598575   -0.00433897  -0.260887   -0.496649   -0.0911204  -0.0570815   0.286282   -0.0253641  -0.407365     0.0749153   0.18212      0.519842   -0.240073    -0.0841265   -0.136065     0.510576    0.218457    0.295786
  0.218545    -0.484847    0.0794104    0.498817    -0.265121     0.169397    -0.260231    -0.0853859  -0.470986    0.140084     0.0891044   0.0568429   0.0582243  -0.274159    0.164406   -0.121094   -0.742151     0.125632   -0.00446542   0.432534   -0.311795     0.385967     0.369544    -0.438711    0.451685    0.369283
  0.31668     -0.331325   -0.719873     0.515199     0.577474     0.102197    -0.084669     0.424571   -0.37529    -0.0227071   -0.273571   -0.120655   -0.166241   -0.164879    0.0760115   0.390165   -0.508306    -0.228056   -0.32427     -0.100415   -0.115474     0.360528     0.0996076   -0.176121   -0.133653    0.241061
  0.0627957    0.147187   -0.00767641  -0.00855847  -0.0629338    0.0674701   -0.222696    -0.479547   -0.72631     0.506699     0.63955    -0.900931    0.330733   -0.255477   -0.455001    0.246513    0.11442     -0.108312    0.0519318    0.585996   -0.0337541    0.153847    -0.362236    -0.116232   -0.108817    0.177202
 -0.0218158    0.156006   -0.510834     0.0713302   -0.0360792    0.0152904   -0.501212    -0.332252    0.0819949  -0.0666736    0.230649    0.625414   -0.276522   -0.0179094  -0.596281   -0.146649    0.255089    -0.557519    0.0263451    0.315189    0.0367185   -0.121864    -0.138595     0.124885   -0.251911    0.215259
  0.151444     0.691922   -0.38669     -0.303953    -0.234841    -0.572208     0.291044     1.12511     0.061843    0.255898    -0.243428   -0.46713    -0.134648    0.55204     0.178679    0.416083    0.135076     0.099286   -0.244014     0.26785    -0.175934    -0.614537     0.0696248    0.193155   -0.0272819   0.0834788
  0.269954     0.124433   -0.302627     0.137336     0.120679    -0.525185    -0.068525     0.462836   -0.182609    0.240753    -0.0721907   0.206664    0.0379115  -0.0718341  -0.181975   -0.261524   -0.310376     0.793362   -0.488227     0.22575     0.120566     0.404662    -0.0492671    0.166049    0.185044    0.0614581
 -0.0725133   -0.0727914   0.758541    -0.514158    -0.567964     0.00804549   0.11107      0.0639546   0.16983     0.0746382    0.25678    -0.415614    0.471333   -0.0676905   0.213712    0.0384378  -0.194976    -0.75665     0.278693    -0.273218   -0.241407    -0.567218     0.735867    -0.480739   -0.605995   -0.15935
 -0.131534    -0.0310721   0.82691     -0.131252    -0.626357     0.0353725   -0.29367     -0.66946     0.460667    0.0452586   -0.0404596   0.448489    0.249918   -0.334226    0.0344274  -0.4183     -0.102157     0.353296    0.526848    -0.0882422   0.302233    -0.328168     0.0505153    0.103508    0.832433    0.095756
 -0.224897     0.0878598  -0.00383697  -0.227946     0.447866     0.404289     0.632365    -0.0347606  -0.0333262  -0.121676    -0.1519     -0.640444   -0.269773    0.310413    0.575571   -0.134066   -0.169476     0.176557    0.859189    -0.372392    0.0832844   -0.479699    -0.790716    -0.0670456   0.287126   -0.959113
 -0.418992    -0.757462    0.166642     0.279616     0.369911     0.0559716    0.529948    -0.22291    -0.0767967  -0.656573    -0.486066    0.0180316   0.437258   -0.181211    0.130383    0.367603    0.117144    -0.139458   -0.10031     -0.485823   -0.321753    -0.231691     0.359588     0.0381006   0.348469    0.082942
 -0.185821    -0.0829825   0.619781     0.311031    -0.016999     0.0892659    0.552516    -0.0657031  -0.432719   -0.65679      0.628046   -0.228955    0.0721144  -0.12823    -0.0999514   0.308076    0.426744     0.193059   -0.435632    -0.0752138  -0.269861     0.86671     -0.318322     0.0535793  -0.0998182  -0.198653
 -0.068279    -0.170767    0.702339    -0.13779     -0.103307     0.163783     0.0578532   -0.410133    0.68176    -0.367087    -0.0219146   0.415211    0.218723   -0.0788138   0.233832    0.079416    0.258338     0.0305266  -0.121229    -0.835751    0.148669     0.655251    -0.131638     0.0273066  -0.624641   -0.195055
  0.0718136    0.0479436   0.0730368    0.515496    -0.320086     0.206915    -0.202893     0.40279     0.341669   -0.27131      0.35546     0.0848992  -0.213053    0.661194    0.395231    0.145872   -0.112369     0.0306271   0.322657     0.0793864  -0.114599     0.696883     0.106282    -0.706284    0.24401    -0.562545
  0.407852    -0.0311559   0.161477    -0.332782    -0.00480513   0.259843     0.741284    -0.145047    0.742743    0.166315     0.333024    0.114365   -0.310795    0.558792    0.62158    -0.0237155   0.0214583    0.629719   -0.448197     0.498711    0.440433     0.451408     0.357625     0.0997476   0.168096    0.638257
 -0.175795    -0.699407    0.0139699   -0.586338    -0.235001    -0.0392323    0.00042021  -0.0332447  -0.0967606   0.386055     0.124335    0.143652    0.0431012  -0.191997   -0.432884   -0.255841   -0.0204144    0.210159   -0.542348     0.203377   -0.702569    -0.834421     0.0615974   -0.141003   -0.304989    0.441885
 -0.141978     0.0625326   0.112065    -0.653646     0.76396      0.0394119   -0.203006    -0.412859    0.126768   -0.0219447    0.168879    0.0497468  -0.138383   -0.208762   -0.284119   -0.115912   -0.0166069   -0.600182   -0.360665    -0.420568   -0.290408    -0.264011    -0.231214     0.038555   -0.419863   -0.385987
  0.307246     0.152537    0.0525503    0.24202     -0.462224    -0.0278979   -0.213681    -0.101899    0.0556849  -0.517239     0.0259559   0.017918    0.257302   -0.182347   -0.469641    0.205502    0.342883     0.0948799  -0.466556     0.314714    0.0969363    0.556752     0.374264     0.215447   -0.0900048   0.728719
  0.444582     0.0261088  -0.276673     0.130205    -0.206788    -0.263958    -0.517032     0.189272    0.160507    0.513649     0.422741    0.278116    0.101481   -0.0851803  -0.441835   -0.0396316   0.00163983  -0.119042   -0.25621      0.173893    0.00124493   0.0842575   -0.0290291   -0.157822   -0.337011   -0.000524525
 -0.264961     0.279429   -0.19036     -0.199741     0.12032     -0.17831     -0.345908     0.511917   -0.704827    0.038869    -0.268134   -0.286387    0.154411   -0.0248995  -0.305735   -0.5935     -0.503246    -0.0416677  -0.115118    -0.0982152   0.437154    -0.441633     0.021423     0.0108816   0.137478    0.174547
  0.191099    -0.0462661  -0.135904     0.209146    -0.15736      0.176016    -0.116409     0.24869     0.754088    0.620154    -0.569317    0.197561    0.486148   -0.317899    0.0480291  -0.272523   -0.126407     0.0618568  -0.0509442   -0.430891    0.688076    -0.437379    -0.0366926   -0.272781    0.297659   -0.288899
 -0.0452846   -0.343458   -0.534321     0.114869     0.0566648    0.0842895   -0.387154    -0.283496    0.243286    0.798009     0.0344751  -0.0280513  -0.202165    0.0320318  -0.633804    0.861032    0.524644     0.186489   -0.0398225    0.161241    0.492693     0.0343815   -0.117964     0.438196    0.334519    0.342295
 -0.318432     0.0289102   0.814263    -0.144458    -0.0723509    0.241947    -0.325606     0.0339542  -0.381317    0.142531    -0.306174   -0.231886   -0.111683   -0.382734   -0.224018    0.750041    0.45942      0.10122     0.0586212   -0.190549    0.0429121    0.106216     0.0473415   -0.165557    0.183562   -0.177284
 -0.0175237    0.027967   -0.0720374    0.00102198   0.120093    -0.0529369    0.115312     0.0326329  -0.110059    0.0517749   -0.125394   -0.280134   -0.0634055   0.165379    0.204091    0.274082   -0.0578274    0.201966   -0.0924714    0.0868031  -0.0725127    0.0918768    0.0077101    0.0585236   0.0663979   0.164968
 -0.0285145   -0.0635577   0.013105     0.0233405   -0.178812     0.0777808   -0.176517    -0.0465305   0.0696857  -0.0706839    0.0322035   0.299758   -0.0187836  -0.0796128  -0.0639257  -0.158874    0.00560849  -0.111833    0.0508182    0.0185947   0.0150764   -0.0287185   -0.0657708   -0.0129903   0.0376756  -0.0732208
  0.114419    -0.153849    0.377163     0.115976     0.0702432   -0.174041     0.376563    -0.0397588   0.304759   -0.125226     0.211224   -0.372445    0.289333    0.0944056   0.32309     0.12579     0.0636526    0.24794     0.206958    -0.408223    0.28947      0.110352     0.282675    -0.175197    0.175227   -0.298562
  0.00589986   0.0843258   0.478197    -0.437731    -0.171834     0.106405     0.357603     0.388868   -0.0703418  -0.378094    -0.146408    0.415366    0.250839   -0.156981    0.943188   -0.0288936  -0.268459     0.0306822  -0.153237    -0.299988   -0.173293     0.244918     0.00323267  -0.176476    0.0111569  -0.0567747
  0.00158743   0.168217   -0.640799    -0.035125     0.142025    -0.230002     0.393563     0.0347839   0.199383   -0.523373    -0.0937553   0.0796885  -0.339955    0.575816    0.0379677  -0.0846046   0.0687359   -0.281502   -0.184745     0.153193   -0.473417    -0.183048    -0.0717899    0.147404   -0.554687    0.0613936
 -0.389998     0.2437     -0.0843508    0.136037     0.0340745   -0.253119     0.091989    -0.0387738   0.249195   -0.3258      -0.143826    0.497562   -0.381215    0.765955   -0.165256   -0.295066    0.429793     0.357253    0.171012     0.311338   -0.209757     0.00598961  -0.152839    -0.141219    0.370455   -0.303816
  0.0359168    0.736025    0.165839    -0.370829    -0.458908     0.339874     0.433417    -0.0176244   0.128027   -0.115843     0.178234    0.0741441  -0.0555824  -0.21171     0.0268378  -0.285094    0.183815     0.134995    0.45441     -0.175861    0.547788    -0.445777    -0.738165     0.271263   -0.1479     -0.252724
  0.460816     0.449027   -0.283673     0.553598     0.144575    -0.0840675   -0.0920699    0.0175565   0.308705   -0.340537    -0.252539   -0.0836989  -0.0671933   0.151439    0.337608    0.349972   -0.00300931  -0.0854815   0.543878    -0.258913    0.275171     0.220598    -0.159998     0.560852    0.0697482  -0.568833[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.402582
[ Info: iteration 2, average log likelihood -1.402569
[ Info: iteration 3, average log likelihood -1.402556
[ Info: iteration 4, average log likelihood -1.402544
[ Info: iteration 5, average log likelihood -1.402531
[ Info: iteration 6, average log likelihood -1.402519
[ Info: iteration 7, average log likelihood -1.402507
[ Info: iteration 8, average log likelihood -1.402495
[ Info: iteration 9, average log likelihood -1.402483
[ Info: iteration 10, average log likelihood -1.402472
┌ Info: EM with 100000 data points 10 iterations avll -1.402472
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.152449e+05
      1       6.929652e+05      -2.222796e+05 |       32
      2       6.798220e+05      -1.314318e+04 |       32
      3       6.749438e+05      -4.878231e+03 |       32
      4       6.724481e+05      -2.495727e+03 |       32
      5       6.709100e+05      -1.538020e+03 |       32
      6       6.698632e+05      -1.046859e+03 |       32
      7       6.691110e+05      -7.522100e+02 |       32
      8       6.685462e+05      -5.647513e+02 |       32
      9       6.680879e+05      -4.583659e+02 |       32
     10       6.676969e+05      -3.909949e+02 |       32
     11       6.673597e+05      -3.371688e+02 |       32
     12       6.670555e+05      -3.041922e+02 |       32
     13       6.667878e+05      -2.677105e+02 |       32
     14       6.665547e+05      -2.330965e+02 |       32
     15       6.663559e+05      -1.987900e+02 |       32
     16       6.661762e+05      -1.797435e+02 |       32
     17       6.659907e+05      -1.854293e+02 |       32
     18       6.658129e+05      -1.778617e+02 |       32
     19       6.656342e+05      -1.787135e+02 |       32
     20       6.654582e+05      -1.759692e+02 |       32
     21       6.652800e+05      -1.782385e+02 |       32
     22       6.651224e+05      -1.575550e+02 |       32
     23       6.649642e+05      -1.581998e+02 |       32
     24       6.648113e+05      -1.528794e+02 |       32
     25       6.646809e+05      -1.304358e+02 |       32
     26       6.645741e+05      -1.067340e+02 |       32
     27       6.644779e+05      -9.622227e+01 |       32
     28       6.643992e+05      -7.869357e+01 |       32
     29       6.643160e+05      -8.321166e+01 |       32
     30       6.642303e+05      -8.572656e+01 |       32
     31       6.641335e+05      -9.677551e+01 |       32
     32       6.640492e+05      -8.435193e+01 |       32
     33       6.639739e+05      -7.521868e+01 |       32
     34       6.639074e+05      -6.657035e+01 |       32
     35       6.638459e+05      -6.146246e+01 |       32
     36       6.637892e+05      -5.675565e+01 |       32
     37       6.637355e+05      -5.361869e+01 |       32
     38       6.636901e+05      -4.546161e+01 |       32
     39       6.636505e+05      -3.957961e+01 |       32
     40       6.636153e+05      -3.522356e+01 |       32
     41       6.635831e+05      -3.215466e+01 |       32
     42       6.635544e+05      -2.868912e+01 |       32
     43       6.635259e+05      -2.851332e+01 |       32
     44       6.634978e+05      -2.812683e+01 |       32
     45       6.634726e+05      -2.522965e+01 |       32
     46       6.634464e+05      -2.618742e+01 |       32
     47       6.634188e+05      -2.760899e+01 |       32
     48       6.633918e+05      -2.693628e+01 |       32
     49       6.633673e+05      -2.457541e+01 |       32
     50       6.633433e+05      -2.393574e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 663343.3174609931)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414231
[ Info: iteration 2, average log likelihood -1.409169
[ Info: iteration 3, average log likelihood -1.407920
[ Info: iteration 4, average log likelihood -1.407119
[ Info: iteration 5, average log likelihood -1.406286
[ Info: iteration 6, average log likelihood -1.405389
[ Info: iteration 7, average log likelihood -1.404611
[ Info: iteration 8, average log likelihood -1.404091
[ Info: iteration 9, average log likelihood -1.403791
[ Info: iteration 10, average log likelihood -1.403613
[ Info: iteration 11, average log likelihood -1.403495
[ Info: iteration 12, average log likelihood -1.403406
[ Info: iteration 13, average log likelihood -1.403335
[ Info: iteration 14, average log likelihood -1.403273
[ Info: iteration 15, average log likelihood -1.403218
[ Info: iteration 16, average log likelihood -1.403169
[ Info: iteration 17, average log likelihood -1.403123
[ Info: iteration 18, average log likelihood -1.403081
[ Info: iteration 19, average log likelihood -1.403041
[ Info: iteration 20, average log likelihood -1.403003
[ Info: iteration 21, average log likelihood -1.402967
[ Info: iteration 22, average log likelihood -1.402932
[ Info: iteration 23, average log likelihood -1.402899
[ Info: iteration 24, average log likelihood -1.402867
[ Info: iteration 25, average log likelihood -1.402837
[ Info: iteration 26, average log likelihood -1.402808
[ Info: iteration 27, average log likelihood -1.402779
[ Info: iteration 28, average log likelihood -1.402752
[ Info: iteration 29, average log likelihood -1.402726
[ Info: iteration 30, average log likelihood -1.402700
[ Info: iteration 31, average log likelihood -1.402675
[ Info: iteration 32, average log likelihood -1.402651
[ Info: iteration 33, average log likelihood -1.402627
[ Info: iteration 34, average log likelihood -1.402604
[ Info: iteration 35, average log likelihood -1.402582
[ Info: iteration 36, average log likelihood -1.402560
[ Info: iteration 37, average log likelihood -1.402538
[ Info: iteration 38, average log likelihood -1.402517
[ Info: iteration 39, average log likelihood -1.402496
[ Info: iteration 40, average log likelihood -1.402476
[ Info: iteration 41, average log likelihood -1.402455
[ Info: iteration 42, average log likelihood -1.402436
[ Info: iteration 43, average log likelihood -1.402416
[ Info: iteration 44, average log likelihood -1.402398
[ Info: iteration 45, average log likelihood -1.402379
[ Info: iteration 46, average log likelihood -1.402361
[ Info: iteration 47, average log likelihood -1.402344
[ Info: iteration 48, average log likelihood -1.402327
[ Info: iteration 49, average log likelihood -1.402311
[ Info: iteration 50, average log likelihood -1.402295
┌ Info: EM with 100000 data points 50 iterations avll -1.402295
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.458632     0.354182    0.373785    -0.23965     -0.257661    -0.212379     0.375662     0.39636    -0.00590718  -0.6377      -0.223796    0.147688      0.0889653   0.384976     0.705815    -0.548582    -0.583344     0.210256   -0.0276444   -0.164427   -0.364882    0.00209083   0.0401559   -0.476501     -0.0583395  -0.455809
 -0.448018    -0.109051   -0.129621     0.0357241    0.335539    -0.11625      0.274203    -0.0353455  -0.413892    -0.297109    -0.640302   -0.360211     -0.324831    0.48267      0.604469    -0.155705    -0.199091     0.387321    0.438945     0.340833    0.144927    0.106774    -0.140132     0.422655      0.382425    0.0930271
  0.353855     0.058142    0.285883    -0.00125927  -0.331817     0.408073     0.41585      0.173252   -0.0359506   -0.48692      0.194364   -0.0967039     0.315864   -0.118878     0.289066     0.188379     0.00569507   0.19514    -0.549813     0.148359    0.159973    0.751594     0.332035    -0.0706934     0.0664838   0.886241
  0.381317    -0.0261312  -0.166058    -0.178407    -0.0633462   -0.588973     0.665045     0.290641   -0.0406414   -0.0683593    0.372328   -0.509195     -0.0781229   0.254082     0.187213     0.303083    -0.19326      0.756975   -0.186659     0.284915   -0.491532    0.12937     -0.136813     0.230407     -0.293954   -0.118809
 -0.282193    -0.0194733   0.109893    -0.393429    -0.0208408   -0.00717634  -0.208737    -0.606179   -1.04301     -0.0557435    0.511177   -0.5328       -0.722592    0.1349       0.0734716    0.321275    -0.0142522   -0.161951   -0.00804544   0.7729     -0.489649    0.537509     0.040404     0.0308801    -0.203763    0.557324
 -0.191935     0.146923   -0.684626    -0.0997829   -0.194981    -0.0346355   -0.363187    -0.335764   -0.117892     0.00909615   0.363305    0.116391      0.0422463   0.159335    -0.581414    -0.239972     0.00788536  -0.444619    0.149627     0.734616    0.308071   -0.343753     0.0393582    0.172158      0.280209    0.507265
 -0.0211238   -0.170944    0.0657311    0.111419    -0.0640162    0.015833     0.0944991   -0.108547    0.143668    -0.160122     0.0756791   0.000879778   0.0960385   0.285003     0.0929934    0.137457     0.0444087    0.209211    0.107813     0.0311243  -0.0186134   0.215802     0.0811894   -0.0417607     0.0958352  -0.019915
  0.0922586   -0.0516041  -0.131861     0.860623    -0.25015      0.205341    -0.626155    -0.0594625   0.243682    -0.146708     0.447712    0.246801     -0.290116    0.19911     -0.19375     -0.101559    -0.0983331   -0.280484    0.129724     0.179194   -0.153021    0.655539     0.0911436   -0.409         0.218708   -0.473512
  0.224355    -0.0533611  -0.443421     0.252966    -0.00878764   0.00458369  -0.331709    -0.262685   -0.0121332    0.78848      0.440009   -0.147575      0.114179   -0.29623     -0.778148     0.711657     0.592542     0.0277665  -0.214213     0.174795    0.376209    0.15457     -0.387873     0.177086     -0.0690595   0.258197
  0.348459     0.897628    0.148624     0.102542    -0.515879     0.130339    -0.290699     0.373753   -0.0278418   -0.326315     0.0165      0.0589073    -0.374834   -0.121944     0.0764458    0.0725485    0.0853757   -0.239615    0.641753     0.200657    0.320796    0.0386317   -0.515508     0.369638     -0.244481   -0.0765923
  0.188116     0.0401875   0.271271    -0.101234    -0.342169    -0.105907    -0.0181234   -0.0290051   0.233476    -0.127167     0.25219     0.445932      0.194192    0.0272418    0.0374597   -0.49509      0.0679304    0.0616465   0.262945    -0.145714    0.192189   -0.0167878   -0.111794    -0.107505      0.0558457  -0.125768
  0.111061    -0.335117    0.219177    -0.0695485   -0.399452     0.00134014   0.190625    -0.0967528  -0.291395     0.189098     0.592842   -0.590186      0.509356   -0.268645     0.34559     -0.339652    -0.751292    -0.207205    0.220362     0.251432    0.207595   -0.607306     0.427361    -0.405621      0.230687    0.111661
  0.459391     0.0377638   0.0632834    0.499991    -0.123777    -0.00195517   0.16757     -0.0586272   0.327167    -0.141888    -0.188158   -0.169067      0.223853   -0.136496     0.492886     0.289173    -0.430486     0.0566569   0.463309    -0.713906    0.518611    0.195064     0.0411339    0.187505      0.193545   -0.52007
  0.220231     0.627463   -0.772614     0.0856711   -0.0805588   -0.610773    -0.00661821   0.670129    0.143906     0.118407    -0.44795    -0.419815     -0.197401    0.533592     0.375648     0.526083    -0.0115227   -0.378719   -0.345341     0.290073   -0.43839    -0.542611     0.289722     0.316362     -0.205533    0.208341
 -0.23243     -0.254679    0.0753067   -0.855599     0.018312    -0.221978     0.0127955    0.261087   -0.160064     0.500423     0.27532     0.0437268    -0.0850009   0.235697    -0.668529    -0.406713     0.334015     0.643153   -0.800028     0.388653   -0.46794    -0.923086     0.0382351   -0.000663442   0.156865    0.756216
 -0.128536     0.578439    0.497625    -0.82218     -0.301833     0.0742917    0.679854    -0.560329    0.381639     0.0469552    0.346664    0.269779      0.101733   -0.298653    -0.116848    -0.711825     0.364872     0.377015   -0.00465292  -0.234075    0.274439   -0.62561     -0.593137     0.489024     -0.187785   -0.166715
 -0.293945     0.119144    0.10119     -0.44576      0.714843     0.612938     0.419245    -0.254397   -0.154984    -0.122834     0.0942376  -0.621554     -0.219463    0.0728532    0.304502    -0.0744592   -0.0296955   -0.121325    0.782144    -0.344962   -0.168043   -0.462109    -1.01082      0.16659       0.193094   -1.00681
 -0.238985     0.336197    0.0178534   -0.470707     0.332577    -0.0376766    0.0248653    0.443837   -0.680404     0.203417    -0.412901   -0.518559      0.0328665  -0.116785    -0.245109    -0.00267003  -0.232211     0.290492   -0.097197    -0.404127    0.559526   -0.370544    -0.110055    -0.0700376     0.0806923   0.0644043
  0.195215     0.293648   -0.993322     0.259968     0.739771    -0.0655571    0.0395788    0.150117   -0.154395    -0.310889     0.0887138   0.0938352    -0.384942    0.127958    -0.119209    -0.19402     -0.399974    -0.390465   -0.477548    -0.0343291  -0.0979203   0.369192    -0.457352     0.0105351    -0.415284    0.259957
 -0.124486     0.271445    0.300426    -0.0390318    0.528887    -0.235046     0.440007     0.399808    0.458809    -0.364318     0.352187   -0.175734      0.0467117   0.525052     0.405466     0.416023     0.595641     0.049653   -0.101106    -0.265856    0.206385    0.303774     0.295399    -0.349243      0.563432   -0.635148
  0.348431     0.157451   -0.0860162   -0.281119    -0.308458    -0.0301967   -0.072699     0.127189    0.883914     0.49871      0.108088    0.708961     -0.884547    0.545762     0.308397    -0.205858    -0.10763      0.64022    -0.42344      0.602395    0.563524    0.446064     0.330419     0.0931453     0.132778    0.236473
 -0.348097    -0.860192    0.344859    -0.00118861   0.457982     0.0389119    0.615279    -0.10769    -0.139126    -0.592157    -0.373441    0.188693      0.287379   -0.328591     0.321636     0.543585    -0.076346    -0.444511   -0.193071    -0.458344   -0.699189   -0.151277     0.31233      0.0682392     0.229442    0.329743
  0.0821404    0.0247947  -0.236449     0.0817035    0.310974    -0.026114     0.202054    -0.24419     0.542841    -0.173901    -0.23082     0.143489     -0.299939    0.535901    -0.0211251    0.298369     0.621477     0.15093     0.336943    -0.0943847   0.033645    0.0666544   -0.102571     0.265327     -0.111008   -0.278266
  0.3176      -0.211923   -0.0821491    0.511235    -0.11275     -0.550547    -0.591427     0.276621   -0.337835     0.395307    -0.102528    0.273586      0.290961   -0.213059    -0.414854    -0.114694    -0.352585     0.473173   -0.424227     0.365029   -0.127848    0.462232     0.399303    -0.059484      0.172798    0.389324
  0.154976     0.112868    0.489799    -0.46633     -0.195555    -0.0985572   -0.22142     -0.0469502   0.246954     0.364466     0.515818   -0.140984      0.397083   -0.221431    -0.0106367    0.19827      0.132882    -0.933305   -0.143997    -0.508835   -0.231843   -0.09087      0.130392    -0.364309     -0.976983   -0.0896526
 -0.54235     -0.0287977   0.431111    -0.613348     0.277429     0.0968303   -0.433694    -0.353773    0.330238    -0.159506    -0.507274    0.385179      0.243434   -0.243241    -0.36913     -0.489033     0.108649    -0.51402    -0.660228    -0.771711    0.525563    0.114384     0.144389    -0.0340453    -0.347721    0.199321
 -0.233411    -0.0191866   0.555407     0.496587    -0.231688     0.0444775    0.438868    -0.165597   -0.117301    -0.80696      0.133218    0.19931      -0.0379659  -0.0911318   -0.186924     0.381163     0.702128     0.26911    -0.530817    -0.239497   -0.331313    0.776352    -0.30234      0.210844     -0.431003   -0.388031
 -0.21798     -0.247749   -0.355949    -0.22678     -0.0449654   -0.0703939   -0.133007     0.0477671   0.104476    -0.0721885   -0.0540784   0.512136     -0.345153    0.238178    -0.381568    -0.303615     0.0935368   -0.439337   -0.0512627    0.140274   -0.667731   -0.721653    -0.234647    -0.256736     -0.339273   -0.240609
  0.12834     -0.680133   -0.00538123  -0.0887307    0.253426     0.262162    -0.167791    -0.341827   -0.501299     0.231067    -0.14722    -0.216798     -0.0444322  -0.628129    -0.039532     0.139842    -0.419172    -0.193397   -0.136922     0.24924    -0.468624    0.0254114    0.184766     0.0441355    -0.0815573   0.205249
 -0.00088429   0.0109534  -0.0265341    0.0357147   -0.0156564   -0.0125027   -0.0721356    0.0559099  -0.0400053    0.00353445  -0.0108806  -0.0243376    -0.0171169   0.00149644   0.0252096    0.0973238   -0.0353937    0.0231513  -0.107588     0.0570806  -0.0397898   0.0545708   -0.00340074   0.00874824    0.0179061   0.0657156
 -0.330926    -0.117221    0.865406    -0.105493    -0.387128     0.41096     -0.405914    -0.114321    0.087249     0.282569    -0.223287    0.14644       0.0967595  -0.283415     0.00976968   0.576799     0.167368     0.349548    0.328595    -0.151031    0.163445    0.0488465    0.00352228  -0.318441      0.554834   -0.184663
  0.202241    -0.0101211  -0.367901     0.225563    -0.0413374    0.095973     0.0291406    0.397606    0.248762     0.401897    -0.662744    0.0849549     0.507732   -0.41009     -0.120231    -0.367449    -0.121823     0.122268   -0.0162241   -0.391982    0.450653   -0.648951    -0.100008    -0.0951468     0.27494    -0.336117[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.402279
[ Info: iteration 2, average log likelihood -1.402265
[ Info: iteration 3, average log likelihood -1.402250
[ Info: iteration 4, average log likelihood -1.402236
[ Info: iteration 5, average log likelihood -1.402223
[ Info: iteration 6, average log likelihood -1.402210
[ Info: iteration 7, average log likelihood -1.402198
[ Info: iteration 8, average log likelihood -1.402186
[ Info: iteration 9, average log likelihood -1.402174
[ Info: iteration 10, average log likelihood -1.402163
┌ Info: EM with 100000 data points 10 iterations avll -1.402163
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
