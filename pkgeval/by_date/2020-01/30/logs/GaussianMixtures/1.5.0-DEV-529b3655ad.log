Julia Version 1.5.0-DEV.204
Commit 529b3655ad (2020-01-30 07:59 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed GaussianMixtures ─── v0.3.0
  Installed CMake ────────────── v1.1.2
  Installed Blosc ────────────── v0.5.1
  Installed ScikitLearnBase ──── v0.5.0
  Installed NearestNeighbors ─── v0.4.4
  Installed OrderedCollections ─ v1.1.0
  Installed Clustering ───────── v0.13.3
  Installed Parameters ───────── v0.12.0
  Installed Distances ────────── v0.8.2
  Installed Compat ───────────── v2.2.0
  Installed Rmath ────────────── v0.6.0
  Installed QuadGK ───────────── v2.3.1
  Installed BinaryProvider ───── v0.5.8
  Installed BinDeps ──────────── v1.0.0
  Installed Distributions ────── v0.22.4
  Installed Arpack ───────────── v0.4.0
  Installed StatsBase ────────── v0.32.0
  Installed HDF5 ─────────────── v0.12.5
  Installed PDMats ───────────── v0.9.11
  Installed SpecialFunctions ─── v0.9.0
  Installed URIParser ────────── v0.4.0
  Installed CMakeWrapper ─────── v0.2.3
  Installed DataAPI ──────────── v1.1.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed Missings ─────────── v0.4.3
  Installed FillArrays ───────── v0.8.4
  Installed StatsFuns ────────── v0.9.3
  Installed DataStructures ───── v0.17.9
  Installed StaticArrays ─────── v0.12.1
  Installed SortingAlgorithms ── v0.3.1
  Installed Arpack_jll ───────── v3.5.0+2
  Installed FileIO ───────────── v1.2.1
  Installed LegacyStrings ────── v0.4.1
  Installed JLD ──────────────── v0.9.2
#=#=#                                                                                                                                                    0.5%###                                                                        5.1%#######                                                                   10.5%#############                                                             18.6%####################                                                      27.8%############################                                              39.6%#####################################                                     51.8%##################################################                        70.6%#########################################################                 79.8%######################################################################## 100.0%
#=#=#                                                                         ########################################################                  77.9%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_EiRvOm/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -3.0757115546614123e6, [38710.26462570307, 61289.73537429693], [-11687.498418793282 6884.153100158935 -10131.552171595034; 12263.469219196111 -7155.9192125457175 10096.365948436991], [[28778.737978646997 8018.703618178143 12512.843584042083; 8018.703618178144 29649.08594204264 -15427.337879367691; 12512.843584042083 -15427.337879367691 34722.997677293795], [70967.43577922352 -8396.686580520613 -12460.552357282326; -8396.686580520613 71358.72843742264 15274.095959745182; -12460.552357282326 15274.095959745182 64741.33636790248]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.679018e+03
      1       1.182519e+03      -4.964987e+02 |        6
      2       1.106243e+03      -7.627605e+01 |        4
      3       1.056007e+03      -5.023631e+01 |        5
      4       9.959597e+02      -6.004748e+01 |        2
      5       9.903698e+02      -5.589858e+00 |        2
      6       9.839952e+02      -6.374631e+00 |        2
      7       9.801900e+02      -3.805206e+00 |        2
      8       9.752821e+02      -4.907853e+00 |        2
      9       9.660269e+02      -9.255221e+00 |        2
     10       9.651012e+02      -9.257196e-01 |        0
     11       9.651012e+02       0.000000e+00 |        0
K-means converged with 11 iterations (objv = 965.1011723704569)
┌ Info: K-means with 272 data points using 11 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.076384
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.750271
[ Info: iteration 2, lowerbound -3.619821
[ Info: iteration 3, lowerbound -3.487437
[ Info: iteration 4, lowerbound -3.336921
[ Info: iteration 5, lowerbound -3.175563
[ Info: iteration 6, lowerbound -3.012220
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.848977
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.690662
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.564182
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.467897
[ Info: iteration 11, lowerbound -2.405109
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.361041
[ Info: iteration 13, lowerbound -2.328440
[ Info: iteration 14, lowerbound -2.311198
[ Info: iteration 15, lowerbound -2.307828
[ Info: dropping number of Gaussions to 2
[ Info: iteration 16, lowerbound -2.302918
[ Info: iteration 17, lowerbound -2.299260
[ Info: iteration 18, lowerbound -2.299256
[ Info: iteration 19, lowerbound -2.299254
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan 31 04:50:51 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan 31 04:50:59 2020: K-means with 272 data points using 11 iterations
11.3 data points per parameter
, Fri Jan 31 04:51:02 2020: EM with 272 data points 0 iterations avll -2.076384
5.8 data points per parameter
, Fri Jan 31 04:51:04 2020: GMM converted to Variational GMM
, Fri Jan 31 04:51:12 2020: iteration 1, lowerbound -3.750271
, Fri Jan 31 04:51:12 2020: iteration 2, lowerbound -3.619821
, Fri Jan 31 04:51:12 2020: iteration 3, lowerbound -3.487437
, Fri Jan 31 04:51:12 2020: iteration 4, lowerbound -3.336921
, Fri Jan 31 04:51:12 2020: iteration 5, lowerbound -3.175563
, Fri Jan 31 04:51:12 2020: iteration 6, lowerbound -3.012220
, Fri Jan 31 04:51:13 2020: dropping number of Gaussions to 7
, Fri Jan 31 04:51:13 2020: iteration 7, lowerbound -2.848977
, Fri Jan 31 04:51:13 2020: dropping number of Gaussions to 6
, Fri Jan 31 04:51:13 2020: iteration 8, lowerbound -2.690662
, Fri Jan 31 04:51:13 2020: dropping number of Gaussions to 5
, Fri Jan 31 04:51:13 2020: iteration 9, lowerbound -2.564182
, Fri Jan 31 04:51:13 2020: dropping number of Gaussions to 4
, Fri Jan 31 04:51:13 2020: iteration 10, lowerbound -2.467897
, Fri Jan 31 04:51:13 2020: iteration 11, lowerbound -2.405109
, Fri Jan 31 04:51:13 2020: dropping number of Gaussions to 3
, Fri Jan 31 04:51:13 2020: iteration 12, lowerbound -2.361041
, Fri Jan 31 04:51:13 2020: iteration 13, lowerbound -2.328440
, Fri Jan 31 04:51:13 2020: iteration 14, lowerbound -2.311198
, Fri Jan 31 04:51:13 2020: iteration 15, lowerbound -2.307828
, Fri Jan 31 04:51:13 2020: dropping number of Gaussions to 2
, Fri Jan 31 04:51:13 2020: iteration 16, lowerbound -2.302918
, Fri Jan 31 04:51:13 2020: iteration 17, lowerbound -2.299260
, Fri Jan 31 04:51:13 2020: iteration 18, lowerbound -2.299256
, Fri Jan 31 04:51:13 2020: iteration 19, lowerbound -2.299254
, Fri Jan 31 04:51:13 2020: iteration 20, lowerbound -2.299254
, Fri Jan 31 04:51:13 2020: iteration 21, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 22, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 23, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 24, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 25, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 26, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 27, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 28, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 29, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 30, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 31, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 32, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 33, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 34, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 35, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 36, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 37, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 38, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 39, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 40, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 41, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 42, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 43, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 44, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 45, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 46, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 47, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 48, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 49, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: iteration 50, lowerbound -2.299253
, Fri Jan 31 04:51:13 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398614, 178.04509222601388]
β = [95.95490777398614, 178.04509222601388]
m = [2.0002292577753704 53.851987172461286; 4.25030073326991 79.28686694436183]
ν = [97.95490777398614, 180.04509222601388]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948431 -0.008953123827346124; 0.0 0.01274866477740934], [0.18404155547484558 -0.007644049042327319; 0.0 0.00858170516633351]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999988
avll from stats: -0.9787979408053875
avll from llpg:  -0.9787979408053867
avll direct:     -0.9787979408053867
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9822190815075458
avll from llpg:  -0.982219081507546
avll direct:     -0.982219081507546
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.0152024    0.0134527   -0.0446883    0.0269936  -0.144578    0.0314506     0.0162341    0.00554622  -0.0286094   -0.13489     -0.102905     0.0933152    -0.0887887   0.0660479    0.158891     0.0273089   -0.0691192   0.0778788    0.0545079    0.0735439    0.0621702    0.0162288    0.00943957   0.0567306   0.0403888  -0.0456633
 -0.0235379   -0.0836236   -0.0587972   -0.110104   -0.0384996   0.111877     -0.118671    -0.0116391   -0.0763315    0.00272635   0.158483     0.000459886  -0.17367    -0.0666347    0.153639    -0.155828    -0.139435    0.00457266   0.167257     0.0864213    0.0385159   -0.158415    -0.0186168    0.0391373  -0.0946605  -0.119814
  0.184142     0.0596431   -0.0571681    0.155919    0.139421   -0.104805     -0.0594307    0.212912     0.0907085   -0.0285225    0.00780582   0.00514399    0.161901   -0.00151835  -0.0118175    0.0735912    0.0332284   0.00232944  -0.0285669   -0.042053    -0.0845931    0.0358628    0.0782245    0.0875735   0.0712299  -0.127313
 -0.138278    -0.080076     0.0994675    0.0154746  -0.0541319   0.0520463    -0.248791    -0.111144    -0.0944536    0.12971     -0.0456009   -0.0159474    -0.0351788   0.040246    -0.229334    -0.0933165    0.0317905  -0.0128973    0.223544    -0.0473051    0.101487    -0.119206     0.00287022  -0.0591112  -0.0340948  -0.0581217
 -0.0527909    0.0307148   -0.0495385   -0.105238    0.13132     0.0649655    -0.072429    -0.0790885   -0.157771    -0.0330912    0.123715     0.0337591    -0.061398    0.110845    -0.121537    -0.2122       0.129732   -0.00102554   0.159942     0.0295265   -0.0484799   -0.00584962   0.00306107  -0.0840674  -0.118605   -0.021418
  0.199033     0.117355     0.0867835    0.171649    0.0748036   0.104167      0.0143962   -0.0231855    0.0266933    0.0914203   -0.0786613   -0.0607985    -0.0310603   0.0275216   -0.14368      0.0461728   -0.101088    0.0612733   -0.00753659  -0.0909707    0.00617434   0.00148119  -0.0349278   -0.113673   -0.019984    0.0129243
 -0.0593378   -0.0957316   -0.186731     0.154182   -0.134514   -0.161597      0.134164     5.79734e-5   0.0685676   -0.00804966  -0.0267062    0.193201      0.0179364  -0.0652837   -0.111122    -0.0526611    0.0639743  -0.0378895   -0.00145519  -0.0403168   -0.0748378   -0.0396976   -0.0421134   -0.0251023  -0.0752809  -0.133536
 -0.00521625  -0.0920518    0.0185715    0.262215    0.0247478  -0.138371     -0.0429835   -0.039934    -0.137386    -0.071648     0.0386588    0.128481     -0.065483    0.0697446    0.0348628    0.108775    -0.116524    0.0668476   -0.0970695    0.0435973   -0.203125     0.0194569   -0.0842014   -0.0829391   0.0937386   0.0874586
 -0.0819493   -0.00474818  -0.0969259    0.05475     0.0348374  -0.00754355    0.106575     0.0360616   -0.00298798  -0.0117843   -0.0974568   -0.083439     -0.0426214  -0.184757    -0.0051325   -0.0200407    0.0857813   0.070471     0.0429407    0.0678328    0.00340348  -0.0420887   -0.048148     0.036114    0.0397246   0.172554
 -0.132691     0.16345      0.07843      0.0528057   0.104482   -0.139711     -0.0343575    0.0817032   -0.0740173   -0.0715948   -0.0475776   -0.0815219     0.0380128  -0.0774154    0.0198547   -0.0021046    0.160563   -0.177797    -0.0810947    0.0423343    0.0174073    0.0950503    0.0763699   -0.0398576   0.0127178  -0.0666014
  0.106517     0.083146    -0.0429524   -0.20348    -0.030857   -0.039072     -0.0450553    0.0843771   -0.0680911    0.0536894    0.0325474   -0.0698794    -0.0435574  -0.163375    -0.131235     0.071111     0.0258817  -0.00763588   0.128223    -0.0882405    0.197277    -0.0701612   -0.150136     0.0935141  -0.130859    0.0869813
 -0.277899     0.173494     0.0100757   -0.130938    0.032856   -0.0674289    -0.0425922    0.0429382   -0.172753     0.114447     0.123274     0.0931548     0.0101478   0.00271798   0.00301215   0.0485913    0.138004   -0.112557    -0.00617882   0.0317205   -0.126719     0.235819    -0.0798301    0.0605032  -0.135236   -0.0816035
 -0.0557168    0.0541171   -0.264301     0.0691373   0.135724   -0.0222219    -0.124922    -0.00108282   0.0617732    0.017698     0.033835    -0.00367285   -0.0696015   0.110661    -0.129889     0.0644517    0.0510492   0.0221063   -0.014239    -0.046475    -0.0443396    0.129254    -0.0055144   -0.130104   -0.016846   -0.0643045
  0.0240721   -0.197206    -0.0764948    0.212947    0.0867011   0.0164789    -0.0741225   -0.0711207    0.0342119    0.0214364    0.0978635    0.0525623     0.0239309   0.0758458    0.0354117    0.023788    -0.0361215  -0.131977    -0.0457874    0.023882     0.0626545   -0.151161     0.135662    -0.147781   -0.0277001  -0.139913
 -0.205545    -0.113292     0.0514844    0.0856476  -0.0520055   0.0242152     0.0580307   -0.151058    -0.0667782    0.206286    -0.016965    -0.0430978     0.0873078  -0.031929     0.0677419    0.113675    -0.0258224   0.11665     -0.0784028   -0.0832728   -0.0447392   -0.0742607   -0.0645059   -0.137246    0.098481    0.0712859
  0.158846     0.00306127  -0.0518263    0.084406   -0.0255967   0.07206      -0.0208827    0.0522931   -0.016319    -0.0879009    0.0327845    0.0771489    -0.139718   -0.07878     -0.0256435   -0.17484     -0.047042    0.082238    -0.0185394    0.158597     0.00747859   0.0740353   -0.0986694    0.10597     0.0250617   0.0392616
 -0.141548     0.00975749  -0.0859695    0.061575   -0.14627     0.0990032     0.0506287    0.0499762   -0.0459168   -0.0668946    0.0317969    0.00558191   -0.0357155  -0.0129949    0.0947587   -0.0943735    0.132672   -0.226361     0.0607637    2.66593e-5  -0.0896176    0.261451    -0.136523     0.0428548   0.0809697   0.0194419
 -0.0645498    0.0364933    0.0820835    0.137302   -0.0794352   0.105885     -0.00184884   0.141278     0.0715584   -0.0910875    0.212908     0.0238484     0.0814264  -0.132937     0.0338258    0.093212    -0.0664133  -0.271179     0.00260543   0.149614    -0.0278318    0.176194     0.031526     0.190433   -0.0382912  -0.0535351
 -0.164458     0.0602705   -0.0320113    0.102559   -0.0324011  -0.12197      -0.139894    -0.288146    -0.111271    -0.120808    -0.127087    -0.00265193   -0.0465199  -0.186344     0.0400165    0.108227     0.0317977   0.10958      0.0156178   -0.0452144    0.163013    -0.194088     0.0917557   -0.102778    0.0240097   0.152771
  0.169021    -0.0552956   -0.0492929   -0.0947266   0.0888053  -0.00530401   -0.0272943   -0.00503707  -0.0841022    0.116906    -0.0413492   -0.0791062    -0.11161     0.00771858   0.126835     0.00587501  -0.0656802  -0.0419658    0.0893144   -0.139793    -0.00695206   0.0194629    0.145626     0.217145   -0.113069    0.186963
  0.0803719    0.0338621   -0.0695065   -0.102388   -0.0524225  -0.0955871     0.00304955   0.0817449    0.175518    -0.0690552   -0.0269394    0.0300481    -0.159825   -0.153834     0.152951     0.106754     0.115878    0.105473    -0.0387895   -0.119793     0.0979895   -0.0861967    0.020293    -0.0480012  -0.0546183   0.0106444
 -0.0802931    0.0299783    0.0733215    0.0705995  -0.107261   -0.0713913    -0.0108961   -0.050499    -0.104819    -0.0672221    0.0995519    0.0613141    -0.122078    0.0439545   -0.0267851   -0.196479     0.031162    0.0804175    0.159818     0.0862329    0.129647    -0.0926675   -0.126749    -0.132857   -0.115552    0.0688709
  0.145975    -0.0305717   -0.0933375    0.199592    0.122482   -0.0263343     0.0162983    0.176518    -0.081243     0.0514053   -0.0170457   -0.131126     -0.0852455  -0.130725     0.166379    -0.0789054   -0.0486716   0.00033408  -0.069932     0.0309433    0.0462074    0.0705515   -0.21268     -0.16225     0.10431    -0.0429066
 -0.00219577  -0.215967     0.114769    -0.0392863   0.0999825  -0.133908     -0.131336     0.0324519    0.133633    -0.0400291    0.248491    -0.0364781     0.184966   -0.121063    -0.0714686    0.0808309    0.0766584   0.0664373   -0.15761      0.0603685    0.195963    -0.108666     0.0291615   -0.0643734  -0.0857102  -0.130834
 -0.017691    -0.114295     0.00853513  -0.0863643   0.0760124   0.00513232    0.0751687   -0.0748372   -0.124605    -0.0897652   -0.0882728    0.0136937     0.157162   -0.0629295    0.0774571    0.0311982    0.0466555   0.0914858    0.086607    -0.0200286   -0.0221994    0.150691    -0.0361762    0.209078   -0.0407351   0.0333379
  0.0158812    0.167034     0.0834651    0.10547     0.0176494   0.0243181    -0.0174711   -0.061756     0.0515148    0.186765     0.0158035    0.0554782     0.0409901  -0.213061    -0.0383671   -0.0687777   -0.0278512  -0.0254055    0.0212721    0.0229552   -0.0724045   -0.019206     0.0181273    0.115687    0.0861513  -0.0135259
 -0.0292732   -0.0833011    0.0561102    0.0396435  -0.0469238  -0.105744      0.201819     0.0231661   -0.0819789    0.0590793   -0.13645      0.0154055     0.119839   -0.0548229    0.032926     0.0524662   -0.0499613   0.14176     -0.121568    -0.117973    -0.0758127    0.118031     0.128619    -0.120654   -0.0498686   0.0819982
  0.21228     -0.0175678   -0.0523454   -0.0628498   0.0391561   0.199693     -0.106147     0.0079382    0.0684142   -0.103672     0.104829     0.0663783    -0.217187   -0.0541123    0.1415       0.0282015   -0.0377968   0.0694081    0.0736232   -0.0503805   -0.123065    -0.0919958    0.0528449    0.0278506  -0.128934   -0.03899
 -0.114653    -0.00137922   0.00184693  -0.06175     0.237732   -0.0144368    -0.0323633    0.0397562   -0.149106     0.0418982    0.0644865    0.00355983   -0.0493281  -0.014083     0.00545228  -0.0826669    0.0227428   0.0489933    0.0142923    0.119386     0.0293845   -0.023463     0.0625309   -0.0437395  -0.0574012   0.131248
  0.00897861   0.0826719   -0.0168492    0.286807   -0.107606    0.145016     -0.0746898    0.0780838   -0.0378005    0.0266546   -0.155615    -0.122854     -0.0136487  -0.0135778    0.075634     0.0704887   -0.0350061  -0.00364064   0.134006    -0.0309077   -0.0310498    0.280926     0.0511918    0.0652676  -0.023643   -0.0888335
  0.00774889   0.0609002    0.0128377    0.123005    0.0945594  -0.000832923   0.0101933   -0.0723163    0.115739    -0.169396     0.0161429    0.0541327     0.229187   -0.166974     0.069677     0.0921378    0.0847857  -0.165162    -0.0622398    0.0297649   -0.099558     0.0516705    0.0492165    0.233692    0.0246238  -0.0965116
  0.143234    -0.0789705    0.287342     0.0418719   0.1119      0.0351454     0.138823    -0.0688521    0.0037607    0.0966842   -0.050365     0.0411729     0.0105468   0.213009     0.0334342    0.0880208   -0.1032     -0.0652827   -0.0731104    0.0630365   -0.129426    -0.113064     0.0337172   -0.155407    0.0186101   0.0464406kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4491737863846363
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.449260
[ Info: iteration 2, average log likelihood -1.449163
[ Info: iteration 3, average log likelihood -1.448142
[ Info: iteration 4, average log likelihood -1.439827
[ Info: iteration 5, average log likelihood -1.425900
[ Info: iteration 6, average log likelihood -1.420020
[ Info: iteration 7, average log likelihood -1.418059
[ Info: iteration 8, average log likelihood -1.417211
[ Info: iteration 9, average log likelihood -1.416768
[ Info: iteration 10, average log likelihood -1.416469
[ Info: iteration 11, average log likelihood -1.416218
[ Info: iteration 12, average log likelihood -1.415976
[ Info: iteration 13, average log likelihood -1.415727
[ Info: iteration 14, average log likelihood -1.415406
[ Info: iteration 15, average log likelihood -1.414858
[ Info: iteration 16, average log likelihood -1.414049
[ Info: iteration 17, average log likelihood -1.413176
[ Info: iteration 18, average log likelihood -1.412678
[ Info: iteration 19, average log likelihood -1.412391
[ Info: iteration 20, average log likelihood -1.412187
[ Info: iteration 21, average log likelihood -1.412050
[ Info: iteration 22, average log likelihood -1.411967
[ Info: iteration 23, average log likelihood -1.411916
[ Info: iteration 24, average log likelihood -1.411883
[ Info: iteration 25, average log likelihood -1.411861
[ Info: iteration 26, average log likelihood -1.411846
[ Info: iteration 27, average log likelihood -1.411834
[ Info: iteration 28, average log likelihood -1.411824
[ Info: iteration 29, average log likelihood -1.411816
[ Info: iteration 30, average log likelihood -1.411808
[ Info: iteration 31, average log likelihood -1.411803
[ Info: iteration 32, average log likelihood -1.411798
[ Info: iteration 33, average log likelihood -1.411795
[ Info: iteration 34, average log likelihood -1.411793
[ Info: iteration 35, average log likelihood -1.411791
[ Info: iteration 36, average log likelihood -1.411790
[ Info: iteration 37, average log likelihood -1.411790
[ Info: iteration 38, average log likelihood -1.411789
[ Info: iteration 39, average log likelihood -1.411789
[ Info: iteration 40, average log likelihood -1.411789
[ Info: iteration 41, average log likelihood -1.411789
[ Info: iteration 42, average log likelihood -1.411789
[ Info: iteration 43, average log likelihood -1.411789
[ Info: iteration 44, average log likelihood -1.411789
[ Info: iteration 45, average log likelihood -1.411789
[ Info: iteration 46, average log likelihood -1.411789
[ Info: iteration 47, average log likelihood -1.411789
[ Info: iteration 48, average log likelihood -1.411789
[ Info: iteration 49, average log likelihood -1.411789
[ Info: iteration 50, average log likelihood -1.411789
┌ Info: EM with 100000 data points 50 iterations avll -1.411789
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4492603142440674
│     -1.4491626326090683
│      ⋮
└     -1.4117886378698985
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411951
[ Info: iteration 2, average log likelihood -1.411817
[ Info: iteration 3, average log likelihood -1.411381
[ Info: iteration 4, average log likelihood -1.406948
[ Info: iteration 5, average log likelihood -1.391161
[ Info: iteration 6, average log likelihood -1.378476
[ Info: iteration 7, average log likelihood -1.373474
[ Info: iteration 8, average log likelihood -1.370715
[ Info: iteration 9, average log likelihood -1.369182
[ Info: iteration 10, average log likelihood -1.368278
[ Info: iteration 11, average log likelihood -1.367731
[ Info: iteration 12, average log likelihood -1.367410
[ Info: iteration 13, average log likelihood -1.367216
[ Info: iteration 14, average log likelihood -1.367090
[ Info: iteration 15, average log likelihood -1.367002
[ Info: iteration 16, average log likelihood -1.366936
[ Info: iteration 17, average log likelihood -1.366880
[ Info: iteration 18, average log likelihood -1.366831
[ Info: iteration 19, average log likelihood -1.366786
[ Info: iteration 20, average log likelihood -1.366743
[ Info: iteration 21, average log likelihood -1.366703
[ Info: iteration 22, average log likelihood -1.366665
[ Info: iteration 23, average log likelihood -1.366631
[ Info: iteration 24, average log likelihood -1.366599
[ Info: iteration 25, average log likelihood -1.366570
[ Info: iteration 26, average log likelihood -1.366543
[ Info: iteration 27, average log likelihood -1.366520
[ Info: iteration 28, average log likelihood -1.366499
[ Info: iteration 29, average log likelihood -1.366481
[ Info: iteration 30, average log likelihood -1.366464
[ Info: iteration 31, average log likelihood -1.366450
[ Info: iteration 32, average log likelihood -1.366438
[ Info: iteration 33, average log likelihood -1.366428
[ Info: iteration 34, average log likelihood -1.366420
[ Info: iteration 35, average log likelihood -1.366413
[ Info: iteration 36, average log likelihood -1.366407
[ Info: iteration 37, average log likelihood -1.366403
[ Info: iteration 38, average log likelihood -1.366399
[ Info: iteration 39, average log likelihood -1.366395
[ Info: iteration 40, average log likelihood -1.366393
[ Info: iteration 41, average log likelihood -1.366390
[ Info: iteration 42, average log likelihood -1.366388
[ Info: iteration 43, average log likelihood -1.366387
[ Info: iteration 44, average log likelihood -1.366385
[ Info: iteration 45, average log likelihood -1.366384
[ Info: iteration 46, average log likelihood -1.366383
[ Info: iteration 47, average log likelihood -1.366382
[ Info: iteration 48, average log likelihood -1.366381
[ Info: iteration 49, average log likelihood -1.366380
[ Info: iteration 50, average log likelihood -1.366379
┌ Info: EM with 100000 data points 50 iterations avll -1.366379
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4119506470923942
│     -1.4118170975467714
│      ⋮
└     -1.3663794207350544
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.366568
[ Info: iteration 2, average log likelihood -1.366379
[ Info: iteration 3, average log likelihood -1.365472
[ Info: iteration 4, average log likelihood -1.358585
[ Info: iteration 5, average log likelihood -1.343141
[ Info: iteration 6, average log likelihood -1.328915
[ Info: iteration 7, average log likelihood -1.318924
[ Info: iteration 8, average log likelihood -1.312949
[ Info: iteration 9, average log likelihood -1.309827
[ Info: iteration 10, average log likelihood -1.308313
[ Info: iteration 11, average log likelihood -1.307348
[ Info: iteration 12, average log likelihood -1.306512
[ Info: iteration 13, average log likelihood -1.305708
[ Info: iteration 14, average log likelihood -1.304998
[ Info: iteration 15, average log likelihood -1.304413
[ Info: iteration 16, average log likelihood -1.303779
[ Info: iteration 17, average log likelihood -1.303018
[ Info: iteration 18, average log likelihood -1.302311
[ Info: iteration 19, average log likelihood -1.301757
[ Info: iteration 20, average log likelihood -1.301305
[ Info: iteration 21, average log likelihood -1.300943
[ Info: iteration 22, average log likelihood -1.300707
[ Info: iteration 23, average log likelihood -1.300572
[ Info: iteration 24, average log likelihood -1.300489
[ Info: iteration 25, average log likelihood -1.300434
[ Info: iteration 26, average log likelihood -1.300394
[ Info: iteration 27, average log likelihood -1.300361
[ Info: iteration 28, average log likelihood -1.300331
[ Info: iteration 29, average log likelihood -1.300297
[ Info: iteration 30, average log likelihood -1.300255
[ Info: iteration 31, average log likelihood -1.300198
[ Info: iteration 32, average log likelihood -1.300111
[ Info: iteration 33, average log likelihood -1.299974
[ Info: iteration 34, average log likelihood -1.299772
[ Info: iteration 35, average log likelihood -1.299492
[ Info: iteration 36, average log likelihood -1.299158
[ Info: iteration 37, average log likelihood -1.298874
[ Info: iteration 38, average log likelihood -1.298704
[ Info: iteration 39, average log likelihood -1.298619
[ Info: iteration 40, average log likelihood -1.298574
[ Info: iteration 41, average log likelihood -1.298545
[ Info: iteration 42, average log likelihood -1.298525
[ Info: iteration 43, average log likelihood -1.298509
[ Info: iteration 44, average log likelihood -1.298498
[ Info: iteration 45, average log likelihood -1.298489
[ Info: iteration 46, average log likelihood -1.298481
[ Info: iteration 47, average log likelihood -1.298476
[ Info: iteration 48, average log likelihood -1.298471
[ Info: iteration 49, average log likelihood -1.298467
[ Info: iteration 50, average log likelihood -1.298464
┌ Info: EM with 100000 data points 50 iterations avll -1.298464
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3665683113856733
│     -1.366379265162309
│      ⋮
└     -1.2984636071405395
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.298716
[ Info: iteration 2, average log likelihood -1.298446
[ Info: iteration 3, average log likelihood -1.297546
[ Info: iteration 4, average log likelihood -1.287489
[ Info: iteration 5, average log likelihood -1.258126
[ Info: iteration 6, average log likelihood -1.233778
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.217731
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.215192
[ Info: iteration 9, average log likelihood -1.230751
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.206732
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.222384
[ Info: iteration 12, average log likelihood -1.221701
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.200786
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.204139
[ Info: iteration 15, average log likelihood -1.235550
[ Info: iteration 16, average log likelihood -1.213406
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.195202
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.199762
[ Info: iteration 19, average log likelihood -1.234422
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.210439
[ Info: iteration 21, average log likelihood -1.210880
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.194757
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.212459
[ Info: iteration 24, average log likelihood -1.230859
[ Info: iteration 25, average log likelihood -1.205777
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.190889
[ Info: iteration 27, average log likelihood -1.228630
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.206920
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.207124
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.207440
[ Info: iteration 31, average log likelihood -1.222992
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.203559
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.204567
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.207230
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.220654
[ Info: iteration 36, average log likelihood -1.219507
[ Info: iteration 37, average log likelihood -1.199778
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     10
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.185399
[ Info: iteration 39, average log likelihood -1.241651
[ Info: iteration 40, average log likelihood -1.215432
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.196424
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.201898
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.217856
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.216825
[ Info: iteration 45, average log likelihood -1.213075
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.196346
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.214727
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.214274
[ Info: iteration 49, average log likelihood -1.212977
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.194070
┌ Info: EM with 100000 data points 50 iterations avll -1.194070
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2987157568938381
│     -1.298445690933294
│      ⋮
└     -1.19406955255825
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.231242
[ Info: iteration 2, average log likelihood -1.209454
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     19
│     20
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.187645
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     12
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.176814
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     12
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.142618
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.127929
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.097101
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│      8
│     12
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.129604
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     12
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.124635
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.102422
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.093416
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      7
│     12
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.119855
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      8
│     12
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.100581
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.112888
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.105077
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.113201
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      8
│     12
│     25
│     26
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.101793
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.117517
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.091759
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.117931
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      8
│     12
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.107564
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.107094
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.098625
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.122625
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      8
│     12
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.096452
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.112715
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.103316
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│     12
│     19
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.111443
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      8
│     12
│     25
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.103839
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.117427
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.091720
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.117799
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      8
│     12
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.107186
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.106322
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.099665
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.122086
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      7
│      8
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.094203
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.114303
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.104462
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.112832
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      8
│     12
│     25
│     26
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.101605
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.115233
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.087489
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.122478
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      7
│     12
│     25
│     26
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.092476
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      8
│     12
│     19
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.101814
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.108383
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     12
│     19
│     20
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.115399
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     12
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.107227
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      8
│     12
│     19
│     20
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.102845
┌ Info: EM with 100000 data points 50 iterations avll -1.102845
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2312415324143937
│     -1.2094538089001534
│      ⋮
└     -1.1028453043918691
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4491737863846363
│     -1.4492603142440674
│     -1.4491626326090683
│     -1.4481419638869264
│      ⋮
│     -1.1153985108235298
│     -1.1072270156763757
└     -1.1028453043918691
32×26 Array{Float64,2}:
 -0.0319726   -0.123563      0.0209289     0.25893       0.0239035   -0.133597     -0.0439829    -0.0182257   -0.138187    -0.0728867    0.0151287    0.129932     -0.0382334    0.0672464    0.0255285    0.108662    -0.118876     0.053503    -0.0984947    0.0482926    -0.191254     0.047207    -0.0430947  -0.0793564   0.0879824     0.147807
  0.172998    -0.0716217     0.291826     -0.050056      0.128726     0.0428837     0.120308     -0.129001     0.00930076   0.113796    -0.095162     0.0406488     0.0114502    0.20042      0.0444379    0.0869929   -0.112485    -0.100634    -0.0768914    0.0634637    -0.180346    -0.113049     0.0625486  -0.160918    0.0138446     0.0613316
 -0.13569     -0.0199971    -0.103285      0.0566992    -0.102673     0.0903608     0.0330476     0.026158    -0.0301204   -0.0661521    0.0289379   -0.00104353   -0.0360558   -0.022404     0.103422    -0.0908156    0.119273    -0.225613     0.0674873    0.00572906   -0.0875274    0.257203    -0.134208    0.0290022   0.0801947    -0.0191895
  0.0300874   -0.0715594     0.0343691    -0.000115658   0.00287434  -0.0151646    -0.0832416    -0.0073254    0.0243617   -0.0741304    0.141682     0.0358302    -0.0529546   -0.0411187    0.00484807  -0.0401872    0.0280959    0.0492019    0.0248138    0.0337401     0.0594462   -0.0866399    0.0074832  -0.05777    -0.107053     -0.0312262
 -0.00410713  -0.11755       0.0118706    -0.0823145     0.0643318    0.0725486     0.103384     -0.149507    -1.35653     -0.102459    -0.0950107    0.0182629     0.160203    -0.0742372    0.0672649    0.0804484    0.0775592    0.147968     0.114053    -0.000835805   0.0587769    0.0618161   -0.121487    0.228908    0.101866      0.0544562
 -0.037292    -0.113122      0.00571235   -0.086392      0.123122    -0.0918029     0.0236196     0.0550233    1.49485      0.224928    -0.0477884    0.000187515   0.158708    -0.0821638    0.0992768   -0.131865     0.0374754    0.0875763    0.0766816   -0.0450005    -0.121079     0.301917     0.0301237   0.199456   -0.191591      0.0155739
  0.152808    -0.0943567    -0.0975393    -0.041063      0.123079    -0.114714     -0.0371741     0.0597486    0.00968536  -0.102389    -0.0960295   -0.0033076     0.111378    -0.0495736    0.0540503    0.134942     0.06387      0.00320074   0.0413315   -0.104191     -0.029426     0.0516602   -0.0734513   0.129986   -0.0433113    -0.0317447
  0.186699    -0.0502387    -0.0663609    -0.0913911     0.0889531   -0.00418464   -0.0223709    -0.0216399   -0.0886618    0.114752    -0.014663    -0.0794341    -0.120937     0.00479608   0.121502     0.00714959  -0.0532988   -0.0402412    0.0921873   -0.136884     -0.0260632    0.0276366    0.160198    0.201028   -0.113135      0.186092
 -0.0490915   -0.0347648     0.0646093     0.358874     -0.0436852    0.138689     -0.0144782     0.125796     0.106032    -0.108155     0.0254097   -0.391003      0.0824117   -0.128079     0.0502054    0.0912371   -0.0696315   -0.45537     -0.00350697   0.165483      0.0146166    0.171588     0.0728602   0.162165   -0.0424145    -0.0314386
 -0.0857256    0.0749833     0.0906299    -0.11948      -0.0807189    0.0371476     0.0133316     0.127397     0.0552258   -0.0388725    0.381205     0.490505      0.0719814   -0.128516     0.0224538    0.122829    -0.0676575   -0.0852399    0.00651978   0.124263     -0.0801869    0.177374    -0.0278942   0.10412    -0.037702     -0.0833827
  0.0203413    0.163177      0.084442      0.101757      0.0215209    0.0605586    -0.0171843    -0.059942     0.0641796    0.198633     0.00311326   0.0587353     0.049592    -0.223218    -0.0462768   -0.0651328   -0.0317936   -0.00770547   0.0204517    0.0378156    -0.128625    -0.0140901    0.0200463   0.157598    0.0868029    -0.0256514
 -0.0457456   -0.1117       -0.136361      0.140909     -0.117496    -0.13999       0.129393     -0.00406937   0.0243742   -0.00302493  -0.0211516    0.189313      0.0236996   -0.0496385   -0.10584     -0.0184833    0.0442713   -0.0279987   -0.00433568  -0.0290445    -0.0553898   -0.0405279   -0.0438143  -0.0369693  -0.0639869    -0.133694
 -0.140409    -0.00968131    0.0840573    -0.0284282    -0.0660427    0.0506547    -0.261083     -0.112363    -0.0899922    0.115759    -0.043546    -0.00983212   -0.0303621    0.044751    -0.215278    -0.0948295    0.0252804   -0.0266448    0.27919     -0.0469922     0.0991954   -0.13981     -0.033886   -0.0566254  -0.0492777    -0.0574436
  0.00932577   0.0738403     0.000951742   0.287032     -0.10094      0.145121     -0.0803303     0.0907682   -0.0379445    0.0334208   -0.16988     -0.141111     -0.0380417   -0.0177311    0.0968837    0.0593653   -0.032227     0.00921343   0.111893     0.000532572  -0.0412334    0.275159     0.0508274   0.05895    -0.0252725    -0.0829925
  0.190182     0.0966975     0.0792256     0.156264      0.0740399    0.103138      0.000394601  -0.0187866    0.0260015    0.0882304   -0.134647    -0.051294     -0.0121077    0.00384399  -0.143337    -0.00804694  -0.0390954    0.0669003   -0.00903973  -0.0890468     0.0107714   -0.00605526  -0.0311674  -0.112396   -0.0321752     0.012283
 -0.0570212   -0.04566      -0.0277145     0.033547     -0.00809357  -0.0564046     0.149647      0.0324253   -0.0185401    0.0332316   -0.114811    -0.0550912     0.0521491   -0.109545     0.0045682    0.0522186    0.0133943    0.0924608   -0.0402289   -0.0119103    -0.0282491    0.0466843    0.0526522  -0.0310354  -0.000482441   0.12101
  0.108674     0.0355252    -0.0982522    -0.0953945    -0.0731538   -0.126451      0.00434844    0.097748     0.177515    -0.0672734   -0.0264545    0.0318072    -0.162314    -0.19211      0.135591     0.0982406    0.115195     0.106889    -0.0393475   -0.114608      0.0895565   -0.0732321    0.0157637  -0.0655169  -0.149019     -0.0170533
  0.0233067   -0.195239     -0.0739278     0.220656      0.092945    -0.0432281    -0.0635946    -0.084399     0.0322295    0.0196751    0.0947955    0.0563277    -0.0182775    0.0773262    0.0497724    0.00250651  -0.0289357   -0.155855    -0.0451109   -0.0398389     0.0230342   -0.118004     0.155196   -0.151432   -0.0255981    -0.123581
 -0.295213     0.172363      0.0173889    -0.128991      0.061386    -0.0349369    -0.0401974     0.0303433   -0.169432     0.114881     0.124014     1.09218       0.00331456  -0.00270007   0.00746949   0.0571201    0.130073    -0.113823    -0.0169907    0.0304635    -0.125532     0.2354      -0.086791    0.0542974  -0.132844     -0.0182694
 -0.280139     0.173012      0.0147164    -0.137056      0.0497705   -0.0902481    -0.0385105     0.0589093   -0.172009     0.114896     0.122686    -0.971591      0.0453709    0.00243038  -0.015401     0.0495218    0.17242     -0.116811    -0.00168295   0.0468118    -0.127732     0.230614    -0.0602304   0.0393484  -0.138345     -0.191616
 -0.19851     -0.112283      0.0440866     0.0749048    -0.0158884    0.04366       0.0574252    -0.118309    -0.0692371    0.291395    -0.0248037   -0.0549508     0.0674712   -0.0285088    0.0573126    0.112731    -0.0268709    0.14574     -0.10529     -0.103134     -0.0177716   -0.0616196   -0.0579965  -0.139763    0.0615149     0.10505
  0.0697681    0.0298253    -0.046799     -0.0620867     0.0291134    0.0595688    -0.0449197    -0.00204921  -0.0797999   -0.0644716    0.0772069    0.081075     -0.101454    -0.0332153   -0.0706644   -0.203498     0.0358514    0.0231755    0.0784426    0.0794935     0.00458681   0.033987    -0.0395465   0.0247093  -0.0332254     0.00824828
 -0.098591     0.00929348   -0.0450171    -0.01086      -0.0361149   -0.0138816    -0.121779     -0.163551    -0.0747462   -0.0633117    0.0340461    0.00556353   -0.107274    -0.119879     0.0894764   -0.0339164   -0.0205281    0.0565803    0.0832463    0.0108016     0.0868936   -0.173778     0.0544991  -0.0446688  -0.041046      0.0236331
  0.0517579   -0.00784588   -0.165986      0.140931      0.137003    -0.020169     -0.0164223     0.0943836   -0.0243511   -0.0160162    0.0235123   -0.0622258    -0.0589038   -0.003194     0.0109767   -0.00971792   0.005407     0.0164505   -0.041647    -0.000571361   0.0337631    0.083263    -0.104435   -0.168123    0.0391627    -0.0560144
 -0.11185     -0.000312164   0.0255709    -0.0646607     0.277753    -0.0106311    -0.0167958     0.0512712   -0.184092     0.0532931    0.0756648    0.00921477   -0.0664465   -0.00397778   0.00125933  -0.0784437   -0.0493705    0.0444011    0.0106915    0.116557      0.0456785   -0.0523662    0.0604954  -0.0582221  -0.0685801     0.128845
  0.101599     0.0821761    -0.0540578    -0.206543     -0.0182553   -0.042315     -0.0460073     0.0864922   -0.0836578    0.0583575    0.0179322   -0.0726487    -0.0443068   -0.167943    -0.132352     0.0691814    0.00645444  -0.025515     0.112583    -0.0750328     0.213349    -0.0810808   -0.1523      0.0399371  -0.133274      0.116138
 -0.0380861    0.0336126    -0.0328245     0.0228611    -0.0622494   -0.645455      0.404512      0.00360293  -0.0279405   -0.120957    -0.10609      0.0552684    -0.104048     0.030156     0.105238    -0.119292    -0.0955655    0.0761726    0.295176     0.163552     -0.0306768    0.022823    -0.0405758   0.0486873   0.0657857    -0.00570249
 -0.00311205  -0.00951853   -0.044492      0.0253321    -0.190236     0.579883     -0.19488       0.0110814   -0.0268846   -0.12973     -0.0832937    0.107758     -0.0851123    0.0991026    0.161323     0.146947    -0.0879254    0.0731445   -0.158182     0.00277105    0.181706     0.0194672    0.0551562   0.0466851   0.0137447    -0.0931096
  0.0128885    0.0602854     0.0121987     0.110894      0.122058    -0.000915928   0.0159626    -0.0721665    0.109999    -0.168575     0.0188504    0.108306      0.224675    -0.163706     0.066114     0.0947467    0.104627    -0.160175    -0.0561961    0.0257913    -0.101368     0.0496896    0.0589142   0.196928    0.0233249    -0.0518181
  0.259272     0.0423235    -0.060962      0.161123      0.118026    -0.0985593    -0.0860471     0.211604     0.092765    -0.0394609   -0.0267719   -0.0121356     0.144332     0.00362024  -0.0109641    0.0728959    0.0400145    0.0108205   -0.0381452   -0.035847     -0.0831028    0.00850539   0.0308731   0.125508    0.0146607    -0.125653
 -0.128688     0.163201      0.0720153     0.00138102    0.0547561   -0.138746     -0.0144625     0.0959804   -0.0515868   -0.067479    -0.0453754   -0.0886652     0.0227828   -0.086008     0.0179056   -0.0224824    0.176575    -0.161658    -0.0867206    0.0338285     0.0282753    0.0828612    0.0788548  -0.0404532   0.0552057    -0.0401463
  0.0678951    0.0747667     0.0165943     0.125678      0.105075    -0.101833     -0.0691762     0.202352     0.0478483   -0.0426133    0.00744669   0.0176991     0.157637    -0.00566632  -0.0114756    0.0805667    0.0116042    0.00854702  -0.0243632   -0.0249129    -0.0831214    0.0600558    0.124271    0.0282272   0.0627296    -0.135017[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.094279
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│     12
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.067440
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.081895
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      8
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.056810
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.093285
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│     12
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.066570
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│     12
│     18
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.082629
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      8
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.057657
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      7
│     12
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.081851
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│     12
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.073669
┌ Info: EM with 100000 data points 10 iterations avll -1.073669
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.394115e+05
      1       7.276308e+05      -2.117808e+05 |       32
      2       6.930724e+05      -3.455833e+04 |       32
      3       6.773676e+05      -1.570486e+04 |       32
      4       6.692044e+05      -8.163201e+03 |       32
      5       6.649029e+05      -4.301494e+03 |       32
      6       6.621485e+05      -2.754348e+03 |       32
      7       6.601220e+05      -2.026549e+03 |       32
      8       6.580900e+05      -2.031985e+03 |       32
      9       6.565219e+05      -1.568043e+03 |       32
     10       6.557268e+05      -7.951655e+02 |       32
     11       6.552874e+05      -4.393976e+02 |       32
     12       6.549960e+05      -2.913826e+02 |       32
     13       6.547517e+05      -2.442949e+02 |       32
     14       6.544477e+05      -3.039869e+02 |       32
     15       6.540121e+05      -4.356162e+02 |       32
     16       6.534755e+05      -5.365728e+02 |       32
     17       6.530135e+05      -4.620157e+02 |       32
     18       6.525448e+05      -4.687539e+02 |       32
     19       6.518852e+05      -6.595838e+02 |       32
     20       6.513053e+05      -5.798737e+02 |       32
     21       6.509402e+05      -3.650608e+02 |       32
     22       6.507534e+05      -1.868719e+02 |       32
     23       6.506569e+05      -9.647291e+01 |       32
     24       6.505835e+05      -7.344207e+01 |       32
     25       6.504932e+05      -9.030381e+01 |       32
     26       6.503915e+05      -1.016194e+02 |       32
     27       6.502703e+05      -1.212141e+02 |       32
     28       6.500720e+05      -1.982859e+02 |       32
     29       6.497988e+05      -2.732771e+02 |       32
     30       6.496134e+05      -1.853515e+02 |       32
     31       6.495546e+05      -5.880132e+01 |       32
     32       6.495357e+05      -1.889452e+01 |       30
     33       6.495239e+05      -1.179236e+01 |       27
     34       6.495162e+05      -7.761116e+00 |       30
     35       6.495102e+05      -5.988056e+00 |       28
     36       6.495043e+05      -5.846579e+00 |       25
     37       6.494980e+05      -6.363270e+00 |       30
     38       6.494891e+05      -8.885243e+00 |       29
     39       6.494777e+05      -1.139441e+01 |       26
     40       6.494665e+05      -1.118958e+01 |       27
     41       6.494536e+05      -1.284152e+01 |       31
     42       6.494414e+05      -1.227795e+01 |       32
     43       6.494298e+05      -1.154057e+01 |       27
     44       6.494201e+05      -9.731163e+00 |       30
     45       6.494088e+05      -1.124839e+01 |       28
     46       6.493987e+05      -1.013008e+01 |       28
     47       6.493906e+05      -8.074336e+00 |       26
     48       6.493848e+05      -5.859697e+00 |       26
     49       6.493796e+05      -5.137400e+00 |       30
     50       6.493750e+05      -4.650399e+00 |       28
K-means terminated without convergence after 50 iterations (objv = 649374.9947816842)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.357966
[ Info: iteration 2, average log likelihood -1.323937
[ Info: iteration 3, average log likelihood -1.292143
[ Info: iteration 4, average log likelihood -1.252250
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.199016
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.168991
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.149300
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.139760
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     10
│     21
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.095266
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.120420
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      9
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.123774
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     12
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.114352
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     18
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.106900
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.126483
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      9
│     10
│     18
│     23
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.065406
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│      6
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.156322
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.137919
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     17
│     18
│     21
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.064892
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.105692
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.148971
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     10
│     12
│     18
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.097340
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.118197
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│      9
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.090933
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.135572
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.121352
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     12
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.084021
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│     10
│     18
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.072407
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.159980
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.116037
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     12
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.066784
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│     10
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.111020
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.144438
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.090909
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.099252
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      7
│     10
│     11
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.076309
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     18
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.102575
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.110163
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.099976
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│     10
│     18
│     22
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.055976
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.132076
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.100832
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     12
│     18
│     23
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.065206
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│     10
│     11
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.099826
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.152689
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.101760
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.077583
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      7
│     10
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.082389
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.102745
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     21
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.110184
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.106277
┌ Info: EM with 100000 data points 50 iterations avll -1.106277
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0792321   -0.011816      0.0077625     0.100492    -0.115927    -0.0950822    0.0337651   -0.0424274   -0.111112    -0.0605689    0.0804372    0.0990398   -0.0919705    0.0286629   -0.0560653    -0.177357     0.0425918   -0.00329074   0.0934902    0.069069     0.0732989   -0.0900652   -0.114906   -0.110769   -0.10011      0.0216083
 -0.0616548    0.0111338     0.0617107     0.131298    -0.0683877    0.0638842    0.0104843    0.118248     0.0816004   -0.0599325    0.182248     0.0575021    0.0688205   -0.118436     0.0241756     0.0897613   -0.0666587   -0.257724     5.33157e-5   0.13349     -0.0345741    0.169703     0.0142327   0.106707   -0.0419004   -0.062964
 -0.0142902   -0.114658      0.0136148    -0.0840035    0.0914334   -0.0062641    0.0665191   -0.0557552   -0.0766996    0.0392064   -0.0828482    0.0104599    0.1576      -0.0748387    0.0795386    -0.00882283   0.0554577    0.119311     0.0943145   -0.0239147   -0.020225     0.16463     -0.0534224   0.209616   -0.0269164    0.0355062
  0.200286    -0.00826705   -0.0656996    -0.0578949    0.0381249    0.169549    -0.108253     0.0047123    0.0667156   -0.103114     0.0993488    0.0675604   -0.205235    -0.0560381    0.142903      0.0253689   -0.0310881    0.0628291    0.0662367   -0.0733218   -0.11545     -0.0452675    0.0641953   0.0234001  -0.120749    -0.0425528
 -0.113324    -0.00166229    0.0162915    -0.0641816    0.255674    -0.0166428   -0.0152812    0.0495902   -0.16783      0.0480508    0.0696763    0.0103091   -0.0632841   -0.00767141   0.00535495   -0.0815138   -0.0384664    0.039536     0.00935036   0.113548     0.0612113   -0.0478286    0.0436279  -0.0456865  -0.0692018    0.129412
  0.0554916   -0.146533      0.00295044    0.193203    -0.0734735   -0.143385     0.111518    -0.0318059    0.0395672    0.0310556   -0.0720455    0.163115     0.0662376   -0.00218404  -0.053432      2.75964e-5   0.0184717   -0.0411847   -0.0311545   -0.0239611   -0.10104     -0.0422092   -0.0516562  -0.0591981  -0.0399932   -0.0955146
  0.175332     0.0505239    -0.037715      0.149857     0.11168     -0.100519    -0.0718057    0.209449     0.0750514   -0.0355191   -0.0104352    0.00536019   0.153835     0.00261421  -0.0134116     0.071866     0.0323522    0.0107319   -0.0301052   -0.0330257   -0.0847054    0.0278445    0.065665    0.0870439   0.041181    -0.130237
  0.107439     0.0361888    -0.0953432    -0.0935106   -0.0750302   -0.127903     0.00400275   0.0989688    0.178092    -0.06672     -0.0261317    0.0317324   -0.163065    -0.191249     0.136712      0.0986176    0.115712     0.107315    -0.0382642   -0.111082     0.0914234   -0.0753177    0.0188748  -0.0676565  -0.144866    -0.0200689
  0.0247005   -0.196257     -0.0731541     0.21882      0.0925367   -0.0459251   -0.062606    -0.0901298    0.0321986    0.0203891    0.0948586    0.0578403   -0.0169988    0.0819726    0.0449407     0.00322534  -0.0302208   -0.155332    -0.0450935   -0.0441293    0.0268064   -0.117315     0.157103   -0.152285   -0.0262764   -0.124877
 -0.0161798    0.0111067    -0.0396783     0.0259286   -0.151233     0.0477133    0.0693309    0.00758203  -0.0299188   -0.125378    -0.0963044    0.0893156   -0.0942617    0.0728381    0.135104      0.0373783   -0.0937382    0.0762745    0.0431874    0.067468     0.0853478    0.0237286    0.0124766   0.050366    0.0364674   -0.0607222
  0.178616    -0.0516663    -0.0863925    -0.0843384    0.0634064   -0.00957827  -0.0192693   -0.0189666   -0.0869484    0.123678    -0.0429561   -0.0533963   -0.114449     0.00711236   0.108332      0.00492851  -0.0483568   -0.0357279    0.091364    -0.163142    -0.0336581    0.0207165    0.152345    0.195167   -0.10702      0.155924
 -0.0337504    0.0385739    -0.223382      0.0587408    0.133033    -0.0107875   -0.0618997   -0.0114615    0.0534315   -0.0246781    0.0306328    0.0149916   -0.0597638    0.164221    -0.134141      0.0867171    0.0200143    2.59635e-5  -0.016788    -0.037857    -0.0409633    0.111851     0.026901   -0.163052   -0.0197513   -0.0637389
 -0.125788     0.159347      0.0654221     0.00472288   0.0439665   -0.139368    -0.0114391    0.0926769   -0.0500047   -0.0668738   -0.049065    -0.0780883    0.0261021   -0.0876116    0.0134671    -0.0152597    0.173284    -0.146414    -0.0843996    0.0231817    0.0218472    0.079154     0.0794618  -0.0403495   0.0490167   -0.0423453
 -0.00401106   0.0758487    -0.0379167    -0.154358     0.0763532    0.0409594   -0.0696915   -0.0659802   -0.139418    -0.0305969    0.121149     0.108091    -0.0701323    0.0414068   -0.0977826    -0.215418     0.128421    -0.0174303    0.16573      0.0306428   -0.0162237    0.0155137    0.0212187  -0.0968723  -0.109423    -0.0147281
  0.0345753   -0.215967      0.112713     -0.0338951    0.0920362   -0.122466    -0.0940518    0.017076     0.126328    -0.0258992    0.242102    -0.0247916    0.140113    -0.118072    -0.0604597     0.0807134    0.054675     0.0373834   -0.126176     0.0714329    0.14055     -0.0915147    0.0810641  -0.042884   -0.0800443   -0.116317
 -0.0383009   -0.0562974    -0.0605244    -0.109766    -0.0508737    0.0993797   -0.116953    -0.0133225   -0.0588558    0.0148664    0.175283     0.0358769   -0.174605    -0.0574785    0.144011     -0.158979    -0.0814497    0.00248255   0.153335     0.090918     0.0364181   -0.157076    -0.0029668   0.025222   -0.110028    -0.116972
  0.0186315    0.15938       0.0782126     0.101191     0.016303     0.0526593   -0.0172053   -0.0597117    0.0672815    0.192249    -0.00214905   0.0627031    0.0491708   -0.219347    -0.0478374    -0.0637008   -0.0311751   -0.00872537   0.0197494    0.0372152   -0.123211    -0.0146853    0.0182402   0.151584    0.0821687   -0.027921
  0.10173      0.0811882    -0.0476627    -0.19977     -0.00626964  -0.0414361   -0.0420232    0.0859334   -0.086632     0.0534648    0.0171664   -0.0673414   -0.0462051   -0.157532    -0.121054      0.0685736    0.00614626  -0.0257873    0.110914    -0.0690206    0.210077    -0.0738141   -0.147286    0.0238978  -0.125651     0.110704
 -0.115863    -1.8607       -0.126022      0.0243888   -0.0328225    0.0478573   -0.313006    -0.0849988   -0.110064     0.303211     0.011171     0.0225073   -0.107323     0.047362    -0.27462      -0.0925659    0.0324917    0.0365077    0.314166    -0.046205     0.111375    -0.249058     0.126424   -0.0498834  -0.0493096   -0.0575579
  0.102355    -0.0517283    -0.0918815     0.184035     0.142648    -0.0189675    0.0507483    0.177378    -0.0861352    0.00959777   0.00322221  -0.148497    -0.0487219   -0.144863     0.145108     -0.0736113   -0.0348087    0.0193271   -0.0895108    0.0319584    0.0794678    0.0352074   -0.214284   -0.157422    0.0889883   -0.0297248
  0.140465    -0.0884393     0.183362     -0.101946     0.100063     0.0763098    0.0973121   -0.13055      0.00301588   0.10527     -0.132847     0.0439557    0.0498294    0.13479      0.0459422     0.0379846   -0.0953838   -0.116987    -0.0574046    0.0725663   -0.293912    -0.0504062    0.0430667  -0.206394    0.021881     0.0777908
  0.0183623    0.0626014     0.00911625    0.108938     0.118369    -0.00175698   0.0148006   -0.0725578    0.108594    -0.163378     0.0193757    0.103814     0.229005    -0.149781     0.0575388     0.0949628    0.107017    -0.165076    -0.0571499    0.0287339   -0.101714     0.0560994    0.0566862   0.200158    0.0231702   -0.0496321
 -0.306887     0.182359      0.0199578    -0.147739     0.0729881   -0.0959307   -0.0327533    0.0410483   -0.167401     0.107656     0.113791     0.055955     0.0687025   -0.00807672  -0.000412602   0.0743926    0.17328     -0.107343    -0.0224156    0.0437296   -0.137836     0.209162    -0.0746611   0.0666739  -0.129258    -0.13832
 -0.196902    -0.110199      0.0430631     0.0736092   -0.0146216    0.0429051    0.0578152   -0.117533    -0.069379     0.290867    -0.0241304   -0.0521098    0.0656911   -0.0265278    0.0574546     0.112653    -0.028944     0.146132    -0.105928    -0.101796    -0.0202022   -0.06197     -0.0579144  -0.139887    0.0574767    0.0991167
  0.00913074   0.0729544    -0.000664764   0.286332    -0.0996948    0.145109    -0.0798187    0.0901683   -0.0350203    0.0337993   -0.169798    -0.142523    -0.0378588   -0.017986     0.0964081     0.0573947   -0.0319573    0.00919965   0.112304     0.00205212  -0.043065     0.276672     0.0506681   0.058929   -0.0252795   -0.083222
  0.149535     0.000782345  -0.0244234     0.042293    -0.0194137    0.0868841   -0.00286425   0.117649    -0.0120918   -0.0664145    0.0234458    0.0734462   -0.200888    -0.0670267   -0.0272306    -0.171332    -0.0764501    0.0863378   -0.0197573    0.199479     0.058403     0.0535884   -0.0854084   0.169116    0.0373021    0.0382529
 -0.149146     0.534762      0.144092     -0.0424345   -0.0778478    0.0516182   -0.246535    -0.120599    -0.0852034    0.0615227   -0.060741    -0.0185358   -0.00642792   0.0443625   -0.199403     -0.0956974    0.0250512   -0.0453224    0.268122    -0.0475416    0.0957786   -0.111584    -0.0822208  -0.0589705  -0.0492574   -0.0576025
 -0.143446     0.0694347    -0.0283327     0.0919624   -0.031074    -0.108434    -0.126155    -0.296632    -0.103895    -0.136007    -0.100857    -0.0285324   -0.039445    -0.191429     0.0305481     0.0707857    0.0312318    0.114491     0.0310684   -0.0770319    0.164146    -0.181993     0.0916111  -0.107603    0.0422716    0.162023
 -0.00703686  -0.114953      0.0630336     0.23522      0.0374808   -0.116529    -0.0245205   -0.0446362   -0.123919    -0.0661626   -0.0271469    0.116387    -0.023046     0.0819467    0.0263483     0.102664    -0.115678     0.0389477   -0.0918254    0.0516231   -0.220278     0.0312692   -0.0237773  -0.0823288   0.0732579    0.157144
 -0.165515     0.018618     -0.0900695     0.026206    -0.0822093    0.0903169    0.0264883    0.024453    -0.0544356   -0.0390042    0.0420961    0.00503705  -0.0440339   -0.020306     0.0862214    -0.0796861    0.124857    -0.228367     0.0592748    0.0104321   -0.094806     0.256527    -0.128427    0.0360497   0.0453357   -0.0453706
 -0.0560637   -0.0496313    -0.0265175     0.0308887   -0.00925604  -0.0549156    0.149926     0.0310586   -0.0178519    0.032157    -0.117271    -0.0480191    0.0482724   -0.104301     0.00433565    0.0549569    0.0128699    0.0878861   -0.0324969   -0.0211074   -0.0409949    0.0437214    0.0512522  -0.0294613  -0.00698583   0.115819
  0.186964     0.0941562     0.0751915     0.156834     0.0739884    0.102911     0.00173334  -0.0186565    0.026234     0.0882189   -0.133379    -0.0473263   -0.0126326    0.00238491  -0.143283     -0.00865602  -0.0361251    0.0639256   -0.00910967  -0.0867116    0.00806241  -0.00599661  -0.0307468  -0.11118    -0.0327254    0.0107519[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│     10
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.055006
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│     10
│     11
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.016562
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      7
│      9
│     10
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.027339
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│     10
│     11
│      ⋮
│     23
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.029352
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      7
│     10
│     12
│     18
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.027510
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      7
│      9
│     10
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.004855
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│     10
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.043486
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      5
│      7
│     10
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.017129
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│      9
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.019388
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│     10
│     11
│      ⋮
│     23
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.034856
┌ Info: EM with 100000 data points 10 iterations avll -1.034856
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.157543     0.111907    -0.140129    0.162058     -0.0425263    0.10257     -0.0747856   -0.0844624   -0.0326581     0.0175119     0.0332486    -0.02527       0.0381003   -0.0220724     0.0627435   -0.0822101  -0.228621      0.215096    -0.0966208   -0.0580716    0.0474927    0.076619    -0.146035     0.224942     0.20449       0.215131
 -0.0627229    0.0634474   -0.0445412   0.167577     -0.0701378    0.0417075    0.123162     0.12657      0.0443167    -0.0640197    -0.0618305    -0.128578     -0.0205561    0.0608889     0.253478    -0.0725065   0.116099     -0.0613194    0.06781      0.146858    -0.0164456   -0.0708093    0.0230266   -0.0685558    0.0149793     0.0707216
 -0.00505268   0.135535    -0.0430816  -0.183224      0.0653923    0.0353787    0.00249374  -0.094794    -0.0785344    -0.0268953    -0.0215388    -0.0801691     0.0963945   -0.0562513    -0.11578      0.0860423  -0.0534725     0.101459     0.105519    -0.0487782   -0.00333866  -0.0554449   -0.0831434    0.0409241   -0.0167455     0.0344752
  0.162912     0.00308154  -0.0551763  -0.206924      0.0346513    0.039001    -0.0988174   -0.0199004   -0.0295034     0.0790659    -0.0734525     0.000236666  -0.114269    -0.0219418    -0.0430765   -0.056833    0.000521238   0.0291613   -0.0207885    0.0319699   -0.133023    -0.0298369   -0.129949    -0.0511034   -0.0877707    -0.0578699
  0.140709    -0.125773    -0.290243    0.0164647    -0.0401735    0.220701     0.178741    -0.0154525   -0.042472     -0.0518057    -0.149042     -0.0519026     0.216505     0.123476     -0.0749462    0.0510571  -0.134747     -0.0129436   -0.102787    -0.228001    -0.163377    -0.0940319    0.0136337   -0.0226032   -0.0526674    -0.0647999
 -0.0871578   -0.115678     0.0825114  -0.0503481    -0.0788473    0.0320711    0.11454      0.0405949   -0.00684807    0.280546     -0.00269129    0.153707     -0.144657    -0.20702      -0.0597607    0.0549241   0.138815     -0.0146445    0.0670407   -0.129351     0.00696706   0.0410993    0.160698    -0.0633735   -0.106056     -0.0440259
  0.0722156   -0.137426     0.0550091   0.026746      0.0985127    0.0148897    0.295206     0.0338295    0.0651831     0.0904579    -0.0739627    -0.209678     -0.0190708    0.000651029   0.0992464    0.0141237  -0.0580019    -0.111752    -0.188032     0.0693107    0.0836572    0.0548188    0.0634746   -0.0676926    0.000883261   0.167035
 -0.0766668   -0.113045    -0.110028   -0.0768246     0.0229846    0.0226893    0.102298     0.059936     0.0960802    -0.0497252     0.0756478     0.193479     -0.0567525   -0.0391833     0.106509     0.17306    -0.0449963     0.268498    -0.0327395   -0.110421     0.094301     0.0359251   -0.00547428   0.0650944   -0.0284398     0.0175527
 -0.0809324    0.0201229   -0.0375647   0.17627      -0.0458248   -0.0307125    0.0707083   -0.21952     -0.0830115    -0.0112634    -0.0833237    -0.136177     -0.0554545    0.148871     -0.0329409   -0.043618    0.0784951     0.0405412    0.133672    -0.00865169  -0.0372497    0.035708    -0.028532     0.131265     0.0639458     0.23435
 -0.0866085    0.133081    -0.0224264   0.103057     -0.116821    -0.0243026   -0.157491     0.152613     0.167696     -0.0155629     0.118072      0.00717355    0.0644334   -0.00633194   -0.00323917   0.121425    0.0753085    -0.128116    -0.0983053    0.0193957    0.0132254    0.0891394    0.0179913    0.0278494   -0.061718      0.029917
 -0.156066     0.277743    -0.0978971   0.233937     -0.103222    -0.148729     0.0208254    0.178482     0.079165     -0.00762472   -0.133798     -0.0252003    -0.00554017   0.00303781   -0.0380861    0.0834093  -0.083635     -0.0051556   -0.114665    -0.0903456   -0.0793531    0.129011     0.0757142    0.0156183    0.0295715    -0.005184
  0.0652021   -0.138946    -0.0600617   0.000856615  -0.0944329   -0.055089    -0.098998     0.0139598    0.0442686     0.134239     -0.141776      0.10193      -0.195558    -0.183059     -0.126195    -0.0227302   0.00217386    0.00294351   0.039433    -0.0112144   -0.171187     0.0416641    0.0833571    0.116091    -0.17338       0.11416
 -0.0132673    0.00458859  -0.0383252  -0.025422      0.0632409   -0.24441      0.027118    -0.0892345    0.187179      0.0153646    -0.0587166    -0.295835      0.0850944    0.0520671    -0.115512    -0.095475   -0.105518      0.0274232    0.0478592   -0.0078857   -0.147702     0.112383    -0.0646157    0.00408115   0.112793     -0.073649
  0.0229947   -0.0115049   -0.23441     0.0101982    -0.068979     0.0963102   -0.100054     0.0500242    0.0908956    -0.00287496   -0.0718307     0.0549155     0.223532    -0.0652941     0.200733     0.0206295  -0.10079       0.0895549    0.305958     0.0794394   -0.0712793   -0.130884    -0.0102269    0.0829929    0.000499383  -0.0219434
  0.0094892   -0.154988     0.131756   -0.025766     -0.0526456   -0.0362433    0.126472    -0.0524746    0.0538306    -0.0759171    -0.109966      0.0697111     0.25426     -0.153122     -0.00797572   0.0495959  -0.0331499    -0.0605929   -0.207076     0.220051    -0.109727    -0.0587793    0.106927     0.126679     0.125663     -0.178045
  0.128438     0.0787746   -0.154447    0.0187488     0.0896714   -0.0537446   -0.0200226   -0.00236429  -0.032067      0.0517525    -0.0489661     0.0754446     0.0460002    0.010201     -0.0168449    0.026963    0.111882     -0.0100669   -0.0339227    0.0361566   -0.0428475   -0.0789563   -0.132493     0.0049173   -0.0338836    -0.059772
  0.025321     0.135966     0.0537971   0.00862838   -0.103257    -0.19167     -0.0610303   -0.00190697   0.10309      -0.0662649    -0.0814303    -0.0746839    -0.0551522    0.0405832     0.0321628    0.0104313  -0.0484985    -0.0545925   -0.0178932    0.0155347    0.0267276    0.0230648   -0.00585444  -0.0115391    0.0158663     0.00188188
  0.0940976    0.0143495    0.10872    -0.147726     -0.00877779   0.0438038    0.0181243   -0.0617291    0.0473755     0.0644371    -0.100874      0.127312      0.0800326    0.0481424     0.0472967    0.123778   -0.202706      0.142466     0.107464     0.0310482   -0.0569666    0.137151     0.223641     0.0197167   -0.0542082    -0.145542
 -0.211674     0.0447222   -0.0861383  -0.0809381    -0.0751505   -0.00217211   0.00300189   0.00456132   0.00957847    0.0839167    -0.105849      0.0267797     0.0181005    0.0547834     0.0888677   -0.220842    0.0527064     0.0595236    0.0382876   -0.127176     0.212461    -0.0797029    0.0530849   -0.0995964    0.0826245     0.171434
  0.0280903   -0.0146083    0.0482489  -0.00172447   -0.0724405   -0.0114362   -0.0593327    0.0347985    0.232164     -0.161279     -0.0480274    -0.040596      0.0470222   -0.199579     -0.00615669  -0.149489    0.0227769    -0.0569137   -0.102346    -0.229922    -0.0761465    0.0167367    0.16698     -0.15089      0.109268     -0.0583074
  0.193062     0.0407516   -0.122086    0.0982945     0.0551105   -0.0437083   -0.102205     0.0876028   -0.0120292    -0.154366      0.0358063     0.0317401    -0.0319228    0.139502      0.0262798    0.0354123   0.10048       0.0985515   -0.0510119   -0.0567836    0.058889    -0.126541    -0.0995362   -0.0405643   -0.065926     -0.240698
  0.0433759    0.225104    -0.0705186  -0.0486411     0.0161851    0.0229703   -0.0865295   -0.142149    -0.0147553    -0.000286683  -0.000510817   0.0302626     0.0944558   -0.144875      0.0364424   -0.0536319  -0.156736      0.0558473    0.0561186   -0.0905942    0.132566     0.150789     0.0424774   -0.0445641   -0.0319697     0.0475419
  0.221469    -0.0570073   -0.0392359   0.173845      0.0487322   -0.0241422    0.143858     0.122659     0.102748     -0.216933      0.0194345    -0.139097     -0.0448286   -0.068029     -0.161107     0.0257075   0.0856549    -0.0718098   -0.158473    -0.138799    -0.00742724  -0.0913752   -0.130953    -0.153378    -0.0322247     0.0726678
  0.00638966  -0.00737188   0.142156   -0.0295842     0.0479616   -0.0214264    0.0858826    0.025309    -0.0494695     0.0515093     0.0855889    -0.0712945     0.248661     0.0317931     0.00848331  -0.0524972   0.101463     -0.0194529    0.206021    -0.13121     -0.169503    -0.199632    -0.101144    -0.189073     0.0148118    -0.0829373
 -0.0771106    0.0519269   -0.109796    0.0244894     0.0301178    0.205613    -0.135276    -0.0334548   -0.0165082     0.0535882    -0.0938015     0.102156     -0.0312306   -0.0934867    -0.159365     0.289354    0.13665      -0.0182405   -0.0705505   -0.0174476    0.014574     0.0316667   -0.012327    -0.056645     0.00801585   -0.0442235
  0.00392158   0.0297638   -0.0607129  -0.0638287    -0.00752122   0.105514    -0.0848227    0.0411314   -0.000313702  -0.0938379     0.0889613    -0.144541     -0.0895864    0.0927855     0.00338906  -0.10596    -0.090288     -0.0473178   -0.0657377   -0.0136702    0.116352    -0.0104972   -0.0373749    0.0637841   -0.206922      0.100499
 -0.127562    -0.230612     0.0653445  -0.000872278   0.0227506    0.014061     0.0585356    0.124363    -0.151756     -0.000777766   0.0309967    -0.109481      0.0704258    0.0327205     0.094893     0.126032   -0.0847306     0.0585141   -0.101788    -0.194075     0.0440655   -0.155799    -0.0648591    0.177331    -0.0185466     0.0311211
  0.0353898   -0.0435574   -0.0649546   0.0741131     0.110285    -0.0962827   -0.0144978    0.039835    -0.207664     -0.168037     -0.108919     -0.102317     -0.155944    -0.0779806    -0.0746314    0.286832    0.161841     -0.104264    -0.0638091    0.0537362    0.0870042   -0.0673224   -0.0723834    0.0724342    0.0342308    -0.06851
 -0.11633      0.0596309   -0.0425915   0.050298     -0.112454     0.109937     0.194641    -0.0369009    0.000793744  -0.0859586    -0.0655651     0.031015     -0.00687088   0.068111     -0.09422     -0.174775    0.109019      0.0197183    0.00931028   0.34688     -0.0373766    0.0450546    0.054495    -0.0142104   -0.0793133    -0.0136971
  0.0627306   -0.0487718   -0.0477555  -0.0395183     0.00427227   0.0482558    0.125554     0.185352     0.0389908     0.148189     -0.0556999     0.113176      0.185894     0.120877      0.044395    -0.184577    0.007072      0.00668191  -0.0144024    0.026779    -0.122751     0.00433001  -0.0839682    0.137108     0.00857703    0.0502186
 -0.00285361   0.00647868  -0.0868915   0.14256      -0.0692768   -0.26868     -0.0627675    0.217719     0.146749      0.0521953     0.12089      -0.15611       0.137811    -0.0129074    -0.116074     0.0205777  -0.0201777     0.0330218   -0.00540372   0.127774    -0.00353721  -0.0358406    0.0288498   -0.033742     0.045348      0.0473111
 -0.135197     0.0141901   -0.0276712  -0.0116728     0.0151635    0.0938203   -0.0330019   -0.0601601   -0.308395      0.0333835     0.182752     -0.0292405    -0.0363174   -0.161901     -0.0825353   -0.0106321   0.0605358     0.0871192    0.0733183    0.00932378   0.0417742   -0.186973     0.13454      0.0583625    0.0106587    -0.0990607kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4309164132639982
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.430936
[ Info: iteration 2, average log likelihood -1.430845
[ Info: iteration 3, average log likelihood -1.430771
[ Info: iteration 4, average log likelihood -1.430686
[ Info: iteration 5, average log likelihood -1.430586
[ Info: iteration 6, average log likelihood -1.430470
[ Info: iteration 7, average log likelihood -1.430339
[ Info: iteration 8, average log likelihood -1.430179
[ Info: iteration 9, average log likelihood -1.429950
[ Info: iteration 10, average log likelihood -1.429574
[ Info: iteration 11, average log likelihood -1.428957
[ Info: iteration 12, average log likelihood -1.428081
[ Info: iteration 13, average log likelihood -1.427125
[ Info: iteration 14, average log likelihood -1.426377
[ Info: iteration 15, average log likelihood -1.425946
[ Info: iteration 16, average log likelihood -1.425744
[ Info: iteration 17, average log likelihood -1.425657
[ Info: iteration 18, average log likelihood -1.425621
[ Info: iteration 19, average log likelihood -1.425605
[ Info: iteration 20, average log likelihood -1.425599
[ Info: iteration 21, average log likelihood -1.425596
[ Info: iteration 22, average log likelihood -1.425594
[ Info: iteration 23, average log likelihood -1.425594
[ Info: iteration 24, average log likelihood -1.425593
[ Info: iteration 25, average log likelihood -1.425593
[ Info: iteration 26, average log likelihood -1.425592
[ Info: iteration 27, average log likelihood -1.425592
[ Info: iteration 28, average log likelihood -1.425592
[ Info: iteration 29, average log likelihood -1.425592
[ Info: iteration 30, average log likelihood -1.425592
[ Info: iteration 31, average log likelihood -1.425592
[ Info: iteration 32, average log likelihood -1.425592
[ Info: iteration 33, average log likelihood -1.425591
[ Info: iteration 34, average log likelihood -1.425591
[ Info: iteration 35, average log likelihood -1.425591
[ Info: iteration 36, average log likelihood -1.425591
[ Info: iteration 37, average log likelihood -1.425591
[ Info: iteration 38, average log likelihood -1.425591
[ Info: iteration 39, average log likelihood -1.425591
[ Info: iteration 40, average log likelihood -1.425591
[ Info: iteration 41, average log likelihood -1.425591
[ Info: iteration 42, average log likelihood -1.425591
[ Info: iteration 43, average log likelihood -1.425591
[ Info: iteration 44, average log likelihood -1.425591
[ Info: iteration 45, average log likelihood -1.425591
[ Info: iteration 46, average log likelihood -1.425591
[ Info: iteration 47, average log likelihood -1.425591
[ Info: iteration 48, average log likelihood -1.425591
[ Info: iteration 49, average log likelihood -1.425591
[ Info: iteration 50, average log likelihood -1.425591
┌ Info: EM with 100000 data points 50 iterations avll -1.425591
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4309356518158638
│     -1.4308447453277704
│      ⋮
└     -1.4255906444324171
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425606
[ Info: iteration 2, average log likelihood -1.425523
[ Info: iteration 3, average log likelihood -1.425451
[ Info: iteration 4, average log likelihood -1.425365
[ Info: iteration 5, average log likelihood -1.425263
[ Info: iteration 6, average log likelihood -1.425149
[ Info: iteration 7, average log likelihood -1.425033
[ Info: iteration 8, average log likelihood -1.424928
[ Info: iteration 9, average log likelihood -1.424841
[ Info: iteration 10, average log likelihood -1.424773
[ Info: iteration 11, average log likelihood -1.424721
[ Info: iteration 12, average log likelihood -1.424683
[ Info: iteration 13, average log likelihood -1.424656
[ Info: iteration 14, average log likelihood -1.424637
[ Info: iteration 15, average log likelihood -1.424623
[ Info: iteration 16, average log likelihood -1.424613
[ Info: iteration 17, average log likelihood -1.424605
[ Info: iteration 18, average log likelihood -1.424599
[ Info: iteration 19, average log likelihood -1.424595
[ Info: iteration 20, average log likelihood -1.424591
[ Info: iteration 21, average log likelihood -1.424587
[ Info: iteration 22, average log likelihood -1.424584
[ Info: iteration 23, average log likelihood -1.424582
[ Info: iteration 24, average log likelihood -1.424579
[ Info: iteration 25, average log likelihood -1.424577
[ Info: iteration 26, average log likelihood -1.424575
[ Info: iteration 27, average log likelihood -1.424573
[ Info: iteration 28, average log likelihood -1.424571
[ Info: iteration 29, average log likelihood -1.424569
[ Info: iteration 30, average log likelihood -1.424567
[ Info: iteration 31, average log likelihood -1.424565
[ Info: iteration 32, average log likelihood -1.424563
[ Info: iteration 33, average log likelihood -1.424561
[ Info: iteration 34, average log likelihood -1.424558
[ Info: iteration 35, average log likelihood -1.424556
[ Info: iteration 36, average log likelihood -1.424554
[ Info: iteration 37, average log likelihood -1.424552
[ Info: iteration 38, average log likelihood -1.424549
[ Info: iteration 39, average log likelihood -1.424547
[ Info: iteration 40, average log likelihood -1.424544
[ Info: iteration 41, average log likelihood -1.424542
[ Info: iteration 42, average log likelihood -1.424539
[ Info: iteration 43, average log likelihood -1.424536
[ Info: iteration 44, average log likelihood -1.424533
[ Info: iteration 45, average log likelihood -1.424530
[ Info: iteration 46, average log likelihood -1.424527
[ Info: iteration 47, average log likelihood -1.424524
[ Info: iteration 48, average log likelihood -1.424521
[ Info: iteration 49, average log likelihood -1.424518
[ Info: iteration 50, average log likelihood -1.424514
┌ Info: EM with 100000 data points 50 iterations avll -1.424514
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.425606272593838
│     -1.42552290731682
│      ⋮
└     -1.4245141202001272
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424522
[ Info: iteration 2, average log likelihood -1.424441
[ Info: iteration 3, average log likelihood -1.424364
[ Info: iteration 4, average log likelihood -1.424267
[ Info: iteration 5, average log likelihood -1.424142
[ Info: iteration 6, average log likelihood -1.423988
[ Info: iteration 7, average log likelihood -1.423817
[ Info: iteration 8, average log likelihood -1.423647
[ Info: iteration 9, average log likelihood -1.423494
[ Info: iteration 10, average log likelihood -1.423368
[ Info: iteration 11, average log likelihood -1.423269
[ Info: iteration 12, average log likelihood -1.423193
[ Info: iteration 13, average log likelihood -1.423136
[ Info: iteration 14, average log likelihood -1.423094
[ Info: iteration 15, average log likelihood -1.423062
[ Info: iteration 16, average log likelihood -1.423038
[ Info: iteration 17, average log likelihood -1.423019
[ Info: iteration 18, average log likelihood -1.423004
[ Info: iteration 19, average log likelihood -1.422992
[ Info: iteration 20, average log likelihood -1.422982
[ Info: iteration 21, average log likelihood -1.422974
[ Info: iteration 22, average log likelihood -1.422966
[ Info: iteration 23, average log likelihood -1.422960
[ Info: iteration 24, average log likelihood -1.422954
[ Info: iteration 25, average log likelihood -1.422949
[ Info: iteration 26, average log likelihood -1.422944
[ Info: iteration 27, average log likelihood -1.422939
[ Info: iteration 28, average log likelihood -1.422935
[ Info: iteration 29, average log likelihood -1.422932
[ Info: iteration 30, average log likelihood -1.422928
[ Info: iteration 31, average log likelihood -1.422925
[ Info: iteration 32, average log likelihood -1.422922
[ Info: iteration 33, average log likelihood -1.422919
[ Info: iteration 34, average log likelihood -1.422916
[ Info: iteration 35, average log likelihood -1.422913
[ Info: iteration 36, average log likelihood -1.422911
[ Info: iteration 37, average log likelihood -1.422909
[ Info: iteration 38, average log likelihood -1.422906
[ Info: iteration 39, average log likelihood -1.422904
[ Info: iteration 40, average log likelihood -1.422902
[ Info: iteration 41, average log likelihood -1.422900
[ Info: iteration 42, average log likelihood -1.422898
[ Info: iteration 43, average log likelihood -1.422896
[ Info: iteration 44, average log likelihood -1.422894
[ Info: iteration 45, average log likelihood -1.422892
[ Info: iteration 46, average log likelihood -1.422891
[ Info: iteration 47, average log likelihood -1.422889
[ Info: iteration 48, average log likelihood -1.422887
[ Info: iteration 49, average log likelihood -1.422885
[ Info: iteration 50, average log likelihood -1.422884
┌ Info: EM with 100000 data points 50 iterations avll -1.422884
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4245219623766736
│     -1.4244414574695135
│      ⋮
└     -1.422883692719214
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422890
[ Info: iteration 2, average log likelihood -1.422840
[ Info: iteration 3, average log likelihood -1.422793
[ Info: iteration 4, average log likelihood -1.422739
[ Info: iteration 5, average log likelihood -1.422671
[ Info: iteration 6, average log likelihood -1.422589
[ Info: iteration 7, average log likelihood -1.422494
[ Info: iteration 8, average log likelihood -1.422389
[ Info: iteration 9, average log likelihood -1.422280
[ Info: iteration 10, average log likelihood -1.422174
[ Info: iteration 11, average log likelihood -1.422074
[ Info: iteration 12, average log likelihood -1.421984
[ Info: iteration 13, average log likelihood -1.421902
[ Info: iteration 14, average log likelihood -1.421829
[ Info: iteration 15, average log likelihood -1.421764
[ Info: iteration 16, average log likelihood -1.421706
[ Info: iteration 17, average log likelihood -1.421656
[ Info: iteration 18, average log likelihood -1.421612
[ Info: iteration 19, average log likelihood -1.421574
[ Info: iteration 20, average log likelihood -1.421540
[ Info: iteration 21, average log likelihood -1.421511
[ Info: iteration 22, average log likelihood -1.421484
[ Info: iteration 23, average log likelihood -1.421461
[ Info: iteration 24, average log likelihood -1.421439
[ Info: iteration 25, average log likelihood -1.421419
[ Info: iteration 26, average log likelihood -1.421401
[ Info: iteration 27, average log likelihood -1.421384
[ Info: iteration 28, average log likelihood -1.421367
[ Info: iteration 29, average log likelihood -1.421351
[ Info: iteration 30, average log likelihood -1.421336
[ Info: iteration 31, average log likelihood -1.421321
[ Info: iteration 32, average log likelihood -1.421307
[ Info: iteration 33, average log likelihood -1.421293
[ Info: iteration 34, average log likelihood -1.421280
[ Info: iteration 35, average log likelihood -1.421267
[ Info: iteration 36, average log likelihood -1.421254
[ Info: iteration 37, average log likelihood -1.421242
[ Info: iteration 38, average log likelihood -1.421230
[ Info: iteration 39, average log likelihood -1.421218
[ Info: iteration 40, average log likelihood -1.421207
[ Info: iteration 41, average log likelihood -1.421196
[ Info: iteration 42, average log likelihood -1.421185
[ Info: iteration 43, average log likelihood -1.421174
[ Info: iteration 44, average log likelihood -1.421164
[ Info: iteration 45, average log likelihood -1.421154
[ Info: iteration 46, average log likelihood -1.421144
[ Info: iteration 47, average log likelihood -1.421135
[ Info: iteration 48, average log likelihood -1.421125
[ Info: iteration 49, average log likelihood -1.421116
[ Info: iteration 50, average log likelihood -1.421108
┌ Info: EM with 100000 data points 50 iterations avll -1.421108
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4228902007714097
│     -1.422840398573819
│      ⋮
└     -1.4211077244867676
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421108
[ Info: iteration 2, average log likelihood -1.421044
[ Info: iteration 3, average log likelihood -1.420983
[ Info: iteration 4, average log likelihood -1.420913
[ Info: iteration 5, average log likelihood -1.420827
[ Info: iteration 6, average log likelihood -1.420725
[ Info: iteration 7, average log likelihood -1.420607
[ Info: iteration 8, average log likelihood -1.420476
[ Info: iteration 9, average log likelihood -1.420338
[ Info: iteration 10, average log likelihood -1.420198
[ Info: iteration 11, average log likelihood -1.420060
[ Info: iteration 12, average log likelihood -1.419929
[ Info: iteration 13, average log likelihood -1.419805
[ Info: iteration 14, average log likelihood -1.419691
[ Info: iteration 15, average log likelihood -1.419586
[ Info: iteration 16, average log likelihood -1.419491
[ Info: iteration 17, average log likelihood -1.419404
[ Info: iteration 18, average log likelihood -1.419325
[ Info: iteration 19, average log likelihood -1.419252
[ Info: iteration 20, average log likelihood -1.419186
[ Info: iteration 21, average log likelihood -1.419124
[ Info: iteration 22, average log likelihood -1.419067
[ Info: iteration 23, average log likelihood -1.419014
[ Info: iteration 24, average log likelihood -1.418964
[ Info: iteration 25, average log likelihood -1.418917
[ Info: iteration 26, average log likelihood -1.418872
[ Info: iteration 27, average log likelihood -1.418830
[ Info: iteration 28, average log likelihood -1.418789
[ Info: iteration 29, average log likelihood -1.418751
[ Info: iteration 30, average log likelihood -1.418714
[ Info: iteration 31, average log likelihood -1.418679
[ Info: iteration 32, average log likelihood -1.418646
[ Info: iteration 33, average log likelihood -1.418614
[ Info: iteration 34, average log likelihood -1.418583
[ Info: iteration 35, average log likelihood -1.418554
[ Info: iteration 36, average log likelihood -1.418526
[ Info: iteration 37, average log likelihood -1.418499
[ Info: iteration 38, average log likelihood -1.418473
[ Info: iteration 39, average log likelihood -1.418449
[ Info: iteration 40, average log likelihood -1.418425
[ Info: iteration 41, average log likelihood -1.418403
[ Info: iteration 42, average log likelihood -1.418381
[ Info: iteration 43, average log likelihood -1.418360
[ Info: iteration 44, average log likelihood -1.418340
[ Info: iteration 45, average log likelihood -1.418321
[ Info: iteration 46, average log likelihood -1.418302
[ Info: iteration 47, average log likelihood -1.418284
[ Info: iteration 48, average log likelihood -1.418267
[ Info: iteration 49, average log likelihood -1.418251
[ Info: iteration 50, average log likelihood -1.418235
┌ Info: EM with 100000 data points 50 iterations avll -1.418235
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4211080850310893
│     -1.4210438207130882
│      ⋮
└     -1.4182349516338386
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4309164132639982
│     -1.4309356518158638
│     -1.4308447453277704
│     -1.4307713217190274
│      ⋮
│     -1.4182672850928746
│     -1.418250836599533
└     -1.4182349516338386
32×26 Array{Float64,2}:
 -0.408006    -0.00646845   -0.387663   -0.142219   -0.15805     -0.0602488   -0.638563    0.336981    -0.21438      0.0145131  -0.110103    0.0338863    0.230532    0.344847     0.486582      0.0400521   -0.0367879   0.619533     -0.329752    -0.563066   -0.142834     0.249952   -0.307263    0.277997    -0.0707833     0.0177373
  0.5663       0.473315     -0.235021    0.107349   -0.176148    -0.595178    -0.0350422   0.0594215   -0.00397555   0.104172   -0.215215    0.0641235   -0.0820215  -0.358799    -0.233321     -0.395007    -0.242889    0.350312     -1.0015      -0.344072   -0.417346    -0.228605   -0.304946    0.403577    -0.337177      0.0978667
 -0.29392      0.213034     -0.544951   -0.287332   -0.271943    -0.90456      0.0202323   0.671251     0.511244    -0.884905   -0.438627    0.0410386   -0.084428   -0.192765     0.816045      0.25585     -0.0159184   0.530666     -1.48854     -0.348178   -0.313323     0.116167    0.682282   -0.157509     0.275415     -0.104552
  0.0831152    0.0617568    -0.217741    0.0244049  -0.0213621    0.450939    -0.0383779  -0.370215     0.164381    -0.42784     0.0209913   0.368135    -0.140654   -0.541123     0.348622      0.225758     0.0228902   0.148605     -0.97416     -0.235411   -0.630764    -0.45418     0.231615   -0.840522     0.269555     -0.0984216
 -0.00014369   1.01846       0.750729   -0.2702     -0.015408     0.122075     0.237289   -0.131071    -0.134732    -0.287959   -0.370697   -0.349785     0.631752   -0.00804866   0.151812      0.171084    -0.831001    0.0350538    -0.22248      0.204523   -0.068284    -0.25217    -0.207689    0.15681     -0.409543      0.304095
 -0.0505549    0.187407      0.971093    0.112147   -0.202161    -0.116739     0.195371   -0.256266     0.146363     0.256362    0.19882     0.0527293    0.145325    0.378531     0.000912058  -0.224927     0.440036    0.594812     -0.0398209    0.508874   -0.525329    -0.280499    0.0142168  -0.2636       0.0148082    -0.225825
  0.13422     -0.0258395     0.722714    0.17786    -0.0967555    0.276783    -0.164635    0.0954226   -0.125548    -0.732802    0.140777   -0.0333063   -0.156102    0.374364     0.147296      0.338191     0.493262   -0.276948      0.0620606    0.301623    0.877639    -0.502015    0.221715    0.279465    -0.073226     -0.235917
  0.588439     0.269964      0.77367     0.175281    0.376305     0.334818     0.642127    0.408021     0.507841    -0.305607    0.319971   -0.545718     0.338695    0.190904    -0.459024      0.187413    -0.24654     0.950883     -0.371643     0.115675    0.929655     0.698499    0.508137    0.231231    -0.462505      0.0964794
  0.0546711    0.610451      0.447696   -0.301733   -0.167029     0.393145     0.468125    0.492061    -0.131487     0.220321    0.288987    0.234322     0.637212   -0.469661     0.228915      0.309801    -0.571241    0.312337      0.400282     0.195225    0.131058     0.402691   -0.416534   -0.270985    -0.271305     -0.622727
 -0.537165    -0.126969      0.0741639  -0.0345105   0.16594      0.237912     0.648289    0.2744       0.0729799   -0.038489    0.311272    0.148021     0.0142553   0.219259     0.523318      0.31923     -0.56106    -0.24217       0.823767     0.242863    0.0572568    0.587217    0.199608   -0.694318    -0.090368     -0.266908
 -0.0553743   -0.142082      0.397388   -0.246344   -0.700687    -0.38676     -0.195622    0.836435    -0.337103     0.557478   -0.16297    -0.290618    -0.346056   -0.590178     0.117723     -0.415607    -0.0550017  -0.14623       0.312978    -0.264493    0.16508     -0.181709    0.467866    0.295358    -0.36941       0.0463427
  0.0418808    0.0406613    -0.0953955   0.561819   -0.45809      0.275725     0.155365   -0.0767449   -0.234384     0.789915    0.345378   -0.132559     0.356196    0.341655    -0.203769     -0.168828    -0.0790777  -0.76307       0.745849    -0.103924    0.391436     0.216398   -0.541846    0.612585    -0.369525     -0.00847008
 -0.0670598   -0.109532     -0.918059   -0.152784   -0.144019    -0.184122     0.198169   -0.116671     0.103223     0.247209   -0.3359     -0.0183357    0.129229    0.0738859   -0.0752706     0.141368    -0.0902888  -0.630898      0.195368    -0.0770276  -0.226059    -0.284695    0.103025   -0.146838     0.158296     -0.0221769
 -0.153128    -0.227829      0.381524    0.124708    0.419035     0.0384055   -0.0654006  -0.256982    -0.61332     -0.522045   -0.151005   -0.52356     -0.140121   -0.472325    -0.142525     -0.402243     0.172407   -0.376902      0.598255     0.259669   -0.067223     0.1717     -0.134077   -0.0707744    0.609621      0.376016
 -0.305927    -0.487381     -0.216799   -0.123052    0.361175    -0.310516    -0.209528   -0.658404     0.268478    -0.195239   -0.300113   -0.210805    -0.962555    0.576666    -0.441542     -0.36657      0.882386   -0.0724442     0.0119132    0.24763    -0.0601136   -0.377698    0.540738   -0.0267546    0.140656      0.612288
  0.533663    -0.205846     -0.163611    0.355765   -0.0113795    0.0839639    0.243291   -0.00151831   1.24136      0.363958    0.189438   -0.192917    -0.554821   -0.159926    -0.0921766     0.0588531   -0.12158    -0.0354195     0.092042    -0.0725991  -0.0304957   -0.265429    0.155439   -0.766813    -0.0164502    -0.0409443
 -0.144967    -0.744687     -0.396186   -0.024822    0.715837     0.0876767   -0.0842677   0.65777      0.190633    -0.470441   -0.490366    0.564076     0.643637    0.211103    -0.0411383     0.203553     0.352332    0.675861     -0.192048     0.246497    0.0185446   -0.159151   -0.0565812   0.443865     0.436819     -1.13813
  0.0397102   -0.0949392    -0.190694    0.333034    0.0193716    0.276555     0.134488   -0.320556     0.0745013    0.0533893   0.607738    0.290006     0.574662   -0.47822     -0.211068      0.327131     0.181532   -0.260413     -0.31255      0.502229    0.0461692   -0.185051    0.509626    0.651075     0.238025     -0.415423
 -0.16621      0.000347278   0.221825   -0.197321   -0.0465072    0.129572    -0.0376665   0.304232    -0.459443    -0.38456    -0.125862   -0.00304118   0.204886   -0.19002      0.206191      0.0955765   -0.276898    0.000477755   0.319298     0.048429    0.0820376    0.27048     0.0242399  -0.0720753    0.362202     -0.150659
 -0.0566439   -0.0614        0.241022   -0.0667669   0.144443     0.23259     -0.0837378   0.0140772   -0.03499     -0.135585    0.0883227  -0.0941757   -0.0914735   0.288983    -0.188722      0.180336     0.527892   -0.153542      0.469254     0.206419    0.189214     0.0832352   0.122616   -0.00498685   0.184761     -0.0555729
 -0.465835    -0.192175     -0.283675    0.500663    0.286593    -0.521913    -0.312513    0.0312499   -0.0932153   -0.142196    0.227783    0.0490071   -0.104224    0.144185     0.105921     -0.45351     -0.320836    0.153841     -0.0761715    0.141817    0.248784     0.389084   -0.411602    0.255599    -0.439311      0.188358
 -0.399286    -0.403128      0.386541    0.357904    0.248631     0.610742    -0.195626   -0.284044    -0.322783    -0.310919    0.741877    0.120826    -0.223438    0.168053    -0.287303     -0.241402    -0.0224093   0.755588     -0.0116522    0.314575    0.407828     0.698175   -0.539143    0.39727     -0.0151139     0.33465
 -0.103312    -0.370757     -0.818744    0.148391    0.531309     0.360145     0.313634   -0.37645      0.417024     0.0734987   0.222916   -0.111385     0.242108    0.106611    -0.0124659    -0.0282264   -0.118404    0.124731      0.115764    -0.520287   -0.170566     0.564439   -0.121779    0.0584914    0.513684      0.441147
 -0.089456    -0.206656     -0.992742    0.170285    0.137829    -0.136088    -0.228453    0.324094    -0.0668862   -0.217544    0.068625    0.0567802   -0.197727    0.0154174   -0.419574      0.6517       0.105621   -0.560327      0.202257    -0.123774    0.675474     0.256051    0.295036   -0.00699448   0.000395649   0.0047664
  0.471893     0.266394      0.123178    0.289504   -0.150535    -0.18134      0.260731   -0.398182     0.592406     0.155405    0.0231862  -0.26191     -0.0614887   0.258102    -0.174842      0.00134655  -0.216809    0.126454     -0.00670623  -0.0164435  -0.00204386  -0.21987    -0.218087   -0.0785304   -0.184048      0.0569071
  0.0819315    0.352791      0.180863   -0.114179   -0.340601     0.0946947    0.513123   -0.561023    -0.00367513   0.486003    0.207465   -0.276651    -0.207827   -0.458857    -0.134209     -0.368214    -0.466507   -0.364134     -0.228908     0.181456   -0.263673     0.182585    0.216827   -0.276214    -0.221499      0.790339
 -0.093429    -0.0950912    -0.232898    0.0824894   0.0965496   -0.00433293   0.0347133  -0.0330782    0.0909433    0.0141237   0.0327518  -0.0049225    0.0119267  -0.0468216    0.0531521    -0.02258     -0.134737    0.0828993    -0.133275    -0.0432927  -0.00639068   0.15009    -0.0216759   0.0292428   -0.0630446     0.113257
  0.242445     0.318052     -0.234593   -0.316431   -0.00213624   0.129244     0.255966    0.158769    -0.0917791    0.333514   -0.223643    0.67666      0.173553   -0.442489    -0.0690065     0.112773    -0.380766    0.352769     -0.341029     0.0224199  -0.26995      0.572861    0.067422    0.010716    -0.189566     -0.175866
 -0.115395    -0.487898     -0.776503   -0.204073   -0.131967    -0.290477    -0.214946   -0.127721    -0.319754     0.307963   -0.576498    0.0508005   -0.0746125  -0.0555762    0.11411      -0.141326     0.0168741  -0.710341      0.267857    -0.170394   -0.578011    -0.43815    -0.252405   -0.146567     0.280136     -0.0259446
  0.0932801    0.366621     -0.0330882  -0.321001   -0.338188    -0.0533117   -0.0113087  -0.0489998   -0.093516     0.4619     -0.776744   -0.236523     0.302974    0.149889    -0.283176      0.310427     0.245345   -0.147195      0.529381    -0.399567   -0.227268    -0.533816   -0.163607   -0.367026     0.0990822    -0.0701548
  0.0601012    0.213664      0.276341   -0.0734543  -0.46813     -0.133995    -0.0471503   0.399982    -0.0691652   -0.0942839  -0.11741     0.0389289    0.0244204  -0.12756      0.171101      0.026766     0.321707    0.00741809   -0.223088    -0.0642096  -0.0892455   -0.732732    0.234832    0.014788    -0.194326     -0.512559
  0.241768     0.140519     -0.0676167  -0.0253662   0.233172    -0.201351    -0.451955    0.122508    -0.015704    -0.164141   -0.289868   -0.269341    -0.0403967   0.122153    -0.0687751    -0.219278     0.38726     0.411012     -0.50691     -0.359079   -0.0769168   -0.342658   -0.20528     0.46916      0.0198062     0.393005[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418220
[ Info: iteration 2, average log likelihood -1.418205
[ Info: iteration 3, average log likelihood -1.418190
[ Info: iteration 4, average log likelihood -1.418176
[ Info: iteration 5, average log likelihood -1.418162
[ Info: iteration 6, average log likelihood -1.418148
[ Info: iteration 7, average log likelihood -1.418134
[ Info: iteration 8, average log likelihood -1.418121
[ Info: iteration 9, average log likelihood -1.418107
[ Info: iteration 10, average log likelihood -1.418094
┌ Info: EM with 100000 data points 10 iterations avll -1.418094
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.668005e+05
      1       7.183253e+05      -2.484753e+05 |       32
      2       7.010589e+05      -1.726637e+04 |       32
      3       6.949557e+05      -6.103229e+03 |       32
      4       6.921718e+05      -2.783912e+03 |       32
      5       6.906403e+05      -1.531451e+03 |       32
      6       6.896048e+05      -1.035517e+03 |       32
      7       6.888283e+05      -7.764483e+02 |       32
      8       6.882209e+05      -6.074865e+02 |       32
      9       6.877284e+05      -4.924581e+02 |       32
     10       6.873391e+05      -3.893218e+02 |       32
     11       6.870183e+05      -3.208118e+02 |       32
     12       6.867408e+05      -2.774882e+02 |       32
     13       6.864840e+05      -2.568033e+02 |       32
     14       6.862496e+05      -2.343860e+02 |       32
     15       6.860241e+05      -2.255128e+02 |       32
     16       6.858046e+05      -2.194771e+02 |       32
     17       6.855963e+05      -2.083264e+02 |       32
     18       6.854207e+05      -1.755931e+02 |       32
     19       6.852663e+05      -1.543830e+02 |       32
     20       6.851231e+05      -1.432384e+02 |       32
     21       6.849840e+05      -1.390733e+02 |       32
     22       6.848412e+05      -1.427574e+02 |       32
     23       6.847190e+05      -1.221882e+02 |       32
     24       6.845994e+05      -1.195973e+02 |       32
     25       6.844805e+05      -1.189455e+02 |       32
     26       6.843826e+05      -9.792862e+01 |       32
     27       6.842730e+05      -1.095555e+02 |       32
     28       6.841644e+05      -1.086281e+02 |       32
     29       6.840689e+05      -9.550983e+01 |       32
     30       6.839752e+05      -9.369678e+01 |       32
     31       6.838812e+05      -9.402438e+01 |       32
     32       6.837871e+05      -9.408933e+01 |       32
     33       6.836960e+05      -9.109086e+01 |       32
     34       6.836169e+05      -7.903015e+01 |       32
     35       6.835489e+05      -6.807932e+01 |       32
     36       6.834895e+05      -5.936264e+01 |       32
     37       6.834326e+05      -5.694929e+01 |       32
     38       6.833818e+05      -5.074015e+01 |       32
     39       6.833297e+05      -5.214104e+01 |       32
     40       6.832750e+05      -5.466091e+01 |       32
     41       6.832237e+05      -5.135747e+01 |       32
     42       6.831775e+05      -4.614338e+01 |       32
     43       6.831373e+05      -4.019960e+01 |       32
     44       6.830996e+05      -3.775897e+01 |       32
     45       6.830607e+05      -3.885355e+01 |       32
     46       6.830241e+05      -3.658433e+01 |       32
     47       6.829920e+05      -3.215945e+01 |       32
     48       6.829598e+05      -3.218429e+01 |       32
     49       6.829259e+05      -3.384167e+01 |       32
     50       6.828942e+05      -3.169487e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 682894.2319777276)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.430223
[ Info: iteration 2, average log likelihood -1.425152
[ Info: iteration 3, average log likelihood -1.423930
[ Info: iteration 4, average log likelihood -1.423163
[ Info: iteration 5, average log likelihood -1.422356
[ Info: iteration 6, average log likelihood -1.421422
[ Info: iteration 7, average log likelihood -1.420513
[ Info: iteration 8, average log likelihood -1.419843
[ Info: iteration 9, average log likelihood -1.419444
[ Info: iteration 10, average log likelihood -1.419219
[ Info: iteration 11, average log likelihood -1.419079
[ Info: iteration 12, average log likelihood -1.418981
[ Info: iteration 13, average log likelihood -1.418905
[ Info: iteration 14, average log likelihood -1.418842
[ Info: iteration 15, average log likelihood -1.418789
[ Info: iteration 16, average log likelihood -1.418742
[ Info: iteration 17, average log likelihood -1.418701
[ Info: iteration 18, average log likelihood -1.418663
[ Info: iteration 19, average log likelihood -1.418629
[ Info: iteration 20, average log likelihood -1.418598
[ Info: iteration 21, average log likelihood -1.418569
[ Info: iteration 22, average log likelihood -1.418542
[ Info: iteration 23, average log likelihood -1.418517
[ Info: iteration 24, average log likelihood -1.418494
[ Info: iteration 25, average log likelihood -1.418472
[ Info: iteration 26, average log likelihood -1.418452
[ Info: iteration 27, average log likelihood -1.418432
[ Info: iteration 28, average log likelihood -1.418414
[ Info: iteration 29, average log likelihood -1.418397
[ Info: iteration 30, average log likelihood -1.418381
[ Info: iteration 31, average log likelihood -1.418365
[ Info: iteration 32, average log likelihood -1.418351
[ Info: iteration 33, average log likelihood -1.418337
[ Info: iteration 34, average log likelihood -1.418324
[ Info: iteration 35, average log likelihood -1.418311
[ Info: iteration 36, average log likelihood -1.418299
[ Info: iteration 37, average log likelihood -1.418287
[ Info: iteration 38, average log likelihood -1.418275
[ Info: iteration 39, average log likelihood -1.418264
[ Info: iteration 40, average log likelihood -1.418254
[ Info: iteration 41, average log likelihood -1.418244
[ Info: iteration 42, average log likelihood -1.418234
[ Info: iteration 43, average log likelihood -1.418224
[ Info: iteration 44, average log likelihood -1.418215
[ Info: iteration 45, average log likelihood -1.418205
[ Info: iteration 46, average log likelihood -1.418196
[ Info: iteration 47, average log likelihood -1.418188
[ Info: iteration 48, average log likelihood -1.418179
[ Info: iteration 49, average log likelihood -1.418171
[ Info: iteration 50, average log likelihood -1.418163
┌ Info: EM with 100000 data points 50 iterations avll -1.418163
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.082473    -0.494283    -0.851205   -0.0477799     0.443671    0.476932    0.0588022    0.221907   -0.132433     -0.0790623  -0.110492    -0.0528601  -0.00977302  -0.159593    0.0857473    0.19877      0.262792   -0.550006     0.565432    -0.487571    -0.170077     0.248033    0.122473    -0.0217816     0.734883    0.261726
 -0.189395    -0.0107807   -0.227102   -0.0471025    -0.408929   -0.273981    0.415305    -0.100178   -0.0703708     0.285925    0.174733     0.19843     0.0688427   -0.336853   -0.742916     0.108552     0.570443   -0.409405    -0.216963     0.722233     0.0409752   -0.282252    0.685525     0.25506       0.0401295  -0.310787
 -0.399104     0.046461    -0.0698632   0.00968203   -0.369689    0.10137    -0.604325     0.122383   -0.988621     -0.478663   -0.0393279   -0.0562849   0.329671     0.366902    0.383506    -0.401386    -0.0625277   0.127371    -0.500229     0.272329     0.416315    -0.0425399  -0.479299     0.653736     -0.2669      0.322961
 -0.292394     0.285734     0.226373   -0.29739       0.166652    0.311579    0.220842     0.521814   -0.373827     -0.0914132   0.21049      0.178787    0.496509    -0.258232    0.586656     0.222936    -0.463749    0.16802      0.446606     0.170078    -0.00252452   0.473307   -0.178108    -0.122584     -0.0739737  -0.418919
  0.236719    -0.0460818   -0.384875    0.222548      0.109387   -0.13012     0.437148    -0.410989    0.80124       0.292707    0.0302814   -0.215658   -0.0933112    0.176641   -0.158682    -0.14342     -0.177886    0.0391653    0.00278356  -0.222054     0.0398277    0.12202    -0.043076    -0.107595     -0.0338742   0.31187
  0.11011      0.0125901    0.984017    0.29298      -0.598465    0.0482465   0.0635246    0.192105   -0.0462189    -0.197437    0.0738564    0.441975    0.0150189    0.307118    0.286041     0.230907     0.786485    0.0916036   -0.205148     0.100153     0.351567    -0.679025    0.184432     0.0871247    -0.261411   -0.53583
  0.349848    -0.0964485   -0.252338    0.149954     -0.198059    0.363536    0.200312    -0.24673     0.46796      -0.259155    0.0462581    0.136414   -0.2847      -0.568559    0.374997     0.194573    -0.0968623  -0.4119      -0.425131     0.00929244  -0.390453    -0.656009    0.407331    -1.04682       0.193792   -0.261298
 -0.0980756   -0.116517    -0.0715142   0.00631485    0.0458128   0.0195165  -0.133509     0.0588979  -0.0687953    -0.0318307  -0.00095739  -0.0318954  -0.0117573    0.0408974   0.027213     0.00804164   0.131967   -0.0486394    0.113419    -0.0077387    0.0287165    0.0255774   0.00268536   0.0619537     0.051748   -0.00700934
  0.0727889    0.238933    -0.263633    0.0320518    -0.41589    -0.67008    -0.177998     0.505085    0.158635      0.0225313  -0.371528     0.0257283  -0.0246307   -0.416159    0.470178    -0.177825    -0.113795    0.434114    -0.984223    -0.595399    -0.524936    -0.349779    0.183688     0.229409     -0.0620136  -0.282526
 -0.0940976    0.0793138    0.0137109  -0.606871     -0.450648    0.0670172  -0.15061      0.486727   -0.629345      0.0336005  -0.516839    -0.259635   -0.00664057  -0.0427902  -0.144402     0.0269261    0.185114   -0.442997     0.763018    -0.257679     0.121875    -0.260933    0.0684073   -0.0266607    -0.0183003  -0.116923
 -0.0826339   -0.886255    -0.381949    0.460678      0.638224    0.320234   -0.227501    -0.209866    0.452552     -0.197871    0.247712     0.271465    0.276321     0.267195    0.0409704    0.241284     0.322575    0.337129     0.10447      0.0546005    0.158562     0.199265   -0.108367     0.218369      0.539182   -0.441886
 -0.550864     0.0176064   -0.482211   -0.0298659     0.118565   -0.101829    0.632921    -0.259422    0.512542     -0.356773    0.21698     -0.0692267   0.00802556   0.232218    0.0796392    0.553169    -0.763344    0.192519    -0.197682    -0.0130909    0.0973802    0.682328    0.376701    -0.764017      0.544189    0.308726
 -0.335512    -0.00908374   0.205609   -0.0424527    -0.208475    0.0364344   0.278896     0.422929    0.226661      0.11489     0.078258    -0.126495    0.0238744    0.343033    0.587524    -0.124552    -0.333701   -0.272029     0.733018     0.360394    -0.056969    -0.0418278   0.179627    -0.477067     -0.318273   -0.543869
 -0.372142    -0.253402     0.374882    0.188036      0.493234   -0.228512   -0.175951    -0.492945   -0.407993     -0.750309    0.0476957   -0.463897   -0.126214    -0.119685   -0.00839937  -0.454405     0.299581   -0.379736     0.490154     0.375887    -0.0494568   -0.279785   -0.12707      0.136102      0.627211    0.213071
  0.0871551    0.38644      0.406576   -0.220862     -0.32489     0.0674496   0.41035     -0.621233   -0.0845877     0.474215    0.0948675   -0.34468    -0.301916    -0.397288    0.0928546   -0.529408    -0.388565   -0.382235    -0.289207     0.0236627   -0.410496     0.0436747   0.27674     -0.228334     -0.2452      1.05563
  0.20318      0.00581996   0.111882    0.131125     -0.18386     0.126214   -0.208273    -0.220903    0.347132      0.0866427  -0.251032    -0.499386    0.0150679    0.288536   -0.46695      0.368042     0.713044   -0.152567     0.0785444   -0.15652      0.0656589   -0.694761    0.125364     0.067814      0.362429   -0.00601439
 -0.0434843   -0.390114    -1.13218    -0.226826     -0.354096   -0.572126   -0.352172    -0.536188   -0.333647      0.627188   -1.12905      0.176701    0.13657      0.236676    0.0510436    0.019146    -0.253149   -1.01657      0.261284    -0.145615    -0.689883    -0.780661   -0.60095     -0.287409      0.299704   -0.0170037
 -0.336655    -0.136308    -0.804887    0.358528      0.350024   -0.276088   -0.463296     0.259776   -0.114719     -0.374134    0.102533     0.0850505  -0.164893     0.0481702  -0.180472     0.269693    -0.0345275  -0.238339    -0.135793    -0.20005      0.702677     0.405332    0.029947     0.189348     -0.347213    0.308566
 -0.0098391    0.436507    -0.173597   -0.217455     -0.189283   -0.084771   -0.1321       0.0120902  -0.0848615     0.0389123  -0.283036    -0.0763681   0.362292     0.188142   -0.0186421    0.0514397   -0.119643    0.588028    -0.335216    -0.92991     -0.48191      0.4637     -0.449933     0.363507      0.290463    0.442825
 -0.169563    -0.0337917    0.221047    0.209176      0.26132     0.180523    0.0879207    0.0452009   0.139098     -0.465373    0.60187     -0.057277   -0.0652754   -0.0896679   0.0117503   -0.237135    -0.184119    0.753832    -0.677603     0.127113    -0.0100126    0.360797   -0.0154374    0.371162     -0.150548    0.103973
  0.121333    -0.105034    -0.44763     0.593087     -0.369186    0.0503812   0.323468    -0.180271    0.0531032     0.788461    0.40242     -0.0272864   0.405147     0.219253   -0.0542476    0.0153869   -0.3304     -0.750095     0.621615    -0.181701     0.43204      0.174572   -0.311003     0.393999     -0.278696    0.0503716
  0.400265     1.1484       0.778639    0.0640905    -0.222006    0.0502647   0.494846    -0.227554    0.164955     -0.0767645   0.0426705   -0.21559     0.484144    -0.145582   -0.462003     0.135698    -0.504957    0.189144    -0.285209     0.15283      0.142163    -0.233423   -0.213742     0.00312705   -0.383451   -0.0752349
 -0.180717    -0.0306856   -0.297507   -0.524238      0.265593   -0.213894   -0.112931     0.517658    0.0413142    -0.423791   -0.564998     0.394696    0.224353    -0.0313009   0.389816     0.177438     0.32495     0.611047    -0.671057    -0.106411    -0.352072    -0.248115    0.265485     0.000296127   0.253551   -0.446348
  0.424469     0.30944     -0.0772558   0.197502      0.344373   -0.220142   -0.7099       0.429503    0.44902       0.286606    0.23532     -0.263404   -0.36416      0.169274   -0.121335    -0.750706     0.532561    0.249247    -0.223716    -0.00747841  -0.226486    -0.393978   -0.574158     0.0235814    -0.731047    0.00959879
  0.256645     0.413691     0.32723    -0.102402     -0.0211751   0.32884     0.352835    -0.108969   -0.16507      -0.0539735   0.0550564    0.346808    0.256591    -0.177697   -0.165323     0.313276    -0.233914    0.122072     0.0477097    0.310913     0.0852031    0.39114     0.0973612    0.0170127     0.0997874  -0.173777
 -0.0974181   -0.290649    -0.503242    0.0539344     0.347332   -0.412366   -0.0454584    0.0261347  -0.398506      0.339102   -0.216218     0.298321   -0.0968585   -0.567178   -0.0247566   -0.473096    -0.579259    0.10647     -0.0605639    0.0238961   -0.598058     0.486756   -0.403613    -0.227826     -0.121326    0.0476773
 -0.419597    -0.168231     0.629601    0.603563      0.0011415   0.32012     0.120862    -0.256672   -0.379691      0.0694488   0.625856     0.115655   -0.359834     0.153073   -0.716248    -0.0711259    0.0941639  -0.0427034    0.983493     0.404024     0.579937     0.741848   -0.531        0.0829125    -0.241836    0.403797
  0.317784     0.420852     0.109518   -0.000852702  -0.353927   -0.302892   -0.0242667    0.0567303   0.000640506   0.0629985  -0.389818    -0.132829    0.0562098   -0.165157    0.0860961   -0.0301538   -0.143192    0.0713852   -0.423464    -0.251595    -0.214366    -0.647368   -0.083061     0.063403     -0.241764    0.00239639
  0.601743    -0.081861     0.908331    0.201655      0.54079     0.130733    0.210273     0.46376     0.369808     -0.277037   -0.0205629   -0.506641   -0.0839591    0.185944    0.0028887    0.207981    -0.0391038   0.366571     0.0935157    0.270815     1.03897      0.384449    0.44771      0.186889     -0.308532    0.158738
  0.282177     0.212934    -0.862386   -0.391846     -0.460316    0.314213   -0.0828037    0.180069    0.328905      0.875489   -0.0987972    0.541936    0.0379161   -0.322523   -0.285419     0.362028    -0.519207    0.277469    -0.476766    -0.158491    -0.0289051    0.477505    0.206555     0.0369171    -0.799244   -0.187554
  0.00708697  -0.416691    -0.159215   -0.0335665     0.212082   -0.229139   -0.13986     -0.293258    0.202172     -0.0938596  -0.201519    -0.272505   -0.732315     0.258311   -0.363814    -0.202778     0.397194   -0.00612175   0.0897322    0.0724348   -0.0737411   -0.125253    0.249307    -0.099813      0.147975    0.475987
 -0.308494     0.0197837    0.488573   -0.0884137     0.022751    0.282081   -0.00487269  -0.528535   -0.107199      1.14117     0.307484    -0.317741    0.502715     0.0571608  -0.0448469   -0.151835    -0.0544265   0.757636     0.538779     0.321483    -1.15435     -0.229176   -0.550725    -0.511922      0.338392   -0.0185892[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418155
[ Info: iteration 2, average log likelihood -1.418147
[ Info: iteration 3, average log likelihood -1.418140
[ Info: iteration 4, average log likelihood -1.418132
[ Info: iteration 5, average log likelihood -1.418125
[ Info: iteration 6, average log likelihood -1.418118
[ Info: iteration 7, average log likelihood -1.418111
[ Info: iteration 8, average log likelihood -1.418104
[ Info: iteration 9, average log likelihood -1.418098
[ Info: iteration 10, average log likelihood -1.418091
┌ Info: EM with 100000 data points 10 iterations avll -1.418091
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
