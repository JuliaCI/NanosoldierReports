Julia Version 1.5.0-DEV.150
Commit 0234e009ab (2020-01-25 18:06 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed Missings ─────────── v0.4.3
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed GaussianMixtures ─── v0.3.0
 Installed LegacyStrings ────── v0.4.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed DataStructures ───── v0.17.9
 Installed StaticArrays ─────── v0.12.1
 Installed StatsBase ────────── v0.32.0
 Installed BinaryProvider ───── v0.5.8
 Installed ScikitLearnBase ──── v0.5.0
 Installed Compat ───────────── v2.2.0
 Installed NearestNeighbors ─── v0.4.4
 Installed Rmath ────────────── v0.6.0
 Installed HDF5 ─────────────── v0.12.5
 Installed JLD ──────────────── v0.9.1
 Installed Clustering ───────── v0.13.3
 Installed StatsFuns ────────── v0.9.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed URIParser ────────── v0.4.0
 Installed Blosc ────────────── v0.5.1
 Installed PDMats ───────────── v0.9.11
 Installed Arpack ───────────── v0.4.0
 Installed DataAPI ──────────── v1.1.0
 Installed Parameters ───────── v0.12.0
 Installed SpecialFunctions ─── v0.9.0
 Installed OrderedCollections ─ v1.1.0
 Installed SortingAlgorithms ── v0.3.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed BinDeps ──────────── v1.0.0
 Installed Distances ────────── v0.8.2
 Installed Distributions ────── v0.22.3
 Installed QuadGK ───────────── v2.3.1
 Installed FileIO ───────────── v1.2.1
 Installed FillArrays ───────── v0.8.4
 Installed CMake ────────────── v1.1.2
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_k9fNpV/Project.toml`
 [no changes]
  Updating `/tmp/jl_k9fNpV/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_djmcAX/Project.toml`
 [no changes]
  Updating `/tmp/jl_djmcAX/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_gyZL03/Project.toml`
 [no changes]
  Updating `/tmp/jl_gyZL03/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_3FenIx/Project.toml`
 [no changes]
  Updating `/tmp/jl_3FenIx/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_6VTcpn/Project.toml`
 [no changes]
  Updating `/tmp/jl_6VTcpn/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_6VTcpn/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.1569251349237855e6, [50956.148449087304, 49043.85155091272], [-28415.411646865534 -4681.468984329345 25886.72959304738; 28860.98639660161 4951.277794557736 -25890.644119765177], [[47860.53229098639 145.50226590364463 -41.78151241315177; 145.50226590364468 49589.874506420034 3262.2344171148875; -41.78151241315173 3262.2344171148875 49160.10581621439], [52677.39783705759 -502.2068165473912 330.22311381654066; -502.206816547391 50339.92895220134 -2943.448153760252; 330.2231138165407 -2943.4481537602514 50980.6394976031]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.302951e+03
      1       9.408187e+02      -3.621325e+02 |        8
      2       9.216164e+02      -1.920226e+01 |        2
      3       9.200993e+02      -1.517132e+00 |        0
      4       9.200993e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 920.0992770804733)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.070682
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.778954
[ Info: iteration 2, lowerbound -3.641000
[ Info: iteration 3, lowerbound -3.490440
[ Info: iteration 4, lowerbound -3.309613
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.101865
[ Info: iteration 6, lowerbound -2.889302
[ Info: iteration 7, lowerbound -2.708216
[ Info: iteration 8, lowerbound -2.580211
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.490915
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.419755
[ Info: iteration 11, lowerbound -2.368988
[ Info: iteration 12, lowerbound -2.336847
[ Info: iteration 13, lowerbound -2.315501
[ Info: iteration 14, lowerbound -2.307432
[ Info: dropping number of Gaussions to 2
[ Info: iteration 15, lowerbound -2.302959
[ Info: iteration 16, lowerbound -2.299262
[ Info: iteration 17, lowerbound -2.299257
[ Info: iteration 18, lowerbound -2.299255
[ Info: iteration 19, lowerbound -2.299254
[ Info: iteration 20, lowerbound -2.299253
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Jan 26 04:46:41 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Jan 26 04:46:50 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Sun Jan 26 04:46:52 2020: EM with 272 data points 0 iterations avll -2.070682
5.8 data points per parameter
, Sun Jan 26 04:46:54 2020: GMM converted to Variational GMM
, Sun Jan 26 04:47:03 2020: iteration 1, lowerbound -3.778954
, Sun Jan 26 04:47:03 2020: iteration 2, lowerbound -3.641000
, Sun Jan 26 04:47:03 2020: iteration 3, lowerbound -3.490440
, Sun Jan 26 04:47:03 2020: iteration 4, lowerbound -3.309613
, Sun Jan 26 04:47:04 2020: dropping number of Gaussions to 7
, Sun Jan 26 04:47:04 2020: iteration 5, lowerbound -3.101865
, Sun Jan 26 04:47:04 2020: iteration 6, lowerbound -2.889302
, Sun Jan 26 04:47:04 2020: iteration 7, lowerbound -2.708216
, Sun Jan 26 04:47:04 2020: iteration 8, lowerbound -2.580211
, Sun Jan 26 04:47:04 2020: dropping number of Gaussions to 5
, Sun Jan 26 04:47:04 2020: iteration 9, lowerbound -2.490915
, Sun Jan 26 04:47:04 2020: dropping number of Gaussions to 3
, Sun Jan 26 04:47:04 2020: iteration 10, lowerbound -2.419755
, Sun Jan 26 04:47:04 2020: iteration 11, lowerbound -2.368988
, Sun Jan 26 04:47:04 2020: iteration 12, lowerbound -2.336847
, Sun Jan 26 04:47:04 2020: iteration 13, lowerbound -2.315501
, Sun Jan 26 04:47:04 2020: iteration 14, lowerbound -2.307432
, Sun Jan 26 04:47:04 2020: dropping number of Gaussions to 2
, Sun Jan 26 04:47:04 2020: iteration 15, lowerbound -2.302959
, Sun Jan 26 04:47:04 2020: iteration 16, lowerbound -2.299262
, Sun Jan 26 04:47:04 2020: iteration 17, lowerbound -2.299257
, Sun Jan 26 04:47:04 2020: iteration 18, lowerbound -2.299255
, Sun Jan 26 04:47:04 2020: iteration 19, lowerbound -2.299254
, Sun Jan 26 04:47:04 2020: iteration 20, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 21, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 22, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 23, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 24, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 25, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 26, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 27, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 28, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 29, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 30, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 31, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 32, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 33, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 34, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 35, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 36, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 37, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 38, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 39, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 40, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 41, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 42, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 43, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 44, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 45, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 46, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 47, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 48, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 49, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: iteration 50, lowerbound -2.299253
, Sun Jan 26 04:47:04 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260138, 95.9549077739862]
β = [178.0450922260138, 95.9549077739862]
m = [4.250300733269911 79.28686694436185; 2.0002292577753713 53.85198717246131]
ν = [180.0450922260138, 97.9549077739862]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484935 -0.007644049042327522; 0.0 0.008581705166333463], [0.3758763611948409 -0.008953123827346032; 0.0 0.012748664777409425]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000004
avll from stats: -1.0030163047294047
avll from llpg:  -1.0030163047294065
avll direct:     -1.0030163047294065
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0030384314822118
avll from llpg:  -1.0030384314822118
avll direct:     -1.0030384314822118
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.149537   -0.151327    -0.00591564   0.0625038   -0.137681    -0.155379     0.0338123    0.183181     0.0607368    0.212591    -0.0250189   -0.138557    -0.0794636   -0.0136092    0.166671      0.145069     0.0242224    0.112913    -0.102129    -0.204839     0.242887     0.199434     -0.0428358    0.00764367  -0.038916     0.0120609
 -0.0655645   0.135493    -0.0236151   -0.154722     0.0496969    0.0112213   -0.0836117    0.0441296   -0.0908838   -0.0599447   -0.127849     0.0912034    0.175239    -0.0247564    0.0589864     0.115739     0.0232709   -0.0446333    0.0101606   -0.0905451    0.0085612   -0.0977776     0.053972     0.0366845   -0.0178086   -0.0285347
  0.243373    0.0804852    0.0153497   -0.01764     -0.00950535   0.0420874   -0.103682     0.220821     0.0305712    0.0694004   -0.104687     0.0272755   -0.0378536    0.0125921   -0.0371988    -0.134957     0.0346674    0.0252793    0.0760015    0.0387729    0.0687691   -0.0363326     0.024111    -0.0562645   -0.0504132    0.312301
 -0.0780734  -0.0913743    0.00422454   0.00132969  -0.0303198    0.0334411   -0.00569041  -0.039882    -0.114054    -0.00926428  -0.0982307   -0.140128     0.107946    -0.213571    -0.000969361  -0.175258    -0.0311264   -0.263298     0.0784813   -0.0850962   -0.0472325    0.0238212    -0.179777     0.243137    -0.0420256   -0.0375815
 -0.129376    0.0883762   -0.027223     0.0222746    0.0104704   -0.128767    -0.0409379   -0.0737724    0.164728     0.133755    -0.0260997    0.0272057    0.0152142    0.0720059   -0.0283628     0.0490044    0.0146841    0.239386    -0.0507755    0.156254     0.217428    -0.069967      0.00461815  -0.115537    -0.00609823  -0.112683
  0.0936451   0.183479     0.114086    -0.108028     0.0261205   -0.0252882    0.12148      0.115746     0.135262    -0.135093    -0.0445335    0.161714    -0.0480254    0.191163    -0.115826     -0.0654553   -0.137638    -0.0426539    0.0600264   -0.0724024   -0.048328    -0.109919     -0.0335308   -0.00318019   0.0985368   -0.0354446
  0.058032    0.17598      0.0424213    0.119705    -0.111212    -0.0346812    0.207822     0.0202198   -0.0130862    0.073053     0.101621    -0.1046       0.088576    -0.153389     0.0642333     0.00713591  -0.149645     0.128319    -0.105404     0.104013    -0.0710706    0.129943      0.173453     0.10464     -0.017461     0.0646445
 -0.0557534  -0.0211981    0.0137558   -0.147637     0.154716    -0.0435734    0.214657    -0.278047    -0.0473917    0.0104142    0.118516    -0.0253385   -0.112343     0.064124     0.134397      0.120869    -0.00743406   0.301265     0.00393362  -0.14437      0.183542    -0.117466      0.151753     0.0982913    0.0200649   -0.0739198
  0.211742    0.103858    -0.135365     0.0170796   -0.0340392   -0.0922623    0.00635893  -0.0537582   -0.10338     -0.19134     -0.0474969    0.0378812   -0.0645197   -0.0928372    0.0706802     0.175234    -0.0254288   -0.0714781    0.0575295    0.0198979   -0.0373672   -0.0299565    -0.0812273   -0.032071     0.0902119    0.0666291
 -0.123597    0.00866468   0.0358631   -0.0868221   -0.113563    -0.0427037    0.0702067    0.122077     0.147777     0.0964052   -0.16187     -0.151969    -0.0744908    0.0193146    0.24295       0.0199955   -0.0113736   -0.159481     0.0501742   -0.021465     0.181527     0.0553167     0.00489095  -0.0558621   -0.0286532   -0.0738299
 -0.0379711   0.0518108   -0.0295736    0.122493    -0.0507921    0.180114     0.0749385    0.0651679   -0.115772    -0.0610982    0.0692139   -0.0856416   -0.10226     -0.183287     0.0510129    -0.0943654   -0.114921    -0.0293408    0.128168    -0.00924627   0.0755912    0.158843     -0.113573     0.0315648   -0.0057758   -0.0474348
 -0.0197909   0.0382941    0.00591198   0.188132     0.0938437    0.0412668    0.121061    -0.0612008   -0.0751803   -0.00255059   0.167222     0.139709    -0.00920557   0.0884625   -0.0052909    -0.0388542   -0.0859179    0.10132      0.016587     0.00806918  -0.014956     0.000324171   0.0185233    0.151049    -0.03071     -0.0436017
 -0.011758    0.102599    -0.0331684    0.0385561   -0.272137     0.161052    -0.0281294    0.0367548    0.102653     0.085165    -0.00533803   0.19646     -0.00493944  -0.111035    -0.164196     -0.221273     0.0266462   -0.139316     0.0326255   -0.0555777   -0.0213612    0.246672      0.0307511    0.0360064    0.048682     0.0301047
  0.202541    0.0648687    0.0639846   -0.102109     0.14328     -0.101649    -0.0893289    0.104268     0.146925     0.0370395    0.117696    -0.0653772    0.0986558    0.0480494    0.0432327     0.0740947   -0.166177     0.256287     0.128593    -0.0371347   -0.103791     0.0835205    -0.0551997   -0.0412217    0.0508054    0.0977372
 -0.122636   -0.0378003   -0.118942    -0.206806    -0.00426784   0.121373     0.0280687    0.203367     0.164978     0.0330978   -0.0304672    0.0701484    0.0251576   -0.0347257   -0.0596447    -0.0580748   -0.0512943    0.0694062   -0.0223248   -0.0227158    0.181166    -0.110503     -0.102798     0.0643549   -0.104756    -0.0494988
  0.0547171  -0.0283473   -0.0281358   -0.0443822    0.0156238    0.0756554    0.127152     0.016091     0.0133332   -0.0343023    0.0539982   -0.063957     0.0281215   -0.144823    -0.0047494     0.165782     0.0842655   -0.0367239   -0.0989647    0.0989031    0.200426     0.068951      0.0121791   -0.00488945  -0.0106264   -0.127352
  0.0442834  -0.00381749  -0.00131343   0.0448892   -0.0377898   -0.121872     0.149111    -0.128229    -0.0441664   -0.0640831   -0.0409099   -0.00325085   0.195971     0.118731    -0.0327372    -0.131263     0.0159166    0.0675644    0.122399    -0.0929727   -0.00790973   0.161049     -0.276947     0.116263     0.00447526   0.0345157
  0.0214491   0.0810534   -0.00468146   0.0217913    0.0562387   -0.031805     0.068158     0.00395726  -0.148827     0.130292     0.00703454  -0.0893671   -0.0672516   -0.155928    -0.0410203    -0.11394      0.0991153    0.111701     0.0708204   -0.024084    -0.0773866   -0.0146758     0.0397138    0.0956895    0.103706    -0.0498622
  0.0260809  -0.0260681    0.0306048    0.0224687   -0.157386    -0.00643338   0.137838     0.0713468    0.0603185    0.108765     0.10349      0.093638     0.00458419   0.21301     -0.00369477   -0.0378037   -0.104877    -0.00920901   0.0144177    0.0497972    0.0638121   -0.0392818     0.0792786    0.11739      0.0292854    0.164645
  0.0358063  -0.107191    -0.0049986    0.118028     0.0478319    0.0627849   -0.173198    -0.0426414   -0.0308592    0.0508729    0.0153215   -0.172269    -0.0254228    0.156248     0.0922996     0.0570584   -0.0787893    0.0561366    0.012079    -0.00217467  -0.224615     0.064477     -0.071032    -0.00748303   0.0539383   -0.0394893
 -0.046328   -0.00269475   0.142045    -0.00371518   0.129114    -0.101865     0.0523435    0.0629752   -0.00384478   0.0338784    0.0343895   -0.0418088   -0.0670473   -0.0173359   -0.0975483    -0.184737    -0.0753162   -0.00839314   0.0127438   -0.0481576    0.154277    -0.0977566     0.0722029   -0.0637366    0.0696852   -0.138519
 -0.0318547   0.111774     0.0634548    0.0618051   -0.0301887    0.0493363   -0.0250404   -0.386827     0.0895323   -0.280773    -0.170823    -0.10534     -0.0957258    0.00018444  -0.0138203     0.0654214   -0.02092     -0.0246468   -0.103224     0.0654436    0.0434181    0.0101457    -0.0786316   -0.0237663    0.0836152   -0.0329942
 -0.0614648  -0.0910813    0.123126     0.137993    -0.141381     0.176984    -0.0207189    0.0452408   -0.121165    -0.0936433   -0.0290954    0.15625      0.207421     0.126072     0.0325447     0.0632934    0.0351156   -0.098934     0.239946     0.164116    -0.00778438  -0.0373263    -0.165688     0.124215     0.132034     0.0392497
  0.144676   -0.0339879   -0.0838432    0.133086     0.00367392  -0.105816     0.0526106   -0.016308     0.0322693   -0.134426     0.0395231    0.0868508   -0.0511532    0.123619    -0.00318525    0.219867     0.0497189   -0.053703     0.056275    -0.0883438    0.149823    -0.000751591  -0.0643931   -0.128502     0.122282    -0.0164577
  0.0597607   0.070666     0.0546359    0.0791565   -0.148742     0.0533681    0.0365845    0.0627624    0.0548006   -0.111979    -0.299692    -0.0887045    0.0285878   -0.146042     0.0232693    -0.0189636    0.26135     -0.199466     0.0783025    0.0385099   -0.00104907  -0.155167      0.0509592    0.174541     0.152275    -0.121795
 -0.0601976  -0.0377717   -0.0745823    0.083163     0.0257865    0.0713703    0.0208393   -0.0652317    0.0127339    0.146613    -0.122959    -0.0296407   -0.0167372    0.20396     -0.0100178     0.09526      0.250847    -0.241318    -0.205521     0.0178026   -0.0365684   -0.00678742   -0.00738809   0.0660237   -0.0255789   -0.138779
  0.0858937   0.07209      0.00205014   0.115644     0.0442466    0.0849373   -0.0654195   -0.159743     0.0137703   -0.00277972   0.00041639   0.0263523    0.0480197   -0.117172     0.0226999     0.0148618    0.122566    -0.0390206    0.0996333    0.112597     0.054875     0.228243      0.00778006   0.171694    -0.0359294    0.127553
 -0.201581   -0.124045     0.0668909   -0.104137    -0.0666944   -0.119085     0.0259129   -0.0616075    0.0164972   -0.0433137   -0.121849     0.091876     0.00475765   0.0963753    0.0992363    -0.0519226    0.0226565   -0.0732308    0.175769    -0.111886     0.025703    -0.0939227     0.00601205   0.0612361   -0.049765    -0.0128641
 -0.0903715  -0.10573      0.0208283    0.163998    -0.13974     -0.0956701   -0.148402     0.163756    -0.0167106    0.0340617    0.0435954   -0.240614     0.182585     0.0781545    0.114838      0.116018     0.064401     0.0709888    0.203549     0.0960742   -0.100371     0.149432     -0.0399643   -0.04095      0.197253     0.0277403
 -0.0412735   0.158745    -0.0321184   -0.0456775    0.0656511    0.0518261    0.00733953   0.117345    -0.101251     0.104047    -0.0894201    0.0766762   -0.148841     0.0906061    0.103703      0.0122453    0.109334     0.138461     0.0788593    0.0658568   -0.235514     0.15005      -0.0769469    0.0442389    0.168853     0.126433
 -0.0434611  -0.175189    -0.0261003    0.0750992    0.0174356    0.0332332   -0.141808     0.0180297   -0.0756727   -0.0185299    0.00545589  -0.128884    -0.0088504   -0.189487     0.0900837     0.00801175  -0.0656851    0.150342     0.048275    -0.00899339  -0.0725896   -0.0308735     0.122562     0.0440862   -0.0106033   -0.0420595
 -0.0900007   0.0149787   -0.163751    -0.213333     0.12743     -0.141289     0.00266079  -0.160598     0.0389603    0.149062    -0.0724903    0.105302     0.102162    -0.0115349   -0.0403207    -0.00961016  -0.0184597   -0.0291039    0.198016     0.0620574   -0.0181225    0.249956      0.0600739    0.0344964    0.006157     0.141042kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4196164567054304
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419681
[ Info: iteration 2, average log likelihood -1.419593
[ Info: iteration 3, average log likelihood -1.418741
[ Info: iteration 4, average log likelihood -1.411006
[ Info: iteration 5, average log likelihood -1.396864
[ Info: iteration 6, average log likelihood -1.392426
[ Info: iteration 7, average log likelihood -1.391442
[ Info: iteration 8, average log likelihood -1.390800
[ Info: iteration 9, average log likelihood -1.390249
[ Info: iteration 10, average log likelihood -1.389611
[ Info: iteration 11, average log likelihood -1.388765
[ Info: iteration 12, average log likelihood -1.387684
[ Info: iteration 13, average log likelihood -1.386254
[ Info: iteration 14, average log likelihood -1.384635
[ Info: iteration 15, average log likelihood -1.383202
[ Info: iteration 16, average log likelihood -1.382077
[ Info: iteration 17, average log likelihood -1.381273
[ Info: iteration 18, average log likelihood -1.380659
[ Info: iteration 19, average log likelihood -1.380192
[ Info: iteration 20, average log likelihood -1.379841
[ Info: iteration 21, average log likelihood -1.379582
[ Info: iteration 22, average log likelihood -1.379392
[ Info: iteration 23, average log likelihood -1.379251
[ Info: iteration 24, average log likelihood -1.379158
[ Info: iteration 25, average log likelihood -1.379105
[ Info: iteration 26, average log likelihood -1.379075
[ Info: iteration 27, average log likelihood -1.379058
[ Info: iteration 28, average log likelihood -1.379047
[ Info: iteration 29, average log likelihood -1.379039
[ Info: iteration 30, average log likelihood -1.379034
[ Info: iteration 31, average log likelihood -1.379031
[ Info: iteration 32, average log likelihood -1.379029
[ Info: iteration 33, average log likelihood -1.379027
[ Info: iteration 34, average log likelihood -1.379026
[ Info: iteration 35, average log likelihood -1.379025
[ Info: iteration 36, average log likelihood -1.379025
[ Info: iteration 37, average log likelihood -1.379024
[ Info: iteration 38, average log likelihood -1.379024
[ Info: iteration 39, average log likelihood -1.379024
[ Info: iteration 40, average log likelihood -1.379023
[ Info: iteration 41, average log likelihood -1.379023
[ Info: iteration 42, average log likelihood -1.379023
[ Info: iteration 43, average log likelihood -1.379023
[ Info: iteration 44, average log likelihood -1.379023
[ Info: iteration 45, average log likelihood -1.379023
[ Info: iteration 46, average log likelihood -1.379023
[ Info: iteration 47, average log likelihood -1.379023
[ Info: iteration 48, average log likelihood -1.379023
[ Info: iteration 49, average log likelihood -1.379023
[ Info: iteration 50, average log likelihood -1.379023
┌ Info: EM with 100000 data points 50 iterations avll -1.379023
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.419681298384
│     -1.4195926888366444
│      ⋮
└     -1.3790231485837194
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.379137
[ Info: iteration 2, average log likelihood -1.379032
[ Info: iteration 3, average log likelihood -1.378654
[ Info: iteration 4, average log likelihood -1.374752
[ Info: iteration 5, average log likelihood -1.362239
[ Info: iteration 6, average log likelihood -1.352212
[ Info: iteration 7, average log likelihood -1.348393
[ Info: iteration 8, average log likelihood -1.346885
[ Info: iteration 9, average log likelihood -1.346156
[ Info: iteration 10, average log likelihood -1.345692
[ Info: iteration 11, average log likelihood -1.345337
[ Info: iteration 12, average log likelihood -1.345046
[ Info: iteration 13, average log likelihood -1.344798
[ Info: iteration 14, average log likelihood -1.344573
[ Info: iteration 15, average log likelihood -1.344355
[ Info: iteration 16, average log likelihood -1.344127
[ Info: iteration 17, average log likelihood -1.343886
[ Info: iteration 18, average log likelihood -1.343647
[ Info: iteration 19, average log likelihood -1.343425
[ Info: iteration 20, average log likelihood -1.343231
[ Info: iteration 21, average log likelihood -1.343062
[ Info: iteration 22, average log likelihood -1.342908
[ Info: iteration 23, average log likelihood -1.342769
[ Info: iteration 24, average log likelihood -1.342645
[ Info: iteration 25, average log likelihood -1.342537
[ Info: iteration 26, average log likelihood -1.342446
[ Info: iteration 27, average log likelihood -1.342370
[ Info: iteration 28, average log likelihood -1.342310
[ Info: iteration 29, average log likelihood -1.342261
[ Info: iteration 30, average log likelihood -1.342221
[ Info: iteration 31, average log likelihood -1.342188
[ Info: iteration 32, average log likelihood -1.342159
[ Info: iteration 33, average log likelihood -1.342133
[ Info: iteration 34, average log likelihood -1.342110
[ Info: iteration 35, average log likelihood -1.342089
[ Info: iteration 36, average log likelihood -1.342068
[ Info: iteration 37, average log likelihood -1.342047
[ Info: iteration 38, average log likelihood -1.342026
[ Info: iteration 39, average log likelihood -1.342004
[ Info: iteration 40, average log likelihood -1.341981
[ Info: iteration 41, average log likelihood -1.341956
[ Info: iteration 42, average log likelihood -1.341929
[ Info: iteration 43, average log likelihood -1.341896
[ Info: iteration 44, average log likelihood -1.341857
[ Info: iteration 45, average log likelihood -1.341807
[ Info: iteration 46, average log likelihood -1.341744
[ Info: iteration 47, average log likelihood -1.341658
[ Info: iteration 48, average log likelihood -1.341537
[ Info: iteration 49, average log likelihood -1.341370
[ Info: iteration 50, average log likelihood -1.341163
┌ Info: EM with 100000 data points 50 iterations avll -1.341163
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3791369182330384
│     -1.3790324020574767
│      ⋮
└     -1.341163255009045
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.341125
[ Info: iteration 2, average log likelihood -1.340769
[ Info: iteration 3, average log likelihood -1.340268
[ Info: iteration 4, average log likelihood -1.336618
[ Info: iteration 5, average log likelihood -1.319590
[ Info: iteration 6, average log likelihood -1.302474
[ Info: iteration 7, average log likelihood -1.296420
[ Info: iteration 8, average log likelihood -1.293505
[ Info: iteration 9, average log likelihood -1.291799
[ Info: iteration 10, average log likelihood -1.290827
[ Info: iteration 11, average log likelihood -1.290214
[ Info: iteration 12, average log likelihood -1.289758
[ Info: iteration 13, average log likelihood -1.289354
[ Info: iteration 14, average log likelihood -1.288933
[ Info: iteration 15, average log likelihood -1.288460
[ Info: iteration 16, average log likelihood -1.287971
[ Info: iteration 17, average log likelihood -1.287519
[ Info: iteration 18, average log likelihood -1.287138
[ Info: iteration 19, average log likelihood -1.286824
[ Info: iteration 20, average log likelihood -1.286565
[ Info: iteration 21, average log likelihood -1.286345
[ Info: iteration 22, average log likelihood -1.286154
[ Info: iteration 23, average log likelihood -1.285989
[ Info: iteration 24, average log likelihood -1.285845
[ Info: iteration 25, average log likelihood -1.285714
[ Info: iteration 26, average log likelihood -1.285594
[ Info: iteration 27, average log likelihood -1.285477
[ Info: iteration 28, average log likelihood -1.285358
[ Info: iteration 29, average log likelihood -1.285235
[ Info: iteration 30, average log likelihood -1.285104
[ Info: iteration 31, average log likelihood -1.284958
[ Info: iteration 32, average log likelihood -1.284779
[ Info: iteration 33, average log likelihood -1.284556
[ Info: iteration 34, average log likelihood -1.284313
[ Info: iteration 35, average log likelihood -1.284066
[ Info: iteration 36, average log likelihood -1.283826
[ Info: iteration 37, average log likelihood -1.283600
[ Info: iteration 38, average log likelihood -1.283390
[ Info: iteration 39, average log likelihood -1.283194
[ Info: iteration 40, average log likelihood -1.283015
[ Info: iteration 41, average log likelihood -1.282854
[ Info: iteration 42, average log likelihood -1.282713
[ Info: iteration 43, average log likelihood -1.282599
[ Info: iteration 44, average log likelihood -1.282511
[ Info: iteration 45, average log likelihood -1.282444
[ Info: iteration 46, average log likelihood -1.282392
[ Info: iteration 47, average log likelihood -1.282349
[ Info: iteration 48, average log likelihood -1.282311
[ Info: iteration 49, average log likelihood -1.282277
[ Info: iteration 50, average log likelihood -1.282247
┌ Info: EM with 100000 data points 50 iterations avll -1.282247
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.341125357155523
│     -1.3407687289565464
│      ⋮
└     -1.2822467206473798
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.282438
[ Info: iteration 2, average log likelihood -1.282156
[ Info: iteration 3, average log likelihood -1.280954
[ Info: iteration 4, average log likelihood -1.269259
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.238476
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.226194
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.216980
[ Info: iteration 8, average log likelihood -1.206081
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.192981
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.210514
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.203352
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.195723
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.211426
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.201961
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.194369
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.199552
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.191015
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.208795
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.201859
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.194477
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.188190
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.206918
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.203406
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.195439
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.196992
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.202676
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.200973
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.193740
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.202891
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.205302
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.195209
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.200370
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.190025
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.206933
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.194990
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.207111
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.193295
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.201550
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.201654
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.194087
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.194797
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.201368
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.208461
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.197488
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.189313
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.207997
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.195530
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.199027
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.189368
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.206608
┌ Info: EM with 100000 data points 50 iterations avll -1.206608
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2824381061386816
│     -1.2821562991599433
│      ⋮
└     -1.2066084262339922
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.203427
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     25
│     26
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.188527
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.190259
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     25
│     26
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.182285
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.162556
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.125295
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     12
│     18
│     24
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.109633
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     19
│     20
│     23
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.115139
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     18
│     22
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.109053
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     19
│     20
│     24
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.095452
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     12
│     18
│     23
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.116849
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.115070
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     18
│     19
│     20
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.087297
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     22
│     23
│     25
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.103045
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     18
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.117079
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.108406
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     23
│     24
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.094169
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     11
│     19
│     20
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.095114
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     18
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.126595
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.114412
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     18
│     19
│     20
│     23
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.087869
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     22
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.101148
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     12
│     18
│     19
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.115146
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     20
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.114391
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     18
│     23
│     24
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.096803
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     20
│     22
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.117068
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     12
│     18
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.112237
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     20
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.105639
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     23
│     24
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.105571
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     20
│     22
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.098741
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.092442
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     20
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.112475
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     18
│     23
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.099536
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     20
│     22
│     24
│     25
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.092140
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.092543
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     20
│     23
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.112101
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.104474
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     20
│     22
│     24
│     25
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.089009
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.091804
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     20
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.116470
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.101269
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     20
│     22
│     23
│     24
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.087824
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.095792
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     20
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.118275
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.102322
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     20
│     22
│     23
│     25
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.088651
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.089778
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     20
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.117532
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     18
│     23
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.101513
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     20
│     22
│     25
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.093704
┌ Info: EM with 100000 data points 50 iterations avll -1.093704
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.203427032300969
│     -1.188526678213515
│      ⋮
└     -1.0937040087311407
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4196164567054304
│     -1.419681298384
│     -1.4195926888366444
│     -1.4187408162267188
│      ⋮
│     -1.1175316593004039
│     -1.1015126671521283
└     -1.0937040087311407
32×26 Array{Float64,2}:
  0.0342034   0.0213985    -0.00690367   0.0468772   -0.0610646    -0.121343    0.148275    -0.127429    -0.042406     -0.0710571    -0.0223481   -0.043195     0.191642      0.118866     0.00647171  -0.132827     0.0341257    0.0824        0.124089     -0.0954169   -0.000205216   0.121059    -0.296004     0.120212      0.0172989    0.0555773
 -0.0403685   0.109409     -0.00854622   0.0343423    0.0916336     0.0133441   0.00510598  -0.0223525   -0.071365     -0.038794      0.0321372    0.120959     0.0744897     0.0265563    0.0335002    0.0297116   -0.0856779    0.0256348     0.0491906    -0.0498721   -0.00661566   -0.0472711    0.0248187    0.101946     -0.0215281   -0.0362211
 -0.0318846   0.00956705    0.0294413    0.0735944   -0.0521882     0.0800238  -0.0112731   -0.228436    -0.0275193    -0.161365     -0.133238    -0.11512      0.00715038   -0.110054    -0.010345    -0.0625081   -0.0235701   -0.141809     -0.0152153    -0.024654     0.00391144    0.0414259   -0.127674     0.112488      0.0421147   -0.0298628
  0.145122    0.00587577    0.00964361  -0.0886317    0.0590297    -0.0266375   0.039799     0.0435656    0.0931432    -0.000955882   0.0668254   -0.0523107    0.0621179    -0.0618142   -0.00826717   0.117988    -0.0286574    0.0912111     0.0189188     0.0609107    0.0774421     0.0562676   -0.0094741   -0.0346784     0.0145717   -0.0499047
  0.0306731  -0.105507     -0.00726919   0.108687     0.0483272     0.0437045  -0.174021    -0.0284147   -0.0312413     0.0585496     0.00963604  -0.16377     -0.0158245     0.176529     0.0838758    0.0407412   -0.0752806    0.0850261     0.0124218    -0.0104299   -0.228718      0.040906    -0.064879    -0.0131126     0.0515423   -0.0344608
  0.214025    0.103481     -0.174087     0.0191372   -0.0342041    -0.0797748   0.00928979  -0.0444876   -0.108319     -0.200933     -0.0984002    0.0385447   -0.0759581    -0.0827162    0.0649263    0.169198    -0.0243032   -0.0733042     0.0670197     0.0155978   -0.0320179    -0.0389919   -0.0822834   -0.0368847     0.0945999    0.0875688
 -0.140899   -0.0685721    -0.00801171  -0.134618    -0.032034     -0.0118546   0.0238298    0.0668441    0.0639618     0.0169691    -0.0627162    0.101479     0.00813949    0.0313774    0.004336    -0.0785897   -0.0307443   -0.0171144     0.0764927    -0.0755821    0.0972777    -0.0986231   -0.0290348    0.0496941    -0.0682347   -0.0301937
 -0.09927    -0.0643646    -0.00718451   0.098409    -0.170978     -0.0556748  -0.0553065    0.153338     0.0503271     0.12989      -0.0209734   -0.0717734    0.0450626     0.00245948   0.0491678    0.0435425    0.0380113    0.0354078     0.0389698    -0.0739426    0.0517381     0.194867    -0.0333324   -0.0029208     0.0619289    0.0143221
 -0.0625768  -0.0372796    -0.0114813    0.124245    -0.0470127     0.187388    0.0729904    0.0574023   -0.0729012    -0.0432333     0.0719163   -0.224522    -0.106533     -0.174436     0.0651151   -0.0935877   -0.123626    -0.0963592     0.131162     -0.582226     0.0866979     0.15484     -0.117568     0.0657489    -0.0113872   -0.0766982
  0.0339823   0.0896967    -0.0422105    0.123705    -0.0541387     0.170631    0.0651292    0.12209     -0.159045     -0.119215      0.0792807    0.0140763   -0.116486     -0.205282     0.0300131   -0.0917824   -0.108926     0.0467695     0.126412      0.646434     0.0090933     0.151072    -0.109557    -0.0475729     0.00226524   0.0289587
 -0.0036066   0.00349643    0.12988     -0.00167454   0.12362      -0.0919675   0.0612279    0.0661877    0.00794585    0.0326424     0.0343244   -0.042154    -0.0735701     0.0101962   -0.127963    -0.206722    -0.0208021    0.00551817   -0.000292849  -0.0137674    0.146641     -0.104361     0.0703479   -0.0797818     0.131978    -0.130971
  0.0363524   0.0697366    -0.0410804    0.0100136    0.0523959    -0.035161    0.0550875   -0.00490917  -0.1535        0.116246     -0.00349926  -0.104326    -0.0746919    -0.174206    -0.0277282   -0.111118     0.0980991    0.108375      0.0554824    -0.0625852   -0.0766067     0.00724668   0.0376788    0.0921416     0.0954762   -0.0885111
  0.037557    0.167875      0.0596773    0.113131    -0.109292     -0.03959     0.203612     0.019       -0.00875448    0.0690643     0.0792964   -0.0929769    0.0759236    -0.149782     0.0488868    0.00560694  -0.144499     0.110613     -0.111678      0.0966736   -0.112541      0.140135     0.160122     0.130003     -0.0165561    0.0686303
  0.111758    0.194092      0.107802    -0.125063     0.0230321    -0.0194057   0.119748     0.108601     0.11573      -0.163412     -0.0355986    0.192718    -0.0444406     0.132938    -0.121219    -0.0689828   -0.126178    -0.0456877     0.018589     -0.0855291   -0.057996     -0.0933822   -0.0324887   -0.000956149   0.0982474   -0.0232591
  0.327799    0.0686336     0.0442109    0.0931969   -0.142103      0.147287    0.027689     0.0482318   -0.000736696  -0.104882     -0.361463    -0.190874     0.037752     -0.17302     -0.0411583   -0.0147809    0.283674    -0.200365      0.193719      0.0261309    0.0888036    -0.769514     0.0961104    0.212318      0.139355    -0.142547
 -0.0786999   0.027532      0.0549973    0.0682821   -0.154735     -0.0113189   0.0509575    0.0666442    0.117807     -0.117174     -0.258737     0.0181468   -0.0245103    -0.058517     0.105714    -0.0232032    0.20881     -0.195724     -0.0423011     0.0357004   -0.0470891     0.338652     0.00834912   0.141967      0.174761    -0.090235
 -0.0792923  -0.174458     -0.0254329    0.0784177   -0.00714848    0.0344119  -0.135135     0.0175889   -0.0947924    -0.0227322     0.0363357   -0.113525     0.000405383  -0.159321     0.0760007   -0.0136444   -0.0535757    0.149276      0.0332521    -0.00920812  -0.0730613    -0.0305071    0.0967834    0.0468098    -0.012685    -0.0425157
 -0.0793608   0.000735724   0.042105    -0.100422    -0.110505     -0.0395557   0.079195     0.12233      0.149309      0.0968295    -0.154616    -0.161527    -0.0747005    -0.00492797   0.234353     0.0245148   -0.00700068  -0.092167      0.0361993    -0.0212295    0.190906      0.0741511    0.00211174  -0.0557372    -0.026486    -0.0741206
 -0.0419187  -0.0928458     0.123485     0.131105    -0.144867      0.179646   -0.0208316    0.0330823   -0.108614     -0.0995676    -0.0531896    0.150688     0.212594      0.124433     0.0242764    0.0628231    0.0307056   -0.0967454     0.243867      0.163686    -0.0274345    -0.0439214   -0.161266     0.137507      0.157498     0.0352419
  0.0241722   0.158334     -0.0313881   -0.0562982    0.0874322     0.0511862   0.0202395    0.117089    -0.118097      0.104025     -0.0781497    0.082948    -0.136474      0.0945136    0.107518     0.0118582    0.0961407    0.131393      0.0685128     0.0622052   -0.238785      0.148663    -0.0735047    0.0167068     0.181632     0.135002
 -0.0993935   0.0204097    -0.134514    -0.201396     0.106232     -0.156692   -0.00047296  -0.244222     0.0362533     0.115796     -0.0709299    0.104844     0.0963227    -0.021667    -0.0523121   -0.00637192  -0.0272349   -0.11798       0.186017      0.071381    -0.0186015     0.239982     0.0415442    0.0424271    -0.00754731   0.145223
  0.144903   -0.029874     -0.0823913    0.155927     0.0123394    -0.121172    0.0524386   -0.01619      0.0304125    -0.112133      0.0391774    0.085616    -0.0479818     0.114053    -0.011593     0.260778    -0.00620885  -0.0607724     0.0433033    -0.102339     0.096564      0.00534257  -0.0830438   -0.124765      0.116209    -0.0658039
 -0.064548    0.00443977   -0.0761074    0.0865414    0.0254362     0.0733639   0.0215948   -0.0890407    0.107213      0.141921     -0.133003    -0.0351643   -0.0268903     0.195515    -0.00936456   0.081871     0.252429    -0.228628     -0.231121      0.0161141   -0.0353725    -0.0207405   -0.00112357   0.0626241    -0.0264987   -0.134676
 -0.123016    0.0975034    -0.0168782    0.0188447    0.00992077   -0.111258   -0.0464105   -0.0619092    0.153583      0.13033      -0.0174323    0.0271416    0.0157893     0.0368695   -0.0349286    0.0234602    0.0252652    0.234003     -0.0346271     0.164204     0.215083     -0.0581247    0.00354163  -0.110083     -0.0162555   -0.119207
  0.0709943  -0.139321     -0.0984872    0.139307    -0.15755      -0.0126407   0.225306     0.141771     0.0612393     0.128718      0.226664     0.0134972   -0.0146278     0.248765     0.00586677   0.0135261   -0.215927    -0.0139041     0.131263      0.0506238   -0.00613832   -0.0272409    0.0528616    0.122123      0.0291031    0.164931
 -0.0260661   0.158715      0.193275    -0.00993396  -0.150849     -0.0148955   0.149801    -0.0109156    0.0608555     0.0825789    -0.022203     0.161954    -0.0234112     0.180266    -0.00374164  -0.0767925   -0.0267518   -0.000805517  -0.141396      0.0497719   -0.0380867    -0.065716     0.11855      0.107638      0.0296743    0.165089
 -0.0583158  -0.00936698   -0.0155063   -0.162039     0.153792     -0.0115282   0.171631    -0.290301    -0.0839333     0.0138277     0.118492    -0.0244819   -0.179092      0.103021     0.253408     0.0606584   -1.77791      0.217914      0.00323584   -0.14624      0.186298     -0.199694     0.150039     0.0937916     0.0123873   -0.0489182
 -0.0405293  -0.027832      0.0436654   -0.150146     0.15398      -0.130127    0.238543    -0.280674    -0.0166369     0.00932695    0.117941    -0.00927213  -0.120344      0.0652357   -0.0302177    0.0962815    1.48914      0.332784      0.00997689   -0.143635     0.167797      0.0417003    0.15256      0.111772      0.0306376   -0.0918331
  0.186041    0.408566     -0.0347218    0.112344    -0.0284264     0.0916047   0.0965754   -0.0912343    0.0156391     0.0730641     0.00618484  -0.173141    -0.127047     -1.139        0.406026     0.0770602    0.102816    -0.0400162    -0.387771      0.112302     0.295106      0.0652647   -0.0624495    0.1688        0.36915      0.342711
  0.0218393  -0.0318969     0.0464596    0.105975     0.0599224     0.0857696  -0.10274     -0.190111     0.0195896    -0.0216068    -0.00803846   0.110918     0.100992      0.196487    -0.0789188    0.00857331   0.11777     -0.0389195     0.187551      0.11238     -0.0326703     0.287859     0.0252113    0.170555     -0.1558       0.0769991
  0.26162     0.0766493     0.142005    -0.0475979    0.000662239   0.105679    0.0273648    0.237279    -0.000253193   0.0995558    -0.188187     0.0703371   -0.0350926    -0.660952    -0.0470971   -0.138676    -0.0850915   -0.027691      0.0627937     0.0298877    0.0585396     0.222512     0.0205617   -0.0532303    -0.042168     0.325076
  0.209683    0.0864355    -0.0951261    0.0107664   -0.0146718    -0.0643709  -0.147238     0.20595      0.0680836     0.0504343    -0.0636049   -0.0944132   -0.0795913     0.585772    -0.0273635   -0.146781     0.029975     0.0718431     0.0726394     0.0422741    0.0686109    -0.156179     0.0276353   -0.0573044    -0.047521     0.336094[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.086356
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.067901
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.079033
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.073184
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.081164
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.066513
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.085637
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.068792
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.078947
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      6
│     11
│     12
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.073172
┌ Info: EM with 100000 data points 10 iterations avll -1.073172
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.051994e+05
      1       6.999546e+05      -2.052448e+05 |       32
      2       6.770349e+05      -2.291964e+04 |       32
      3       6.626205e+05      -1.441443e+04 |       32
      4       6.511000e+05      -1.152049e+04 |       32
      5       6.441350e+05      -6.965002e+03 |       32
      6       6.401268e+05      -4.008248e+03 |       32
      7       6.366685e+05      -3.458328e+03 |       32
      8       6.341733e+05      -2.495188e+03 |       32
      9       6.327338e+05      -1.439491e+03 |       32
     10       6.317578e+05      -9.759506e+02 |       32
     11       6.309588e+05      -7.990170e+02 |       32
     12       6.302316e+05      -7.272073e+02 |       32
     13       6.292991e+05      -9.325047e+02 |       32
     14       6.280863e+05      -1.212753e+03 |       32
     15       6.266182e+05      -1.468183e+03 |       32
     16       6.255022e+05      -1.115923e+03 |       32
     17       6.248251e+05      -6.771617e+02 |       32
     18       6.242817e+05      -5.433446e+02 |       32
     19       6.238204e+05      -4.613109e+02 |       32
     20       6.234111e+05      -4.093344e+02 |       32
     21       6.231610e+05      -2.501045e+02 |       32
     22       6.230397e+05      -1.212704e+02 |       32
     23       6.229776e+05      -6.213109e+01 |       31
     24       6.229439e+05      -3.364439e+01 |       31
     25       6.229275e+05      -1.643890e+01 |       32
     26       6.229175e+05      -9.998083e+00 |       30
     27       6.229133e+05      -4.170893e+00 |       26
     28       6.229113e+05      -2.027098e+00 |       23
     29       6.229099e+05      -1.411038e+00 |       23
     30       6.229085e+05      -1.404604e+00 |       15
     31       6.229073e+05      -1.152052e+00 |       21
     32       6.229061e+05      -1.204529e+00 |       12
     33       6.229057e+05      -3.976373e-01 |        9
     34       6.229053e+05      -4.159340e-01 |        7
     35       6.229050e+05      -3.442776e-01 |        6
     36       6.229045e+05      -4.955222e-01 |        8
     37       6.229042e+05      -2.398003e-01 |        7
     38       6.229040e+05      -2.343580e-01 |        7
     39       6.229039e+05      -9.297401e-02 |        0
     40       6.229039e+05       0.000000e+00 |        0
K-means converged with 40 iterations (objv = 622903.9023397531)
┌ Info: K-means with 32000 data points using 40 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.339533
[ Info: iteration 2, average log likelihood -1.314275
[ Info: iteration 3, average log likelihood -1.289691
[ Info: iteration 4, average log likelihood -1.257391
[ Info: iteration 5, average log likelihood -1.219826
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.172671
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.144675
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.131417
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.113492
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│     14
│     24
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.096010
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.151980
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.128892
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     20
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.091781
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     11
│     14
│     17
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.090196
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.136325
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.117962
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.096119
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│     14
│     25
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.086942
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.157893
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.110565
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     20
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.094858
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│     11
│     14
│     22
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.088586
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.140104
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.133704
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.099377
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      7
│     14
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.085771
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     22
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.127619
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.120678
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     20
│     21
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.092542
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      7
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.114558
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.139477
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.108808
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.093348
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      7
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.093348
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     17
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.132005
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.131911
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     20
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.082429
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│     14
│     17
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.098983
[ Info: iteration 39, average log likelihood -1.164456
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.099932
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     17
│     20
│     21
│     22
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.056557
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      7
│      9
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.132333
[ Info: iteration 43, average log likelihood -1.154874
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.101115
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     11
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.084602
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      9
│     14
│      ⋮
│     22
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.067370
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.142356
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.140963
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.107495
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│      7
│     17
│     20
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.067732
┌ Info: EM with 100000 data points 50 iterations avll -1.067732
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0401442    0.17112      0.0548909    0.109179    -0.107783    -0.0362584    0.204349      0.0222073  -0.0163249    0.0713573    0.0622431    -0.0833819   0.0762896   -0.137164     0.0533291    0.00622258   -0.130247     0.11218     -0.110782     0.0989852   -0.12471      0.145871     0.155391     0.124001    -0.0060835    0.0722233
 -0.0189695    0.022309    -0.0257916    0.123895    -0.0505983    0.179477     0.0689645     0.0867499  -0.113465    -0.0792532    0.075443     -0.11223    -0.111115    -0.189042     0.0487466   -0.0925509    -0.116376    -0.0295892    0.128989    -0.00957555   0.0503673    0.153171    -0.113864     0.0121423   -0.00506949  -0.0276136
 -0.080651     0.0116119    0.0426643   -0.0965064   -0.113058    -0.0392621    0.0819781     0.123129    0.149895     0.0970884   -0.155026     -0.160999   -0.0746298   -0.00217597   0.232625     0.021249     -0.00779683  -0.092532     0.0357045   -0.0209885    0.187757     0.0770602    0.00733775  -0.0566125   -0.030133    -0.0737645
 -0.0543466   -0.0276047   -0.0185115    0.0374403   -0.0442464   -0.0989346    0.0389664     0.0720645  -0.0379322    0.166118    -0.0304082    -0.0948     -0.0967642   -0.091904     0.0622829    0.00437872    0.0591716    0.125548    -0.0345225   -0.132794     0.0608228    0.098272     1.71881e-5   0.0574102    0.0076243   -0.0451715
  0.212234     0.111307    -0.168032     0.0199472   -0.0198337   -0.0851177    0.00680404   -0.0513046  -0.106335    -0.194252    -0.103124      0.0374675  -0.0789661   -0.081609     0.0658529    0.178555     -0.0237558   -0.0622294    0.0625454    0.0244681   -0.0188018   -0.0450366   -0.0804278   -0.0389642    0.0948906    0.0819712
  0.0335041   -0.104979    -0.0128527    0.118933     0.0499093    0.0417069   -0.176255     -0.034802   -0.0393418    0.0584331    0.00954692   -0.162715   -0.0161052    0.184956     0.0842452    0.0432003    -0.0679859    0.083102     0.0157523   -0.00252828  -0.249681     0.0471427   -0.0736697   -0.00929985   0.0556806   -0.0348688
 -0.0377295   -0.086975    -0.00121958   0.00506327  -0.0359263    0.0406467   -0.00320453   -0.0819174  -0.112382    -0.0369222   -0.0943356    -0.130372    0.101609    -0.210952     0.0120865   -0.175911     -0.0310753   -0.281359     0.0680419   -0.0922294   -0.0381646    0.0633025   -0.174107     0.240124    -0.0271181   -0.0295269
  0.116983     0.0476344    0.0494831    0.0806001   -0.148644     0.0653919    0.0398741     0.0564442   0.0590198   -0.111083    -0.308099     -0.0826726   0.00454059  -0.114515     0.0350683   -0.0192589     0.245485    -0.198107     0.0706745    0.0332258    0.0151639   -0.187621     0.050591     0.176023     0.157745    -0.115836
 -0.0365233    0.114021     0.0609125    0.128973    -0.0626278    0.106337    -0.0209275    -0.377716    0.0691927   -0.276413    -0.17804      -0.0899285  -0.0943132   -0.00496484  -0.0401188    0.0598256    -0.0130356    0.0107186   -0.103638     0.0574402    0.0532879    0.0165787   -0.0762894   -0.0241094    0.119086    -0.0422247
 -0.0347791   -0.0184515   -0.0280115    0.0105252    0.0392795    0.0417507   -0.0736616     0.0624749  -0.110785     0.0364521   -0.0123294    -0.0241204  -0.0688983   -0.0468964    0.0900169   -0.000873374   0.0150279    0.142035     0.0518636    0.0204039   -0.144003     0.0419903    0.018362     0.0275257    0.0776151    0.0333717
 -0.00186718   0.075853    -0.0675736    0.0333179   -0.26334      0.143894    -0.036422      0.0905707   0.0291242    0.122893    -0.000340459   0.174664    0.115656    -0.115424    -0.134376    -0.18291      -0.0138219   -0.0942029    0.00160795  -0.115616     0.00655619   0.257655     0.0128041    0.0202908    0.0704215    0.0130796
 -0.199778    -0.134703     0.0777181   -0.104047    -0.0705728   -0.129759     0.0282776    -0.0638965  -0.01577     -0.00106425  -0.120431      0.0968213   0.0221827    0.0952137    0.0925985   -0.0524577     0.0308977   -0.0717508    0.171644    -0.116912     0.0412177   -0.110276     0.00180764   0.0560744   -0.0831607    0.00216512
 -0.0973588    0.0181407   -0.138486    -0.211561     0.112297    -0.1686      -0.000369658  -0.247569    0.0396042    0.123686    -0.0674827     0.102085    0.0984273   -0.0131957   -0.0467118   -0.00404568   -0.0160331   -0.10925      0.185679     0.072831    -0.0158981    0.239744     0.0420016    0.0420677   -0.0063454    0.145346
  0.017442     0.108841    -0.0690052    0.0918402   -0.109059    -0.0503905   -0.0447014    -0.011962   -0.00720183   0.0260227   -0.051117      0.0672611   0.0163433   -0.053675    -0.00411572   0.0559062    -0.0096543    0.0252954    0.0754971    0.121707     0.0501506    0.105342    -0.0227261   -0.135027     0.135126    -0.00222321
  0.234989     0.0522387    0.062374    -0.0916689    0.132694    -0.122976    -0.0678648     0.082956    0.176164     0.0530653    0.114788     -0.0259954   0.11683      0.0453177    0.038131     0.0668535    -0.16037      0.254235     0.144049    -0.0278051   -0.105695     0.0789014   -0.0434221   -0.0321019    0.0533717    0.0950007
  0.236718     0.0814302    0.0248915   -0.0182097   -0.00658201   0.0216663   -0.0581968     0.221842    0.0326839    0.0750031   -0.125423     -0.0103922  -0.057438    -0.0487514   -0.0374152   -0.143257     -0.0291457    0.0210813    0.0682694    0.0358716    0.0630018    0.0357235    0.0240709   -0.0551638   -0.0442211    0.331519
 -0.0321142   -0.00444264   0.124864    -0.00272337   0.128997    -0.0953296    0.0486123     0.0638688  -0.00174355   0.0321653    0.0309428    -0.0313254  -0.0782439    0.00512521  -0.112909    -0.207416     -0.0550218    0.019769     0.0156792   -0.00619009   0.155073    -0.11255      0.0718621   -0.0945377    0.108601    -0.135179
 -0.0695382    0.126738    -0.0269314   -0.141962     0.0370894    0.00878395  -0.108523      0.0367394  -0.0655794   -0.0530561   -0.122602      0.0734148   0.18539     -0.0248813    0.06799      0.125448     -0.0192308   -0.044242     0.0556653   -0.0853867    0.0441229   -0.0902183    0.0563097    0.0310171   -0.0206469   -0.0533745
  0.0335202    0.023116    -0.00745223   0.046913    -0.0601479   -0.121005     0.148128     -0.127215   -0.042494    -0.070957    -0.022115     -0.0436179   0.191941     0.119002     0.00643085  -0.133636      0.0340347    0.0822799    0.124011    -0.0953248   -0.00129513   0.121415    -0.296213     0.119887     0.0171112    0.0546621
  0.144035    -0.0265579   -0.0843839    0.148251     0.0106664   -0.115453     0.0518054    -0.0169785   0.0312103   -0.104449     0.038381      0.0875719  -0.0514659    0.111736    -0.0126878    0.253037     -0.00782309  -0.064564     0.0437193   -0.108062     0.0949692    0.00762404  -0.0803571   -0.124147     0.118909    -0.0636835
 -0.0496501   -0.0084772   -0.0760292    0.104316     0.0255335    0.0778095    0.0252094    -0.073876    0.0893265    0.147194    -0.114245     -0.029982   -0.014255     0.201003    -0.0011125    0.0876934     0.238224    -0.223315    -0.223043     0.0197955   -0.0435662   -0.0256472    0.00282125   0.0650772   -0.0441603   -0.133517
  0.0183838    0.0102332    0.0417706    0.0727272   -0.155896    -0.0145939    0.181917      0.0615405   0.0609021    0.107271     0.101746      0.0842657  -0.0142848    0.212764     0.00122385  -0.0345533    -0.123581    -0.00569617  -0.00384247   0.0508681   -0.0174551   -0.0447909    0.0849963    0.1116       0.0291204    0.164066
 -0.0912266   -0.106581     0.0234262    0.175568    -0.13992     -0.0990874   -0.144046      0.175106    0.0270072    0.038855     0.000757423  -0.239859    0.126057     0.0801611    0.081782     0.116154      0.0758262    0.0503498    0.209033     0.0791718   -0.0786426    0.151632    -0.0535934   -0.043019     0.211308     0.0207631
 -0.0784468    0.121709    -0.00727198   0.0697101    0.0221335   -0.0624634   -0.024633     -0.0659571   0.219282     0.127071    -0.0298732     0.0795418   0.0143111   -0.0394679   -0.0513122    0.0030238    -0.0507132    0.204021    -0.017277     0.166731     0.183556    -0.0341343    0.00815122  -0.0645004   -0.0506261   -0.074866
  0.061752     0.0679536    0.0240915    0.104657     0.0389614    0.0825265   -0.0554178    -0.162278    0.0183642    0.00455341  -0.0082981     0.0450169   0.0420815   -0.131726     0.0397205    0.0290315     0.115081    -0.035991     0.0469163    0.111291     0.0533218    0.231774     0.00319389   0.167372    -0.0183549    0.14284
 -0.0390754   -0.0932028    0.123118     0.131902    -0.145247     0.179533    -0.0207891     0.0328186  -0.109118    -0.0991248   -0.0519342     0.151864    0.212309     0.124774     0.0242053    0.0631119     0.0315964   -0.0952387    0.24389      0.163949    -0.0288674   -0.0442757   -0.161524     0.137848     0.159384     0.0370654
 -0.0195439    0.0751778    0.00790517   0.200607     0.12432      0.039496     0.106592     -0.0737533  -0.107174    -0.0408948    0.175603      0.163846   -0.0105866    0.0669293   -0.00825968  -0.0427904    -0.110281     0.0791051    0.0262406   -0.0301517   -0.0429421   -0.00236623   0.00886361   0.148705    -0.0302941   -0.0373151
 -0.0490608   -0.0177267    0.0163405   -0.155082     0.153874    -0.0757508    0.207926     -0.286088   -0.0471944    0.0111992    0.11819      -0.0164027  -0.146996     0.0849048    0.100888     0.077785     -0.0294868    0.276248     0.00670945  -0.144441     0.175784    -0.0704342    0.151464     0.104001     0.021956    -0.0711621
  0.06213     -0.0284059   -0.0290909   -0.0816192    0.00632751   0.0605289    0.153002      0.0157249   0.0342074   -0.0284769    0.0447436    -0.0829727  -0.00773478  -0.154264    -0.0357316    0.144877      0.0754224   -0.0773656   -0.081716     0.146163     0.215837     0.0429711    0.0054145   -0.0218217   -0.0166331   -0.151621
  0.0992449    0.192772     0.109336    -0.123886     0.0197753   -0.0190373    0.119679      0.110667    0.117088    -0.159884    -0.0369016     0.19093    -0.0424174    0.133164    -0.11896     -0.0694007    -0.123783    -0.0453212    0.015709    -0.0852869   -0.0535343   -0.091196    -0.032203    -4.3179e-5    0.0981554   -0.0205572
 -0.130213    -0.0394281   -0.130768    -0.206313    -0.0119275    0.116912     0.0394185     0.208051    0.158565     0.0371772   -0.0301316     0.102238   -0.00257065  -0.020025    -0.0579752   -0.0598898    -0.0559088    0.0445301   -0.0198836   -0.0410523    0.178699    -0.116517    -0.0969109    0.0766793   -0.0970376   -0.053667
 -0.152501     0.0781967   -0.0334475   -0.0125101    0.0177681   -0.0999847   -0.0309718    -0.0556684   0.173024     0.137288    -0.0652823     0.016707    0.00531158   0.143025    -0.0450413    0.0226226     0.138902     0.150069    -0.0683841    0.141155     0.183483    -0.0477592    0.00282812  -0.0490151   -0.0454209   -0.131873[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     21
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.117386
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     14
│     18
│     21
│     22
│     25
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.068082
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     11
│     17
│     18
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.032504
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      9
│     14
│      ⋮
│     25
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.062145
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     11
│     21
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.081240
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      9
│     17
│     18
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.054691
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     11
│     14
│     18
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.051816
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      9
│     18
│      ⋮
│     25
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.050143
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     11
│     14
│     17
│      ⋮
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.067051
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     18
│     21
│     22
│     25
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.083265
┌ Info: EM with 100000 data points 10 iterations avll -1.083265
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0294236    -0.0799915     0.0521915  -0.0616693   -0.00957578  -0.084582    0.0310915    0.0657878   -0.0513141    0.0809959    0.0304699    0.0661215    -0.0907543    0.0491337   -0.158043    -0.136457     0.0441735   -0.00703657   0.0612437    0.00194663   0.00067386   0.0426605    -0.0421442   -0.0531872    0.175563   -0.142153
  0.0248501     0.0927652    -0.108806   -0.0117687   -0.0495316   -0.0747273   0.153256     0.0238585    0.117744     0.141069    -0.0988626    0.0567745     0.0131109   -0.0144367   -0.13246      0.097257     0.0439055    0.0067104   -0.00530603   0.0378707   -0.148045     0.0936239     0.0123391    0.0259385    0.122737   -0.0210253
  0.215215      0.0584125     0.114615    0.204086    -0.221879     0.23981     0.214619     0.037547    -0.135498    -0.035102    -0.0763132    0.0299129     0.0494773   -0.0764041    0.158277     0.0698704    0.0837078    0.0722311    0.162616     0.186021    -0.0129558    0.0449087    -0.0583841    0.0140679    0.0596768  -0.0145863
 -0.263259     -0.0683478     0.0456776   0.0528266   -0.0510946    0.0804553   0.067399    -0.0355095   -0.187432     0.144647    -0.0624227    0.000376247   0.0298506    0.111677     0.0922195   -0.0852484    0.237107     0.0438942    0.0323995   -0.154104     0.0191362   -0.0664103     0.0106336   -0.0960467    0.0262524   0.00828239
  0.0235752    -0.172692      0.0299752  -0.111558    -0.0214686   -0.0669808   0.00883466   0.0270594   -0.0891123   -0.129985     0.0123793   -0.000936025  -0.105735     0.235384     0.0604654    0.0390586    0.021052     0.00285043   0.012325     0.0699615    0.0474999    0.00537834    0.095197     0.0679879   -0.0537901   0.0476272
  0.107497     -0.0275732    -0.142495   -0.0550561    0.00462111   0.0584806  -0.2407       0.0689041   -0.0676403   -0.10369      0.0291393   -0.12091       0.0927166    0.123479    -0.196718     0.00245918   0.107016    -0.00214808   0.0859557    0.0464784    0.0850988    0.0371011     0.125309    -0.128483     0.0297889   0.0442793
  0.100837     -0.186372     -0.0503212  -0.115937    -0.0527185    0.104073   -0.158269     0.122842    -0.0717978    0.148049    -0.163702     0.0529768     0.134318     0.201077    -0.00909633   0.107077    -0.0703141   -0.0802004    0.0160602   -0.02345      0.0479632   -0.000422287  -0.00234675  -0.00273473  -0.0530486   0.00524393
 -0.0303326     0.127453      0.0757782   0.0198803    0.0925351    0.0826805  -0.0954492    0.0614548    0.105785     0.0879416   -0.140657     0.0516973     0.0409861   -0.0513652    0.138951    -0.109994    -0.0399465   -0.0155223   -0.12964      0.0255012   -0.0803752   -0.00596867   -0.13896     -0.0157744    0.106573   -0.0689916
 -0.127299     -0.229746     -0.094287   -0.0149236    0.131293    -0.0522029  -0.0899198    0.0493609   -0.143545     0.0753147    0.0719705   -0.0766895     0.0667791   -0.0382264   -0.0930215    0.212587     0.0998109   -0.224481    -0.122547     0.128265    -0.0710359    0.05749       0.140486     0.0512596    0.0314211  -0.154294
  0.0701464    -0.0891815    -0.0410497  -0.0613711    0.100827     0.152695   -0.0150771   -0.0112124    0.0674218   -0.0810285    0.097029     0.0213745     0.00827972   0.00362793  -0.00983174   0.0495447    0.0388658    0.177211    -0.135566     0.133581    -0.0930706    0.014829      0.09052      0.114462    -0.0355856  -0.170046
  0.0974106     0.00760999   -0.0403387  -0.0416334    0.102433    -0.0293535  -0.0879282   -0.0246332   -0.0900795    0.00369336  -0.0296754   -0.00283683    0.0397902   -0.0713877    0.12863      0.205101     0.0469825    0.167181     0.0470499   -0.227101     0.123897     0.0933819    -0.0487284    0.150361     0.0569676  -0.044743
  0.0398042     0.048686      0.032267   -0.0809811   -0.0458094    0.0407935   0.16042     -0.0246469   -0.00519083   0.152541     0.130925    -0.0887854    -0.0542699   -0.0880623   -0.0281468    0.0880289    0.187192     0.166029     0.10578      0.0399191    0.0999771    0.120986      0.023079    -0.0240034   -0.133882   -0.0866932
  0.0990691     0.00494934    0.0326328   0.0049646   -0.0741152    0.0254558   0.167528    -0.0509585    0.0887113   -0.136662    -0.00323467   0.142098     -0.0613561    0.0425497    0.050556     0.165547    -0.137652    -0.111078     0.0289419    0.0835935    0.104603     0.08093      -0.0570881    0.0201709   -0.0971489   0.12115
  0.0902375     0.000640852  -0.0223702  -0.0793603    0.0429927    0.118944   -0.140137    -0.0777039    0.0762791    0.17461      0.15144      0.00202568   -0.0587085   -0.0449354   -0.142635    -0.0464268    0.120789    -0.106401    -0.162763    -0.0893741    0.210245     0.0228121    -0.0870561    0.179099     0.0861501  -0.032486
  0.0342025     0.000759059  -0.15122     0.0460096    0.152687    -0.143926   -0.0125045    0.155147    -0.0160863   -0.0157725    0.00096899  -0.00284259    0.0114245    0.0936808   -0.0758186   -0.18439      0.0914153   -0.0185581    0.220803    -0.00216064  -0.0982132    0.037057      0.0711953    0.0797057   -0.031977   -0.138216
  0.131847      0.0196531     0.112531    0.112138    -0.0495772   -0.0632731   0.159487     0.0628052    0.0416943    0.124756    -0.193714     0.140669      0.0210151    0.0714085    0.0568694    0.115999     0.186824     0.0678392    0.0485882    0.150511    -0.119039    -0.105409     -0.0695639    0.0201025   -0.206228    0.0685169
  0.0199798    -0.220562      0.075555   -0.00793967  -0.0143678   -0.0773249  -0.232057     0.111711    -0.082133    -0.0444101    0.0841339   -0.161641     -0.177817     0.0963093    0.0171718   -0.0301794    0.0827929   -0.0272186    0.0452333    0.240343    -0.155855    -0.155929      0.00359206   0.161294    -0.0807314   0.0160153
  0.138807      0.0526904    -0.0189824   0.0453211    0.00599517  -0.0620326  -0.164201    -0.201524    -0.0514828   -0.0628648    0.0440501    0.174584     -0.210431    -0.051319    -0.063544     0.120901    -0.0439287    0.103057    -0.0161242    0.0675159   -0.136874    -0.11643       0.093807     0.0302881   -0.209197   -0.0179925
  0.0268013     0.0503848     0.0954793  -0.0422375    0.0553287    0.0558999  -0.0715841   -0.00829962  -0.222282    -0.030693    -0.0322821    0.351573     -0.0186618   -0.00261835   0.068581    -0.0525669   -0.0318483    0.0823006   -0.0191198   -0.0734688    0.0895753    0.007923      0.160463     0.0623421    0.127558    0.0433018
  0.0861097    -0.0646313     0.0442817   0.141342    -0.0427552   -0.095574    0.15777     -0.118933    -0.0177795   -0.0897311    0.103394     0.104037     -0.123791     0.0408092    0.206533     0.186958     0.145077     0.125154    -0.0440932   -0.044711    -0.0498019    0.17674      -0.0824352    0.158103     0.0195027   0.0772093
 -0.00553189   -0.0392825     0.0241576  -0.0794375    0.00683365  -0.0406421  -0.20015     -0.113686    -0.176619     0.036192     0.0722658    0.175521      0.0684419    0.00455764   0.0819571    0.0984008   -0.0496682    0.186924    -0.0541778    0.137734     0.0613462    0.00222257   -0.00303681   0.0352234   -0.0683919   0.00637626
 -0.000610979  -0.00862879    0.0601291   0.0845346    0.0443723    0.0470129   0.0450488    0.00819161   0.046888     0.24168     -0.0849601    0.161322      0.062782    -0.0242793    0.0360124    0.127977     0.0171183   -0.209531    -0.0751338   -0.0149163   -0.134593    -0.148302      0.171181    -0.019354    -0.142001   -0.0705537
 -0.2024        0.130503      0.11765    -0.0106484    0.140476     0.0421718   0.145493     0.0264806   -0.0595629    0.0180547    0.0406204   -0.0171961     0.171252    -0.0706487    0.0662836    0.00711913  -0.0153676   -0.0759407    0.0862382   -0.093856    -0.00686175  -0.113076     -0.0629325    0.210435     0.0256121   0.12851
  0.177731     -0.116284      0.0342692  -0.103884     0.0928595   -0.0351406   0.124905    -0.0733532   -0.182008     0.0800728    0.0528795   -0.134332      0.130804     0.0413922    0.0136123   -0.0555306   -0.0967073    0.145468    -0.139474    -0.152594    -0.0028984   -0.0926529     0.0386578   -0.0305361    0.0637038   0.0148833
  0.0463107     0.13232      -0.167723    0.00289159  -0.0022825   -0.0482735  -0.0709242    0.2675       0.0805538    0.0506003    0.096779    -0.0973782    -0.19181     -0.112297     0.0887683    0.281298    -0.088179     0.114603    -0.0274341   -0.107586    -0.112307    -0.149443     -0.13076      0.0777288   -0.0449312   0.173365
 -0.0244529    -0.153648     -0.0273559  -0.158082    -0.120012    -0.0385567   0.00961324  -0.133861    -0.0104927   -0.100176     0.0162606   -0.0284576    -0.0269865   -0.0988562   -0.095442     0.115245    -0.0159366   -0.125015    -0.023341     0.0713605   -0.0765035   -0.0386366    -0.0607695   -0.0800603   -0.152731    0.174699
  0.0166038    -0.00536964   -0.0264732   0.100662     0.00234645   0.0641909  -0.0246578   -0.170653    -0.0821439   -0.113812    -0.0214226   -0.171313      0.0219385    0.00578421   0.0703033    0.00830271  -0.01571      0.0122406    0.10208      0.0202575    0.00641381  -0.0166631     0.0393566   -0.0877498   -0.0576821  -0.0470655
 -0.052238      0.339191      0.0514148   0.108352    -0.0444009    0.0488897  -0.0837095   -0.131397    -0.0896589   -0.0283964   -0.0887952    0.00329612    0.0800443   -0.0168645   -0.0657344   -0.119607    -0.0723606    0.181432    -0.0913802   -0.042881    -0.0917396    0.0440232     0.0127649    0.144987    -0.0433365   0.1895
 -0.179246     -0.0140315    -0.187891   -0.138189    -0.0590367   -0.130773    0.0550142    0.0249348   -0.150693     0.0900022    0.0525331    0.135936      0.0757084    0.0940639   -0.071433    -0.098363    -0.00334351  -0.13927      0.0398956    0.226651    -0.0502034   -0.140989     -0.103642    -0.00899283   0.254474    0.0652642
 -0.0153059    -0.00447732    0.205046   -0.0510922   -0.0154273   -0.0772787   0.0865718   -0.150311     0.186831     0.104704     0.0374496   -0.0722151    -0.0195108   -0.066197     0.0114712   -0.116205     0.0621769   -0.118287     0.0296833    0.109605     0.0607183   -0.0471173    -0.0905336    0.0356566    0.0503613  -0.122278
  0.0835066    -0.151309      0.0391681   0.110113    -0.0168889    0.0307961  -0.248712    -0.0646402   -0.145759    -0.0501762    0.125876     0.00227195   -0.025513     0.0562403    0.12268      0.0161405    0.0124446    0.0762438   -0.133193     0.0548507   -0.0710579   -0.021218      0.136609     0.00456157  -0.1531      0.0465184
 -0.12597      -0.0253262    -0.0258593   0.0524591   -0.0291582   -0.0834938   0.0923696   -0.120496    -0.0667574    0.142907     0.147999     0.153416      0.162211    -0.0242748   -0.0553508    0.0993392    0.0906106    0.0458925   -0.0457495    0.0630903   -0.083867    -0.0847883     0.0345852    0.214204     0.0474845   0.169553kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4236372909085562
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423656
[ Info: iteration 2, average log likelihood -1.423579
[ Info: iteration 3, average log likelihood -1.423514
[ Info: iteration 4, average log likelihood -1.423433
[ Info: iteration 5, average log likelihood -1.423325
[ Info: iteration 6, average log likelihood -1.423160
[ Info: iteration 7, average log likelihood -1.422873
[ Info: iteration 8, average log likelihood -1.422334
[ Info: iteration 9, average log likelihood -1.421405
[ Info: iteration 10, average log likelihood -1.420193
[ Info: iteration 11, average log likelihood -1.419149
[ Info: iteration 12, average log likelihood -1.418556
[ Info: iteration 13, average log likelihood -1.418300
[ Info: iteration 14, average log likelihood -1.418202
[ Info: iteration 15, average log likelihood -1.418164
[ Info: iteration 16, average log likelihood -1.418149
[ Info: iteration 17, average log likelihood -1.418143
[ Info: iteration 18, average log likelihood -1.418140
[ Info: iteration 19, average log likelihood -1.418139
[ Info: iteration 20, average log likelihood -1.418138
[ Info: iteration 21, average log likelihood -1.418138
[ Info: iteration 22, average log likelihood -1.418138
[ Info: iteration 23, average log likelihood -1.418138
[ Info: iteration 24, average log likelihood -1.418137
[ Info: iteration 25, average log likelihood -1.418137
[ Info: iteration 26, average log likelihood -1.418137
[ Info: iteration 27, average log likelihood -1.418137
[ Info: iteration 28, average log likelihood -1.418137
[ Info: iteration 29, average log likelihood -1.418137
[ Info: iteration 30, average log likelihood -1.418137
[ Info: iteration 31, average log likelihood -1.418137
[ Info: iteration 32, average log likelihood -1.418137
[ Info: iteration 33, average log likelihood -1.418137
[ Info: iteration 34, average log likelihood -1.418137
[ Info: iteration 35, average log likelihood -1.418137
[ Info: iteration 36, average log likelihood -1.418136
[ Info: iteration 37, average log likelihood -1.418136
[ Info: iteration 38, average log likelihood -1.418136
[ Info: iteration 39, average log likelihood -1.418136
[ Info: iteration 40, average log likelihood -1.418136
[ Info: iteration 41, average log likelihood -1.418136
[ Info: iteration 42, average log likelihood -1.418136
[ Info: iteration 43, average log likelihood -1.418136
[ Info: iteration 44, average log likelihood -1.418136
[ Info: iteration 45, average log likelihood -1.418136
[ Info: iteration 46, average log likelihood -1.418136
[ Info: iteration 47, average log likelihood -1.418136
[ Info: iteration 48, average log likelihood -1.418136
[ Info: iteration 49, average log likelihood -1.418136
[ Info: iteration 50, average log likelihood -1.418136
┌ Info: EM with 100000 data points 50 iterations avll -1.418136
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4236561260917786
│     -1.4235785778540433
│      ⋮
└     -1.4181361802768924
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418152
[ Info: iteration 2, average log likelihood -1.418080
[ Info: iteration 3, average log likelihood -1.418017
[ Info: iteration 4, average log likelihood -1.417942
[ Info: iteration 5, average log likelihood -1.417853
[ Info: iteration 6, average log likelihood -1.417756
[ Info: iteration 7, average log likelihood -1.417659
[ Info: iteration 8, average log likelihood -1.417573
[ Info: iteration 9, average log likelihood -1.417501
[ Info: iteration 10, average log likelihood -1.417441
[ Info: iteration 11, average log likelihood -1.417390
[ Info: iteration 12, average log likelihood -1.417345
[ Info: iteration 13, average log likelihood -1.417306
[ Info: iteration 14, average log likelihood -1.417271
[ Info: iteration 15, average log likelihood -1.417241
[ Info: iteration 16, average log likelihood -1.417215
[ Info: iteration 17, average log likelihood -1.417193
[ Info: iteration 18, average log likelihood -1.417173
[ Info: iteration 19, average log likelihood -1.417155
[ Info: iteration 20, average log likelihood -1.417137
[ Info: iteration 21, average log likelihood -1.417121
[ Info: iteration 22, average log likelihood -1.417105
[ Info: iteration 23, average log likelihood -1.417090
[ Info: iteration 24, average log likelihood -1.417076
[ Info: iteration 25, average log likelihood -1.417062
[ Info: iteration 26, average log likelihood -1.417049
[ Info: iteration 27, average log likelihood -1.417038
[ Info: iteration 28, average log likelihood -1.417027
[ Info: iteration 29, average log likelihood -1.417017
[ Info: iteration 30, average log likelihood -1.417007
[ Info: iteration 31, average log likelihood -1.416999
[ Info: iteration 32, average log likelihood -1.416992
[ Info: iteration 33, average log likelihood -1.416985
[ Info: iteration 34, average log likelihood -1.416980
[ Info: iteration 35, average log likelihood -1.416975
[ Info: iteration 36, average log likelihood -1.416970
[ Info: iteration 37, average log likelihood -1.416966
[ Info: iteration 38, average log likelihood -1.416962
[ Info: iteration 39, average log likelihood -1.416959
[ Info: iteration 40, average log likelihood -1.416957
[ Info: iteration 41, average log likelihood -1.416954
[ Info: iteration 42, average log likelihood -1.416952
[ Info: iteration 43, average log likelihood -1.416950
[ Info: iteration 44, average log likelihood -1.416948
[ Info: iteration 45, average log likelihood -1.416947
[ Info: iteration 46, average log likelihood -1.416945
[ Info: iteration 47, average log likelihood -1.416944
[ Info: iteration 48, average log likelihood -1.416943
[ Info: iteration 49, average log likelihood -1.416942
[ Info: iteration 50, average log likelihood -1.416941
┌ Info: EM with 100000 data points 50 iterations avll -1.416941
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4181515252200754
│     -1.4180799279705358
│      ⋮
└     -1.416940580735215
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416953
[ Info: iteration 2, average log likelihood -1.416906
[ Info: iteration 3, average log likelihood -1.416869
[ Info: iteration 4, average log likelihood -1.416826
[ Info: iteration 5, average log likelihood -1.416774
[ Info: iteration 6, average log likelihood -1.416714
[ Info: iteration 7, average log likelihood -1.416644
[ Info: iteration 8, average log likelihood -1.416570
[ Info: iteration 9, average log likelihood -1.416496
[ Info: iteration 10, average log likelihood -1.416427
[ Info: iteration 11, average log likelihood -1.416366
[ Info: iteration 12, average log likelihood -1.416314
[ Info: iteration 13, average log likelihood -1.416271
[ Info: iteration 14, average log likelihood -1.416234
[ Info: iteration 15, average log likelihood -1.416204
[ Info: iteration 16, average log likelihood -1.416177
[ Info: iteration 17, average log likelihood -1.416154
[ Info: iteration 18, average log likelihood -1.416133
[ Info: iteration 19, average log likelihood -1.416113
[ Info: iteration 20, average log likelihood -1.416095
[ Info: iteration 21, average log likelihood -1.416078
[ Info: iteration 22, average log likelihood -1.416062
[ Info: iteration 23, average log likelihood -1.416046
[ Info: iteration 24, average log likelihood -1.416031
[ Info: iteration 25, average log likelihood -1.416017
[ Info: iteration 26, average log likelihood -1.416003
[ Info: iteration 27, average log likelihood -1.415990
[ Info: iteration 28, average log likelihood -1.415977
[ Info: iteration 29, average log likelihood -1.415965
[ Info: iteration 30, average log likelihood -1.415952
[ Info: iteration 31, average log likelihood -1.415940
[ Info: iteration 32, average log likelihood -1.415929
[ Info: iteration 33, average log likelihood -1.415917
[ Info: iteration 34, average log likelihood -1.415906
[ Info: iteration 35, average log likelihood -1.415895
[ Info: iteration 36, average log likelihood -1.415884
[ Info: iteration 37, average log likelihood -1.415873
[ Info: iteration 38, average log likelihood -1.415862
[ Info: iteration 39, average log likelihood -1.415852
[ Info: iteration 40, average log likelihood -1.415841
[ Info: iteration 41, average log likelihood -1.415830
[ Info: iteration 42, average log likelihood -1.415820
[ Info: iteration 43, average log likelihood -1.415810
[ Info: iteration 44, average log likelihood -1.415799
[ Info: iteration 45, average log likelihood -1.415789
[ Info: iteration 46, average log likelihood -1.415779
[ Info: iteration 47, average log likelihood -1.415770
[ Info: iteration 48, average log likelihood -1.415760
[ Info: iteration 49, average log likelihood -1.415751
[ Info: iteration 50, average log likelihood -1.415742
┌ Info: EM with 100000 data points 50 iterations avll -1.415742
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4169528489438759
│     -1.4169057156936025
│      ⋮
└     -1.4157420440516897
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415743
[ Info: iteration 2, average log likelihood -1.415688
[ Info: iteration 3, average log likelihood -1.415638
[ Info: iteration 4, average log likelihood -1.415582
[ Info: iteration 5, average log likelihood -1.415515
[ Info: iteration 6, average log likelihood -1.415433
[ Info: iteration 7, average log likelihood -1.415336
[ Info: iteration 8, average log likelihood -1.415225
[ Info: iteration 9, average log likelihood -1.415104
[ Info: iteration 10, average log likelihood -1.414980
[ Info: iteration 11, average log likelihood -1.414858
[ Info: iteration 12, average log likelihood -1.414741
[ Info: iteration 13, average log likelihood -1.414634
[ Info: iteration 14, average log likelihood -1.414538
[ Info: iteration 15, average log likelihood -1.414453
[ Info: iteration 16, average log likelihood -1.414380
[ Info: iteration 17, average log likelihood -1.414316
[ Info: iteration 18, average log likelihood -1.414261
[ Info: iteration 19, average log likelihood -1.414214
[ Info: iteration 20, average log likelihood -1.414172
[ Info: iteration 21, average log likelihood -1.414136
[ Info: iteration 22, average log likelihood -1.414104
[ Info: iteration 23, average log likelihood -1.414076
[ Info: iteration 24, average log likelihood -1.414050
[ Info: iteration 25, average log likelihood -1.414026
[ Info: iteration 26, average log likelihood -1.414003
[ Info: iteration 27, average log likelihood -1.413983
[ Info: iteration 28, average log likelihood -1.413963
[ Info: iteration 29, average log likelihood -1.413944
[ Info: iteration 30, average log likelihood -1.413925
[ Info: iteration 31, average log likelihood -1.413908
[ Info: iteration 32, average log likelihood -1.413890
[ Info: iteration 33, average log likelihood -1.413873
[ Info: iteration 34, average log likelihood -1.413857
[ Info: iteration 35, average log likelihood -1.413840
[ Info: iteration 36, average log likelihood -1.413824
[ Info: iteration 37, average log likelihood -1.413809
[ Info: iteration 38, average log likelihood -1.413793
[ Info: iteration 39, average log likelihood -1.413778
[ Info: iteration 40, average log likelihood -1.413763
[ Info: iteration 41, average log likelihood -1.413749
[ Info: iteration 42, average log likelihood -1.413735
[ Info: iteration 43, average log likelihood -1.413721
[ Info: iteration 44, average log likelihood -1.413707
[ Info: iteration 45, average log likelihood -1.413694
[ Info: iteration 46, average log likelihood -1.413681
[ Info: iteration 47, average log likelihood -1.413669
[ Info: iteration 48, average log likelihood -1.413657
[ Info: iteration 49, average log likelihood -1.413645
[ Info: iteration 50, average log likelihood -1.413634
┌ Info: EM with 100000 data points 50 iterations avll -1.413634
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4157425499828138
│     -1.4156877941376462
│      ⋮
└     -1.4136337594064292
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413631
[ Info: iteration 2, average log likelihood -1.413562
[ Info: iteration 3, average log likelihood -1.413495
[ Info: iteration 4, average log likelihood -1.413416
[ Info: iteration 5, average log likelihood -1.413316
[ Info: iteration 6, average log likelihood -1.413191
[ Info: iteration 7, average log likelihood -1.413044
[ Info: iteration 8, average log likelihood -1.412882
[ Info: iteration 9, average log likelihood -1.412716
[ Info: iteration 10, average log likelihood -1.412554
[ Info: iteration 11, average log likelihood -1.412402
[ Info: iteration 12, average log likelihood -1.412262
[ Info: iteration 13, average log likelihood -1.412136
[ Info: iteration 14, average log likelihood -1.412025
[ Info: iteration 15, average log likelihood -1.411927
[ Info: iteration 16, average log likelihood -1.411841
[ Info: iteration 17, average log likelihood -1.411766
[ Info: iteration 18, average log likelihood -1.411700
[ Info: iteration 19, average log likelihood -1.411641
[ Info: iteration 20, average log likelihood -1.411588
[ Info: iteration 21, average log likelihood -1.411541
[ Info: iteration 22, average log likelihood -1.411498
[ Info: iteration 23, average log likelihood -1.411458
[ Info: iteration 24, average log likelihood -1.411420
[ Info: iteration 25, average log likelihood -1.411386
[ Info: iteration 26, average log likelihood -1.411353
[ Info: iteration 27, average log likelihood -1.411321
[ Info: iteration 28, average log likelihood -1.411292
[ Info: iteration 29, average log likelihood -1.411263
[ Info: iteration 30, average log likelihood -1.411236
[ Info: iteration 31, average log likelihood -1.411210
[ Info: iteration 32, average log likelihood -1.411185
[ Info: iteration 33, average log likelihood -1.411161
[ Info: iteration 34, average log likelihood -1.411138
[ Info: iteration 35, average log likelihood -1.411116
[ Info: iteration 36, average log likelihood -1.411094
[ Info: iteration 37, average log likelihood -1.411074
[ Info: iteration 38, average log likelihood -1.411054
[ Info: iteration 39, average log likelihood -1.411034
[ Info: iteration 40, average log likelihood -1.411015
[ Info: iteration 41, average log likelihood -1.410996
[ Info: iteration 42, average log likelihood -1.410978
[ Info: iteration 43, average log likelihood -1.410960
[ Info: iteration 44, average log likelihood -1.410943
[ Info: iteration 45, average log likelihood -1.410926
[ Info: iteration 46, average log likelihood -1.410909
[ Info: iteration 47, average log likelihood -1.410893
[ Info: iteration 48, average log likelihood -1.410876
[ Info: iteration 49, average log likelihood -1.410861
[ Info: iteration 50, average log likelihood -1.410845
┌ Info: EM with 100000 data points 50 iterations avll -1.410845
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.413631268967717
│     -1.4135622699119021
│      ⋮
└     -1.4108451772323047
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4236372909085562
│     -1.4236561260917786
│     -1.4235785778540433
│     -1.4235137084404443
│      ⋮
│     -1.4108764354917949
│     -1.4108606387724736
└     -1.4108451772323047
32×26 Array{Float64,2}:
 -0.650206   -0.0493589   -0.535171    -0.0692559   -0.0966678  -0.466375      0.300122    0.366803   -0.356721   -0.214244    0.463495    -0.113904    0.0152445  -0.197054    0.338169   -0.530256    -0.147597    0.104953     0.562846     0.202504    -0.379897    -0.0481748   0.0560778   -0.155295    -0.434764    -0.0437953
  0.121021   -0.160726    -0.454091    -0.392191     0.0884124   0.0580968     0.315901    0.597012   -0.506613    0.590319   -0.317802     0.635532    0.0209356  -0.602902    0.048677   -0.152546    -0.383836   -0.655323     0.0541749    0.185896     0.0593664   -0.278267    0.10091      0.062077    -0.147626    -0.364114
 -0.298462   -0.320676     0.181175     0.216142     0.542827   -0.143591     -0.44559     0.194369    0.14461    -0.624548   -0.238975     0.129464    0.190663    0.172886    0.12174     0.390458    -0.230777    0.402037     0.39542      0.315225    -0.401956     0.10353     0.193909    -0.19687     -0.435207     0.0239124
  0.179282    0.0803214    0.214388     0.707745    -0.252884   -0.191542      0.818924    0.167788    0.625588   -0.208577   -0.0262916    0.321579   -0.048229   -0.449339   -0.0211902   0.776713     0.297159    0.381648     0.617624     0.051016    -0.00729846   0.139717    0.0533592    0.08906      0.302712    -0.0599732
  0.289295   -0.437714     0.0976191   -0.352576     0.217197   -0.524468      0.313888    0.48188    -0.017045   -0.0230824  -0.0781167   -0.090695    0.515886    0.25        0.107483   -0.162541    -0.503494    0.127623    -0.203385     0.084359    -0.159612     0.122534   -0.204566     0.496309     0.43672      0.159824
  0.283326   -0.474162     0.186414    -0.570272     0.0917688   0.447244      0.342594    0.616531   -0.32391    -0.267684    0.166601    -0.0838958   0.0606314   0.0462261   0.0402174   0.0996228   -0.254796    0.0185137    0.353561     0.134429    -0.094903    -0.173579    0.00175703   0.21388     -0.0912379    0.157533
 -0.140044    0.011086     0.0675116   -0.306856     0.344062   -0.0681358    -0.19656     0.204759    0.511966   -0.848665   -0.133384     0.0699137  -0.501569    0.0664964  -0.278569    0.38009      0.266984   -0.573158     0.285946     0.0405425    0.310281    -0.313363    0.1456      -0.0996331   -0.765013    -0.154934
 -0.285985   -0.0611762    1.08876     -0.370643     0.0310415  -0.0393326    -0.137737   -0.175341    0.0122326   0.227146   -0.198676    -0.594525    0.386716    0.321239   -0.116723    0.33068      0.421961   -0.105332     0.20938     -0.108421     0.0396666   -0.357831    0.230983    -0.138278    -0.0557408    0.0932285
  0.0540197   0.546408    -0.457888     0.398857    -0.0241442  -0.234284     -0.072898   -0.185593    0.198087    0.163351   -0.207001    -0.132003    0.183919    0.207702   -0.283998   -0.140509    -0.164576    0.0729221   -0.410699    -0.233965     0.0992609   -0.229882    0.105177     0.250553    -0.0231947   -0.355105
  0.0316398   0.277508    -0.172575     0.339565    -0.0435823  -0.0201878    -0.112259   -0.545852   -0.0166414  -0.490817    0.648321     0.0363577   0.105178    0.399      -0.346263   -0.46422      0.114814   -0.0220904   -0.11233     -0.0437033    0.157246    -0.0104049  -0.0877153    0.107076     0.694437     0.166424
  0.0875377  -0.0274187   -0.00257078   0.0925146   -0.0410927   0.071249      0.0664947  -0.0060544  -0.118215   -0.0128845  -0.0692006    0.063307   -0.367595   -0.186723    0.16555     0.114857     0.0400514   0.154589    -0.0530351    0.0400078    0.0447465   -0.0465806  -0.19461     -0.091205    -0.12566     -0.0272195
 -0.0282006  -0.0391287    0.0189874   -0.0889836    0.0736239  -0.00982101   -0.168188   -0.0698484   0.0265909   0.127383    0.0965058    0.0629784   0.305435    0.186158   -0.106096   -0.014487     0.0614845  -0.097754     0.0121354    0.0344147   -0.114364     0.0725988   0.181301     0.15175      0.0662635    0.0635478
 -0.0700178   0.221241    -0.151936     0.407947    -0.0129109  -0.296902     -0.404073   -0.437831   -0.404116    0.359712    0.146791     0.135271   -0.0829882  -0.205123   -0.207127    0.0876354    0.176385    0.223557    -0.516708     0.310287    -0.18152     -0.40229    -0.26431     -0.440278    -0.0934664    0.637887
 -0.0581263  -0.0643135    0.226554    -0.394187     0.148198    1.02173      -0.448594   -0.25193    -0.511554    0.375356    0.020194     0.056128   -0.0867235   0.292755    0.383489    0.0785843    0.60149     0.0651907   -0.384233     0.118687    -0.099768     0.271182   -0.0884145   -0.243463    -0.221082     0.152098
  0.351446    0.519703     0.116295    -0.520847    -0.527298   -0.000178727   0.313945   -0.39044     0.156192    0.770638    0.244973    -0.0918229  -0.632571   -0.160304    0.0859344  -0.483847     0.313756   -0.347568    -0.163537    -0.130382     0.12065     -0.204033    0.0721359    0.407261     0.00581821  -0.0658788
  0.0312208  -0.059516     0.0752642    0.169203    -0.685085    0.302341      0.628655   -0.150283   -0.432804    0.6342      0.0281081   -0.245863    0.0477609  -0.09507     0.323906   -0.0687457    0.323424    0.117096    -0.164927    -0.558286     0.371916    -0.282197   -0.482416    -0.0489207    0.681681    -0.287691
 -0.394177    0.0585099   -0.400401     0.00463598  -1.04592    -0.271478     -0.398897    0.208094    0.131551   -0.313461    0.0302231   -0.882282   -0.752778    0.0798548  -0.37021     0.612022     0.0803314   0.00966567   0.0663661   -0.0589544   -0.145157     0.364299   -0.0963877    0.234229     0.246272    -0.0847195
 -0.0372049   0.441611    -0.506128     0.690511    -0.134594    0.146305     -0.101682   -0.587446   -0.032161   -0.330038   -0.229188     0.321953   -0.886697   -0.725925   -0.114987    0.37925      0.200978    0.0838491   -0.256254    -0.163528     0.526106    -0.215325   -0.377216    -0.00365359  -0.592707     0.217628
 -0.599714   -0.30114     -0.507889     0.537991    -0.0295852  -0.0987874    -0.506827   -0.332186    0.0599714   0.0167489  -0.00552826   0.270577    0.588302   -0.0260165   0.0130862   0.236247     0.138385   -0.554428    -0.0109113   -0.416318    -0.122486     0.0398285   0.381692    -0.0393431    0.226653    -0.380759
  0.236762   -0.383396     0.474835     0.147943     0.486708    0.245449     -0.644805   -0.424746    0.166766    0.110033   -0.387702     0.211353    0.0563981   0.309779   -0.401563    0.671879     0.370622   -0.604354    -0.784159    -0.311896     0.0652197    0.189573    0.372001     0.690946     0.370426     0.119321
 -0.134631    0.100132    -0.165779    -0.394213    -0.419083   -0.138493     -0.430273    0.295754    0.791812    0.311159   -0.168511     0.0613796   0.197653    0.221533    0.108059    0.606783     0.222692    0.13939      0.424518    -0.966177    -0.7751      -0.0410024   0.13441     -0.00427091  -0.333253    -0.40121
  0.339053    0.0719682    0.0753587   -0.750918    -0.0842967  -0.131646     -0.339651   -0.194312    0.354943    0.473647    0.56879      0.19509     0.414501    0.307253   -0.42973    -0.259531    -0.238275    0.193719     0.00867213   0.685444    -0.720045     0.690326    0.328336     0.317629    -0.135727    -0.0724586
 -0.0486146  -0.481605     0.0608061   -0.300155     0.158475    0.0967939     0.014304    0.464097   -0.118865   -0.383378    0.176741     0.306211   -0.027373   -0.197977    0.106574    0.00591287  -0.0734454  -0.0631646    0.535496     0.0809991   -0.275495     0.0895655   0.0650034   -0.245181    -0.465465     0.12807
  0.172834   -0.0250441    0.509337     0.0865774   -0.073193    0.192065     -0.935319   -0.0568984   0.0164741   0.260323    0.46006     -0.638034    0.556802    0.101757   -0.870176    0.733531    -0.361159    0.158819     0.43625      0.062118    -0.441247     0.410648   -0.280832    -0.287507     0.248701     0.0517606
  0.178647    0.437892     0.00276204   0.0310536   -0.107125   -0.675494      0.161147   -0.0523054   0.0874215   0.572424   -0.735868    -0.119631    0.277771   -0.196915    0.273566    0.235567    -0.325044    0.334042    -0.246622     0.00447337  -0.633263    -0.365186    0.121817     0.284782    -0.0501186   -0.144852
 -0.0552153   0.471508    -0.104259     0.085255    -0.0842931   0.0428836     0.219461   -0.338024   -0.0287341   0.208008   -0.0688548   -0.142629   -0.0283078   0.34241    -0.0420611  -0.351678     0.221045    0.0179045   -0.242343    -0.129908     0.456543    -0.388132   -0.159443     0.152256     0.230412    -0.216831
  0.038343   -0.224364    -0.0957378   -0.127653     0.53195     0.426381      1.04577     0.0342088   0.220114    0.104405   -1.05893      0.513503   -0.486901   -0.0141716   0.831866   -1.18051      0.221497    0.483587     0.0103589   -0.251392     0.493118     0.557877    0.168733     0.268224    -0.253268     0.144803
  0.863177   -0.0385044   -0.188406    -0.354594    -0.187374    0.262873      0.511714    0.364477    0.062431   -0.0369342   0.274223     0.542555   -0.434463    0.238279    0.622623    0.468164     0.133732    0.548554     0.131307     0.138943    -0.067476     0.50358     0.164363     0.175343    -0.292824    -0.0936372
 -0.461059   -0.00364838   0.201124     0.9483       0.493141    0.0903328    -0.263634    0.225397   -0.562531   -0.196063   -0.914285     0.0853959  -0.0680471  -0.403812    0.419151   -0.212602     0.117468   -0.144829     0.0132199   -0.673405     0.539459    -0.706046   -0.248463    -0.629561     0.951418     0.199002
  0.259345   -0.279963    -0.0530439    0.351648     0.103077    0.379674     -0.107405   -0.0551207   0.0611495  -0.31234     0.556628     0.406611   -0.341789    0.179884   -0.040863   -0.392205    -0.180679    0.0936142    0.595968    -0.253993     0.967592     0.33683    -0.379614    -1.0218      -0.0225209   -0.114541
  0.339868   -0.141374     0.508691     0.337694     0.14094     0.122696      0.039543   -0.362989   -0.685132   -0.366737    0.115092    -0.10256    -0.320702   -0.024914   -0.174006   -0.510006    -0.252664   -0.0599463   -0.300409     1.36191      0.439594     0.37341    -0.201565     0.251707     0.292387     0.397901
  0.152416   -0.393766     0.0476587    0.291238     0.0504965  -0.0511498     0.639626   -0.0942195  -0.690472    0.143158    0.488886    -0.124625    0.0288582  -0.682299    0.235589    0.158592     0.224149    0.121534    -0.613812     1.01507      0.0726469    0.19279    -0.00676667   0.49394      0.105162     0.517297[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410830
[ Info: iteration 2, average log likelihood -1.410815
[ Info: iteration 3, average log likelihood -1.410801
[ Info: iteration 4, average log likelihood -1.410787
[ Info: iteration 5, average log likelihood -1.410773
[ Info: iteration 6, average log likelihood -1.410760
[ Info: iteration 7, average log likelihood -1.410746
[ Info: iteration 8, average log likelihood -1.410734
[ Info: iteration 9, average log likelihood -1.410721
[ Info: iteration 10, average log likelihood -1.410709
┌ Info: EM with 100000 data points 10 iterations avll -1.410709
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.714180e+05
      1       7.033131e+05      -2.681050e+05 |       32
      2       6.907442e+05      -1.256891e+04 |       32
      3       6.856306e+05      -5.113518e+03 |       32
      4       6.829827e+05      -2.647916e+03 |       32
      5       6.813772e+05      -1.605572e+03 |       32
      6       6.801971e+05      -1.180062e+03 |       32
      7       6.792305e+05      -9.666325e+02 |       32
      8       6.784226e+05      -8.078844e+02 |       32
      9       6.777618e+05      -6.607508e+02 |       32
     10       6.772315e+05      -5.303149e+02 |       32
     11       6.767760e+05      -4.555093e+02 |       32
     12       6.763696e+05      -4.064439e+02 |       32
     13       6.759814e+05      -3.881553e+02 |       32
     14       6.756757e+05      -3.057132e+02 |       32
     15       6.754244e+05      -2.512650e+02 |       32
     16       6.751878e+05      -2.366516e+02 |       32
     17       6.749612e+05      -2.265254e+02 |       32
     18       6.747498e+05      -2.114875e+02 |       32
     19       6.745642e+05      -1.856028e+02 |       32
     20       6.744070e+05      -1.571936e+02 |       32
     21       6.742711e+05      -1.358869e+02 |       32
     22       6.741542e+05      -1.168662e+02 |       32
     23       6.740460e+05      -1.082456e+02 |       32
     24       6.739395e+05      -1.064265e+02 |       32
     25       6.738489e+05      -9.059087e+01 |       32
     26       6.737728e+05      -7.616470e+01 |       32
     27       6.737047e+05      -6.805465e+01 |       32
     28       6.736426e+05      -6.210479e+01 |       32
     29       6.735896e+05      -5.303055e+01 |       32
     30       6.735405e+05      -4.910635e+01 |       32
     31       6.734983e+05      -4.221976e+01 |       32
     32       6.734562e+05      -4.206837e+01 |       32
     33       6.734152e+05      -4.097809e+01 |       32
     34       6.733792e+05      -3.599523e+01 |       32
     35       6.733445e+05      -3.468150e+01 |       32
     36       6.733148e+05      -2.977681e+01 |       32
     37       6.732853e+05      -2.947509e+01 |       32
     38       6.732561e+05      -2.923216e+01 |       32
     39       6.732275e+05      -2.858320e+01 |       32
     40       6.731976e+05      -2.989685e+01 |       32
     41       6.731655e+05      -3.211091e+01 |       32
     42       6.731377e+05      -2.778256e+01 |       32
     43       6.731089e+05      -2.876192e+01 |       32
     44       6.730842e+05      -2.474812e+01 |       32
     45       6.730622e+05      -2.202268e+01 |       32
     46       6.730397e+05      -2.248024e+01 |       32
     47       6.730140e+05      -2.568784e+01 |       32
     48       6.729887e+05      -2.526204e+01 |       32
     49       6.729635e+05      -2.524402e+01 |       32
     50       6.729411e+05      -2.236826e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672941.1081948676)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422828
[ Info: iteration 2, average log likelihood -1.417668
[ Info: iteration 3, average log likelihood -1.416165
[ Info: iteration 4, average log likelihood -1.415001
[ Info: iteration 5, average log likelihood -1.413872
[ Info: iteration 6, average log likelihood -1.412979
[ Info: iteration 7, average log likelihood -1.412446
[ Info: iteration 8, average log likelihood -1.412163
[ Info: iteration 9, average log likelihood -1.412000
[ Info: iteration 10, average log likelihood -1.411889
[ Info: iteration 11, average log likelihood -1.411804
[ Info: iteration 12, average log likelihood -1.411734
[ Info: iteration 13, average log likelihood -1.411673
[ Info: iteration 14, average log likelihood -1.411618
[ Info: iteration 15, average log likelihood -1.411569
[ Info: iteration 16, average log likelihood -1.411524
[ Info: iteration 17, average log likelihood -1.411483
[ Info: iteration 18, average log likelihood -1.411444
[ Info: iteration 19, average log likelihood -1.411407
[ Info: iteration 20, average log likelihood -1.411372
[ Info: iteration 21, average log likelihood -1.411339
[ Info: iteration 22, average log likelihood -1.411308
[ Info: iteration 23, average log likelihood -1.411277
[ Info: iteration 24, average log likelihood -1.411248
[ Info: iteration 25, average log likelihood -1.411220
[ Info: iteration 26, average log likelihood -1.411193
[ Info: iteration 27, average log likelihood -1.411167
[ Info: iteration 28, average log likelihood -1.411141
[ Info: iteration 29, average log likelihood -1.411117
[ Info: iteration 30, average log likelihood -1.411092
[ Info: iteration 31, average log likelihood -1.411069
[ Info: iteration 32, average log likelihood -1.411046
[ Info: iteration 33, average log likelihood -1.411024
[ Info: iteration 34, average log likelihood -1.411003
[ Info: iteration 35, average log likelihood -1.410983
[ Info: iteration 36, average log likelihood -1.410963
[ Info: iteration 37, average log likelihood -1.410944
[ Info: iteration 38, average log likelihood -1.410927
[ Info: iteration 39, average log likelihood -1.410910
[ Info: iteration 40, average log likelihood -1.410894
[ Info: iteration 41, average log likelihood -1.410879
[ Info: iteration 42, average log likelihood -1.410864
[ Info: iteration 43, average log likelihood -1.410851
[ Info: iteration 44, average log likelihood -1.410838
[ Info: iteration 45, average log likelihood -1.410826
[ Info: iteration 46, average log likelihood -1.410814
[ Info: iteration 47, average log likelihood -1.410803
[ Info: iteration 48, average log likelihood -1.410793
[ Info: iteration 49, average log likelihood -1.410783
[ Info: iteration 50, average log likelihood -1.410773
┌ Info: EM with 100000 data points 50 iterations avll -1.410773
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.000501046   0.075017   -0.10983       0.10885     0.127943   -0.140405   -0.262224   -0.249155     -0.121385     0.192971   -0.0109921    0.0685247    0.368199    0.163261   -0.24148    -0.169497   -0.136532    -0.057878    -0.347814     0.128301   -0.195741    0.00948117   0.0261452     0.244121    0.266316    0.13661
  0.11343       0.555979   -0.581298      0.758113    0.0717323  -0.186521   -0.363521   -0.647849     -0.344275     0.362733   -0.0679347    0.260401     0.321726    0.4337     -0.37729    -0.65422     0.27747     -0.26851     -0.00652291  -0.493788   -0.140839   -0.548732     0.151421     -0.195433    0.166441   -0.131609
  0.188816      0.235156    0.141341      0.391377   -0.813606    0.0108273   1.0667     -0.296646      0.0120986    0.590258    0.176878     0.12238      0.262988   -0.213267    0.399059    0.115217    0.458302     0.251402     0.157224    -0.427694    0.0687526  -0.131017    -0.1431        0.256355    0.897457   -0.155946
 -0.386294      0.215042    0.0987217    -0.0116294  -0.507563   -0.363261   -0.63944    -0.0659206    -0.42775      0.0891205   0.722866    -0.705622     0.385562    0.0312447  -0.786891    1.0135     -0.0219746   -0.307338     0.142989     0.118736   -0.625198   -0.527838    -0.178677     -0.0746959   0.265592    0.0439492
 -0.35123      -0.0320457  -0.0557643     0.198911    0.103272   -0.205114   -0.0511951   0.0450105     0.322868    -0.302902    0.0386872   -0.0209188    0.0993558   0.0171432   0.0269022   0.21365     0.140991     0.155302     0.229202     0.0187101  -0.103773   -0.026722     0.111043     -0.0835361  -0.210856   -0.0589744
  0.228619      0.577236    0.350265     -0.288534   -0.03605    -0.327096    0.0901128  -0.17804       0.213408     0.923227   -0.799584    -0.347425     0.16089    -0.0994551   0.184714    0.360164    0.0931025    0.213351    -0.413487    -0.155145   -0.366328   -0.48642      0.0698812     0.33894    -0.153925   -0.253959
  0.512978      0.643271   -0.365258     -0.115159   -0.423059    0.186292   -0.325038   -0.171226      0.796684     0.246068    0.132209     0.00942506   0.0022213   0.413099   -0.8146      0.617973    0.072668     0.381049    -0.156111    -0.199538   -0.286067    0.488033    -0.0219483    -0.0851006  -0.104247   -0.413054
  0.296383     -0.0701407   0.0254273    -0.126548   -0.0697318   0.175684    0.188095    0.155914     -0.158715     0.119434    0.0181913    0.131302    -0.178192    0.0220058   0.0981633   0.0887097   0.0118766   -0.00671105   0.0489793   -0.0203502   0.0526766  -0.00958723  -0.000245066   0.090228   -0.0172396  -0.0282904
  0.242988     -0.630291    0.221399     -0.409317    0.293318   -0.160223    0.211387    0.497857      0.0566782   -0.173553    0.12235     -0.125756     0.558936    0.281331   -0.044279    0.0583439  -0.376199     0.157429     0.186981     0.0883843  -0.158589    0.198041     0.0806144     0.331987    0.251006    0.105427
  0.281609     -0.0872352   0.0733721    -0.187551    0.448439    0.321534    0.97466     0.121459      0.299856     0.0934282  -0.653879     0.660206    -0.518134    0.245136    0.664652   -0.766433    0.37929      0.494855     0.0204037   -0.198903    0.629852    0.636351     0.126853      0.216237   -0.175394    0.0335804
  0.133439     -0.411045    0.303499      0.0289257   0.398328    0.230559   -0.646105   -0.360528      0.138688     0.227757   -0.244977     0.264202     0.188245    0.303309   -0.440452    0.58433     0.303553    -0.868789    -0.736372    -0.395768    0.0493374   0.160304     0.419305      0.684657    0.428296    0.0292631
  0.121342     -0.170594    0.568338     -0.349293   -0.34685     0.0111818   0.490683    0.21533      -0.254393     0.28066     0.0151758   -0.714103    -0.411761   -0.104329    0.133186   -0.343838    0.100579     0.0214057   -0.0466919   -0.0338226   0.316788   -0.345557    -0.582834      0.0838052   0.11666     0.0291178
 -0.0557798     0.0375405  -0.0398369     0.892646    0.348413   -0.128257   -0.173043   -0.0812913     0.369024    -0.377096   -0.696107     0.359392    -0.100393   -0.30103     0.191992    0.51367     0.10112      0.299388    -0.338578    -0.243211    0.197094   -0.23287     -0.146136      0.169767    0.342062   -0.0870497
  0.040846     -0.338913    0.355407     -0.172771    0.606407    0.0665542  -0.212871    0.472202     -0.03025     -0.691814   -0.250922     0.307843    -0.0862839  -0.101607   -0.186832    0.428393   -0.327544    -0.0215121    0.302273     0.687445   -0.270034    0.0251514    0.15463      -0.218233   -0.57021     0.166976
 -0.210684     -0.208464   -0.27041      -0.288832   -0.362275   -0.123873   -0.155419    0.578387      0.625922     0.034859   -0.217514     0.300637     0.112494    0.128509    0.545251    0.497578    0.00827235  -0.134411     0.652146    -0.808173   -0.504463   -0.435565     0.216038     -0.230494   -0.403927   -0.573103
  0.196608      0.267249   -0.798231     -0.285112   -0.486269   -0.402995    0.294298   -0.0111714    -0.157261     0.101245    0.0882484    0.677375    -0.429832   -0.429344    0.247908    0.403122   -0.0483607   -0.0386431   -0.356354     0.095453   -0.521838    0.109195     0.158716      0.411513   -0.575834    0.139636
  0.205021     -0.0420508  -0.0691267    -0.52734    -0.160826   -0.0916125   0.19579     0.264667     -0.0724235    0.230887    0.554017     0.115804     0.195476    0.1005     -0.050815   -0.100599   -0.132694     0.278171     0.25493      0.340647   -0.645429    0.340533     0.175198      0.198437   -0.119545    0.180231
  0.58389       0.603548   -0.309185      0.142751   -0.197083    0.310504    0.836703   -0.235468      0.0644557   -0.412987   -0.252854     0.190615    -0.532988   -0.459434   -0.145327   -0.210783   -0.623114     0.496427    -0.189644    -0.0660958   0.846449   -0.575681    -0.474842     -0.499407   -0.269693    0.166872
 -0.356358      0.0808736  -0.212657     -0.0396535   0.0271825   0.10365     0.0542607   0.0514919     0.32663     -0.706401    0.162618    -0.171129    -0.694413   -0.151957   -0.0821224   0.566205    0.898783    -0.439234     0.230864    -0.0499875   0.474798   -0.405523     0.217232     -0.0397959  -0.557642   -0.0157322
 -0.223253     -0.0805994   0.0243823     0.384756    0.04727     0.0961523   0.0101276  -0.22824      -0.553755    -0.0381559  -0.10094     -0.090376    -0.119437   -0.16815     0.144835   -0.281424    0.0714024   -0.129141    -0.319443    -0.0311597   0.585115   -0.375422    -0.446052     -0.267076    0.317281    0.156519
 -0.0371137     0.538232    0.053373      0.0952593  -0.0700123  -0.338187    0.0922225  -0.442287      0.315531    -0.392707    0.454832    -0.581821    -0.331943    0.901193   -0.156088   -0.241034    0.212755     0.332162    -0.527049     0.222696    0.44391    -0.175042    -0.0332383     0.228601    0.710622    0.114354
  0.0106747     0.324486    0.170114     -0.75979    -0.097732   -0.293867   -0.406367   -0.213253      0.44775      0.2536      0.401259     0.362114     0.0371687   0.110967   -0.05501    -0.555991   -0.245429    -0.205267     0.238375     0.279464   -0.320118    0.230125     0.291967      0.148693   -0.195435   -0.205204
 -0.425633      0.495313   -0.556124      0.743963   -0.617505   -0.831236    0.528433    0.0387325     0.00390773  -0.381254   -0.273314    -0.592456    -0.127447   -0.586275   -0.460971   -0.090409   -0.683819     0.288987     0.577322    -0.0378282  -0.0599015  -0.309004     0.232261      0.116149   -0.287406   -0.182993
  0.0116452    -0.339931   -0.447735      0.542906    0.0593298   0.266402   -0.22142    -0.0622197    -0.0844554   -0.473174    0.830304     0.422846    -0.162491    0.0613617  -0.250554   -0.365077   -0.246549    -0.0983432    0.568606    -0.0383426   0.622369    0.547828    -0.184358     -0.480763    0.166314   -0.131651
 -0.120872     -0.109398    0.789553     -0.399964    0.105293    0.3453     -0.28833    -0.25629      -0.0883123    0.359596   -0.136646    -0.336679     0.294241    0.522438    0.0532267   0.290375    0.538604     0.0336506    0.0326163   -0.0876537  -0.0718035  -0.097008     0.338026     -0.165674   -0.130872    0.160826
 -0.378749     -0.348221    0.403864      0.0719951  -0.0420222  -0.0189029  -0.944911   -0.0702391     0.556243    -0.286356   -0.257187    -0.380776     0.25957     0.291213   -0.247002    0.405931   -0.103978     0.012192     0.457548    -0.382103   -0.22603     0.611266    -0.0184286    -0.202989   -0.181937   -0.199703
  0.352645     -0.0857435   0.378212      0.316574    0.172997    0.14918     0.156735   -0.412364     -0.717132    -0.0540956   0.340631    -0.158211    -0.107152   -0.190139   -0.2163     -0.184182    0.0461498    0.0209877   -0.481671     1.19533     0.119326    0.560478    -0.108804      0.539655    0.173589    0.527131
  0.0544908    -0.282696   -0.52567      -0.478398   -0.0365796   0.115318    0.547768    0.774683     -0.57106      0.489836   -0.290887     0.400665     0.0312766  -0.476138    0.0134056  -0.266562   -0.476519    -0.680033    -0.0163856    0.134503    0.275378   -0.358832     0.0859133     0.231909    0.0950478  -0.369484
 -0.158265      0.0943933   0.00279861    0.259712   -0.141203    0.295684   -0.385575   -0.534696     -0.3093       0.247433    0.0106524    0.091758    -0.358402   -0.364394   -0.0432688   0.0171497   0.495605    -0.242312    -0.289261    -0.069074    0.294219    0.0213256   -0.246556     -0.281289   -0.0617217   0.0900782
 -0.101404      0.053179   -0.751216     -0.22058     0.240549    0.189052   -0.0203972   0.341299     -0.290808     0.0704838   0.00737103  -0.233464     0.0143631   0.190338    0.8265     -0.535616   -0.377918     0.317792    -0.172869     0.105935   -0.512478    0.0972807   -0.41795       0.327492   -0.29923    -0.0826472
  0.269438     -0.293233    0.000923364   0.319378   -0.359146    0.334662    0.0597888  -0.000609896  -0.480299     0.0282078   0.370819     0.256813    -0.249249   -0.349033    0.665971    0.288651    0.00122915   1.18977      0.140693     0.417483   -0.2675      0.0722535   -0.0661912    -0.570179   -0.169802    0.289313
 -0.360155     -0.473634    0.14729       0.0240322   0.581744   -0.0463137   0.267221    0.398139     -0.865823     0.0975766   0.0858644    0.420033     0.264293   -0.237249    0.701187   -0.37318     0.624705    -0.574364     0.634726     0.0772931  -0.182129   -0.226678     0.245556     -0.205262   -0.306933    0.235271[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410764
[ Info: iteration 2, average log likelihood -1.410755
[ Info: iteration 3, average log likelihood -1.410746
[ Info: iteration 4, average log likelihood -1.410738
[ Info: iteration 5, average log likelihood -1.410729
[ Info: iteration 6, average log likelihood -1.410721
[ Info: iteration 7, average log likelihood -1.410714
[ Info: iteration 8, average log likelihood -1.410706
[ Info: iteration 9, average log likelihood -1.410698
[ Info: iteration 10, average log likelihood -1.410691
┌ Info: EM with 100000 data points 10 iterations avll -1.410691
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
